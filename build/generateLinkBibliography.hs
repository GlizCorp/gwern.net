#!/usr/bin/env runghc
{-# LANGUAGE OverloadedStrings #-}
module Main where

-- Generate "link bibliographies" for Gwern.net pages.
--
-- Link bibliographies are similar to directory indexes in compiling a list of all links on a
-- Gwern.net page/essay, in order, with their annotations (where available). They are the
-- forward-citation dual of backlinks, are much easier to synoptically browse than mousing over
-- links one at a time, and can help provide a static version of the page (ie. download page + link
-- bibliography to preserve the annotations).
--
-- Link bibliographies are generated by parsing each $PAGE (provided in default.html as '$url$'),
-- filtering for Links using the Pandoc API, querying the metadata, generating a numbered list of
-- links, and then writing out the generated Markdown file to 'metadata/annotations/link-bibliography/$ESCAPED($PAGE).html'.
-- They are compiled like normal pages by Hakyll, and they are exposed to readers as an additional
-- link in the page metadata block, paired with the backlinks.

import Control.Monad (when)
import Data.List (isPrefixOf, isSuffixOf, nub, sort)
import Data.Text.Titlecase (titlecase)
import qualified Data.Map as M (lookup, keys)
import System.FilePath (takeDirectory, takeFileName)

import Data.Text.IO as TIO (readFile)
import qualified Data.Text as T (pack, unpack)
import System.Directory (doesFileExist)
import Control.Monad.Parallel as Par (mapM_)

import Text.Pandoc (Inline(Code, Link, Str, Space, Span, Strong), def, nullAttr, nullMeta, readMarkdown, readerExtensions, writerExtensions, runPure, pandocExtensions, ListNumberDelim(DefaultDelim), ListNumberStyle(LowerAlpha), Block(Para, OrderedList), Pandoc(..), writeHtml5String)
import Text.Pandoc.Walk (walk)

import LinkBacklink (getBackLinkCheck, getSimilarLinkCheck, getLinkBibLink)
import LinkMetadata (generateAnnotationTransclusionBlock, readLinkMetadata, authorsTruncate, hasAnnotation)
import LinkMetadataTypes (Metadata, MetadataItem)
import Query (extractURLs, extractLinks)
import Typography (typographyTransform)
import Utils (writeUpdatedFile, replace, printRed)
import Interwiki (convertInterwikiLinks)

main :: IO ()
main = do
          md <- readLinkMetadata
          -- build HTML fragments for each page or annotation link, containing just the list and no header/full-page wrapper, so they are nice to transclude *into* popups:
          Par.mapM_ (writeLinkBibliographyFragment md) $ sort $ M.keys md

-- don't waste the user's time if the annotation is not heavily linked, as most are not, or if all the links are WP links:
mininumLinkBibliographyFragment :: Int
mininumLinkBibliographyFragment = 3

writeLinkBibliographyFragment :: Metadata -> FilePath -> IO ()
writeLinkBibliographyFragment md path =
  case M.lookup path md of
       Nothing -> return ()
       Just (_,_,_,_,_,"") -> return ()
       Just (_,_,_,_,_,abstract) -> do
        let self = takeWhile (/='#') path
            selfAbsolute = "https://www.gwern.net"++self
        -- toggle between parsing the full original Markdown page, and just the annotation abstract:
        linksRaw <- if head path == '/' && '.'`notElem`path then
                      if '#' `elem` path && abstract=="" then return [] -- if it's just an empty annotation triggered by a section existing, ignore
                      else
                        extractLinksFromPage (tail (takeWhile (/='#') path) ++ ".page")
                    else return $ map T.unpack $ extractLinks False (T.pack abstract)
            -- delete self-links, such as in the ToC of scraped abstracts, or newsletters linking themselves as the first link (eg '/newsletter/2022/05' will link to 'https://www.gwern.net/newsletter/2022/05' at the beginning)
        let links = filter (\l -> not (self `isPrefixOf` l || selfAbsolute `isPrefixOf` l)) linksRaw
        when (length (filter (\l -> not ("https://en.wikipedia.org/wiki/" `isPrefixOf` l))  links) >= mininumLinkBibliographyFragment) $
          do backlinks    <- mapM (fmap snd . getBackLinkCheck) links
             similarlinks <- mapM (fmap snd . getSimilarLinkCheck) links
             let pairs = linksToAnnotations md links
                 pairs' = zipWith3 (\(a,b) c d -> (a,b,c,d)) pairs backlinks similarlinks
                 body = [Para [Strong [Str "Link Bibliography"], Str ":"], generateLinkBibliographyItems pairs']
                 document = Pandoc nullMeta body
                 html = runPure $ writeHtml5String def{writerExtensions = pandocExtensions} $
                   walk typographyTransform $ walk convertInterwikiLinks $ walk (hasAnnotation md) document
             case html of
               Left e   -> printRed (show e)
               -- compare with the old version, and update if there are any differences:
               Right p' -> do let (path',_) = getLinkBibLink path
                              when (path' == "") $ error ("generateLinkBibliography.hs: writeLinkBibliographyFragment: writing out failed because received empty path' from getLinkBibLink for original path: " ++ path)
                              writeUpdatedFile "link-bibliography-fragment" path' p'

generateLinkBibliographyItems :: [(String,MetadataItem,FilePath,FilePath)] -> Block
generateLinkBibliographyItems [] = Para []
generateLinkBibliographyItems items = OrderedList (1, LowerAlpha, DefaultDelim) $ map generateLinkBibliographyItem items
generateLinkBibliographyItem  :: (String,MetadataItem,FilePath,FilePath) -> [Block]
generateLinkBibliographyItem (f,(t,aut,_,_,_,""),_,_)  = -- short:
  let f'
        | "http" `isPrefixOf` f = f
        | "index" `isSuffixOf` f = takeDirectory f
        | otherwise = takeFileName f
      authorShort = authorsTruncate aut
      authorSpan  = if authorShort/=aut then Span ("",["full-authors-list"],[("title", T.pack aut)]) [Str (T.pack $ authorsTruncate aut)]
                    else Str (T.pack authorShort)
      author = if aut=="" || aut=="N/A" then []
               else
                 [Str ",", Space, authorSpan]
      -- I skip date because files don't usually have anything better than year, and that's already encoded in the filename which is shown
  in
    let linkAttr = if "https://en.wikipedia.org/wiki/" `isPrefixOf` f then ("",["include-annotation", "include-spinner-not"],[]) else nullAttr
    in
    if t=="" then
      [Para (Link linkAttr [Code nullAttr (T.pack f')] (T.pack f, "") : author)]
    else
      [Para (Link linkAttr [Str "“", Str (T.pack $ titlecase t), Str "”"] (T.pack f, "") : author)]
-- long items:
generateLinkBibliographyItem (f,a,bl,sl) = generateAnnotationTransclusionBlock (f,a) bl sl ""

extractLinksFromPage :: String -> IO [String]
extractLinksFromPage "" = error "generateLinkBibliography: `extractLinksFromPage` called with an empty '' argument—this should never happen!"
extractLinksFromPage path =
  do existsp <- doesFileExist path
     if not existsp then return [] else
                    do f <- TIO.readFile path
                       let pE = runPure $ readMarkdown def{readerExtensions=pandocExtensions} f
                       return $ case pE of
                                  Left  _ -> []
                                  -- make the list unique, but keep the original ordering
                                  Right p -> map (replace "https://www.gwern.net/" "/") $
                                                     filter (\l -> head l /= '#') $ -- self-links are not useful in link bibliographies
                                                     nub $ map T.unpack $ extractURLs p -- TODO: maybe extract the title from the metadata for nicer formatting?

linksToAnnotations :: Metadata -> [String] -> [(String,MetadataItem)]
linksToAnnotations m = map (linkToAnnotation m)
linkToAnnotation :: Metadata -> String -> (String,MetadataItem)
linkToAnnotation m u = case M.lookup u m of
                         Just i  -> (u,i)
                         Nothing -> (u,("","","","",[],""))
