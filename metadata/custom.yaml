- - /docs/genetics/selection/2007-maejima.pdf
  - Traits and genotypes may predict the successful training of drug detection dogs
  - Masami Maejima, Miho Inoue-Murayama, Keiichi Tonosaki, Naoto Matsuura, Shota Kato,
    Yasuhiro Saito, Alexander Weiss, Yuichi Murayama, Shin'ichi Ito
  - '2007'
  - 10.1016/j.applanim.2006.10.005
  - ! 'In Japan, approximately 30% of dogs that enter training programs to become
    drug detection dogs successfully complete training. To clarify factors related
    to the aptitude of drug detection dogs and develop an assessment tool, we evaluated
    genotypes and behavioural traits of 197 candidate dogs. The behavioural traits
    were evaluated within 2 weeks from the start of training and included <em>general
    activity</em>, <em>obedience training</em>, <em>concentration</em>, <em>affection
    demand</em>, <em>aggression toward dogs</em>, <em>anxiety</em>, and <em>interest
    in target</em>. Principal components analysis of these ratings yielded two components:
    Desire for Work and Distractibility. Desire for Work was significantly related
    to successful completion of training (<em>p</em>&lt;0.001). Since 93.3% of dogs
    that passed training and 53.3% of the dogs that failed training had Desire for
    Work scores of 45 or higher, we will be able to reject about half of inappropriate
    dogs before 3 months of training by adopting this cut-off point. We also surveyed
    eight polymorphic regions of four genes that have been related to human personality
    dimensions. Genotypes were not related to whether dogs passed, but there was a
    weak relationship between Distractibility and a 5<span class="smallcaps-auto">HTT</span> haplotype (<em>p</em> &lt;
    0.05).'
- - https://onlinelibrary.wiley.com/doi/full/10.1111/joim.12926
  - ! 'The Chinese National Twin Registry: a ''gold mine'' for scientific research'
  - W. Gao, W. Cao, J. Lv, C. Yu, T. Wu, S. Wang, L. Meng, D. Wang, Z. Wang, Z. Pang,
    M. Yu, H. Wang, X. Wu, Z. Dong, F. Wu, G. Jiang, X. Wang, Y. Liu, J. Deng, L.
    Lu, L. Li
  - 2019-07-04
  - 10.1111/joim.12926
  - The Chinese National Twin Registry (<span class="smallcaps-auto">CNTR</span>) currently includes data from 61&thinsp;566
    twin pair from 11 provinces or cities in China. Of these, 31&thinsp;705, 15&thinsp;060 and 13
    531 pairs are monozygotic, same-sex dizygotic and opposite-sex dizygotic pairs,
    respectively, determined by opposite sex or intrapair similarity. Since its establishment
    in 2001, the <span class="smallcaps-auto">CNTR</span> has provided an important resource for analysing genetic and
    environmental influences on chronic diseases especially cardiovascular diseases.
    Recently, the <span class="smallcaps-auto">CNTR</span> has focused on collecting biologic specimens from disease-concordant
    or disease-discordant twin pairs or from twin pairs reared apart. More than 8000
    pairs of these twins have been registered, and blood samples have been collected
    from more than 1500 pairs. In this review, we summarize the main findings from
    univariate and multivariate genetic effects analyses, gene-environment interaction
    studies, omics studies exploring <span class="smallcaps-auto">DNA</span> methylation and metabolomic markers associated
    with phenotypes. There remains further scope for <span class="smallcaps-auto">CNTR</span> research and data mining.
    The plan for future development of the <span class="smallcaps-auto">CNTR</span> is described. The <span class="smallcaps-auto">CNTR</span> welcomes worldwide
    collaboration.
- - /docs/iq/2014-johnson.pdf
  - ! 'Genetics of Intellectual and Personality Traits Associated with Creative Genius:
    Could Geniuses Be Cosmobian Dragon Kings?'
  - Wendy Johnson, Thomas J. Bouchard Jr.
  - '2014'
  - 10.1002/9781118367377.ch14
  - ! '[Behavioral genetics discussion of eminence/genius: intelligence, developmental
    processes, psychopathology, and creativity scales all contribute to accomplishment
    but leave much unexplained, in particular, the odd pattern of inheritance where
    genius runs in families but highly sporadically and not following any standard
    Mendelian or polygenic inheritance pattern. The authors refer to the concept of
    ''emergenesis'', where emergenic traits are not additive combinations of subtraits
    (as is strongly the case for traits like intelligence) but rather are multiplicative
    combinations, which are epistatic at the genetic level. Because all subtraits
    must be present to have a chance of producing the overall trait, emergenic traits
    can be highly genetically influenced yet still rare and sporadically appearing
    within families. (<em>The Wiley Handbook of Genius</em> 2014, chapter 14)]'
- - https://archive.org/details/originsofgeniusd00simo
  - ! 'Origins of Genius: Darwinian Perspectives on Creativity'
  - Dean Keith Simonton
  - '1999'
  - ''
  - How can we account for the sudden appearance of such dazzling artists and scientists
    as Mozart, Shakespeare, Darwin, or Einstein? How can we define such genius? What
    conditions or personality traits seem to produce exceptionally creative people?
    Is the association between genius and madness really just a myth? These and many
    other questions are brilliantly illuminated in <em>The Origins of Genius</em>.
    Dean Simonton convincingly argues that creativity can best be understood as a
    Darwinian process of variation and selection. The artist or scientist generates
    a wealth of ideas, and then subjects these ideas to aesthetic or scientific judgment,
    selecting only those that have the best chance to survive and reproduce. Indeed,
    the true test of genius is the ability to bequeath an impressive and influential
    body of work to future generations. Simonton draws on the latest research into
    creativity and explores such topics as the personality type of the genius, whether
    genius is genetic or produced by environment and education, the links between
    genius and mental illness (Darwin himself was emotionally and mentally unwell),
    the high incidence of childhood trauma, especially loss of a parent, amongst Nobel
    Prize winners, the importance of unconscious incubation in creative problem-solving,
    and much more. Simonton substantiates his theory by examining and quoting from
    the work of such eminent figures as Henri Poincare, W. H. Auden, Albert Einstein,
    Marie Curie, Charles Darwin, Niels Bohr, and many others. For anyone intrigued
    by the spectacular feats of the human mind, <em>The Origins of Genius</em> offers
    a revolutionary new way of understanding the very nature of creativity.
- - http://cogprints.org/772/3/152.pdf#page=8
  - ! 'Emergenesis: Genetic Traits That May Not Run in Families: Genius'
  - D. T. Lykken, M. McGue, A. Tellegen, T. J. Bouchard, J
  - '1992'
  - ''
  - ! '<p>[Further discussion of “emergenesis” and relationship to genius: why are geniuses, while sometimes clearly affiliated with entire clans, so sporadic even within those? This is difficult to explain on any environmental or simple additive genetic grounds, suggesting that it may require entire complexes of exactly aligned genes and environmental factors.]</p><p>Human genius has always been a problem for both environmentalists and hereditarians to understand (Galton, 1869; Kroeber, 1944; Simonton, 1988.) There have been families of genius, of course—the Bernoullis and the Baths, the Darwins and the Huxleys, the musical Marsalis family—but it is the solitary genius, rising like a great oak in a forest of scrub and bramble, who challenges our understanding. Carl Friedrich Gauss, ranked with Archimedes and Newton as one of the “princes of mathematics,” had uneducated parents. His mother was illiterate, yet the boy had taught himself to read and to do simple arithmetic by the time he was 3 years old (Buhler, 1981).</p><p>…Suppose that Gauss or Ramanujan had been born with a healthy <span class="smallcaps-auto">MZ</span> twin who was spirited away to be reared by some country parson in Oxfordshire. Barring cholera or other accident, is it not likely that the parson’s surname too would now be immortal? Ramanujan died young without offspring; his parents and one brother apparently were unexceptional. Although Gauss provided rich stimulation and opportunity for his six offspring (by two different and highly cultivated wives), none of them distinguished themselves.<sup>2</sup> But if the genius of these men was prefigured in their genes, why was it never manifested elsewhere in their lineage? The answer is, we think, that genius consists of unique configurations of attributes that cannot be transmitted in half helpings.</p>'
- - http://cogprints.org/772/3/152.pdf
  - ! 'Emergenesis: Genetic Traits That May Not Run in Families'
  - D. T. Lykken, M. McGue, A. Tellegen, T. J. Bouchard, J
  - '1992'
  - ''
  - Traits that are influenced by a configuration, rather than by a simple sum, of
    polymorphic genes may not be seen to be genetic unless one studies monozygotic
    twins (who share all their genes and thus all gene configurations) because such
    'emergenic' traits will tend not to run in families. Personal idiosyncrasies that
    have been found to be surprisingly concordant among monozygotic twins separated
    in infancy and reared apart may be emergenic traits. More speculatively, important
    human traits like leadership, genius in its many manifestations, being an effective
    therapist or parent, as well as certain psychopathological syndromes may also
    be emergenic. These ideas reemphasize the importance of the role played in human
    affairs by genetic variation.
- - https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1601-183X.2006.00233.x
  - The mechanism of emergenesis
  - D. T. Lykken
  - '2006'
  - 10.1111/j.1601-183X.2006.00233.x
  - ! 'The intraclass correlations of monozygotic twins who were separated in infancy
    and reared apart (<span class="smallcaps-auto">MZA</span> twins) provide estimates of trait heritability, and the
    Minnesota Study of Twins Reared Apart [<span class="smallcaps-auto">MZA</span>: Bouchard et al. (1990), ''The sources
    of human psychological differences: the Minnesota study of twins reared apart'',
    <em>Science</em> 250, 223--228] has demonstrated that <span class="smallcaps-auto">MZA</span> pairs are as similar
    in most respects as MZ pairs reared together. Some polygenic traits—e.g. stature,
    IQ, harm avoidance, negative emotionality, interest in sports—are polygenic-additive,
    so pairs of relatives resemble one another on the given trait in proportion to
    their genetic similarity. But the existence and the intensity of other important
    psychological traits seem to be emergent properties of gene configurations (or
    configurations of independent and partially genetic traits) that interact multiplicatively
    rather than additively. Monozygotic (MZ) twins may be strongly correlated on such
    emergenic traits, while the similarity of dizygotic (DZ) twins, sibs or parent-offspring
    pairs may be much less than half that of MZ pairs. Some emergenic traits, although
    strongly genetic, do not appear to run in families. <span class="smallcaps-auto">MISTRA</span> has provided at least
    two examples of traits for which <span class="smallcaps-auto">MZA</span> twins are strongly correlated, and <span class="smallcaps-auto">DZA</span> pairs
    correlate near zero, while DZ pairs reared together (<span class="smallcaps-auto">DZT</span>s) are about half as similar
    as <span class="smallcaps-auto">MZT</span>s. These findings suggest that even more traits may be emergenic than those
    already identified. Studies of adoptees reared together (who are perhaps more
    common than twins reared apart) may help to identify traits that are emergenic,
    but that also are influenced by a common rearing environment. [Keywords: Epistasis,
    heritability, polygenic additivity, psychophysiology]'
- - https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-8986.1982.tb02489.x
  - ! 'Research With Twins: The Concept of Emergenesis'
  - D. T. Lykken
  - '1982'
  - 10.1111/j.1469-8986.1982.tb02489.x
  - ! 'Preliminary findings from an on-going study of monozygotic twins reared apart
    (<span class="smallcaps-auto">MZA</span>) and data from a larger sample of twins reared together (<span class="smallcaps-auto">MZT</span> and <span class="smallcaps-auto">DZT</span>), indicate
    a surprisingly strong influence of genetic variation on aptitudes, psychophysiological
    characteristics, personality traits and even dimensions of attitude and interest.
    For some of these variables, <span class="smallcaps-auto">MZT</span> and <span class="smallcaps-auto">MZA</span> twins show high intra-class correlations
    while <span class="smallcaps-auto">DZT</span> twins are no more similar than pairs of unrelated persons. It is suggested
    that such traits are ''emergenic'', i.e., that they are determined by the interaction—rather
    than the sum—of genetic influences. Emergenic traits, although perhaps strongly
    genetic, will not tend to run in families and for this reason have been neglected
    by students of behavior genetics. For this and several other listed reasons, wider
    use of twins in psychological research is strongly recommended. [Keywords: twins,
    behavior genetics, emergenesis, range correction, <span class="smallcaps-auto">EEG</span> spectra]'
- - https://www.nature.com/articles/s41467-017-01284-y
  - Inequality in genetic cancer risk suggests bad genes rather than bad luck
  - Mats Julius Stensrud, Morten Valberg
  - '2017'
  - 10.1038/s41467-017-01284-y
  - Heritability is often estimated by decomposing the variance of a trait into genetic
    and other factors. Interpreting such variance decompositions, however, is not
    straightforward. In particular, there is an ongoing debate on the importance of
    genetic factors in cancer development, even though heritability estimates exist.
    Here we show that heritability estimates contain information on the distribution
    of absolute risk due to genetic differences. The approach relies on the assumptions
    underlying the conventional heritability of liability model. We also suggest a
    model unrelated to heritability estimates. By applying these strategies, we describe
    the distribution of absolute genetic risk for 15 common cancers. We highlight
    the considerable inequality in genetic risk of cancer using different metrics,
    e.g., the Gini Index and quantile ratios which are frequently used in economics.
    For all these cancers, the estimated inequality in genetic risk is larger than
    the inequality in income in the <span class="smallcaps-auto">USA</span>.
- - /docs/genetics/selection/2019-sella.pdf
  - Thinking About the Evolution of Complex Traits in the Era of Genome-Wide Association
    Studies
  - Guy Sella, Nicholas H. Barton
  - 2019-06-21
  - 10.1146/annurev-genom-083115-022316
  - ! 'Many traits of interest are highly heritable and genetically complex, meaning
    that much of the variation they exhibit arises from differences at numerous loci
    in the genome. Complex traits and their evolution have been studied for more than
    a century, but only in the last decade have genome-wide association studies (<span class="smallcaps-auto">GWAS</span>s)
    in humans begun to reveal their genetic basis. Here, we bring these threads of
    research together to ask how findings from <span class="smallcaps-auto">GWAS</span>s can further our understanding
    of the processes that give rise to heritable variation in complex traits and of
    the genetic basis of complex trait evolution in response to changing selection
    pressures (i.e., of polygenic adaptation). Conversely, we ask how evolutionary
    thinking helps us to interpret findings from <span class="smallcaps-auto">GWAS</span>s and informs related efforts
    of practical importance. [Keywords: evolution, genome-wide association study,
    <span class="smallcaps-auto">GWAS</span>, quantitative genetics, complex traits, polygenic adaptation, genetic architecture]'
- - https://www.newyorker.com/magazine/2019/07/22/the-promise-and-price-of-cellular-therapies
  - ! 'The Promise and Price of Cellular Therapies: New ''living drugs''—made from
    a patient''s own cells—can cure once incurable cancers. But can we afford them?'
  - Siddhartha Mukherjee
  - 2019-07-15
  - ''
  - ! '[Mukherjee traces the evolution of <span class="smallcaps-auto">CAR</span> T-cell therapy, a form of immunotherapy
    that uses engineered immune cells to eliminate cancer, beginning with the development
    of bone marrow transplantation by Fred Hutch''s Dr. E. Donnall Thomas. In his
    article, Mukherjee profiles recent T-cell therapy research by Dr. Carl June at
    the Perelman School of Medicine of the University of Pennsylvania and other leaders
    in the immunotherapy field including Drs. Steve Rosenberg and Michel Sadelain
    and the Hutch''s Drs. Stan Riddell and Phil Greenberg. In addition to the promising
    early successes with this new therapy, Mukherjee explores some of the challenges
    that remain to making these approaches more accessible and affordable. In particular,
    the staggering price of custom single-patient <span class="smallcaps-auto">CAR</span>-T immunotherapy is in the hundreds
    of thousands or millions of dollars, posing a challenge to health insurance and
    national healthcare systems.]'
- - https://www.cs.cmu.edu/~noamb/papers/19-Science-Superhuman.pdf
  - Pluribus:Superhuman AI for multiplayer poker
  - Noam Brown, Tuomas Sandholm
  - 2019-07-11
  - 10.1126/science.aay2400
  - ! 'In recent years there have been great strides in artificial intelligence (AI),
    with games often serving as challenge problems, benchmarks, and milestones for
    progress. Poker has served for decades as such a challenge problem. Past successes
    in such benchmarks, including poker, have been limited to two-player games. However,
    poker in particular is traditionally played with more than two players. Multiplayer
    games present fundamental additional issues beyond those in two-player games,
    and multiplayer poker is a recognized AI milestone. In this paper we present Pluribus,
    an AI that we show is stronger than top human professionals in six-player no-limit
    Texas hold''em poker, the most popular form of poker played by humans. [Keywords:
    Monte Carlo <span class="smallcaps-auto">CFR</span>, state abstraction, Nash equilibrium]'
- - https://waifulabs.com/blog/ax
  - How we built the Waifu Vending Machine
  - Sizigi Studios
  - 2019-07-23
  - ''
  - ! '[Design company Sizigi Studios discusses their creation of Waifu Labs (https://waifulabs.com/),
    a deep learning <span class="smallcaps-auto">GAN</span> website for interactive generation of anime faces, and their
    experience running a prototype of it at the Anime Expo (AX) 2019 anime convention
    in Los Angeles, where it was a popular exhibit. Laptops were setup attached to
    printers in an enclosed booth, making a ''vending machine''. Challenges included:
    no electricity outlets and no WiFi. Multiple laptops were cycled through as batteries
    wore out, while a gaming PC ran the neural network <span class="smallcaps-auto">GAN</span>s locally rather than in
    a cloud VM. The failed WiFi was bypassed by using a smartphone as a local router.
    Further bugs were discovered in the code while many users waited in a long line.
    but were fixed in time, and the waifu vending machine was a success.]'
- - https://www.its.caltech.edu/~dg/crunch_art.html
  - The Big Crunch
  - David Goodstein
  - '1994'
  - ''
  - ! '<p>[On the end to the post-<span class="smallcaps-auto">WWII</span> Vannevar Bushian exponential growth of academia
    and consequences thereof: growth can''t go on forever, and it didn''t.]</p> <p>According
    to modern cosmology, the universe began with a big bang about 10 billion years
    ago, and it has been expanding ever since. If the density of mass in the universe
    is great enough, its gravitational force will cause that expansion to slow down
    and reverse, causing the universe to fall back in on itself. Then the universe
    will end in a cataclysmic event known as ''the Big Crunch''. I would like to present
    to you a vaguely analogous theory of the history of science. The upper curve on
    Figure 1 was first made by historian Derek da Solla Price, sometime in the 1950s.
    It is a semilog plot of the cumulative number of scientific journals founded worldwide
    as a function of time…the growth of the profession of science, the scientific
    enterprise, is bound to reach certain limits. I contend that these limits have
    now been reached.</p> <p>…But after about 1970 and the Big Crunch, the gleaming
    gems produced at the end of the vast mining-and-sorting operation produced less
    often from American ore. Research professors and their universities, using ore
    imported from across the oceans, kept the machinery humming.</p><p>…Let me finish
    by summarizing what I''ve been trying to tell you. We stand at an historic juncture
    in the history of science. The long era of exponential expansion ended decades
    ago, but we have not yet reconciled ourselves to that fact. The present social
    structure of science, by which I mean institutions, education, funding, publications
    and so on all evolved during the period of exponential expansion, before The Big
    Crunch. They are not suited to the unknown future we face. Today''s scientific
    leaders, in the universities, government, industry and the scientific societies
    are mostly people who came of age during the golden era, 1950–1970. I am myself
    part of that generation. We think those were normal times and expect them to return.
    But we are wrong. Nothing like it will ever happen again. It is by no means certain
    that science will even survive, much less flourish, in the difficult times we
    face. Before it can survive, those of us who have gained so much from the era
    of scientific elites and scientific illiterates must learn to face reality, and
    admit that those days are gone forever.</p>'
- - https://slatestarcodex.com/2019/04/22/1960-the-year-the-singularity-was-cancelled/
  - ! '1960: The Year The Singularity Was Cancelled'
  - Scott Alexander
  - 2019-04-22
  - ''
  - ! '[On the relationship between absolute population size, population growth, economic
    growth (absolute and per capita), innovation, ideas, and science: is the long
    exponential history of the progress of science, technology, and computing merely
    due to the accompanying exponential growth of the human population size after
    reaching a critical point where the Malthusian trap could be escaped and a new
    higher equilibrium sought, creating more possible researchers and enabling positive
    externalities? If so, then the end of exponential global population growth in
    the 1960s–1970s was also the end of the exponential era in human progress… At
    least until a new mode of exponential growth, such as artificial intelligence
    or brain emulations, begins.]'
- - https://forum.effectivealtruism.org/posts/dCjz5mgQdiv57wWGz/ingredients-for-creating-disruptive-research-teams
  - Ingredients for creating disruptive research teams
  - Stefan Torges
  - 2019-05-16
  - ''
  - ! '<p>This post tries to answer the question of what qualities make some research
    teams more effective than others. I was particularly interested in learning more
    about "disruptive" research teams, i.e. research teams that have an outsized impact
    on (1) the research landscape itself (e.g. by paving the way for new fields or
    establishing a new paradigm), and/or (2) society at large (e.g. by shaping technology
    or policy).[1] However, I expect the conclusions to be somewhat relevant for all
    research teams…</p><p>Key findings: excellent researchers have individual qualities
    and diversity, with shared direction, purposeful vision, concrete goals, leadership,
    and no inconveniences. Their organizations emphasize autonomy & self-organization,
    organic decentralized collaboration (with possibly metrics, goal-setting, and
    incentives), spaces for interaction, shared physical space, shared ''psychological
    spaces'' and forced interaction combined with psychological safety. Teams are
    small, seek external input and feedback, and value immaterial rewards.</p><p>…Based
    on the findings above, these are the most important takeaways for our research
    team at the Foundational Research Institute (<span class="smallcaps-auto">FRI</span>) as I see them: (1) We should
    continue to apply a high bar for hiring researchers… (2) Currently, we have
    staff who either excel at leadership or at research but nobody who combines both
    skill sets. We would likely benefit significantly from such an addition to our
    team…(3) We should continue to provide our research staff with as much freedom
    and operational support as possible… (4) Currently, many of our researchers
    work remotely which seems to have higher costs than I previously thought. As a
    consequence, I have become more convinced that we should try to create a research
    office geared toward the needs of our research staff… (5) We should invest
    more time into creating psychological safety for our research staff. I''m not
    yet sure how to best proceed here… (6) It was worth it to invest time into developing
    a theory of change, i.e., thinking about how exactly our research would lead to
    real-world changes when it comes to AI designs and deployment… (7) Organizing
    research workshops with other organizations focused on similar questions is worth
    it. We should also look into other formats of high-intensity in-person interaction.</p>'
- - /docs/history/1994-weschler.pdf
  - ! 'Inhaling the spore: Field trip to a museum of natural (un)history'
  - Lawrence Weschler
  - 1994-09-01
  - ''
  - ! '[Description of a visit to an unusual science museum: the LA Museum of Jurassic
    Technology. Unlike most science museums, only <em>some</em> of the exhibits are
    genuine. The others are fakes, many made by the museum''s curator. The visitor
    is challenged to discern the fabulous from the fraudulent.] [Keywords: 20<sup>th</sup> century,
    California, Curiosities and wonders, David Hildebrand Wilson, Los Angeles, Museum
    of Jurassic Technology, Science museums, hoax, performance art, critical thinking]'
- - http://www.sciencesuccess.org/uploads/1/5/5/4/15543620/science_quantifying_aaf5239_sinatra.pdf
  - Quantifying the evolution of individual scientific impact
  - Roberta Sinatra, Dashun Wang, Pierre Deville, Chaoming Song, Albert-László Barabási
  - 2016-11-04
  - 10.1126/science.aaf5239
  - ! '<p>Are there quantifiable patterns behind a successful scientific career? Sinatra
    et al. analyzed the publications of 2887 physicists, as well as data on scientists
    publishing in a variety of fields. When productivity (which is usually greatest
    early in the scientist''s professional life) is accounted for, the paper with
    the greatest impact occurs randomly in a scientist''s career. However, the process
    of generating a high-impact paper is not an entirely random one. The authors developed
    a quantitative model of impact, based on an element of randomness, productivity,
    and a factor <em>Q</em> that is particular to each scientist and remains constant
    during the scientist''s career.</p> <p><strong><em>Introduction</em></strong>:
    In most areas of human performance, from sport to engineering, the path to a major
    accomplishment requires a steep learning curve and long practice. Science is not
    that different: Outstanding discoveries are often preceded by publications of
    less memorable impact. However, despite the increasing desire to identify early
    promising scientists, the temporal career patterns that characterize the emergence
    of scientific excellence remain unknown.</p> <p><strong><em>Rationale</em></strong>:
    How do impact and productivity change over a scientific career? Does impact, arguably
    the most relevant performance measure, follow predictable patterns? Can we predict
    the timing of a scientist''s outstanding achievement? Can we model, in quantitative
    and predictive terms, scientific careers? Driven by these questions, here we quantify
    the evolution of impact and productivity throughout thousands of scientific careers.
    We do so by reconstructing the publication record of scientists from seven disciplines,
    associating to each paper its long-term impact on the scientific community, as
    quantified by citation metrics.</p> <p><strong><em>Results</em></strong>: We find
    that the highest-impact work in a scientist''s career is randomly distributed
    within her body of work. That is, the highest-impact work can be, with the same
    probability, anywhere in the sequence of papers published by a scientist—it could
    be the first publication, could appear mid-career, or could be a scientist''s
    last publication. This random-impact rule holds for scientists in different disciplines,
    with different career lengths, working in different decades, and publishing solo
    or with teams and whether credit is assigned uniformly or unevenly among collaborators.</p>
    <p>The random-impact rule allows us to develop a quantitative model, which systematically
    untangles the role of productivity and luck in each scientific career. The model
    assumes that each scientist selects a project with a random potential <em>p</em>
    and improves on it with a factor <em>Q<sub>i</sub></em>, resulting in a publication
    of impact <em>Q<sub>ip</sub></em>. The parameter <em>Q<sub>i</sub></em> captures
    the ability of scientist <em>i</em> to take advantage of the available knowledge
    in a way that enhances (<em>Q<sub>i</sub></em> &gt; 1) or diminishes (<em>Q<sub>i</sub></em>
    &lt; 1) the potential impact <em>p</em> of a paper. The model predicts that truly
    high-impact discoveries require a combination of high <em>Q</em> and luck (<em>p</em>)
    and that increased productivity alone cannot substantially enhance the chance
    of a very high impact work. We also show that a scientist''s <em>Q</em>, capturing
    her sustained ability to publish high-impact papers, is independent of her career
    stage. This is in contrast with all current metrics of excellence, from the total
    number of citations to the <em>h</em>-index, which increase with time. The <em>Q</em>
    model provides an analytical expression of these traditional impact metrics and
    allows us to predict their future time evolution for each individual scientist,
    being also predictive of independent recognitions, like Nobel prizes.</p> <p><strong><em>CONCLUSION</em></strong>:
    The random-impact rule and the <em>Q</em> parameter, representing two fundamental
    characteristics of a scientific career, offer a rigorous quantitative framework
    to explore the evolution of individual careers and understand the emergence of
    scientific excellence. Such understanding could help us better gauge scientific
    performance and offers a path toward nurturing high-impact scientists, potentially
    informing future policy decisions.</p>'
- - /static/js/popups.js
  - '<code>popups.js</code>'
  - Said Achmiz
  - 2019-08-21
  - ''
  - ! '<p><code>popups.js</code>: standalone Javascript library for creating ''popups''
    which display link metadata (typically, title/author/date/summary), for extremely
    convenient reference/abstract reading, with mobile and YouTube support. Whenever
    any such link is mouse-overed by the user, popups.js will pop up a large tooltip-like
    square with the contents of the attributes. This is particularly intended for
    references, where it is extremely convenient to autopopulate links such as to
    Arxiv.org/Biorxiv.org/Pubmed/<span class="smallcaps-auto">PLOS</span>/gwern.net/Wikipedia with the link''s title/author/date/abstract,
    so the reader can see it instantly.</p><p><code>popups.js</code> parses a <span class="smallcaps-auto">HTML</span>
    document and looks for <code>&lt;a&gt;</code> links which have the <code>docMetadata</code>
    attribute class, and the attributes <code>data-popup-title</code>, <code>data-popup-author</code>,
    <code>data-popup-date</code>, <code>data-popup-doi</code>, <code>data-popup-abstract</code>.
    (These attributes are expected to be populated already by the <span class="smallcaps-auto">HTML</span> document''s
    compiler, however, they can also be done dynamically. See <a href="https://share.obormot.net/misc/gwern/wikipedia-popups.js"><code>wikipedia-popups.js</code></a>
    for an example of a library which does Wikipedia-only dynamically on page loads.)</p><p>For
    an example of a Hakyll library which generates annotations for Wikipedia/Biorxiv/Arxiv/<span class="smallcaps-auto">PDF</span>s/arbitrarily-defined
    links, see <a href="/LinkMetadata.hs"><code>LinkMetadata.hs</code></a>;
    for a live demonstration, see the links in <a href="/newsletter/2019/07">the
    July 2019 newsletter</a>.</p>'
- - https://share.obormot.net/misc/gwern/wikipedia-popups.js
  - '<code>wikipedia-popups.js</code>'
  - Said Achmiz
  - 2019-07-29
  - ''
  - ! '<code>wikipedia-popups.js</code>: standalone Javascript library for creating
    ''popups'' for links to English Wikipedia articles when the user mouse-overs the
    link. The tooltip-style popup displays the summaries/introductions/ledes to Wikipedia
    articles as returned by the Wikipedia <span class="smallcaps-auto">API</span> (see <code>https://www.mediawiki.org/wiki/Page_Previews/API_Specification</code>
    and <code>https://en.wikipedia.org/api/rest_v1/</code>). All summaries are loaded
    on page load so as to have minimal latency (on-mouseover summary loading is noticeably
    slow). If a page has many Wikipedia links on it, this can result in quite a few
    requests; the summaries can instead be provided statically, encoded into data
    attributes. (This also allows encoding summaries/previews of arbitrary websites
    by whatever is compiling the <span class="smallcaps-auto">HTML</span>.) See <code>/static/js/popups.js</code> for
    a JS library which takes that approach instead.'
- - /Questions#mouse-utopia
  - On the 'Mouse Utopia' experiment
  - Gwern Branwen
  - 2019-08-12
  - ''
  - <p>Did John Calhoun's 1960s Mouse Utopia really show that animal (and human) populations
    will expand to arbitrary densities, creating socially-driven pathology and collapse?
    I give reasons for doubt about its replicability, interpretation, and meaningfulness.</p><p>One
    of the most famous experiments in psychology & sociology was John Calhoun's Mouse
    Utopia experiments in the 1960s–1970s. In the usual telling, Mouse Utopia created
    ideal mouse environments in which the mouse population was permitted to increase
    as much as possible; however, the overcrowding inevitably resulted in extreme
    levels of physical & social dysfunctionality, and eventually population collapse
    & even extinction. Looking more closely into it, there are reasons to doubt the
    replicability of the growth & pathological behavior & collapse, and if it does
    happen, whether it is driven by the social pressures as claimed by Calhoun or
    by other causal mechanisms at least as consistent with the evidence like disease
    or mutational meltdown.</p>
- - /Order-statistics#sampling-gompertz-distribution-extremes
  - ! 'Order Statistics: Sampling Gompertz Distribution Extremes'
  - Gwern Branwen
  - 2019-08-14
  - ''
  - <p>Efficient random sampling of extreme order statistics (such as 1-in-10-billion)
    in R code using the beta transform trick, with a case study applying to the <a
    href="/Questions#jeanne-calment">Jeanne Calment lifespan anomaly</a>.</p><p>I
    implement random sampling from the extremes/order statistics of the Gompertz survival
    distribution, used to model human life expectancies, with the beta transformation
    trick and <code>flexsurv</code>/root-finding inversion. I then discuss the unusually
    robust lifespan record of Jeanne Calment, and show that records like hers (which
    surpass the runner-up's lifespan by such a degree) are not usually produced by
    a Gompertz distribution, supporting the claim that her lifespan was indeed unusual
    even for the record holder.</p>
- - https://www.nature.com/articles/d41586-019-01770-x
  - ! 'Russian biologist plans more <span class="smallcaps-auto">CRISPR</span>-edited babies: The proposal follows a Chinese
    scientist who claimed to have created twins from edited embryos last year'
  - David Cyranoski (<em>Nature News</em>)
  - 2019-07-10
  - ''
  - <p>A Russian scientist says he is planning to produce gene-edited babies, an act
    that would make him only the second person known to have done this. It would also
    fly in the face of the scientific consensus that such experiments should be banned
    until an international ethical framework has agreed on the circumstances and safety
    measures that would justify them.</p><p>Molecular biologist Denis Rebrikov has
    told <em>Nature</em> he is considering implanting gene-edited embryos into women,
    possibly before the end of the year if he can get approval by then. Chinese scientist
    He Jiankui prompted an international outcry when he announced last November that
    he had made the world's first gene-edited babies—twin girls.</p><p>…Rebrikov
    heads a genome-editing laboratory at Russia's largest fertility clinic, the Kulakov
    National Medical Research Center for Obstetrics, Gynecology and Perinatology in
    Moscow and is a researcher at the Pirogov Russian National Research Medical University,
    also in Moscow. According to Rebrikov he already has an agreement with an <span class="smallcaps-auto">HIV</span>
    centre in the city to recruit women infected with <span class="smallcaps-auto">HIV</span> who want to take part in
    the experiment…[he] plans to implant embryos only into a subset of <span class="smallcaps-auto">HIV</span>-positive
    mothers who do not respond to standard anti-<span class="smallcaps-auto">HIV</span> drugs. Their risk of transmitting
    the infection to the child is higher. If editing successfully disables the <span class="smallcaps-auto">CCR</span>5
    gene, that risk would be greatly reduced, Rebrikov says. 'This is a clinical situation
    which calls for this type of therapy', he says.</p>
- - https://icare.hse.ru/data/2018/10/24/1142422445/Rust.pdf
  - Has dynamic programming improved decision making?
  - John Rust
  - 2018-08-22
  - 10.1146/annurev-economics-080218-025721
  - ! '<p>Dynamic programming (DP) is an extremely powerful tool for solving a wide
    class of sequential decision making problems under uncertainty. In principle,
    it enables us to compute <em>optimal decision rules</em> that specify the best
    possible decision to take in any given situation. This article reviews developments
    in DP and contrasts its revolutionary impact on economics, operations research,
    engineering, and artificial intelligence, with the comparative paucity of real
    world applications where DP is actually used to improve decision making. I discuss
    the literature on numerical solution of DPs and its connection to the literature
    on reinforcement learning (RL) and artificial intelligence (AI). Despite amazing,
    highly publicized successes of these algorithms that result in superhuman levels
    of performance in board games such as chess or Go, I am not aware of comparably
    successful applications of DP for helping individuals and firms to solve real-world
    problems. I point to the fuzziness of many real world decision problems and the
    difficulty in mathematically formulating and modeling them as key obstacles to
    wider application of DP to improve decision making. Nevertheless, I provide several
    success stories where DP has demonstrably improved decision making and discuss
    a number of other examples where it seems likely that the application of DP could
    have significant value. I conclude that ''applied DP'' offers substantial promise
    for economic policy making if economists can let go of the empirically untenable
    assumption of unbounded rationality and try to tackle the challenging decision
    problems faced every day by individuals and firms.</p> <p>[Keywords: actor-critic
    algorithms, Alpha Zero, approximate dynamic programming, artificial intelligence,
    behavioral economics, Bellman equation, bounded rationality, curse of dimensionality,
    computational complexity, decision rules, dynamic pricing, dynamic programming,
    employee compensation, Herbert Simon, fleet sizing, identification problem, individual
    and firm behavior life-cycle problem, locomotive allocation, machine learning,
    Markov decision processes, mental models, model-free learning, neural networks,
    neurodynamic programming, offline versus online training, optimal inventory management,
    optimal replacement, optimal search, principle of decomposition, Q-learning, revenue
    management, real-time dynamic programming, reinforcement learning, Richard Bellman,
    structural econometrics, supervised versus unsupervised learning]</p>'
- - https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/
  - ! 'We Need a New Science of Progress: Humanity needs to get better at knowing
    how to get better'
  - Patrick Collison, Tyler Cowen
  - 2019-07-30
  - ''
  - <p>Progress itself is understudied. By 'progress,' we mean the combination of
    economic, technological, scientific, cultural, and organizational advancement
    that has transformed our lives and raised standards of living over the past couple
    of centuries. For a number of reasons, there is no broad-based intellectual movement
    focused on understanding the dynamics of progress, or targeting the deeper goal
    of speeding it up. We believe that it deserves a dedicated field of study. We
    suggest inaugurating the discipline of 'Progress Studies.'</p><p>Before digging
    into what Progress Studies would entail, it's worth noting that we still need
    a lot of progress. We haven't yet cured all diseases; we don't yet know how to
    solve climate change; we're still a very long way from enabling most of the world's
    population to live as comfortably as the wealthiest people do today; we don't
    yet understand how best to predict or mitigate all kinds of natural disasters;
    we aren't yet able to travel as cheaply and quickly as we'd like; we could be
    far better than we are at educating young people. The list of opportunities for
    improvement is still extremely long.</p><p>…Plenty of existing scholarship touches
    on these topics, but it takes place in a highly fragmented fashion and fails to
    directly confront some of the most important practical questions.</p><p>Imagine
    you want to know how to most effectively select and train the most talented students.
    While this is an important challenge facing educators, policy makers, and philanthropists,
    knowledge about how best to do so is dispersed across a very long list of different
    fields. Psychometrics literature investigates which tests predict success. Sociologists
    consider how networks are used to find talent. Anthropologists investigate how
    talent depends on circumstances, and a historiometric literature studies clusters
    of artistic creativity. There's a lively debate about when and whether '10,000
    hours of practice' are required for truly excellent performance. The education
    literature studies talent-search programs such as the Center for Talented Youth.
    Personality psychologists investigate the extent to which openness or conscientiousness
    affect earnings. More recently, there's work in sportometrics, looking at which
    numerical variables predict athletic success. In economics, Raj Chetty and his
    co-authors have examined the backgrounds and communities liable to best encourage
    innovators. Thinkers in these disciplines don't necessarily attend the same conferences,
    publish in the same journals, or work together to solve shared problems.</p><p>When
    we consider other major determinants of progress, we see insufficient engagement
    with the central questions. For example, there's a growing body of evidence suggesting
    that management practices determine a great deal of the difference in performance
    between organizations. One recent study found that a particular intervention—teaching
    better management practices to firms in Italy—improved productivity by 49 percent
    over 15 years when compared with peer firms that didn't receive the training.
    How widely does this apply, and can it be repeated? Economists have been learning
    that firm productivity commonly varies within a given sector by a factor of two
    or three, which implies that a priority in management science and organizational
    psychology should be understanding the drivers of these differences. In a related
    vein, we're coming to appreciate more and more that organizations with higher
    levels of trust can delegate authority more effectively, thereby boosting their
    responsiveness and ability to handle problems. Organizations as varied as Y Combinator,
    <span class="smallcaps-auto">MIT</span>'s Radiation Lab, and <span class="smallcaps-auto">ARPA</span> have astonishing track records in catalyzing progress
    far beyond their confines. While research exists on all of these fronts, we're
    underinvesting considerably. These examples collectively indicate that one of
    our highest priorities should be figuring out interventions that increase the
    efficacy, productivity, and innovative capacity of human organizations…</p>
- - /docs/statistics/decision/2019-isakov.pdf
  - ! 'Is the FDA too conservative or too aggressive?: A Bayesian decision analysis
    of clinical trial design'
  - Leah Isakov, Andrew W. Lo, Vahid Montazerhodjat
  - 2019-01-04
  - 10.1016/j.jeconom.2018.12.009
  - Implicit in the drug-approval process is a host of decisions—target patient population,
    control group, primary endpoint, sample size, follow-up period, etc.—all of which
    determine the trade-off between Type I and Type II error. We explore the application
    of Bayesian decision analysis (<span class="smallcaps-auto">BDA</span>) to minimize the expected cost of drug approval,
    where the relative costs of the two types of errors are calibrated using U.S.
    Burden of Disease Study 2010 data. The results for conventional fixed-sample randomized
    clinical-trial designs suggest that for terminal illnesses with no existing therapies
    such as pancreatic cancer, the standard threshold of 2.5% is substantially more
    conservative than the <span class="smallcaps-auto">BDA</span>-optimal threshold of 23.9% to 27.8%. For relatively
    less deadly conditions such as prostate cancer, 2.5% is more risk-tolerant or
    aggressive than the <span class="smallcaps-auto">BDA</span>-optimal threshold of 1.2% to 1.5%. We compute <span class="smallcaps-auto">BDA</span>-optimal
    sizes for 25 of the most lethal diseases and show how a <span class="smallcaps-auto">BDA</span>-informed approval
    process can incorporate all stakeholders' views in a systematic, transparent,
    internally consistent, and repeatable manner.
- - https://www.theguardian.com/world/2019/aug/06/christian-science-church-medicine-death-horror-of-my-fathers-last-days
  - ! 'Dying the Christian Science way: the horror of my father''s last days; The
    anti-medical dogma of Christian Science led my father to an agonising death. Now
    the church itself is in decline—and it can''t happen fast enough'
  - Caroline Fraser
  - 2019-08-06
  - ''
  - ! '<p>[''Caroline Fraser, herself raised in a Scientist household, traces the
    growth of the Church from a small, eccentric sect into a politically powerful
    and socially respectable religion. She takes us into the closed world of Eddy''s
    followers, who reject modern medicine even at the cost of their children''s lives.
    And she reveals just how Christian Science managed to gain extraordinary legal
    and congressional approval for its dubious practices.''</p><p>Memoir of a former
    Christian Scientist, a Christian cult which believes all illness is spiritual
    and that medicine is useless/sinful and so whose adherents refuse medical treatment,
    describing her father''s slow decay from injuries and eventual death from a spreading
    gangrene that could have been treated. Author describes how (akin to Scientology)
    Christian Science is in decay itself, with rapidly declining numbers despite healthy
    financials and real estate assets from better days. While Christian Science may
    soon shrivel away, it leaves a toxic and literally infectious legacy: to profit
    off offering ''treatment'' and enable its members to avoid real medical treatment
    for their children and themselves, Christian Science spearheaded the legislation
    of ''religious exemptions'' to vaccines, empowering the current anti-vax movement,
    which may kill more children than Christian Science ever did.]</p>'
- - https://www.theatlantic.com/magazine/archive/2014/03/the-dark-power-of-fraternities/357580/
  - Why Don't Colleges Get Rid of Their Bad Fraternities? A yearlong investigation
    of Greek houses reveals their endemic, lurid, and sometimes tragic problems—and
    a sophisticated system for shifting the blame
  - Caitlin Flanagan (<em>The Atlantic</em>)
  - 2014-03-01
  - ''
  - ! '[History and investigation of legal records/settlements involving US college
    fraternities. Author finds that fraternities are involved in a remarkable number
    of serious, often fatal, injuries in part because of deliberate decisions to preserve
    traditions such as bunk beds for drunken partiers deliberately placed next to
    permanently-wide-open windows on the 2<sup>nd</sup> or 3<sup>rd</sup> story of frat buildings. Fraternities
    are able to survive because of their long history, including highly valuable real
    estate next to universities acquired in their earliest days (many frats being
    older than many American universities), and because of carefully-tailored insurance
    and regulations which enable them to push legal liability onto the students or
    members for the slightest infraction, such as bringing an additional bottle of
    beer, and thus responsibility for anything that might happen (like falling out
    of an open window); frat members are debriefed by the frat''s lawyers immediately
    after incidents with an eye to finding one who can be blamed, before the frat
    members can realize that the lawyers are not there to help them. While the frat
    members in question may have no assets to be sued over, their (frequently middle
    or upper-class) parents do, and may lose their houses in the subsequent lawsuits.]'
- - https://www.esquire.com/news-politics/news/a28718/why-men-love-war/
  - ! 'Why Men Love War: Like all lust, for as long as it lasts it dominates everything
    else'
  - William Broyles, Jr.
  - 1984-11-01
  - ''
  - ! '<p>"What people can''t understand," Hiers said, gently picking up each tiny
    rabbit and placing it in the nest, "is how much fun Vietnam was. I loved it. I
    loved it, and I can''t tell anybody." Hiers loved war. And as I drove back from
    Vermont in a blizzard, my children asleep in the back of the car, I had to admit
    that for all these years I also had loved it, and more than I knew. I hated war,
    too. Ask me, ask any man who has been to war about his experience, and chances
    are we''ll say we don''t want to talk about it—implying that we hated it so much,
    it was so terrible, that we would rather leave it buried. And it is no mystery
    why men hate war. War is ugly, horrible, evil, and it is reasonable for men to
    hate all that. But I believe that most men who have been to war would have to
    admit, if they are honest, that somewhere inside themselves they loved it too,
    loved it as much as anything that has happened to them before or since. And how
    do you explain that to your wife, your children, your parents, or your friends?</p><p>…I
    spent most of my combat tour in Vietnam trudging through its jungles and rice
    paddies without incident, but I have seen enough of war to know that I never want
    to fight again, and that I would do everything in my power to keep my son from
    fighting. Then why, at the oddest times—when I am in a meeting or running errands,
    or on beautiful summer evenings, with the light fading and children playing around
    me—do my thoughts turn back fifteen years to a war I didn''t believe in and never
    wanted to fight? Why do I miss it?</p><p>I miss it because I loved it, loved it
    in strange and troubling ways. When I talk about loving war I don''t mean the
    romantic notion of war that once mesmerized generations raised on Walter Scott.
    What little was left of that was ground into the mud at Verdun and Passchendaele:
    honor and glory do not survive the machine gun. And it''s not the mindless bliss
    of martyrdom that sends Iranian teenagers armed with sticks against Iraqi tanks.
    Nor do I mean the sort of hysteria that can grip a whole country, the way during
    the Falklands war the English press inflamed the lust that lurks beneath the cool
    exterior of Britain. That is vicarious war, the thrill of participation without
    risk, the lust of the audience for blood. It is easily fanned, that lust; even
    the invasion of a tiny island like Grenada can do it. Like all lust, for as long
    as it lasts it dominates everything else; a nation''s other problems are seared
    away, a phenomenon exploited by kings, dictators, and presidents since civilization
    began.</p>'
- - https://www.amazon.com/Third-World-First-Singapore-1965-2000/dp/0060197765
  - ! '<em>From Third World to First: The Singapore Story—1965&endash;2000</em>'
  - Lee Kuan Yew
  - 2000-10-03
  - ''
  - ! '<p>Few gave tiny Singapore much chance of survival when it was granted independence
    in 1965. How is it, then, that today the former British colonial trading post
    is a thriving Asian metropolis with not only the world''s number one airline,
    best airport, and busiest port of trade, but also the world''s fourth-highest
    per capita real income?</p><p>The story of that transformation is told here by
    Singapore''s charismatic, controversial founding father, Lee Kuan Yew. Rising
    from a legacy of divisive colonialism, the devastation of the Second World War,
    and general poverty and disorder following the withdrawal of foreign forces, Singapore
    now is hailed as a city of the future. This miraculous history is dramatically
    recounted by the man who not only lived through it all but who fearlessly forged
    ahead and brought about most of these changes.</p><p>Delving deep into his own
    meticulous notes, as well as previously unpublished government papers and official
    records, Lee details the extraordinary efforts it took for an island city-state
    in Southeast Asia to survive at that time.</p><p>Lee explains how he and his cabinet
    colleagues finished off the communist threat to the fledgling state''s security
    and began the arduous process of nation building: forging basic infrastructural
    roads through a land that still consisted primarily of swamps, creating an army
    from a hitherto racially and ideologically divided population, stamping out the
    last vestiges of colonial-era corruption, providing mass public housing, and establishing
    a national airline and airport.</p><p>In this illuminating account, Lee writes
    frankly about his trenchant approach to political opponents and his often unorthodox
    views on human rights, democracy, and inherited intelligence, aiming always "to
    be correct, not politically correct." Nothing in Singapore escaped his watchful
    eye: whether choosing shrubs for the greening of the country, restoring the romance
    of the historic Raffles Hotel, or openly, unabashedly persuading young men to
    marry women as well educated as themselves. Today''s safe, tidy Singapore bears
    Lee''s unmistakable stamp, for which he is unapologetic: "If this is a nanny state,
    I am proud to have fostered one."</p><p>Though Lee''s domestic canvas in Singapore
    was small, his vigor and talent assured him a larger place in world affairs. With
    inimitable style, he brings history to life with cogent analyses of some of the
    greatest strategic issues of recent times and reveals how, over the years, he
    navigated the shifting tides of relations among America, China, and Taiwan, acting
    as confidant, sounding board, and messenger for them. He also includes candid,
    sometimes acerbic pen portraits of his political peers, including the indomitable
    Margaret Thatcher and Ronald Reagan, the poetry-spouting Jiang Zemin, and ideologues
    George Bush and Deng Xiaoping.</p><p>Lee also lifts the veil on his family life
    and writes tenderly of his wife and stalwart partner, Kwa Geok Choo, and of their
    pride in their three children—particularly the eldest son, Hsien Loong, who is
    now Singapore''s deputy prime minister.</p><p>For more than three decades, Lee
    Kuan Yew has been praised and vilified in equal measure, and he has established
    himself as a force impossible to ignore in Asian and international politics. <em>From
    Third World to First</em> offers readers a compelling glimpse into this visionary''s
    heart, soul, and mind.</p>'
- - https://www.newcriterion.com/issues/2006/4/a-science-fiction-writer-of-the-fifties
  - A science fiction writer of the Fifties
  - Brad Leithauser
  - 2006-04-01
  - ''
  - <p>II. When the Smoke Clears</p><p>The mind, that rambling bear, ransacks the
    sky<br/>In search of honey,<br/>Fish, berries, carrion. It minds no laws …<br/>As
    if the heavens were some canvas tent,<br/>It slashes through the firmament<br/>To
    prise up the sealed stores with its big paws.<br/></p><p>The mind, that sovereign
    camel, sees the sky<br/>For what it is:<br/>Each star a grain of sand along the
    vast<br/>Passage to that oasis where, below<br/>The pillared palms, the portico<br/>Of
    fronds, the soul may drink its fill at last.<br/></p><p>The mind, that gorgeous
    spider, webs the sky<br/>With lines so sheer<br/>They all but vanish, and yet
    star to star<br/>(Thread by considered thread) slowly entwines<br/>The universe
    in its designs—<br/>Un-earthing patterns where no patterns are.<br/></p><p>The
    mind, that termite, seems to shun the sky.<br/>It burrows down,<br/>Tunneling
    in upon that moment when,<br/>In Time—its element—will come a day<br/>The longest-shadowed
    tower sway,<br/>Unbroken sunlight fall to earth again.</p> <p>…<span class="smallcaps-auto">DNA</span> was unspooled
    in the year<br/>I was born, and the test-tube births<br/>Of cloned mammals emerged
    in a mere<br/>Half-century; it seems the earth's<br/>Future's now in the hands
    of a few<br/>Techies on a caffeinated all-nighter who<br/>Sift the gene-alphabet
    like Scrabble tiles<br/></p><p>And our computer geeks are revealed, at last,<br/>As
    those quick-handed, sidelined little mammals<br/>In the dinosaurs' long shadows—those
    least-<br/>Likely-to-succeed successors whose kingdom come<br/>Was the globe itself
    (an image best written down,<br/>Perhaps, beneath a streetlamp, late, in some<br/>Star-riddled
    Midwestern town).<br/></p><p>He wrote boys' books and intuitively<br/>Recognized
    that the real<br/>Realist isn't the one who details<br/>Lowdown heartland factories
    and farms<br/>As if they would last, but the one who affirms,<br/>From the other
    end of the galaxy,<br/>Ours is the age of perilous miracles.<br/></p></blockquote>
- - http://www.atlasobscura.com/articles/is-hansel-and-gretel-real
  - ! 'How a Literary Prank Convinced Germany That ''Hansel and Gretel'' Was Real:
    A 1963 book purported to prove that the siblings were murderous bakers'
  - Jordan Todorov
  - 2019-07-03
  - ''
  - <p>So one can imagine the furor in 1963 when a German writer claimed to have uncovered
    the real story behind the fairy tale.</p><p>According to <em>Die Wahrheit über
    Hänsel und Gretel</em> (<em>The Truth About Hansel and Gretel</em>), the two siblings
    were, in fact, adult brother and sister bakers, living in Germany during the mid-17<sup>th</sup>
    century. They murdered the witch, an ingenious confectioner in her own right,
    to steal her secret recipe for lebkuchen, a gingerbread-like traditional treat.
    The book published a facsimile of the recipe in question, as well as sensational
    photos of archaeological evidence.</p><p>…The media picked up the story and
    turned it into national news. "Book of the week? No, it's the book of the year,
    and maybe the century!" proclaimed the West German tabloid <em>Abendzeitung</em>
    in November 1963. The state-owned <em>East German Berliner Zeitung</em> came out
    with the headline "Hansel and Gretel—a duo of murderers?" and asked whether this
    could be "a criminal case from the early capitalist era." The news spread like
    wildfire not only in Germany, but abroad too. Foreign publishers, smelling a profit,
    began negotiating for the translation rights. School groups, some from neighboring
    Denmark, traveled to the Spessart woods in the states of Bavaria and Hesse to
    see the newly discovered foundations of the witch's house.</p><p>As intriguing
    as <em>The Truth About Hansel and Gretel</em> might sound, however, none of it
    proved to be true. In fact, the book turned out to be a literary forgery concocted
    by Hans Traxler, a German children's book writer and cartoonist, known for his
    sardonic sense of humor. "1963 marked the 100<sup>th</sup> anniversary of Jacob Grimm's death,"
    says the now 90-year-old Traxler, who lives in Frankfurt, Germany. "So it was
    natural to dig into [the] Brothers Grimm treasure chest of fairy tales, and pick
    their most famous one, 'Hansel and Gretel.'"</p>
- - /docs/philo/2004-wallace-considerthelobster.html
  - ! 'Consider the Lobster: For 56 years, the Maine Lobster Festival has been drawing
    crowds with the promise of sun, fun, and fine food. One visitor would argue that
    the celebration involves a whole lot more'
  - David Foster Wallace
  - 2004-08-01
  - ''
  - ! '<p>[Originally published in the August 2004 issue of <em>Gourmet</em> magazine,
    this review of the 2003 Maine Lobster Festival generated some controversy among
    the readers of the culinary magazine. The essay is concerned with the ethics of
    boiling a creature alive in order to enhance the consumer''s pleasure, including
    a discussion of lobster sensory neurons.]</p><p>A detail so obvious that most
    recipes don''t even bother to mention it is that each lobster is supposed to be
    alive when you put it in the kettle…Another alternative is to put the lobster
    in cold salt water and then very slowly bring it up to a full boil. Cooks who
    advocate this method are going mostly on the analogy to a frog, which can supposedly
    be kept from jumping out of a boiling pot by heating the water incrementally.
    In order to save a lot of research-summarizing, I''ll simply assure you that the
    analogy between frogs and lobsters turns out not to hold.</p><p>…So then here
    is a question that''s all but unavoidable at the World''s Largest Lobster Cooker,
    and may arise in kitchens across the U.S.: Is it all right to boil a sentient
    creature alive just for our gustatory pleasure? A related set of concerns: Is
    the previous question irksomely PC or sentimental? What does ''all right'' even
    mean in this context? Is it all just a matter of individual choice?</p><p>…As
    far as I can tell, my own main way of dealing with this conflict has been to avoid
    thinking about the whole unpleasant thing. I should add that it appears to me
    unlikely that many readers of gourmet wish to think hard about it, either, or
    to be queried about the morality of their eating habits in the pages of a culinary
    monthly. Since, however, the assigned subject of this article is what it was like
    to attend the 2003 <span class="smallcaps-auto">MLF</span>, and thus to spend several days in the midst of a great
    mass of Americans all eating lobster, and thus to be more or less impelled to
    think hard about lobster and the experience of buying and eating lobster, it turns
    out that there is no honest way to avoid certain moral questions.</p>'
- - https://story.californiasunday.com/cosmic-crisp-apple-launch
  - ! 'The Launch: Inside the ''largest launch of a produce item in American history'''
  - Brooke Jarvis
  - 2019-07-18
  - ''
  - ! '<p>In those early days, the company, just like almost everybody else in Washington,
    primarily produced Red Delicious apples, plus a few Goldens and Grannies—familiar
    workhorse varieties that anybody was allowed to grow. Back then, the state apple
    commission advertised its wares with a poster of a stoplight: one apple each in
    red, green, and yellow. Today, across more than 4,000 acres of McDougall apple
    trees, you won''t find a single Red; every year, you''ll also find fewer acres
    of the apples that McDougall calls "core varieties," the more modern open-access
    standards such as Gala and Fuji. Instead, McDougall is betting on what he calls
    "value-added apples": Ambrosias, whose rights he licensed from a Canadian company;
    Envy, Jazz, and Pacific Rose, whose intellectual properties are owned by the New
    Zealand giant Enzafruit; and a brand-new variety, commercially available for the
    first time this year and available only to Washington-state growers: the Cosmic
    Crisp.</p><p>…The Cosmic Crisp is debuting on grocery stores after this fall''s
    harvest, and in the nervous lead-up to the launch, everyone from nursery operators
    to marketers wanted me to understand the crazy scope of the thing: the scale of
    the plantings, the speed with which mountains of commercially untested fruit would
    be arriving on the market, the size of the capital risk. People kept saying things
    like "unprecedented," "on steroids," "off the friggin'' charts," and "the largest
    launch of a single produce item in American history."</p><p>McDougall took me
    to the highest part of his orchard, where we could look down at all its hundreds
    of very expensively trellised and irrigated acres (he estimated the costs to plant
    each individual acre at $60,000 to $65,000, plus another $12,000 in operating
    costs each year), their neat, thin lines of trees like the stitching over so many
    quilt squares. "If you''re a farmer, you''re a riverboat gambler anyway," McDougall
    said. "But Cosmic Crisp—woo!" I thought of the warning of one former fruit-industry
    journalist that, with so much on the line, the enormous launch would have to go
    flawlessly: "It''s gotta be like the new iPhone."</p><p>…Though Washington State
    University owns the WA 38 patent, the breeding program has received funding from
    the apple industry, so it was agreed, over some objections by people who worried
    that quality would be diluted, that the variety should be universally and exclusively
    available to Washington growers. (Growers of Cosmic Crisp pay royalties both on
    every tree they buy and on every box they sell, money that will fund future breeding
    projects as well as the shared marketing campaign.) The apple tested so well that
    <span class="smallcaps-auto">WSU</span>, in collaboration with commercial nurseries, began producing apple saplings
    as fast as possible; the plan was to start with 300,000 trees, but growers requested
    4 million, leading to a lottery for divvying up the first available trees. Within
    three years, the industry had sunk 13 million of them, plus more than half a billion
    dollars, into the ground. Proprietary Variety Management expects that the number
    of Cosmic Crisp apples on the market will grow by millions of boxes every year,
    outpacing Pink Lady and Honeycrisp within about five years of its launch.</p>'
- - https://www.nytimes.com/2007/08/12/magazine/12fonts-t.html
  - The Road to Clarity
  - Joshua Yaffa (<em>The New York Times</em>)
  - 2007-08-12
  - ''
  - ! '<p>Looking at a sign in Clearview after reading one in Highway Gothic is like
    putting on a new pair of reading glasses: there''s a sudden lightness, a noticeable
    crispness to the letters. The Federal Highway Administration granted Clearview
    interim approval in 2004, meaning that individual states are free to begin using
    it in all their road signs. More than 20 states have already adopted the typeface,
    replacing existing signs one by one as old ones wear out. Some places have been
    quicker to make the switch—much of Route I-80 in western Pennsylvania is marked
    by signs in Clearview, as are the roads around Dallas-Fort Worth International
    Airport—but it will very likely take decades for the rest of the country to finish
    the roadside makeover. It is a slow, almost imperceptible process. But eventually
    the entire country could be looking at Clearview.</p><p>…Meeker initially assumed
    that the solution to the nation''s highway sign problem lay in the clean utilitarian
    typefaces of Europe. One afternoon in the late fall of 1992, Meeker was sitting
    in his Larchmont office with a small team of designers and engineers. He suggested
    that the group get away from the computer screens and out of the office to see
    what actually worked in the open air at long distances. They grabbed all the roadsigns
    Meeker had printed—nearly 40 metal panels set in a dozen different fonts of varying
    weights—and headed across the street to the Larchmont train station, where they
    rested the signs along a railing. They then hiked to the top of a nearby hill.
    When they stopped and turned, they were standing a couple hundred feet from the
    lineup below. There was the original Highway Gothic; British Transport, the road
    typeface used in the United Kingdom; Univers, found in the Paris Metro and on
    Apple computer keyboards; <span class="smallcaps-auto">DIN</span> 1451, used on road and train signage in Germany;
    and also Helvetica, the classic sans-serif seen in modified versions on roadways
    in a number of European countries. "There was something wrong with each one,"
    Meeker remembers. "Nothing gave us the legibility we were looking for." The team
    immediately realized that it would have to draw something from scratch.</p>'
- - https://www.ribbonfarm.com/2012/03/08/halls-law-the-nineteenth-century-prequel-to-moores-law/
  - ! 'Hall''s Law: The Nineteenth Century Prequel to Moore''s Law'
  - Venkatesh Rao
  - 2012-03-08
  - ''
  - ! '<p>[Coins "Hall''s law": "the maximum complexity of artifacts that can be manufactured
    at scales limited only by resource availability doubles every 10 years." Economic
    history discussion of industrialization: the replacement of esoteric artisanal
    knowledge, based on trial-and-error and epitomized by a classic Sheffield steel
    recipe which calls for adding 4 white onions to iron, by formalized, specialized,
    rationalized processes such as interchangeable parts in a rifle produced by a
    factory system, which can create standardized parts at larger scales than craft-based
    processes, on which other systems can be built (once a reliable controlled source
    of parts exists). Examples include British gun-making, John Hall, the Montgomery
    Ward catalogue.]</p><p>I believe this law held between 1825 and 1960, at which
    point the law hit its natural limits. Here, I mean complexity in the loose sense
    I defined before: some function of mechanical complexity and operating tempo of
    the machine, analogous to the transistor count and clock-rate of chips. I don''t
    have empirical data to accurately estimate the doubling period, but 10 years is
    my initial guess, based on the anecdotal descriptions from Morris'' book and the
    descriptions of the increasing presence of technology in the world fairs. Along
    the complexity dimension, mass-produced goods increased rapidly got more complex,
    from guns with a few dozen parts to late-model steam engines with thousands. The
    progress on the consumer front was no less impressive, with the Montgomery Ward
    catalog offering mass-produced pianos within a few years of its introduction for
    instance. By the turn of the century, you could buy entire houses in mail-order
    kit form. The cost of everything was collapsing. Along the tempo dimension, everything
    got relentlessly faster as well. Somewhere along the way, things got so fast thanks
    to trains and the telegraph, that time zones had to be invented and people had
    to start paying attention the second hand on clocks.</p><p>…History is repeating
    itself. And the rerun episode we are living right now is not a pleasant one. The
    problem with history repeating itself of course, is that sometimes it does not.
    The fact that 1819–1880 map pretty well to 1959–2012 does not mean that 2012–2112
    will map to 1880–1980. Many things are different this time around. But assuming
    history <em>does</em> repeat itself, what are we in for? If the Moore''s Law endgame
    is the same century-long economic-overdrive that was the Hall''s Law endgame,
    today''s kids will enter the adult world with prosperity and a fully-diffused
    Moore''s Law all around them. The children will do well. In the long term, things
    will look up. But in the long term, you and I will be dead.</p>'
- - https://www.newyorker.com/magazine/1987/02/23/atchafalaya
  - Atchafalaya
  - John McPhee
  - 1987-02-15
  - ''
  - ! '[A study of the Mississippi River, its history, and efforts by the U.S. Army
    Corps of Engineers to hold it in place.] It was published in February, 1987, and
    it''s about the Herculean effort of the U.S. Army Corps of Engineers to control
    the flow of the Mississippi River, the fourth-longest river in the world. "Atchafalaya"
    is the name of the "distributary waterscape" that threatens to capture and redirect
    the flow of the Mississippi. If that happens, the cities and industrial centers
    of Southern Louisiana could find themselves sitting, uselessly, next to a "tidal
    creek," and economic ruin would be the inevitable result. To prevent that, the
    Corps of Engineers embarks on a vast project to artificially freeze the naturally
    shifting landscape. McPhee meets the engineers and explores the structures they''ve
    built to "preserve 1950 … in perpetuity."… Like the Mississippi, "Atchafalaya"
    is long—around twenty-seven thousand words. But it''s all available online, and
    it gives you a real sense of what it''s like not just to live and work beside
    one of the world''s great rivers but actually to struggle with it.'
- - https://rootsofprogress.org/why-did-we-wait-so-long-for-the-bicycle
  - Why did we wait so long for the bicycle?
  - Jason Crawford
  - 2019-07-13
  - ''
  - <p>The bicycle, as we know it today, was not invented until the late 1800s. Yet
    it was a simple mechanical invention. It would seem to require no brilliant inventive
    insight, and certainly no scientific background.</p><p>…Technology factors are
    more convincing to me. They may have been necessary for bicycles to become practical
    and cheap enough to take off. But they weren't needed for early experimentation.
    Frames can be built of wood. Wheels can be rimmed with metal. Gears can be omitted.
    Chains can be replaced with belts; some early designs even used treadles instead
    of pedals, and at least one design drove the wheels with levers, as on a steam
    locomotive. So what's the real explanation?</p><p>First, the correct design was
    not obvious. For centuries, progress was stalled because inventors were all trying
    to create multi-person four-wheeled carriages, rather than single-person two-wheeled
    vehicles. It's unclear why this was; certainly inventors were copying an existing
    mode of transportation, but why would they draw inspiration only from the horse-and-carriage,
    and not from the horse-and-rider? (Some commenters have suggested that it was
    not obvious that a two-wheeled vehicle would balance, but I find this unconvincing
    given how many other things people have learned to balance on, from dugout canoes
    to horses themselves.) It's possible (I'm purely speculating here) that early
    mechanical inventors had a harder time realizing the fundamental impracticability
    of the carriage design because they didn't have much in the way of mathematical
    engineering principles to go on, but then again it's unclear what led to Drais's
    breakthrough. And even after Drais hit on the two-wheeled design, it took multiple
    iterations, which happened over decades, to get to a design that was efficient,
    comfortable, and safe.</p><p>…But we can go deeper, and ask the questions that
    inspired my intense interest in this question in the first place. Why was no one
    even experimenting with two-wheeled vehicles until the 1800s? And why was no one,
    as far as we know, even considering the question of human-powered vehicles until
    the 1400s? Why weren't there bicycle mechanics in the 1300s, when there were clockmakers,
    or at least by the 1500s, when we had watches? Or among the ancient Romans, who
    built water mills and harvesting machines? Or the Greeks, who built the Antikythera
    mechanism ? Even if they didn't have tires and chains, why weren't these societies
    at least experimenting with draisines? Or even the failed carriage designs?</p>
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2495396/pdf/postmedj00315-0056.pdf
  - Features of a successful therapeutic fast of 382 days' duration
  - Stewart & Fleming
  - 1973-03-01
  - 10.1136/pgmj.49.569.203
  - <p>A 27-year-old male patient fasted under supervision for 382 days and has subsequently
    maintained his normal weight. Blood glucose concentrations around 30 mg/100 ml
    were recorded consistently during the last 8 months, although the patient was
    ambulant and attending as an out-patient. Responses to glucose and tolbutamide
    tolerance tests remained normal. The hyperglycaemic response to glucagon was reduced
    and latterly absent, but promptly returned to normal during carbohydrate refeeding.
    After an initial decrease was corrected, plasma potassium levels remained normal
    without supplementation. A temporary period of hypercalcaemia occurred towards
    the end of the fast. Decreased plasma magnesium concentrations were a consistent
    feature from the first month onwards. After 100 days of fasting there was a marked
    and persistent increase in the excretion of urinary cations and inorganic phosphate,
    which until then had been minimal. These increases may be due to dissolution of
    excessive soft tissue and skeletal mass. Prolonged fasting in this patient had
    no ill-effects.</p><p>…During the 382 days of the fast, the patient's weight
    decreased from 456 to 180lb. Five years after undertaking the fast, Mr A.B.'s
    weight remains around 196lb…The amount of weight lost and the rate of loss were
    not strikingly different from that of an earlier patient (Stewart, Fleming & Robertson,
    1966) who reduced his weight from 432 to 235lb during 350 days of intermittent
    starvation.</p><p>…We wish to express our gratitude to Mr A.B. for his cheerful
    cooperation and steadfast application to the task of achieving a normal physique.</p>
- - /docs/psychology/2019-letexier.pdf
  - Debunking the Stanford Prison Experiment
  - Thibault Le Texier
  - 2019-08-05
  - 10.1037/amp0000401
  - ! 'The Stanford Prison Experiment (<span class="smallcaps-auto">SPE</span>) is one of psychology''s most famous studies.
    It has been criticized on many grounds, and yet a majority of textbook authors
    have ignored these criticisms in their discussions of the <span class="smallcaps-auto">SPE</span>, thereby misleading
    both students and the general public about the study''s questionable scientific
    validity. Data collected from a thorough investigation of the <span class="smallcaps-auto">SPE</span> archives and
    interviews with 15 of the participants in the experiment further question the
    study''s scientific merit. These data are not only supportive of previous criticisms
    of the <span class="smallcaps-auto">SPE</span>, such as the presence of demand characteristics, but provide new criticisms
    of the <span class="smallcaps-auto">SPE</span> based on heretofore unknown information. These new criticisms include
    the biased and incomplete collection of data, the extent to which the <span class="smallcaps-auto">SPE</span> drew
    on a prison experiment devised and conducted by students in one of Zimbardo''s
    classes 3 months earlier, the fact that the guards received precise instructions
    regarding the treatment of the prisoners, the fact that the guards were not told
    they were subjects, and the fact that participants were almost never completely
    immersed by the situation. Possible explanations of the inaccurate textbook portrayal
    and general misperception of the <span class="smallcaps-auto">SPE</span>''s scientific validity over the past 5 decades,
    in spite of its flaws and shortcomings, are discussed. [Keywords: Stanford Prison
    Experiment, Zimbardo, epistemology]'
- - https://harpers.org/archive/2013/09/the-devils-bait/?single=1
  - ! 'The Devil''s Bait: Symptoms, signs, and the riddle of Morgellons'
  - Leslie Jamison (<em>Harper's Magazine</em>)
  - 2013-09-01
  - ''
  - ! '<p>For Paul, it started with a fishing trip. For Lenny, it was an addict whose
    knuckles were covered in sores. Dawn found pimples clustered around her swimming
    goggles. Kendra noticed ingrown hairs. Patricia was attacked by sand flies on
    a Gulf Coast beach. Sometimes the sickness starts as blisters, or lesions, or
    itching, or simply a terrible fog settling over the mind, over the world.</p><p>For
    me, Morgellons disease started as a novelty: people said they had a strange ailment,
    and no one—or hardly anyone—believed them. But there were a lot of them, reportedly
    12,000, and their numbers were growing. Their illness manifested in many ways,
    including fatigue, pain, and formication (a sensation of insects crawling over
    the skin). But the defining symptom was always the same: fibers emerging from
    their bodies. Not just fibers but fuzz, specks, and crystals. They didn''t know
    what this stuff was, or where it came from, or why it was there, but they knew—and
    this was what mattered, the important word—that it was real.</p><p>…Browne''s
    "harsh hairs" were the early ancestors of today''s fibers. Photos online show
    them in red, white, and blue—like the flag—and also black and translucent. These
    fibers are the kind of thing you describe in relation to other kinds of things:
    jellyfish or wires, animal fur or taffy candy or a fuzzball off your grandma''s
    sweater. Some are called goldenheads, because they have a golden-colored bulb.
    Others simply look sinister, technological, tangled.</p><p>Patients started bringing
    these threads and flecks and fuzz to their doctors, storing them in Tupperware
    or matchboxes, and dermatologists actually developed a term for this phenomenon.
    They called it "the matchbox sign", an indication that patients had become so
    determined to prove their disease that they might be willing to produce fake evidence.</p><p>…This
    isn''t an essay about whether Morgellons disease is real. That''s probably obvious
    by now. It''s an essay about what kinds of reality are considered prerequisites
    for compassion. It''s about this strange sympathetic limbo: Is it wrong to speak
    of empathy when you trust the fact of suffering but not the source?</p>'
- - https://www.thecut.com/2019/07/what-happens-when-lyme-disease-becomes-an-identity.html
  - ! 'Maybe It''s Lyme: What happens when illness becomes an identity?'
  - Molly Fischer (<em>The Cut</em>)
  - 2019-07-24
  - ''
  - ! '<p>This is the rallying cry of the Lyme Warrior. Spend a while browsing <code>#lymewarrior</code>
    on Instagram and what you find looks like wellness content at first. There are
    selfies, shots of food, talk of toxins, exhortations toward self-care. There are
    more extensive arrays of supplements than you might expect. Then the IVs snake
    into view. There are hospital gowns and seats at outpatient-treatment centers
    and surgically implanted ports displayed with pride. This is wellness predicated
    on the constant certainty that all is not well. Like Hadid, the Lyme Warriors
    struggle against those who would doubt their condition, and, like Hadid, they
    are firm in their resolve. They have a name, and they have each other.</p><p>Where
    Murray sought to answer a question, the warrior who now takes up the cause of
    chronic Lyme is seeking to affirm an answer. For this community of patients, Lyme
    has come to function as something more expansive than a diagnosis. While Lyme
    disease is a specific medical condition—one that may manifest more severely or
    less, be treated more easily or less—chronic Lyme is something else altogether.
    (The medical establishment generally avoids using the term <em>chronic Lyme</em>,
    and because of this establishment wariness, advocates who believe Lyme is a chronic
    infection now sometimes advise patients to avoid it too.) This version of Lyme
    has no consistent symptoms, no fixed criteria, and no accurate test. This Lyme
    is a kind of identity. Lyme is a label for a state of being, a word that conveys
    your understanding of your lived experience. Lyme provides the language to articulate
    that experience and join with others who share it. In the world of chronic Lyme,
    doctors are trustworthy (or not) based on their willingness to treat Lyme. Tests
    are trustworthy (or not) based on their ability to confirm Lyme. Lyme is the fundamental
    fact, and you work backward from there. Lyme is a community with a cause: the
    recognition of its sufferers'' suffering—and, with it, the recognition of Lyme.</p>'
- - http://gershmanlab.webfactional.com/pubs/GenerativeAdversarialBrain.pdf
  - The Generative Adversarial Brain
  - Samuel J. Gershman
  - 2019-07-21
  - ''
  - ! '<p>The idea that the brain learns generative models of the world has been widely
    promulgated. Most approaches have assumed that the brain learns an explicit density
    model that assigns a probability to each possible state of the world. However,
    explicit density models are difficult to learn, requiring approximate inference
    techniques that may find poor solutions. An alternative approach is to learn an
    implicit density model that can sample from the generative model without evaluating
    the probabilities of those samples. The implicit model can be trained to fool
    a discriminator into believing that the samples are real. This is the idea behind
    generative adversarial algorithms, which have proven adept at learning realistic
    generative models. This paper develops an adversarial framework for probabilistic
    computation in the brain. It first considers how generative adversarial algorithms
    overcome some of the problems that vex prior theories based on explicit density
    models. It then discusses the psychological and neural evidence for this framework,
    as well as how the breakdown of the generator and discriminator could lead to
    delusions observed in some mental disorders.</p><p>…Our sensory inputs are impoverished,
    and yet our experience of the world feels richly detailed. For example, our fovea
    permits us access to a high fidelity region of the visual field only twice the
    size of our thumbnail held at arm''s length. But we don''t experience the world
    as though looking through a tiny aperture. Instead, our brains feed us a "grand
    illusion" of panoptic vision (Chater, 2018; Noe et al., 2000; Odegaard et al.,
    2018). Similarly, we receive no visual input in the region of the retina that
    connects to the optic nerve, yet under normal circumstances we are unaware of
    this blind spot. Moreover, even when we receive high fidelity visual input, we
    may still fail to witness dramatic changes in scenes (Simons, 2000), as though
    our brains have contrived imaginary scenes that displace the true scenes.</p><p>…First,
    how can we explain the phenomenology of illusion: why do some illusions feel real,
    as though one is actually seeing them, whereas other inferences carry information
    content without the same perceptual experience. For example, Ramachandran and
    Hirstein (1997) use the example of gazing at wallpaper in a bathroom, where the
    wallpaper in your visual periphery is ''filled in'' (you subjectively experience
    it as high fidelity even though objectively you perceive it with low fidelity),
    but the wallpaper behind your head is not filled in. In other words, you infer
    that the wallpaper continues behind your head, and you may even know this with
    high confidence, but you do not have the experience of seeing the wallpaper behind
    your head. Thus, the vividness or "realness" of perceptual experience is not a
    simple function of belief strength. So what is it a function of? Second, how can
    we explain the peculiar ways that the inferential apparatus breaks down? In particular,
    how can we understand the origins of delusions, hallucinations, and confabulations
    that arise in certain mental disorders? While Bayesian models have been developed
    to explain these phenomena, they fall short in certain ways that we discuss later
    on.</p>'
- - https://qualiacomputing.com/2019/08/10/logarithmic-scales-of-pleasure-and-pain-rating-ranking-and-comparing-peak-experiences-suggest-the-existence-of-long-tails-for-bliss-and-suffering/
  - ! 'Logarithmic Scales of Pleasure and Pain: Rating, Ranking, and Comparing Peak
    Experiences Suggest the Existence of Long Tails for Bliss and Suffering'
  - Qualia Computing
  - 2019-08-10
  - ''
  - ! '<p>Based on: the characteristic distribution of neural activity, personal accounts
    of intense pleasure and pain, the way various pain scales have been described
    by their creators, and the results of a pilot study we conducted which ranks,
    rates, and compares the hedonic quality of extreme experiences, we suggest that
    the best way to interpret pleasure and pain scales is by thinking of them as logarithmic
    compressions of what is truly a long-tail. The most intense pains are orders of
    magnitude more awful than mild pains (and symmetrically for pleasure).</p><p>This
    should inform the way we prioritize altruistic interventions and plan for a better
    future. Since the bulk of suffering is concentrated in a small percentage of experiences,
    focusing our efforts on preventing cases of intense suffering likely dominates
    most utilitarian calculations.</p><p>An important pragmatic takeaway from this
    article is that if one is trying to select an effective career path, as a heuristic
    it would be good to take into account how one''s efforts would cash out in the
    prevention of extreme suffering (see: ''Hell-Index''), rather than just <span class="smallcaps-auto">QALY</span>s
    and wellness indices that ignore the long-tail. Of particular note as promising
    Effective Altruist careers, we would highlight working directly to develop remedies
    for specific, extremely painful experiences. Finding scalable treatments for migraines,
    kidney stones, childbirth, cluster headaches, <span class="smallcaps-auto">CRPS</span>, and fibromyalgia may be extremely
    high-impact (cf. ''Treating Cluster Headaches and Migraines Using N,N-<span class="smallcaps-auto">DMT</span> and
    Other Tryptamines'', ''Using Ibogaine to Create Friendlier Opioids'', and ''Frequency
    Specific Microcurrent for Kidney-Stone Pain''). More research efforts into identifying
    and quantifying intense suffering currently unaddressed would also be extremely
    helpful. Finally, if the positive valence scale also has a long-tail, focusing
    one''s career in developing bliss technologies may pay-off in surprisingly good
    ways (whereby you may stumble on methods to generate high-valence healing experiences
    which are orders of magnitude better than you thought were possible). [Keywords:
    consciousness research, Effective Altruism, ethics, Hedonic Tone, meaning, psychedelic,
    sex, spirituality, valence]</p>'
- - http://www.structuredprocrastination.com/
  - Structured Procrastination
  - John Perry
  - 1996-02-23
  - ''
  - <p>All procrastinators put off things they have to do. Structured procrastination
    is the art of making this bad trait work for you. The key idea is that procrastinating
    does not mean doing absolutely nothing. Procrastinators seldom do absolutely nothing;
    they do marginally useful things, like gardening or sharpening pencils or making
    a diagram of how they will reorganize their files when they get around to it.
    Why does the procrastinator do these things? Because they are a way of not doing
    something more important. If all the procrastinator had left to do was to sharpen
    some pencils, no force on earth could get him do it. However, the procrastinator
    can be motivated to do difficult, timely and important tasks, as long as these
    tasks are a way of not doing something more important.</p><p>Structured procrastination
    means shaping the structure of the tasks one has to do in a way that exploits
    this fact. The list of tasks one has in mind will be ordered by importance. Tasks
    that seem most urgent and important are on top. But there are also worthwhile
    tasks to perform lower down on the list. Doing these tasks becomes a way of not
    doing the things higher up on the list. With this sort of appropriate task structure,
    the procrastinator becomes a useful citizen. Indeed, the procrastinator can even
    acquire, as I have, a reputation for getting a lot done.</p>
- - https://sites.duke.edu/tomasellolabduke/files/2016/09/Herrmann_PsychScience_2010.pdf#page=4
  - 'The Structure of Individual Differences in the Cognitive Abilities of Children and Chimpanzees: Table 1. Primate Cognition Test Battery: Description of Tasks and Mean Proportion (With Standard Deviation) of Correct Responses by Chimpanzees and Human Children'
  - Esther Herrmann, Maria Victoria Hernández-Lloreda, Josep Call, Brian Hare, Michael
    Tomasello
  - 2010-01-01
  - 10.1177/0956797609356511
  - ! '[Table comparing human children and chimpanzee performance. The means are similar.]'
- - https://sites.duke.edu/tomasellolabduke/files/2016/09/Herrmann_PsychScience_2010.pdf
  - The Structure of Individual Differences in the Cognitive Abilities of Children
    and Chimpanzees
  - Esther Herrmann, Maria Victoria Hernández-Lloreda, Josep Call, Brian Hare, Michael
    Tomasello
  - 2010-01-01
  - 10.1177/0956797609356511
  - ! 'Most studies of animal cognition focus on group performance and neglect individual
    differences and the correlational structure of cognitive abilities. Moreover,
    no previous studies have compared the correlational structure of cognitive abilities
    in nonhuman animals and humans. We compared the structure of individual differences
    of 106 chimpanzees and 105 two-year-old human children using 15 cognitive tasks
    that posed problems about the physical or social world. We found a similar factor
    of spatial cognition for the two species. But whereas the chimpanzees had only
    a single factor in addition to spatial cognition, the children had two distinct
    additional factors: one for physical cognition and one for social cognition. These
    findings, in combination with previous research, support the proposal that humans
    share many cognitive skills with nonhuman apes, especially for dealing with the
    physical world, but in addition have evolved some specialized skills of social
    cognition. [Keywords: individual differences, chimpanzees, human children, social
    cognition, physical cognition]'
- - /docs/psychology/1992-rymer.pdf
  - A Silent Childhood
  - Rymer (<em>The New Yorker</em>)
  - 1992-04-13
  - ''
  - ! '''Annals Of Science'' about a case of child abuse in which a child named Genie
    was kept isolated from the world, locked in a restraining harness in a silent
    bedroom in her parent''s house in Temple City, California. She was either harnessed
    to an infant''s potty chair, unable to move anything except her fingers and hands,
    feet and toes, she was left to sit, tied-up, hour after hour, often into the night,
    day after day, month after month, year after year. At night, when Genie was not
    forgotten, she was placed into another restraining garment—a sleeping bag which
    her father had fashioned to hold Genie''s arms stationary. In effect, it was a
    straight jacket. Describes her environment, and the "toys" she was given to "play"
    with. Because of two plastic raincoats that were sometimes hung in the room, she
    had an inordinate fondness for anything plastic. She was incarcerated by her father
    for 11 1/2 of the first 13 years of her life in a silent room. She could not speak
    when she was rescued, and only learned to talk when she reached the hospital.
    Tells about the fallout, both in human terms and legally, surrounding the research
    into her linguistic abilities. Investigations of Genie''s brain unveiled the utter
    dominance of her "spatial" right hemisphere over her "linguistic" left… This
    may have been why she was unable to grasp grammar—because she was using the wrong
    equipment… From the misfortunes of brain-damaged people, it is clear that language
    tasks are dispersed within their left-hemisphere home. Someone whose brain is
    injured above the left ear will still be able to speak, but there will be no idea
    behind the word strings… Tells about a suit her mother, Irene, brought against
    the hospital when her therapy sessions with hospital staff were included in research
    results by Susan Curtiss, a graduate student studying Genie. The results of Curtiss''s
    doctorate study seemed to both confirm and deny linguist Noam Chomsky''s theory
    about language acquisition. Genie was shuttled from foster home to foster home
    after the scientists at the hospital (including the head of research, David Rigler,
    who adopted her for four years) ran out of grant money. She is currently institutionalized
    in an adult home for the mentally retarded, and in the words of one scientist,
    Jay Shurley, filled with a soul-sickness, and sinking into an apparent'' replica
    of an organic dementia.'
- - https://www.perell.com/blog/peter-thiel
  - Peter Thiel's Religion
  - David Perell
  - 2019-08-04
  - ''
  - ! '<p>We''ll study religion through the lens of Peter Thiel. He''s an investor
    who found wealth in PayPal, a student who found wisdom in Libertarian ideals,
    and a philosopher who found faith in the resurrection of Jesus Christ. Thiel was
    raised as an Evangelical and inherited the Christianity of his parents. But his
    beliefs are "somewhat heterodox." In a profile in the New Yorker, Thiel said:
    "I believe Christianity to be true. I don''t feel a compelling need to convince
    other people of that."</p> <p>Three simple statements will lead us towards our
    ultimate answer about the importance of religion:</p> <ol type="1"> <li>Don''t
    copy your neighbors</li> <li>Time moves forward</li> <li>The future will be different
    from the present</li> </ol> <p>Rather than focusing on Thiel''s actions, I''ve
    chosen to focus on his ideas. First, we''ll explore the principles of Peter Thiel''s
    worldview. We''ll begin by explaining Thiel''s connection to a French philosopher
    named Rene Girard. We''ll return to old books like The Bible, old ideas like sacrifice,
    and old writers like Shakespeare, and see why this ancient wisdom holds clues
    for modern life. Then, we''ll return to the tenets of the Christian story. We''ll
    cover the shift from cyclical time to linear time, which was spurred by technological
    development and human progress. We''ll see why the last book in The Bible,The
    Book of Revelation, is a core pillar of Thiel''s philosophy. Then, we''ll close
    with Thiel''s advice and wisdom almost as old as Cain and Abel: the Ten Commandments.</p>
    <p>…Mimetic conflict emerges when two people desire the same, scarce resource.
    Like lions in a cage, we mirror our enemies, fight because of our sameness, and
    ascend status hierarchies instead of providing value for society. Only by observing
    others do we learn how and what to desire. Our Mimetic nature is simultaneously
    our biggest strength and biggest weakness. When it goes right, imitation is a
    shortcut to learning. But when it spirals out of control, Mimetic imitation leads
    to envy, violence, and bitter, ever-escalating violence…Girard observed that
    even when you put a group of kids together in a room full of toys, they''ll inevitably
    desire the same toy instead of finding their own toy to play with. A rivalry will
    emerge. Human see, human want.</p> <p>…Here''s what I do know: Thiel is trying
    to save the world from apocalypse. The Book of Revelation paints two outcomes
    for the future of humanity: catastrophic apocalypse or a new heaven and a new
    earth…The probability of a civilization-ending apocalypse is increasing. Just
    because we no longer believe that Zeus can strike humans with sky-lighting thunderbolts,
    doesn''t mean that existential risk isn''t possible. Like Girard, he worries that
    the world is becoming more Mimetic. Worse, globalization is raising the threat
    of runaway mimesis and an apocalyptic world with cold corpses, dead horses, and
    splintered guns.</p> <p>…Christianity promises a Living Hope that enables believers
    to endure unimaginable suffering. A hope so resilient that like a Captain America''s
    shield, it can survive any evil, any sickness, or any torture. No matter the obstacles,
    certainty about the future gives you the confidence to act in the present. Thiel''s
    idea of Definite Optimism is Christian theology cloaked in secular language. By
    raising our spirits, a positive vision for the future unites society and raises
    our spirits. And that''s what the Western world needs right now. Technological
    growth is the best way to reduce suffering in the world. Technological progress
    has stagnated since the 1970s, which contributes to the vile political atmosphere
    and the pessimism of modern Westerners. Thiel says we should acknowledge our lack
    of progress, dream up a vision of Definite Optimism, and guided by Christian theology,
    work to make it a reality.</p>'
- - https://old.reddit.com/r/TheMotte/comments/ceajmw/book_review_from_third_world_to_first_by_lee_kuan/
  - ! 'Book Review: From Third World to First, by Lee Kuan Yew [<span class="smallcaps-auto">PART</span> <span class="smallcaps-auto">ONE</span>]'
  - TracingWoodgrains
  - 2019-07-17
  - ''
  - <p>What happens when you give an honest, capable person absolute power?</p> <p>In
    <em>From Third World to First</em>, Lee Kuan Yew, in characteristically blunt
    style, does his best to answer that question.</p> <p>Lee Kuan Yew's politics—and
    by extension Singapore's, because he really did define the country—are often,
    I feel, mischaracterized. In "We Sail Tonight For Singapore", for example, Scott
    Alexander characterizes it as reactionary. This is agreeable to the American left,
    because it's run so differently to Western liberal ideals, and agreeable to reactionaries,
    because Singapore is preternaturally successful by almost any metric you care
    to use.</p> <p>The only problem is that the claim reflects almost nothing about
    how Lee Kuan Yew actually ran the country or who he was.</p> <p>I get the impression
    it's a mistake to frame Singapore alongside a partisan political axis at all,
    because the second you do, half of what the country does will seem bizarre. Lee,
    personally, is open about his party's aim to claim the middle ground, opposed
    by "only the extreme left and right." (111) With that in mind, what works best
    to predict Lee's choices? In his telling, he is guided continually by a sort of
    ruthless pragmatism. Will a policy increase the standard of living in the country?
    Will it make the citizens more self-sufficient, more capable, or safer? Ultimately,
    does it work? Oh, and does it make everybody furious?</p> <p>Great, do that.</p>
    <p><em>From Third World to First</em> is the single most compelling political
    work I've read, and I'd like to capture as much of Lee's style and ideology as
    possible. He divides the book (or at least the half I'm reviewing; I'll leave
    his thoughts on world affairs alone because there's so much to cover as is) into
    sections based on specific policy problems and how he approached them. I'll focus
    my attention on a few:</p> <ul> <li>Citizen welfare &amp; development</li> <li>Free
    speech &amp; free press</li> <li>Approach to political opposition</li> <li>Handling
    of racial &amp; cultural tensions</li> </ul>
- - https://old.reddit.com/r/TheMotte/comments/cgowu1/lee_kuan_yew_review_part_two_you_are_free_to_agree/
  - ! 'Lee Kuan Yew Review, Part Two: ''You are free to agree'''
  - TracingWoodgrains
  - 2019-07-23
  - ''
  - <p>Are you a fan of free speech? Are you eager for everyone to have a platform?
    Are you in favor of an open, unconstrained press? Lee Kuan Yew isn't, and he's
    probably poking fun at you.</p><p>…Here's a question. You're a tiny city-state
    occupying valuable territory, trying to stay independent. You are watching the
    cultural revolution sweep across the homeland of three-quarters of your people,
    and you keep noticing them funding your newspapers. Meanwhile, other superpowers
    are locked in an all-out ideological struggle with those forces, a struggle that's
    shaping policy around the whole world. The country's dominant English-language
    newspaper at the time of gaining independence was "owned by the British and actively
    promoted their interests."<sup>(185)</sup></p><p>What's the right level of freedom
    of press?…Dystopian information lockdown, or prudent defense against foreign
    influence and misinformation? <span class="smallcaps-auto">LKY</span> is convinced, rightly or not, that it is the
    latter. Read with modern US politics in mind, it's easy to compare it to deplatformings
    from tech websites, concerns about Russian infiltration of social media, or the
    controversies around fake news. The context changes, the challenges stay the same.</p>
- - https://old.reddit.com/r/TheMotte/comments/cjqd9i/lee_kuan_yew_review_part_three_race_language_and/
  - ! 'Lee Kuan Yew Review, Part Three: Race, Language, and Uncomfortable Questions'
  - TracingWoodgrains
  - 2019-07-30
  - ''
  - <p>Here's a tricky governing problem for you.</p><p>Imagine your country had historically
    encouraged a minority group to segregate into lower income communities with poor
    living conditions.</p><p>Picture, too, that that minority group had historically
    underperformed in school compared to others.</p><p>Say that your country had faced
    large-scale riots in the 1960s over concerns about perceived government discrimination
    and oppression.</p><p>To spice things up, let's add that they're the country's
    indigenous people, and that they speak a different language and practice a different
    faith than everybody else in the country.</p><p>…and that initially, they formed
    the vast majority of the military and the police force, and the majority in your
    much larger neighbor country. It's hardly going to mirror other countries exactly,
    after all.<sup>(12)</sup></p><p>How do you ensure justice for them and for all
    citizens?</p><p>Singapore has its advantages over other countries, true. It's…
    what was the quote?… "a single city with a beautiful natural harbor right smack
    in the middle of a fantastic chokepoint in one of the biggest trade routes in
    the world."<sup>1</sup></p><p>But demographically, it's <em>complicated</em>,
    to say the least.</p>
- - https://old.reddit.com/r/TheMotte/comments/cmoo25/lee_kuan_yew_review_part_four_the_pathway_to_power/
  - ! 'Lee Kuan Yew Review, Part Four: The Pathway to Power'
  - TracingWoodgrains
  - 2019-08-06
  - ''
  - ! 'So far, my review has mostly left out one massive elephant in the room. Lee
    Kuan Yew was Prime Minister of Singapore from 1959 to 1990. When he stepped down
    from office, he went straight into a close advisory role, sticking around the
    government in some official capacity until 2011. How was he in power so long?
    What was his approach to opposition and to political disagreements, beyond lawsuits?
    Where did he fall on the scale of democratically elected leader to dictator? As
    with every other topic, <span class="smallcaps-auto">LKY</span> is pretty candid about this all. The best place to
    start, though, is likely not with the overt political battles. Instead, I''ll
    focus where he focused early: the unions.'
- - https://medium.com/@deepmindsafetyresearch/designing-agent-incentives-to-avoid-reward-tampering-4380c1bb6cd
  - Designing agent incentives to avoid reward tampering
  - Tom Everitt, Ramana Kumar, Marcus Hutter
  - 2019-08-14
  - ''
  - <p>From an AI safety perspective, having a clear design principle and a crisp
    characterization of what problem it solves means that we don't have to guess which
    agents are safe. In this post and paper we describe how a design principle called
    'current-RF optimization' avoids the reward function tampering problem.</p><p>…One
    way to prevent the agent from tampering with the reward function is to isolate
    or encrypt the reward function. However, we do not expect such solutions to scale
    indefinitely with our agent's capabilities, as a sufficiently capable agent may
    find ways around most defenses. In our new paper, we describe a more principled
    way to fix the reward tampering problem. Rather than trying to protect the reward
    function, we <b>change the agent's incentives</b> for tampering with it.</p><p>The
    fix relies on a slight <b>change to the RL framework</b> that gives the agent
    query access to the reward function. In the rocks and diamonds environment, this
    can be done by specifying to the agent how the purple nodes describe the reward
    function.</p><p>Using query access to the reward function, we can design a model-based
    agent that uses the <b>current reward function</b> to evaluate rollouts of potential
    policies (a current-RF agent, for short). For example, in the rocks and diamonds
    environment, a current-RF agent will look at the current reward description, and
    at time 1 see that it should collect diamonds. This is the criteria by which it
    will choose its first action, which will be going upwards towards the diamond.
    Note that the reward description is still changeable, just as before. Still, the
    current-RF agent will not use the reward-tampering possibility, because it is
    focused on satisfying the current reward description.</p>
- - https://gwern.substack.com/
  - Gwern.net newsletter (Substack subscription page)
  - Gwern Branwen
  - 2013-12-01
  - ''
  - Subscription page for the monthly gwern.net newsletter. There are monthly updates,
    which will include summaries of projects I've worked on that month (the same as
    the <a href="/Changelog">changelog</a>), collations of links
    or discussions from <a href="https://old.reddit.com/r/gwern/">my subreddit</a>,
    and book/movie reviews. You can also browse <a href="/tags/newsletter">the
    archives since December 2013</a>.
- - /tags/newsletter
  - Gwern.net newsletter archives
  - Gwern Branwen
  - 2013-12-01
  - ''
  - ! 'Newsletter tag: archive of all issues back to 2013 for the gwern.net newsletter
    (monthly updates, which will include summaries of projects I''ve worked on that
    month (the same as the <a href="/Changelog">changelog</a>),
    collations of links or discussions from <a href="https://old.reddit.com/r/gwern/">my
    subreddit</a>, and book/movie reviews.)'
- - https://old.reddit.com/r/gwern/
  - /r/gwern subreddit
  - Gwern Branwen
  - 2018-10-01
  - ''
  - A subreddit for posting links of interest and also for announcing updates to gwern.net
    (which can be <a href="https://old.reddit.com/r/gwern/.rss">used as a <span class="smallcaps-auto">RSS</span> feed</a>).
    Submissions are categorized similar to the monthly newsletter and typically will
    be collated there.
- - https://idlewords.com/2010/03/scott_and_scurvy.htm
  - ! 'Scott and Scurvy: How the Cure for Scurvy Was Lost'
  - Maciej Ceglowski
  - 2010-06-03
  - ''
  - <p>[Scott's Antarctic expedition in 1911 was plagued by the disease scurvy, despite
    its having been "conquered in 1747, when the Scottish physician James Lind proved
    in one of the first controlled medical experiments that citrus fruits were an
    effective cure for the disease." How it all went wrong would make a case study
    for a philosophy of science class.</p><p>The British Admiralty switched their
    scurvy cure from lemon juice to lime juice in 1860. The new cure was much less
    effective, but by that time advances in technology meant that most sea voyages
    were so short that there was little or no danger of scurvy anyway. So poor Scott's
    expedition, as well as applying 'state-of-the-art' (i.e. wrong) cures, were falling
    back on a 'tried-and-true' remedy that in fact had been largely ineffective already
    for 50 years… without anyone noticing.]</p><p>An unfortunate series of accidents
    conspired with advances in technology to discredit the cure for scurvy. What had
    been a simple dietary deficiency became a subtle and unpredictable disease that
    could strike without warning. Over the course of fifty years, scurvy would return
    to torment not just Polar explorers, but thousands of infants born into wealthy
    European and American homes. And it would only be through blind luck that the
    actual cause of scurvy would be rediscovered, and vitamin C finally isolated,
    in 1932.</p><p>…So when the Admiralty began to replace lemon juice with an ineffective
    substitute in 1860, it took a long time for anyone to notice. In that year, naval
    authorities switched procurement from Mediterranean lemons to West Indian limes.
    The motives for this were mainly colonial—it was better to buy from British plantations
    than to continue importing lemons from Europe. Confusion in naming didn't help
    matters. Both "lemon" and "lime" were in use as a collective term for citrus,
    and though European lemons and sour limes are quite different fruits, their Latin
    names (<em>citrus medica</em>, var. <em>limonica</em> and <em>citrus medica</em>,
    var. <em>acida</em>) suggested that they were as closely related as green and
    red apples. Moreover, as there was a widespread belief that the antiscorbutic
    properties of lemons were due to their acidity, it made sense that the more acidic
    Caribbean limes would be even better at fighting the disease.</p><p>In this, the
    Navy was deceived. Tests on animals would later show that fresh lime juice has
    a quarter of the scurvy-fighting power of fresh lemon juice. And the lime juice
    being served to sailors was not fresh, but had spent long periods of time in settling
    tanks open to the air, and had been pumped through copper tubing. A 1918 animal
    experiment using representative samples of lime juice from the navy and merchant
    marine showed that the 'preventative' often lacked any antiscorbutic power at
    all.</p><p>By the 1870s, therefore, most British ships were sailing without protection
    against scurvy. Only speed and improved nutrition on land were preventing sailors
    from getting sick.</p><p>…In the course of writing this essay, I was tempted
    many times to pick a villain. Maybe the perfectly named Almroth Wright, who threw
    his considerable medical reputation behind the ptomaine theory and so delayed
    the proper re-understanding of scurvy for many years. Or the nameless Admiralty
    flunky who helped his career by championing the switch to West Indian limes. Or
    even poor Scott himself, sermonizing about the virtues of scientific progress
    while never conducting a proper experiment, taking dreadful risks, and showing
    a most unscientific reliance on pure grit to get his men out of any difficulty.</p><p>But
    the villain here is just good old human ignorance, that master of disguise. We
    tend to think that knowledge, once acquired, is something permanent. Instead,
    even holding on to it requires constant, careful effort.</p>
- - https://www.nytimes.com/2019/07/02/magazine/dead-pig-brains-reanimation.html
  - Scientists Are Giving Dead Brains New Life. What Could Go Wrong? In experiments
    on pig organs, scientists at Yale made a discovery that could someday challenge
    our understanding of what it means to die.
  - Matthew Shaer (<em>The New York Times</em>)
  - 2019-07-02
  - ''
  - ! '<p>In the course of his research, Sestan, an expert in developmental neurobiology,
    regularly ordered slices of animal and human brain tissue from various brain banks,
    which shipped the specimens to Yale in coolers full of ice. Sometimes the tissue
    arrived within three or four hours of the donor''s death. Sometimes it took more
    than a day. Still, Sestan and his team were able to culture, or grow, active cells
    from that tissue—tissue that was, for all practical purposes, entirely dead. In
    the right circumstances, they could actually keep the cells alive for several
    weeks at a stretch.</p><p>When I met with Sestan this spring, at his lab in New
    Haven, he took great care to stress that he was far from the only scientist to
    have noticed the phenomenon. "Lots of people knew this," he said. "Lots and lots."
    And yet he seems to have been one of the few to take these findings and push them
    forward: If you could restore activity to individual post-mortem brain cells,
    he reasoned to himself, what was to stop you from restoring activity to entire
    slices of post-mortem brain?</p><p>…The technical hurdles were immense: To perfuse
    a post-mortem brain, you would have to somehow run fluid through a maze of tiny
    capillaries that start to clot minutes after death. Everything, from the composition
    of the blood substitute to the speed of the fluid flow, would have to be calibrated
    perfectly. In 2015, Sestan struck up an email correspondence with John L. Robertson,
    a veterinarian and research professor in the department of biomedical engineering
    at Virginia Tech. For years, Robertson had been collaborating with a North Carolina
    company, BioMedInnovations, or <span class="smallcaps-auto">BMI</span>, on a system known as a Ca<span class="smallcaps-auto">VESW</span>ave—a perfusion
    machine capable of keeping kidneys, hearts and livers alive outside the body for
    long stretches. Eventually, Robertson and <span class="smallcaps-auto">BMI</span> hoped, the machine would replace
    cold storage as a way to preserve organs designated for transplants.</p><p>…By
    any measure, the contents of the paper Sestan and his team published in Nature
    this April were astonishing: Not only were Sestan and his team eventually able
    to maintain perfusion for six hours in the organs, but they managed to restore
    full metabolic function in most of the brain—the cells in the dead pig brains
    took oxygen and glucose and converted them into metabolites like carbon dioxide
    that are essential to life. "These findings," the scientists write, "show that,
    with the appropriate interventions, the large mammalian brain retains an underappreciated
    capacity for normothermic restoration of microcirculation and certain molecular
    and cellular functions multiple hours after circulatory arrest."</p><p>…"What''s
    happened, I''d argue," says Christof Koch, the president and chief scientist at
    the Allen Institute for Brain Science, "is that a lot of things about the brain
    that we once thought were irreversible have turned out not necessarily to be so."</p>'
- - https://nintil.com/bloom-sigma/
  - ! 'On Bloom''s two sigma problem: A systematic review of the effectiveness of
    mastery learning, tutoring, and direct instruction'
  - José Luis Ricón
  - 2019-07-28
  - ''
  - ! '<p>Is Bloom''s "Two Sigma" phenomenon real? If so, what do we do about it?</p><p>Educational
    psychologist Benjamin Bloom found that one-on-one tutoring using mastery learning
    led to a two sigma(!) improvement in student performance. The results were replicated.
    He asks in his paper that identified the "2 Sigma Problem": how do we achieve
    these results in conditions more practical (i.e., more scalable) than one-to-one
    tutoring?</p><p>In a related vein, this large-scale meta-analysis shows large
    (>0.5 Cohen''s <em>d</em>) effects from direct instruction using mastery learning.
    "Yet, despite the very large body of research supporting its effectiveness, DI
    has not been widely embraced or implemented."</p><p><ul> <li>The literatures examined
    here are full of small sample, non-randomized trials, and highly heterogeneous
    results.</li> <li>Tutoring in general, most likely, does not reach the 2-sigma
    level that Bloom suggested. Likewise, it''s unlikely that mastery learning provides
    a 1-sigma improvement. <ul> <li>But high quality tutors, and high quality software
    are likely able to reach a 2-sigma improvement and beyond. </li> </ul> </li> <li>All
    the methods (mastery learning, direct instruction, tutoring, software tutoring,
    deliberate practice, and spaced repetition) studied in this essay are found to
    work to various degrees, outlined below.</li> <li>This essay covers many kinds
    of subjects being taught, and likewise many groups (special education vs regular
    schools, college vs K-12). The effect sizes reported here are averages that serve
    as general guidance.</li> <li>The methods studied tend to be more effective for
    lower skilled students relative to the rest.</li> <li>The methods studied work
    at all levels of education, with the exception of direct instruction: There is
    no evidence to judge its effectiveness at the college level.</li> <li>The methods
    work substantially better when clear objectives and facts to be learned are set.
    There is little evidence of <a href="https://www.econlib.org/archives/2012/08/low_transfer_of.html">learning
    transfer</a>: Practicing or studying X subject does not improve much performance
    outside of X.</li> <li>There is some suggestive evidence that the underlying reasons
    these methods work are increased and repeated exposure to the material, the <a
    href="https://en.wikipedia.org/wiki/Testing_effect">testing effect</a>, and fine-grained
    feedback on performance in the case of tutoring.</li> <li>Long term studies tend
    to find evidence of a fade-out effect, effect sizes decrease over time. This is
    likely due to the skills being learned not being practiced.</li> </ul></p><p>Bloom
    noted that mastery learning had an effect size of around 1 (one sigma); while
    tutoring leads to <em>d</em>=2. This is mostly an outlier case.</p><p>Nonetheless,
    Bloom was on to something: Tutoring and mastery learning do have a degree of experimental
    support, and fortunately it seems that carefully designed software systems can
    completely replace the instructional side of traditional teaching, achieving better
    results, on par with one to one tutoring. However, designing them is a hard endeavour,
    and there is a motivational component of teachers that may not be as easily replicable
    purely by software.</p><p>Overall, it''s good news that the effects are present
    for younger and older students, and across subjects, but the effect sizes of tutoring,
    mastery learning or DI are not as good as they would seem from Bloom''s paper.
    That said, it is true that tutoring does have large effect sizes, and that properly
    designed software does as well. The <span class="smallcaps-auto">DARPA</span> case study shows what is possible with
    software tutoring, in the case the effect sizes went even beyond Bloom''s paper.</p>'
- - /docs/iq/2019-hegelund.pdf
  - ! 'The influence of familial factors on the association between IQ and educational
    and occupational achievement: A sibling approach'
  - Emilie Rune Hegelund, Trine Flensborg-Madsen, Jesper Dammeyer, Laust Hvas Mortensen,
    Erik Lykke Mortensen
  - 2019-06-04
  - 10.1016/j.paid.2019.05.045
  - ! 'The present register-based study investigated the influence of familial factors
    on the association of IQ with educational and occupational achievement among young
    men in Denmark. The study population comprised all men with at least one full
    brother where both the individual and his brothers were born from 1950 and appeared
    before a draft board in 1968–1984 and 1987–2015 (<em>n</em> = 364,193 individuals).
    Intelligence was measured by Børge Priens Prøve at age 18. Educational and occupational
    achievement were measured by grade point average (<span class="smallcaps-auto">GPA</span>) in lower secondary school,
    time to receiving social benefits at ages 18–30, and gross income at age 30. The
    statistical analyses comprised two distinct statistical analyses of the investigated
    associations: A conventional cohort analysis and a within-sibship analysis in
    which the association under investigation was analysed within siblings while keeping
    familial factors shared by siblings fixed. The results showed that an appreciable
    part of the associations of IQ with educational and occupational achievement could
    be attributed to familial factors shared by siblings. However, only the within
    sibling association between IQ and <span class="smallcaps-auto">GPA</span> in lower secondary school clearly differed
    from the association observed in the cohort analysis after covariates had been
    taken into account.'
- - https://www.econ.ku.dk/cebi/publikationer/working-papers/CEBI_WP_04-19.pdf
  - ! 'Cognitive Consequences Of Iodine Deficiency In Adolescence: Evidence From Salt
    Iodization In Denmark'
  - Benjamin Ly Serena
  - 2019-06-21
  - 10.2139/ssrn.3409795
  - ! 'Over the past three decades, many countries have introduced iodized salt policies
    to eradicate iodine deficiency. While it is well known that iodine deficiency
    in utero is detrimental to cognitive ability, little is known about the consequences
    of iodine deficiencies after birth. This paper examines the impact of iodine deficiency
    in adolescence on cognitive performance. I identify the causal effect of iodine
    deficiency quasi-experimentally using the introduction of iodized salt in Denmark.
    Denmark went from a ban on iodized salt before 1998 to a mandate after 2001, making
    it an ideal national experiment. Combining administrative records on high school
    grades over a thirty-year period with geographic variation in initial iodine deficiency,
    I find that salt iodization increases the Grade Point Averages of high school
    students by 6–9 percent of a standard deviation. This improvement is comparable
    to the benefits of more standard school achievement policies and at much lower
    costs. [Key words: Iodine Deficiency, Iodized Salt, Nutrition, Human Capital,
    Health]'
- - https://www.wired.com/2008/02/ff-seacowboys/
  - ! 'High Tech Cowboys of the Deep Seas: The Race to Save the Cougar Ace'
  - Joshua Davis
  - 2008-02-25
  - ''
  - ! '<p>[On July 23, 2006 the <em>Cougar Ace</em>, a 654-foot car carrier owned
    by Mitsui O.S.K. Lines, reported to the Coast Guard that they were taking on water
    and listing 80 degrees. The Singapore homeported vessel, carrying 4,813 vehicles,
    was en route to Vancouver B.C. In a dramatic rescue, the Coast Guard was able
    to successfully remove all 23 crewmembers from the ship. Joshua Davis of Wired
    tells the story of how a crew from Titan Salvage were able to save the ship, although
    they lost one of their own in the process.]</p><p>…At the worst possible moment,
    a large swell hits the <em>Cougar Ace</em> and rolls the ship even farther to
    port. Objects begin to slide across the deck. They pick up momentum and crash
    against the port-side walls as the ship dips farther. Wedged naked in the shower
    stall, Kyin is confronted by an undeniable fact: The <em>Cougar Ace</em> is capsizing.</p><p>He
    lunges for a towel and staggers into the hallway as the ship''s windmill-sized
    propeller spins out of the water. Throughout the ship, the other 22 crew members
    begin to lose their footing as the decks rear up. There are shouts and screams.
    Kyin escapes through a door into the damp night air. He''s barefoot and dripping
    wet, and the deck is now a slick metal ramp. In an instant, he''s skidding down
    the slope toward the Pacific. He slams into the railings and his left leg snaps,
    bone puncturing skin. He''s now draped naked and bleeding on the railing, which
    has dipped to within feet of the frigid ocean. The deck towers 105 feet above
    him like a giant wave about to break. Kyin starts to pray.</p><p>…Ship captains
    spend their careers trying to avoid a collision or grounding like this. But for
    Rich Habib, nearly every month brings a welcome disaster. While people are shouting
    "Abandon ship!" Habib is scrambling aboard. He''s been at sea since he was 18,
    and now, at 51, his tanned face, square jaw, and don''t-even-try-bullshitting-me
    stare convey a world-weary air of command. He holds an unlimited master''s license,
    which means he''s one of the select few who are qualified to pilot ships of any
    size, anywhere in the world. He spent his early years captaining hulking vessels
    that lifted other ships on board and hauled them across oceans. He helped the
    Navy transport a nuclear refueling facility from California to Hawaii. Now he''s
    the senior salvage master—the guy who runs the show at sea—for Titan Salvage,
    a highly specialized outfit of men who race around the world saving ships.</p><p>They''re
    a motley mix: American, British, Swedish, Panamanian. Each has a specialty—deep-sea
    diving, computer modeling, underwater welding, big-engine repair. And then there''s
    Habib, the guy who regularly helicopters onto the deck of a sinking ship, greets
    whatever crew is left, and takes command of the stricken vessel.</p><p>..The job
    is daunting: Board the <em>Cougar Ace</em> with the team and build an on-the-fly
    digital replica of the ship. The car carrier has 33 tanks containing fuel, freshwater,
    and ballast. The amount of fluid in each tank affects the way the ship moves at
    sea, as does the weight and placement of the cargo. It''s a complex system when
    the ship is upright and undamaged. When the cargo holds take on seawater or the
    ship rolls off-center—both of which have occurred—the vessel becomes an intricate,
    floating puzzle.</p><p>Johnson will have to unravel the complexity. He''ll rely
    on ship diagrams and his own onboard measurements to re-create the vessel using
    an obscure maritime modeling software known as <span class="smallcaps-auto">GHS</span>—General HydroStatics. The model
    will allow him to simulate and test what will happen as water is transferred from
    tank to tank in an effort to use the weight of the liquid to roll the ship upright.
    If the model isn''t accurate, the operation could end up sinking the ship.</p>'
- - https://www.pnas.org/content/111/19/6934
  - Field experiments of success-breeds-success dynamics
  - Arnout van de Rijt, Soong Moon Kang, Michael Restivo, Akshay Patil
  - 2014-05-13
  - 10.1073/pnas.1316836111
  - ! '<p>Social scientists have long debated why similar individuals often experience
    drastically different degrees of success. Some scholars have suggested such inequality
    merely reflects hard-to-observe personal differences in ability. Others have proposed
    that one fortunate success may trigger another, thus producing arbitrary differentiation.
    We conducted randomized experiments through intervention in live social systems
    to test for success-breeds-success dynamics. Results show that different kinds
    of success (money, quality ratings, awards, and endorsements) when bestowed upon
    arbitrarily selected recipients all produced significant improvements in subsequent
    rates of success as compared with the control group of nonrecipients. However,
    greater amounts of initial success failed to produce much greater subsequent success,
    suggesting limits to the distortionary effects of social feedback.</p><p>Seemingly
    similar individuals often experience drastically different success trajectories,
    with some repeatedly failing and others consistently succeeding. One explanation
    is preexisting variability along unobserved fitness dimensions that is revealed
    gradually through differential achievement. Alternatively, positive feedback operating
    on arbitrary initial advantages may increasingly set apart winners from losers,
    producing runaway inequality. To identify social feedback in human reward systems,
    we conducted randomized experiments by intervening in live social environments
    across the domains of funding, status, endorsement, and reputation. [Kickstarter/Wikipedia/Change.org/Epinions]
    In each system we consistently found that early success bestowed upon arbitrarily
    selected recipients produced significant improvements in subsequent rates of success
    compared with the control group of nonrecipients. However, success exhibited decreasing
    marginal returns, with larger initial advantages failing to produce much further
    differentiation. These findings suggest a lesser degree of vulnerability of reward
    systems to incidental or fabricated advantages and a more modest role for cumulative
    advantage in the explanation of social inequality than previously thought. [Keywords:
    Matthew effect, preferential attachment, scale-free networks, rich-get-richer
    effects, power law]</p>'
- - /docs/philo/2010-yvain-inverselawofscientificnomenclature.html
  - Inverse Law of Scientific Nomenclature
  - Scott Alexander
  - 2010-10-23
  - ''
  - <p>It is, of course, a notable prediction of this theory that the least scientific
    idea possible would end up called "Scientology".</p><p>Or so I thought! Last night,
    I discovered there was a movement called "Factology". Obviously this requires
    further investigation!</p><p>…<p>But surely they don't just randomly draw crazy
    conclusions based on a few words that sound the same, do they? Well, here's a
    quote from their Wikipedia article, about "examples of movies with encoded content
    about the reality of aliens among us":</p><blockquote><p>"Yoda… is short for
    Judah. Freemasons are inspired by one entity and that is a grey, by the name of
    Yoda. Yoda guides Freemasonry back to Judah, with the ancient Israel masonry.
    The British"Covenant Of Man" symbolizes the empire striking back. America is the
    empire fighting to overthrow Europe… The word Yoda is not an English word as
    you have been led to believe. Its root word yawdaw appears 111 times in the Old
    Testament, means "to give thanks or praise, throw down, cast, shoot." The word
    Yadah meaning, to "to praise, give thanks" stems from the root word Yawdaw and
    appears only two times in the Old Testament (Daniel 2:23, Daniel 6:10). Not to
    mention the fact Yoda played in [the film] Return of the Jedi, and the word jedi
    is the same as yeti, it's just a matter of a letter, it's really the same word.
    Yeti is the name of Sasquatch (Bigfoot), also called Seti which is equivalent
    to the Extraterrestrials called the Seirians."</p>…<p>Okay, so Uncle Sam is
    a gnostic demon, as revealed by Dr. Seuss who is secretly the king of the pagan
    gods. But can they get even <em>crazier</em>?:</p><blockquote><p>"White people
    were bred to be food, and the 'rapture' expected by Christians is really the return
    of the 'raptors' who will dine on the now-ripe delicious white flesh."</p></blockquote></p>
- - https://www.outsideonline.com/1902036/king-ferret-leggers
  - ! 'The King of the Ferret Leggers: What kind of person sticks a ferret down his
    pants for more than five consecutive hours? Our writer tried to find out'
  - Donald Katz
  - 1983-02-01
  - ''
  - <p>Mr. Reg Mellor, the "king of ferret legging," paced across his tiny Yorkshire
    miner's cottage as he explained the rules of the English sport that he has come
    to dominate rather late in life. "Ay lad," said the 72-year-old champion, "no
    jockstraps allowed. No underpants—nothin' whatever. And it's no good with tight
    trousers, mind ye. Little bah-stards have to be able to move around inside there
    from ankle to ankle."</p><p>Basically, the contest involves the tying of a competitor's
    trousers at the ankles and the subsequent insertion into those trousers of a couple
    of peculiarly vicious fur-coated, foot-long carnivores called ferrets. The brave
    contestant's belt is then pulled tight, and he proceeds to stand there in front
    of the judges as long as he can, while animals with claws like hypodermic needles
    and teeth like number 16 carpet tacks try their damnedest to get out. From a dark
    and obscure past, the sport has made an astonishing comeback in the past 15 years.
    When I first heard about ferret legging, the world record stood at 40 painful
    seconds of "keepin' 'em down," as they say in ferret-legging circles. A few years
    later the dreaded one-minute mark was finally surpassed. The current record—implausible
    as it may seem—now stands at an awesome 5 hours and 26 minutes, a mark reached
    last year by the gaudily tattooed 72-year-old little Yorkshireman with the waxed
    military mustache who now stood two feet away from me in the middle of the room,
    apparently undoing his trousers.</p><p>"The ferrets must have a full mouth o'
    teeth," Reg Mellor said as he fiddled with his belt. "No filing of the teeth;
    no clipping. No dope for you or the ferrets. You must be sober, and the ferrets
    must be hungry—though any ferret'll eat yer eyes out even if he isn't hungry."</p><p>…Loyal
    to nothing that lives, the ferret has only one characteristic that might be deemed
    positive—a tenacious, single-minded belief in finishing whatever it starts. That
    usually entails biting off whatever it bites. The rules of ferret legging do allow
    the leggers to try to knock the ferret off a spot it's biting (from outside the
    trousers only), but that is no small matter, as ferrets never let go. No less
    a source than the Encyclopaedia Britannica suggests that you can get a ferret
    to let go by pressing a certain spot over its eye, but Reg Mellor and the other
    ferret specialists I talked to all say that is absurd. Reg favors a large screwdriver
    to get a ferret off his finger. Another ferret legger told me that a ferret that
    had almost dislodged his left thumb let go only after the ferret and the man's
    thumb were held under scalding tap water—for 10 minutes. Mr. Graham Wellstead,
    the head of the British Ferret and Ferreting Society, says that little is known
    of the diseases carried by the ferret because veterinarians are afraid to touch
    them. Reg Mellor, a man who has been more intimate with ferrets than many men
    have been with their wives, calls ferrets "cannibals, things that live only to
    kill, that'll eat your eyes out to get at your brain" at their worst, and "untrustworthy"
    at their very best.</p>
- - http://nautil.us/issue/39/sport/the-strange-brain-of-the-worlds-greatest-solo-climber
  - ! 'The Strange Brain of the World''s Greatest Solo Climber: Alex Honnold doesn''t
    experience fear like the rest of us'
  - J.B. MacKinnon (<em>Nautilus</em>)
  - 2016-08-11
  - ''
  - ! '<p>Synnott got the biggest response from a story set in Oman, where the team
    had traveled by sailboat to visit the remote mountains of the Musandam Peninsula,
    which reaches like a skeletal hand into the mouth of the Persian Gulf. Coming
    upon an isolated village, they went ashore to mix with the locals. "At a certain
    point," Synnott said, "these guys start yelling and they''re pointing up at the
    cliff. And we''re like, ''What''s going on?'' And of course I''m thinking, ''Well,
    I''m pretty sure I know.'' "</p><p>Up came the photograph for the gasp from the
    crowd. There was Honnold, the same casual dude who was sitting on stage in a grey
    hoodie and khakis, now looking like a toy as he scaled a huge, bone-colored wall
    behind the town. ("The rock quality wasn''t the best," Honnold said later.) He
    was alone and without a rope. Synnott summed up the villagers'' reaction: "Basically,
    they think Alex is a witch." When the Explorers Hall presentation concluded, the
    adventurers sat down to autograph posters. Three lines formed. In one of them,
    a neurobiologist waited to share a few words with Synnott about the part of the
    brain that triggers fear. The concerned scientist leaned in close, shot a glance
    toward Honnold, and said, "That kid''s amygdala isn''t firing."</p><p>…Inside
    the tube, Honnold is looking at a series of about 200 images that flick past at
    the speed of channel surfing. The photographs are meant to disturb or excite.
    "At least in non-Alex people, these would evoke a strong response in the amygdala,"
    says Joseph. "I can''t bear to look at some of them, to be honest." The selection
    includes corpses with their facial features bloodily reorganized; a toilet choked
    with feces; a woman shaving herself, Brazilian style; and two invigorating mountain-climbing
    scenes. "Maybe his amygdala is not firing—he''s having no internal reactions to
    these stimuli," says Joseph. "But it could be the case that he has such a well-honed
    regulatory system that he can say, ''OK, I''m feeling all this stuff, my amygdala
    is going off,'' but his frontal cortex is just so powerful that it can calm him
    down."</p><p>…<em>Absence Of Fear</em>: Scans compare Honnold''s brain (left) with a
    control subject''s (right), a rock climber of a similar age. Crosshairs mark the
    amygdala, a group of nuclei involved in generating fear. As both climbers look
    at the same arousing images, the control subject''s amygdala glows, while Honnold''s
    remains inert, showing no activity whatsoever.</p><p>There is also a more existential
    question. "Why does he do this?" she says. "He knows it''s life-threatening—I''m
    sure people tell him every day. So there may be some kind of really strong reward,
    like the thrill of it is very rewarding." To find out, Honnold is now running
    through a second experiment, the "reward task," in the scanner. He can win or
    lose small amounts of money (the most he can win is $22) depending on how quickly
    he clicks a button when signaled. "It''s a task that we know activates the reward
    circuitry very strongly in the rest of us," Joseph says. In this case, she''s
    looking most closely at another brain apparatus, the nucleus accumbens, located
    not far from the amygdala (which is also at play in the reward circuitry) near
    the top of the brainstem. It is one of the principal processors of dopamine, a
    neurotransmitter that arouses desire and pleasure. High sensation seekers, Joseph
    explains, may require more stimulation than other people to get a dopamine hit.</p><p>After
    about half an hour, Honnold emerges from the scanner looking sleepily doe-eyed.
    Raised in Sacramento, California, he has a refreshingly frank manner of speaking,
    and an oddly contradictory demeanor that might be described as intensely laid
    back—his nickname is No Big Deal, which is his assessment of almost every experience
    he undergoes. Like most expert climbers, he is leanly muscled, more like a fitness
    buff than a body builder. The exceptions are his fingers, which permanently look
    as though they''ve just been slammed in a car door, and his forearms, which bring
    to mind Popeye.</p><p>"Looking at all those images—does that count as being under
    stress?" he asks Joseph. "Those images that you saw are used pretty widely in
    the field for inducing fairly strong arousal responses," Joseph replies. "Because,
    I can''t say for sure, but I was like, <em>whatever</em>," he says. The photographs,
    even the "gruesome burning children and stuff" struck him as dated and jaded.
    "It''s like looking through a curio museum."</p>'
- - https://www.framerated.co.uk/the-haunting-1963/
  - ! 'Film Review: <em>The Haunting</em> (1963)'
  - Remy Dean
  - 2017-10-31
  - ''
  - <p>Gidding hints that the house <em>itself</em> is doing the haunting, implying
    that the architectural environment is responsible for reflecting back the fears
    of those within, teasing out their vulnerabilities, feeding upon them, and making
    them manifest. The house becomes a monster, a maleficent presence that resents
    its human tenants. If the house can be read as a metaphor for the body, as is
    often the case in Gothic mansions and castles, then the occupants become its consciousness,
    the archetypes inhabiting its ego and id. Then the house inevitably suffers from
    a mental schism, a multiple personality disorder. The characters become those
    internal voices of nagging doubt and paranoia for the house… and it eventually
    suffers a mental breakdown.</p><p>Despite filming in England, the setting remained
    as New England. Ettington Park in Stratford-upon-Avon was the spooky mansion that
    Robert Wise chose for Hill House's exteriors, reputedly selected from a list he
    sourced from the British Psychical Research Society of buildings considered to
    be <em>genuinely</em> haunted. This is the first 'character' to appear in the
    film, emerging out of darkness and looking very eerie indeed, due to the inventive
    use of infra-red film stock.</p><p>It's been argued that the house is the true
    star of the film, and I have to admit it turns in a memorable 'performance'. This,
    though, has more to do with marvellous production design by Elliot Scott and the
    huge labyrinthine sets built at Borehamwood. Corridors were made to converge or
    open out, creating a subtly expressionistic feel and rooms were constructed slightly
    askew, sometimes with walls that angled inward. Scott went on to design <em>Labyrinth</em>
    (1986) and the first two Indiana Jones sequels.</p><p>…<em>The Haunting</em>
    is regularly included in Top 10 lists of the scariest films ever made. But the
    special effects are limited to only a few ingenious mechanical effects, as the
    terror is mostly the result of brilliant sound-design, clever use of shadows,
    and inventive camerawork.</p><p>Wise chose to shoot the film in Panavision's wide
    format and every shot makes full use of it, with beautiful compositions and plenty
    of visual interest across every inch of the screen. The otherworldly atmosphere
    and ominous tracking shots, enhanced by special lenses, work in tandem with the
    subtly distorted sets.</p><p>Wise had some problems sourcing the wide-angle lenses
    he needed, mainly because they didn't exist at that time. He wanted the interior
    to look deep, dark, and foreboding, seeming to move as if we were within a living
    thing. The available lenses just weren't cutting it for him. He badgered Bob Gottschalk,
    president of Panavision, until he let slip that wider-lenses were in development
    at their optics labs. Gottschalk explained that they were early prototypes and
    the lenses caused unacceptable distortions. This was <em>exactly</em> what Wise
    wanted! After signing a disclaimer to waive any legal repercussions, he became
    the first director to use such wide angles, imbuing Hill House with its unique
    and disquieting visual personality.</p><p>The unique look of the film goes a long
    way to creating the brooding atmosphere, but the sound design was the real breakthrough.
    The slightest creak of floorboard or sigh of draught makes audiences hold their
    breath to better listen, and then cacophonous groans and thuds really get the
    heart racing.</p><p>…Of course, our emotional involvement hinges on the performances
    of the actors. It seems that the personal circumstances and attitudes of the actors
    already reflected the characters they were to play. Harris admits that she was
    suffering from a bout of depression during filming, and this inadvertently helped
    her play the central role of the sensitive Eleanor, who feels isolated and shunned
    by her colleagues, and so becomes victim to the seductively malign atmosphere
    of the house. Her performance is both fragile and disturbingly unhinged in turns.
    The voice-over she provides, to share her character's paranoia, might have looked
    corny on paper to those American studio executives, but Harris delivers it so
    perfectly that it draws the sympathies of the audience. We feel for her, even
    as she seems to succumb to madness and becomes the willing victim.</p><p><em>The
    Haunting</em> stands alongside <em>Night of the Demon</em> (1957) and <em>The
    Innocents</em> (1961) as a defining classic in the cinema of the supernatural.
    It has never been surpassed and its 'presence' is palpable in most intelligent
    psychological horror films to this day. If special effects had been used more
    extensively, then it surely would have dated, but keeping the focus on mood and
    the psychological aspects of the narrative has ensured it remains as effective
    as ever.</p><p>It's the best Halloween film I could recommend.</p>
- - https://tvtropes.org/pmwiki/pmwiki.php/Anime/MobileSuitGundamCharscounterattack
  - ! '<span class="smallcaps-auto">TVT</span>ropes: Anime / Mobile Suit Gundam: Char''s Counterattack'
  - <span class="smallcaps-auto">TVT</span>ropes
  - '2019'
  - ''
  - ! '<p><em>Mobile Suit Gundam: Char''s Counterattack</em> is the first full-length
    Gundam animated movie released in 1988. <em>Char''s Counterattack</em> is the
    culmination of the original saga begun in <em>Mobile Suit Gundam</em> and continued
    through <em>Mobile Suit Zeta Gundam</em> and <em>Mobile Suit Gundam ZZ</em>, marking
    the final conflict of the fourteen-year rivalry between Amuro Ray and Char Aznable,
    and the end of the Earth Federation/Zeon conflicts.</p><p>…The movie is noteworthy
    for having a rather unusual genesis. Originally, director Yoshiyuki Tomino was
    going to wrap up Amuro and Char''s storyline in <em>Gundam ZZ</em>, but mid-way
    through production he was given the go-ahead to make a movie, forcing the plot
    of <em>ZZ</em> to be rewritten (details on its trope page). In the meantime Tomino
    wrote the novel <em>Hi-Streamer</em>, but when Sunrise gave him the green light,
    he went back and wrote a second novel, <em>Beltorchika''s Children</em>, which
    he specifically wrote to be adapted into a movie. However, Sunrise instead chose
    to use <em>Hi-Streamer</em>, with the final film being a pretty straightforward
    adaptation of its second half. These two novels serve as the origin of the Hi-Nu
    Gundam (the finalized, "perfect" Nu Gundam) and Nightingale (a bigger, beefier
    Sazabi), which pop up in video games like <em>Super Robot Wars</em>, <em>SD Gundam
    G Generation</em>, and <em>Gundam Vs Series</em>.</p>'
- - https://www.animenewsnetwork.com/news/2007-02-20/hideaki-anno-releases-statement-about-new-evangelion-movies
  - Hideaki Anno Releases Statement About New Evangelion Movies
  - 2007-02-20
  - Hideaki Anno
  - ''
  - <p>Many different desires are motivating us to create the new "Evangelion" film.</p><p>The
    desire to portray my sincere feelings on film.</p><p>The desire to share, with
    an audience, the embodiment of image, the diversity of expressions, and the detailed
    portrayal of emotions that animation offers.</p><p>The desire to connect today's
    exhausted Japanese animation [industry] to the future.</p><p>The desire to fight
    the continuing trend of stagnation in anime.<p/><p>The desire to support the strength
    of heart that exists in the world.<p/><p>Finally, the desire to have these wishes
    be realized.</p><p>For these purposes, we used the best methods available to us
    to make another Evangelion film.</p><p>Many times we wondered, "It's a title that's
    more than 10 years old. Why now?"</p><p>"Eva is too old", we felt.</p><p>However,
    over the past 12 years, there has been no anime newer than Eva.<p/><p>… As the
    creator of this project, [I assure you that] a very new-feeling Evangelion world
    has been constructed.</p><p>… Although it seems obvious, we aim to create a
    form of entertainment that anyone can look forward to; one that people who have
    never seen Evangelion can easily adjust to, one that can engage audiences as a
    movie for theatres, and one that produces a new understanding of the world.</p>
- - https://www.khara.co.jp/2019/08/01/01/
  - 『シン・ウルトラマン』映画化に関するお知らせ
  - Studio Khara
  - 2019-08-01
  - ''
  - <p>A new film production of "<span class="smallcaps-auto">SHIN</span> <span class="smallcaps-auto">ULTRAMAN</span>" was publicly announced today. The
    new movie will come to theaters in 2021.</p><p>Hideaki Anno will join a film team,
    Higuchi-Gumi led by Director Shinji Higuchi, taking charge of Produce and Screenplay.
    First draft script has been finished in February 5<sup>th</sup>, 2019. Anno will fully join
    the project after finishing his "<span class="smallcaps-auto">EVANGELION</span>:3.0+1.0" film.</p>
- - https://www.amazon.com/Secret-History-Star-Wars/dp/0978465237
  - <em>The Secret History of Star Wars</em>
  - Michael Kaminski
  - 2008-11-18
  - ''
  - ! 'Star Wars is one of the most important cultural phenomena of the Western world.
    The tale of Luke Skywalker, Han Solo, and the fall and redemption of Anakin Skywalker
    has become modern myth, an epic tragedy of the corruption of a young man in love
    into darkness, the rise of evil, and the power of good triumphing in the end.
    But it didn''t start out that way. In this thorough account of one of cinema''s
    most lasting works, Michael Kaminski presents the true history of how Star Wars
    was written, from its beginnings as a science fiction fairy tale to its development
    over three decades into the epic we now know, chronicling the methods, techniques,
    thought processes, and struggles of its creator. For this unauthorized account,
    he has pored through over four hundred sources, from interviews to original scripts,
    to track how the most powerful modern epic in the world was created, expanded,
    and finalized into the tale an entire generation has grown up with. [<span class="smallcaps-auto">ISBN</span>: 0978465237]'
- - https://scholars-stage.blogspot.com/2010/08/notes-on-dynamics-of-human-civilization.html
  - ! 'Notes on the Dynamics of Human Civilization: The Growth Revolution'
  - Tanner Greer
  - 2018-08-04
  - ''
  - ! '<p>My interest lies in the dynamics of civilized societies: their material
    needs and limitations, the recurring patterns of geography, social organization,
    and cultural complexity upon which they are built, and the type of interactions
    that define their relationships with each other and the physical systems they
    depend on for survival—or in simpler words, the means by which human communities
    flourish and fall.</p><p>…Human civilization has gone through two stages. The
    first of these stages is the longest, beginning with the emergence of complex
    societies in the Near East c. 11,500 years ago and ending only at the beginning
    of the 19<sup>th</sup> century. I submit that every society of this period—from the first
    chiefdoms to the great empires of Rome and China—operated under the same basic
    structural constraints. The rules and limitations were the same; the differences
    were a matter of emphasis and scale. This changes at the turn of the 19<sup>th</sup> century.
    Humanity''s third great period begins here (it has not yet ended). The rules by
    which the modern world operates are incredibly different from those of the old
    order. The transformation wrought by modernization was no less revolutionary than
    that wrought by the advent of complex society 11,000 years previous.</p><p>This
    revolution is widely recognized, but also grossly mischaracterized. The standard
    label for this transition is the "Industrial Revolution". This title is misleading.
    The industrialization of the world economy was the <em>result</em>, not the <em>cause</em>
    of modernization. The nature of this radical transformation is captured better
    by a different title: <b>The Growth Revolution</b>. Population, wealth, and energy
    production/consumption are three quantitative variables that can be estimated
    with some accuracy through much of human history. When displayed on a broad scale
    like this, a striking trend is seen in all three data sets: by 1820 all three
    begin an exponential climb upwards. This is the "Growth Revolution." During this
    revolution human energy production and consumption, population size, wealth, technological
    capacity, and knowledge all began to increase at an exponential rate. <b>This
    constant expansion of human resources is the defining feature of our time.</b>
    Ours is an exponential age.</p><p>…500 years of growth on the part of the wealthiest
    static societies of the old order is <em>equal to less than 7% of a single year''s
    growth on the part of their modern equivalent!</em></p><p>…Many of the world''s
    fallen civilizations met their doom by trying to exceed the inherit limits of
    static civilization.</p>'
- - https://scholars-stage.blogspot.com/2018/01/vengeance-as-justice-passages-i.html
  - ! 'Vengeance As Justice: Passages I Highlighted in My Copy of <em>Eye for an Eye</em>'
  - Tanner Greer
  - 2018-01-26
  - ''
  - ! 'These type of questions naturally lead to the topic of this book: <em>lex talionis</em>,
    the law of the talion, the principle of an eye for an eye, of justice through
    vengeance, retaliation sanctioned by culture and law. This understanding of justice
    is what propels the Icelandic sagas. But it wasn''t just a Viking tick. "Eye for
    an eye" was standard practice just about everywhere a few thousand years ago,
    from the shores of Germainia and the fields of the Greek <em>polis</em> to the
    warring tribes of Canaan and the even more distant lands of the Kurus and the
    Zhou. We view this understanding of justice as backward and crude. We say things
    like "an eye for an eye makes the whole world blind." Miller aims to convince
    us otherwise. We have a lot to learn from these talionic cultures, he argues,
    and our world could be made a more just place if we could humble ourselves enough
    to learn from them.</p><p>I am not going to provide a precis of Miller''s argument
    here. Like past editions of ''Passages I Highlighted'' (see here) I will reserve
    myself to quoting the passages of this book I found most interesting. But to really
    give you a sense for Miller''s argument, I think the best thing I can do is quote
    first from another one of his books, one that focuses specifically on Icelandic
    society. He begins <em>that</em> book by quoting a passage from an obscure saga.
    In only a paragraph, the saga lays out what <em>lex talionis</em> looked like
    in real life:</p><blockquote><p>Some Norwegian merchants chopped off Skæring''s
    hand. Gudmund was given self-judgment in the injury case. Haf Brandsson [Gudmund''s
    second cousin] and Gudmund together adjudged compensation in the amount of thirty
    hundreds, which was to be paid over immediately. Gudmund then rode away from the
    ship. But the Norwegians confronted Haf, who had remained behind; they thought
    the judgment had been too steep and they asked him to do one of two things: either
    reduce the award or swear an oath. Haf refused to do either.</p><p>Some people
    rode after Gudmund and told him what had happened. He turned back immediately
    and asked Haf what was going on. Haf told him where matters stood. Gudmund said,
    "Swear the oath, Haf, or else I will do it, but then they will have to pay sixty
    hundreds. The oath of either one of us will have the same price as Skæring''s
    hand."</p><p>The Norwegians refused the offer. "Then I shall make you another
    proposal," said Gudmund. "I will pay Skæring the thirty hundreds that you were
    judged to pay, but I shall choose one man from amongst you who seems to me of
    equivalent standing with Skæring and chop off his hand. You may then compensate
    that man''s hand as cheaply as you wish."</p><p>This did not appeal to the Norwegians
    and they decided to pay the original award immediately. Gudmund took Skæring with
    him when they left the ship. (<em>G.dýri</em> 26:212) [1]</p></blockquote><p>Iceland
    was a country without a state. They had laws but no government to enforce them.
    If you were wronged, the responsibility to right the wrong rested with you and
    your kin. To prevent retaliatory feuds the Icelanders would often give the wronged
    party a chance to stand in judgement and mete out a punishment to pay for their
    mistakes and restore balance between the two groups. The saga passage you''ve
    just read is an excellent example of how the system worked. Miller''s comments
    on it are worth pondering:</p><blockquote><p>By the time the saga writer focuses
    attention on this incident it is not the hand that is the subject of the dispute
    but the legitimacy and justice of Gudmund''s judgment. The Norwegians think the
    award excessive, and not without reason. More than a few men''s lives at this
    time were compensated for with thirty hundreds or less. <strong><em>Gudmund, however,
    is able to justify astutely his over-reaching by giving these men of the market
    a lesson on the contingency of value and values. To the Norwegians the award should
    reflect the price of a middling Icelandic hand. Gudmund forces them to conceive
    of the award in a different way: it is not the price of buying Skæring''s hand,
    but the price of preserving a Norwegian hand.</em></strong> By introducing the
    prospect of one of their hands to balance against Skæring''s, he is able to remind
    the Norwegians that the thirty hundreds they must pay purchases more than Skæring''s
    hand; it also buys off vengeance in kind. <strong><em>He is also able to force
    them to take into account the costs of personalizing the injury. Most people,
    he bets, are willing to pay more to save their own hands than they would be willing
    to pay to take someone else''s. The justice of Gudmund''s award thus depends on
    a redefinition of its significance. Rather than buying Skæring''s hand, the Norwegians
    are preserving their own, and the price, they now feel, is well worth paying.</em></strong>
    Fellow feeling thus comes not in the form of imagining Skæring''s anguish and
    pain as Skæring''s, but in imagining the pain as their own. [2]</p></blockquote><p>This
    is the logic of <em>lex talionis</em>. This is why "an eye for an eye" did not
    in fact make the whole world go blind. The principle of an eye for an eye, as
    Miller sees it, is "the more ancient and deeper notion that justice is a matter
    of restoring balance, achieving equity, determining equivalence, making reparations…
    getting back to zero, to even." [3] Trading eyes for eyes is not so much about
    indiscriminate, unthinking violence as it is carefully calculated attempts to
    match punishment to crime. Talionic justice is a system built on deterrence—not
    only deterring criminals from committing crimes, but deterring vengeance seekers
    from exacting too heavy a price in retaliation for crimes committed against them.'
- - https://scholars-stage.blogspot.com/2018/08/tradition-is-smarter-than-you-are.html
  - Tradition is Smarter Than You Are
  - Tanner Greer
  - 2018-08-27
  - ''
  - ! '<p>Let''s talk about Henrich first. One of the clearest presentations of his
    ideas is in his 2016 book <em>The Secret of Our Success</em>. The book is less
    a heavy scholarly tome than a popified version of Henrich''s research, but Henrich''s
    decision to trade theoretical detail for accessibility is understandable (it is
    also why I don''t feel bad quoting large blocks of text from the book in this
    post). Henrich advances the argument that brain-power alone is not enough to explain
    why humans are such a successful species. Humans, he argues, are not nearly as
    intelligent as we think they are. Remove them from the culture and environment
    they have learned to operate in and they fail quickly. His favorite example of
    this are European explorers who die in the middle of deserts, jungles, or arctic
    wastes even though thousands of generations of hunter-gatherers were able to survive
    and thrive in these same environments. If human success was due to our ability
    to problem solve, analyze, and rationally develop novel solutions to novel challenges,
    the explorers should have been fine. Their ghastly fates suggest that rationality
    may not be the key to human survival…Henrich has dozens of these examples. The
    common thread pulling them together is that the people whose survival is guaranteed
    by strict observance of these traditions have no real explanation for <em>why</em>
    they are following them. Henrich goes into this with more depth in discussion
    of his ethnographic work in Fiji, where women do not eat certain fish while pregnant.</p><p>…
    Henrich makes two arguments here, both relevant to contemporary debates in politics
    and philosophy. The first is that customs, traditions, and the like are subject
    to Darwinian selection. Henrich is not always clear on exactly what is being selected
    for—is it individuals who follow a tradition, groups whose members all follow
    the tradition, or the tradition itself?—but the general gist is that traditions
    stick around longest when they are adaptive. This process is "blind." Those who
    follow the traditions do not know how they work, and in some cases (like religious
    rituals that build social solidarity) knowing the details of how they work might
    actually reduce the efficacy of the tradition. That is the second argument of
    note: we do not (and often cannot) understand just how the traditions we inherit
    help our survival, and because of that, it is difficult to artificially create
    replacements.</p><p>…Can any of this be put into action? I suspect many conservatives
    will think the answer to this question is obvious. Henrich and Scott have provided
    empirical support for maintaining "Chesterton''s fence." Chesterton asks us not
    destroy customs, tradition, and social structures that we cannot explain. Henrich
    and Scott question our ability to rationally explain them. Implicit in this is
    a strong defense of the local, the traditional, and the unchanging. The trouble
    with our world is that it <em>is</em> changing. Henrich focuses on small scale
    societies. These societies are not static. The changes they undergo are often
    drastic. But the distance between the life-style of a forager today and that of
    her ancestors five hundred years ago pales next to the gap that yawns between
    the average city-slicker and her ancestors five centuries past…Europeans, Japanese,
    Taiwanese, and South Koreans born today look forward to spending their teenage
    years in stage five societies. What traditions could their grandparents give them
    that might prepare them for this new world? By the time any new tradition might
    arise, the conditions that made it adaptive have already changed. This may be
    why the rationalist impulse wrests so strong a hold on the modern mind. The traditions
    are gone; custom is dying. In the search for happiness, rationalism is the only
    tool we have left.</p>'
- - https://scholars-stage.blogspot.com/2015/05/the-war-where-future-met-past.html
  - When Modern War Met an Antique Art
  - Tanner Greer
  - 2015-05-08
  - ''
  - ! '<p>We associate <em>ukiyo-e</em> prints with traditional Japanese landscapes
    or pastoral settings, episodes from Japanese myths or historical epics, and scenes
    of courtesan life in Edo. It can be a bit bewildering when we see the same art
    style and production methods used to produce more modern images. This should not
    be too much of a surprise, however: the most famous of the great Japanese woodblock
    artists died only a few decades before Commodore Perry brought his black boats
    to Edo bay. Much of their era would disappear in the miraculous changes of the
    Meiji revolution, but as the prints included here show quite clearly,  much of
    the old order lived on into the 20<sup>th</sup> century.</p><p>These prints all depict episodes
    from the Sino-Japanese War of 1894 or the Russo-Japanese War that was waged a
    decade later. Remarkably, none of these prints were designed to be great works
    of art; the great majority were carved and colored to accompany news reports from
    the front-lines, printed in newspapers or periodicals circulating in Japan on
    short notice. The artists never saw the battlefields they depicted, relying instead
    on common visual tropes, reporter''s accounts (you can see a gaggle of such reporters
    in the bottom right corner of the print placed directly below), and their own
    imaginations to create these images. The prints are therefore less useful for
    understanding the tactics or battlefield conditions of these wars than they are
    for understanding the attitude of a Japanese public mobilized for external conquest
    for  the first time in centuries.</p><p>As historical sources the prints are revealing.
    A comparison of the physical features of the Japanese and Chinese soldiers depicted
    testifies to how thoroughly the Japanese people had adopted the racialist ideology
    common in European circles at the time. The prints, like the wars themselves,
    also betray how eager the Japanese were to prove that they were the equals of
    the Western powers. Perhaps most interesting, however, is how <em>exultantly</em>
    they depict the wars of their day. Tactically, the Russo-Japanese War was not
    far removed from the Great War that soon followed it, but the way the Japanese
    portrayed their experience with industrial warfare could not be further removed
    from the collective horror Europeans felt when they fought in the trenches. These
    woodblock prints were some of the first artistic renderings of industrial age
    warfare; never again would a people forced to wage such a war render it so beautifully.</p><p>Copied
    below are the war prints I found most useful as historical windows or most visually
    arresting as works of art…</p>'
- - https://scholars-stage.blogspot.com/2014/12/isis-mongols-and-return-of-ancient.html
  - <span class="smallcaps-auto">ISIS</span>, the Mongols, and 'The Return of Ancient Challenges'
  - Tanner Greer
  - 2014-12-18
  - ''
  - <p>The most interesting parallel between <span class="smallcaps-auto">ISIS</span> and the forces of Chinggis Khan
    is actually not one Anderson makes explicitly. He sets up this comparison in his
    discussion of the <span class="smallcaps-auto">ISIS</span> command structure:</p><blockquote><p><strong><em>Use Mission
    Orders to Enhance Operational Security</em></strong>. Telling subordinates what
    to do, not how to do it, is a basic tenant of maneuver warfare; but it also allows
    Baghdadi to command and control his forces with an absolute minimum of cell phone
    and radio communications that are subject to American intercepts which can be
    provided to Iraqi security forces. Baghdadi makes extensive use of runners and
    motorcycle messengers to keep his opponents in the dark.</p><p>American commanders
    talk a good game about Maneuver Warfare, but many take advantage of technology
    and secure communications to micromanage. It is not unusual for an American Colonel
    to be tracking squad sized units on his computer; worse still, it is not unusual
    to require American squad and platoon sized units to submit detailed patrol plans
    three days in advance so they can be plotted into computers. <em>Baghdadi can
    simply say; "take this town and let me know when you have it". It doesn't make
    him a good guy, but he is a very effective military leader. Contrast this with
    Maliki and Karzai who will move or fire a commander who appears so competent or
    popular that he might become a competitor for</em> power (emphasis added) [9].</p></blockquote><p>And
    <em>here</em> is where things get interesting. I don't think it is possible to
    isolate one, single variable that can account for the epochal success of the Mongol
    military machine. But if I was forced to try and boil down the secret of the Mongol
    Empire to a sentence or two it would sound a lot like the one Anderson has written
    here. In contrast to <strong>both</strong> the kingdoms the Mongols destroyed
    and every other nomadic confederation that preceded or followed his empire, Chinggis
    Khan possessed the complete loyalty of his troops and his generals. The men under
    his command were absolutely, and to their enemies, terrifyingly, united. Chinggis
    Khan could wage simultaneous wars on opposite sides of the known world, erode
    the internal cohesion of every kingdom his envoys visited, and paralyze enemy
    defenses with a flood of independently commanded units only because of the fearsome
    unity and loyalty of his forces.</p> While none of the Mongol's other foes imploded
    so spectacularly, sowing dissension and division within the ranks of their enemies
    was an essential element of all Mongol campaigns. Whether they were fighting Hungarian
    monarchs on Pannonian plains or Song Dynasty navies on the Yangtze, the Mongols
    were masters at turning their enemies against each other. The same could not be
    said about the Mongol's rivals. No one ever managed to turn a Mongol. For the
    first three generation of the empire there were no secession crises, no infighting,
    and few traitors. Powerful commanders deferred to their leaders, even when, as
    Juvainyi hints, doing so meant to demotion or punishment. [11] This is really
    quite extraordinary when you consider the kind of positions these commanders were
    placed in. Consider the case of Muqali, one of the greatest but least known of
    the Mongol generals. While Chinggis was off fighting the Khawarezm Empire and
    other enemies in the West, Muqali was placed in charge of the war effort in Northern
    China. For six years he controlled all of Mongolia, Manchuria, and the North China
    plain and for six years he fought the Jin Empire without losing a single battle.
    He was a powerful and popular commander. But neither he nor his sons ever challenged
    the great Khan's authority. There is no evidence that Chinggis ever feared that
    they would. [12]</p>.<p>.. The story of how Chinggis Khan created an empire whose
    many branches were unified in effort and whose many subjects were absolutely loyal
    to him is one of the most fascinating in world history. Unfortunately, it is only
    tangentially related to the topic at hand. A full investigation of that question
    must be reserved for a later post. For the purposes of this discussion what matters
    is that the conquests of the Mongol empire, the type of warfare it waged, and
    the methods it used to incorporate new peoples into its domains would not have
    been possible except for the unshakable unity of its commanders and warriors.
    In this the Mongols are very much like Abu Bakr al-Baghdadi and the warriors under
    his command.</o>
- - https://scholars-stage.blogspot.com/2014/06/the-cross-section-ilusion.html
  - The Cross Section Illusion
  - Tanner Greer
  - 2014-06-07
  - ''
  - <p>If you are concerned with American obesity rates and turn to the cross sectional
    data to try and figure out what is going on, it is easy to reach a flawed conclusion.
    The correlation between education and obesity, for example, seems quite clear.
    The poorer and less educated an American is, the more likely he or she is to be
    obese. Looking at this data it seems reasonable to suggest that something about
    poverty is making people more obese—perhaps cruddy processed food is the only
    thing America's poor and less educated can afford to buy, or maybe the poor live
    in urban areas where people do not exercise. These hypotheses are plausible…
    until you look at the time series. It then becomes apparent that the rich and
    educated are gaining weight at the same rate as the poor. Poverty cannot explain
    this.</p><p>It is very difficult to make meaningful claims about causation—or
    even correlation!—on the basis of cross section data alone. Often times seemingly
    perfect, statistically significant correlations disappear when the same variables
    are viewed over a longer stretch of time. In other cases—as in this one—time series
    data reveals that the real story isn't about variance between two groups at all,
    but about the rate at which each group is changing. It is all too easy to be fooled
    by the Cross Section Illusion.</p>
- - http://zenpundit.com/?p=52965
  - ! 'Announcing: The Thucydides Roundtable'
  - Tanner Greer et al
  - 2016-08-23
  - ''
  - <p>I am proud to announce the upcoming Thucydides Roundtable, to be hosted at
    the group blog Zenpundit in October 2016.</p><p>Thucydides is a man of firsts.
    He has been called the father of realism, the first "theorist of war" in the Western
    tradition, the inventor of political science and international relations, the
    first man to ever attempt an objective and evidence based history of the world
    he lived in, and many other things besides. In the two thousand years since they
    were first written, his words have been used and abused by historians, poets,
    social scientists, and statesmen from one side of the Earth to the other. His
    chronicle of the thirty year war waged between his native Athens and her rival
    Sparta has just about everything in it. I really do mean <em>everything</em>.
    No great or enduring theme of the human experience is left untouched—war and international
    order of course make their appearance, but so do meditations on statesmanship,
    bargaining, courage, partisanship, justice, ethics, ambition, greed, honor, religion,
    culture, history, and so much more. His <em>History of the Peloponnesian War</em>
    is not just the story of a quarrel between Athenians and Lacedaemonians in the
    5<sup>th</sup> century BC. It is a story about all of mankind.</p><p>Or at least this is
    what Thucydides hoped it would be.</p><p>I invite you to discover for yourself
    if Thucydides' ambition was realized by reading his work with us. We will officially
    kick off the roundtable discussion at Zenpundit in mid-October. In the weeks to
    come we will publish the full list of official participants as well as the Roundtable's
    official rules of engagement. Until then, I encourage you to go out and purchase
    the <em>Landmark Thucydides</em> to get a head start on the reading. It's a big
    book, but one well worth reading.</p>
- - https://scholars-stage.blogspot.com/2016/10/everybody-wants-thucydides-trap.html
  - Everybody Wants a Thucydides Trap
  - Tanner Greer
  - 2016-10-30
  - ''
  - ! '<p>We don''t come to Thucydides'' <em>History</em> with preexisting knowledge
    of the war. Our only guide to Thucydides is Thucydides himself. We thus must read
    with utmost care. If we do not, we risk mistaking Thucydides'' judgments about
    the war for the events of the war itself.</p><p>Nowhere is more careful attention
    demanded than Thucydides'' treatment of the Megarian Decree. Like all Greeks of
    the age, the Athenians had long memories. Their enmity for Megara began a generation
    earlier, when Athenian blood was lost as consequence of Megarian betrayal. The
    Megarian betrayal came during a day of war, Athen''s first life-and-death struggle
    with the men of Sparta. The proximate causes of the this dispute were more recent,
    however. Thucydides reports that Athens "accused the Megarians of pushing their
    cultivation into consecrated ground and the unenclosed land on their border, and
    of harboring runaway slaves." Thucydides'' description of the Athenian response:
    a "Megara Decree, excluding the Megarians from the use of Athenian harbors and
    of the market of Athens." (1.139.2)</p><p>…In face of these questions Pericles
    was dismissive:</p><p><blockquote>"<b>I hope that none of you think that we shall
    be going to war for a trifle if we refuse to revoke the Megara decree, which appears
    in front of their complaints</b>, and the revocation of which is to save us from
    war, or let any feeling of self-reproach linger in your minds, as if you went
    to war for slight cause. <b>Why, this trifle contains the whole seal and trial
    of your resolution.</b> If you give way, you will instantly have to meet some
    greater demand, as having been frightened into obedience in the first instance;
    while a firm refusal will make them clearly understand that they must treat you
    more as equals. Make your decision therefore at once, either to submit before
    you are harmed, or <b>if we are to go to war, as I for one think we ought, to
    do so without caring whether the ostensible cause be great or small</b>, resolved
    against making concessions or consenting to a precarious tenure of our possessions.
    For all claims from an equal, urged upon a neighbor as commands before any attempt
    at legal settlement, be they great or be they small, have only one meaning, and
    that is slavery. [1.40.4, emphasis added]</blockquote></p><p>The argument that
    Thucydides puts into Pericles'' mouth is simple: the coming war is not really
    about the decree at all, but more fundamental questions of power and rank. Is
    Athens subordinate to Sparta? Or are the two polis equal in rank? That was the
    real question being decided by this war. Any "ostensible cause" to get things
    rolling would do—in this case that ostensible cause just happened to be the embargo
    of Megara.</p><p>…See this for what it is: Thucydides has omitted from his history
    a central cause of the war! This was not an oversight. It may have been the entire
    point of Book I. In Thucydidean terms, the Megarian decree was (as Thucydides
    has Pericles say) "a trifle." It was an "ostensible cause" of the great war, but
    not its true one. A war of this magnitude could not be caused by trifles, and
    to drive home the point of just how trifling and irrelevant this <em>casus belli</em>
    was to the war''s actual conduct, Thucydides crafts a narrative of the war that
    does not include it at all…A review of the origins and first moments of this
    war suggests that it was less a matter of growing fear and growing power, than
    a matter of tarnished honor and quests for glory. Athens'' growing wealth was
    a necessary condition for the war, but it was hardly the only or the most important
    cause of it. Had Athens'' quest for glory been less ambitious, had Sparta not
    tied herself to an ally hellbent on forcing her private wars and narrow interests
    onto the entire league of Spartan allies, and had the Greeks not been a people
    obsessed with insults, rank, and honor, this war may never have occurred. It was
    not an inevitable clash of fear and power that brought war to Hellas, but a very
    specific set of decisions made by a very specific set of leaders in the years
    before the war.</p>'
- - https://scholars-stage.blogspot.com/2016/12/men-of-honor-men-of-interest.html
  - Men of Honor, Men of Interest
  - Tanner Greer
  - 2016-12-01
  - ''
  - ! 'The Plataeans and the Mytilenians both heard a case arguing for their death,
    as well as one arguing for their continued survival. In the Mytilenian case, both
    the defendant and the prosecution were represented by Athenians. In the case of
    Plataea, the Plataeans were forced to speak in their own defense, with the Thebans
    arguing for their death. The parallel is clear. It to the arguments we turn to
    find the contrast between the two hegemonic powers.</p><blockquote><p>…<em>What
    is this but to make greater enemies than you have already, and to force others
    to become so who would otherwise have never thought of it?</em></p></blockquote><p>The
    Athenians were once a people of honor. "For glory then and honor now" was the
    rallying cry Pericles raised to lead his people to war (2.64.6). The Athenians
    began this entire drama chasing it. No longer. Athenian honor died long before
    the war''s close. Athenian honor could not survive the plague. Then the beastly
    truth was revealed: honor meant nothing but scarred skin and blistered visage.
    Nobility brought no recompense but rotting flesh. Eat now, drink now, be merry
    now, for tomorrow men will die! And die, and, die, and die. Justice, integrity,
    honor—mere words. Where could those words be found? Buried deep in burning heaps
    of flesh! Abandoned in lonely, forgotten corners where none would see them croak
    away! Beneath blood, phlegm, pustule, and vomit! What has honor to do with Athens?
    Nothing. What is more, they knew it…Thucydides relates the speech of two men
    in the debate over Mytilene, one Cleon, son of Cleanetus, the ''most violent man
    in Athens.'' The other Diodotus, son of Eucrates, a more measured sort who does
    not appear elsewhere in this history. Cleon argues for the Mytilene''s extinction.
    Diodotus, for their salvation. They disagreed on almost every point. What sticks
    out, however, is what they <em>did</em> agree on. Both wanted everyone to know
    that their arguments had nothing whatsoever to do with justice, honor, or mercy.</p><p>Said
    Cleon:</p><blockquote><p>…However, if, right or wrong, you determine to rule,
    you must carry out your principle and punish the Mytilenians as your interest
    requires; or else you must give up your empire and cultivate honesty without danger
    (3.37; 3.40).</p></blockquote><p>In reply, Diodotus:</p><blockquote><p>…However,
    I have not come forward either to oppose or to accuse in the matter of Mytilene;
    indeed, the question before us as sensible men is not their guilt, but our interests.
    Though I prove them ever so guilty, I shall not, therefore, advise their death,
    unless it be expedient; nor though they should have claims to indulgence, shall
    I recommend it, unless it be clearly for the good of the country</p></blockquote><p>Behold
    the men of Athens! Dead to honor, to principle, to humanity. This was a people
    whose hearts had hardened. Nothing was left to Athens but the pursuit of power—and
    its cousin, profit. The only language they spoke was the language of naked interest.
    That language saved the Mytilenians. They were lucky. Interest is a fickle master.
    The men of Melos discovered just how twisted a master it can be. In time, so would
    the Athenians.'
- - https://scholars-stage.blogspot.com/2016/11/history-is-written-by-losers.html
  - ! ' History is Written by the Losers '
  - Tanner Greer
  - 2016-11-21
  - ''
  - <p>In his roundtable post, "Treason Makes the Historian," Lynn Rees lists a few
    of the type. Herodotus wrote his history only after his exile from Halicarnassus;
    Xenophon wrote his memoirs only after his faction was forced out of Athens. Polybius
    was once a general for the Archean League, but wrote his history as a hostage
    at Rome. The destruction of Judea was chronicled by a Josephus, a Jew.</p><p>These
    men abandoned their countries and people for the victors of the future. But Quislingdom
    was not the only losing path to historical fame. Tacitus's loyalty to Rome never
    wavered—but neither did his identification with Rome's Senatorial class, a group
    whose power was slowly stripped away as Tacitus wrote his chronicles. Sima Guang,
    the second most significant historian of Chinese history, only finished his massive
    Zizhi Tongjian after court rivalries had forced him to retire. The history of
    the Mongols was written almost entirely by their vanquished enemies. Ibn Khaldun
    was associated with so many failed regimes that it is a wonder he found time to
    write his history at all.</p><p>I am sure more examples can be found. The example
    most relevant to this roundtable is one Thucydides, son of Olorus. It is here
    in Book IV we finally learn a tad about the man behind the curtain:</p><p><blockquote>The
    passage of Brasidas was a complete surprise to the people in the town; and the
    capture of many of those outside, and the flight of the rest within the wall,
    combined to produce great confusion among the citizens; especially as they did
    not trust one another… Meanwhile the party opposed to the traitors proved numerous
    enough to prevent the gates being immediately thrown open, and in concert with
    Eucles, the general, who had come from Athens to defend the place, sent to the
    other commander in Thrace, Thucydides, son of Olorus, the author of this history,
    who was at the isle of Thasos, a Parian colony, half a day's sail from Amphipolis,
    to tell him to come to their relief. On receipt of this message he at once set
    sail with seven ships which he had with him, in order, if possible, to reach Amphipolis
    in time to prevent its capitulation, or in any case to save Eion (4.103).</blockquote></p><p>Now
    pieces of Thucydides work start to click together. Few Spartans are mentioned
    by name; fewer still are Spartans mentioned by name on multiple occasions. The
    exception is Brasidas. Brasidas, brave defender of Methone, and thus "the first
    man in this war to receive the official honors of Sparta" (2.25). Brasidas, whose
    stratagems almost defeated the Athenians at sea (2.86-87). Brasidas, the daring
    leading who almost stormed the fort at Pylos (4.12). Brasidas, the savior of Megara
    (4.70-73). Brasidas, the only Spartan eloquent and wise enough to raise all of
    Thessaly into revolt (4.84). Brasidas, the general who defeated Thucydides.</p><p>Thucydides'
    obsession with Brasidas is easy to understand once his personal relation to Thucydides
    is made clear. His portrayal of Brasidas as daring, brilliant, charismatic, and
    clever beyond measure also begins to make sense—the greater Brasidas' past feats
    appear, the less damning Thucydides defeat at his hands becomes.</p>
- - https://scholars-stage.blogspot.com/2015/10/pre-modern-battlefields-were-absolutely.html
  - Pre-Modern Battlefields Were Absolutely Terrifying
  - Tanner Greer
  - 2015-10-25
  - ''
  - ! '<p>Why was cold steel a "unique terror" for troops in combat? On the face of
    it a sword does not <em>seem</em> any more frightening than the cannon-ball. Pop
    culture portrayals of small imperialist forces putting hordes of backward natives
    to flight with nothing but gun and powder suggest the opposite conclusion. Images
    of countless thousands led to the slaughter on the banks of the Somme or hills
    of Verdun only strengthen the impression. But those men who actually withstood
    both the bullet and the bayonet overwhelmingly preferred to face the former. A
    similar preference for arrows and cross-bows shot from afar over spear thrusts
    and sword strokes closer to home pervades the ancient and medieval sources.</p><p>To
    understand why this was so you must discard Hollywood notions of close combat.
    This is hard to do, for the notions are much older than Hollywood. The classical
    Chinese novels Outlaws of the Marsh and Romance of the Three Kingdoms speak of
    warriors who exchange five, ten, twenty, and even fifty "rounds" or "clashes"
    on the battlefield. The long duels of ancient India''s great war epic, the Mahabharata,
    are matched only by the extended contests of its Greek counterpart, the Iliad.
    All of it is poppycock. Ancient battles did not descend into a series of extended
    melees when the two front lines collided. The silliness of the Hollywood style
    of battle becomes immediately apparent when you watch sparring competitions that
    use pre-modern weapons: [video link]</p><p>As you can see, most close quarter
    engagements are decided within seconds. To engage in hand to hand combat is to
    hang your life on a the balance of a few split second decisions. This is terrifying.
    It is all the more terrifying if the enemy force is as committed and disciplined
    as your own. If you survive the first encounter—that is, if you successfully kill
    the first man who attempts to kill you—there will be another, and then yet another
    to fill in his place. How long can you keep making instant life-or-death decisions
    before you make a mistake? The odds are not in your favor. The physical and mental
    strain of close quarters combat on those in the front lines is simply more than
    can be borne for any great stretch of time.</p>'
- - https://scholars-stage.blogspot.com/2015/01/the-radical-sunzi.html
  - The Radical Sun Tzu
  - Tanner Greer
  - 2015-01-02
  - ''
  - <p>Timeless as it may seem, however, the <em>Sunzi</em> was the product of problems
    experienced at a specific time and a specific place. It is my belief that we cannot
    really understand the <em>Sunzi</em> if we do not first understand the world from
    which it came—the world of the Warring States.[2] A few historians and scholars
    of Chinese thought have written this sort of analysis; the best of these attempts
    to place the <em>Sunzi</em> within its historical context are usually focused
    on the broad, macro-historical trends that divided the Spring and Autumn period
    that preceded the <em>Sunzi</em> from the Warring States period that gave birth
    to it. From this perspective the <em>Sunzi</em> and the other military manuals
    that followed it were the natural product of a world torn asunder by wars waged
    on an ever increasing scale between large infantry armies fighting in the name
    of territorial, bureaucratized states.[3] There is, however, more to the <em>Sunzi</em>'s
    historical setting than the institutional history of ancient China. Just as important
    is the intellectual milieu of early Warring States times. The compilers of the
    <em>Sunzi</em> were not the first Chinese to write about war. When read as a response
    to these earlier voices, the <em>Sunzi</em>'s vision of war and politics is nothing
    less than radical.</p><p>…Its revolutionary nature only becomes clear when we
    see what it was written in response to. The place to turn is the <em>Zuo Zhuan</em>,
    China's oldest narrative historical account and one of the few preserves of the
    old Spring and Autumn ethos. One of its better known dictums reads:</p><p><blockquote>The
    great affairs of state are sacrifice and warfare.[5]</blockquote></p><p>Meyer
    comments on the contrast between the two statements:</p><p><blockquote>[In the
    <em>Sunzi</em>] all mention of sacrifice is eliminated, telegraphing the text's
    contention that martial matters must be viewed in purely material terms. Rather
    than "warfare", the "military" is held up as the great affair of state, implying
    (as the text goes on to elaborate) that there are uses for military power beyond
    the 'honorable' contest of arms. Moreover, the word that the <em>Sunzi</em> uses
    by reference to the "military", <em>bing</em> (兵), does not evoke the aristocratic
    charioteer but the common foot solider, who had become the backbone of the Warring
    States army.[6]</blockquote></p><p>The <em>Sunzi</em>'s insistence that military
    methods were more important to the state's survival than sacrifice was not merely
    radical—it was nonsensical. In the early Chinese world view, sacrifice and warfare
    could not be separated from each other. As with the Aztecs, Maya, and many other
    premodern peoples, for the Chinese of Zhou times, warfare <em>was</em> a sacrificial
    ritual.</p>
- - /docs/iq/1957-shockley.pdf
  - On the Statistics of Individual Variations of Productivity in Research Laboratories
  - William Shockley
  - '1957'
  - 10.1109/JRPROC.1957.278364
  - It is well-known that some workers in scientific research laboratories are enormously
    more creative than others. If the number of scientific publications is used as
    a measure of productivity, it is found that some individuals create new science
    at a rate at least 50 times greater than others. Thus differences in rates of
    scientific production are much bigger than differences in the rates of performing
    simpler acts, such as the rate of running the mile, or the number of words a man
    can speak per minute. On the basis of statistical studies of rates of publication,
    it is found that it is more appropriate to consider not simply the rate of publication
    but its logarithm. The logarithm appears to have a normal distribution over the
    population of typical research laboratories. The existence of a "log-normal distribution"
    suggests that the logarithm of the rate of production is a manifestation of some
    fairly fundamental mental attribute. The great variation in rate of production
    from one individual to another can be explained on the basis of simplified models
    of the mental processes concerned. The common feature in the models is that a
    large number of factors are involved so that small changes in each, all in the
    same direction, may result in a very large [multiplicative] change in output.
    For example, the number of ideas a scientist can bring into awareness at one time
    may control his ability to make an invention and his rate of invention may increase
    very rapidly with this number.
- - /docs/nootropics/2013-rojas.pdf
  - Neurological and psychological applications of transcranial lasers and LEDs
  - Julio C.Rojas, F.Gonzalez-Lima
  - '2013'
  - 10.1016/j.bcp.2013.06.012
  - Transcranial brain stimulation with low-level light/laser therapy (<span class="smallcaps-auto">LLLT</span>) is the
    use of directional low-power and high-fluency monochromatic or quasimonochromatic
    light from lasers or <span class="smallcaps-auto">LED</span>s in the red-to-near-infrared wavelengths to modulate
    a neurobiological function or induce a neurotherapeutic effect in a nondestructive
    and non-thermal manner. The mechanism of action of <span class="smallcaps-auto">LLLT</span> is based on photon energy
    absorption by cytochrome oxidase, the terminal enzyme in the mitochondrial respiratory
    chain. Cytochrome oxidase has a key role in neuronal physiology, as it serves
    as an interface between oxidative energy metabolism and cell survival signaling
    pathways. Cytochrome oxidase is an ideal target for cognitive enhancement, as
    its expression reflects the changes in metabolic capacity underlying higher-order
    brain functions. This review provides an update on new findings on the neurotherapeutic
    applications of <span class="smallcaps-auto">LLLT</span>. The photochemical mechanisms supporting its cognitive-enhancing
    and brain-stimulatory effects in animal models and humans are discussed. <span class="smallcaps-auto">LLLT</span>
    is a potential non-invasive treatment for cognitive impairment and other deficits
    associated with chronic neurological conditions, such as large vessel and lacunar
    hypoperfusion or neurodegeneration. Brain photobiomodulation with <span class="smallcaps-auto">LLLT</span> is paralleled
    by pharmacological effects of low-dose <span class="smallcaps-auto">USP</span> methylene blue, a non-photic electron
    donor with the ability to stimulate cytochrome oxidase activity, redox and free
    radical processes. Both interventions provide neuroprotection and cognitive enhancement
    by facilitating mitochondrial respiration, with hormetic dose-response effects
    and brain region activational specificity. This evidence supports enhancement
    of mitochondrial respiratory function as a generalizable therapeutic principle
    relevant to highly adaptable systems that are exquisitely sensitive to energy
    availability such as the nervous system.
- - /docs/radiance/2005-gusterson.pdf
  - ! 'A Pedagogy of Diminishing Returns: Scientific Involution across Three Generations
    of Nuclear Weapons Science'
  - Hugh Gusterson
  - '2005'
  - ''
  - ! '<p>A generation of historians, sociologists, and anthropologists of science
    has learned from actor-network theory and the sociology of scientific knowledge
    (<span class="smallcaps-auto">SSK</span>) to focus on the building of scientific institutions and facts, and from
    Thomas Kuhn to expect a certain historical rhythm in the evolution of scientific
    fields of knowledge: first, a dynamic burst of creativity (the "revolution") as
    the foundational ideas of the new field are laid down; second, a period of "normal
    science" in which gaps are filled in as the new knowledge is institutionalized;
    and, finally, as puzzles emerge that cannot be fully explained by the established
    paradigm, a new burst of creativity as another generation redefines the fundamental
    precepts of the field.</p><p>In this essay, looking at three generations of nuclear
    weapons designers, I follow and then depart from the Kuhnian script. Although
    the first two generations of nuclear weapons scientists conformed perfectly to
    the Kuhnian storyline, the final story is not about the punctuated equilibrium
    of scientific revolution, but about a process of scientific involution as nuclear
    weapons science has simultaneously matured and withered in a way that is beautifully
    evoked in a blues ballad once sung for me by a group of weapons designers from
    the Lawrence Livermore National Laboratory:</p><blockquote><p>Went down to Amarillo<br/>Lookin''
    for my sweet ''53<sup>3</sup><br/>It was laying on a long white table<br/>Looked
    cold and hard to me<br/>Let it go, let it go, retire it<br/>No city scrapers do
    we need<br/>Take a 61<sup>4</sup> and modify it.<br/>Call it the mod 11-E<br/>Now
    you can search this whole world over<br/>From Frisco to Albuquerque<br/>You can
    mentor anyone that you want to<br/>But you''ll never find designers like me<br/>Now
    when I''m gone, just put me way down<br/>In a hole off the old Orange Road.<br/>''ttach
    a cable to my device can<br/>So I can run those legacy codes (fading)<br/>So I
    can run those legacy codes<br/>So I can run those legacy codes.<sup>5</sup></p></blockquote><p>…The
    1970s and the 1980s, when nuclear testing moved underground, were a period of
    routinization: the institutional apparatus for nuclear weapons design and testing
    grew, its scientific achievements shrank, and the arteries of the weapons design
    bureaucracy hardened. Attempts to perfect a third-generation nuclear weapon—the
    x-ray laser—failed and were abandoned in an atmosphere of scandal and disgrace.<sup>11</sup>
    The art of weapons design progressed, but by increments rather than great leaps:
    weapons designers learned to squeeze greater yields out of smaller quantities
    of plutonium so that nuclear weapons could be made lighter and smaller, weapons
    were made safer through the addition of Permissive Action Links (<span class="smallcaps-auto">PALS</span>) and the
    substitution of Insensitive High Explosive (<span class="smallcaps-auto">IHE</span>) for conventional explosives,<sup>12</sup>
    and the supercomputer codes used to model the behavior of nuclear weapons were
    gradually refined. The names of the men (and now women) behind these achievements
    are largely unknown outside the nuclear weapons bureaucracy, and in some cases
    their achievements are only partially known within the weapons laboratories, thanks
    to the compartmentalizing effects of official secrecy in the weapons complex.<sup>13</sup></p><p>Nuclear
    tests were forbidden after the end of the Cold War, and the practice and pedagogy
    of nuclear weapons science shifted again. Forced to largely abandon their nuclear
    test site in Nevada—a place where the desert sands encroach on the old bowling
    alley and cinema, now disused, as tourist buses disgorge camera-laden voyeurs
    to gawk at the nuclear craters—many of the old-timers elected to retire. Those
    that stayed have regrouped their forces in the virtual world of simulated testing,
    where they are attempting to train a new generation of scientists to maintain
    devices they cannot test. In some ways the scientific challenges of nuclear weapons
    design have shrunk to microscopic proportions: new designs are not built or deployed,
    and even the decision to substitute a new epoxy in an aging weapon can send a
    tremor of fear through design teams unsure if their weapons will still work. In
    other ways, the scientific challenges are suddenly magnified: how to design implosion,
    shock wave, and laser fusion experiments that will shed light on the performance
    of aging nuclear weapons in the absence of nuclear testing? How to use the physics
    knowledge of today to understand test data, long buried in dusty filing cabinets,
    from the 1950s and the 1960s? And how to convert old two-dimensional codes designed
    for Cray supercomputers into three-dimensional codes that can run on massively
    parallel systems now being designed?</p>'
- - /docs/psychology/1963-gussow.pdf
  - ! 'A Preliminary Report of Kayak Angst Among the Eskimo of West Greenland: A Study
    in Sensory Deprivation'
  - Zachary Gussow
  - '1963'
  - 10.1177/002076406300900103
  - <p>Sensory deprivation experiences and isolation phenomena belong to the broader
    field of environmental stress and, as such, research in this area is of importance
    to the anthropologist concerned with mental disorder. In one form or another sensory
    deprivation is a universal experience. It is present in such diverse events as
    research experiments, sleep, vision experiences, 'highway hypnosis' and kayak-angst.
    Sensory deprivation and isolation may be culturally required, recommended, unavoidable
    or even individually sought out. Reactions are variable and are dependent upon
    the interplay of a number of factors. Experiences may be occupationally linked,
    as in the confused and disoriented reactions reported by aviators flying solo
    or in positions cut off from the rest of the crew. Creative people who seek out
    retreats in order to work more efficiently and productively, as well as persons
    on the couch in psychoanalytic treatment are also experiencing sensory deprivation,
    though in a mild form.</p><p>In kayak-angst the Eskimo of West Greenland provide
    us with an instance of a group where severe sensory deprivation reactions are
    culturally typical for the adult male segment of the population and forms a part
    of their routinized, seasonal, if not everyday, round of life.</p><p>Kayak-angst
    (kayak-phobia, kayak-dizziness) is well known throughout all districts of West
    Greenland. It is also known to occur among the Polar Eskimo and in East Greenland,
    though an intensive search of the literature, extensive correspondence, and interviews
    with eastern Canadian Eskimos has failed so far to document it for other Eskimo
    groups. Kayak-angst is scarcely mentioned in English written accounts, with the
    exception of brief references in Freuchen, Birket-Smith and a few others. On the
    other hand there is a considerable body of material in the Scandinavian languages,
    much of it gathered by Danish physicians. The condition was reported as early
    as 1806 and in 1949 Dr. Av M Ch. Ehrstrom diagnosed 24 cases in one of the northern
    districts. Kenneth I. Taylor, a student of anthropology with considerable kayak
    experience informs me (private communication) that as recently as 1959 he met
    three such individuals in Northwest Greenland. In 1900, Meldorf estimated that
    10% of all men in the Julianhaab district over the age of 18 suffered from kayak-angst.
    Others have regarded it as the 'national disease' of the West Greenland Eskimo.</p><p>Material
    for the present paper is based on an analysis of 13 cases out of the 60 kayak-angst
    individuals medically examined and interviewed by Bertelsen in 1905.</p><p><em>Kayak-Angst
    Syndrome</em></p><p>Typically, kayak-angst afflict male hunters out alone on a
    calm, 'mirroring' slightly wavy sea or lake, close to or at a distance from shore,
    either while paddling or sitting quietly. Under these conditions of sea, and especially
    with the sun directly overhead or in his eyes, there develops a lowering in the
    level of consciousness brought on by the absence of external reference points
    at a time when the hunter is involved in a visually 'fixed' or staring position
    demanding minimal or repetitive movements. A lesser number report they are equally
    affected in storms, windy or rough weather. Some claim not to have attacks when
    in the company of others and consequently will never hunt alone. A few report
    attacks when others are around, though claim they are less severe at this time.
    On the other hand some report that the presence of others increases their anxiety.
    One man was afraid their kayaks might collide, particularly in storms. Another
    said he felt at ease only in the company of men he trusted.</p>
- - /docs/lithium/2014-mauer.pdf
  - ! 'Standard and trace-dose lithium: A systematic review of dementia prevention
    and other behavioral benefits'
  - Sivan Mauer, Derick Vergne, S. Nassir Ghaemi
  - 2014-06-11
  - 10.1177/0004867414536932
  - ! '<p><em>Objective</em>: Dementia is a major public health issue, with notably
    high rates in persons with mood illnesses. Lithium has been shown to have considerable
    neuroprotective effects, even in trace or low doses. The aim of this review is
    to summarize the current understanding of lithium benefits in trace or low doses
    in dementia prevention and for other behavioral or medical benefits.</p><p><em>Methods</em>:
    A systematic review identified 24 clinical, epidemiological, and biological reports
    that met inclusion criteria of assessing lithium in standard or low doses for
    dementia or other behavioral or medical benefits.</p><p><em>Results</em>: 5 out
    of 7 epidemiological studies found an association between standard-dose lithium
    and low dementia rates. 9 out of 11 epidemiological studies, usually of drinking
    water sources, found an association between trace-dose lithium and low suicide/homicide/mortality
    and crime rates. All four small randomized clinical trials of lithium for Alzheimer''s
    dementia have found at least some clinical or biological benefits versus placebo.
    Only one small randomized clinical trial (<span class="smallcaps-auto">RCT</span>) of trace lithium has been conducted,
    assessing mood symptoms in former substance abusers, and found benefit with lithium
    versus placebo.</p><p><em>Conclusions</em>: Lithium, in both standard and trace
    doses, appears to have biological benefits for dementia, suicide, and other behavioral
    outcomes. Further <span class="smallcaps-auto">RCT</span> research of trace lithium in dementia is warranted. [Keywords:
    Cognition, dementia, lithium, prevention, standard dose, trace]</p>'
- - /docs/eva/2008-gardner.pdf
  - Aum Shinrikyo and a Panic About Manga and Anime
  - Richard A. Gardner
  - '2008'
  - 10.4324/9781315703152-16
  - <p>In the midst of the accolades, it is important to recall that there have been
    moments in recent history when manga and anime have been regarded as potentially
    dangerous or as emblems of what is wrong with Japan.</p><p>Such was the case in
    the months following the release of sarin gas in several Tokyo subway lines by
    members of the religious group Aum Shinrikyo on the morning of March 20, 1995.
    As the extent of the Aum's crimes gradually became clear, Japanese journalists,
    scholars, intellectuals, and commentators of every sort attempted to explain the
    origin and rise of Aum, the reasons for the group's turn to violence, and what
    the appearance of such a group might mean about Japan. In the various theories
    and explanations presented, nearly every aspect of Japanese society, culture,
    and religion has been held to be at least partially accountable for the rise of
    Aum and the turn to violence by some of its members (see Gardner 1999, 221–222;
    2002a, 36–42). In the efforts to explain Aum, considerable attention was given
    to the roles that manga and anime might have played. This resulted in what might
    be described as a panic about their possible negative influence on Japanese culture
    and society. Rather than attempting to explain precisely how manga and anime might
    have contributed to the rise of Aum and its vision of 'Harumagedon', or Armageddon,
    this chapter will simply present an overview of the ways in which both members
    of Aum and commentators on Aum understood the role of manga and anime in relation
    to Aum. Attention will be given, in particular, to how these perceptions were
    linked with broader concerns about the possible negative influence of various
    forms of media, technology, and 'virtual reality'.</p>
- - /docs/statistics/bias/2013-ioannidis.pdf
  - What's to know about the credibility of empirical economics?
  - John Ioannidis, Chris Doucouliagos
  - '2013'
  - 10.1111/joes.12032
  - ! 'The scientific credibility of economics is itself a scientific question that
    can be addressed with both theoretical speculations and empirical data. In this
    review, we examine the major parameters that are expected to affect the credibility
    of empirical economics: sample size, magnitude of pursued effects, number and
    pre-selection of tested relationships, flexibility and lack of standardization
    in designs, definitions, outcomes and analyses, financial and other interests
    and prejudices, and the multiplicity and fragmentation of efforts. We summarize
    and discuss the empirical evidence on the lack of a robust reproducibility culture
    in economics and business research, the prevalence of potential publication and
    other selective reporting biases, and other failures and biases in the market
    of scientific information. Overall, the credibility of the economics literature
    is likely to be modest or even low. [Keywords: Bias; Credibility; Economics; Meta-research;
    Replication; Reproducibility]'
- - /docs/iq/smpy/2013-kell.pdf
  - ! 'Who Rises to the Top?: Early Indicators'
  - Harrison J. Kell, David Lubinski, Camilla P. Benbow
  - 2013-03-26
  - 10.1177/0956797612457784
  - ! 'Youth identified before age 13 (<em>n</em> = 320) as having profound mathematical
    or verbal reasoning abilities (top 1 in 10,000) were tracked for nearly three
    decades. Their awards and creative accomplishments by age 38, in combination with
    specific details about their occupational responsibilities, illuminate the magnitude
    of their contribution and professional stature. Many have been entrusted with
    obligations and resources for making critical decisions about individual and organizational
    well-being. Their leadership positions in business, health care, law, the professoriate,
    and <span class="smallcaps-auto">STEM</span> (science, technology, engineering, and mathematics) suggest that many
    are outstanding creators of modern culture, constituting a precious human-capital
    resource. Identifying truly profound human potential, and forecasting differential
    development within such populations, requires assessing multiple cognitive abilities
    and using atypical measurement procedures. This study illustrates how ultimate
    criteria may be aggregated and longitudinally sequenced to validate such measures.
    [Keywords: cognitive abilities, creativity, human capital, intelligence, profoundly
    gifted, <span class="smallcaps-auto">STEM</span>]'
- - /docs/psychology/1955-abramson.pdf
  - ! 'Lysergic Acid Diethylamide (LSD-25): Xv. the Effects Produced By Substitution
    of a Tap Water Placebo'
  - H. A. Abramson, M. E. Jarvik, A. Levine, M. R. Kaufman, M. W. Hirsch
  - '1955'
  - 10.1080/00223980.1955.9712991
  - ! '<p>The purpose of this paper is to study the responses given to a questionnaire
    by subjects who received a tap water ''placebo'' instead of lysergic acid diethylamide
    (<span class="smallcaps-auto">LSD</span>-25), and to relate the number of responses to other variables. These variables
    are: body weight, number of responses on a health questionnaire, arithmetic test
    scores, scores on the Wechsler-Bellevue Intelligence Scale, and Rorschach test
    responses.</p><p>…Figure 4 shows for each question the percentage and number
    of subjects out of 28 who gave a positive response at least once during the 0.5,
    2.5, and 4.5-hour intervals. The questions appear in the figure in the order of
    decreasing percentages of response to them. The time of the response and the magnitude
    are disregarded in this tabulation. The question receiving the greatest percentage
    response was (Subject 24), "Are your palms moist?" As many as 60.7 per cent reported
    this symptom. Half of the subjects reported headache (Subject 13), fatigue (Subject
    44), and drowsiness (Subject 45). About 36 per cent reported anxiety (Subject
    47). Illness (Subject 1), and dizziness (Subject 15) were reported by 28.6 per
    cent of the group and 25 per cent indicated a dream-like feeling (Subject 46),
    increased appetite (Subject 6), unsteadiness (Subject 16), a hot feeling (Subject
    22), heaviness of hands and feet (Subject 30), and weakness (Subject 43). There
    were 19 questions which received positive responses from between 10 and 22 per
    cent of the subjects. Less than 10 per cent of the group (or no more than two
    subjects) responded positively to the remaining questions, but each question received
    a positive response from at least one subject.</p><p>…The findings point out
    that a substance such as tap water, which is generally considered chemically and
    pharmacologically inactive, is capable of eliciting certain responses from certain
    subjects who believe they have received lysergic acid diethylamide. These observations
    emphasize once more the need for placebo controls in studies investigating the
    effects of drugs; without them changes which are produced merely by the situation
    and not by the drug are frequently falsely attributed to the action of the drug…Most
    subjects who respond to a placebo tend to do so most markedly during the first
    0.5 hour after receiving the substance. At this time their anticipation of, and
    anxiety about, the effects of <span class="smallcaps-auto">LSD</span>-25 are probably greatest. Gradually the effects
    wear off, as the anticipation wears off. Individual differences exist in the time
    of peak effect, but this is the most common finding. The questions which elicited
    the greatest percentage response from the group were those related to anxiety
    (moist palms and feeling anxious) or to phenomena which commonly occur without
    the presence of any foreign agent (drowsiness, fatigue, and headache). The remaining
    questions received random responses. The fact that there is a wide range in the
    number of positive responses made to the questionnaire is of major interest.</p>'
- - /docs/statistics/bias/2008-scherer.pdf
  - Full publication of results initially presented in abstracts
  - Roberta W. Scherer, Patricia Langenberg, Erik von Elm
  - '2007'
  - 10.1002/14651858.MR000005.pub3
  - ! '<p><b>Studies initially reported as conference abstracts that have positive
    results are subsequently published as full-length journal articles more often
    than studies with negative results.</b></p><p>Less than half of all studies, and
    about 60% of randomized or controlled clinical trials, initially presented as
    summaries or abstracts at professional meetings are subsequently published as
    peer-reviewed journal articles. An important factor appearing to influence whether
    a study described in an abstract is published in full is the presence of ''positive''
    results in the abstract. Thus, the efforts of persons trying to collect all of
    the evidence in a field may be stymied, first by the failure of investigators
    to take abstract study results to full publication, and second, by the tendency
    to take to full publication only those studies reporting ''significant'' results.
    The consequence of this is that systematic reviews will tend to over-estimate
    treatment effects.</p><p><em>Background</em>: Abstracts of presentations at scientific
    meetings are usually available only in conference proceedings. If subsequent full
    publication of abstract results is based on the magnitude or direction of study
    results, publication bias may result. Publication bias, in turn, creates problems
    for those conducting systematic reviews or relying on the published literature
    for evidence.</p><p><em>Objectives</em>: To determine the rate at which abstract
    results are subsequently published in full, and the time between meeting presentation
    and full publication.</p><p><em>Search methods</em>: We searched <span class="smallcaps-auto">MEDLINE</span>, <span class="smallcaps-auto">EMBASE</span>,
    The Cochrane Library, Science Citation Index, reference lists, and author files.
    Date of most recent search: June 2003. Selection criteria We included all reports
    that examined the subsequent full publication rate of biomedical results initially
    presented as abstracts or in summary form. Follow-up of abstracts had to be at
    least two years.</p><p><em>Data collection and analysis</em>: Two reviewers extracted
    data. We calculated the weighted mean full publication rate and time to full publication.
    Dichotomous variables were analyzed using relative risk and random effects models.
    We assessed time to publication using Kaplan-Meier survival analyses.</p><p><em>Main
    results</em>: Combining data from 79 reports (29,729 abstracts) resulted in a
    weighted mean full publication rate of 44.5% (95% confidence interval (CI) 43.9
    to 45.1). Survival analyses resulted in an estimated publication rate at 9 years
    of 52.6% for all studies, 63.1% for randomized or controlled clinical trials,
    and 49.3% for other types of study designs.</p><p>''Positive'' results defined
    as any ''significant'' result showed an association with full publication (RR
    = 1.30; CI 1.14 to 1.47), as did ''positive'' results defined as a result favoring
    the experimental treatment (RR =1.17; CI 1.02 to 1.35), and ''positive'' results
    emanating from randomized or controlled clinical trials (RR = 1.18, CI 1.07 to
    1.30).</p><p>Other factors associated with full publication include oral presentation
    (RR = 1.28; CI 1.09 to 1.49); acceptance for meeting presentation (RR = 1.78;
    CI 1.50 to 2.12); randomized trial study design (RR = 1.24; CI 1.14 to 1.36);
    and basic research (RR = 0.79; CI 0.70 to 0.89). Higher quality of abstracts describing
    randomized or controlled clinical trials was also associated with full publication
    (RR = 1.30, CI 1.00 to 1.71).</p><p><em>Authors'' conclusions</em>: Only 63% of
    results from abstracts describing randomized or controlled clinical trials are
    published in full. ''Positive'' results were more frequently published than not
    ''positive'' results.</p>'
- - /docs/melatonin/2013-preckel.pdf
  - ! 'Morningness-eveningness and educational outcomes: the lark has an advantage
    over the owl at high school'
  - Franzis Preckel, Anastasiya A. Lipnevich, Katharina Boehme, Lena Brandner, Karsten
    Georgi, Tanja Könen, Katharina Mursin, Richard D. Roberts
  - 2012-01-02
  - 10.1111/j.2044-8279.2011.02059.x
  - ! '<p><em>Background</em>: Chronotype refers to individuals'' preference for morning
    or evening activities. Its two dimensions (morningness and eveningness) are related
    to a number of academic outcomes.</p><p><em>Aims</em>: The main goal of the study
    was to investigate the incremental validity of chronotype as a predictor of academic
    achievement after controlling for a number of traditional predictors. In so doing,
    a further aim was ongoing validation of a chronotype questionnaire, the Lark-Owl
    Chronotype Indicator.</p><p><em>Sample</em>: The sample comprised 272 students
    attending 9<sup>th</sup> and 10<sup>th</sup> grades at five German high schools. Data was also obtained
    from 132 parents of these students.</p><p><em>Method</em>: Students were assessed
    in class via self-report questionnaires and a standardized cognitive test. Parents
    filled out a questionnaire at home. The incremental validity of chronotype was
    investigated using hierarchical linear regression. Validity of the chronotype
    questionnaire was assessed by correlating student ratings of their chronotype
    with behavioural data on sleep, food intake, and drug consumption and with parent
    ratings of chronotype.</p><p><em>Results</em>: Eveningness was a significant (negative)
    predictor of overall grade point average (<span class="smallcaps-auto">GPA</span>), math-science <span class="smallcaps-auto">GPA</span>, and language
    <span class="smallcaps-auto">GPA</span>, after cognitive ability, conscientiousness, need for cognition, achievement
    motivation, and gender were held constant. Validity evidence for the chronotype
    measure was established by significant correlations with parent-ratings and behavioural
    data.</p><p><em>Conclusions</em>: Results point to the possible discrimination
    of adolescents with a proclivity towards eveningness at school. Possible explanations
    for the relationship between chronotype and academic achievement are presented.
    Implications for educational practice are also discussed.</p>'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959137/
  - The Unilateralist's Curse and the Case for a Principle of Conformity
  - Nick Bostrom, Thomas Douglas, Anders Sandberg
  - 2016-01-26
  - 10.1080/02691728.2015.1108373
  - ! 'In some situations a number of agents each have the ability to undertake an
    initiative that would have significant effects on the others. Suppose that each
    of these agents is purely motivated by an altruistic concern for the common good.
    We show that if each agent acts on her own personal judgment as to whether the
    initiative should be undertaken, then the initiative will be undertaken more often
    than is optimal. We suggest that this phenomenon, which we call the unilateralist''s
    curse, arises in many contexts, including some that are important for public policy.
    To lift the curse, we propose a principle of conformity, which would discourage
    unilateralist action. We consider three different models for how this principle
    could be implemented, and respond to an objection that could be raised against
    it. [Keywords: The Winner''s Curse, Disagreement, Rationality, Aumann, informative
    prior, shrinkage, bid shading]'
- - /docs/psychology/2014-vyssoki.pdf
  - Direct Effect of Sunshine on Suicide
  - Benjamin Vyssoki, Nestor D. Kapusta, Nicole Praschak-Rieder, Georg Dorffner, Matthaeus
    Willeit
  - 2014:09:10
  - 10.1001/jamapsychiatry.2014.1198
  - ! '<p><em>Importance</em>: It has been observed that suicidal behavior is influenced
    by sunshine and follows a seasonal pattern. However, seasons bring about changes
    in several other meteorological factors and a seasonal rhythm in social behavior
    may also contribute to fluctuations in suicide rates.</p><p><em>Objective</em>:
    To investigate the effects of sunshine on suicide incidence that are independent
    of seasonal variation.</p><p><em>Design, Setting, and Participants</em>: Retrospective
    analysis of data on all officially confirmed suicides in Austria between January
    1, 1970, and May 6, 2010 (<em>n</em> = 69 462). Data on the average duration of
    sunshine per day (in hours) were calculated from 86 representative meteorological
    stations. Daily number of suicides and daily duration of sunshine were differentiated
    to remove variation in sunshine and variation in suicide incidence introduced
    by season. Thereafter, several models based on Pearson correlation coefficients
    were calculated.</p><p><em>Main Outcomes and Measures</em>: Correlation of daily
    number of suicides and daily duration of sunshine after mathematically removing
    the effects of season.</p><p><em>Results</em>: Sunshine hours and number of suicides
    on every day from January 1, 1970, to May 6, 2010, were highly correlated (<em>r</em> = 0.4870;
    <em>p</em> &lt; 10<sup>−9</sup>). After differencing for the effects of season,
    a mathematical procedure that removes most of the variance from the data, a positive
    correlation between number of suicides and hours of daily sunshine remained for
    the day of suicide and up to 10 days prior to suicide (<em>r<sub>maximum</sub></em> = 0.0370;
    <em>p</em> &lt; 10<sup>−5</sup>). There was a negative correlation between the
    number of suicides and daily hours of sunshine for the 14 to 60 days prior to
    the suicide event (<em>r<sub>minimum</sub></em> = −0.0383; <em>p</em> &lt; 10<sup>−5</sup>).
    These effects were found in the entire sample and in violent suicides.</p><p><em>Conclusions
    and Relevance</em>: Duration of daily sunshine was significantly correlated with
    suicide frequency independent of season, but effect sizes were low. Our data support
    the hypothesis that sunshine on the day of suicide and up to 10 days prior to
    suicide may facilitate suicide. More daily sunshine 14 to 60 days previously is
    associated with low rates of suicide. Our study also suggests that sunshine during
    this period may protect against suicide.</p>'
- - /docs/nootropics/2015-hall.pdf
  - ! 'Genetics and the placebo effect: the placebome'
  - Kathryn T. Hall, Joseph Loscalzo, Ted J. Kaptchuk
  - 2015-05-01
  - 10.1016/j.molmed.2015.02.009
  - <ul><li>Predisposition to respond to placebo treatment may be in part a stable
    heritable trait.</li><li>Candidate placebo response pathways may interact with
    drugs to modify outcomes in both the placebo and drug treatment arms of clinical
    trials.</li><li>Genomic analysis of randomized placebo and no-treatment controlled
    trials are needed to fully realize the potential of the placebome.</li></ul><p>Placebos
    are indispensable controls in randomized clinical trials (<span class="smallcaps-auto">RCT</span>s), and placebo responses
    significantly contribute to routine clinical outcomes. Recent neurophysiological
    studies reveal neurotransmitter pathways that mediate placebo effects. Evidence
    that genetic variations in these pathways can modify placebo effects raises the
    possibility of using genetic screening to identify placebo responders and thereby
    increase <span class="smallcaps-auto">RCT</span> efficacy and improve therapeutic care. Furthermore, the possibility
    of interaction between placebo and drug molecular pathways warrants consideration
    in <span class="smallcaps-auto">RCT</span> design. The study of genomic effects on placebo response, 'the placebome',
    is in its infancy. Here, we review evidence from placebo studies and <span class="smallcaps-auto">RCT</span>s to identify
    putative genes in the placebome, examine evidence for placebo-drug interactions,
    and discuss implications for <span class="smallcaps-auto">RCT</span>s and clinical care.</p>
- - /docs/radiance/1995-mackenzie.pdf
  - Tacit Knowledge, Weapons Design, and the Uninvention of Nuclear Weapons
  - Donald MacKenzie, Graham Spinardi
  - '1995'
  - 10.1086/230699
  - ! '''Tacit Knowledge'', embodied in people rather than words, equations, or diagrams,
    plays a vital role in science. The historical record of the development and spread
    of nuclear weapons and the recollections of their designers suggest that tacit
    knowledge is also crucial to nuclear weapons development. Therefore, if design
    ceases, and if there is no new generation of designers to whom that tacit knowledge
    can be passed, then in an important (though qualified) sense nuclear weapons will
    have been uninvented. Their renewed development would thus have some of the characteristics
    of reinvention rather than simply copying. In addition, knowledge may be lost
    not only as a result of complete disarmament, but also as a consequence of likely
    measures such as a nuclear test ban.'
- - /docs/genetics/2015-rottensteiner.pdf
  - Physical activity, fitness, glucose homeostasis, and brain morphology in twins
  - Mirva Rottensteiner, Tuija Leskinen, Eini Niskanen, Sari Aaltonen, Sara Mutikainen,
    Jan Wikgren, Kauko Heikkilä, Vuokko Kovanen, Heikki Kainulainen, Jaakko Kaprio,
    Ina Tarkka, Urho Kujala
  - '2015'
  - 10.1249/MSS.0000000000000437
  - ! '<p><em>Purpose</em>: The main aim of the present study (<span class="smallcaps-auto">FITFATTWIN</span>) was to
    investigate how physical activity level is associated with body composition, glucose
    homeostasis, and brain morphology in young adult male monozygotic twin pairs discordant
    for physical activity.</p><p><em>Methods</em>: From a population-based twin cohort,
    we systematically selected 10 young adult male monozygotic twin pairs (age range,
    32–36 yr) discordant for leisure time physical activity during the past 3 yr.
    On the basis of interviews, we calculated a mean sum index for leisure time and
    commuting activity during the past 3 yr (3-yr <span class="smallcaps-auto">LTMET</span> index expressed as <span class="smallcaps-auto">MET</span>-hours
    per day). We conducted extensive measurements on body composition (including fat
    percentage measured by dual-energy x-ray absorptiometry), glucose homeostasis
    including homeostatic model assessment index and insulin sensitivity index (Matsuda
    index, calculated from glucose and insulin values from an oral glucose tolerance
    test), and whole brain magnetic resonance imaging for regional volumetric analyses.</p><p><em>Results</em>:
    According to pairwise analysis, the active twins had lower body fat percentage
    (<em>p</em> = 0.029) and homeostatic model assessment index (<em>p</em> = 0.031)
    and higher Matsuda index (<em>p</em> = 0.021) compared with their inactive co-twins.
    Striatal and prefrontal cortex (subgyral and inferior frontal gyrus) brain gray
    matter volumes were larger in the nondominant hemisphere in active twins compared
    with those in inactive co-twins, with a statistical threshold of <em>p</em> &lt;
    0.001.</p><p><em>Conclusions</em>: Among healthy adult male twins in their mid-30s,
    a greater level of physical activity is associated with improved glucose homeostasis
    and modulation of striatum and prefrontal cortex gray matter volume, independent
    of genetic background. The findings may contribute to later reduced risk of type
    2 diabetes and mobility limitations.</p>'
- - /docs/statistics/causality/2017-allamee.pdf
  - ! 'Percutaneous coronary intervention in stable angina (ORBITA): a double-blind,
    randomised controlled trial'
  - Rasha Al-Lamee, David Thompson, Hakim-Moulay Dehbi, Sayan Sen, Kare Tang, John
    Davies, Thomas Keeble, Michael Mielewczik, Raffi Kaprielian, Iqbal S Malik, Sukhjinder
    S Nijjer, Ricardo Petraco, Christopher Cook, Yousif Ahmad, James Howard, Christopher
    Baker, Andrew Sharp, Robert Gerber, Suneel Talwar, Ravi Assomull, Jamil Mayet,
    Roland Wensel, David Collier, Matthew Shun-Shin, Simon A Thom, Justin E Davies,
    Darrel P Francis
  - 2017-11-02
  - 10.1016/S0140-6736(17)32714-9
  - ! '<p><em>Summary: Background Symptomatic relief is the primary goal of percutaneous
    coronary intervention (<span class="smallcaps-auto">PCI</span>) in stable angina and is commonly observed clinically.
    However, there is no evidence from blinded, placebo-controlled randomised trials
    to show its efficacy.</p><p><em>Methods>/em>: <span class="smallcaps-auto">ORBITA</span> is a blinded, multicentre
    randomised trial of <span class="smallcaps-auto">PCI</span> versus a placebo procedure for angina relief that was
    done at five study sites in the UK. We enrolled patients with severe (≥70%) single-vessel
    stenoses. After enrolment, patients received 6 weeks of medication optimisation.
    Patients then had pre-randomisation assessments with cardiopulmonary exercise
    testing, symptom questionnaires, and dobutamine stress echocardiography. Patients
    were randomised 1:1 to undergo <span class="smallcaps-auto">PCI</span> or a placebo procedure by use of an automated
    online randomisation tool. After 6 weeks of follow-up, the assessments done before
    randomisation were repeated at the final assessment. The primary endpoint was
    difference in exercise time increment between groups. All analyses were based
    on the intention-to-treat principle and the study population contained all participants
    who underwent randomisation. This study is registered with ClinicalTrials.gov,
    number <span class="smallcaps-auto">NCT</span>02062593.</p><p><em>Findings</em>: <span class="smallcaps-auto">ORBITA</span> enrolled 230 patients with
    ischaemic symptoms. After the medication optimisation phase and between Jan 6,
    2014, and Aug 11, 2017, 200 patients underwent randomisation, with 105 patients
    assigned <span class="smallcaps-auto">PCI</span> and 95 assigned the placebo procedure. Lesions had mean area stenosis
    of 84.4% (SD 10.2), fractional flow reserve of 0.69 (0.16), and instantaneous
    wave-free ratio of 0.76 (0.22). There was no significant difference in the primary
    endpoint of exercise time increment between groups (<span class="smallcaps-auto">PCI</span> minus placebo 16.6 s,
    95% CI -8.9 to 42.0, <em>p</em>=0.200). There were no deaths. Serious adverse
    events included four pressure-wire related complications in the placebo group,
    which required <span class="smallcaps-auto">PCI</span>, and five major bleeding events, including two in the <span class="smallcaps-auto">PCI</span> group
    and three in the placebo group.</p><p><em>Interpretation</em>: In patients with
    medically treated angina and severe coronary stenosis, <span class="smallcaps-auto">PCI</span> did not increase exercise
    time by more than the effect of a placebo procedure. The efficacy of invasive
    procedures can be assessed with a placebo control, as is standard for pharmacotherapy.</p>'
- - https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc
  - ! 'Open<span class="smallcaps-auto">GPT</span>-2: We Replicated <span class="smallcaps-auto">GPT</span>-2-1.5b Because You Can Too'
  - Aaron Gokaslan, Vanya Cohen
  - 2019-08-22
  - ''
  - <p>Recently, large language models like <span class="smallcaps-auto">BERT</span>¹, <span class="smallcaps-auto">XLN</span>et², <span class="smallcaps-auto">GPT</span>-2³, and Grover⁴ have
    demonstrated impressive results generating new content and multiple tasks. Since
    Open-AI has not released their largest model [<span class="smallcaps-auto">GPT</span>-2-1.5b] at this time, we seek
    to replicate the model to allow others to build on our pretrained model and further
    improve it. You can access the model and generate text using our Google Colab.</p><p>…We
    demonstrate that many of the results of the paper can be replicated by two masters
    students…Because our replication efforts are not unique, and large language
    models are the current most effective means of countering generated text, we believe
    releasing our model is a reasonable first step towards countering the potential
    future abuse of these kinds of models.</p><p>We base our implementation off of
    the Grover model⁴ and modify their codebase to match the language modeling training
    objective of <span class="smallcaps-auto">GPT</span>-2. Since their model was trained on a similarly large corpus,
    much of the code and hyperparameters proved readily reusable. We did not substantially
    change the hyperparameters from Grover.</p><p>From start to finish, we estimate
    that we use under $500,000 in cloud compute for all of our experiments including
    searching for hyper-parameters and testing various cleaning methods on our datasets.
    The cost of training the model from scratch using our code is about $50,000.</p><p>…Despite
    the differences in our training distribution, we do report similar perplexities
    over most datasets.</p>
- - https://scholars-stage.blogspot.com/2014/09/what-edward-luttwak-doesnt-know-about.html
  - What Edward Luttwak Doesn't Know About Ancient China (Or a Short History of Han-Xiongnu
    Relations), pt. 1
  - Tanner Greer
  - 2014-10-04
  - ''
  - ! 'A few weeks ago a friend passed along one of the least correct essays I have
    ever had the misfortune to read. It was written by Edward Luttwak…In it Luttwak
    suggests contemporary Chinese foreign policy follows a pattern first seen in the
    foreign relations of the Han Dynasty two millennia ago:<br><blockquote>Formidable
    mounted archers and capable of sustained campaigning (a primary objective of the
    Steppe State), the Xiongnú ravaged and savaged and extorted tribute from the perpetually
    less martial, and certainly cavalry-poor Han until the latter finally felt able
    to resist again. Even then, 147 years of intermittent warfare ensued until Huhanye
    (呼韓邪), the paramount Chanyu (Qagan, Khan) of the Xiongnú, personally and formally
    submitted to the emperor Han Xuandi in 51 <span class="smallcaps-auto">BCE</span>, undertaking to pay homage, to leave
    a son at court as a hostage, and to deliver tribute, as befitted a vassal. That
    was a very great downfall from the familial status of earlier Chanyus of the epoch
    of Xiongnú predominance, who were themselves recognized as emperors, whose sons
    and heirs could have imperial daughters in marriage, and who from 200 <span class="smallcaps-auto">BCE</span> had
    received tribute from the Han, instead of the other way around. It is this successful
    transformation of a once superior power first into an equal (signified by imperial
    marriages) and then into a subservient client-state that seems to have left an
    indelible residue in China''s tradition of statecraft.</blockquote><br>..if Edward
    Luttwak wants to talk about how the echoes of the Han-Xiongnu war can be heard
    in modern China''s foreign policy, I am all ears.  Long term readers of The Stage
    know that there are few conversation starters I would find more thrilling to hear.
    Too many contemporary controversies cannot be understood until we step back and
    look at world affairs from the long view of history. But there is a catch in all
    this: <em>the history has to be correct</em>. It must accord to the facts. If
    one uses the past to interpret the present then your reading must be based on
    events that <em>actually</em> happened. This cannot be said for Mr. Luttwak''s
    essay. The story he tells simply did not happen.<br>Luttwak''s descriptions of
    the <em>heqin</em> policy''s aim is basically correct. It was designed to corrupt
    the Xiongnu and slowly ''Sinicize'' them. It was designed, through the power of
    Confucian family norms, to subordinate the Xiongnu ruler to Han Emperor.<br>What
    Luttwak neglects to mention is that the policy was a complete and utter failure.'
- - https://scholars-stage.blogspot.com/2014/09/what-edward-luttwak-doesnt-know-about_6.html
  - What Edward Luttwak Doesn't Know About Ancient China (Or a Short History of Han-Xiongnu
    Relations), pt. 2
  - Tanner Greer
  - 2014-10-06
  - ''
  - If the 'peace marriage' (<em>heqin</em>) system Luttwak describes did not do the
    Xiongnu in, what did?<br>…The logistics machine the Han created to defeat the
    Xiongnu is one of the marvels of the ancient world [3]. Each of the Han's campaigns
    was a feat worthy of Alexander the Great. But Alexander only pushed to India once.
    The Han launched these campaigns year after year for <em>decades</em> [4]. The
    sheer expanse of the conflict is staggering; Han armies ranged from Fergana to
    Manchuria, theaters 3,000 miles apart. Each campaign required the mobilization
    of tens of thousands of men and double the number of animals. Chang Chun-shu has
    tallied the numbers:<br><blockquote>"In the many campaigns in the Western regions
    (Hexi, Qiang, and Xiyu) and the Xiongnu land, the Han sent a total force of over
    1.2 million cavalrymen, 800,000 foot soldiers, and 10.5 million men in support
    and logistic roles. The total area of lad seized in Hexi alone was 426,700 square
    kilometers. In developing this region the Han spent 100 billion in cash per year,
    compared to the regular annual government revenue of 12 billion. In the process
    the Han government moved from the interior over 1 million people to populate and
    develop the Hexi river. Thus the Han conquest of the land west of the Yellow River
    was the greatest expansion in Chinese history." [5]</blockquote><br>The demands
    of the war forced the Han to restructure not only the Chinese state, but all of
    Chinese society. [6] The Han's willingness to radically restructure their society
    to meet the immense financial and logistic demands of an eighty year conflict
    is one of the central reasons they emerged victorious from it.<br>…The Han followed
    the same basic strategy. The aim of generals like Wei Qing and Huo Qubing was
    to kill every single man, woman and child they came across and by doing so instill
    such terror in their enemies that tribes would surrender <em>en masse</em> upon
    their arrival. By trapping the Xiongnu into one bloody slug match after another
    the Han forced them into a grinding war of attrition that favored the side with
    the larger population reserves. The Xiongnu were unprepared for such carnage in
    their own lands; within the first decade of the conflict the Han's sudden attacks
    forced the Xiongnu to retreat from their homeland in the Ordos to the steppes
    of northern Mongolia. Then came a sustained—and successful—effort to apply the
    same sort of pressure on the Xiongnu's allies and vassals in Turkestan and Fergana.
    By sacking oasis towns and massacring tribes to the east, the Han were able to
    terrorize the peoples of Turkestan into switching their allegiance to China or
    declare their independence from the Xiongnu.<br>The Xiongnu were left isolated
    north of the Orkhorn. Under constant military pressure and cut off from the goods
    they had always extorted from agrarian peoples in China and Turkestan, the Xiongnu
    political elite began to fracture. A series of succession crises and weak leaders
    ensued; by 58 BC the Xiongnu's domain had fallen into open civil war. It was one
    of the aspiring claimants to the title of Chanyu that this conflict produced who
    traveled to Chang'an, accepted the Han's suzerainty, and ended eighty years of
    war between the Han and the Xiongnu [8].<br>How did the Chinese transform an enemy
    whose realm stretched thousands of miles across Inner Asia into a mere tributary
    vassal? They did it through <em>flame and blood and terror</em>. Any narrative
    of Han-Xiongnu relations that passes over these eighty years of grueling warfare
    is a distorted depiction of the times.
- - https://scholars-stage.blogspot.com/2014/03/smallpox-on-steppe.html
  - Smallpox on the Steppe
  - Tanner Greer
  - 2014-03-08
  - ''
  - ! '<blockquote>…The Manchus, before the founding of the Qing, also rarely encountered
    smallpox, but they knew of its danger. Mongols and Manchus who had not been exposed
    to the disease were exempted from coming to Beijing to receive titles of succession.
    The main response of the Mongols and Manchus to those who did fall ill was quarantine.
    Li Xinheng commented that if anyone in a tribe caught smallpox, his relatives
    abandoned him in a cave or distant grassland. <b>70 to 80 percent of those infected
    died.</b> The German traveler Peter Simon Pallas, who visited the Mongols three
    times front 1768 to I771, commented that smallpox was the only disease they greatly
    feared. It occurred very seldom, but spread rapidly when it struck: "If someone
    catches it, they abandon him in his tent; they only approach front the windward
    side to provide food. Children who catch it are sold to the Russians very cheaply."
    The Mongols whom Pallas visited lived far from the Chinese border, but they knew
    well that smallpox was highly contagious and nearly fatal.<br>The Chinese discovery
    of variolation—a method of inoculation—was of great aid in reducing the severity
    of attacks. The Kangxi emperor himself was selected as heir in part because he
    had survived the disease in childhood; his father had died of it. <b>In 1687 he
    inaugurated regular inoculation of the royal family, and his successor extended
    mandatory inoculation to all Manchu children. The Manchus adopted this Chinese
    medical practice in order to protect themselves against the virulent strains that
    were absent from the steppe. Only Manchus who had survived the disease were allowed
    to be sent to the Mongolian steppe.</b> Mongols close to the Manchu and Chinese
    border gradually grew immune, but those farther away suffered great losses in
    the nineteenth century when Chinese penetration increased. [1]</blockquote><br>…
    For several millennia historians have tried to explain the generally superior
    strength and endurance of steppe warriors, often focusing on the demands of life
    in the saddle or the nomads'' protein-rich diets as the explanation for their
    vitality. A more powerful explanation may be the absence of the debilitating and
    deadly diseases of settled life among the peoples of the steppe.'
- - https://scholars-stage.blogspot.com/2014/04/meditations-on-maoism-ye-fus-hard-road.html
  - Meditations on Maoism—Ye Fu's <em>Hard Road Home</em>
  - Tanner Greer
  - 2014-04-14
  - ''
  - ! '<p>Americans-and particularly American conservatives-are sometimes accused
    of failing to confront their country''s past honestly.  Ye Fu''s challenge—and
    in many respects all of China''s—was not honestly facing his past, but simply
    <em>finding</em> it. Ye Fu was born the great grandson of a ranking Nationalist
    commander, the grand son of a landlord, and the son of two parents who zealously
    joined the revolution only to be discarded by later ''struggles of the Proletariat''.
    Ye Fu was only dimly aware of this heritage growing up. It was not until his father''s
    funeral, when he first stepped foot on his ancestral lands, that he had either
    the chance or a reason to find the truth of his family''s past. This became a
    quest that drove and consumed him and is a recurring motif that unites his most
    poignant essays.</p><p>…Thus the true details of his father''s life and heritage
    were revealed: a grandfather who had climbed from the peasantdom of his birth
    to the hallowed class of landlord only a few years before the revolution overtook
    the village (he earned the title by being the only one in the village rich enough
    to employ a single field hand); a son who zealously hunted down landlords for
    the Party, unaware that his own family 50 miles to the east suffered the same
    persecution he so earnestly delivered; the suicide of his father and the destruction
    of the clan''s eldest generation in its entirety, both brothers and wives, within
    a single night.</p><p>"Hundreds of millions of lives were shoveled into the trenches
    of the 20<sup>th</sup> century", Ye Fu reflects. [4] Historians estimate that the death toll
    of these land reform campaigns is in the range of two to three million. [5] But
    for Ye Fu those ditches are not those of the nameless millions. These were ditches
    dug by his father and filled by his grandfather. The tragedies of the 20<sup>th</sup> century
    are <em>his</em> tragedies. He was born from the ditches—though he would not discover
    this gruesome truth until he was a grown man.</p><p>He who reads Ye Fu''s meditations
    on these mournful roots leaves with the strong—but unexpected—impression that
    the true tragedy of modern Chinese history is not found in its colossal death
    toll. For Ye Fu the real tragedy is what all these dead represented. The first
    to die were those most committed to the old order. They were the upholders of
    traditional propriety, keepers of the ancestral shrine, and symbols of basic human
    decency. These men and women often lived far below their ideals, profiting from
    a system rightly seen as exploitative, but as long they lived so did the ideal.
    Their deaths meant the destruction of their entire society. With them passed old
    structures of power and control, but also the old values and traditions these
    social arrangements had embodied and enshrined. The life defined by decorum, trust,
    filial piety, and kindness lost its place as the ideal of Chinese civilization,
    replaced by a new model that honored cruelty, deception, and revolutionary ardor.</p>'
- - https://scholars-stage.blogspot.com/2019/01/reflections-on-chinas-stalinist.html
  - ! 'Reflections on China''s Stalinist Heritage I: A Tyrant''s Toolkit'
  - Tanner Greer
  - 2019-01-17
  - ''
  - ! '<p>One of the extraordinary things about reading Mao''s speeches from this
    period is the fluidity of who was considered an ally and who was considered an
    enemy. Mao framed his campaigns as a struggle between "the people" and "the enemy,"
    but who fit into each group differed drastically based off of the Party''s perceptions
    of who was a credible threat to The Cause and who was not. As Mao put it:</p><p><blockquote>To
    understand these two different types of contradictions correctly, we must first
    be clear on what is meant by "the people" and what is meant by "the enemy". The
    concept of "the people" varies in content in different countries and in different
    periods of history in a given country. Take our own country for example. During
    the War of Resistance Against Japan, all those classes, strata and social groups
    opposing Japanese aggression came within the category of the people, while the
    Japanese imperialists, their Chinese collaborators and the pro-Japanese elements
    were all enemies of the people. During the War of Liberation, the U.S. imperialists
    and their running dogs—the bureaucrat-capitalists, the landlords and the Kuomintang
    reactionaries who represented these two classes—were the enemies of the people,
    while the other classes, strata and social groups, which opposed them, all came
    within the category of the people. At the present stage, the period of building
    socialism, the classes, strata and social groups which favour, support and work
    for the cause of socialist construction all come within the category of the people,
    while the social forces and groups which resist the socialist revolution and are
    hostile to or sabotage socialist construction are all enemies of the people.[5]</blockquote></p><p>Thus
    a particular group could at one point be an honored part of "the people," at another
    point an ally in a "united front," and later a despised "enemy" of the regime.
    How the regime treated you depended very much on how threatening Party leaders
    believed you might be to the regime and its cause.</p><p>Today The Cause has flipped—officially—from
    socialist revolution to national rejuvenation. The Party works under the same
    schema but has shifted the "people" that Mao identified with specific economic
    classes to the nation at large.[6] Mass mobilization campaigns have been retired.
    <b>But struggle and united front campaigns have not.</b> Xi''s great corruption
    purge, the Uighur labor camps of Xinjiang, the attack on Christians across China—these
    all follow the same methods for crushing and coercing "enemies" developed by Mao
    and the Party in the early ''40s. "One Country, Two Systems," interference campaigns
    in the Chinese diaspora, the guided, gilded tours given to Musk and his ilk—these
    all follow the same methods for corrupting and controlling "allies" developed
    by Mao and the Party that same decade. <b>The tools have never changed.</b> The
    only thing that has changed is the Party''s assessment of who is an "enemy" and
    who is part of the "people."</p><p>There is one threat, however, that the Communist
    legacy has poorly prepared the Party to face. Stalin and Mao conceived of their
    projects in cultural terms—they were not just attempting to stamp out dangerous
    people, but dangerous <em>ideas</em>. To that end both Stalin and Mao cut their
    countries off from the world they had no control over. If your end goal is socialist
    revolution this might be tenable. But if your end goal is national rejuvenation—that
    is, a future where China sits at the top of a global order, more wealthy and powerful
    than any other—then engagement with the outside world must be had. It means foreigners
    coming to China in great numbers, and Chinese going abroad in numbers no smaller.
    It means a much more accurate conception of the way the rest of the world works
    among the minds of the Chinese people. It means contemplating paths for China
    that do not involve being ruled by a dictatorial party-state.</p><p>This tension
    lies at the root of the Party''s problems with the West. Countries like America
    threaten the Party with their mere existence. Consider what these countries do:
    they allow dissidents from authoritarian powers shelter. Their societies spawn
    (even when official government policy is neutral on the question) movement after
    movement devoted to spreading Western ideals and ideas to other lands and peoples.
    They are living proof that a country does not need a one-party state to become
    powerful and wealthy. These things pose a threat to the Communist Party of China.
    The Party itself is the first to admit it. [7]</p>'
- - https://scholars-stage.blogspot.com/2019/03/reflections-on-chinas-stalinist.html
  - ! 'Reflections on China''s Stalinist Heritage II: Just How Totalitarian is Modern
    China?'
  - Tanner Greer
  - 2019-03-07
  - ''
  - ! '<p>Under the Khmer Rouge, making love was an explicitly <em>political</em>
    act. Marriage was a <em>political</em> decision. Refusing to sleep with your husband
    was an act of <em>political</em> rebellion. <strong><em>The first claim of the
    totalitarian is that everything is political.</em></strong></p><p>In my view,
    a totalitarian system must meet two minimum requirements:</p><ol type="1"><li>In
    this system all human action is considered political action.</li><li>The system
    is ruled by a Party which claims commanding authority to direct all political
    action—and thus all human action—for its cause.</li></ol><p>The great tragedies
    of 20<sup>th</sup> century history occurred as the totalitarian leaders attempted to translate
    their <em>claim</em> of authority over all human action into actual control over
    the same.</p><p>This view of totalitarian society crystallized in my mind some
    years ago, when I first read Liang Heng''s memoir of his youthful escapades as
    a Red Guard in the Cultural Revolution. A professor had asked me to review it.
    In that brief review I noted:</p><blockquote><p>In Mao''s China the personal was
    always political. And not just the personal—<em>everything</em> anyone did was
    political. Maoism was a political ideology that asked its members to give everything
    they were, had, and did to the socialist cause. This intellectual framework implies
    that everything one does should be layered with political meaning. A child''s
    prank, a lover''s kiss, and a friend''s embrace were all political acts. The clothes
    one wore, the way one walked, the letters one wrote, and the words one spoke all
    had political valence. It was with this in mind Liang Shan warned: "Never give
    your opinion on anything, even if you''re asked directly" (76).</p><p>Such caution
    is inevitable in a world where there is no distinction between the personal and
    the political. Politics is the division of power, politicking the contest for
    it. In a system where the most intimate and private actions have political meaning,
    these actions will be used by those who seek power. These naked contests for control
    leave no room for good and evil—good becomes what those with power declare it.
    "One day you are red, one day you are black, and one day you are red again" (76),
    Liang Shan instructed, and he was correct. This struggle stretched from factions
    warring within the walls of Zhongnanhai to the village black class child currying
    for favor.</p><p>The problem is not competition: that is an ingrained aspect of
    human life. The special tragedy of the Maoist system was that it spared nothing
    from the pursuit of power. There was no aspect of life that could be cordoned
    off as a refuge from the storm. [2]</p>'
- - https://scholars-stage.blogspot.com/2017/07/everything-is-worse-in-china.html
  - Everything is Worse in China
  - Tanner Greer
  - 2017-07-19
  - ''
  - ! '<p>Here I will just share one of my strongest reactions to the book—a thought
    that occurred again and again as I drifted through its pages. Esolen presents
    a swarm of maladies sickening American society, ranging from a generation of children
    suffocated by helicopter parenting to a massive state bureaucracy openly hostile
    too virtuous living. My reaction to each of his carefully drawn portraits was
    the same: this problem is even worse in China.</p><p>Are you worried about political
    correctness gone awry, weaponized by mediocrities to defame the worthy, suffocating
    truth, holding honest inquiry hostage through fear and terror? <em>That problem
    is worse in China.</em></p><p>Do you lament the loss of beauty in public life?
    Its loss as a cherished ideal of not just art and oratory but in the building
    of homes, chapels, bridges, and buildings? Its disappearance in the comings-and-goings
    of everyday life? <em>That problem is worse in China.</em>Do you detest a rich,
    secluded, and self-satisfied cultural elite that despises, distrusts, and derides
    the uneducated and unwashed masses not lucky enough to live in one of their chosen  urban
    hubs? <em>That problem is worse in China.</em> Are you sickened by crass materialism?
    Wealth chased, gained, and wasted for nothing more than vain display? Are you
    oppressed by the sight of children denied the joys of childhood, guided from one
    carefully structured resume-builder to the next by parents eternally hovering
    over their shoulders? Do you dread a hulking, bureaucratized leviathan, unaccountable
    to the people it serves, and so captured by special interests that even political
    leaders cannot control it? Are you worried by a despotic national government that
    plays king-maker in the economic sphere and crushes all opposition to its social
    programs into the dust? Do you fear a culture actively hostile to the free exercise
    of religion? Hostility that not only permeates through every layer of society,
    but is backed by the awesome power of the state?</p><p><em>These too are all worse
    in China.</em></p><p>…All of this should lighten the tone of gloom and doom
    that pervades the traditionalist critique of modern America. The reference point
    of these writers is the American (or less usually, the European) past. Look instead
    at the present! It could be so much worse for those of our ilk. In some countries,
    it is.</p>'
- - https://scholars-stage.blogspot.com/2019/05/the-utterly-dysfunctional-belt-and-road.html
  - The Utterly Dysfunctional Belt and Road
  - Tanner Greer
  - 2019-05-08
  - ''
  - ! '<p>The always excellent Stella Zhang directed me to a newish paper by political
    scientists Lee Jones and Zeng Jinhan on the domestic politics of China''s Belt
    and Road. Long term readers will remember that I am bearish on Xi''s grand dream.
    Here is how I described the central problems with the scheme for <em>Foreign Policy</em>:</p><blockquote><p>There
    is also a gap between how <span class="smallcaps-auto">BRI</span> projects are supposed to be chosen and how they
    actually have been selected. Xi and other party leaders have characterized <span class="smallcaps-auto">BRI</span>
    investment in Eurasia as following along defined "economic corridors" that would
    directly connect China to markets and peoples in other parts of the continent.
    By these means the party hopes to channel capital into areas where it will have
    the largest long-term benefit and will make cumulative infrastructure improvements
    possible.</p><p>This has not happened: one analysis of 173 <span class="smallcaps-auto">BRI</span> projects concluded
    that with the exception of the China-Pakistan Economic Corridor (<span class="smallcaps-auto">CPEC</span>) "there
    appears to be no significant relationship between corridor participation and project
    activity… [suggesting that] interest groups within and outside China are skewing
    President Xi''s signature foreign policy vision."</p><p>This skew is an inevitable
    result of China''s internal political system. <span class="smallcaps-auto">BRI</span> projects are not centrally directed.
    Instead, lower state bodies like provincial and regional governments have been
    tasked with developing their own <span class="smallcaps-auto">BRI</span> projects. The officials in charge of these
    projects have no incentive to approve financially sound investments: by the time
    any given project materializes, they will have been transferred elsewhere. <span class="smallcaps-auto">BRI</span>
    projects are shaped first and foremost by the political incentives their planners
    face in China: There is no better way to signal one''s loyalty to Xi than by laboring
    for his favored foreign-policy initiative. From this perspective, the most important
    criteria for a project is how easily the <span class="smallcaps-auto">BRI</span> label can be slapped on to it…</p><p>The
    problems China has had with the <span class="smallcaps-auto">BRI</span> stem from contradictions inherent in the ends
    party leaders envision for the initiative and the means they have supplied to
    reach them. <span class="smallcaps-auto">BRI</span> projects are chosen through a decentralized project-management
    system and then funded through concessional loans offered primarily by <span class="smallcaps-auto">PRC</span> policy
    banks. This is a recipe for cost escalation and corruption. In countries like
    Cambodia, a one-party state ruled by autocrats, this state of affairs is viable,
    for there is little chance that leaders will be held accountable for lining their
    pockets (or, more rarely, the coffers of their local communities) at the entire
    nation''s expense. But most <span class="smallcaps-auto">BRI</span> countries are not Cambodia. In democracies this
    way of doing things is simply not sustainable, and in most <span class="smallcaps-auto">BRI</span> countries it is
    only so long before an angry opposition eager to pin their opponents with malfeasance
    comes to power, armed with the evidence of misplaced or exploitative projects.
    [1]</p></blockquote><p>The key points to take away from my account is that the
    failures of the <span class="smallcaps-auto">BRI</span> seem to factor back to a few central points: first, that project
    selection is mostly driven by the priorities of folks working in <span class="smallcaps-auto">SOE</span>s, provincial
    governments, and a plethora of different policy banks. The central government
    in Beijing has difficulty directing their efforts. Secondly, that these people
    do not have a good understanding of the countries in which they are investing,
    and face little incentive to gain this understanding. This leads to the sort of
    corruption and ''predatory'' funding that has given <span class="smallcaps-auto">BRI</span> its poisonous reputation
    in countries long exposed to it.</p><p>Jones and Zeng agree with this general
    picture, but provide a far more detailed account of what is happening ''behind
    the scenes'' when <span class="smallcaps-auto">BRI</span> projects are chosen and funded. The process they describe
    is not unique to the Belt and Road. It starts as Communist high leadership paints
    bold words in the sky:</p><blockquote><p>Foreign-policy steering happens through
    several important mechanisms. The first is top leaders'' major speeches, which
    are usually kept vague to accommodate diverse interests and agendas. Rather than
    ''carefully-worked out grand strategies'', they are typically ''platitudes, slogans,
    catchphrases, and generalities'', offering ''atmospheric guidance'' that others
    must then interpret and implement. Examples include: Deng''s <em>tao guang yang
    hui</em>, whose meaning is ''debatable''; Hu''s ''harmonious world''—''more of
    a narrative than a grand strategy''; and Xi''s ''new type of great power relations.''
    As discussed below, Xi''s vague 2013 remarks on the ''silk road economic belt''
    (<span class="smallcaps-auto">SREB</span>) and ''maritime silk road'' (<span class="smallcaps-auto">MSR</span>) exemplify this tendency. [2]</p></blockquote><p>But
    bold words are not policy. The Party often has difficulty transforming grand visions
    into detailed policy proposals. This is sometimes quite intentional—in a closed
    system like the People''s Republic, it may be better to have politicos arguing
    over <em>how</em> to make the Core''s vision possible, instead of whether the
    Core''s vision is worth making possible in the first place.</p>'
- - https://scholars-stage.blogspot.com/2019/04/the-inner-life-of-chinese-teenagers.html
  - The Inner Life of Chinese Teenagers
  - Tanner Greer
  - 2019-04-19
  - ''
  - ! '<p>The second point probably deserves more space than I was able to give in
    the <em>LA Review of Books</em>. Consider, for a moment, the typical schedule
    of a Beijing teenager:</p><p>She will (depending on the length of her morning
    commute) wake up somewhere between 5:30 and 7:00 AM. She must be in her seat by
    7:45, 15 minutes before classes start. With bathroom breaks and gym class excepted,
    she will not leave that room until the 12:00 lunch hour and will return to the
    same spot after lunch is ended for another four hours of instruction. Depending
    on whether she has after-school tests that day, she will be released from her
    classroom sometime between 4:10 and 4:40. She then has one hour to get a start
    on her homework, eat, and travel to the evening cram school her parents have enrolled
    her in. Math, English, Classical Chinese—there are cram schools for every topic
    on the <em>gaokao</em>. On most days of the week she will be there studying from
    6:00 to 9:00 PM (if the family has the money, she will spend another six hours
    at these after-school schools on Saturday and Sunday mornings). Our teenager will
    probably arrive home somewhere around 10:00 PM, giving her just enough time to
    spend two or three hours on that day''s homework before she goes to bed. Rinse
    and repeat, day in and day out, for six years. The strain does not abate until
    she has defeated—or has been defeated by—the <em>gaokao</em>.</p><p>This is well
    known, but I think the wrong aspects of this experience are emphasized. Most outsiders
    look at this and think: see how much pressure these Chinese kids are under. I
    look and think: <em>how little privacy and independence these Chinese kids are
    given!</em></p><p>To put this another way: Teenage demands for personal space
    are hardly unique to China. What makes China distinctive is the difficulty its
    teenagers have securing this goal. Chinese family life is hemmed in narrow bounds.
    The urban apartments that even well-off Chinese call their homes are tiny and
    crowded. Few have more than two bedrooms. Teenagers are often forced to share
    their bedroom with a grandparent. So small was the apartment of one 16-year-old
    I interviewed that she slept, without apparent complaint, in the same bed as her
    parents for her entire first year of high school. Where can a teenager like her
    go, what door could she slam, when she was angry with her family? Within the walls
    of her home there was no escape from the parental gaze.</p><p>A Chinese teen has
    few better options outside her home. No middle-class Chinese teenager has a job.
    None have cars. The few that have boyfriends or girlfriends go about it as discreetly
    as possible. Apart from the odd music lesson here or there, what Americans call
    "extra-curricular activities" are unknown. One a recent graduate of a prestigious
    international high school in Beijing once explained to me the confusion she felt
    when she was told she would need to excel at an after-school activity to be competitive
    in American university admissions:</p><p>"In tenth grade our home room teacher
    told us that American universities cared a lot about the things we do outside
    of school, so from now on we would need to find time to ''cultivate a hobby.''
    I remember right after he left the girl sitting at my right turned to me and whispered,
    ''I don''t know how to cultivate a hobby. Do you?''"</p>'
- - https://scholars-stage.blogspot.com/2013/02/ominous-parallels-what-antebellum.html
  - ! 'Ominous Parallels: What Antebellum America Can Teach Us About Our Modern Political
    Regime'
  - Tanner Greer
  - 2013-02-26
  - ''
  - ! '<p>Many people point to the hyper-partisanship of national Democratic and Republican
    parties as the greatest challenge facing 21<sup>st</sup> century America. When seen through
    the lens of another vapidly partisan political system—that of Jacksonian America—we
    see that the real danger is not noisy partisanship, but the iniquity it hides:
    for them it was slavery; for us, plutarchy.</p><p>…As in the antebellum, today''s
    hyperpartisanship has its uses. The issues are real enough, and the cultural divide
    between each party''s demographic "base" is wide.  Politicians take advantage
    of this with over-the-top rhetoric, turning all issues into a cultural crusade
    against the radicalism of the progressive left or the bigotry of entrenched conservatism.
    The accuracy of these attacks is unimportant. The antebellum party system allowed
    Southerners to define themselves as ''Whigs'' or ''Democrats'' instead of ''slavers''.
    The current system serves its purpose just as well, allowing plutocrats to define
    themselves not in terms of power or privilege, but as part of a culturally cohesive
    group that represents ''real'' America. With partisan issues taking the fore,
    politicians, lobbyists, and corporate big wigs  can plunder the American economy
    and strip American citizens of their liberties in a decidedly bipartisan fashion.
    [9] And thus the greatest structural fault-line in America''s body-politic and
    the most dangerous challenge to the integrity of her republican institutions and
    the liberties of her citizenry continues onward without public comment. And all
    of this without a gag rule.</p><p>If the comparison of the antebellum Republic''s
    political regime with its ailing modern descendent seems a bit chilling—well,
    it <em>is</em>. The last time America''s sins broke through the partisan politics
    designed to hide them the result was the most destructive war of her history.
    It is an ominous precedent.</p>'
- - https://scholars-stage.blogspot.com/2015/09/shakespeare-in-american-politics.html
  - Shakespeare in American Politics
  - Tanner Greer
  - 2015-09-30
  - ''
  - <p>…A good place to start is with the Webster-Hayne debate of 1830. Of all American
    oratory, only the Lincoln-Douglass debates can claim greater fame than the debate
    Daniel Webster and Robert Hayne held on the antebellum Senate floor. At that time
    there was a resolution before the Senate calling for all new federal land surveys
    to be postponed until all of the existing land already surveyed was sold. This
    struck the ire of the westerners, who pushed for federal land to be given to new
    settlers without charge or delay…These allusions to Shakespeare only occupy
    a normal portion of the two men's debate—no more than a few paragraphs out of
    ninety or so pages of text. Nevertheless, the use of <em>Macbeth</em>'s script
    in the debate is telling. Neither Webster nor Hayne thought it was a waste of
    their time to debate the finer points of Shakespeare's plays in the halls of the
    Senate. The reader senses that Webster, in particular, did so in a positively
    gleeful fashion.</p><p>What has happened here? How have we gone from long discussions
    of Shakespearean drama on the senate floor to the shallow repetition of disembodied
    sentence fragments? The answers to this question tell us much about the American
    body politic:</p><p>1. <em>The decline of public speaking as a vital part of American
    culture</em>. Oratory is something of a lost art in modern America. It is hard
    to imagine just how vital it was to public life for most of America's history.
    In Webster's day public speaking was a central part of entertainment, education,
    civic life, and religious practice. He was elected in the midst of the 2<sup>nd</sup> Great
    Awakening, when American religious life was dominated by camp meetings and church
    members were expected to preach and testify one to another. It was a time when
    every township had a lyceum at its center, and intellectual life was dominated
    by those who traveled the lyceum circuit. Collections of speeches like <em>The
    Columbian Orator</em> were the most common type of schoolbook in the antebellum
    era, while most American men actively participated in town assemblies and party
    caucuses. The mastery of proper political rhetoric was an essential social skill.</p><p>Add
    all this together and you are left with a population that found immense pleasure
    in listening to, reenacting, and reading the speeches of others. It was a prized
    art, and when masters like Webster or Lincoln displayed their talents, people
    flocked together to listen to them. There was thus a great deal of patience for
    the sort of rhetorical flourish inherit in the long discussions of Shakespeare
    seen above. Today's Americans will not sit still and listen to a political speech
    for longer than ten minutes. The medium through which politicians communicate
    to the masses really doesn't let them. Radio shows and news channels rely on the
    soundbite. If a politician's message cannot be squeezed into a seven second slot
    it will not be heard.</p>
- - https://scholars-stage.blogspot.com/2015/10/awareness-vs-action-two-modes-of.html
  - ! 'Awareness vs. Action: Two Modes of Protest in American History'
  - Tanner Greer
  - 2015-10-07
  - ''
  - ! '<p>…Daniel Walker Howe devotes several pages to the origins of the [Temperance]
    movement in his excellent book <em>What God Hath Wrought: The Transformation of
    America, 1814–1848</em>. It is worth quoting from them at length:</p><p><blockquote>Americans
    in the early nineteenth century quaffed alcohol in prodigious quantities. In 1825,
    the average American over fifteen years of age consumed seven gallons of alcohol
    a year, mostly in the form of whiskey and hard cider. (The corresponding figure
    at the start of the twenty-first century was less than two gallons, most of it
    from beer and wine.) Workers typically took a midmorning break and a mid-afternoon
    break, both accompanied by alcohol, as well as liquor with every meal. To entertain
    guests meant to ply them with several kinds of alcohol until some fell down. All
    social classes drank heavily; college students, journeyman printers, agricultural
    laborers, and canal-diggers were especially notorious. Schoolchildren might face
    an inebriated teacher in the classroom. Although socially tolerated, drunkenness
    frequently generated violence, especially domestic violence, and other illegal
    behavior. In such a society, intemperance represented a serious issue of public
    health, comparable to the problems of drug abuse experienced in later generations.<br>Making
    temperance a Christian cause constituted an innovation, for traditional Christianity
    had not discouraged drinking. Indeed, Beecher recalled, ministerial conferences
    during his youth had been occasions for heavy convivial drinking. Unlike a later
    generation of crusaders, Beecher never thought the legal prohibition of alcohol
    a practical solution; he relied purely on changing public attitudes. This was
    no mean feat. To take stand against the strong social pressures to drink took
    real courage, especially for young men. To help them, temperance workers paid
    reformed alcoholics to go on speaking tours, published temperance tracts, put
    on temperance plays, and drove the "water wagon" through towns encouraging converts
    to jump on. Publicists and organizers like Beecher struck a nerve with the public.
    The temperance cause resonated among people in all walks of life, rural and urban,
    white and black. Although it began in the Northeast, temperance reached the South
    and West and exerted powerful and lasting influence there. At first the temperance
    advocates restricted themselves to encouraging moderation (hence the name "temperance");
    in this phase they condemned only distilled liquors, not beer and wine. At the
    grassroots level, however, it became apparent that total abstinence made a more
    effective appeal. Beecher endorsed this shift in <em>Six Sermons on Intemperance</em>
    (1825). Those who signed a temperance pledge were encouraged to put a <em>T</em>
    after their names if willing to take the extra step of pledging total abstinence;
    from this derives our word "teetotaler."<br>The campaign to alter age old habits
    and attitudes proved amazingly successful: consumption of alcohol, especially
    of hard liquor, declined steadily and dramatically after 1830, falling to 1.8
    gallons per person over fifteen by the late 1840s. [2]</blockquote></p><p>A few
    things to note about this account: temperance societies were organized and worked
    at the level of towns, congregations, families, and individuals, not entire states
    or nations. The information they passed along was not intended to make people
    <em>aware</em> of the danger of drinking, but to inspire or scare them into <em>acting</em>
    on this knowledge. They created communities who could help individuals who were
    struggling to do this. They were most successful when they secured <em>individual
    commitments to action</em>. It was also incredibly successful. This became the
    standard template for American civic associations until the late 19<sup>th</sup> century.</p>'
- - https://scholars-stage.blogspot.com/2019/06/passages-i-highlighted-in-my-copy-of.html
  - ! 'Passages I Highlighted in My Copy of <em>Only Yesterday: An Informal History
    of the 1920s</em>'
  - Tanner Greer
  - 2019-06-24
  - ''
  - ! '<p>Last week''s post, "If You Were to Write a History of 21<sup>st</sup> Century America,
    What Would It Look Like?", asked what a 21<sup>st</sup> century version of Frederick Lewis
    Allen''s <em>Only Yesterday: An Informal History of the 1920s</em> might look
    like. Here is how I described the book in that post:</p><p><blockquote>There are
    many things to love about this book. Allen wrote his history of the 1920''s in
    a jaunty, breezy style. When you pick his book up it is hard to put it down. Allen''s
    tone is fair, his judgements sharp, and prose delectably entertaining. The most
    notable thing about this history of the 1920s, however, is its publication date:
    Allen wrote the book in 1930. He saw it published in 1931.</p><p>I often wish
    Allen had more imitators. Allen''s book shines as a social history. The genius
    of writing such a history directly after the events took place is that the historian
    can narrate not just what happened in a period, but what it felt like to live
    through it. Names have not receded into history; the little things of daily existence
    are still remembered, and often still in use. Judgements of past events have not
    been too clouded by the downstream effects they had three or four decades down
    the line. There is an immediacy to <em>Only Yesterday</em> that I have never found
    in any other work of history (though I have found it in several works of fiction).</blockquote></p><p>While
    Allen gives due coverage to economic and political affairs (the League of Nations
    debates, the Teapot Dome scandal, and the crash of ''29 each get their own chapter
    length narrations), the majority of Allen''s book is what we would today call
    "social history." Allen spends about equal time describing the fads for crossword
    puzzles and mahjong (yes, you read that last one right) as he does the entire
    administration of Calvin Coolidge…</p>'
- - https://scholars-stage.blogspot.com/2019/04/on-quests-for-transcendence.html
  - Questing for Transcendence
  - Tanner Greer
  - 2019-04-29
  - ''
  - ! '<p>Will Wilkinson explored one possibility in an essay he wrote a few years
    ago on American country music. Wilkinson begins with the observation that American
    conservatives (i.e., the consumers of country music) tend to be low on "openness"
    in the Big-5 personality scale. Folks who rate high on openness are the sort attracted
    to novelty: world travels, new drugs, and so forth. Country music, he suggests,
    captures the emotional lives of a different group of people:</p><blockquote><p>Emotional
    highlights of the low-openness life are going to be the type celebrated in "One
    Boy, One Girl": the moment of falling in love with "the one," the wedding day,
    the birth one''s children (though I guess the song is about a surprising ultrasound).
    More generally, country music comes again and again to the marvel of advancing
    through life''s stations, and finds delight in experiencing traditional familial
    and social relationships from both sides. Once I was a girl with a mother, now
    I''m a mother with a girl. My parents took care of me, and now I take care of
    them. I was once a teenage boy threatened by a girl''s gun-loving father, now
    I''m a gun-loving father threatening my girl''s teenage boy. Etc. And country
    is full of assurances that the pleasures of simple, rooted, small-town, lives
    of faith are deeper and more abiding than the alternatives.</p><p>My conjecture,
    then, is that country music functions in part to reinforce in low-openness individuals
    the idea that life''s most powerful, meaningful emotional experiences are precisely
    those to which conservative personalities living conventional lives are most likely
    to have access. And it functions as a device to coordinate members of conservative-minded
    communities on the incomparable emotional weight of traditional milestone experiences…</p><p>But
    why would you want your kids to grow up with the same way of life as you and your
    grandparents? My best guess (and let me stress guess) is that those low in openness
    depend emotionally on a sense of enchantment of the everyday and the profundity
    of ritual. Even a little change, like your kids playing with different toys than
    you did, comes as a small reminder of the instability of life over generations
    and the contingency of our emotional attachments. This is a reminder low-openness
    conservatives would prefer to avoid, if possible. What high-openness liberals
    feel as mere nostalgia, low-openness conservatives feel as the baseline emotional
    tone of a recognizably decent life. If your kids don''t experience the same meaningful
    things in the same way that you experienced them, then it may seem that their
    lives will be deprived of meaning, which would be tragic. And even if you''re
    able to see that your kids will find plenty of meaning, but in different things
    and in different ways, you might well worry about the possibility of ever really
    understanding and relating to them. The inability to bond over profound common
    experience would itself constitute a grave loss of meaning for both generations.
    So when the culture redefines a major life milestone, such as marriage, it trivializes
    one''s own milestone experience by imbuing it was a sense of contingency, threatens
    to deprive one''s children of the same experience, and thus threatens to make
    the generations strangers to one another. And what kind of monster would want
    that?</p><p>Country music is a bulwark against cultural change, a reminder that
    "what you see is what you get," a means of keeping the charge of enchantment in
    "the little things" that make up the texture of the every day, and a way of literally
    broadcasting the emotional and cultural centrality of the conventional big-ticket
    experiences that make a life a life.[3]</p></blockquote><p>…Yet there is one
    segment of society that seems to get it. In the years since my [Mormon missionary]
    service, I have been surprised to find that the one group of people who consistently
    understands my experience are soldiers…both many ex-missionaries (known as
    "RMs" or "Return Missionaries" in Mormon lingo) and many veterans have such trouble
    adapting to life when they return to their homes. This comparison occurred to
    me first several years ago, when I read a Facebook comment left by a man who had
    served as a Marine mechanic in Afghanistan…I did not save the comment at the
    time, but I remember it well enough to reproduce a paraphrase here:</p><blockquote><p>"I
    do not know if I want to live any more. I served in Afghanistan from [various
    dates of various deployments] and am now working as a salesman for [a prominent
    American company]. I despise this world I am in now—everything is so selfish and
    so self centered. In Afghanistan every single decision I made had a purpose; every
    single thing I did was for something bigger than myself. Everything I did, I did
    to save lives. Every deed helped accomplish our mission. Here in America no one
    does anything except for themselves. We work to earn a buck—what is the point
    to living like this? There is not a day that goes by that I don''t wish I was
    back in that hellhole. There what I did mattered. Here it is all meaningless."</p>'
- - https://scholars-stage.blogspot.com/2016/01/america-will-always-fail-at-regional.html
  - America Will Always Fail At Regional Expertise
  - Tanner Greer
  - 2016-01-
  - ''
  - <p>I have argued before that any potential American foreign policy or 'grand strategy'
    that requires  statesmen with a nuanced understanding of a foreign region's cultures,
    politics, and languages to implement it is doomed to fail. Regional acumen is
    a rare trait, and one I greatly admire. But it is rare for a reason. Regional
    acumen just does not scale—or at least, Americans do not know how to scale it.
    I have said this before. But it was reinforced tonight when I stumbled—quite by
    accident—across this old <em>New York Times Magazine</em> personal by Lydia Kiesling.
    In it she describes her experience learning Uzbek with a <span class="smallcaps-auto">FLAS</span> grant from the Department
    of Education.</p><p>…This article gets to the heart of why America will always
    lack the kind of language and area expertise needed to succeed in the kinds of
    things the American people (or American leaders) often demand the United States
    government do. Uzbek is an obscure language. But it is an obscure language at
    the center of the national security concerns that have bedeviled the United States
    over the last decade and a half. To give a brief picture:</p><ul><li>There are
    about three million Uzbeks who live in Afghanistan. Uzbeks were an essential part
    of the Northern Alliance's resistance against the Taliban, and Uzbek leaders became
    an important part of the government established by <span class="smallcaps-auto">NATO</span> forces once the Taliban
    was driven from power. This is still true. Afghanistan's current vice-president,
    Abdul Rashid Dostum, is an Uzbek.</li><li>Uzbekistan is the central hub of central
    Asia. One of the greatest defeats of our Afghan campaign happened not on the battlefield,
    but at the diplomats' table. Uzbekistan's decision to withdraw American basing
    and supply rights was nothing short of a disaster, forcing the United States to
    be even more dependent on Pakistan (our true enemy in the region) for logistic
    support.</li><li>Uzbek and Uighur are a hair's breadth away from mutually intelligible.
    Xinjiang's low intensity Uighur insurgency is the single greatest security concern
    of China, America's greatest rival.</li></ul><p>This is a language that <em>matters</em>.
    What happens to the woman who spent a year of her life studying it? She was rejected
    from the <span class="smallcaps-auto">CIA</span> (or wherever) on background technicalities, and has not used her
    language since. Or to be more precise, she has used it twice. Twice in four years.
    <em>Twice</em>.</p><p>This gets to the heart of America's problem with regional
    acumen. Area expertise simply doesn't pay. You may count the number of private
    sector jobs currently on the market that demand Uzbek fluency on two hands. And
    even if there <em>were</em> a multitude of jobs that required proficiency in Uzbek
    and English, there are undoubtedly several hundred—perhaps several thousand—Uzbekistanis
    who speak English better than Ms. Kiesling speaks Uzbek, and who will work for
    less pay to boot.</p>
- - https://scholars-stage.blogspot.com/2015/02/the-education-of-american-strategist.html
  - American Policy Makers Do Not Read Books
  - Tanner Greer
  - 2015-02-18
  - ''
  - <p>If the American strategist of 2015 has a deep base of historical, cultural,
    and scientific knowledge to draw on to guide the decisions he makes this is because
    he acquired this knowledge base <em>before</em> he was a senior policy maker.
    You can actually see hints of this in the survey data—Avey and Desch asked policy
    makers to list the living international relations scholars they thought had the
    greatest influence on actual policy making. Along with scholars-turned-officials
    (e.g. Henry Kissinger, Zbigniew Brzezinski, Anne-Marie Slaughter) and public intellectuals
    (e.g. Francis Fukuyama, Fareed Zakaria) were a list of men whose scholarly apogee
    was twenty to thirty years ago, back when our policy makers were undergrads! (Funnily
    enough many of these men—Samuel Huntington, Albert Wohlstetter, Hans Morgenthau—are
    not only past their scholarly prime, <em>but are no longer alive!</em>) Those
    who rose to prominence after 1995 barely register. [3]</p><p>One of the lessons
    we can draw from this is that the books and material we expect American students
    to read and master in the early stages of their life will have an outsized influence
    on the knowledge they will possess in their old age. Today's strategists survive
    off of what they learned when they were in school forty years ago. [4] Absent
    dramatic changes in the life style of government officials or unforeseen technological
    developments, <b>the policy-makers crafting strategy in 2040 will be working off
    of the knowledge base they are building from the books they are reading right
    now.</b></p>
- - https://scholars-stage.blogspot.com/2018/03/you-dont-have-people.html
  - You Do Not Have the People
  - Tanner Greer
  - 2018-03-
  - ''
  - ! '<p>These numbers are taken from a November <span class="smallcaps-auto">NBC</span> News/Gen Forward poll, a survey
    that questions 18–35 year olds across the nation on the political issues of the
    day. Respondents are asked to list what they believe are the three most important
    issues facing America. [3] There are a lot of interesting things one can say about
    this data, but for our purposes here I would focus your attention on the two rows
    labeled "foreign policy" and "military strength." There is one big thing you will
    notice about these two figures: they are minuscule. Respondents are largely satisfied
    with America''s place in the world. In their minds, police brutality, education,
    crime, taxes, racism, the economy, immigration, climate change, health care, gun
    control and the national budget are all more critical problems than anything involving
    foreign affairs.</p><p>Millennials do not stand in for all of America. Older generations
    care more for foreign policy than the Millennial and Generation Z cohorts do,
    though other polls suggest that their priorities also lie in the domestic sphere.
    But I focus in on this group for a reason: the opinions of this generation will
    have an outsized influence on our defense policies. In the case of war, these
    are the people who will actually be called to sacrifice their time and lives for
    the sake of American interests. Their willingness to suffer for the sake of the
    public interest sets the upper bounds for what is militarily possible in a time
    of conflict. Their attitude in peace will be even more important. Armament programs
    are decade long affairs. Proper sized navies are generation-length projects. Great
    power rivalries take decades to unfold. Who will be responsible for maintaining
    this effort? <em>These guys</em>. The millennial generation is already the largest
    cohort in this republic''s history (given current fertility rates there will likely
    be none larger). Were they not so politically desensitized, they would also already
    possess the power to decide most elections in the country. When the last of the
    boomers die out, by sheer power of numbers alone, these men and women will rule
    the roost. Their perception of America''s role in the world, and the threats she
    faces, will determine America''s future.</p><p>The take-away: more important than
    developing new weapon systems, devising new treaties, or crafting new strategies
    will be convincing the American people that they can and should bear the costs
    of doing any of that. Nothing is more important than winning the public opinion
    war. If we lose there, nothing else really matters.</p><p>… If we lived in an
    age when public trust in elites and the institutions they manned was stronger,
    many of the worries I voice could be dispensed with. That is simply not where
    we are at. Unfortunately, the Trump administration''s disregard for public opinion
    on the Korea issue is but an extreme expression of a tendency that blights the
    entire field. We are uncomfortable with democratic accountability, unwilling to
    subject ourselves to public debate, and uninterested in the constraints public
    opinion and popular politics place on the policies we craft. This complacency
    is not excusable. It is not sustainable. <em>We cannot defend the cause of freedom
    without the support of the people.</em> To try and do this is to risk terrible
    disaster.</p>'
- - https://scholars-stage.blogspot.com/2018/07/what-cyber-war-will-look-like.html
  - What Cyber-War Will Look Like
  - Tanner Greer
  - 2018-07-06
  - ''
  - ! '<p>In a report Cancian wrote for the Center for Strategic and International
    Studies on how great powers adapt to tactical and strategic surprise, Cancian
    sketched out twelve "vignettes" of potential technological or strategic shocks
    to make his abstract points a bit more concrete. Here is how Cancian imagines
    an "asymmetric cyber-attack" launched by the <span class="smallcaps-auto">PRC</span> against the United States Military:</p><blockquote><p>The
    U.S. secretary of defense had wondered this past week when the other shoe would
    drop. Finally, it had, though the U.S. military would be unable to respond effectively
    for a while.</p><p>The scope and detail of the attack, not to mention its sheer
    audacity, had earned the grudging respect of the secretary. Years of worry about
    a possible Chinese "Assassin''s Mace"—a silver bullet super-weapon capable of
    disabling key parts of the American military—turned out to be focused on the wrong
    thing.</p><p>The cyber attacks varied. Sailors stationed at the 7<sup>th</sup> Fleet''s homeport
    in Japan awoke one day to find their financial accounts, and those of their dependents,
    empty. Checking, savings, retirement funds: simply gone. The Marines based on
    Okinawa were under virtual siege by the populace, whose simmering resentment at
    their presence had boiled over after a YouTube video posted under the account
    of a Marine stationed there had gone viral. The video featured a dozen Marines
    drunkenly gang-raping two teenaged Okinawan girls. The video was vivid, the girls''
    cries heart-wrenching the cheers of Marines sickening And all of it fake. The
    National Security Agency''s initial analysis of the video had uncovered digital
    fingerprints showing that it was a computer-assisted lie, and could prove that
    the Marine''s account under which it had been posted was hacked. But the damage
    had been done.</p><p>There was the commanding officer of Edwards Air Force Base
    whose Internet browser history had been posted on the squadron''s Facebook page.
    His command turned on him as a pervert; his weak protestations that he had not
    visited most of the posted links could not counter his admission that he had,
    in fact, trafficked some of them. Lies mixed with the truth. Soldiers at Fort
    Sill were at each other''s throats thanks to a series of text messages that allegedly
    unearthed an adultery ring on base.</p><p>The variations elsewhere were endless.
    Marines suddenly owed hundreds of thousands of dollars on credit lines they had
    never opened; sailors received death threats on their Twitter feeds; spouses and
    female service members had private pictures of themselves plastered across the
    Internet; older service members received notifications about cancerous conditions
    discovered in their latest physical.</p><p>Leadership was not exempt. Under the
    hashtag <code>#PACOMMUSTGO</code> a dozen women allegedly described harassment
    by the commander of Pacific command. Editorial writers demanded that, under the
    administration''s "zero tolerance" policy, he step aside while Congress held hearings.</p><p>There
    was not an American service member or dependent whose life had not been digitally
    turned upside down. In response, the secretary had declared "an operational pause,"
    directing units to stand down until things were sorted out.</p><p>Then, China
    had made its move, flooding the South China Sea with its conventional forces,
    enforcing a sea and air identification zone there, and blockading Taiwan. But
    the secretary could only respond weakly with a few air patrols and diversions
    of ships already at sea. Word was coming in through back channels that the Taiwanese
    government, suddenly stripped of its most ardent defender, was already considering
    capitulation. [2]</p>'
- - https://mbio.asm.org/content/3/2/e00036-12
  - ! 'The Black Queen Hypothesis: Evolution of Dependencies through Adaptive Gene
    Loss'
  - J. Jeffrey Morris, Richard E. Lenski, Erik R. Zinser
  - 2012-03-23
  - 10.1128/mBio.00036-12
  - Reductive genomic evolution, driven by genetic drift, is common in endosymbiotic
    bacteria. Genome reduction is less common in free-living organisms, but it has
    occurred in the numerically dominant open-ocean bacterioplankton <em>Prochlorococcus</em>
    and “<em>Candidatus Pelagibacter</em>,” and in these cases the reduction appears
    to be driven by natural selection rather than drift. Gene loss in free-living
    organisms may leave them dependent on co-occurring microbes for lost metabolic
    functions. We present the Black Queen Hypothesis (<span class="smallcaps-auto">BQH</span>), a novel theory of reductive
    evolution that explains how selection leads to such dependencies; its name refers
    to the queen of spades in the game Hearts, where the usual strategy is to avoid
    taking this card. Gene loss can provide a selective advantage by conserving an
    organism’s limiting resources, provided the gene’s function is dispensable. Many
    vital genetic functions are leaky, thereby unavoidably producing public goods
    that are available to the entire community. Such leaky functions are thus dispensable
    for individuals, provided they are not lost entirely from the community. The <span class="smallcaps-auto">BQH</span>
    predicts that the loss of a costly, leaky function is selectively favored at the
    individual level and will proceed until the production of public goods is just
    sufficient to support the equilibrium community; at that point, the benefit of
    any further loss would be offset by the cost. Evolution in accordance with the
    <span class="smallcaps-auto">BQH</span> thus generates “beneficiaries” of reduced genomic content that are dependent
    on leaky “helpers,” and it may explain the observed nonuniversality of prototrophy,
    stress resistance, and other cellular functions in the microbial world.
- - https://papers.tinbergen.nl/19059.pdf
  - Cannabis Prices on the Dark Web
  - Jakub Cerveny, Jan C. van Ours
  - 2019-08-13
  - ''
  - This paper examines prices of cannabis sold over the anonymous internet marketplace
    AlphaBay. We analyze cannabis prices of 500 listings from about 140 sellers, originating
    from 18 countries. We find that both listing characteristics and country characteristics
    matter. Cannabis prices are lower if sold in larger quantities, so there is a
    clear quantity discount. Cannabis prices increase with perceived quality. Cannabis
    prices are also higher when the seller is from a country with a higher <span class="smallcaps-auto">GDP</span> per
    capita or higher electricity prices. The internet based cannabis market seems
    to be characterized by monopolistic competition where many sellers offer differentiated
    products with quality variation causing a dispersion of cannabis prices and sellers
    have some control over the cannabis prices.
- - /docs/modafinil/2019-kredlow.pdf
  - ! 'The Efficacy of Modafinil as a Cognitive Enhancer: A Systematic Review and
    Meta-Analysis'
  - M. Alexandra Kredlow, Ani Keshishian, Sarah Oppenheimer, Michael W. Otto
  - 2019-08-19
  - 10.1097/JCP.0000000000001085
  - ! '<p><strong>Background</strong>: Animal models and human studies have identified
    the potential of modafinil as a cognitive enhancing agent, independent of its
    effects on promoting wakefulness in sleep-deprived samples. Given that single-dose
    applications of other putative memory enhancers (eg, D-cycloserine, yohimbine,
    and methylene blue) have shown success in enhancing clinical outcomes for anxiety-related
    disorders, we conducted a meta-analytic review examining the potential for single-dose
    effects for modafinil on cognitive functioning in non–sleep-deprived adults.</p><p><strong>Methods</strong>:
    A total of 19 placebo-controlled trials that examined the effects of single-dose
    modafinil versus placebo on the cognitive domains of attention, executive functioning,
    memory, or processing speed were identified, allowing for the calculation of 67
    cognitive domain–specific effect sizes.</p><p><strong>Results</strong>: The overall
    positive effect of modafinil over placebo across all cognitive domains was small
    and significant (<em>g</em> = 0.10; 95% confidence interval, 0.05–0.15; <em>p</em>
    &lt; 0.001). No significant differences between cognitive domains were found.
    Likewise, no significant moderation was found for modafinil dose (100 mg vs 200
    mg) or for the populations studied (psychiatric vs nonpsychiatric).</p><p><strong>Conclusions</strong>:
    In conclusion, the available evidence indicates only limited potential for modafinil
    to act as a cognitive enhancer outside sleep-deprived populations.</p>'
- - https://www.nature.com/articles/s41467-019-11786-6
  - A critique of pure learning and what artificial neural networks can learn from
    animal brains
  - Anthony M. Zador
  - 2019-08-21
  - 10.1038/s41467-019-11786-6
  - ! '<p>Artificial neural networks (<span class="smallcaps-auto">ANN</span>s) have undergone a revolution, catalyzed
    by better supervised learning algorithms. However, in stark contrast to young
    animals (including humans), training such networks requires enormous numbers of
    labeled examples, leading to the belief that animals must rely instead mainly
    on unsupervised learning. Here we argue that most animal behavior is not the result
    of clever learning algorithms—supervised or unsupervised—but is encoded in the
    genome. Specifically, animals are born with highly structured brain connectivity,
    which enables them to learn very rapidly. Because the wiring diagram is far too
    complex to be specified explicitly in the genome, it must be compressed through
    a “genomic bottleneck”. The genomic bottleneck suggests a path toward <span class="smallcaps-auto">ANN</span>s capable
    of rapid learning.</p><p>…As the name implies, <span class="smallcaps-auto">ANN</span>s were invented in an attempt
    to build artificial systems based on computational principles used by the nervous
    system5. In what follows, we suggest that additional principles from neuroscience
    might accelerate the goal of achieving artificial mouse, and eventually human,
    intelligence. We argue that in contrast to <span class="smallcaps-auto">ANN</span>s, animals rely heavily on a combination
    of both learned and innate mechanisms. These innate processes arise through evolution,
    are encoded in the genome, and take the form of rules for wiring up the brain6.
    Specifically, we introduce the notion of the “genomic bottleneck”—the compression
    into the genome of whatever innate processes are captured by evolution—as a regularizing
    constraint on the rules for wiring up a brain. We discuss the implications of
    these observations for generating next-generation machine algorithms.</p><p>…In
    this view, supervised learning in <span class="smallcaps-auto">ANN</span>s should not be viewed as the analog of learning
    in animals. Instead, since most of the data that contribute an animal’s fitness
    are encoded by evolution into the genome, it would perhaps be just as accurate
    (or inaccurate) to rename it “supervised evolution.” Such a renaming would emphasize
    that “supervised learning” in <span class="smallcaps-auto">ANN</span>s is really recapitulating the extraction of
    statistical regularities that occurs in animals by both evolution and learning.
    In animals, there are two nested optimization processes: an outer “evolution”
    loop acting on a generational timescale, and an inner “learning” loop, which acts
    on the lifetime of a single individual. Supervised (artificial) evolution may
    be much faster than natural evolution, which succeeds only because it can benefit
    from the enormous amount of data represented by the life experiences of quadrillions
    of individuals over hundreds of millions of years.</p>'
- - https://nv-adlr.github.io/MegatronLM
  - ! 'MegatronLM: Training Billion+ Parameter Language Models Using <span class="smallcaps-auto">GPU</span> Model Parallelism'
  - <span class="smallcaps-auto">NVIDIA</span> <span class="smallcaps-auto">ADLR</span>
  - 2019-08-13
  - ''
  - Larger language models are dramatically more useful for <span class="smallcaps-auto">NLP</span> tasks such as article
    completion, question answering, and dialog systems. Training the largest neural
    language model has recently been the best way to advance the state of the art
    in <span class="smallcaps-auto">NLP</span> applications. Two recent papers, <a href="https://arxiv.org/abs/1810.04805"><span class="smallcaps-auto">BERT</span></a>
    and <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"><span class="smallcaps-auto">GPT</span>-2</a>,
    demonstrate the benefits of large scale language modeling. Both papers leverage
    advances in compute and available text corpora to significantly surpass state
    of the art performance in natural language understanding, modeling, and generation.
    Training these models requires hundreds of exaflops of compute and <a href="https://arxiv.org/abs/1604.06174">clever
    memory management</a> to trade recomputation for a reduced memory footprint. However,
    for very large models beyond a billion parameters, the memory on a single <span class="smallcaps-auto">GPU</span>
    is not enough to fit the model along with the parameters needed for training,
    requiring model parallelism to split the parameters across multiple <span class="smallcaps-auto">GPU</span>s. Several
    approaches to model parallelism exist, but they are difficult to use, either because
    they rely on custom compilers, or because they scale poorly or require changes
    to the optimizer.</p></div><div><p> In this work, we implement a simple and efficient
    model parallel approach by making only a few targeted modifications to existing
    <a href="https://openreview.net/pdf?id=BJJsrmfCZ">PyTorch</a> transformer implementations.
    <a href="https://github.com/nvidia/megatron-lm">Our code</a> is written in native
    Python, leverages mixed precision training, and utilizes the <a href="https://developer.nvidia.com/nccl"><span class="smallcaps-auto">NCCL</span>
    library</a> for communication between <span class="smallcaps-auto">GPU</span>s. We showcase this approach by training
    an 8.3 billion parameter transformer language model with 8-way model parallelism
    and 64-way data parallelism on 512 <span class="smallcaps-auto">GPU</span>s, making it the <b>largest transformer
    based language model ever trained at 24× the size of <span class="smallcaps-auto">BERT</span> and 5.6× the size of
    <span class="smallcaps-auto">GPT</span>-2</b>. We have published the code that implements this approach at <a href="https://github.com/NVIDIA/Megatron-LM">our
    GitHub repository</a>.</p></div><div><p> Our experiments are conducted on <span class="smallcaps-auto">NVIDIA</span>’s
    <a href="https://devblogs.nvidia.com/dgx-superpod-world-record-supercomputing-enterprise"><span class="smallcaps-auto">DGX</span>
    Super<span class="smallcaps-auto">POD</span></a>. Without model parallelism, we can fit a baseline model of 1.2B parameters
    on a single V100 32GB <span class="smallcaps-auto">GPU</span>, and sustain 39 Tera<span class="smallcaps-auto">FLOPS</span> during the overall training
    process, which is 30% of the theoretical peak <span class="smallcaps-auto">FLOPS</span> for a single <span class="smallcaps-auto">GPU</span> in a <span class="smallcaps-auto">DGX</span>2-H
    server. Scaling the model to 8.3 billion parameters on 512 <span class="smallcaps-auto">GPU</span>s with 8-way model
    parallelism, we achieved up to <b>15.1 Peta<span class="smallcaps-auto">FLOPS</span> sustained performance</b> over
    the entire application and reached <b>76% scaling efficiency</b> compared to the
    single <span class="smallcaps-auto">GPU</span> case.
- - https://en.wikipedia.org/wiki/Gambler%27s_fallacy#Monte_Carlo_Casino
  - ! 'Gambler''s Fallacy, examples: The Monte Carlo Casino'
  - English Wikipedia
  - 'NA'
  - ''
  - ! '<p>Perhaps the most famous example of the gambler’s fallacy occurred in a game
    of roulette at the <a href="https://en.wikipedia.org/wiki/Monte_Carlo_Casino">Monte
    Carlo Casino</a> on August 18, 1913, when the ball fell in black 26 times in a
    row. This was an extremely uncommon occurrence: the probability of a sequence
    of either red or black occurring 26 times in a row is <math display="inline"
    xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mfrac><mn>18</mn><mn>37</mn></mfrac><mrow><mn>26</mn><mo>−</mo><mn>1</mn></mrow></msup><annotation
    encoding="application/x-tex">\frac{18}{37}^{26-1}</annotation></semantics></math>
    or around 1 in 66.6 million, assuming the mechanism is unbiased. Gamblers lost
    millions of francs betting against black, reasoning incorrectly that the streak
    was causing an imbalance in the randomness of the wheel, and that it had to be
    followed by a long streak of red.</p>'
- - https://davidreiley.com/papers/PandoraListenerDemandCurve.pdf
  - ! 'Measuring Consumer Sensitivity to Audio Advertising: A Field Experiment on
    Pandora Internet Radio'
  - Jason Huang, David H. Reiley, Nickolai M. Riabov
  - 2018-04-21
  - 10.2139/ssrn.3166676
  - A randomized experiment with almost 35 million Pandora listeners enables us to
    measure the sensitivity of consumers to advertising, an important topic of study
    in the era of ad-supported digital content provision. The experiment randomized
    listeners into 9 treatment groups, each of which received a different level of
    audio advertising interrupting their music listening, with the highest treatment
    group receiving more than twice as many ads as the lowest treatment group. By
    keeping consistent treatment assignment for 21 months, we are able to measure
    long-run demand effects, with three times as much ad-load sensitivity as we would
    have obtained if we had run a month-long experiment. We estimate a demand curve
    that is strikingly linear, with the number of hours listened decreasing linearly
    in the number of ads per hour (also known as the price of ad-supported listening).
    We also show the negative impact on the number of days listened and on the probability
    of listening at all in the final month. Using an experimental design that separately
    varies the number of commercial interruptions per hour and the number of ads per
    commercial interruption, we find that neither makes much difference to listeners
    beyond their impact on the total number of ads per hour. Lastly, we find that
    increased ad load causes a significant increase in the number of paid ad-free
    subscriptions to Pandora, particularly among older listeners.
- - https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf#openai
  - Language Models are Unsupervised Multitask Learners
  - Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever
  - '2019'
  - ''
  - Natural language processing tasks, such as question answering, machine translation,
    reading comprehension, and summarization, are typically approached with supervised
    learning on task-specific datasets. We demonstrate that language models begin
    to learn these tasks without any explicit supervision when trained on a new dataset
    of millions of webpages called WebText. When conditioned on a document plus questions,
    the answers generated by the language model reach 55 F1 on the CoQA dataset—matching
    or exceeding the performance of 3 out of 4 baseline systems without using the
    127,000+ training examples. The capacity of the language model is essential to
    the success of zero-shot task transfer and increasing it improves performance
    in a log-linear fashion across tasks. Our largest model, <span class="smallcaps-auto">GPT</span>-2, is a 1.5B parameter
    Transformer that achieves state of the art results on 7 out of 8 tested language
    modeling datasets in a zero-shot setting but still underfits WebText. Samples
    from the model reflect these improvements and contain coherent paragraphs of text.
    These findings suggest a promising path towards building language processing systems
    which learn to perform tasks from their naturally occurring demonstrations.
- - https://openai.com/blog/language-unsupervised/
  - Improving Language Understanding with Unsupervised Learning
  - OpenAI
  - June 11, 2018
  - ''
  - ! 'We’ve obtained state-of-the-art results on a suite of diverse language tasks
    with a scalable, task-agnostic system, which we’re also releasing. Our approach
    is a combination of two existing ideas: <a href="https://arxiv.org/abs/1706.03762">transformers</a>
    and <a href="https://arxiv.org/abs/1511.01432">unsupervised pre-training</a>.
    These results provide a convincing example that pairing supervised learning methods
    with unsupervised pre-training works very well; this is an idea that many have
    explored in the past, and we hope our result motivates further research into applying
    this idea on larger and more diverse datasets.'
- - /docs/modafinil/2000-jasinski.pdf
  - An evaluation of the abuse potential of modafinil using methylphenidate as a reference
  - Donald R. Jasinski
  - 2000-01-01
  - 10.1177/026988110001400107
  - Modafinil is a unique wake-promoting agent. Preclinical studies indicate a mechanism
    of action which is distinct from that of amphetamine or methylphenidate. To compare
    the pharmacodynamic profiles of modafinil, methylphenidate, and placebo in humans,
    a double-blind Latin square crossover study was conducted in 24 male volunteers
    with a history of polysubstance abuse that included the stimulant cocaine. Each
    subject was given single oral doses of methylphenidate (45 mg or 90 mg), modafinil
    (200 mg, 400 mg or 800 mg) and placebo. Measures of subjective, behavioural, and
    physiological responses were evaluated at fixed intervals during 72h after each
    dosing occasion. Subjects discriminated both modafinil and methylphenidate from
    placebo. Subjects liked the effects of both drugs. However, modafinil differed
    from methylphenidate in its lack of a significant response on the Amphetamine
    Scale of the Addiction Research Center Inventory. The profile of physiological
    effects for modafinil differed from methylphenidate in that it showed greater
    inhibition of observed and reported sleep, less facilitation of orthostatic tachycardia
    and less reduction of caloric intake. These findings are consistent with preclinical
    pharmacological data suggesting that modafinil is not an amphetamine-like agent.
- - /Questions#jeanne-calment
  - On the Jeanne Calment longevity anomaly
  - Gwern Branwen
  - 2018-10-17
  - ''
  - ! '<p>Jeanne Calment holds the record for human longevity at ~122.5 years, and
    will have held it for a minimum of 3 decades, despite countless countervailing
    factors. No challenging centenarian has come close to her record, and arithmetically,
    they will not for years to come. Some <a href="Order-statistics#sampling-gompertz-distribution-extremes"
    title="Order Statistics: efficiently sampling Gompertz distribution extremes">statistical
    simulations</a> suggest that Calment-like records are not expected from the distribution
    of human life expectancies, and as time passes, her record becomes increasingly
    anomalous.</p><p>This truly remarkable longevity raises the question of whether
    Calment''s longevity is due to the same factors as all other centenarians: did
    she benefit from some unique factor like genetic mutations, or, as accused in
    late 2018 of being, is she, in fact, merely a fraud which has escaped previous
    verification?</p>'
- - /docs/economics/2001-fehr.pdf
  - Do Incentive Contracts Crowd Out Voluntary Cooperation?
  - Ernst Fehr, Simon Gächter
  - 2001-11-05
  - ''
  - In this paper we provide experimental evidence indicating that incentive contracts
    may cause a strong crowding out of voluntary cooperation. This crowding-out effect
    constitutes costs of incentive provision that have been largely neglected by economists.
    In our experiments the crowding-out effect is so strong that the incentive contracts
    are less efficient than contracts without any incentives. Principals, nonetheless,
    prefer the incentive contracts because they allow them to appropriate a much larger
    share of the (smaller) total surplus and are, hence, more profitable for them.
- - /docs/economics/2007-schneider.pdf
  - A Rule Against Perpetuities For The Twenty-First Century
  - Frederick R. Schneider
  - '2007'
  - 10.2307/20787089
  - <p>The common law rule against perpetuities maintained alienation of property
    by voiding interests in property that did not vest within a life in being at the
    creation of the interest plus twenty-one years. The rule was applied strictly,
    often producing harsh results. The courts used a what-might-happen test to strike
    down nonvested interests that might not have vested in a timely manner. During
    the last half-century, many legislatures have softened the application of the
    rule against perpetuities by enacting wait-and-see provisions, which require courts
    to decide cases based on the facts as they actually developed, and reformation,
    which allowed some nonvested interests to be reformed to save them from invalidity.</p><p>This
    paper describes the common law rule. Then it traces the modern developments, including
    promulgation of the widely adopted Uniform Statutory Rule Against Perpetuities,
    which includes an alternate 90 year fixed wait-and-see period to be applied in
    place of the common law's lives in being plus twenty-one years.</p><p>The paper
    continues by exploring the policies which underlie the rule against perpetuities.
    Then, after finding that there is no significant movement to repeal the rule except
    for trusts, it is established that proposals for that federal law, including federal
    transfer taxes, cannot and should not be used to implement the policies served
    by the rule itself.</p><p>There is a continuing need for state rules against perpetuities.
    The paper proposes that the rule be modified to make it more understandable and
    easier to apply. The proposed rule would replace lives in being plus twenty-one
    years with a fixed term of years. This would eliminate most of the difficulties
    encountered in application of the rule. Wait-and-see and reformation are part
    of the proposed rule. The proposed rule provides for determination of valid interests
    at the end of the fixed term of year Rule and contains a definition of "vested"
    to enable judges and attorneys to apply the rule in cases which will arise many
    years in the future.</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.306.7113&rep=rep1&type=pdf
  - On the Near Impossibility of Measuring the Returns to Advertising
  - Randall A. Lewis, Justin M. Rao
  - 2013-04-23
  - ''
  - Classical theories of the firm assume access to reliable signals to measure the
    causal impact of choice variables on profit. For advertising expenditure we show,
    using twenty-five online field experiments (representing $2.8 million) with major
    U.S. retailers and brokerages, that this assumption typically does not hold. Statistical
    evidence from the randomized trials is very weak because individual-level sales
    are incredibly volatile relative to the per capita cost of a campaign—a “small”
    impact on a noisy dependent variable can generate positive returns. A concise
    statistical argument shows that the required sample size for an experiment to
    generate sufficiently informative confidence intervals is typically in excess
    of ten million person-weeks. This also implies that heterogeneity bias (or model
    misspecification) unaccounted for by observational methods only needs to explain
    a tiny fraction of the variation in sales to severely bias estimates. The weak
    informational feedback means most firms cannot even approach profit maximization.
- - https://www.uea.ac.uk/documents/107435/107587/ccp_11_9.pdf
  - Does Retail Advertising Work? Measuring the Effects of Advertising on Sales Via
    a Controlled Experiment on Yahoo!
  - Randall A. Lewis, David H. Reiley
  - 2011-06-08
  - ''
  - We measure the causal effects of online advertising on sales, using a randomized
    experiment performed in cooperation between Yahoo! and a major retailer. After
    identifying over one million customers matched in the databases of the retailer
    and Yahoo!, we randomly assign them to treatment and control groups. We analyze
    individual-level data on ad exposure and weekly purchases at this retailer, both
    online and in stores. We find statistically and economically significant impacts
    of the advertising on sales. The treatment effect persists for weeks after the
    end of an advertising campaign, and the total effect on revenues is estimated
    to be more than seven times the retailer’s expenditure on advertising during the
    study. Additional results explore differences in the number of advertising impressions
    delivered to each individual, online and offline sales, and the effects of advertising
    on those who click the ads versus those who merely view them. Power calculations
    show that, due to the high variance of sales, our large number of observations
    brings us just to the frontier of being able to measure economically significant
    effects of advertising. We also demonstrate that without an experiment, using
    industry-standard methods based on endogenous crosssectional variation in advertising
    exposure, we would have obtained a wildly inaccurate estimate of advertising effectiveness.
- - /docs/biology/1966-kessler.pdf
  - Interplay Between Social Ecology and Physiology, Genetics and Population Dynamics
    of Mice
  - Alexander Kessler
  - 1966-03-31
  - ''
  - ! '<p>The interplay between socioecologlcal and biological processes manifests
    Itself at the level of individuals, populations, and species. The biology of Individuals
    is deeply modified when they are groups; many of the attributes of populations
    such as size, distribution, composition, etc. are related to social interactions,
    and at the level of species, patterns of social relations within groups tend to
    be structured in ways that influence survival, reproduction, and exchange among
    populations.</p><p>In one experimental approach to these problems, the social
    ecology of freely growing populations of mice In large enclosures was related
    to behavioral, physiological, and health changes of individuals, to demographic
    changes and to changes of gene frequencies. Another experiment examined the process
    and effects of artificial selection for the same trait in different social environments.</p><p><strong><em>Population
    Experiment</em></strong></p><p>The population enclosures were octagonal structures
    subdivided Into central and peripheral sections with a total surface area of 13.3
    square feet. From a founder group of mice of known genetic (progeny of a four-way
    cross among inbred mouse strains C57L/J, <span class="smallcaps-auto">SWR</span>/J, C3HeB/FeJ, 129/J) and environmental
    background, three equivalent samples of mice were distributed into replicate population
    enclosures (Pop A and B) and into standard laboratory cages as randomly mated
    male-female pairs—the control group (Pop C).</p><p>During the first year of study,
    daily observations of the enclosures were made, and several censuses were performed.
    Identifiable cohorts, animals born during each census interval, were established
    to provide an additional way of analyzing changes in the populations.</p><p>In
    Pop C, reproduction remained constant and mortality was negligible. Marked changes
    occurred in Pop A and B. The sizes (1000—A and 800—B mice) and densities (85—A
    and 60—B mice per square foot) are several times greater than those of any previously
    reported population of small mammals. However, there would have been 100,000 mice
    in each enclosure at the end of a year had the populations continued to grow as
    they did at first. Changes of reproductive physiology constituted prominent aspects
    of self-regulation in the enclosures. Peak demographic input rates occurred during
    the third month, but were already associated with decreased productivity per adult
    female. Analysis of maturation and reproduction pointed to inhibition of reproduction
    in sexually mature females as the most important factor in the decline of productivity.
    Pregnancy rates fell steadily and inhibition of full-term gestation occurred.
    Gonads and reproductive cells of males were adult, but a large proportion of males
    showed little sexual activity.</p><p>Neonatal mortality was particularly striking
    in Pop B, where 30% of females showed advanced pregnancy during the last 5.5 months
    with no newborns surviving. About 25% of the mice in the enclosures died during
    the year. Highest weekly death rates occurred during the first half of the year
    before peak numbers were present. Autopsies of mice of Pop A revealed little in
    the way of abnormal findings.</p><p>Biomass either paralleled or increased more
    rapidly than numbers in both enclosures, contrasting with some other population:
    studies in which growth was impaired with crowding.</p><p>Changes of behavior
    included: 1. disappearance of circadian activity peaks, 2. decline in frequency
    of fighting per male but an increase in unusual aggressiveness, 3. aberrations
    of sexual behavior, 4. deterioration of maternal care, 5. cannibalism, 6) striking
    decrease in social responsiveness.</p><p>Cohorts in the populations were biologically
    distinguishable sub-units in contrast to control cohorts, which showed no such
    differentiation. Cohorts in Pop A and B differed with respect to reproduction
    physiology, mortality, and behavior, and intercohort differences persisted at
    all levels of population density.</p><p>Many of the properties of Pop A and B
    mice changes when the mice were placed in different social environments, attesting
    to the specificity of the influence of social factors. For example, mice of Pop
    A, randomly paired in control cages, showed a marked rise in reproduction, and
    cohorts reproductively inhibited before were most productive in the new social
    environment. Behavioral tests performed outside the enclosure environment revealed:
    1. intercohort differences among Pop A mice contrasted with stereotyped behavior
    of Pop C mice, and 2. changes in behavior of Pop A mice both immediately after
    removal from the population and after six weeks in new social conditions. Pop
    B mice changed their social environment by emigrating into the empty interconnected
    enclosure of Pop A. Two distinctive sub-populations formed. Greater changes in
    reproduction, mortality, and behavior occurred in the emigrant subpopulation,
    which underwent more extensive social reorganization. Immediately following reunion
    of the two subpopulations, a population crash occurred, possibly related to the
    sudden changes of social conditions.</p><p>Use of genetically defined animals
    made feasible the study of gene frequency changes. Polymorphism of alleles at
    the C locus affecting coat color differed between Pop A and B on the one hand
    and Pop C on the other. Although the magnitude of the upward change of recessive
    c in Pop A and B was not large, the consistency and similarity of the change in
    Pop A and B and lack of change in Pop C suggested the action of systematic processes
    and the probable adaptiveness of the changes. There was little evidence of differential
    adult reproduction or mortality among the phenotypes but there were suggestions
    of differential neonatal survival. The relatively slow rate of change of the alleles
    after the first generation suggested the establishment of a state of balanced
    polymorphism at the C locus. Hemoglobin allele and genotype frequencies of mice
    of Pop A alive at the end of the year did not deviate from what might have been
    predicted on the basis of panmixia.</p><p><strong><em>Selection Experiment</em></strong></p><p>Selection
    for the same trait in varied environments tends to involve genetic and physiological
    differences. The question of adaptability to different social environments was
    studied; heavy body weight at sexual maturity was chosen as the trait for selection;
    groups of different sizes—pairs or groups of 20-30 mice—were the environmental
    variables. Sexes were kept separate between weaning and sexual maturity. A within-litter
    selection method was used.</p><p>Crowding depressed weight at sexual maturity
    but equal improvement with selection occurred in both social environments. Heritability
    was also equal in crowded and uncrowded groups. Environmental exchange carried
    out in the sixth and seventh generation suggested that mice selected in crowded
    environments performed slightly better in both crowded and uncrowded environments.</p><p>The
    large sizes and unusual degree of crowding attained by the freely growing populations
    in this study compared with previous studies may be related to the types of animals
    used, to the number of individuals in the founder nuclei, and to the physical
    structure of the enclosures. Extreme crowding was compatible with general physical
    health. The decline of fertility and fecundity, the decreased survival of newborns,
    and the appearance of behavioral aberrations—rather than disease or an increase
    in adult mortality—represented the major self-regulatory mechanisms that eventually
    limited population growth. The growth of individuals was not inhibited. Social
    withdrawal and the decline of social interaction rather than a rise of interaction
    characterized the populations. Such findings cast doubt about the generality of
    the so-called “Stress” theory of social ecology that emphasizes increased interaction
    and pituitary-adrenal hyperactivity as the principal mechanisms involved in self-regulation
    of vertebrate populations.</p><p>Other formulations of mammalian social ecology,
    such as those that focus on the importance of early development, of spatial requirements,
    of neurophysiological reactivity, and of communications, constitute additional
    explanations of the interplay of social and biological processes in crowded populations.</p><p>Although
    man’s potential reactions are more complex and variable than those of lower vertebrates
    and give prominence to the role of symbols and culture, his social environment
    is even more fundamental to his entire existence. This, if anything, increases
    the importance of the interplay of socioecological and biological processes for
    man.</p>'
- - https://paperswithcode.com/task/language-modelling
  - Language Modelling State-of-the-art leaderboards
  - paperswithcode.com
  - 2019-08-28
  - ''
  - ! 'Language modeling is the task of predicting the next word or character in a
    document. This page lists key recent papers on <span class="smallcaps-auto">NLP</span> language modeling and records
    reported research performance on the following tasks: WikiText-103, Penn Treebank
    (Word Level), enwiki8, Text8, One Billion Word, WikiText-2, Hutter Prize, Penn
    Treebank (Character Level).'
- - https://gpt2.apps.allenai.org/?text=Joel%20is
  - LM Explorer (alpha)
  - Allen Institute For Artificial Intelligence
  - 2019-02-26
  - ''
  - <p>This demonstration uses the public 345M 117M parameter OpenAI <span class="smallcaps-auto">GPT</span>-2 language
    model to generate sentences.</p><p>Enter some initial text and the model will
    generate the most likely next words. You can click on one of those words to choose
    it and continue or just keep typing. Click the left arrow at the bottom to undo
    your last choice.</p>
- - https://www.poetryfoundation.org/poems/49303/howl
  - Howl
  - Allen Ginsberg
  - '1955'
  - ''
  - <p>[Poem]</p><p>I saw the best minds of my generation destroyed by madness, starving
    hysterical naked,<br>dragging themselves through the negro streets at dawn looking
    for an angry fix,<br>angelheaded hipsters burning for the ancient heavenly connection
    to the starry dynamo in the machinery of night,<br>who poverty and tatters and
    hollow-eyed and high sat up smoking in the supernatural darkness of cold-water
    flats floating across the tops of cities contemplating jazz,<br>who bared their
    brains to Heaven under the El and saw Mohammedan angels staggering on tenement
    roofs illuminated,<br>who passed through universities with radiant cool eyes hallucinating
    Arkansas and Blake-light tragedy among the scholars of war,<br>who were expelled
    from the academies for crazy & publishing obscene odes on the windows of the skull,
    …</p>
- - http://antinegationism.tumblr.com/post/182901133106/an-eternal-howl
  - An Eternal Howl
  - antinegationism
  - 2019-02-18
  - ''
  - ! '<p>[<span class="smallcaps-auto">GPT</span>-2] Prompt: </p><p>“Moloch! Solitude! Filth! Ugliness! Ashcans and unobtainable
    dollars! Children screaming under the stairways! Boys sobbing in armies! Old men
    weeping in the parks! <br>Moloch! Moloch! Nightmare of Moloch! Moloch the loveless!
    Mental Moloch! Moloch the heavy judger of men! <br>Moloch the incomprehensible
    prison! Moloch the crossbone soulless jailhouse and Congress of sorrows!<br>Moloch
    whose buildings are judgment! Moloch the vast stone of war! Moloch the stunned
    governments! <br>Moloch whose mind is pure machinery! Moloch whose blood is running
    money! Moloch whose fingers are ten armies! Moloch whose breast is a cannibal
    dynamo! <br>Moloch whose ear is a smoking tomb! <br>Moloch whose eyes are a thousand
    blind windows! <br>Moloch whose skyscrapers stand in the long streets like endless
    Jehovahs! <br>Moloch whose factories dream and croak in the fog! <br>Moloch whose
    smoke-stacks and antennae crown the cities …”<br>Response: <br>like a pile of
    wood! <br>Moloch whose huge flawless towers cry like song in the daytime! <br>Moloch
    whose buildings implode like a living Iometer of History! <br>Moloch whose bridges
    sag violently like a lattice apple falling on the stream! <br>Moloch whose court
    are the host of billions of millions of nerves of passion and anger still raging
    up and down every dollar in the world! <br>Moloch the shadow world long, Americanized
    and red in red! <br>Moloch is cruel always and everywhere. <br>Moloch is perfect
    to human purposes! <br>Moloch is kept beyond height blind. Moloch the incorporeal
    skull of man! <br>Moloch the flag of equality! <br>Moloch the endless ever-splitting
    price of hell! <br>Moloch the worldly bathing anchor in fungicide money! <br>Moloch
    the hideous empire in feeble lines! Moloch the death of the dreamless things!
    Moloch the glorious command of justice! Moloch the bloody trail!</p>'
- - https://twitter.com/robertskmiles/status/1104008764997419009
  - Rob Miles on Twitter
  - Robert Miles
  - 2019-03-08
  - ''
  - Has anyone done this yet? I told my <span class="smallcaps-auto">GPT</span>-2 program to write new verses for Allen
    Ginsberg&#39;s Howl, and forgot to tell it to stop:<a href="https://t.co/TpNnR5V2Ex">https://t.co/TpNnR5V2Ex</a>
    <a href="https://t.co/Q4fUQY8czU">pic.twitter.com/Q4fUQY8czU</a>
- - https://medium.com/@ysaw/gpt-2-writes-a-shelley-poem-bc0c19fe4ee3
  - <span class="smallcaps-auto">GPT</span>-2 Writes a Shelley Poem
  - Stephen Woods
  - 2019-02-20
  - ''
  - ! '<p>(seed text was Ozymandias)</p><p>The sea hath never parted from the rocky
    shores,<br>That doth not rise again the sea, and its long, tumbled,<br>As if the
    waters have broken by its side.<br>And as the ocean came up to sea,<br>And the
    sea was broken by the wreck,<br>And the sea sank to the Sea of the Dead<br>By
    the wad of blood. It would have slain the Sea of the Dead<br>But it would not:
    its last breath, And it did.<br>This sea in the sea hath a Sea of waggon,<br>And
    a Sea of waggon of blood; For all what hath not come<br>With it hath fallen, And
    as a waggon of blood the waggon<br>And the blood is flowing out of that waggon.<br>So,
    then, are the works of Zeus,<br>And the work of Zeus, O Great Creator, whose designs<br>With
    the work of the great King are he wrought<br>In their midst. . . . .<br>In the
    desert have the mighty Gods<br>And the gods themselves come.”<br>A serpent of
    darkness rises among the hills<br>In a forest on the land of the gods.<br>A mighty
    bird that flies out a bird-hoast,<br>And flies out a fly, from behind its wing.<br>And
    there the sky is filled with white, and it is broken through.<br>And like this,
    we know the mighty Man<br>Of the clouds from which he fled upon the land of the
    gods,<br>The mighty serpent that the king sent for them,<br>And he brought them
    to that man; and he said:<br>“I know you, O mighty Man from the earth!”<br>And
    what do you say? You knew him when you saw in the dream,<br>And you saw from under
    one of his arms a mighty serpent<br>That a mighty man can lift up, and drive<br>He
    that was in the way and lifted up; and he led him to be a god,<br>And he he led
    him down the great mountain which I have prepared.<br>Let his tongue speak, tell
    thee, O man: “I know thee.<br>Here thou dost see, O great King, that is the very
    power of the Gods”<br>Let His voice say, to thee, “that is the very power of the
    Gods”<br>Let His voice say to thee, “that is the voice of the whole creation”</p>'
- - https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/
  - <span class="smallcaps-auto">GPT</span>-2 As Step Toward General Intelligence
  - Scott Alexander
  - 2019-02-19
  - ''
  - ! 'A machine learning researcher writes me in response to yesterday’s post, saying:<p><blockquote>I
    still think <span class="smallcaps-auto">GPT</span>-2 is a brute-force statistical pattern matcher which blends up
    the internet and gives you back a slightly unappetizing slurry of it when asked.</blockquote></p><p>I
    resisted the urge to answer “Yeah, well, your mom is a brute-force statistical
    pattern matcher which blends up the internet and gives you back a slightly unappetizing
    slurry of it when asked.”</p><p>But I think it would have been true.</p><p>A very
    careless plagiarist takes someone else’s work and copies it verbatim: “The mitochondria
    is the powerhouse of the cell”. A more careful plagiarist takes the work and changes
    a few words around: “The mitochondria is the energy dynamo of the cell”. A plagiarist
    who is more careful still changes the entire sentence structure: “In cells, mitochondria
    are the energy dynamos”. The most careful plagiarists change everything except
    the underlying concept, which they grasp at so deep a level that they can put
    it in whatever words they want—at which point it is no longer called plagiarism.</p><p><span class="smallcaps-auto">GPT</span>-2
    writes fantasy battle scenes by reading a million human-written fantasy battle
    scenes, distilling them down to the concept of a fantasy battle scene, and then
    building it back up from there. I think this is how your mom (and everyone else)
    does it too. <span class="smallcaps-auto">GPT</span>-2 is worse at this, because it’s not as powerful as your mom’s
    brain. But I don’t think it’s doing a different thing. We’re all blending experience
    into a slurry; the difference is how finely we blend it…</p>'
- - https://twitter.com/peterkz_swe/status/1098668851640848384
  - Peter Krantz on Twitter
  - Peter Krantz
  - 2019-02-21
  - ''
  - ! '<p>First line of famous poems continued by the <a href="https://twitter.com/OpenAI">@openAI</a>
    <span class="smallcaps-auto">GPT</span>-2 example model from &quot;Language Models are Unsupervised Multitask Learners&quot;
    <a href="https://twitter.com/hashtag/gpt2poetrytwsrcpt2poetry</a> <a href="https://twitter.com/hashtag/GPT2">#GPT2</a><br>\U0001F447\U0001F3FC</p>&mdash;
    Peter Krantz (@peterkz_swe) <a href="https://twitter.com/peterkz_swe/status/1098668851640848384">February
    21, 2019</a></blockquote><br><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script><br><blockquote class="twitter-tweet" data-lang="en"><p
    lang="en" dir="ltr">It little profits that an idle king,<br>who loves his
    throne for a moment to enjoy a good meal, <br>might, if he was not in the right
    position, <br>become the subject of a great banquet.<br>But as the royal household
    will do, <br>so too shall their subjects. <a href="https://twitter.com/hashtag/gpt2poetry">#gpt2poetry</a>
    <a href="https://twitter.com/hashtag/tennyson">#tennyson</a></p>'
- - https://github.com/kylemcdonald/gpt-2-poetry
  - gpt-2-poetry
  - Kyle McDonald
  - 2019-03-04
  - ''
  - <p>I used <code>download-urls.py</code> to quickly download the <span class="smallcaps-auto">HTML</span> from poetryfoundation.org
    based on the <span class="smallcaps-auto">URL</span>s in <code>romantic-urls.txt</code>.</p><p>Then I used <code>Parse
    Poetry.ipynb</code> to parse the <span class="smallcaps-auto">HTML</span> and extract the title, author, and poem.
    There are some glitches here with newlines being rendered in some places they
    shouldn't, and not being rendered in places where they should. This notebook saves
    a bunch of text files to output/ that include metadata as the first few lines.</p><p>Then
    I used <code>Generate GPT-2.ipynb</code> to generate poems based on random chunks
    from the poems and the seed words. This notebook saves files to <code>poems.json</code>
    and <code>generated.json</code>. To run this notebook, first get <span class="smallcaps-auto">GPT</span>-2 running,
    and drop the notebook in the <code>gpt-2/src/</code> directory.</p><p>Both Python
    notebooks import from <code>utils</code> which I have separately pushed here.</p><p>Finally,
    I load <code>generated.json</code> and <code>poems.json</code> with JavaScript
    in <code>index.html</code> and display the results.</p>
- - https://medium.com/merzazine/fridai-water-water-everywhere-as-read-by-artificial-intelligence-d02bb3d2b156
  - ! 'FridAI: ‘Water, water, everywhere’, as read by Artificial Intelligence'
  - Merzmensch Kosmopol
  - 2019-03-15
  - ''
  - ! '<p>Samuel Taylor Coleridge once introduced to the world that desolated ship
    journey in his “The Rime of the Ancient Mariner”:<br><blockquote>Water, water,
    everywhere,<br>And all the boards did shrink;<br>Water, water, everywhere,<br>Nor
    any drop to drink.</blockquote>Ulysses, Noah and Job, so many allusions are hidden
    in this masterpiece about “a sadder and a wiser man”. And so I wanted to know,
    which journey will be chosen by <span class="smallcaps-auto">GPT</span>-2, a Deep Learning entity, developed by OpenAI
    to write texts.</p><p>And it wrote me a poem.</p><p>My input was the four lined
    stanza, as cited above. And here is the poetic vision by Artificial Intelligence:</p><p><blockquote>Water,
    water, everywhere, <br>And all the boards did shrink; <br>Water, water, everywhere,
    <br>Nor any drop to drink. <br>Water, water, everywhere, <br>And all the boards
    did shrink; <br>Water, water, everywhere, <br>No balm in his hair: <br>Water,
    water, everywhere, <br>And all the boards did shrink. <br>Water, water, everywhere,
    <br>Yet we like its rarity. <br>Water, water, everywhere, <br>And all the boards
    did shrink. <br>Water, water, everywhere.</blockquote></p><p>Yes, the rarity of
    the water (everywhere) is striking. Even if the hair is suffering without balm.
    Probably because you cannot drink a drop.</p><p>But the poem was not over. AI
    was embraced by inspiration…</p>'
- - http://yudhanjaya.com/2019/04/the-poetry-machine/
  - The Poetry Machine
  - Yudhanjaya Wijeratne
  - 2019-04-12
  - ''
  - ! '<p>I’ve always admired the translations of Chinese poetry–I’m no expert on
    the field, but there are two poets named Du Fu and Li Bai that I really like.
    They were legendary masters from the Great Tang Dynasty, and (if the translations
    are accurate), they had a phenomenal talent for freezing a moment and capturing
    that particular slice of time with their words; their poems read like a string
    of Polaroids stretched across a riverbank.</p><p>Here, for example, is a Du Fu
    poem. Among other things, there’s a certain simplicity here: one strong emotion
    resonates through, and unlike much of the English verse I grew up with, it’s firmly
    in the present tense:<blockquote>A <span class="smallcaps-auto">GPT</span> <span class="smallcaps-auto">GPT</span><br>In a sharp gale from the wide
    sky apes are whimpering,<br>Birds are flying homeward over the clear lake and
    white sand,<br>Leaves are dropping down like the spray of a waterfall,<br>While
    I watch the long river always rolling on.<br>I have come three thousand miles
    away. Sad now with autumn<br>And with my hundred years of woe, I climb this height
    alone.<br>Ill fortune has laid a bitter frost on my temples,<br>Heart-ache and
    weariness are a thick dust in my wine.</blockquote> <p>Which I suppose is why
    this appeals to me—there’s a rare clarity here, even if the translation might
    be inaccurate.</p><p>So the Tang poets seemed like the right place to start with
    for my experiment with machine-generated art (and besides, the excellent GWERN
    already did the usual English[1]). Right now, I’ve snuck away for a few hours
    from a my statistical models to peek at the code I set to run this morning.<p><p>Among
    those of us who work with machine learning, the work I’ve put into this whole
    project is trivial: a tiny dataset, a cup of coffee, a few lines of Python code,
    and a single cigarette while I waited for OpenAI’s transformer-based generation
    model [2] to download.</p>'
- - https://twitter.com/rossgoodwin/status/1124901310677913600
  - Ross Goodwin on Twitter
  - ! '@rossgoodwin'
  - 2019-05-04
  - ''
  - <p>THREE MORE GPT-2 POEMS</p><p>I've been training this poetry model on a corpus
    structured to encourage thematic integration of individual keyword prompts, and
    the word "ghost" produced these results.</p><p>{ 1 / 3 } <a href="https://t.co/GehRqfQGq8">pic.twitter.com/GehRqfQGq8</a>…</p>
- - https://iforcedabot.com/what-can-a-fake-news-detector-do/
  - Testing The Limits of Grover The Neural Fake News Detector. Can It Write Fiction?
    Can It Write Riddles?
  - Jonathan Fly
  - 2019-05-31
  - ''
  - ! '<p>Grover is a neural network modeled after <span class="smallcaps-auto">GPT</span>-2 as a state-of-the-art detector
    for Neural Network fake news. Grover is also a state-of-the-art generator of fake
    news and they provide a web interface. Since Grover is modeled after the full-size
    1.5B <span class="smallcaps-auto">GPT</span>-2—not the smaller version the public has access to—this is a bit like
    getting a back door to the full-size <span class="smallcaps-auto">GPT</span>-2. This is very exciting! (Update: They
    just reduced the size of the public model to 345M—everything in this post come
    from the full size model. Glad I stayed up way too late hammering the real thing
    for samples… Update 2: It’s back up!)</p><p>Grover was trained on 5000 news domains
    indexed by Google News, not the internet generally like <span class="smallcaps-auto">GPT</span>-2. As you would expect
    Grover excels at writing fake news: <blockquote><p>Scientists Recommend Against
    Vaccination: "The Evidence Is Now Clear: Vaccines Cause Autism and Cancer"</p><p>After
    a 15-year study, scientists in Britain are recommending that the British government
    refrain from administering vaccines. The study, written by Mike Gunton, professor
    of epidemiology and professor of genetic medicine at the University of Liverpool,
    claims that the chances of the <span class="smallcaps-auto">GPT</span> vaccine, a vaccine for measles, mumps and rubella,
    causing autism in children are “strongly possible.” And while Gunton and his team
    say their findings only apply to the <span class="smallcaps-auto">GPT</span> vaccine, they believe there are “many
    similar disorders” linked to vaccines and there is “strong evidence” vaccines
    cause autism and leukemia. Gunton told the Telegraph that no effort should be
    made to give vaccines to children younger than 3 months of age. The vaccine is
    highly controversial, and parents have been choosing to opt out of the <span class="smallcaps-auto">GPT</span> vaccination
    in recent years. This year, the British government’s vaccination program chose
    not to distribute the <span class="smallcaps-auto">GPT</span> vaccine, citing the study as the reason.</p></blockquote>
    You don’t have to fish to get coherent fake news of Grover, it’s absolutely great
    at it.</p>'
- - https://medium.com/@NPCollapse/replicating-gpt2-1-5b-86454a7f26af
  - Replicating <span class="smallcaps-auto">GPT</span>2–1.5B
  - Connor Leahy
  - 2019-06-06
  - ''
  - ! '<p>In this post, I want to quickly talk about the technical and organizational
    questions around my recent replication of <span class="smallcaps-auto">GPT</span>2–1.5B. Please read my main post
    for the full story. I will try to keep this post brief.</p>><b>The important facts</b></p><p>Code:
    <a href="https://github.com/ConnorJL/GPT2">https://github.com/ConnorJL/GPT2</a></p><p>Samples:
    <a href="https://github.com/ConnorJL/GPT2/tree/master/samples">https://github.com/ConnorJL/GPT2/tree/master/samples</a></p><p>The
    code should run out of the box on <span class="smallcaps-auto">GPT</span>s and <span class="smallcaps-auto">GPT</span>s (and <span class="smallcaps-auto">GPT</span>s, if you’re really desperate).
    I used the parameters specified in 1.5B.json and trained it on a preemptible v3–512
    <span class="smallcaps-auto">GPT</span> pod (which is actually more powerful than the machine OpenAI used) for around
    a week (with interruptions). Code and instructions for generating the dataset
    are also included in the repo.</p><p>You can download my models with the script
    in the repo. Currently I have a weaker version of 117M, and a model I call PrettyBig
    which is slightly larger than OpenAI’s 345M, which means it is technically the
    largest <span class="smallcaps-auto">GPT</span>2 model currently publicly available.</p><p>I will be releasing 1.5B
    to the public on July 1<sup>st</sup>, if, and only if, no one shows me a convincing reason
    not to. When I do, it will be downloadable just like my other models.</p>'
- - https://medium.com/@NPCollapse/addendum-evaluation-of-my-model-e6734b51a830
  - ! 'Addendum: Evaluation of My Model'
  - Connor Leahy
  - 2019-06-12
  - ''
  - ! '<p>As a mercifully short addendum, I’d like to quickly address a few questions
    about my model. Please read my update post to hear my important updated beliefs
    on this situation, because I believe the details of how powerful my model is or
    not are not actually very important to the overall situation.</p><p>As described
    in my technical post, my model is not identical to OpenAI’s, because I simply
    didn’t have all the details of what they did. The truth is also that the samples
    and metrics I have shown aren’t 100% accurate. For one, my metric code is flawed,
    I made several rookie mistakes in setting up accurate evaluation (let train and
    eval data mix, used metrics whose math I didn’t understand etc), and the model
    I used to generate the samples is in fact not the final trained model, but one
    about halfway through the training. I didn’t take my time to evaluate the strength
    of my model, I simply saw I had the same amount of hardware as OpenAI and code
    as close to the paper as possible and went with it. The reason for this is a simple
    human flaw: I got cold feet once I realized what I was sitting on and acted rashly.
    I made a mistake, I did something stupid, that’s all there is to it.</p><p>Thanks
    to help from OpenAI it is now safe to say that my model is not as powerful as
    OpenAI’s. The metric results for WikiText2, <span class="smallcaps-auto">GPT</span> and <span class="smallcaps-auto">GPT</span> are (lower is better):</p><p><span class="smallcaps-auto">GPT</span>2:
    18.67 / 8.63 / 36.51</p><p>Mine: 43.79 / 109.47 / 202.29</p><p>Although I used
    the same amount of hardware (or more), the differences in my training setup and
    hyperparameters made a significant difference. Which is an unfortunate reality
    to anyone familiar with reproducing deep learning papers. I don’t think my model
    in its current state is even as dangerous as 117M in its text generating abilities.
    But I believe to have found the quirks in my setup that have held the model back,
    and they are easy to fix. I am very tempted to continue tinkering with the model
    and seeing if I can improve it…but I will be holding back for now.</p>'
- - https://www.rand.org/research/gun-policy/analysis/essays/mass-shootings.html
  - ! 'Mass Shootings: Definitions and Trends'
  - Rosanna Smart (<span class="smallcaps-auto">RAND</span>)
  - 2018-03-02
  - ''
  - ! '<p>There is no standard definition of what constitutes a mass shooting. Media
    outlets, academic researchers, and law enforcement agencies frequently use different
    definitions when discussing mass shootings, leading to different assessments of
    the frequency with which mass shootings occur and about whether mass shootings
    are more common now than they were a decade or two ago.</p><p>…These definitions
    matter. Depending on which data source is referenced, there were seven, 65, 332,
    or 371 mass shootings in the United States in 2015 (see table below), and those
    are just some examples. More-restrictive definitions (e.g., Mother Jones) focus
    on the prevalence of higher-profile events motivated by mass murder, but they
    omit more-common incidents occurring in connection with domestic violence or criminal
    activity, which make up about 80 percent of mass shooting incidents with four
    or more fatally injured victims (Krouse and Richardson, 2015).</p><p>…In 2014,
    the <span class="smallcaps-auto">RAND</span> released a study showing that “active shooting incidents” had increased
    at an average annual rate of 16 percent between 2000 and 2013 (Blair and Schweit,
    2014). In contrast to the varied definitions for mass shootings, there is an agreed-upon
    definition among government agencies for <em>active shooter</em>: “an individual
    actively engaged in killing or attempting to kill people in a confined and populated
    area; in most cases, active shooters use firearm(s) and there is no pattern or
    method to their selection of victims” (U.S. Department of Homeland Security, 2008,
    p. 2). Using a modified version of this definition to include incidents that had
    multiple offenders or occurred in confined spaces, Blair and Schweit (2014) found
    that active shootings had increased from only one incident in 2000 to 17 in 2013.</p><p>…In
    their analysis of mass shooting trends from 1999 to 2013, Krouse and Richardson
    (2015) distinguished between mass shootings occurring in public locations that
    are indiscriminate in nature (“mass public shootings”), mass shootings in which
    the majority of victims are members of the offender’s family and that are not
    attributable to other criminal activity (“familicide mass shootings”), and mass
    shootings that occur in connection to some other criminal activity (“other felony
    mass shootings”). The two figures below show trends in these types of mass shooting
    incidents and fatalities, respectively, using the data provided in Krouse and
    Richardson (2015). Extending the data back to the 1970s, two studies found evidence
    of a slight increase in the frequency of mass public shootings over the past three
    decades (Cohen, Azrael, and Miller, 2014; Krouse and Richardson, 2015). However,
    using an expanded definition that includes domestic- or felony-related killings,
    there is little evidence to suggest that mass shooting incidents or fatalities
    have increased (Cohen, Azrael, and Miller, 2014; Krouse and Richardson, 2015;
    Fox and Fridel, 2016). Thus, different choices about how to define a mass shooting
    result in different findings for both the prevalence of these events at a given
    time and whether their frequency has changed over time.</p><p>…Definitional
    issues aside, the relative rarity of mass shooting events makes analysis of trends
    particularly difficult. Chance variability in the annual number of mass shooting
    incidents makes it challenging to discern a clear trend, and trend estimates will
    be sensitive to outliers and to the time frame chosen for analysis. For example,
    while Krouse and Richardson (2015) found evidence of an upward trend in mass public
    shootings from 1999 to 2013, they noted that the increase was driven largely by
    2012, which had an unusually high number of mass public shooting incidents. Additionally,
    Lott (2015) showed that the <span class="smallcaps-auto">RAND</span> study’s estimate of a dramatic increase in active-shooter
    incidents was largely driven by the choice of 2000 as the starting date, because
    that year had an unusually low number of shooting incidents; extending the analysis
    to cover 1977 onward and adjusting the data to exclude events with fewer than
    two fatalities, Lott (2015) found a much smaller and statistically insignificant
    increase (less than 1 percent annually) in mass shooting fatalities over time.</p>'
- - https://medium.com/huggingface/distilbert-8cf3380435b5
  - ! 'Smaller, faster, cheaper, lighter: Introducing Distil<span class="smallcaps-auto">GPT</span>, a distilled version
    of <span class="smallcaps-auto">GPT</span>'
  - Victor Sanh
  - 2019-08-28
  - ''
  - ! '<p>[HuggingFace has released a <span class="smallcaps-auto">GPT</span> transformer model "Distil<span class="smallcaps-auto">GPT</span>", which is
    similar to the <span class="smallcaps-auto">GPT</span> architecture: only 66 million parameters (instead of 110 million)
    while keeping 95% of the performance on <span class="smallcaps-auto">GPT</span>. It is available on their repository
    ''pytorch-transformers'' alongside 7 other transformer models. It uses knowledge
    distillation with a cross-entropy loss to train a much smaller faster version
    of <span class="smallcaps-auto">GPT</span> with similar performance.]</p><p>"We train Distil<span class="smallcaps-auto">GPT</span> on eight 16GB V100
    <span class="smallcaps-auto">GPT</span>s for approximately three and a half days using the concatenation of Toronto
    Book Corpus and English Wikipedia (same data as original <span class="smallcaps-auto">GPT</span>)…As shown in the
    following table, Distil<span class="smallcaps-auto">GPT</span>’s performances compare favorably with the baselines
    while having respectively about half and one third the number of parameters (more
    on this below). Among the 9 tasks, Distil<span class="smallcaps-auto">GPT</span> is always on par or improving over
    the <span class="smallcaps-auto">GPT</span>o baseline (up to 14 points of accuracy on <span class="smallcaps-auto">GPT</span>). Distil<span class="smallcaps-auto">GPT</span> also compares
    surprisingly well to <span class="smallcaps-auto">GPT</span>: we are able to retain more than 95% of the performance
    while having 40% fewer parameters. In terms of inference time, Distil<span class="smallcaps-auto">GPT</span> is more
    than 60% faster and smaller than <span class="smallcaps-auto">GPT</span> and 120% faster and smaller than <span class="smallcaps-auto">GPT</span>o+Bi<span class="smallcaps-auto">GPT</span>."</p>'
- - https://www.outsideonline.com/1925841/inside-look-surprisingly-violent-quidditch-world-cup
  - An Inside Look at the Surprisingly Violent Quidditch World Cup
  - Eric Hansen (Outside)
  - 2012-05-04
  - ''
  - ! '<p>The Quidditch World Cup sounds dorky, and make no mistake: it is. But these
    sorcery-loving Harry Potter fans play pretty rough, as Eric Hansen found out when
    he captained a bad-news team of ex-athletes, ultimate Frisbee studs, slobs, drunks,
    and some people he knows from Iceland. Brooms up, and may the best Muggles win.</p><p>…But
    there were portents of violence, like when I spoke to a longtime player who gave
    me strange-sounding advice that I relayed to the team. “‘Hide your girls?’” Josh
    kept asking. “What does that even mean?”</p><p>…“Drepa, drepa, drekka blód!”
    we shouted, thinking then that “Kill, kill, drink blood” was the height of irony.</p><p>…A
    goalie—the keeper—guards his team’s hula-hoops, usually by swatting the quaffle
    out of the air with his hand. Or so we thought…I try, but he barges past with
    the flailing arms and unblinking eyes of a proper Potter psycho. For reasons unknown,
    just shy of our goal the bastard chooses to ignore the hoops and instead clobbers
    my wife, Hrund, who isn’t even in the game.</p><p>I see the whole episode from
    just inches away, a dirty lock of his hair waving in my face as I sprint behind
    him. One moment she’s relaxing on the sideline, looking away, not even holding
    a broom. The next, this freak lowers his non-broom-carrying shoulder and blasts
    her in the sternum. The impact sends her flying through the dusky air, nearly
    completing a full back layout before landing on her head.</p><p>…I didn’t catch
    a whiff of the terrifying stench of Quid Kid hostility until I ambled out into
    the parking lot at the south gate and ended up chatting with a tired ambulance
    driver who was having a smoke. He was one of 30 <span class="smallcaps-auto">EMT</span>s posted at the event. “Easy
    duty,” I said. “This is just the quiet before another storm,” he corrected. “I’ve
    had eight concussions, two people taken to the hospital, bloody noses, scrapes,
    twisted ankles. I stopped counting injuries after 10.” My teammates weren’t as
    surprised by these stats as I expected. One recalled stopping a young female chaser
    just short of the goal, only to have the girl yell an extremely unprintable comment.
    Another teammate recalled watching a man in Division 1 lift a girl, spin her like
    the blades of a helicopter, and throw her to the dirt. The violence was not only
    pervasive but gender neutral. Hide your girls, indeed.</p>'
- - /docs/psychology/2013-hurlburt.pdf
  - Toward a phenomenology of inner speaking
  - Russell T. Hurlburt, Christopher L. Heavey, Jason M. Kelsey
  - 2013-12-01
  - 10.1016/j.concog.2013.10.003
  - ! '<p><em>Highlights</em>:</p><ul><li>Inner speaking is a common but not ubiquitous
    phenomenon of inner experience.</li><li>There are large individual differences
    in the frequency of inner speaking (from near 0% to near 100%).</li><li>There
    is substantial variability in the phenomenology of naturally occurring moments
    of inner speaking.</li><li>Use of an appropriate method is critical to the study
    of inner experience.</li><li>Descriptive Experience Sampling is designed to apprehend
    high fidelity descriptions of inner experience.</li></ul><p><em>Abstract</em>:
    Inner speaking is a common and widely discussed phenomenon of inner experience.
    Based on our studies of inner experience using Descriptive Experience Sampling
    (a qualitative method designed to produce high fidelity descriptions of randomly
    selected pristine inner experience), we advance an initial phenomenology of inner
    speaking. Inner speaking does occur in many, though certainly not all, moments
    of pristine inner experience. Most commonly it is experienced by the person as
    speaking in his or her own naturally inflected voice but with no sound being produced.
    In addition to prototypical instances of inner speaking, there are wide-ranging
    variations that fit the broad category of inner speaking and large individual
    differences in the frequency with which individuals experience inner speaking.
    Our observations are discrepant from what many have said about inner speaking,
    which we attribute to the characteristics of the methods different researchers
    have used to examine inner speaking.</p>'
- - http://www.bbc.com/future/story/20190819-what-your-inner-voice-says-about-you
  - ! 'What the voice inside your head says about you: We tend to assume that our
    internal monologue ''speaks'' in words---but it turns out that, for many of us,
    it’s much more complicated'
  - Kelly Oakes (<span class="smallcaps-auto">BBC</span>)
  - 2019-08-20
  - ''
  - ! '<p>Psychologist Russell Hurlburt at the University of Nevada, Las Vegas, has
    spent the last few decades training people to see inside their own minds more
    clearly in an attempt to learn something about our inner experiences at large.
    Though many individual studies on inner speech include only a small number of
    participants, making it hard to know whether their results apply more widely,
    Hurlburt estimates he’s been able to peek inside the minds of hundreds of people
    since he began his research. What he’s found suggests that the thoughts running
    through our heads are a lot more varied than we might suppose.</p><p>For one,
    words don’t seem to feature as heavily in our day-to-day thoughts as many of us
    think they do. “Most people think that they think in words, but many people are
    mistaken about that,” he says. In one small study, for example, <a href="http://hurlburt.faculty.unlv.edu/brouwers--hurlburt%202018.pdf"
    title="&#39;Pristine Inner Experience while Silent Reading: It’s *Not* Silent
    Speaking of the Text&#39;, Brouwers et al 2018">16 college students were given
    short stories before being randomly sampled</a> to find out what they were thinking
    during the course of reading. Only a quarter of their sampled thoughts featured
    words at all, and just 3% involved internal narration.</p><p>…If people aren’t
    constantly talking to themselves, what are they doing?</p><p>In his years of studying
    the inner workings of people’s minds, Hurlburt has come up with five categories
    of inner experiences: inner speaking, which comes in a variety of forms; inner
    seeing, which could feature images of things you’ve seen in real life or imaginary
    visuals; feelings, such as anger or happiness; sensory awareness, like being aware
    of the scratchiness of the carpet under your feet; and unsymbolised thinking,
    a trickier concept to get your head around, but essentially a thought that doesn’t
    manifest as words or images, but is undoubtedly present in your mind. But those
    categories leave room for variation, too. Take inner speaking, which can come
    in the form of a single word, a sentence, some kind of monologue, or even a conversation.
    The idea of an internal dialogue—rather than a monologue—will be familiar to anyone
    who’s ever rehearsed an important conversation, or rehashed an argument, in their
    mind. But the person we talk to inside our head is not always a stand in for someone
    else—often, that other voice is another aspect of ourselves.</p><p>…Famira Racy,
    co-ordinator of the Inner Speech Lab at Mount Royal University, Canada, and her
    colleagues recently used a method called thought listing—which, unsurprisingly,
    involves getting participants to list their thoughts at certain times—to take
    a broader look at <a href="/docs/psychology/2019-famira.pdf"
    title="&#39; Using a Thought Listing Procedure to Construct the General Inner
    Speech Questionnaire: An Ecological Approach&#39;, Racy et al 2019">why and when
    people use inner speech, as well as what they say to themselves.</a></p><p>They
    found that the students in the study were talking to themselves about everything
    from school to their emotions, other people, and themselves, while they were doing
    everyday tasks like walking and getting in and out of bed. Though it has the same
    limitations as much research on inner speech—namely, you can’t always trust people
    to know what or how they were really thinking—the results appear consistent with
    previous work.</p><p>“I can’t say for sure if it’s any more important [than other
    kinds of inner experience], but there’s been enough research done to show that
    inner speech plays an important role in self-regulation behaviour, problem solving,
    critical thinking and reasoning and future thinking,” Racy says…“It gives you
    a way to communicate with yourself using a meaningful structure,” says Racy. Or
    as one of her colleagues sometimes puts it: “Inner speech is your flashlight in
    the dark room that is your mind.”</p>'
- - https://openai.com/blog/gpt-2-6-month-follow-up/
  - ! '<span class="smallcaps-auto">GPT</span>-2: 6-Month Follow-Up'
  - OpenAI
  - 2019-08-20
  - ''
  - <p>We’re releasing the 774 million parameter <span class="smallcaps-auto">GPT</span>-2 language model after the release
    of our small 124M model in February, staged release of our medium 355M model in
    May, and subsequent research with partners and the AI community into the model’s
    potential for misuse and societal benefit. We’re also releasing an open-source
    legal agreement to make it easier for organizations to initiate model-sharing
    partnerships with each other, and are publishing a technical report about our
    experience in coordinating with the wider AI research community on publication
    norms.</p><p>…Research from these partners will factor into our future release
    decisions, as will observing how the 774M model is used, and discussing language
    models with researchers and policymakers to understand the considerations around
    larger models. As part of our staged release strategy, our current plan is to
    release the 1558M parameter model in a few months, but it’s plausible that findings
    from a partner, or malicious usage of our 774M model, could change this.</p>
- - /docs/iq/1987-simonton.pdf
  - Developmental antecedents of achieved eminence
  - Dean Keith Simonton
  - '1987'
  - ''
  - ! '<p>[Literature review of Simonton & other''s research into life history predictors
    of great accomplishment in the arts/sciences/politics/etc, particularly childhood:
    what variables seem to correlate with later eminence? Simonton discusses as predictors:
    1. intelligence; 2. birth order (first-born); 3. extreme motivation/drive; 3.
    parental loss/orphanhood (!); 4. a previous generation of role models to imitate;
    5. formal education (or lack thereof); 6. global circumstances/''zeitgeist''.</p><p>On
    nature-nurture, Simonton deprecates the role of genetics, arguing that genius
    counts fluctuate too much and are too sporadic over time to reflect primarily
    genetics, but see Lykken et al on ''emergenesis'', dysgenics, and tail effects
    in order statistics (especially the Lotka curve/log-normal distribution Simonton
    is so familiar with) for why this argument is weak.]</p>'
- - https://warontherocks.com/2019/08/lets-not-make-a-deal-geopolitics-and-greenland/
  - ! 'Let''s (Not) Make a Deal: Geopolitics and Greenland'
  - Jon Rahbek-Clemmensen (War on the Rocks)
  - 2019-08-28
  - ''
  - As is often the case, the truth lies somewhere in between these extremes. Trump’s
    offer to buy Greenland is not a wild-eyed fluke. Instead, it reflects a steadily
    increasing American interest in Greenland that is spurred by fear of Chinese and
    Russian encroachments. At the same time, however, a quest to purchase Greenland
    is not the optimal way to achieve American security interests, as it is unlikely
    to succeed, and even if it did, it would be far more expensive than other, more
    sensible approaches. Instead, the United States should engage with Denmark and
    Greenland to find common ground on shared concerns…Instead of offering to buy
    Greenland, the United States should pursue an engagement strategy that combines
    targeted concessions with clever diplomacy to get the Danes and Greenlanders to
    cooperate. Luckily, if approached correctly, both nations are very interested
    in supporting U.S. security interests, as they are broadly shared—especially in
    Copenhagen. The key will be to see this not as a zero-sum game, but as a win-win-win
    situation.
- - https://www.vulture.com/2019/08/spottedrisk-scandal-insurance-hollywood.html
  - Can You Indemnify Against Dick Pics? The rise of scandal insurance in Hollywood
  - Boris Kachka
  - 2019-08-05
  - ''
  - ! '<p>A standard Lloyd’s contract defined disgrace in vague terms—as “any criminal
    act, or any offence against public taste or decency … which degrades or brings
    that person into disrepute or provokes insult or shock to the community.” Most
    effective policies rely on precise terms and evidence that both sides can agree
    on—the Richter scale, a hospital bill. Subjective wording leads to disputes. Insurance
    “has to involve no litigation,” says Bill Hubbard, <span class="smallcaps-auto">CEO</span> of the entertainment insurer
    <span class="smallcaps-auto">HCC</span> Specialty Group. “You know the Supreme Court justice who said, ‘I know pornography
    when I see it’? You can’t settle claims that way.”</p><p>The contracts were much
    clearer on the definition of what <em>didn’t</em> merit a payout: Many of them
    exempted non-felonious offenses and acts committed prior to the policy’s start
    date. Even if the <em>All the Money</em> producers had bought a policy, Spacey’s
    past transgressions might have been excluded, treated as preexisting conditions.</p><p>While
    these limitations kept the industry small, the foibles of the rich and famous
    only increased demand for a better product. Tiger Woods’s 2009 car crash, followed
    by revelations of his infidelities, cost him $22 million in contracts with brands
    like AT&amp;T and Gatorade—which was nothing compared to what they cost the companies.
    A UC Davis study put the brands’ shareholder losses somewhere between $5 billion
    and $12 billion.</p><p>But it wasn’t Woods who made disgrace insurance look viable;
    it was reality television. A few months before the golfer’s car crash came what
    one underwriter refers to only as “that Viacom loss.” Ryan Jenkins, then a contestant
    on the VH1 reality show <em>Megan Wants a Millionaire</em> and the star of an
    upcoming season of <em>I Love Money</em>, became the lead suspect in his wife’s
    murder and killed himself a few days later. <em>Megan</em> was canceled after
    three episodes and the <em>Money</em> season shelved entirely, costing Viacom
    seven figures in losses. That’s when the company started buying disgrace insurance.</p><p>Thousands
    of reality shows have been insured in the ensuing decade, many of them via two
    insurance brokers, Gallagher Entertainment and <span class="smallcaps-auto">HUB</span> International. <span class="smallcaps-auto">HUB</span>’s managing
    director, Bob Jellen, can recall about half a dozen claims paying out since the
    Jenkins murder. He wouldn’t offer specifics, but others have given two examples:
    <em>P.I. Moms</em>, which was canceled in 2011 following fraud and drug charges,
    and Spike TV’s <em>Bar Rescue</em>, after an owner killed a country singer in
    his own rescued bar. “It’s something we don’t advertise,” says Jellen of disgrace
    insurance. “You don’t have to sell people on disgrace.”</p>'
- - /docs/psychology/2017-mercier.pdf
  - How Gullible are We? A Review of the Evidence from Psychology and Social Science
  - Hugo Mercier
  - 2017-05-18
  - 10.1037/gpr0000111
  - ! '<p>A long tradition of scholarship, from ancient Greece to Marxism or some
    contemporary social psychology, portrays humans as strongly gullible—wont to accept
    harmful messages by being unduly deferent. However, if humans are reasonably well
    adapted, they should not be strongly gullible: they should be vigilant toward
    communicated information. Evidence from experimental psychology reveals that humans
    are equipped with well-functioning mechanisms of epistemic vigilance. They check
    the plausibility of messages against their background beliefs, calibrate their
    trust as a function of the source’s competence and benevolence, and critically
    evaluate arguments offered to them. Even if humans are equipped with well-functioning
    mechanisms of epistemic vigilance, an adaptive lag might render them gullible
    in the face of new challenges, from clever marketing to omnipresent propaganda.
    I review evidence from different cultural domains often taken as proof of strong
    gullibility: religion, demagoguery, propaganda, political campaigns, advertising,
    erroneous medical beliefs, and rumors. Converging evidence reveals that communication
    is much less influential than often believed—that religious proselytizing, propaganda,
    advertising, and so forth are generally not very effective at changing people’s
    minds. Beliefs that lead to costly behavior are even less likely to be accepted.
    Finally, it is also argued that most cases of acceptance of misguided communicated
    information do not stem from undue deference, but from a fit between the communicated
    information and the audience’s preexisting beliefs.</p><p>[Keywords: epistemic
    vigilance, gullibility, trust]</p>'
- - https://www.youtube.com/watch?v=HEqQ2_1XRTs
  - ! 'Reinforcement Learning for Recommender Systems: A Case Study on Youtube'
  - Minmin Chen
  - 2019-03-28
  - ''
  - While reinforcement learning (RL) has achieved impressive advances in games and
    robotics, it has not been widely adopted in recommender systems. Framing recommendation
    as an RL problem offers new perspectives, but also faces significant challenges
    in practice. Industrial recommender systems deal with extremely large action spaces—many
    millions of items to recommend and complex user state spaces—billions of users,
    who are unique at any point in time. In this talk, I will discuss our work on
    scaling up a policy-gradient-based algorithm, i.e. <span class="smallcaps-auto">REINFORCE</span> to a production recommender
    system at Youtube. We proposed algorithms to address data biases when deriving
    policy updates from logged implicit feedback. I will also discuss some follow
    up work and outstanding research questions in applying RL, in particular off-policy
    optimization in recommender systems. [33m:16s; with slides]
- - /docs/rl/2016-graves.pdf
  - Hybrid computing using a neural network with dynamic external memory
  - Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka
    Grabska-Barwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho,
    John Agapiou, Adrià Puigdomènech Badia, Karl Moritz Hermann, Yori Zwols, Georg
    Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray
    Kavukcuoglu, Demis Hassabis
  - 2016-10-27
  - 10.1038/nature20101
  - Artificial neural networks are remarkably adept at sensory processing, sequence
    learning and reinforcement learning, but are limited in their ability to represent
    variables and data structures and to store data over long timescales, owing to
    the lack of an external memory. Here we introduce a machine learning model called
    a differentiable neural computer (<span class="smallcaps-auto">DNC</span>), which consists of a neural network that
    can read from and write to an external memory matrix, analogous to the random-access
    memory in a conventional computer. Like a conventional computer, it can use its
    memory to represent and manipulate complex data structures, but, like a neural
    network, it can learn to do so from data. When trained with supervised learning,
    we demonstrate that a <span class="smallcaps-auto">DNC</span> can successfully answer synthetic questions designed
    to emulate reasoning and inference problems in natural language. We show that
    it can learn tasks such as finding the shortest path between specified points
    and inferring the missing links in randomly generated graphs, and then generalize
    these tasks to specific graphs such as transport networks and family trees. When
    trained with reinforcement learning, a <span class="smallcaps-auto">DNC</span> can complete a moving blocks puzzle
    in which changing goals are specified by sequences of symbols. Taken together,
    our results demonstrate that <span class="smallcaps-auto">DNC</span>s have the capacity to solve complex, structured
    tasks that are inaccessible to neural networks without external read–write memory.
- - /docs/rl/2016-silver.pdf
  - Mastering the game of Go with deep neural networks and tree search
  - David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George
    van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam,
    Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya
    Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel,
    Demis Hassabis
  - 2016-01-28
  - 10.1038/nature16961
  - The game of Go has long been viewed as the most challenging of classic games for
    artificial intelligence owing to its enormous search space and the difficulty
    of evaluating board positions and moves. Here we introduce a new approach to computer
    Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’
    to select moves. These deep neural networks are trained by a novel combination
    of supervised learning from human expert games, and reinforcement learning from
    games of self-play. Without any lookahead search, the neural networks play Go
    at the level of state-of-the-art Monte Carlo tree search programs that simulate
    thousands of random games of self-play. We also introduce a new search algorithm
    that combines Monte Carlo simulation with value and policy networks. Using this
    search algorithm, our program AlphaGo achieved a 99.8% winning rate against other
    Go programs, and defeated the human European Go champion by 5 games to 0. This
    is the first time that a computer program has defeated a human professional player
    in the full-sized game of Go, a feat previously thought to be at least a decade
    away.
- - https://geneticsexbehavior.info/wp-content/uploads/2019/08/ganna190830.pdf
  - Large-scale <span class="smallcaps-auto">GWAS</span> reveals insights into the genetic architecture of same-sex sexual
    behavior
  - Andrea Ganna, Karin J. H. Verweij, Michel G. Nivard, Robert Maier, Robbee Wedow,
    Alexander S. Busch, Abdel Abdellaoui, Shengru Guo, J. Fah Sathirapongsasuti, 23andMe
    Research Team, Paul Lichtenstein, Sebastian Lundström, Niklas Långström, Adam
    Auton, Kathleen Mullan Harris, Gary W. Beecham, Eden R. Martin, Alan R. Sanders,
    John R. B. Perry, Benjamin M. Neale, Brendan P. Zietsch
  - 2019-08-29
  - 10.1126/science.aat7693
  - ! '<p>Twin studies and other analyses of inheritance of sexual orientation in
    humans has indicated that same-sex sexual behavior has a genetic component. Previous
    searches for the specific genes involved have been underpowered and thus unable
    to detect genetic signals. Ganna et al. perform a genome-wide association study
    on 493,001 participants from the United States, the United Kingdom, and Sweden
    to study genes associated with sexual orientation (see the Perspective by Mills).
    They find multiple loci implicated in same-sex sexual behavior indicating that,
    like other behavioral traits, nonheterosexual behavior is polygenic.</p><p><strong>Introduction</strong>:
    Across human societies and in both sexes, some 2 to 10% of individuals report
    engaging in sex with same-sex partners, either exclusively or in addition to sex
    with opposite-sex partners. Twin and family studies have shown that same-sex sexual
    behavior is partly genetically influenced, but previous searches for the specific
    genes involved have been underpowered to detect effect sizes realistic for complex
    traits.</p><p><strong>Rationale</strong>: For the first time, new large-scale
    datasets afford sufficient statistical power to identify genetic variants associated
    with same-sex sexual behavior (ever versus never had a same-sex partner), estimate
    the proportion of variation in the trait accounted for by all variants in aggregate,
    estimate the genetic correlation of same-sex sexual behavior with other traits,
    and probe the biology and complexity of the trait. To these ends, we performed
    genome-wide association discovery analyses on 477,522 individuals from the United
    Kingdom and United States, replication analyses in 15,142 individuals from the
    United States and Sweden, and follow-up analyses using different aspects of sexual
    preference.</p><p><strong>Results</strong>: In the discovery samples (UK Biobank
    and 23andMe), 5 autosomal loci were significantly associated with same-sex sexual
    behavior. Follow-up of these loci suggested links to biological pathways that
    involve sex hormone regulation and olfaction. 3 of the loci were significant in
    a meta-analysis of smaller, independent replication samples. Although only a few
    loci passed the stringent statistical corrections for genome-wide multiple testing
    and were replicated in other samples, our analyses show that many loci underlie
    same-sex sexual behavior in both sexes. In aggregate, all tested genetic variants
    accounted for 8 to 25% of variation in male and female same-sex sexual behavior,
    and the genetic influences were positively but imperfectly correlated between
    the sexes [genetic correlation coefficient (<em>r<sub>g</sub></em>)= 0.63; 95%
    confidence intervals, 0.48 to 0.78]. These aggregate genetic influences partly
    overlapped with those on a variety of other traits, including externalizing behaviors
    such as smoking, cannabis use, risk-taking, and the personality trait “openness
    to experience.” Additional analyses suggested that sexual behavior, attraction,
    identity, and fantasies are influenced by a similar set of genetic variants (<em>r<sub>g</sub></em>
    &gt; 0.83); however, the genetic effects that differentiate heterosexual from
    same-sex sexual behavior are not the same as those that differ among nonheterosexuals
    with lower versus higher proportions of same-sex partners, which suggests that
    there is no single continuum from opposite-sex to same-sex preference.</p><p><strong>Conclusion</strong>:
    Same-sex sexual behavior is influenced by not one or a few genes but many. Overlap
    with genetic influences on other traits provides insights into the underlying
    biology of same-sex sexual behavior, and analysis of different aspects of sexual
    preference underscore its complexity and call into question the validity of bipolar
    continuum measures such as the Kinsey scale. Nevertheless, many uncertainties
    remain to be explored, including how sociocultural influences on sexual preference
    might interact with genetic influences. To help communicate our study to the broader
    public, we organized workshops in which representatives of the public, activists,
    and researchers discussed the rationale, results, and implications of our study.</p>'
- - /docs/ai/2019-gervais.pdf
  - The Machine As Author
  - Daniel J. Gervais
  - 2019-03-24
  - ''
  - ! 'The use of Artificial Intelligence (AI) machines using deep learning neural
    networks to create material that facially looks like it should be protected by
    copyright is growing exponentially. From articles in national news media to music,
    film, poetry and painting, AI machines create material that has economic value
    and that competes with productions of human authors. The Article reviews both
    normative and doctrinal arguments for and against the protection by copyright
    of literary and artistic productions made by AI machines. The Article finds that
    the arguments in favor of protection are flawed and unconvincing and that a proper
    analysis of the history, purpose, and major doctrines of copyright law all lead
    to the conclusion that productions that do not result from human creative choices
    belong to the public domain. The Article proposes a test to determine which productions
    should be protected, including in case of collaboration between human and machine.
    Finally, the Article applies the proposed test to three specific fact patterns
    to illustrate its application. [Keywords: copyright, author, artificial intelligence,
    machine learning]'
- - /docs/anime/2015-saito.pdf
  - ! '<code>Illustration2Vec</code>: a semantic vector representation of illustrations'
  - Saito Masaki, Yusuke Matsui
  - 2015-11-02
  - 10.1145/2820903.2820907
  - ! 'Referring to existing illustrations helps novice drawers to realize their ideas.
    To find such helpful references from a large image collection, we first build
    a semantic vector representation of illustrations by training convolutional neural
    networks. As the proposed vector space correctly reflects the semantic meanings
    of illustrations, users can efficiently search for references with similar attributes.
    Besides the search with a single query, a <em>semantic morphing</em> algorithm
    that searches the intermediate illustrations that gradually connect two queries
    is proposed. Several experiments were conducted to demonstrate the effectiveness
    of our methods. [Keywords: illustration, <span class="smallcaps-auto">CNN</span>s, visual similarity, search]'
- - /docs/statistics/decision/1960-kelley.pdf
  - Gradient Theory of Optimal Flight Paths
  - Henry J. Kelley
  - 1960-10-01
  - 10.2514/8.5282
  - An analytical development of flight performance optimization according to the
    method of gradients or 'method of steepest decent' is presented. Construction
    of a minimizing sequence of flight paths by a stepwise process of descent along
    the local gradient direction is described as a computational scheme. Numerical
    application of the technique is illustrated in a simple example of orbital transfer
    via solar sail propulsion. Successive approximations to minimum time planar flight
    paths from Earth's orbit to the orbit of Mars are presented for cases corresponding
    to free and fixed boundary conditions on terminal velocity components.
- - /docs/ai/1962-bryson.pdf
  - A Steepest-Ascent Method for Solving Optimum Programming Problems
  - A. E. Bryson, W. F. Denham
  - 1962-06-01
  - 10.1115/1.3640537
  - ! '<p>A systematic and rapid steepest-ascent numerical procedure is described
    for solving two-point boundary-value problems in the calculus of variations for
    systems governed by a set of nonlinear ordinary differential equations. Numerical
    examples are presented for minimum time-to-climb and maximum altitude paths for
    a supersonic interceptor and maximum-range paths for an orbital glider. [Keywords:
    Boundary-value problems, Computer programming, Differential equations, Variational
    techniques]</p><p>…A systematic and rapid steepest-ascent numerical procedure
    is described for determining optimum programs for nonlinear systems with terminal
    constraints. The procedure uses the concept of local linearization around a nominal
    (non-optimum) path. The effect on the terminal conditions of a small change in
    the control variable program is determined by numerical integration of the adjoint
    differential equations for small perturbations about the nominal path. Having
    these adjoint (or influence) functions, it is then possible to determine the change
    in the control variable program that gives maximum increase in the pay-off function
    for a given mean-square perturbation of the control variable program while simultaneously
    changing the terminal quantities by desired amounts. By repeating this process
    in small steps, a control variable program that minimizes one quantity and yields
    specified values of other terminal quantities can be approached as closely as
    desired. Three numerical examples are presented: (<em>a</em>) The angle-of-attack
    program for a typical supersonic interceptor to climb to altitude in minimum time
    is determined with and without specified terminal velocity and heading. (<em>b</em>)
    The angle-of-attack program for the same interceptor to climb to maximum altitude
    is determined, (<em>c</em>) The angle-of-attack program is determined for a hypersonic
    orbital glider to obtain maximum surface range starting from satellite speed at
    300,000 ft altitude.</p>'
- - /docs/traffic/2015-lewis.pdf
  - The Unfavorable Economics of Measuring the Returns to Advertising
  - Randall A. Lewis, Justin M. Rao
  - 2015-07-06
  - 10.1093/qje/qjv023
  - Twenty-five large field experiments with major U.S. retailers and brokerages,
    most reaching millions of customers and collectively representing $2.8 million
    in digital advertising expenditure, reveal that measuring the returns to advertising
    is difficult. The median confidence interval on return on investment is over 100
    percentage points wide. Detailed sales data show that relative to the per capita
    cost of the advertising, individual-level sales are very volatile; a coefficient
    of variation of 10 is common. Hence, informative advertising experiments can easily
    require more than 10 million person-weeks, making experiments costly and potentially
    infeasible for many firms. Despite these unfavorable economics, randomized control
    trials represent progress by injecting new, unbiased information into the market.
    The inference challenges revealed in the field experiments also show that selection
    bias, due to the targeted nature of advertising, is a crippling concern for widely
    employed observational methods.
- - /docs/sociology/2014-flyvbjerg.pdf
  - ! 'What You Should Know About Megaprojects and Why: An Overview'
  - Bent Flyvbjerg
  - 2014-04-07
  - 10.1002/pmj.21409
  - ! 'This paper takes stock of megaproject management, an emerging and hugely costly
    field of study. First, it answers the question of how large megaprojects are by
    measuring them in the units mega, giga, and tera, concluding we are presently
    entering a new "tera era" of trillion-dollar projects. Second, total global megaproject
    spending is assessed, at <span class="smallcaps-auto">USD</span> 6-9 trillion annually, or 8 percent of total global
    <span class="smallcaps-auto">GDP</span>, which denotes the biggest investment boom in human history. Third, four "sublimes"
    —political, technological, economic, and aesthetic—are identified to explain
    the increased size and frequency of megaprojects. Fourth, the "iron law of megaprojects"
    is laid out and documented: Over budget, over time, over and over again. Moreover,
    the "break-fix model" of megaproject management is introduced as an explanation
    of the iron law. Fifth, Albert O. Hirschman''s theory of the Hiding Hand is revisited
    and critiqued as unfounded and corrupting for megaproject thinking in both the
    academy and policy. Sixth, it is shown how megaprojects are systematically subject
    to "survival of the unfittest," explaining why the worst projects get built instead
    of the best. Finally, it is argued that the conventional way of managing megaprojects
    has reached a "tension point," where tradition is challenged and reform is emerging.'
- - https://psyarxiv.com/g4x6r/
  - Low Base Rates Prevented Terman from Identifying Future Nobelists
  - Russell Warne, Ross Larsen, Jonathan Clark
  - 2019-08-28
  - 10.31234/osf.io/g4x6r
  - Although the accomplishments of the 1,528 subjects of the Genetic Studies of Genius
    are impressive, they do not represent the pinnacle of human achievement. Since
    the early 1990s, commentators (e.g., Bond, 2014; Gladwell, 2006; Heilman, 2016;
    Shurkin, 1992) have drawn attention to the fact that two future Nobelists—William
    Shockley and Luis Alvarez—were among the 168,000 candidates screened for the study;
    but they were rejected because their IQ scores were too low. Critics see this
    as a flaw of Terman’s methodology and/or intelligence testing. However, events
    with a low base rate (such as winning a Nobel prize) are difficult to predict
    (Taylor & Russell, 1939). This study simulates the Terman’s sampling procedure
    to estimate the probability that Terman’s sampling procedure would have selected
    one or both future Nobelists from a population of 168,000 candidates. Using data
    simulations, we created a model that realistically reflected the test-retest and
    split-half reliability of the IQ scores used to select individuals for the Genetic
    Studies of Genius and the relationship between IQ and Nobelist status. Results
    showed that it was unlikely for Terman to identify children who would later earn
    Nobel prizes, mostly due to the low base rates of such high future achievement
    and the high minimum IQ needed to be selected for Terman’s study. Changes to the
    methodology that would have been required to select one or both Nobelists for
    the longitudinal study were not practical. Therefore, Alvarez’s and Shockley’s
    absence from the Genetic Studies of Genius sample does not invalidate intelligence
    testing or Terman’s landmark study.
- - /docs/genetics/heritable/2015-polderman.pdf
  - Meta-analysis of the heritability of human traits based on fifty years of twin
    studies
  - Tinca J. C. Polderman, Beben Benyamin, Christiaan A. de Leeuw, Patrick F. Sullivan,
    Arjen van Bochoven, Peter M. Visscher, Danielle Posthuma
  - 2015-05-18
  - 10.1038/ng.3285
  - Despite a century of research on complex traits in humans, the relative importance
    and specific nature of the influences of genes and environment on human traits
    remain controversial. We report a meta-analysis of twin correlations and reported
    variance components for 17,804 traits from 2,748 publications including 14,558,903
    partly dependent twin pairs, virtually all published twin studies of complex traits.
    Estimates of heritability cluster strongly within functional domains, and across
    all traits the reported heritability is 49%. For a majority (69%) of traits, the
    observed twin correlations are consistent with a simple and parsimonious model
    where twin resemblance is solely due to additive genetic variation. The data are
    inconsistent with substantial influences from shared environment or non-additive
    genetic variation. This study provides the most comprehensive analysis of the
    causes of individual differences in human traits thus far and will guide future
    gene-mapping efforts. All the results can be visualized using the Ma<span class="smallcaps-auto">TCH</span> webtool.
- - /docs/genetics/correlation/2016-belsky.pdf
  - ! 'The Genetics of Success: How Single-Nucleotide Polymorphisms Associated With
    Educational Attainment Relate to Life-Course Development'
  - Daniel W. Belsky, Terrie E. Moffitt, David L. Corcoran, Benjamin Domingue, HonaLee
    Harrington, Sean Hogan, Renate Houts, Sandhya Ramrakha, Karen Sugden, Benjamin
    S. Williams, Richie Poulton, Avshalom Caspi
  - 2016-06-01
  - 10.1177/0956797616643070
  - ! 'A previous genome-wide association study (<span class="smallcaps-auto">GWAS</span>) of more than 100,000 individuals
    identified molecular-genetic predictors of educational attainment. We undertook
    in-depth life-course investigation of the polygenic score derived from this <span class="smallcaps-auto">GWAS</span>
    using the four-decade Dunedin Study (N = 918). There were five main findings.
    First, polygenic scores predicted adult economic outcomes even after accounting
    for educational attainments. Second, genes and environments were correlated: Children
    with higher polygenic scores were born into better-off homes. Third, children’s
    polygenic scores predicted their adult outcomes even when analyses accounted for
    their social-class origins; social-mobility analysis showed that children with
    higher polygenic scores were more upwardly mobile than children with lower scores.
    Fourth, polygenic scores predicted behavior across the life course, from early
    acquisition of speech and reading skills through geographic mobility and mate
    choice and on to financial planning for retirement. Fifth, polygenic-score associations
    were mediated by psychological characteristics, including intelligence, self-control,
    and interpersonal skill. Effect sizes were small. Factors connecting <span class="smallcaps-auto">GWAS</span> sequence
    with life outcomes may provide targets for interventions to promote population-wide
    positive development. [Keywords: genetics, behavior genetics, intelligence, personality,
    adult development]'
- - /Danbooru2017
  - ! 'Danbooru2017: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset
    [replaced by Danbooru2018]'
  - Gwern Branwen
  - 2015-12-15
  - ''
  - Danbooru2017 was a large-scale anime image database with 2.9m+ images annotated
    with 77.5m+ tags; it can be useful for machine learning purposes such as image
    recognition and generation. It has been replaced by <a href="/Danbooru2018">Danbooru2018</a>,
    an updated and larger dataset.
- - https://www.nature.com/articles/mp2015225
  - Shared genetic aetiology between cognitive functions and physical and mental health
    in UK Biobank (<em>N</em>=112 151) and 24 <span class="smallcaps-auto">GWAS</span> consortia
  - S. P. Hagenaars, S. E. Harris, G. Davies, W. D. Hill, D. C. M. Liewald, S. J.
    Ritchie, R. E. Marioni, C. Fawns-Ritchie, B. Cullen, R. Malik, <span class="smallcaps-auto">GWAS</span> Consortium,
    International Consortium for Blood Pressure <span class="smallcaps-auto">GWAS</span>, SpiroMeta Consortium, <span class="smallcaps-auto">CHARGE</span>
    Consortium Pulmonary Group, <span class="smallcaps-auto">CHARGE</span> Consortium Aging and Longevity Group, B. B.
    Worrall, C. L. M. Sudlow, J. M. Wardlaw, J. Gallacher, J. Pell, A. M. McIntosh,
    D. J. Smith, C. R. Gale, Ian J. Deary
  - 2016-01-26
  - 10.1038/mp.2015.225
  - Causes of the well-documented association between low levels of cognitive functioning
    and many adverse neuropsychiatric outcomes, poorer physical health and earlier
    death remain unknown. We used linkage disequilibrium regression and polygenic
    profile scoring to test for shared genetic aetiology between cognitive functions
    and neuropsychiatric disorders and physical health. Using information provided
    by many published genome-wide association study consortia, we created polygenic
    profile scores for 24 vascular–metabolic, neuropsychiatric, physiological–anthropometric
    and cognitive traits in the participants of UK Biobank, a very large population-based
    sample (<em>N</em>=112 151). Pleiotropy between cognitive and health traits was
    quantified by deriving genetic correlations using summary genome-wide association
    study statistics and to the method of linkage disequilibrium score regression.
    Substantial and significant genetic correlations were observed between cognitive
    test scores in the UK Biobank sample and many of the mental and physical health-related
    traits and disorders assessed here. In addition, highly significant associations
    were observed between the cognitive test scores in the UK Biobank sample and many
    polygenic profile scores, including coronary artery disease, stroke, Alzheimer’s
    disease, schizophrenia, autism, major depressive disorder, body mass index, intracranial
    volume, infant head circumference and childhood cognitive ability. Where disease
    diagnosis was available for UK Biobank participants, we were able to show that
    these results were not confounded by those who had the relevant disease. These
    findings indicate that a substantial level of pleiotropy exists between cognitive
    abilities and many human mental and physical health disorders and traits and that
    it can be used to predict phenotypic variance across samples.
- - /docs/rl/2017-silver.pdf
  - Mastering the game of Go without human knowledge
  - David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang,
    Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen,
    Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel,
    Demis Hassabis
  - 2017-10-19
  - 10.1038/nature24270
  - ! 'A long-standing goal of artificial intelligence is an algorithm that learns,
    tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo
    became the first program to defeat a world champion in the game of Go. The tree
    search in AlphaGo evaluated positions and selected moves using deep neural networks.
    These neural networks were trained by supervised learning from human expert moves,
    and by reinforcement learning from self-play. Here we introduce an algorithm based
    solely on reinforcement learning, without human data, guidance or domain knowledge
    beyond game rules. AlphaGo becomes its own teacher: a neural network is trained
    to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games.
    This neural network improves the strength of the tree search, resulting in higher
    quality move selection and stronger self-play in the next iteration. Starting
    tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning
    100–0 against the previously published, champion-defeating AlphaGo.'
- - /docs/statistics/order/1947-elfving.pdf
  - The Asymptotical Distribution of Range in Samples from a Normal Population
  - G. Elfving
  - '1947'
  - 10.1093/biomet/34.1-2.111
  - ! '<p>Consider a sample of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation
    encoding="application/x-tex">n</annotation></semantics></math> observations,
    taken from an infinite normal population with the mean 0 and the standard deviation
    1. Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation
    encoding="application/x-tex">a</annotation></semantics></math> be the smallest
    and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation
    encoding="application/x-tex">b</annotation></semantics></math> the greatest
    of the observed values. Then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>=</mo><mi>b</mi><mo>−</mo><mi>a</mi></mrow><annotation
    encoding="application/x-tex">w = b − a</annotation></semantics></math> is the
    <em>range</em> of the sample. For certain statistical purposes knowledge of the
    sampling distribution of range is needed. The distribution function, however,
    involves a rather complicated integral, whose exact calculation is, for <math
    display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>&gt;</mo><mn>2</mn></mrow><annotation
    encoding="application/x-tex">n &gt; 2</annotation></semantics></math>, impossible…it
    seems to be at least of theoretical interest to investigate the asymptotical distribution
    of range for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>→</mo><mi>∞</mi></mrow><annotation
    encoding="application/x-tex">n \rightarrow \\infty</annotation></semantics></math>.
    This is the purpose of the present paper.</p>'
- - /docs/statistics/order/1999-chen.pdf
  - Accurate approximation to the extreme order statistics of Gaussian samples
  - Chien-Chung Chen, Christopher W. Tyler
  - '1999'
  - 10.1080/03610919908813542
  - <p>Evaluation of the integral properties of Gaussian Statistics is problematic
    because the Gaussian function is not analytically integrable. We show that the
    expected value of the greatest order statistics in Gaussian samples (the max distribution)
    can be accurately approximated by the expression Φ<sup>−1</sup>(0.5264<sup>1/<em>n</em></sup>),
    where <em>n</em> is the sample size and Φ<sup>−1</sup> is the inverse of the Gaussian
    cumulative distribution function. The expected value of the least order statistics
    in Gaussian samples (the min distribution) is correspondingly approximated by
    -Φ<sup>-1</sup>(0.5264<sup>1/<em>n</em></sup>). The standard deviation of both
    extreme order distributions can be approximated by the expression 0.5[Φ<sup>-1</sup>(0.8832<sup>1/<em>n</em></sup>)
    - Φ<sup>−1</sup>(0.2142<sup>1/<em>n</em></sup>)]. We also show that the probability
    density function of the extreme order distribution can be well approximated by
    gamma distributions with appropriate parameters. These approximations are accurate,
    computationally efficient, and readily implemented by build-in functions in many
    commercial mathematical software packages such as Matlab, Mathematica, and Excel.</p>
- - /docs/genetics/selection/2019-lopez.pdf
  - Genomic Evidence for Local Adaptation of Hunter-Gatherers to the African Rainforest
  - Marie Lopez, Jeremy Choin, Martin Sikora, Katherine Siddle, Christine Harmant,
    Helio A. Costa, Martin Silvert, Patrick Mouguiama-Daouda, Jean-Marie Hombert,
    Alain Froment, Sylvie Le Bomin, George H. Perry, Luis B. Barreiro, Carlos D. Bustamante,
    Paul Verdu, Etienne Patin, Lluís Quintana-Murci
  - 2019-08-08
  - 10.1016/j.cub.2019.07.013
  - ! '<p><em>Highlights</em>:</p><ul><li>A strong selective sweep at <em><span class="smallcaps-auto">TRPS</span>1</em>
    occurred in African rainforest hunter-gatherers</li><li>Pleiotropic height genes
    lead to polygenic selection signals for reproductive age</li><li>Pathogen-driven
    selection, mostly viral, has been pervasive among hunter-gatherers</li><li>Post-admixture
    selection has maintained adaptive variation in hunter-gatherers</li></ul><p><em>Summary</em>:
    African rainforests support exceptionally high biodiversity and host the world’s
    largest number of active hunter-gatherers [1, 2, 3]. The genetic history of African
    rainforest hunter-gatherers and neighboring farmers is characterized by an ancient
    divergence more than 100,000 years ago, together with recent population collapses
    and expansions, respectively [4, 5, 6, 7, 8, 9, 10, 11, 12]. While the demographic
    past of rainforest hunter-gatherers has been deeply characterized, important aspects
    of their history of genetic adaptation remain unclear. Here, we investigated how
    these groups have adapted—through classic selective sweeps, polygenic adaptation,
    and selection since admixture—to the challenging rainforest environments. To do
    so, we analyzed a combined dataset of 566 high-coverage exomes, including 266
    newly generated exomes, from 14 populations of rainforest hunter-gatherers and
    farmers, together with 40 newly generated, low-coverage genomes. We find evidence
    for a strong, shared selective sweep among all hunter-gatherer groups in the regulatory
    region of <em><span class="smallcaps-auto">TRPS</span>1</em>—primarily involved in morphological traits. We detect
    strong signals of polygenic adaptation for height and life history traits such
    as reproductive age; however, the latter appear to result from pervasive pleiotropy
    of height-associated genes. Furthermore, polygenic adaptation signals for functions
    related to responses of mast cells to allergens and microbes, the IL-2 signaling
    pathway, and host interactions with viruses support a history of pathogen-driven
    selection in the rainforest. Finally, we find that genes involved in heart and
    bone development and immune responses are enriched in both selection signals and
    local hunter-gatherer ancestry in admixed populations, suggesting that selection
    has maintained adaptive variation in the face of recent gene flow from farmers.
    [Keywords: natural selection, genetic adaptation, rainforest, height, immunity,
    hunter-gatherers, admixture, Africa, positive selection, polygenic adaptation]</p>'
- - /docs/technology/2019-kwong.pdf
  - ! 'Hard Drive of Hearing: Disks that Eavesdrop with a Synthesized Microphone'
  - Andrew Kwong, Wenyuan Xu, Kevin Fu
  - 2019-05-01
  - 10.1109/SP.2019.00008
  - Security conscious individuals may take considerable measures to disable sensors
    in order to protect their privacy. However, they often overlook the cyberphysical
    attack surface exposed by devices that were never designed to be sensors in the
    first place. Our research demonstrates that the mechanical components in magnetic
    hard disk drives behave as microphones with sufficient precision to extract and
    parse human speech. These unintentional microphones sense speech with high enough
    fidelity for the Shazam service to recognize a song recorded through the hard
    drive. This proof of concept attack sheds light on the possibility of invasion
    of privacy even in absence of traditional sensors. We also present defense mechanisms,
    such as the use of ultrasonic aliasing, that can mitigate acoustic eavesdropping
    by synthesized microphones in hard disk drives.
- - https://www.theatlantic.com/magazine/archive/2006/08/nightfall/305030/
  - Nightfall
  - Brad Leithauser
  - 2006-07-31
  - ''
  - <p>In Iceland, in early January,<br/>when dusk begins at dawn,<br/>alone in a
    wind-whipped shack,<br/>I kneel as though cowering<br/>before my little stove
    door.<br/>Nights are immense, and my coal is black<br/>as night.</p><p>A geologist<br/>in
    his lab might be able to say,<br/>within a million years or so, just<br/>when
    and where the coal’s towering<br/>source-plants were laid down;<br/>I only know,
    while waiting for<br/>the room to warm, it was very<br/>long ago, and far away.</p>
- - https://www.newcriterion.com/issues/2006/10/a-good-list
  - A good list
  - Brad Leithauser
  - 2006-10-01
  - ''
  - <p>Some nights, can’t sleep, I draw up a list,<br/>Of everything I’ve never done
    wrong.<br/>To look at me now, you might insist<br/>My list could hardly be long,<br/>But
    I’ve stolen no gnomes from my neighbor’s yard,<br/>Or struck his dog, backing
    out my car.<br/>Never ate my way up and down the Loire<br/>On a stranger’s credit
    card.<br/></p><p>I’ve never given a cop the slip,<br/>Stuffed stiffs in a gravel
    quarry,<br/>Or silenced Cub Scouts on a first camping trip<br/>With an unspeakable
    ghost story.<br/>Never lifted a vase from a museum foyer,<br/>Or rifled a Turkish
    tourist’s backpack.<br/>Never cheated at golf. Or slipped out a blackjack<br/>And
    flattened a patent lawyer.<br/></p><p>I never forged a lottery ticket,<br/>Took
    three on a two-for-one pass,<br/>Or, as a child, toasted a cricket<br/>With a
    magnifying glass.<br/>I never said “air” to mean “err,” or obstructed<br/>Justice,
    or defrauded a securities firm.<br/>Never mulcted—so far as I understand the term.<br/>Or
    unjustly usufructed.<br/></p><p>I never swindled a widow of all her stuff<br/>By
    means of a false deed and title<br/>Or stood up and shouted, <em>My God, that’s
    enough!</em><br/>At a nephew’s piano recital.<br/>Never practiced arson, even
    as a prank,<br/>Brightened church-suppers with off-color jokes,<br/>Concocted
    an archaeological hoax—<br/>Or dumped bleach in a goldfish tank.<br/></p><p>Never
    smoked opium. Or smuggled gold<br/>Across the Panamanian Isthmus.<br/>Never hauled
    back and knocked a rival out cold,<br/>Or missed a family Christmas.<br/>Never
    borrowed a book I <em>intended</em> to keep.<br/>… My list, once started, continues
    to grow,<br/>Which is all for the good, but just goes to show<br/>It’s the good
    who do not sleep.</p>
- - /docs/psychology/2018-brouwers.pdf
  - ! 'Pristine inner experience while silent reading: It’s <em>not</em> silent speaking
    of the text'
  - Vincent P. Brouwers, Christopher L. Heavey, Leiszle Lapping-Carr, Stefanie Moynihan,
    Jason Kelsey, Russell T. Hurlburt
  - 2018-01-01
  - ''
  - ! '<p>We used Descriptive Experience Sampling to explore the pristine inner experience
    of 16 college students while reading Fitzgerald and Hemingway short stories. We
    provide rich descriptions of the phenomena while reading. Visual imagery was frequent.
    Although many theorists presume the ubiquitous presence of an inner voice that
    narrates the text as it is read, we found that only about 3% of samples involved
    such inner narration. Words were experienced during about a quarter of all samples,
    including: a focus on specific words from the text (but which were not merely
    inner reading), words innerly spoken in response to the text (content was related
    to the text but not of the text itself), and innerly spoken unrelated words (apparently
    not connected to the text). We suggest that presuppositions account for others''
    overestimation of silent speech frequency, and discuss the impact of these findings
    on understanding reading and consciousness science.</p><p>[Keywords: Descriptive
    Experience Sampling; inner speaking; inner speech; iterative method; phenomenology;
    pristine inner experience; reading; silent reading]</p>'
- - /docs/psychology/2019-famira.pdf
  - ! 'Using a Thought Listing Procedure to Construct the General Inner Speech Questionnaire:
    An Ecological Approach'
  - Racy Famira, Morin Alain, Duhnych Christina
  - 2019-07-09
  - 10.1080/10720537.2019.1633572
  - ! 'The construction of existing self-report measures of inner speech is guided
    by a priori theoretical views regarding how it is experienced or what functions
    it serves. We present two studies aimed at constructing and validating a more
    ecologically valid tool called the General Inner Speech Questionnaire (<span class="smallcaps-auto">GISQ</span>).
    Study 1 employed an open-format thought-listing procedure inviting 227 participants
    to freely recall what they talk to themselves about in general. The most frequently
    self-generated inner speech instances were about negative emotions, problem solving/thinking,
    planning, self-motivating, emotional control, and self. In Study 2, we used this
    inner speech content to construct the 57-item <span class="smallcaps-auto">GISQ</span>. The <span class="smallcaps-auto">GISQ</span> is normally distributed,
    shows acceptable internal consistency, and contains four moderately strong factors:
    self-reflection, self-observation, cognition, and inner speech accompanying activities.
    Importantly, the <span class="smallcaps-auto">GISQ</span> correlates positively with other measures of inner speech
    and self-related process.'
- - /newsletter/2019/07#evangelion-3.0
  - ! 'Review: <em>Rebuild 3.0</em> (<em>Evangelion: 3.0 You Can (Not) Redo</em>)'
  - Gwern Branwen
  - 2019-07-31
  - ''
  - ! '[Review of the third <em>Rebuild</em> film. The long-delayed tetralogy, which
    now stretches over a decade of production, shows a lack of artistic vision or
    interest by anyone at Studio Khara, particularly director Hideaki Anno. It appears
    now to be a naked cash grab for launching a new studio with a guaranteed moneymaker.
    <em>3.0</em>, the last chance for <em>Rebuild</em> to redeem itself and deliver
    a satisfying whole, wastes its time with irrelevancies and fails to deliver on
    anything promised by Anno and Khara, lazily embracing the worst parts of the Evangelion
    style while destroying much of what was good about characters like Kaworu. It
    is the worst Evangelion film ever made, and so bad that it has largely destroyed
    my interest in the franchise.]'
- - https://wiki.evageeks.org/Episode_06
  - ! '<span class="smallcaps-auto">NGE</span> TV, Episode 6: "Showdown in Tokyo-3"/"Rei-3"'
  - EvaGeeks EvaWiki
  - ''
  - ''
  - Continuing from the previous episode, the Angel Ramiel is drilling down into the
    GeoFront to attack Nerv HQ directly. After Shinji barely survived a direct confrontation
    with it, Misato devises a plan to have Eva-00 and Eva-01 defeat the Angel by sniping
    it from a distance using a positron rifle which requires the total electric output
    of Japan to power up…Misato codenames the plan she creates to defeat the Angel
    Ramiel as "Operation Yashima". This is named after the <a href="https://en.wikipedia.org/wiki/Battle_of_Yashima">Battle
    of Yashima</a> which occurred in 1185 in medieval Japan, which also included a
    feat of conspicuously talented archery.
- - http://www.animenewsservice.com/archives-dec13/
  - ! '12-11-99: Japan Maritime Self-Defence Force Series Supervised By Hideaki Anno'
  - J-Dream Direct Newsletter, J-Dream Web
  - 1999-12-20
  - ''
  - ! 'The filming of Japan Self-Defense Force equipment and training, supervised
    by Gainax director, Hideaki Anno (Evangelion), is being released in Japan on LD
    and <span class="smallcaps-auto">DVD</span>. The first volume: “JUSDF FLEET POWER1 -Yokosuka- Japan Maritime Self-Defense
    Force” went on sale on Nov. 25<sup>th</sup>. The first volume includes scenes of carrier-based
    aircraft and asroc shooting and retails for 5800 Yen.'
- - /otaku#karekano-research
  - Please Listen To Me, Mr. Anno! Anno Hideaki X Highschool Boys & Girls [excerpts]
  - Hideaki Anno et al
  - '1998'
  - ''
  - In 1998, Hideaki Anno, prior to production of <em><a href="https://en.wikipedia.org/wiki/Kare_Kano">His
    and Her Circumstances</a></em>, engaged in a series of dialogues with students
    in several high schools (Toyoko Academy High School/Fujimi High School/Kanagawa
    Prefectural Ikuta High School/The Meiji University Associated Junior-High and
    High Schools of Nakano and Hachioji/Tokyo Toyama Public High School/Tokyo Nishi
    Public High School), which were published by the <em>Mainichi Intermediate-School
    News</em> and eventually translated & republished on the Gainax website. The dialogues
    are interesting because of the wide range of material discussed like contemporary
    politics.
- - https://www.newscientist.com/article/2208777-exclusive-five-couples-lined-up-for-crispr-babies-to-avoid-deafness/
  - ! 'Exclusive: Five couples lined up for <span class="smallcaps-auto">CRISPR</span> babies to avoid deafness'
  - Michael Le Page
  - 2019-07-04
  - ''
  - Five Russian couples who are deaf want to try the <span class="smallcaps-auto">CRISPR</span> gene-editing technique
    so they can have a biological child who can hear, biologist Denis Rebrikov has
    told New Scientist. He plans to apply to the relevant Russian authorities for
    permission in “a couple of weeks”…Both would-be parents in each couple have
    a recessive form of deafness, meaning that all their children would normally inherit
    the same condition. While the vast majority of genetic diseases can be prevented
    by screening <span class="smallcaps-auto">IVF</span> embryos before implantation, with no need for gene-editing, this
    is not an option for these couples. Several reports have suggested that—if it
    can be done safely—editing the genes of babies might be justified in this kind
    of situation…Now Rebrikov has told New Scientist that he also wants to prevent
    children inheriting a form of deafness caused by mutations in the <span class="smallcaps-auto">GJB</span>2 gene. In
    western Siberia, many people have a missing <span class="smallcaps-auto">DNA</span> letter in position 35 of the <span class="smallcaps-auto">GJB</span>2
    gene. Having one copy has no effect, but those who inherit this mutation from
    both parents never develop the ability to hear. Rebrikov has found five couples
    in which both would-be parents are deaf because of this mutation and don’t want
    their children to be deaf too. So he plans to use <span class="smallcaps-auto">CRISPR</span> to correct this mutation
    in <span class="smallcaps-auto">IVF</span> embryos from these couples. All these embryos will have the mutation in
    both copies of the <span class="smallcaps-auto">GJB</span>2 gene—correcting one copy using a method known as homology-directed
    repair will prevent deafness. “Technically, it is achievable,” says Burgio.
- - /docs/economics/2019-mckenzie.pdf
  - ! 'Predicting entrepreneurial success is hard: Evidence from a business plan competition
    in Nigeria'
  - David McKenzie, Dario Sansone
  - 2019-11-01
  - 10.1016/j.jdeveco.2019.07.002
  - ! 'We compare the absolute and relative performance of three approaches to predicting
    outcomes for entrants in a business plan competition in Nigeria: Business plan
    scores from judges, simple ad-hoc prediction models used by researchers, and machine
    learning approaches. We find that (i) business plan scores from judges are uncorrelated
    with business survival, employment, sales, or profits three years later; (ii)
    a few key characteristics of entrepreneurs such as gender, age, ability, and business
    sector do have some predictive power for future outcomes; (iii) modern machine
    learning methods do not offer noticeable improvements; (iv) the overall predictive
    power of all approaches is very low, highlighting the fundamental difficulty of
    picking competition winners.'
- - https://www.nonstopsystems.com/radio/pdf-hell/article-hell-patents-plunder.pdf
  - Secrets by the thousands
  - Charles Lester Walker (Harper's Magazine)
  - 1946-10-01
  - ''
  - ! '<p>Someone wrote to Wright Field recently, saying he understood this country
    had got together quite a collection of enemy war secrets, that many were now on
    public sale, and could he, please, be sent everything on German jet engines. The
    Air Documents Division of the Army Air Forces answered: “Sorry–but that would
    be fifty tons”. Moreover, that fifty tons was just a small portion of what is
    today undoubtedly the biggest collection of captured enemy war secrets ever assembled.
    ..It is estimated that over a million separate items must be handled, and that
    they, very likely, practically all the scientific, industrial and military secrets
    of Nazi Germany. One Washington official has called it “the greatest single source
    of this type of material in the world, the first orderly exploitation of an entire
    country’s brain-power.”</p><p>What did we find? You’d like some outstanding examples
    from the war secrets collection?</p><p>…the tiniest vacuum tube I had ever seen.
    It was about half thumb-size. Notice it is heavy porcelain—not glass—and thus
    virtually indestructible. It is a thousand watt—one-tenth the size of similar
    American tubes…“That’s Magnetophone tape,” he said. “It’s plastic, metallized
    on one side with iron oxide. In Germany that supplanted phonograph recordings.
    A day’s Radio program can be magnetized on one reel. You can demagnetize it, wipe
    it off and put a new program on at any time. No needle; so absolutely no noise
    or record wear. An hour-long reel costs fifty cents.”…He showed me then what had
    been two of the most closely-guarded, technical secrets of the war: the infra-red
    device which the Germans invented for seeing at night, and the remarkable diminutive
    generator which operated it. German cars could drive at any, speed in a total
    blackout, seeing objects clear as day two hundred meters ahead. Tanks with this
    device could spot; targets two miles away. As a sniper scope it enabled German
    riflemen to pick off a man in total blackness…We got, in addition, among these
    prize secrets, the technique and the machine for making the world’s most remarkable
    electric condenser…The Kaiser Wilhelm Institute for Silicate Research had discovered
    how to make it and—something which had always eluded scientists—in large sheets.
    We know now, thanks to <span class="smallcaps-auto">FIAT</span> teams, that ingredients of natural mica were melted
    in crucibles of carbon capable of taking 2,350 degrees of heat, and then—this
    was the real secret—cooled in a special way…“This is done on a press in one operation.
    It is called the ‘cold extrusion’ process. We do it with some soft, splattery
    metals. But by this process the Germans do it with cold steel! Thousands of parts
    now made as castings or drop forgings or from malleable iron can now be made this
    way. The production speed increase is a little matter of one thousand per cent.”
    This one war secret alone, many American steel men believe, will revolutionize
    dozens of our metal fabrication industries.</p><p>…In textiles the war secrets
    collection has produced so many revelations, that American textile men are a little
    dizzy.But of all the industrial secrets, perhaps, the biggest windfall came from
    the laboratories and plants of the great German cartel, I. G. Farbenindustrie.
    Never before, it is claimed, was there such a store-house of secret information.
    It covers liquid and solid fuels, metallurgy, synthetic rubber, textiles, chemicals,
    plastics. drugs, dyes. One American dye authority declares: “It includes the production
    know-how and the secret formulas for over fifty thousand dyes. Many of them are
    faster and better than ours. Many are colors we were never able to make. The American
    dye industry will be advanced at least ten years.”</p><p>…Milk pasteurization
    by ultra-violet light…how to enrich the milk with vitamin D…cheese was being made—“good
    quality Hollander and Tilsiter”—by a new method at unheard-of speed…a continuous
    butter making machine…The finished product served as both animal and human food.
    Its caloric value is four times that of lean meat, and it contains twice as much
    protein. The Germans also had developed new methods of preserving food by plastics
    and new, advanced refrigeration techniques…German medical researchers had discovered
    a way to produce synthetic blood plasma.</p><p>…When the war ended, we now know,
    they had 138 types of guided missiles in various stages of production or development,
    using every known kind of remote control and fuse: radio, radar, wire, continuous
    wave, acoustics, infra-red, light beams, and magnetics, to name some; and for
    power, all methods of jet propulsion for either subsonic or supersonic speeds.
    Jet propulsion had even been applied to helicopter flight…Army Air Force experts
    declare publicly that in rocket power and guided missiles the Nazis were ahead
    of us by at least ten years.</p>'
- - /docs/statistics/order/beanmachine-multistage/index.html
  - ! 'Multi-Stage Bean Machine Visualization: Advantages of Repeated Optimization'
  - Rafe Kennedy, Gwern Branwen
  - 2018-12-17
  - ''
  - ! '<p>An interactive JavaScript of order statistics visualized as a Galton bean
    machine, showing difference in means & maxima between single stage of selection
    and multiple stages.</p><p>This is an interactive JS-based visualization of the
    difference in optimization potentials of a single-stage pipeline vs a multi-stage
    pipeline, in which new samples/measurements can be generated at each step (such
    as in evolutionary processes).</p><p>Because it optimizes over multiple steps,
    the multi-stage pipeline “ratchets upward” and can attain far more extreme maxima
    than a single-stage pipeline, even with the same total number of samples&mdash;the
    single-stage process quickly hits “diminishing returns”, where large increases
    in sample count result in only small increases in the expected maximum. This means
    that small gains per stage, or a few stages, or a few generations of evolution,
    can result in large increases of sample means, compared to a single-stage process.
    Due to <a href="https://en.wikipedia.org/wiki/Order_statistic">order statistics</a>,
    the increases in means can cause larger increases in the probability of samples
    passing thresholds such as “top 1%”/≥2.32σ, or yielding extremes. And the more
    stages, the greater differences can be (single-stage selection increases logarithmically,
    while multi-stage increases linearly).</p><p>These increases can be counterintuitively
    large, but the gains/losses are relevant to understanding many processes, such
    as the clinical drug discovery pipeline (eg <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0147215"
    title="When Quality Beats Quantity: Decision Theory, Drug Discovery, and the Reproducibility
    Crisis">Scannell &amp; Bosley 2016</a>).</p><p>The visualization metaphor here
    is <a href="https://en.wikipedia.org/wiki/Bean_machine">Francis Galton’s <em>quincunx</em>
    or “bean machine”</a>: a ball (sample) falls from the top (zero-mean), and is
    affected by sets of pins (stochastic variables) which bounce the ball left/right
    with 50-50 probability (increase/decrease it) as it falls to the bottom (final
    total). The resulting binomial distribution approximates a normal distribution.
    The bean machine visually &amp; concretely illustrates the sampling distribution
    of how a normally-distributed final variable can emerge out of the sum of many
    individual small discrete effects, without requiring any mathematics.</p><p>In
    this visualization, we generalize Galton’s “bean machine” by allowing stacking
    of bean machines. To stack bean machines, we select the ball which is the <em>maximum</em>
    within each sample. How large is it? In the single-stage bean machine, selection
    stops there. In the multi-stage bean machine, <em>another</em> bean machine begins
    with the maximum serving as the seed &amp; new average, and another round of generation
    &amp; selection begins, and so on, until a final sample is selected, and we can
    see how large it is. The gains turn out to be larger the more samples we use total,
    unsurprisingly, but also the more stages we specify; the maximum possible maximum
    turns out to be when we have so many stages that there are just 2 samples per
    stage.</p><p><img style="border: 1px solid #666;" alt="Screenshot of the multi-stage
    bean machine, showing selection in progress in a 3x3 pipeline" width="300" src="/docs/statistics/order/beanmachine-multistage/beanmachine-demo.pngbeanmachine-demo.png"
    title="Multi-Stage Bean Machine"></p>'
- - /docs/cs/1982-perlis.pdf
  - Epigrams on Programming
  - Alan J. Perlis
  - 1982-09-1
  - 10.1145/947955.1083808
  - ! '<p>[130 epigrams on computer science and technology, published in 1982, for
    <span class="smallcaps-auto">ACM</span>''s <span class="smallcaps-auto">SIGPLAN</span> journal, by noted computer scientist and programming language researcher
    <a href="https://en.wikipedia.org/wiki/Alan_Perlis">Alan Perlis</a>. The epigrams
    are a series of short, programming-language-neutral, humorous statements about
    computers and programming, distilling lessons he had learned over his career,
    which are widely quoted.]</p><p>8. A programming language is low level when its
    programs require attention to the irrelevant.…19. A language that doesn’t affect
    the way you think about programming, is not worth knowing.…54. Beware of the Turing
    tar-pit in which everything is possible but nothing of interest is easy.</p><p>15.
    Everything should be built top-down, except the first time.…30. In programming,
    everything we do is a special case of something more general—and often we know
    it too quickly.…31. Simplicity does not precede complexity, but follows it.…58.
    Fools ignore complexity. Pragmatists suffer it. Some can avoid it. Geniuses remove
    it.…65. Make no mistake about it: Computers process numbers—not symbols. We measure
    our understanding (and control) by the extent to which we can arithmetize an activity.
    …56. Software is under a constant tension. Being symbolic it is arbitrarily perfectible;
    but also it is arbitrarily changeable.</p><p>1. One man’s constant is another
    man’s variable. 34. The string is a stark data structure and everywhere it is
    passed there is much duplication of process. It is a perfect vehicle for hiding
    information.</p><p>36. The use of a program to prove the 4-color theorem will
    not change mathematics—it merely demonstrates that the theorem, a challenge for
    a century, is probably not important to mathematics.</p><p>39. Re graphics: A
    picture is worth 10K words—but only those to describe the picture. Hardly any
    sets of 10K words can be adequately described with pictures.</p><p>48. The best
    book on programming for the layman is <em>Alice in Wonderland</em>; but that’s
    because it’s the best book on anything for the layman.</p><p>77. The cybernetic
    exchange between man, computer and algorithm is like a game of musical chairs:
    The frantic search for balance always leaves one of the 3 standing ill at ease.
    …79. A year spent in artificial intelligence is enough to make one believe in God.
    …84. Motto for a research laboratory: What we work on today, others will first
    think of tomorrow.</p><p>91. The computer reminds one of Lon Chaney—it is the
    machine of a thousand faces.</p><p>7. It is easier to write an incorrect program
    than understand a correct one.…93. When someone says “I want a programming language
    in which I need only say what I wish done,” give him a lollipop.…102. One can’t
    proceed from the informal to the formal by formal means.</p><p>100. We will never
    run out of things to program as long as there is a single program around.</p><p>108.
    Whenever 2 programmers meet to criticize their programs, both are silent.…112.
    Computer Science is embarrassed by the computer.…115. Most people find the concept
    of programming obvious, but the doing impossible. 116. You think you know when
    you can learn, are more sure when you can write, even more when you can teach,
    but certain when you can program. 117. It goes against the grain of modern education
    to teach children to program. What fun is there in making plans, acquiring discipline
    in organizing thoughts, devoting attention to detail and learning to be self-critical?</p>'
- - /docs/japanese/1997-carter-shotetsu-unforgottendreams.pdf
  - ! 'Unforgotten Dreams: Poems by the Zen Monk Shōtetsu'
  - Shōtetsu, Steven D. Carter (translator)
  - '1997'
  - ''
  - ! '<p>[This volume presents translations of over 200 poems by Shōtetsu, who is
    generally considered to be the last great poet of the <em>uta</em> form. Includes
    an introduction, a glossary of important names and places and a list of sources
    of the poems.]</p><p>The Zen monk Shōtetsu (1381–1459) suffered several rather
    serious misfortunes in his life: he lost all the poems of his first thirty years—more
    than 30,000 of them—in a fire; his estate revenues were confiscated by an angry
    shogun; and rivals refused to allow his work to appear in the only imperially
    commissioned poetry anthology of his time. Undeterred by these obstacles, he still
    managed to make a living from his poetry and won recognition as a true master,
    widely considered to be the last great poet of the classical <em>uta</em>, or
    <em>waka</em>, tradition. Shōtetsu viewed his poetry as both a professional and
    religious calling, and his extraordinarily prolific corpus comprised more than
    11,000 poems—the single largest body of work in the Japanese canon.</p><p>The
    first major collection of Shōtetsu''s work in English, <em>Unforgotten Dreams</em>
    presents beautifully rendered translations of more than two hundred poems. The
    book opens with Steven Carter''s generous introduction on Shōtetsu''s life and
    work and his significance in Japanese literature, and includes a glossary of important
    names and places and a list of sources of the poems. Revealing as never before
    the enduring creative spirit of one of Japan''s greatest poets, this fine collection
    fills a major gap in the English translations of medieval Japanese literature.</p>'
- - /docs/iq/smpy/2016-makel.pdf
  - When Lightning Strikes Twice
  - Matthew C. Makel, Harrison J. Kell, David Lubinski, Martha Putallaz, Camilla P.
    Benbow
  - 2016-07-01
  - 10.1177/0956797616644735
  - ! 'The educational, occupational, and creative accomplishments of the profoundly
    gifted participants (IQs ⩾ 160) in the Study of Mathematically Precocious Youth
    (<span class="smallcaps-auto">SMPY</span>) are astounding, but are they representative of equally able 12-year-olds?
    Duke University’s Talent Identification Program (<span class="smallcaps-auto">TIP</span>) identified 259 young adolescents
    who were equally gifted. By age 40, their life accomplishments also were extraordinary:
    Thirty-seven percent had earned doctorates, 7.5% had achieved academic tenure
    (4.3% at research-intensive universities), and 9% held patents; many were high-level
    leaders in major organizations. As was the case for the <span class="smallcaps-auto">SMPY</span> sample before them,
    differential ability strengths predicted their contrasting and eventual developmental
    trajectories—even though essentially all participants possessed both mathematical
    and verbal reasoning abilities far superior to those of typical Ph.D. recipients.
    Individuals, even profoundly gifted ones, primarily do what they are best at.
    Differences in ability patterns, like differences in interests, guide development
    along different paths, but ability level, coupled with commitment, determines
    whether and the extent to which noteworthy accomplishments are reached if opportunity
    presents itself. [Keywords intelligence, creativity, giftedness, replication,
    blink comparator]'
- - /docs/psychology/1993-lipsey.pdf
  - ! 'The Efficacy of Psychological, Educational, and Behavioral Treatment: Confirmation
    from Meta-Analysis'
  - Mark W. Lipsey, David B. Wilson
  - 1993-12-01
  - 10.1037/0003-066x.48.12.1181
  - Conventional reviews of research on the efficacy of psychological, educational,
    and behavioral treatments often find considerable variation in outcome among studies
    and, as a consequence, fail to reach firm conclusions about the overall effectiveness
    of the interventions in question. In contrast, meta-analysis reviews show a strong,
    dramatic pattern of positive overall effects that cannot readily be explained
    as artifacts of meta-analytic technique or generalized placebo effects. Moreover,
    the effects are not so small that they can be dismissed as lacking practical or
    clinical significance. Although meta-analysis has limitations, there are good
    reasons to believe that its results are more credible than those of conventional
    reviews and to conclude that well-developed psychological, educational, and behavioral
    treatment is generally efficacious.
- - /docs/iq/2015-hofman.pdf
  - ! 'Evolution of the Human Brain: From Matter to Mind'
  - Michel A. Hofman
  - '2015'
  - 10.1007/978-1-4939-1562-0_5
  - ! 'Design principles and operational modes are explored that underlie the information
    processing capacity of the human brain. The hypothesis is put forward that in
    higher organisms, especially in primates, the complexity of the neural circuitry
    of the cerebral cortex is the neural correlate of the brain’s coherence and predictive
    power, and, thus, a measure of intelligence. It will be argued that with the evolution
    of the human brain we have nearly reached the limits of biological intelligence.
    [Keywords: Biological intelligence, Cognition, Consciousness, Cerebral cortex,
    Primates, Information processing, Neural networks, Cortical design, Human brain
    evolution]'
- - /docs/catnip/2011-villani.pdf
  - Heritability and Characteristics of Catnip Response in Two Domestic Cat Populations
  - Natalie Adele Villani
  - '2011'
  - ''
  - The domestic cat response to catnip is unique in nature as it represents a repeatable,
    recognizable behavioral response to an olfactory stimulus that appears to have
    little evolutionary significance. There is clear variation in response between
    cats and this has been attributed to genetic factors in the past. These factors
    are explored in this study using behavioral observation after presenting of catnip
    to cats in two different research colonies with different environmental and genetic
    backgrounds. The response trait is defined and Gibbs sampling methods are used
    to explore a mixed model for the trait to determine genetic effects. Heritabilities
    obtained in the two colonies for the most significant response behaviors, the
    head over roll and cheek rub, were 0.511 and 0.794 using catnip spray and dried
    catnip respectively. No clear Mendelian mode of inheritance was ascertained in
    either colony. The variation in response behaviors and intensity seen in the two
    colonies reflects the complex nature of expression of the catnip response, but
    there is a clear genetic influence on the feline predisposition to responding.
- - /docs/statistics/causality/2019-gordon.pdf
  - ! 'A Comparison of Approaches to Advertising Measurement: Evidence from Big Field
    Experiments at Facebook'
  - Brett R. Gordon, Florian Zettelmeyer, Neha Bhargava, Dan Chapsky
  - 2019-05-04
  - 10.1287/mksc.2018.1135
  - Measuring the causal effects of digital advertising remains challenging despite
    the availability of granular data. Unobservable factors make exposure endogenous,
    and advertising’s effect on outcomes tends to be small. In principle, these concerns
    could be addressed using randomized controlled trials (<span class="smallcaps-auto">RCT</span>s). In practice, few
    online ad campaigns rely on <span class="smallcaps-auto">RCT</span>s and instead use observational methods to estimate
    ad effects. We assess empirically whether the variation in data typically available
    in the advertising industry enables observational methods to recover the causal
    effects of online advertising. Using data from 15 U.S. advertising experiments
    at Facebook comprising 500 million user-experiment observations and 1.6 billion
    ad impressions, we contrast the experimental results to those obtained from multiple
    observational models. The observational methods often fail to produce the same
    effects as the randomized experiments, even after conditioning on extensive demographic
    and behavioral variables. In our setting, advances in causal inference methods
    do not allow us to isolate the exogenous variation needed to estimate the treatment
    effects. We also characterize the incremental explanatory power our data would
    require to enable observational methods to successfully measure advertising effects.
    Our findings suggest that commonly used observational approaches based on the
    data usually available in the industry often fail to accurately measure the true
    effect of advertising.
- - /docs/math/1979-demillo.pdf
  - Social Processes and Proofs of Theorems and Programs
  - Richard A. De Millo, Richard J. Lipton, Alan J. Perlis
  - '1979'
  - 10.1145/359104.359106
  - Many people have argued that computer programming should strive to become more
    like mathematics. Maybe so, but not in the way they seem to think. The aim of
    program verification, an attempt to make programming more mathematics-like, is
    to increase dramatically one’s confidence in the correct functioning of a piece
    of software, and the device that verifiers use to achieve this goal is a long
    chain of formal, deductive logic. In mathematics, the aim is to increase one’s
    confidence in the correctness of a theorem, and it’s true that one of the devices
    mathematicians could in theory use to achieve this goal is a long chain of formal
    logic. But in fact they don’t. What they use is a proof, a very different animal.
    Nor does the proof settle the matter; contrary to what its name suggests, a proof
    is only one step in the direction of confidence. We believe that, in the end,
    it is a social process that determines whether mathematicians feel confident about
    a theorem—and we believe that, because no comparable social process can take place
    among program verifiers, program verification is bound to fail. We can’t see how
    it’s going to be able to affect anyone’s confidence about programs.
- - https://www.esquire.com/news-politics/a5609/chimpanzee-attack-0409/
  - ! 'The Worst Story I Ever Heard: The Davises are like any other family, only instead
    of a son, they raised a chimpanzee. As with Travis, the chimp that attacked a
    woman who''s finally speaking out, for years everything seemed fine. Then something
    strange and horrifying happened—though not necessarily what you''d think'
  - Rich Schapiro
  - 2009-11-11
  - ''
  - ! '[The story of a couple who raised a chimpanzee (Moe) as their surrogate son.
    After many years, Moe was taken away from them because he bit another person.
    They visited Moe in the sanctuary which also sheltered other chimps. One day they
    brought Moe a birthday cake, and the other chimps were watching Moe eat the cake.
    Those others were out of their cage for some reason. They viciously attacked and
    mauled the man, biting off his face and genitals before they could be stopped,
    and didn’t even go for the cake.]'
- - https://www.nature.com/articles/s42003-019-0558-4
  - Social and non-social autism symptoms and trait domains are genetically dissociable
  - Varun Warrier, Roberto Toro, Hyejung Won, Claire S. Leblond, Freddy Cliquet, Richard
    Delorme, Ward De Witte, Janita Bralten, Bhismadev Chakrabarti, Anders D. Børglum,
    Jakob Grove, Geert Poelmans, David A. Hinds, Thomas Bourgeron, Simon Baron-Cohen
  - 2019-09-03
  - 10.1038/s42003-019-0558-4
  - The core diagnostic criteria for autism comprise two symptom domains – social
    and communication difficulties, and unusually repetitive and restricted behaviour,
    interests and activities. There is some evidence to suggest that these two domains
    are dissociable, though this hypothesis has not yet been tested using molecular
    genetics. We test this using a genome-wide association study (N = 51,564) of a
    non-social trait related to autism, systemising, defined as the drive to analyse
    and build systems. We demonstrate that systemising is heritable and genetically
    correlated with autism. In contrast, we do not identify significant genetic correlations
    between social autistic traits and systemising. Supporting this, polygenic scores
    for systemising are significantly and positively associated with restricted and
    repetitive behaviour but not with social difficulties in autistic individuals.
    These findings strongly suggest that the two core domains of autism are genetically
    dissociable, and point at how to fractionate the genetics of autism.
- - /Embryo-selection#sperm-phenotype-selection
  - Sperm Phenotype Selection
  - Gwern Branwen
  - 2019-08-17
  - ''
  - <p>Sperm can be selected on traits such as mobility, which are measures of quality.
    These may be correlated with genetics for adult traits, and one can select from
    billions of sperm. Estimating the gain, it is probably worthwhile but small.</p><p>A
    possible adjunct to embryo selection is sperm selection. Non-destructive sequencing
    is not yet possible, but measuring phenotypic correlates of genetic quality (such
    as sperm speed/motility) is. These correlations of sperm quality/genetic quality
    are, however, small and confounded in current studies by between-individual variation.
    Optimistically, the gain from such sperm selection is probably small, <0.1SD,
    and there do not appear to be any easy ways to boost this effect. Sperm selection
    is probably cost-effective and a good enhancement of existing <span class="smallcaps-auto">IVF</span> practices, but
    not particularly notable.</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.174.621&rep=rep1&type=pdf
  - Intelligence and semen quality are positively correlated
  - Rosalind Arden, Linda S. Gottfredson, Geoffrey Miller, Arand Pierce
  - '2008'
  - 10.1016/j.intell.2008.11.001
  - ! 'Human cognitive abilities intercorrelate to form a positive matrix, from which
    a large first factor, called ‘Spearman''s <em>g</em>’ or general intelligence,
    can be extracted. General intelligence itself is correlated with many important
    health outcomes including cardiovascular function and longevity. However, the
    important evolutionary question of whether intelligence is a fitness-related trait
    has not been tested directly, let alone answered. If the correlations among cognitive
    abilities are part of a larger matrix of positive associations among fitness-related
    traits, then intelligence ought to correlate with seemingly unrelated traits that
    affect fitness—such as semen quality. We found significant positive correlations
    between intelligence and 3 key indices of semen quality: log sperm concentration
    (<em>r</em>=.15, <em>p</em>=.002), log sperm count (<em>r</em>=.19, <em>p</em>&lt;.001),
    and sperm motility (<em>r</em>=.14, <em>p</em>=.002) in a large sample of US Army
    Veterans. None was mediated by age, body mass index, days of sexual abstinence,
    service in Vietnam, or use of alcohol, tobacco, marijuana, or hard drugs. These
    results suggest that a phenotype-wide fitness factor may contribute to the association
    between intelligence and health. Clarifying whether a fitness factor exists is
    important theoretically for understanding the genomic architecture of fitness-related
    traits, and practically for understanding patterns of human physical and psychological
    health.'
- - https://rbej.biomedcentral.com/articles/10.1186/s12958-015-0029-9
  - Infertility etiologies are genetically and clinically linked with other diseases
    in single meta-diseases
  - Juan J. Tarín, Miguel A. García-Pérez, Toshio Hamatani, Antonio Cano
  - 2015-05-15
  - 10.1186/s12958-015-0029-9
  - ! 'The present review aims to ascertain whether different infertility etiologies
    share particular genes and/or molecular pathways with other pathologies and are
    associated with distinct and particular risks of later-life morbidity and mortality.
    In order to reach this aim, we use two different sources of information: (1) a
    public web server named <a href="http://disease-connect.org">DiseaseConnect</a>
    focused on the analysis of common genes and molecular mechanisms shared by diseases
    by integrating comprehensive omics and literature data; and (2) a literature search
    directed to find clinical comorbid relationships of infertility etiologies with
    only those diseases appearing after infertility is manifested. This literature
    search is performed because DiseaseConnect web server does not discriminate between
    pathologies emerging before, concomitantly or after infertility is manifested.
    Data show that different infertility etiologies not only share particular genes
    and/or molecular pathways with other pathologies but they have distinct clinical
    relationships with other diseases appearing after infertility is manifested. In
    particular, (1) testicular and high-grade prostate cancer in male infertility;
    (2) non-fatal stroke and endometrial cancer, and likely non-fatal coronary heart
    disease and ovarian cancer in polycystic ovary syndrome; (3) osteoporosis, psychosexual
    dysfunction, mood disorders and dementia in premature ovarian failure; (4) breast
    and ovarian cancer in carriers of <span class="smallcaps-auto">BRCA</span>1/2 mutations in diminished ovarian reserve;
    (5) clear cell and endometrioid histologic subtypes of invasive ovarian cancer,
    and likely low-grade serous invasive ovarian cancer, melanoma and non-Hodgkin
    lymphoma in endometriosis; and (6) endometrial and ovarian cancer in idiopathic
    infertility. The present data endorse the principle that the occurrence of a disease
    (in our case infertility) is non-random in the population and suggest that different
    infertility etiologies are genetically and clinically linked with other diseases
    in single meta-diseases. This finding opens new insights for clinicians and reproductive
    biologists to treat infertility problems using a phenomic approach instead of
    considering infertility as an isolated and exclusive disease of the reproductive
    system/hypothalamic–pituitary–gonadal axis. In agreement with a previous validation
    analysis of the utility of DiseaseConnect web server, the present study does not
    show a univocal correspondence between common gene expression and clinical comorbid
    relationship. Further work is needed to untangle the potential genetic, epigenetic
    and phenotypic relationships that may be present among different infertility etiologies,
    morbid conditions and physical/cognitive traits.'
- - http://www.toddkshackelford.com/downloads/Jeffery-et-al-AJHB-2016.pdf
  - Does Human Ejaculate Quality Relate to Phenotypic Traits?
  - Austin John Jeffery, Michael N. Pham, Todd K. Shackelford, Bernhard Fink
  - '2016'
  - 10.1002/ajhb.22805
  - A given man’s phenotype embodies cues of his ancestral ability to effectively
    defend himself and his kin from harm, to survive adverse conditions, and to acquire
    status and mating opportunities. In this review, we explore the hypothesis that
    a man’s phenotype also embodies cues to fertility or the probability that an ejaculate
    will fertilize ova. Female mate choice depends on the ability to discern the quality
    of a male reproductive partner through his phenotype, and male fertility may be
    among the traits that females have evolved to detect. A female who selects as
    mates males that deliver higher quality ejaculates will, on average, be more fecund
    than her competitors. Data on several non-human species demonstrate correlations
    between ejaculate quality and secondary sexual characteristics that inform female
    mate choice, suggesting that females may select mates in part on the basis of
    fertility. While the non-human literature on this topic has advanced, the human
    literature remains limited in scope and there is no clear consensus on appropriate
    methodologies or theoretical positions. We provide a comprehensive review and
    meta-analysis of this literature, and conclude by proposing solutions to the many
    issues that impede progress in the field. In the process, we hope to encourage
    interest and insight from investigators in other areas of human mating and reproductive
    biology.
- - https://parenting.nytimes.com/becoming-a-parent/ivf-sperm-selection
  - ! 'Tinder for Sperm: Even in the Petri Dish, Looks and Athleticism Are Prized:
    What makes one sperm cell—a blob of <span class="smallcaps-auto">DNA</span> with a tail—stand out? The selection process
    is like a microscopic Mr. America contest'
  - Randi Hutter Epstein (<span class="smallcaps-auto">NYT</span>)
  - 2019-07-18
  - ''
  - <p>Fertility treatments have gone so high-tech, it’s logical to assume there’s
    an exact formula for each procedure. Embryos are frozen and warmed at precise
    temperatures, hormones are measured to the billionth of a gram, and women inject
    themselves with strictly-calibrated doses of drugs. But sperm selection remains
    more art than science. Though fertility specialists generally agree that an “ideal”
    human sperm has a smooth, olive-shaped head and a long, undulating tail, the degree
    to which the appearance of sperm cells correlates with their fertilizing potential
    is a subject of much controversy. It isn’t always possible to find sperm with
    this ideal physique in a given sample, Lo noted, and even homely, misshapen sperm
    can produce healthy babies. Sometimes, Lo said, “You pick the least ugly of the
    sample you have.”</p><p>…These days, many leading fertility centers use techniques
    that allow them to bypass all these steps. Instead, they pick a single sperm and
    inject it into the egg, a technique called intracytoplasmic sperm injection or
    <span class="smallcaps-auto">ICSI</span> (pronounced <span class="smallcaps-auto">ICK</span>-see). <span class="smallcaps-auto">ICSI</span> was designed to help men with few or defective
    sperm, but has become so common that it’s used in more than half of all I.V.F.
    procedures. (Despite its widespread use, studies have not proven that <span class="smallcaps-auto">ICSI</span> boosts
    pregnancy rates when men have sufficient numbers of healthy sperm.)</p><p>…Techniques
    to sort sperm by putting them through fine mesh filters and by having them swim
    through specially-engineered pathways called microchannels have also failed to
    yield better results than simply choosing by appearance. Research efforts continue
    but, for now, sperm selection is generally left up to the aesthetic judgement
    of the individual embryologist.</p><p>…Since it’s impossible to individually
    examine each of the thousands of sperm in a typical sample, embryologists acknowledge
    that the quest for the best possible sperm involves an element of fate. “If I
    look in my scope and say, ‘That one looks really great,’ I’ll choose it,” Lo explained.
    But if an especially strong swimmer darts across his field of vision, he sometimes
    changes course at the last minute. When this happens, he said, he wonders, “Did
    I choose that sperm? Did the sperm choose me?”</p>
- - /docs/genetics/selection/2014-mcdowell.pdf
  - Advanced sperm selection techniques for assisted reproduction (Review)
  - S. McDowell, B. Kroon, E. Ford, Y. Hook, D. Glujovsky, A. Yazdani
  - '2014'
  - 10.1002/14651858.CD010461.pub2
  - ! '<p><strong>Background</strong>: Assisted reproductive technologies (<span class="smallcaps-auto">ART</span>) such
    as in vitro fertilisation (<span class="smallcaps-auto">IVF</span>) and intracytoplasmic sperm injection (<span class="smallcaps-auto">ICSI</span>) bring
    together gametes outside of the body to enhance the probability of fertilisation
    and pregnancy. Advanced sperm selection techniques are increasingly being employed
    in <span class="smallcaps-auto">ART</span>, most commonly in cycles utilising <span class="smallcaps-auto">ICSI</span>. Advanced sperm selection techniques
    are thought to improve the chance that structurally intact and mature sperm with
    high <span class="smallcaps-auto">DNA</span> integrity are selected for fertilisation. Advanced sperm selection strategies
    include selection according to surface charge; sperm apoptosis; sperm birefringence;
    ability to bind to hyaluronic acid; and sperm morphology under ultra-high magnification.
    These techniques theoretically improve <span class="smallcaps-auto">ART</span> outcomes.</p><p><strong>Objectives</strong>:
    To evaluate the impact of advanced sperm selection techniques on <span class="smallcaps-auto">ART</span> outcomes.</p><p><strong>Search
    methods</strong>: Systematic search of electronic databases (Cochrane Menstrual
    Disorders and Subfertility Group Specialised Register, the Cochrane Central Register
    of Controlled Trials (<span class="smallcaps-auto">CENTRAL</span>), <span class="smallcaps-auto">MEDLINE</span>, <span class="smallcaps-auto">EMBASE</span>, Psyc<span class="smallcaps-auto">INFO</span>, Cumulative Index to
    Nursing and Allied Health Literature (<span class="smallcaps-auto">CINAHL</span>), Latin American and Caribbean Health
    Science Information Database (<span class="smallcaps-auto">LILACS</span>)), trials registers (ClinicalTrials.gov,
    Current Controlled Trials, World Health Organization International Clinical Trials
    Registry Platform), conference abstracts (Web of Knowledge) and grey literature
    (OpenGrey) for relevant randomised controlled trials. We hand-searched the reference
    lists of included studies and similar reviews. The search was conducted in May
    2014.</p><p><strong>Selection criteria</strong>: We included randomised controlled
    trials (<span class="smallcaps-auto">RCT</span>s) comparing an advanced sperm selection technique versus standard
    <span class="smallcaps-auto">IVF</span> or <span class="smallcaps-auto">ICSI</span> or versus another advanced sperm selection technique. We excluded
    studies of sperm selection using ultra-high magnification (intracytoplasmic morphologically
    selected sperm injection, or <span class="smallcaps-auto">IMSI</span>), as they are the subject of a separate Cochrane
    review. Quasi-randomised and pseudo-randomised trials were excluded. Our primary
    outcome measure was live birth rate per woman randomly assigned. Secondary outcome
    measures included clinical pregnancy per woman randomly assigned, miscarriage
    per clinical pregnancy and fetal abnormality per clinical pregnancy.</p><p><strong>Data
    collection and analysis</strong>: Two review authors independently assessed eligibility
    of studies and risk of bias, and performed data extraction. Disagreements were
    resolved by consultation with a third review author. Study investigators were
    consulted to resolve other queries that arose. Risk ratios (RRs) were calculated
    with 95% confidence intervals (CIs). We planned to combine studies using a fixed-effect
    model, if sufficient data were available. The quality of the evidence was evaluated
    using Grades of Recommendation, Assessment, Development and Evaluation (<span class="smallcaps-auto">GRADE</span>)
    methods.</p><p><strong>Main results</strong>: Two <span class="smallcaps-auto">RCT</span>s were included in the review.
    Both evaluated sperm selection by hyaluronanic acid binding for <span class="smallcaps-auto">ICSI</span>, but only
    one reported live births. No studies were identified that were related to surface
    charge selection, sperm apoptosis or sperm birefringence.</p><p>One <span class="smallcaps-auto">RCT</span> compared
    hyaluronanic acid binding versus conventional <span class="smallcaps-auto">ICSI</span>. Live birth was not reported.
    Evidence was insufficient to show whether there was a difference between groups
    in clinical pregnancy rates (RR 1.01, 95% CI 0.84 to 1.22, one <span class="smallcaps-auto">RCT</span>, 482 women).
    This evidence was deemed to be of low quality, mainly as the result of poor reporting
    of methods and findings. Miscarriage data were unclear, and fetal abnormality
    rates were not reported.</p><p>The other <span class="smallcaps-auto">RCT</span> compared two different hyaluronanic
    acid binding techniques, SpermSlow and physiological intracytoplasmic sperm injection
    (<span class="smallcaps-auto">PISCI</span>). Evidence was insufficient to indicate whether there was a difference
    between groups in rates of live birth (RR 1.16, 95% CI 0.65 to 2.05, one <span class="smallcaps-auto">RCT</span>,
    99 women), clinical pregnancy (RR 1.07, 95% CI 0.67 to 1.71, one <span class="smallcaps-auto">RCT</span>, 99 women)
    or miscarriage (RR 0.76, 95% CI 0.24 to 2.44, one <span class="smallcaps-auto">RCT</span>, 41 women). The evidence
    for these comparisons was deemed to be of low quality, as it was limited by imprecision
    and poor reporting of study methods. Fetal abnormality rates were not reported.</p><p><strong>Authors’
    conclusions</strong>: Evidence was insufficient to allow review authors to determine
    whether sperm selected by hyaluronanic acid binding improve live birth or pregnancy
    outcomes in <span class="smallcaps-auto">ART</span>, and no clear data on adverse effects were available. Evidence
    was also insufficient to show whether there is a difference in efficacy between
    the hyaluronic acid binding methods SpermSlow and <span class="smallcaps-auto">PICSI</span>. No randomised evidence
    evaluating sperm selection by sperm apoptosis, sperm birefringence or surface
    charge was found. Further studies of suitable quality are required to evaluate
    whether any of these advanced sperm selection techniques can be recommended for
    use in clinical practice.</p>'
- - https://www.frontiersin.org/articles/10.3389/fvets.2019.00241/full
  - ! 'Throwing the Baby Out With the Bath Water: Could Widespread Neutering of Companion
    Dogs Cause Problems at a Population Level?'
  - Jessica K. Dawson, Tiffani J. Howell, Matthew B. Ruby, Pauleen C. Bennett
  - 2019-07-22
  - 10.3389/fvets.2019.00241
  - <p>In many countries where companion dogs are popular, owners are strongly encouraged
    to neuter their dogs. Consequently, millions of dogs are neutered each year. In
    recent times considerable attention has been paid to the possible effects of such
    procedures on canine health and welfare. Less scrutinized are the potential ramifications
    of widespread neutering on the breeding of dogs and their continued success as
    human companions. This paper summarizes research investigating factors influencing
    the breeding and rearing of dogs most suited to companionship roles in contemporary,
    typically high-density, communities, and briefly reviews current breeder practices.
    It then argues that a fundamental shift to promote inclusion of “proven” companion
    dogs in the gene pool, as opposed to dogs meeting conformation or working/sporting
    standards, is required to successfully meet the needs of modern urban dog owners.
    A new model is proposed, whereby responsible owners and breeders work together
    to produce dogs most suited for life as human companions.</p><p>…The demonstrated
    importance of genetics and early environment in determining behavioral predispositions
    makes it imperative to consider where companion dogs come from. Prior to the widespread
    introduction of neutering practices, dogs often bred indiscriminately, and people
    typically obtained their dogs for free from neighbors whose bitch had produced
    a litter (47). While this was problematic in terms of creating dog overpopulation,
    it meant that most of the dogs who produced offspring were well suited to the
    demands of the lives they were expected to lead. Those who weren't well-suited
    were disposed of. Today, strong demand for companion dogs, coupled with rapid
    urbanization, increased concern regarding the welfare of animals, particularly
    companion dogs, and high neutering rates, has resulted in a multimillion-dollar
    industry involving the selective breeding and selling of puppies (48). Widespread
    neutering means that humans intentionally control nearly all dog breeding in developed
    countries…As described previously, in many developed countries, neutering companion
    dogs is considered an important aspect of responsible ownership. Hence, the very
    best companion dogs in the general community, those owned by responsible citizens
    who choose their dogs carefully and ensure they are reared correctly, are almost
    certainly those most likely to be neutered. Conversely, it is those companion
    dog owners who fail to perform the “responsible” behavior of neutering their dog
    who are perhaps most likely to breed. These “breeders” may also choose not to
    perform other “responsible” behaviors, such as selecting their dog carefully,
    testing it for genetic disorders, or evaluating the dog's suitability as a companion
    prior to allowing it to reproduce. In other words, they may not thoroughly consider
    the genetic and environmental factors known to be critical to optimal puppy development.</p><p>Second,
    we advocate that all dogs should be independently tested for suitability before
    being bred—much as breeders now advertise that their puppies' parents are successful
    show dogs, or that they are free from known genetic disorders, so they should
    be encouraged to advertise that independent testing has shown their breeding dogs
    to be well-suited behaviourally to life as human companions. We anticipate that
    responsible breeders would be willing to pay for this independent certification,
    much as they presently pay for genetic tests, eye screening and tests for hip
    dysplasia. Several behavioral tests exist to measure specific traits, such as
    the Socially Acceptable Behavior test (64), which measures aggression, or the
    Dog Mentality Assessment test (65), which examines levels of playfulness, curiosity,
    aggression, sociability, and chase-proneness. In the <span class="smallcaps-auto">USA</span>, the Canine Good Citizen
    program, administered by the American Kennel Club, takes <30 min to administer
    and is designed to identify dogs that meet ten objectives consistent with being
    a good companion dog. Any one of these tests could be used as a basis for developing
    an assessment suited to breeding dogs—dogs that are not themselves good companions
    are less likely to produce puppies able to excel at this role.</p>
- - /Clone#dog-heritabilities
  - Dog behavioral trait heritabilities review
  - Gwern Branwen
  - 2019-01-13
  - ''
  - ! '<p>Notes on reading reviews &amp; meta-analyses on the psychometric properties
    &amp; heritabilities of dog behavioral traits, particularly for working dogs.
    Dog heritabilities might be expected to be low in the context of considering dogs
    of the same breed (as would be relevant to a breeding or training context): heavy
    selective breeding would tend to reduce within-breed heritabilities (while increasing
    group heritability).</p><p>Overall, heritabilities appear to differ by breed and
    be quite low (say, closer to 25% than to the <a href="/docs/genetics/heritable/2015-polderman.pdf"
    title="&#39;Meta-analysis of the heritability of human traits based on fifty years
    of twin studies&#39;, Polderman et al 2015">human average of &gt;50%</a>) but
    the psychometric properties of dog behavioral tests also appear to be poor, with
    low item counts, reliabilities, test-retests, and predictive power, rater/judge
    effects, and little use of latent factors to extract more reliable measures, suggesting
    considerable total measurement error and thus considerable underestimation of
    prediction/heritabilities. Possibly dog heritabilities are much closer to human
    heritabilities than they seem.</p>'
- - /docs/genetics/heritable/1965-scott-geneticsandthesocialbehaviorofthedog.pdf
  - ! 'Genetics and the Social Behavior of the Dog [Dog Behavior: The Genetic Basis]'
  - John Paul Scott, John L. Fuller
  - '1965'
  - ''
  - ! 'Classic study of dog behavior, the authoritative information from 20 years
    of research at the Jackson Laboratory. The authors synthesize developmental problems
    and canine genetics, based on study of 470 dogs. Central to the book is the role
    heredity plays in the development of behavior. Giving puppies an environment designed
    on the principles of a well-run school, Scott and Fuller tested five breeds representing
    the major dog groups and carried out a Mendelian experiment with two of the most
    different breeds: The basenji and the cocker spaniel. They found that heredity
    affects almost every trait tested; that gender affects aggressiveness and the
    dominance order, but not trainability and problem-solving; that emotional traits
    profoundly influence performance; that, although breeds differ widely in emotional
    and motivational characteristics, none shows distinct superiority in problem solving;
    and that detailed statistical analyses indicate a highly complex pathway between
    primary gene action and its final effect on behavior. Includes important information
    on rearing methods, the origin and history of dog breeds, basic behavior patterns
    and the psychological and behavioral development of puppies. Their careful scientific
    work demonstrated the importance and existence of time limited phases in the early
    life of dogs within which certain experiences need to occur or the dogs may be
    forever deficient. Their work (with that of Eckhard Hess''s on ducks and geese)
    demonstrated that these critical or sensitive periods in early development could
    be scientifically studied in ways compatible with a scientific psychology. This
    book will always be especially valuable to dog breeders and trainers; its last
    chapters summarize in very clear terms the particular phases in early development
    and experiences the dog needs to be adequately socialized. The reader can refer
    back to earlier chapters to get more information on how the experiments were conducted
    and the distribution of results. It answers questions on proper age that puppies
    can be separated from their mothers, what experiences are important to provide
    at what age, etc. Originally published in 1965. [<span class="smallcaps-auto">ISBN</span>: 0-226-74335-7]'
- - https://annesofiebeckknudsen.com/wp-content/uploads/2019/01/thosewhostayed.pdf
  - ! 'Those Who Stayed: Individualism, Self-Selection and Cultural Change during
    the Age of Mass Migration'
  - Anne Sofie Beck Knudsen
  - 2019-01-01
  - ''
  - ! 'This paper examines the joint evolution of emigration and individualism in
    Scandinavia during the Age of Mass Migration (1850&ndash;1920). A long-standing
    hypothesis holds that people of a stronger individualistic mindset are more likely
    to migrate as they suffer lower costs of abandoning existing social networks.
    Building on this hypothesis, I propose a theory of cultural change where migrant
    self-selection generates a relative push away from individualism, and towards
    collectivism, in migrant-sending locations through a combination of initial distributional
    effects and channels of intergenerational cultural transmission. Due to the interdependent
    relationship between emigration and individualism, emigration is furthermore associated
    with cultural convergence across subnational locations. I combine various sources
    of empirical data, including historical population census records and passenger
    lists of emigrants, and test the relevant elements of the proposed theory at the
    individual and subnational district level, and in the short and long run. Together,
    the empirical results suggest that individualists were more likely to migrate
    than collectivists, and that the Scandinavian countries would have been considerably
    more individualistic and culturally diverse, had emigration not taken place. [Keywords:
    Culture, individualism, migration, selection, economic history]'
- - /Statistical-notes#selective-emigration-and-personality-trait-change
  - Selective Emigration and Personality Trait Change
  - Gwern Branwen
  - 2019-09-03
  - ''
  - ! '<p><a href="https://annesofiebeckknudsen.com/wp-content/uploads/2019/01/thosewhostayed.pdf"
    title="Those Who Stayed: Individualism, Self-Selection and Cultural Change during
    the Age of Mass Migration">Knudsen 2019</a> finds that the emigration of 25% of
    the Scandinavian population to the <span class="smallcaps-auto">USA</span> 1850–1920 was driven in part by more ‘individualistic’
    personality factors among emigrants, leading to permanent decreases in mean ‘individualism’
    in the home countries. This is attributed to cultural factors, rather than genetics.
    I model the overall migration as a simple truncation selection scenario, and find
    that in a simple model under reasonable assumptions, the entire effect could be
    genetic.</p>'
- - https://www.nature.com/articles/s41467-019-11724-6
  - Extreme inbreeding in a European ancestry sample from the contemporary UK population
  - Loic Yengo, Naomi R. Wray, Peter M. Visscher
  - 2019-09-03
  - 10.1038/s41467-019-11724-6
  - ! '<p>In most human societies, there are taboos and laws banning mating between
    first- and second-degree relatives, but actual prevalence and effects on health
    and fitness are poorly quantified. Here, we leverage a large observational study
    of ~450,000 participants of European ancestry from the UK Biobank (<span class="smallcaps-auto">UKB</span>) to quantify
    extreme inbreeding (EI) and its consequences. We use genotyped <span class="smallcaps-auto">SNP</span>s to detect
    large runs of homozygosity (<span class="smallcaps-auto">ROH</span>) and call EI when &gt;10% of an individual’s genome
    comprise <span class="smallcaps-auto">ROH</span>s. We estimate a prevalence of EI of ~0.03%, i.e., ~$. EI cases have
    phenotypic means between 0.3 and 0.7 standard deviation below the population mean
    for 7 traits, including stature and cognitive ability, consistent with inbreeding
    depression estimated from individuals with low levels of inbreeding. Our study
    provides <span class="smallcaps-auto">DNA</span>-based quantification of the prevalence of EI in a European ancestry
    sample from the UK and measures its effects on health and fitness traits.</p><p>In
    most human societies, there are taboos and laws banning mating between first-
    and second-degree relatives, but actual prevalence and effects on health and fitness
    are poorly quantified. Here, we leverage a large observational study of ~450,000
    participants of European ancestry from the UK Biobank (<span class="smallcaps-auto">UKB</span>) to quantify extreme
    inbreeding (EI) and its consequences. We use genotyped <span class="smallcaps-auto">SNP</span>s to detect large runs
    of homozygosity (<span class="smallcaps-auto">ROH</span>) and call EI when &gt;10% of an individual’s genome comprise
    <span class="smallcaps-auto">ROH</span>s. We estimate a prevalence of EI of ~0.03%, i.e., ~<math display="inline"
    xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mn>3652</mn></mfrac><annotation
    encoding="application/x-tex">\frac{1}{3652}</annotation></semantics></math>.
    EI cases have phenotypic means between 0.3 and 0.7 standard deviation below the
    population mean for 7 traits, including stature and cognitive ability, consistent
    with inbreeding depression estimated from individuals with low levels of inbreeding.
    Our study provides <span class="smallcaps-auto">DNA</span>-based quantification of the prevalence of EI in a European
    ancestry sample from the UK and measures its effects on health and fitness traits.</p>'
- - https://minimaxir.com/2019/09/howto-gpt2/
  - How To Make Custom AI-Generated Text With <span class="smallcaps-auto">GPT</span>-2
  - Max Woolf
  - 2019-09-04
  - ''
  - ! 'From a text-generation perspective, the included demos were very impressive:
    the text is coherent over a long horizon, and grammatical syntax and punctuation
    are near-perfect.</p><p><img src="/images/ai/2019-openai-gpt2-demo-recyclingtextsample.png"></p><p>At
    the same time, the Python code which allowed anyone to download the model (albeit
    smaller versions out of concern the full model can be abused to mass-generate
    fake news) and the <a href=https://www.tensorflow.org>TensorFlow</a> code to
    load the downloaded model and generate predictions was <a href=https://github.com/openai/gpt-2
    >open-sourced on GitHub</a>.</p><p>Neil Sheppard created <a href=https://github.com/nshepperd/gpt-2
    >a fork</a> of OpenAI’s repo which contains additional code to allow <em>finetuning</em>
    the existing OpenAI model on custom datasets. A <a href=https://github.com/ak9250/gpt-2-colab
    >notebook</a> was created soon after, which can be copied into <a href=https://colab.research.google.com
    >Google Colaboratory</a> and clones Sheppard''s repo to finetune <span class="smallcaps-auto">GPT</span>-2 backed
    by a free <span class="smallcaps-auto">GPU</span>. From there, the proliferation of <span class="smallcaps-auto">GPT</span>-2 generated text took off:
    researchers such as Gwern Branwen made <a href=https://www.gwern.net/GPT-2 ><span class="smallcaps-auto">GPT</span>-2
    Poetry</a> and Janelle Shane made <a href=https://aiweirdness.com/post/183471928977/dd-character-bios-now-making-slightly-more
    ><span class="smallcaps-auto">GPT</span>-2 Dungeons and Dragons character bios</a>.</p><p>I waited to see if anyone
    would make a tool to help streamline this finetuning and text generation workflow,
    a la <a href=https://github.com/minimaxir/textgenrnn >textgenrnn</a> which I had
    made for recurrent neural network-based text generation. Months later, no one
    did. So I did it myself. Enter <a href=https://github.com/minimaxir/gpt-2-simple
    >gpt-2-simple</a>, a Python package which wraps Sheppard''s finetuning code in
    a functional interface and adds <em>many</em> utilities for model management and
    generation control.</p><p><p>Thanks to gpt-2-simple and <a href=https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce
    >this Colaboratory Notebook</a>, you can easily finetune <span class="smallcaps-auto">GPT</span>-2 on your own dataset
    with a simple function, and generate text to your own specifications!</p>'
- - /docs/genetics/selection/2013-walsh-book2-ch14-draft.pdf
  - ! 'Chapter 14. Short-term Changes in the Mean: 2. Truncation and Threshold Selection
    [2013 draft]'
  - Michael Lynch, Bruce Walsh
  - '2013'
  - ''
  - <p>This brief chapter first considers the theory of truncation selection on the
    mean, which is of general interest, and then examines a number of more specialized
    topics that may be skipped by the casual reader. Truncation selection (Figure
    14.1) occurs when all individuals on one side of a threshold are chosen, and is
    by far the commonest form of artificial selection in breeding and laboratory experiments.
    One key result is that for a normally-distributed trait, the selection intensity
    <em>ī</em> is fully determined by the fraction <em>p</em> saved (Equation 14.3a),
    provided that the chosen number of adults is large. This allows a breeder or experimentalist
    to predict the expected response given their choice of <em>p</em>.</p><p>The remaining
    topics are loosely organized around the theme of selection intensity and threshold
    selection. First, when a small number of adults are chosen to form the next generation,
    Equation 14.3a overestimates the expected <em>ī</em>, and we discuss how to correct
    for this small sample effect. This correction is important when only a few individuals
    form the next generation, but is otherwise relatively minor. The rest of the chapter
    considers the response in discrete traits. We start with a binary (present/absence)
    trait, and show how an underlying liability model can be used to predict response.
    We also examine binary trait response in a logistic regression framework (estimating
    the probability of showing the trait given some underlying liability scores) and
    the evolution of both the mean value on the liability scale and the threshold
    value. We conclude with a few brief comments on response when a trait is better
    modeled as Poisson, rather than normally, distributed….In addition to being the
    commonest form of artificial selection, truncation selection is also the most
    efficient, giving the largest selection intensity of any scheme culling the same
    fraction of individuals from a population (Kimura and Crow 1978, Crow and Kimura
    1979).</p><p>[Preprint chapter of <a href="https://www.amazon.com/Evolution-Selection-Quantitative-Traits-Bruce/dp/0198830874"><em>Evolution
    and Selection of Quantitative Traits</em></a>, Lynch and Walsh 2018]</p>
- - /Statistical-notes#oh-deer-could-deer-evolve-to-avoid-car-accidents
  - ! 'Oh Deer: Could Deer Evolve to Avoid Car Accidents?'
  - Gwern Branwen
  - 2018-11-11
  - ''
  - ! '<p>Can deer evolve under the selection pressure of car accidents to learn to
    avoid roads? Probably, but it''ll take a long time.</p><p>I’ve noticed while driving
    many deer corpses over the years. Cars seem like they could be a major source
    of deer mortality. If they are, deer might be evolving behavior to avoid cars.
    But deer/car accident rates appear stable or increasing (perhaps due to human
    population growth &amp; construction). How fast would we expect to see any deer
    adaptation?</p><p>Looking at some of the mortality statistics, I model it as a
    liability threshold trait being selected on via truncation selection, and calculate
    some hypotheticals about whether and how fast they could adapt.</p><p>Teal deer:
    of course, but it’d be slow.</p>'
- - /Clone#nba-screening-scenario
  - NBA Screening Scenario
  - Gwern Branwen
  - 2019-06-03
  - ''
  - <p>Analogous to the <a href="/Clone">dog cloning scenario</a>, I consider the
    case of selecting for extremes on <span class="smallcaps-auto">PGS</span>es, motivated by a scenario of scouting tall
    men for the <span class="smallcaps-auto">NBA</span>.</p><p>Setting up the <span class="smallcaps-auto">NBA</span> selection problem as a liability threshold
    model with current height <span class="smallcaps-auto">PGS</span>es as a noisy predictor, height selection can be
    modeled as selecting for extremes on a <span class="smallcaps-auto">PGS</span> which is regressed back to the mean
    to yield expected adult height, and probability of being tall enough to consider
    a <span class="smallcaps-auto">NBA</span> career.</p><p>Filling in reasonable values, nontrivial numbers of tall people
    can be found by genomic screening with a current <span class="smallcaps-auto">PGS</span>, and as <span class="smallcaps-auto">PGS</span>es approach their
    predictive upper bound (derived from whole-genome-based heritability estimates
    of height), selection is capable of selecting almost all tall people by taking
    the top <span class="smallcaps-auto">PGS</span> percentile.</p>
- - https://tvtropes.org/pmwiki/pmwiki.php/Main/RuleOfCool
  - Rule of Cool
  - <span class="smallcaps-auto">TVT</span>ropes
  - ''
  - ''
  - <p><em>The limit of the Willing Suspension of Disbelief for a given element is
    directly proportional to its awesomeness.</em></p><p>Stated another way, all but
    the most pedantic of viewers will forgive liberties with reality as long as the
    result is wicked sweet or awesome. This applies to the audience in general; there
    will naturally be a different threshold for each individual. Also known in some
    circles as a "rad herring", in which something doesn't make sense within the guidelines
    of the story's reality, but it's too cool <em>not</em> to include it…Since it's
    subjective, it doesn't have to be cool in the sense of "Grim reaper on a mountain
    playing an electric guitar". The protagonist might not use guns because it's cooler
    to have them fight vampires with knives and stakes. You might have Missing Parent
    Syndrome because it would be weird to have parents with you on a road trip across
    the country. Basically, Rule of Cool works differently for whichever genre you're
    writing for.</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.691.3734&rep=rep1&type=pdf
  - ! 'Hatred and Profits: Getting Under the Hood of the Ku Klux Klan'
  - Roland G. Fryer, Steven D. Levitt
  - 2010-08-31
  - ''
  - The Ku Klux Klan reached its heyday in the mid-1920s, claiming millions of members.
    In this paper, we analyze the 1920s Klan, those who joined it, and the social
    and political impact that it had. We utilize a wide range of newly discovered
    data sources including information from Klan membership roles, applications, robe-order
    forms, an internal audit of the Klan by Ernst and Ernst, and a census that the
    Klan conducted after an internal scandal. Combining these sources with data from
    the 1920 and 1930 U.S. Censuses, we find that individuals who joined the Klan
    were better educated and more likely to hold professional jobs than the typical
    American. Surprisingly, we find few tangible social or political impacts of the
    Klan. There is little evidence that the Klan had an effect on black or foreign
    born residential mobility, or on lynching patterns. Historians have argued that
    the Klan was successful in getting candidates they favored elected. Statistical
    analysis, however, suggests that any direct impact of the Klan was likely to be
    small. Furthermore, those who were elected had little discernible effect on legislation
    passed. Rather than a terrorist organization, the 1920s Klan is best described
    as a social organization built through a wildly successful pyramid scheme fueled
    by an army of highly-incentivized sales agents selling hatred, religious intolerance,
    and fraternity in a time and place where there was tremendous demand.
- - /docs/economics/2007-doran.pdf
  - So You Discovered an Anomaly … Gonna Publish It? An Investigation Into the Rationality
    of Publishing a Market Anomaly
  - James Doran, Colbrin A. Wright
  - 2007-01-11
  - 10.2139/ssrn.956105
  - If publishing an anomaly leads to the dissipation of its profitability, a notion
    that has mounting empirical support, then publishing a highly profitable market
    anomaly seems to be irrational behavior. This paper explores the issue by developing
    and empirically testing a theory that argues that publishing a market anomaly
    may, in fact, be rational behavior. The theory predicts that researchers with
    few (many) publications and lesser (stronger) reputations have the highest (lowest)
    incentive to publish market anomalies. Employing probit models, simple <span class="smallcaps-auto">OLS</span> regressions,
    and principal component analysis, we show that (a) market anomalies are more likely
    to be published by researchers with fewer previous publications and who have been
    in the field for a shorter period of time and (b) the profitability of published
    market anomalies is inversely related to the common factor spanning the number
    of publications the author has and the number of years that have elapsed since
    the professor earned his Ph.D. The empirical results suggest that the probability
    of publishing an anomaly and the profitability of anomalies that are published
    are inversely related to the reputation of the authors. These results corroborate
    the theory that publishing an anomaly is rational behavior for an author trying
    to establish his or her reputation.
- - https://static1.squarespace.com/static/5329e895e4b09fd4786211a3/t/56cb78e3d51cd4c4751d1245/1456175333161/Public+Opin+Q-2014-Makowsky-poq-nfu041.pdf
  - Education, Intelligence, and Attitude Extremity
  - Michael D. Makowsky, Stephen C. Miller
  - '2014'
  - 10.1093/poq/nfu041
  - Education and general intelligence both serve to inform opinions, but do they
    lead to greater attitude extremity? The potential civic returns to education include
    not only the sophistication of citizen opinions, but also their moderation. We
    use questions on economic policy, social issues, and environmental issues from
    the General Social Survey [<span class="smallcaps-auto">GSS</span>] to test the impact of education on attitude extremity,
    as measured by deviation from centrist or neutral positions, while controlling
    for intelligence. We use quantile regression modeling to identify effects on both
    the most extreme beliefs as well as the most ambivalent. We find that intelligence
    is a moderating force across the entire distribution in economic, social, and
    environmental policy beliefs. Completing high school strongly correlates to reduced
    extremity, particularly in the upper quantiles. College education increases attitude
    extremity in the lower tail, while postgraduate education increases extremity
    in the upper tail. Results are discussed in the context of enlightenment and motivated-reasoning
    theories of beliefs and education. The relevance to political party core and swing
    voters is briefly discussed.
- - https://www.thiswaifudoesnotexist.net/
  - ThisWaifuDoesNotExist.net
  - Gwern Branwen
  - 2019-02-19
  - ''
  - <p><a href="https://www.thiswaifudoesnotexist.net/"><code>ThisWaifuDoesNotExist.net</code></a>
    (<a href="/TWDNE"><span class="smallcaps-auto">TWDNE</span></a>) is a static website which uses
    JS to display random <a href="/Faces">anime faces generated
    by Style<span class="smallcaps-auto">GAN</span></a> neural networks, along with <a href="/GPT-2"><span class="smallcaps-auto">GPT</span>-2</a>-generated
    'anime plot summaries'.</p><p><figure><img src="/images/gan/thiswaifudoesnotexist.png"
    alt="A screenshot of “This Waifu Does Not Exist” (TWDNE) showing a random StyleGAN-generated
    anime face and a random GPT-2-117M text sample conditioned on anime keywords/phrases."
    /><figcaption>A screenshot of “This Waifu Does Not Exist” (<span class="smallcaps-auto">TWDNE</span>) showing
    a random Style<span class="smallcaps-auto">GAN</span>-generated anime face and a random <span class="smallcaps-auto">GPT</span>-2-117M text sample conditioned
    on anime keywords/phrases.</figcaption></figure></p>
- - https://classic.esquire.com/article/1990/12/1/terminal-delinquents
  - ! 'Terminal Delinquents: Once, They Stole Hubcaps And Shot Out Street-Lights.
    Now They''re Stealing Your Social Security Number And Shooting Out Your Credit
    Rating. A Layman''s Guide To Computer High Jinks'
  - Jack Hitt, Paul Tough (Esquire)
  - 1990-12-01
  - ''
  - ! '[Gonzo-style account of hanging out with teenage hackers and phreakers in <span class="smallcaps-auto">NYC</span>,
    Phiber Optik and Acid Phreak, similar to <a href="https://classic.esquire.com/article/1990/12/1/terminal-delinquents"><em>Hackers</em></a>]
    <p>“Sometimes,” says Kool, “it’s so simple. I used to have contests with my friends
    to see how few words we could use to get a password. Once I called up and said,
    ‘Hi, I’m from the social-engineering center and I need your password,’ and they
    gave it to me! I swear, sometimes I think I could call up and say, ‘Hi, I’m in
    a diner, eating a banana split. Give me your password.’” <em>Like its</em> mechanical counterpart,
    social engineering is half business and half pleasure. It is a social game that
    allows the accomplished hacker to show off his knowledge of systems, his mastery
    of jargon, and especially his ability to manipulate people. It not only allows
    the hacker to get information; it also has the comic attractions of the old-fashioned
    prank phone call—fooling an adult, improvisation, cruelty. In the months we spent
    with the hackers, the best performance in a social-engineering role was by a hacker
    named Oddjob. With him and three other guys we pulled a hacking all-nighter in
    the financial district, visiting pay phones in the hallway of the World Trade
    Center, outside the bathrooms of the Vista Hotel, and in the lobby of the international
    headquarters of American Express.</p><p>…Where we see only a machine’s function,
    they see its potential. This is, of course, the noble and essential trait of the
    inventor. But hackers warp it with teenage anarchic creativity: Edison with attitude.
    Consider the fax machine. We look at it; we see a document-delivery device. One
    hacker we met, Kaos, looked at the same machine and immediately saw the Black
    Loop of Death. Here’s how it works: Photocopy your middle finger displaying the
    international sign of obscene derision. Make two more copies. Tape these three
    pages together. Choose a target fax machine. Wait until nighttime, when you know
    it will be unattended, and dial it up. Begin to feed your long document into your
    fax machine. When the first page begins to emerge below, tape it to the end of
    the last page. Ecce. This three-page loop will continuously feed your image all
    night long. In the morning, your victim will find an empty fax machine, surrounded
    by two thousand copies of your finger, flipping the bird.</p><p>…From a distance,
    a computer network looks like a fortress—impregnable, heavily guarded. As you
    get closer, though, the walls of the fortress look a little flimsy. You notice
    that the fortress has a thousand doors; that some are unguarded, the rest watched
    by unwary civilians. All the hacker has to do to get in is find an unguarded door,
    or borrow a key, or punch a hole in the wall. The question of whether he’s allowed
    in is made moot by the fact that it’s unbelievably simple to enter. Breaking into
    computer systems will always remain easy because the systems have to accommodate
    dolts like you and me. If computers were used only by brilliant programmers, no
    doubt they could maintain a nearly impenetrable security system. But computers
    aren’t built that way; they are “dumbed down” to allow those who must use them
    to do their jobs. So hackers will always be able to find a trusting soul to reveal
    a dialup, an account, and a password. And they will always get in.</p>'
- - https://advances.sciencemag.org/content/5/9/eaaw2594
  - ! 'Different languages, similar encoding efficiency: Comparable information rates
    across the human communicative niche'
  - Christophe Coupé, Yoon Oh, Dan Dediu, François Pellegrino
  - 2019-09-04
  - 10.1126/sciadv.aaw2594
  - ! 'Language is universal, but it has few indisputably universal characteristics,
    with cross-linguistic variation being the norm. For example, languages differ
    greatly in the number of syllables they allow, resulting in large variation in
    the Shannon information per syllable. Nevertheless, all natural languages allow
    their speakers to efficiently encode and transmit information. We show here, using
    quantitative methods on a large cross-linguistic corpus of 17 languages, that
    the coupling between language-level (information per syllable) and speaker-level
    (speech rate) properties results in languages encoding similar information rates
    (~39 bits/s) despite wide differences in each property individually: Languages
    are more similar in information rates than in Shannon information or speech rate.
    These findings highlight the intimate feedback loops between languages’ structural
    properties and their speakers’ neurocognition and biology under communicative
    pressures. Thus, language is the product of a multiscale communicative niche construction
    process at the intersection of biology, environment, and culture.'
- - https://scholarship.law.georgetown.edu/cgi/viewcontent.cgi?article=1557&context=facpub#pdf
  - Constitutional Hardball
  - Mark Tushnet
  - '2004'
  - ''
  - ! 'For the past several years I have been noticing a phenomenon that seems to
    me new in my lifetime as a scholar of constitutional law. I  call the phenomenon
    <em>constitutional hardball</em>. This Essay develops the idea that there is such
    a practice, that there is a sense in which it is new, and that its emergence (or
    re-emergence) is interesting because it signals that political actors understand
    that they are in a position to put in place a new set of deep institutional arrangements
    of a sort I call a ''constitutional order''. A shorthand sketch of constitutional
    hardball is this: it consists of political claims and practices-legislative and
    executive initiatives-that are without much question within the bounds of existing
    constitutional doctrine and practice but that are nonetheless in some tension
    with existing <em>pre</em>-constitutional understandings. It is <em>hardball</em>
    because its practitioners see themselves as playing for keeps in a special kind
    of way; they believe the stakes of the political controversy their actions provoke
    are quite high, and that their defeat and their opponents'' victory would be a
    serious, perhaps permanent setback to the political positions they hold.'
- - /docs/economics/2017-gard.pdf
  - ! 'Creating a Last Twenty (L20) Collection: Implementing Section 108(h) in Libraries,
    Archives and Museums'
  - Elizabeth Townsend Gard
  - 2017-10-02
  - 10.2139/ssrn.3049158
  - ! 'Section 108(h) has not been utilized by libraries and archives, in part because
    of the uncertainty over definitions (e.g. “normal commercial exploitation”), determination
    of the eligibility window (last twenty years of the copyright term of published
    works), and how to communicate the information in the record to the general public.
    This paper seeks to explore the elements necessary to implement the Last Twenty
    exception, otherwise known as Section 108(h) and create a Last Twenty (L20) collection.
    In short, published works in the last twenty years of the copyright may be digitized
    and distributed by libraries, archives, and museums, as long as there is no commercial
    sale of the works and no reasonably priced copy is available. This means that
    Section 108(h) is available for the forgotten and neglected works, 1923-1941,
    including millions of foreign works restored by <span class="smallcaps-auto">GATT</span>. Section 108(h) is less effective
    for big, commercially available works. In many ways, that is the dividing line
    created by Section 108(h): allow for commercial exploitation of works throughout
    their term, but allow libraries to rescue works that had no commercial exploitation
    or copies available for sale and make them available through copying and distribution
    for research, scholarship, and preservation. In fact, Section 108(h) when it was
    being debated in Congress was called labeled “orphan works.” This paper suggests
    ways to think about the requirements of Section 108(h) and to make it more usable
    for libraries. Essentially, by confidently using Section 108(h) we can continue
    to make the past usable one query at a time. The paper ends with an evaluation
    of the recent Discussion Paper by the U.S. Copyright Office on Section 108 and
    suggests changes/recommendations related to the proposed changes to Section 108(h).
    [Keywords: Copyright, Public Domain, Library, Archives, Museum, Section 108(h),
    Internet Archive, orphan works]'
- - https://openscholarship.wustl.edu/cgi/viewcontent.cgi?article=6319&context=law_lawreview
  - Algorithmic Entities
  - Lynn M. LoPucki
  - '2018'
  - ''
  - <p>In a 2014 article, Professor Shawn Bayern demonstrated that anyone can confer
    legal personhood on an autonomous computer algorithm by putting it in control
    of a limited liability company. Bayern’s demonstration coincided with the development
    of “autonomous” online businesses that operate independently of their human owners—accepting
    payments in online currencies and contracting with human agents to perform the
    off-line aspects of their businesses. About the same time, leading technologists
    Elon Musk, Bill Gates, and Stephen Hawking said that they regard human-level artificial
    intelligence as an existential threat to the human race.</p><p>This Article argues
    that algorithmic entities—legal entities that have no human controllers—greatly
    exacerbate the threat of artificial intelligence. Algorithmic entities are likely
    to prosper first and most in criminal, terrorist, and other anti-social activities
    because that is where they have their greatest comparative advantage over human-controlled
    entities. Control of legal entities will contribute to the threat algorithms pose
    by providing them with identities. Those identities will enable them to conceal
    their algorithmic natures while they participate in commerce, accumulate wealth,
    and carry out anti-social activities.</p><p>Four aspects of corporate law make
    the human race vulnerable to the threat of algorithmic entities. First, algorithms
    can lawfully have exclusive control of not just American <span class="smallcaps-auto">LLC</span>’s but also a large
    majority of the entity forms in most countries. Second, entities can change regulatory
    regimes quickly and easily through migration. Third, governments—particularly
    in the United States—lack the ability to determine who controls the entities they
    charter and so cannot determine which have non-human controllers. Lastly, corporate
    charter competition, combined with ease of entity migration, makes it virtually
    impossible for any government to regulate algorithmic control of entities.</p>
- - /docs/economics/2016-mclean.pdf
  - Does Academic Research Destroy Stock Return Predictability?
  - R. David McLean, Jeffrey Pontiff
  - 2016-02-01
  - 10.1111/jofi.12365
  - We study the out-of-sample and post-publication return predictability of 97 variables
    shown to predict cross-sectional stock returns. Portfolio returns are 26% lower
    out-of-sample and 58% lower post-publication. The out-of-sample decline is an
    upper bound estimate of data mining effects. We estimate a 32% (58%–26%) lower
    return from publication-informed trading. Post-publication declines are greater
    for predictors with higher in-sample returns, and returns are higher for portfolios
    concentrated in stocks with high idiosyncratic risk and low liquidity. Predictor
    portfolios exhibit post-publication increases in correlations with other published-predictor
    portfolios. Our findings suggest that investors learn about mispricing from academic
    publications.
- - /docs/sociology/2019-akbari.pdf
  - Kinship, fractionalization and corruption
  - Mahsa Akbari, Duman Bahrami-Rad, Erik O. Kimbrough
  - 2019-08-16
  - 10.1016/j.jebo.2019.07.015
  - ! 'We examine the roots of variation in corruption across societies, and we argue
    that marriage practices and family structure are an important, overlooked determinant
    of corruption. By shaping patterns of relatedness and interaction, marriage practices
    influence the relative returns to norms of nepotism/favoritism versus norms of
    impartial cooperation. In-marriage (e.g. consanguineous marriage) generates fractionalization
    because it yields relatively closed groups of related individuals and thereby
    encourages favoritism and corruption. Out-marriage creates a relatively open society
    with increased interaction between non-relatives and strangers, thereby encouraging
    impartiality. We report a robust association between in-marriage practices and
    corruption both across countries and within countries. Instrumental variables
    estimates exploiting historical variation in preferred marriage practices and
    in exposure to the Catholic Church’s family policies provide evidence that the
    relationship could be causal. [Keywords: Corruption, Fractionalization, Institutions,
    Mating patterns, Consanguinity]'
- - /docs/economics/1996-dempsey.pdf
  - ! 'Taxi Industry Regulation, Deregulation, and Reregulation: The Paradox of Market
    Failure'
  - Paul Stephen Dempsey
  - '1996'
  - ''
  - ! '<p>During the last fifteen years, Congress has deregulated, wholly or partly,
    a number of infrastructure industries, including most modes of transport&mdash;airlines,
    motor carriers, railroads, and intercity bus companies. Deregulation emerged in
    a comprehensive ideological movement which abhorred governmental pricing and entry
    controls as manifestly causing waste and inefficiency, while denying consumers
    the range of price and service options they desire.</p><p>In a nation dedicated
    to free market capitalism, governmental restraints on the freedom to enter into
    a business or allowing the competitive market to set the price seem fundamentally
    at odds with immutable notions of economic liberty. While in the late 19<sup>th</sup> and
    early 20<sup>th</sup> Century, market failure gave birth to economic regulation of infrastructure
    industries, today, we live in an era where the conventional wisdom is that government
    can do little good and the market can do little wrong.</p><p>Despite this passionate
    and powerful contemporary political/economic ideological movement, one mode of
    transportation has come full circle from regulation, through deregulation, and
    back again to regulation&mdash;the taxi industry. American cities began regulating
    local taxi firms in the 1920s. Beginning a half century later, more than 20 cities,
    most located in the Sunbelt, totally or partially deregulated their taxi companies.
    However, the experience with taxicab deregulation was so profoundly unsatisfactory
    that virtually every city that embraced it has since jettisoned it in favor of
    resumed economic regulation.</p><p>Today, nearly all large and medium-sized communities
    regulate their local taxicab companies. Typically, regulation of taxicabs involves:
    (1) limited entry (restricting the number of firms, and/or the ratio of taxis
    to population), usually under a standard of "public convenience and necessity,"
    [PC&N] (2) just, reasonable, and non-discriminatory fares, (3) service standards
    (e.g., vehicular and driver safety standards, as well as a common carrier obligation
    of non-discriminatory service, 24-hour radio dispatch capability, and a minimum
    level of response time), and (4) financial responsibility standards (e.g., insurance).</p><p>This
    article explores the legal, historical, economic, and philosophical bases of regulation
    and deregulation in the taxi industry, as well as the empirical results of taxi
    deregulation. The paradoxical metamorphosis from regulation, to deregulation,
    and back again, to regulation is an interesting case study of the collision of
    economic theory and ideology, with empirical reality. We begin with a look at
    the historical origins of taxi regulation.</p> <p>[Keywords: Urban Transportation,
    Taxi Industry, Common Carrier, Mass Transit, Taxi Industry Regulation, Taxi Deregulation,
    Reregulation, Taxicab Ordinance, <span class="smallcaps-auto">PUC</span>, Open Entry, Reglated Entry, Operating Efficiency,
    Destructive Competition, Regulated Competition, Cross Subsidy, Cream Skimming,
    PC&N, Pollution, Cabs]</p>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.708.3217&rep=rep1&type=pdf
  - Taxes, Lawyers, and the Decline of Witch Trials in France
  - Noel D. Johnson, Mark Koyama
  - 2014-02-01
  - 10.1086/674900
  - How is rule of law established? We address this question by exploring the effect
    of increases in fiscal capacity on the establishment of well-enforced, formal,
    legal standards in a preindustrial economy. Between 1550 and 1700, there were
    over 2,000 witch trials in France. Prosecuting a witch required local judges to
    significantly deviate from formal rules of evidence. Hence, we exploit the significant
    variation across time and space in witch trials and fiscal capacity across French
    regions between 1550 and 1700 to show that increases in fiscal capacity were associated
    with increased adherence to the formal rule of law. As fiscal capacity increased,
    local judges increasingly upheld de jure rules, and the frequency of witch trials
    declined.
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.364.697&rep=rep1&type=pdf
  - ! 'The Age of Reason: Financial Decisions over the Life Cycle and Implications
    for Regulation'
  - Sumit Agarwal, John C. Driscoll, Xavier Gabaix, David Laibson
  - '2009'
  - 10.1353/eca.0.0067
  - Many consumers make poor financial choices, and older adults are particularly
    vulnerable to such errors. About half of the population between ages 80 and 89
    have a medical diagnosis of substantial cognitive impairment. We study life-cycle
    patterns in financial mistakes using a proprietary database with information on
    10 types of credit transactions. Financial mistakes include suboptimal use of
    credit card balance transfer offers and excess interest rate and fee payments.
    In a cross section of prime borrowers, middle-aged adults made fewer financial
    mistakes than either younger or older adults. We conclude that financial mistakes
    follow a U-shaped pattern, with the cost-minimizing performance occurring around
    age 53. We analyze nine regulatory strategies that may help individuals avoid
    financial mistakes. We discuss laissez-faire, disclosure, nudges, financial "driver's
    licenses," advance directives, fiduciaries, asset safe harbors, and ex post and
    ex ante regulatory oversight. Finally, we pose seven questions for future research
    on cognitive limitations and associated policy responses.
- - https://harpers.org/archive/1998/11/the-radioactive-boy-scout/?single=1
  - ! 'The Radioactive Boy Scout: When a teenager attempts to build a breeder reactor'
  - Ken Silverstein (Harper's)
  - 1998-11-01
  - ''
  - ! 'Growing up in suburban Detroit, David Hahn was fascinated by science. While
    he was working on his Atomic Energy badge for the Boy Scouts, David’s obsessive
    attention turned to nuclear energy. Throwing caution to the wind, he plunged into
    a new project: building a model nuclear reactor in his backyard garden shed. Posing
    as a physics professor, David solicited information on reactor design from the
    U.S. government and from industry experts. Following blueprints he found in an
    outdated physics textbook, David cobbled together a crude device that threw off
    toxic levels of radiation. His wholly unsupervised project finally sparked an
    environmental emergency that put his town’s forty thousand suburbanites at risk.
    The <span class="smallcaps-auto">EPA</span> ended up burying his lab at a radioactive dumpsite in Utah. [Keywords:
    20<sup>th</sup> century, David Hahn, Experiments, Michigan, Nuclear engineering, Radiochemistry,
    Recreation, Teenage boys].'
- - /Embryo-selection#history-of-ies
  - History of IES (Iterated Embryo Selection)
  - Gwern Branwen
  - 2019-01-18
  - ''
  - <p>The idea of <em>iterated embryo selection</em>—conducing multiple generations
    of embryo selection in a petri dish by exploiting gametogenesis or stem cells—has
    a complicated history. Tracing relevant papers back to 1989, the idea appears
    to have been invented independently at least 4 times, and has been proposed under
    as many names.</p><p>A predecessor was introduced by <a href="/docs/genetics/selection/1991-georges.pdf">Georges
    & Massey 1991</a> as “velogenetics”. Velogenetics led to what appears to be the
    first invention of <span class="smallcaps-auto">IES</span>, <a href="/docs/genetics/selection/1998-haley.pdf">Haley
    & Visscher 1998’s</a> “whizzogenetics”. It was then invented in 2009 by <a href="https://web.archive.org/web/20091214014113/http://theuncertainfuture.com/faq.html#7">Carl
    Shulman</a> as “iterated embryo selection”/“<span class="smallcaps-auto">IES</span>”. It was reinvented a third time
    by <a href="https://pdfs.semanticscholar.org/29d0/884cf4ed6acdb2711f556863a1ef2bd3a908.pdf">Sparrow
    2013</a< as “in vitro eugenics”. And it was reinvented up to three times in 2018,
    as “in vitro breeding”, by <a href="https://www.pnas.org/content/pnas/early/2018/02/08/1716161115.full.pdf">Bogliotti
    et al 2018</a>/<a href="/docs/genetics/selection/2018-goszczynski.pdf">Goszczynski
    et al 2018</a>/<a href="https://jasbsci.biomedcentral.com/articles/10.1186/s40104-018-0304-7">Hou
    et al 2018</a> (whose relationship is unclear, as the latter two claim novelty
    but publish not just the same idea but same name, while the former, published
    before them and giving said name & idea, nevertheless does not claim novelty).</p>
- - /Embryo-selection#glue-robbers-sequencing-nobelists-using-collectible-letters
  - ! 'Glue Robbers: Sequencing Nobelists Using Collectible Letters'
  - Gwern Branwen
  - 2019-03-04
  - ''
  - <p>A major challenge in <span class="smallcaps-auto">GWAS</span>es of cognitive traits like intelligence &amp; personality
    is getting sufficient statistical power to produce results. Statistical power
    can be increased by increasing sample size, or increasing the ‘effect size’ (ie
    size of differences). One way of increasing effect size is collecting extreme
    datapoints, such as the extremely-high IQ <span class="smallcaps-auto">TIP</span>/<span class="smallcaps-auto">SMPY</span> samples for comparison with
    a baseline group. As such datapoints are by definition rare, they are hard to
    collect in bulk. This is true for other cognitive traits such as personality,
    ambition, accomplishment, scientific breakthroughs—all of which are surely connected
    with each other &amp; intelligence, but even harder to screen for &amp; collect
    genomes.</p><p>The increasing power of <span class="smallcaps-auto">DNA</span> sequencing methods means that as of
    2018, one can extract &amp; sequence <span class="smallcaps-auto">DNA</span> from envelopes &amp; postal stamps which
    are decades or centuries old. This is legally permissible, and many such envelopes
    &amp; stamps from historical figures can be bought for low prices. This means
    that one can potentially genotype—in addition to everyone else in the past—the
    greatest minds in history and run analyses. They could be used as an ultra-highly-enriched
    sample in <span class="smallcaps-auto">GWAS</span>es for intelligence or achievement with potentially high statistical
    power and combined with other datasets for further gains in <span class="smallcaps-auto">PGS</span>es.</p>
- - /Embryo-selection#iq-income-bibliography
  - IQ/income bibliography
  - Gwern Branwen
  - 2016-02-17
  - ''
  - Partial bibliography of fulltext papers discussing intelligence and income or
    socioeconomic status.
- - /Archiving-URLs#sort---key-compression-trick
  - The `sort --key` compression trick (CLI folklore)
  - Gwern Branwen
  - 2014-03-03
  - ''
  - <p>Programming folklore notes that one way to get better lossless compression
    efficiency is to rearrange files inside the archive to group ‘similar’ files together
    and expose redundancy to the compressor, in accordance with information-theoretical
    principles. A particularly easy and broadly-applicable way of doing this, which
    does not require using any unusual formats or tools and is fully compatible with
    the default archive methods, is to sort the files by <em>filename</em> and especially
    file extension. I show how to do this with the standard Unix command-line <code>sort</code>
    tool, using the so-called “<code>sort --key</code> trick”, and give examples of
    the large space-savings possible from my archiving work for personal website mirrors
    and for making <a href="/DNM-archives">darknet market mirror datasets</a> where
    the redundancy at the file level is particularly extreme and the <code>sort --key</code>
    trick shines compared to the naive approach.</p>
- - http://www.unm.edu/~gfmiller/newpapers_sept6/penke%202007%20targetarticle.pdf
  - The Evolutionary Genetics of Personality
  - Lars Penke, Jaap J. A. Denissen, Geoffrey F. Miller
  - 2007-04-27
  - 10.1002/per.629
  - ! 'Genetic influences on personality differences are ubiquitous, but their nature
    is not well understood. A theoretical framework might help, and can be provided
    by evolutionary genetics. We assess three evolutionary genetic mechanisms that
    could explain genetic variance in personality differences: selective neutrality,
    mutation-selection balance, and balancing selection. Based on evolutionary genetic
    theory and empirical results from behaviour genetics and personality psychology,
    we conclude that selective neutrality is largely irrelevant, that mutation-selection
    balance seems best at explaining genetic variance in intelligence, and that balancing
    selection by environmental heterogeneity seems best at explaining genetic variance
    in personality traits. We propose a general model of heritable personality differences
    that conceptualises intelligence as fitness components and personality traits
    as individual reaction norms of genotypes across environments, with different
    fitness consequences in different environmental niches. We also discuss the place
    of mental health in the model. This evolutionary genetic framework highlights
    the role of gene-environment interactions in the study of personality, yields
    new insight into the person-situation-debate and the structure of personality,
    and has practical implications for both quantitative and molecular genetic studies
    of personality. [Keywords: evolutionary psychology; personality differences; behaviour
    genetics; intelligence; personality traits; gene-environment interactions; mutation
    load; mutation-selection balance; mutational cross-section; epistasis; frequency-dependent
    selection]'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3590899/
  - Procreative beneficence and <em>in vitro</em> gametogenesis
  - Hannah Bourne, Thomas Douglas, Julian Savulescu
  - 2012-09-01
  - 10.1007/bf03351338
  - ! '<p>The Principle of Procreative Beneficence (PB) holds that when a couple plans
    to have a child, they have significant moral reason to select, of the possible
    children they could have, the child who is most likely to experience the greatest
    wellbeing – that is, the most advantaged child, the child with the best chance
    at the best life…In this paper we wish address a different and more practical
    objection: the objection that parents will be heavily restricted in the number
    of traits that they can select, since they will have to choose among a very limited
    number of embryos. Recent advances in stem cell research may provide a solution
    to this problem. Recent research suggests that it may become possible to derive
    gametes (eggs and sperm) from human stem cells in vitro, a process which we will
    term in vitro gametogenesis (<span class="smallcaps-auto">IVG</span>). <span class="smallcaps-auto">IVG</span> would allow the creation of stems cells
    from a patient’s somatic (body) cells, and these stems cells could then be used
    to generate a plentiful supply of eggs or sperm in the laboratory…The ability
    to create large numbers of eggs or sperm through <span class="smallcaps-auto">IVG</span> greatly increases our capacity
    to select the best child possible. Selection could occur in two ways: (1) the
    most genetically desirable of this massive number of gametes could be selected
    and then used to create an embryo, or alternatively, (2) large numbers of embryos
    could be produced from these gametes and then the best embryo selected. Whatever
    the method, the advent of <span class="smallcaps-auto">IVG</span> could allow us to select for a much larger number
    of traits than is currently conceivable.</p><p>…Suppose that a couple would
    like to select for 20 single gene traits which are carried on 20 different and
    unlinked autosomal loci. Suppose further that at ten of these loci, alleles contribute
    recessively to the desired trait…The chance of the couple having such a child
    would be just over 1% with traditional <span class="smallcaps-auto">IVF</span> plus selection, but would increased
    to over 99.99% if 10,000 embryos could be created using <span class="smallcaps-auto">IVG</span>…By enabling the
    creation of large numbers of gametes and embryos, <span class="smallcaps-auto">IVG</span> may allow the selection
    of traits in future children to a degree that has previously been inconceivable.</p>'
- - /docs/economics/2010-rost.pdf
  - The corporate governance of Benedictine abbeys
  - Katja Rost, Emil Inauen, Margit Osterloh, Bruno S. Frey
  - 2010-01-12
  - 10.1108/17511341011008331
  - ! '<p><em>Purpose</em>: This paper aims to analyse the governance structure of
    monasteries to gain new insights and apply them to solve agency problems of modern
    corporations. In an historic analysis of crises and closures it asks, if Benedictine
    monasteries were and are capable of solving agency problems. The analysis shows
    that monasteries established basic governance instruments very early and therefore
    were able to survive for centuries.</p><p><em>Design/methodology/approach</em>:
    The paper uses a dataset of all Benedictine abbeys that ever existed in Bavaria,
    Baden‐Württemberg, and German‐speaking Switzerland to determine their lifespan
    and the reasons for closures. The governance mechanisms are analyzed in detail.
    Finally, it draws conclusions relevant to the modern corporation. The theoretical
    foundations are based upon principal agency theory, psychological economics, as
    well as embeddedness theory.</p><p><em>Findings</em>: The monasteries that are
    examined show an average lifetime of almost 500 years and only a quarter of them
    dissolved as a result of agency problems. This paper argues that this success
    is due to an appropriate governance structure that relies strongly on internal
    control mechanisms.</p><p><em>Research limitations/implications</em>: Benedictine
    monasteries and stock corporations differ fundamentally regarding their goals.
    Additional limitations of the monastic approach are the tendency to promote groupthink,
    the danger of dictatorship and the life long commitment.</p><p><em>Practical implications</em>:
    The paper adds new insights into the corporate governance debate designed to solve
    current agency problems and facilitate better control.</p><p><em>Originality/value</em>:
    By analyzing monasteries, a new approach is offered to understand the efficiency
    of internal behavioral incentives and their combination with external control
    mechanisms in corporate governance.</p>'
- - https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&topic_id=1
  - Sparkline theory and practice
  - Edward Tufte et al
  - '2004'
  - ''
  - ! '[Originally the draft chapter of the <a href="https://en.wikipedia.org/wiki/Sparkline">sparkline</a>
    ("Intense, Simple, Word-Sized Graphics") chapter of <a href="https://en.wikipedia.org/wiki/Edward_Tufte">Edward
    Tufte''s</a> <em>Beautiful Evidence</em> (2005), this page is a compilation of
    sparkline examples, links to sparkline software tools, and debates over how best
    to use sparklines to graph statistical data.]'
- - /Faces#biggan
  - Generating Anime Faces with BigGAN
  - Gwern Branwen
  - 2019-06-04
  - ''
  - I explore Big<span class="smallcaps-auto">GAN</span>, another recent <span class="smallcaps-auto">GAN</span> with <span class="smallcaps-auto">SOTA</span> results on the most complex image
    domain tackled by <span class="smallcaps-auto">GAN</span>s so far, ImageNet. Big<span class="smallcaps-auto">GAN</span>'s capabilities come at a steep
    compute cost, however. I experiment with 128px ImageNet transfer learning (successful)
    with ~6 <span class="smallcaps-auto">GPU</span>-days, and from-scratch 256px anime portraits of 1000 characters on
    a 8x2080ti machine for a month (mixed results). My Big<span class="smallcaps-auto">GAN</span> results are good but
    compromised by practical problems with the released Big<span class="smallcaps-auto">GAN</span> code base. While Big<span class="smallcaps-auto">GAN</span>
    is not yet superior to Style<span class="smallcaps-auto">GAN</span> for many purposes, Big<span class="smallcaps-auto">GAN</span>-like approaches may
    turn out to be necessary to scale to whole anime images.
- - /docs/sunkcosts/2003-carmichael.pdf
  - ! 'Caring About Sunk Costs: A Behavioral Solution to Holdup Problems With Small
    Stakes'
  - Lorne Carmichael, W. Bentley MacLeod
  - 2003-04-01
  - 10.1093/jleo/19.1.106
  - Economics students need to be taught that opportunity costs are important for
    optimal decision making but that sunk costs are not. Why should this be? Presumably
    these students have been making optimal decisions all their lives, and the concepts
    should be easy for them. We show that caring about sunk costs can help agents
    achieve efficient investments in a simple team production environment. Furthermore,
    the solution we propose is uniquely efficient if the environment is sufficiently
    complex. Hence, in addition to explaining contract form and ownership (Williamson,
    1975; Hart, 1995), studies of the holdup problem may also provide insights into
    observed behavior in day-today bilateral bargaining problems.
- - /docs/sunkcosts/2010-cohen.pdf
  - Free Distribution or Cost-Sharing? Evidence from a Randomized Malaria Prevention
    Experiment
  - Jessica Cohen, Pascaline Dupas
  - 2010-02-01
  - 10.2307/40506276
  - ! 'It is often argued that cost-sharing—charging a subsidized, positive price—for
    a health product is necessary to avoid wasting resources on those who will not
    use or do not need the product. We explore this argument through a field experiment
    in Kenya, in which we randomized the price at which prenatal clinics could sell
    long-lasting antimalarial insecticide-treated bed nets (<span class="smallcaps-auto">ITN</span>s) to pregnant women.
    We find no evidence that cost-sharing reduces wastage on those who will not use
    the product: women who received free <span class="smallcaps-auto">ITN</span>s are not less likely to use them than
    those who paid subsidized positive prices. We also find no evidence that cost-sharing
    induces selection of women who need the net more: those who pay higher prices
    appear no sicker than the average prenatal client in the area in terms of measured
    anemia (an important indicator of malaria). Cost-sharing does, however, considerably
    dampen demand. We find that uptake drops by sixty percentage points when the price
    of <span class="smallcaps-auto">ITN</span>s increases from zero to $0.60 (i.e., from 100% to 90% subsidy), a price
    still $0.15 below the price at which <span class="smallcaps-auto">ITN</span>s are currently sold to pregnant women
    in Kenya. We combine our estimates in a cost-effectiveness analysis of the impact
    of <span class="smallcaps-auto">ITN</span> prices on child mortality that incorporates both private and social returns
    to <span class="smallcaps-auto">ITN</span> usage. Overall, our results suggest that free distribution of <span class="smallcaps-auto">ITN</span>s could
    save many more lives than cost-sharing programs have achieved so far, and, given
    the large positive externality associated with widespread usage of <span class="smallcaps-auto">ITN</span>s, would
    likely do so at a lesser cost per life saved. [Keywords: Subsidies, Prices, Malaria,
    Distribution costs, Sharing, Women, Anemia, Cost efficiency, Random allocation,
    Sunk costs]'
- - /docs/sunkcosts/2007-karavanov.pdf
  - ! 'Factors Affecting Entrapment: Justification Needs, Face Concerns, and Personal
    Networks'
  - Anya Karavanov, Deborah A. Cai
  - '2007'
  - 10.2139/ssrn.1087332
  - ! '<p>This study explores the link between the entrapment bias and the concept
    of face (self- and other-positive) and internal and external justification processes.
    It examines how face-saving concerns and justification needs moderate the entrapment
    bias in accountability condition (i.e., presence of constituencies and reporting
    requirements). In addition, this research looks at whether the size and influence
    of personal networks is associated with face-saving behaviors that, in turn, affect
    entrapment. The research also explores whether overall face concerns have an effect
    on internal and external self-justification.</p><p>Participants were 236 undergraduate
    communication majors enrolled in a large East Coast university, who were assigned
    to one of the four conditions: (1) constituency, reporting; (2) constituency,
    no reporting; (3) no constituency; reporting; (4) no constituency; no reporting.</p><p>The
    current investigation did not support the findings from previous studies that
    suggest that justification processes and face concerns lead to entrapment. This
    study found that only internal self-justification and other-positive face concerns
    are related to entrapment, but instead of contributing to entrapment, these aspects
    prevent individuals from becoming entrapped. Personal networks were demonstrated
    to have positive effect on both self- and other-positive face concerns, providing
    empirical support for the value of using personal networks as a predictor of face
    goals. However, personal networks did not contribute to entrapment.</p><p>Overall,
    this study identifies processes and conditions (e.g., concern for other-positive
    face, internal self-justification, reporting requirement, no direct observation
    by constituency, keeping clear record of performance success or failure) that
    may prevent the entrapment bias from occurring. Implications of this research
    are discussed as well as directions for future research.</p>'
- - /docs/sunkcosts/2018-hong.pdf
  - Sunk Cost as a Self-Management Device
  - Fuhai Hong, Wei Huang, Xiaojian Zhao
  - 2018-08-01
  - 10.1287/mnsc.2018.3032
  - <p>The sunk cost effect has been widely observed in individual decisions. Building
    on an intrapersonal self-management game, the paper theoretically shows that the
    sunk cost effect may stem from an attempt to overcome the underinvestment problem
    associated with a high degree of present bias or to resolve the multi-selves coordination
    problem when the degree of present bias is low. Especially for individuals with
    severe present bias, the current self may take a costly action (which is a sunk
    cost for the future self) to signal the individual’s high success probability
    that motivates his future self-disciplining behaviors. In equilibrium, a higher
    level of sunk cost is more likely to give rise to a higher probability for the
    individual to continue the project. We then conduct a laboratory experiment. The
    empirical findings are consistent with our theoretical implications.</p> <p>The
    online appendix is available at <a href="https://doi.org/10.1287/mnsc.2018.3032">10.1287/mnsc.2018.3032</a></p>.
- - https://www.andrew.cmu.edu/user/nicolasc/publications/Christin-WWW13.pdf
  - ! 'Traveling the Silk Road: A Measurement Analysis of a Large Anonymous Online
    Marketplace'
  - Nicolas Christin
  - 2013-05-13
  - 10.1145/2488388.2488408
  - ! 'We perform a comprehensive measurement analysis of Silk Road, an anonymous,
    international online marketplace that operates as a Tor hidden service and uses
    Bitcoin as its exchange currency. We gather and analyze data over eight months
    between the end of 2011 and 2012, including daily crawls of the marketplace for
    nearly six months in 2012. We obtain a detailed picture of the type of goods sold
    on Silk Road, and of the revenues made both by sellers and Silk Road operators.
    Through examining over 24,400 separate items sold on the site, we show that Silk
    Road is overwhelmingly used as a market for controlled substances and narcotics,
    and that most items sold are available for less than three weeks. The majority
    of sellers disappears within roughly three months of their arrival, but a core
    of 112 sellers has been present throughout our measurement interval. We evaluate
    the total revenue made by all sellers,from public listings, to slightly over <span class="smallcaps-auto">USD</span>
    1.2 million per month; this corresponds to about <span class="smallcaps-auto">USD</span> 92,000 per month in commissions
    for the Silk Road operators. We further show that the marketplace has been operating
    steadily, with daily sales and number of sellers overall increasing over our measurement
    interval. We discuss economic and policy implications of our analysis and results,
    including ethical considerations for future research in this area. [Keywords:
    Online crime, anonymity, electronic commerce]'
- - https://msu.edu/course/eng/487/johnsen/61.1moretti.pdf
  - The Slaughterhouse of Literature
  - Franco Moretti
  - 2000-03-01
  - ''
  - ! '<p>The history of the world is the slaughterhouse of the world, reads a famous
    Hegelian aphorism; and of literature. The majority of books disappear forever—and
    “majority” actually misses the point: if we set today’s canon of nineteenth-century
    British novels at two hundred titles (which is a very high figure), they would
    still be only about 0.5 <em>percent</em> of all published novels.</p> <p>[Literature
    paper by <a href="https://en.wikipedia.org/wiki/Franco_Moretti">Franco Moretti</a>.
    Moretti considers the vast production of literature of which only the slightest
    fraction is still read and studied as part of a ''canon''. Canons are formed by
    market forces, leading to preservation and reading in a feedback loop&mdash;far
    from academics selecting the best based on esthetic grounds. Moretti offers a
    case study of Arthur Conan Doyle''s Sherlock Holmes by comparing to all the now-forgotten
    competing detective fiction, to study the evolution of the idea of a ''clue'';
    his competitors reveal its difficult evolution and how everyone groped towards
    it. Surprisingly, clues were neither obvious nor popular nor showed any clear
    evolution towards success. This raises puzzling questions about how to create
    and interpret ''literary history''.]</p>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.508.2792&rep=rep1&type=pdf
  - Does High Self-Esteem Cause Better Performance, Interpersonal Success, Happiness,
    Or Healthier Lifestyles?
  - Roy F. Baumeister, Jennifer D. Campbell, Joachim I. Krueger, Kathleen D. Vohs
  - 2003-05-01
  - 10.1111/1529-1006.01431
  - ! '<p>Self-esteem has become a household word. Teachers, parents, therapists,
    and others have focused efforts on boosting self-esteem, on the assumption that
    high self-esteem will cause many positive outcomes and benefits—an assumption
    that is critically evaluated in this review.</p><p>Appraisal of the effects of
    self-esteem is complicated by several factors. Because many people with high self-esteem
    exaggerate their successes and good traits, we emphasize objective measures of
    outcomes. High self-esteem is also a heterogeneous category, encompassing people
    who frankly accept their good qualities along with narcissistic, defensive, and
    conceited individuals.</p><p>The modest correlations between self-esteem and school
    performance do not indicate that high self-esteem leads to good performance. Instead,
    high self-esteem is partly the result of good school performance. Efforts to boost
    the self-esteem of pupils have not been shown to improve academic performance
    and may sometimes be counterproductive. Job performance in adults is sometimes
    related to self-esteem, although the correlations vary widely, and the direction
    of causality has not been established. Occupational success may boost self-esteem
    rather than the reverse. Alternatively, self-esteem may be helpful only in some
    job contexts. Laboratory studies have generally failed to find that self-esteem
    causes good task performance, with the important exception that high self-esteem
    facilitates persistence after failure.</p><p>People high in self-esteem claim
    to be more likable and attractive, to have better relationships, and to make better
    impressions on others than people with low self-esteem, but objective measures
    disconfirm most of these beliefs. Narcissists are charming at first but tend to
    alienate others eventually. Self-esteem has not been shown to predict the quality
    or duration of relationships.</p><p>High self-esteem makes people more willing
    to speak up in groups and to criticize the group’s approach. Leadership does not
    stem directly from self-esteem, but self-esteem may have indirect effects. Relative
    to people with low self-esteem, those with high self-esteem show stronger in-group
    favoritism, which may increase prejudice and discrimination.</p><p>Neither high
    nor low self-esteem is a direct cause of violence. Narcissism leads to increased
    aggression in retaliation for wounded pride. Low self-esteem may contribute to
    externalizing behavior and delinquency, although some studies have found that
    there are no effects or that the effect of self-esteem vanishes when other variables
    are controlled. The highest and lowest rates of cheating and bullying are found
    in different subcategories of high self-esteem.</p><p>Self-esteem has a strong
    relation to happiness. Although the research has not clearly established causation,
    we are persuaded that high self-esteem does lead to greater happiness. Low self-esteem
    is more likely than high to lead to depression under some circumstances. Some
    studies support the buffer hypothesis, which is that high self-esteem mitigates
    the effects of stress, but other studies come to the opposite conclusion, indicating
    that the negative effects of low self-esteem are mainly felt in good times. Still
    others find that high self-esteem leads to happier outcomes regardless of stress
    or other circumstances.</p><p>High self-esteem does not prevent children from
    smoking, drinking, taking drugs, or engaging in early sex. If anything, high self-esteem
    fosters experimentation, which may increase early sexual activity or drinking,
    but in general effects of self-esteem are negligible. One important exception
    is that high self-esteem reduces the chances of bulimia in females.</p><p>Overall,
    the benefits of high self-esteem fall into two categories: enhanced initiative
    and pleasant feelings. We have not found evidence that boosting self-esteem (by
    therapeutic interventions or school programs) causes benefits. Our findings do
    not support continued widespread efforts to boost self-esteem in the hope that
    it will by itself foster improved outcomes. In view of the heterogeneity of high
    self-esteem, indiscriminate praise might just as easily promote narcissism, with
    its less desirable consequences. Instead, we recommend using praise to boost self-esteem
    as a reward for socially desirable behavior and self-improvement.</p>'
- - /docs/iq/1969-jensen-her.pdf
  - How Much Can We Boost IQ and Scholastic Achievement?
  - Arthur R. Jensen
  - 1969-05-01
  - 10.17763/haer.39.1.l3u15956627424k7
  - ! '<p>Arthur Jensen argues that the failure of recent compensatory education efforts
    to produce lasting effects on children''s IQ and achievement suggests that the
    premises on which these efforts have been based should be reexamined. He begins
    by questioning a central notion upon which these and other educational programs
    have recently been based: that IQ differences are almost entirely a result of
    environmental differences and the cultural bias of IQ tests. After tracing the
    history of IQ tests, Jensen carefully defines the concept of IQ, pointing out
    that it appears as a common factor in all tests that have been devised thus far
    to tap higher mental processes. Having defined the concept of intelligence and
    related it to other forms of mental ability, Jensen employs an analysis of variance
    model to explain how IQ can be separated into genetic and environmental components.
    He then discusses the concept of "heritability," a statistical tool for assessing
    the degree to which individual differences in a trait like intelligence can be
    accounted for by genetic factors. He analyzes several lines of evidence which
    suggest that the heritability of intelligence is quite high (i.e., genetic factors
    are much more important than environmental factors in producing IQ differences).
    After arguing that environmental factors are not nearly as important in determining
    IQ as are genetic factors, Jensen proceeds to analyze the environmental influences
    which may be most critical in determining IQ. He concludes that prenatal influences
    may well contribute the largest environmental influence on IQ. He then discusses
    evidence which suggests that social class and racial variations in intelligence
    cannot be accounted for by differences in environment but must be attributed partially
    to genetic differences. After he has discussed the influence on the distribution
    of IQ in a society on its functioning, Jensen examines in detail the results of
    educational programs for young children, and finds that the changes in IQ produced
    by these programs are generally small. A basic conclusion of Jensen''s discussion
    of the influence of environment on IQ is that environment acts as a "threshold
    variable." Extreme environmental deprivation can keep the child from performing
    up to his genetic potential, but an enriched educational program cannot push the
    child above that potential. Finally, Jensen examines other mental abilities that
    might be capitalized on in an educational program, discussing recent findings
    on diverse patterns of mental abilities between ethnic groups and his own studies
    of associative learning abilities that are independent of social class. He concludes
    that educational attempts to boost IQ have been misdirected and that the educational
    process should focus on teaching much more specific skills. He argues that this
    will be accomplished most effectively if educational methods are developed which
    are based on other mental abilities besides I.Q.'
- - /docs/statistics/causality/1987-fraker.pdf
  - The Adequacy of Comparison Group Designs for Evaluations of Employment-Related
    Programs
  - Thomas Fraker, Rebecca Maynard
  - '1987'
  - 10.2307/145902
  - ! 'This study investigates empirically the strengths and limitations of using
    experimental versus nonexperimental designs for evaluating employment and training
    programs. The assessment involves comparing results from an experimental-design
    study-the National Supported Work Demonstration-with the estimated impacts of
    Supported Work based on analyses using comparison groups constructed from the
    Current Population Surveys. The results indicate that nonexperimental designs
    cannot be relied on to estimate the effectiveness of employment programs. Impact
    estimates tend to be sensitive both to the comparison group construction methodology
    and to the analytic model used. There is currently no way a priori to ensure that
    the results of comparison group studies will be valid indicators of the program
    impacts. [Keywords: Public assistance programs, Analytical models, Analytical
    estimating, Employment, Control groups, Estimation methods, Random sampling, Human
    resources, Public works legislation, Statistical significance]'
- - /docs/iq/2018-lee.pdf
  - Gene discovery and polygenic prediction from a genome-wide association study of
    educational attainment in 1.1 million individuals
  - James J. Lee, Robbee Wedow, Aysu Okbay, Edward Kong, Omeed Maghzian, Meghan Zacher,
    Tuan Anh Nguyen-Viet, Peter Bowers, Julia Sidorenko, Richard Karlsson Linnér,
    Mark Alan Fontana, Tushar Kundu, Chanwook Lee, Hui Li, Ruoxi Li, Rebecca Royer,
    Pascal N. Timshel, Raymond K. Walters, Emily A. Willoughby, Loïc Yengo, 23andMe
    Research Team, <span class="smallcaps-auto">COGENT</span> (Cognitive Genomics Consortium), Social Science Genetic
    Association Consortium, Maris Alver, Yanchun Bao, David W. Clark, Felix R. Day,
    Nicholas A. Furlotte, Peter K. Joshi, Kathryn E. Kemper, Aaron Kleinman, Claudia
    Langenberg, Reedik Mägi, Joey W. Trampush, Shefali Setia Verma, Yang Wu, Max Lam,
    Jing Hua Zhao, Zhili Zheng, Jason D. Boardman, Harry Campbell, Jeremy Freese,
    Kathleen Mullan Harris, Caroline Hayward, Pamela Herd, Meena Kumari, Todd Lencz,
    Jian’an Luan, Anil K. Malhotra, Andres Metspalu, Lili Milani, Ken K. Ong, John
    R. B. Perry, David J. Porteous, Marylyn D. Ritchie, Melissa C. Smart, Blair H.
    Smith, Joyce Y. Tung, Nicholas J. Wareham, James F. Wilson, Jonathan P. Beauchamp,
    Dalton C. Conley, Tõnu Esko, Steven F. Lehrer, Patrik K. E. Magnusson, Sven Oskarsson,
    Tune H. Pers, Matthew R. Robinson, Kevin Thom, Chelsea Watson, Christopher F.
    Chabris, Michelle N. Meyer, David I. Laibson, Jian Yang, Magnus Johannesson, Philipp
    D. Koellinger, Patrick Turley, Peter M. Visscher, Daniel J. Benjamin & David Cesarini
  - 10.1038/s41588-018-0147-3
  - 2018-07-23
  - Here we conducted a large-scale genetic association analysis of educational attainment
    in a sample of approximately 1.1 million individuals and identify 1,271 independent
    genome-wide-significant <span class="smallcaps-auto">SNP</span>s. For the <span class="smallcaps-auto">SNP</span>s taken together, we found evidence of
    heterogeneous effects across environments. The <span class="smallcaps-auto">SNP</span>s implicate genes involved in
    brain-development processes and neuron-to-neuron communication. In a separate
    analysis of the X chromosome, we identify 10 independent genome-wide-significant
    <span class="smallcaps-auto">SNP</span>s and estimate a <span class="smallcaps-auto">SNP</span> heritability of around 0.3% in both men and women, consistent
    with partial dosage compensation. A joint (multi-phenotype) analysis of educational
    attainment and three related cognitive phenotypes generates polygenic scores that
    explain 11–13% of the variance in educational attainment and 7–10% of the variance
    in cognitive performance. This prediction accuracy substantially increases the
    utility of polygenic scores as tools in research.
- - /docs/iq/2016-okbay-2.pdf
  - Genome-wide association study identifies 74 loci associated with educational attainment
  - Aysu Okbay, Jonathan P. Beauchamp, Mark Alan Fontana, James J. Lee, Tune H. Pers,
    Cornelius A. Rietveld, Patrick Turley, Guo-Bo Chen, Valur Emilsson, S. Fleur W.
    Meddens, Sven Oskarsson, Joseph K. Pickrell, Kevin Thom, Pascal Timshel, Ronald
    de Vlaming, Abdel Abdellaoui, Tarunveer S. Ahluwalia, Jonas Bacelis, Clemens Baumbach,
    Gyda Bjornsdottir, Johannes H. Brandsma, Maria Pina Concas, Jaime Derringer, Nicholas
    A. Furlotte, Tessel E. Galesloot, Giorgia Girotto, Richa Gupta, Leanne M. Hall,
    Sarah E. Harris, Edith Hofer, Momoko Horikoshi, Jennifer E. Huffman, Kadri Kaasik,
    Ioanna P. Kalafati, Robert Karlsson, Augustine Kong, Jari Lahti, Sven J. van der  Lee,
    Christiaan de Leeuw, Penelope A. Lind, Karl-Oskar Lindgren, Tian Liu, Massimo
    Mangino, Jonathan Marten, Evelin Mihailov, Michael B. Miller, Peter J. van der
    Most, Christopher Oldmeadow, Antony Payton, Natalia Pervjakova, Wouter J. Peyrot,
    Yong Qian, Olli Raitakari, Rico Rueedi, Erika Salvi, Börge Schmidt, Katharina
    E. Schraut, Jianxin Shi, Albert V. Smith, Raymond A. Poot, Beate St Pourcain,
    Alexander Teumer, Gudmar Thorleifsson, Niek Verweij, Dragana Vuckovic, Juergen
    Wellmann, Harm-Jan Westra, Jingyun Yang, Wei Zhao, Zhihong Zhu, Behrooz Z. Alizadeh,
    Najaf Amin, Andrew Bakshi, Sebastian E. Baumeister, Ginevra Biino, Klaus Bønnelykke,
    Patricia A. Boyle, Harry Campbell, Francesco P. Cappuccio, Gail Davies, Jan-Emmanuel
    De Neve, Panos Deloukas, Ilja Demuth, Jun Ding, Peter Eibich, Lewin Eisele, Niina
    Eklund, David M. Evans, Jessica D. Faul, Mary F. Feitosa, Andreas J. Forstner,
    Ilaria Gandin, Bjarni Gunnarsson, Bjarni V. Halldórsson, Tamara B. Harris, Andrew
    C. Heath, Lynne J. Hocking, Elizabeth G. Holliday, Georg Homuth, Michael A. Horan,
    Jouke-Jan Hottenga, Philip L. de Jager, Peter K. Joshi, Astanand Jugessur, Marika
    A. Kaakinen, Mika Kähönen, Stavroula Kanoni, Liisa Keltigangas-Järvinen, Lambertus
    A. L. M. Kiemeney, Ivana Kolcic, Seppo Koskinen, Aldi T. Kraja, Martin Kroh, Zoltan
    Kutalik, Antti Latvala, Lenore J. Launer, Maël P. Lebreton, Douglas F. Levinson,
    Paul Lichtenstein, Peter Lichtner, David C. M. Liewald, LifeLines Cohort Study,
    Anu Loukola, Pamela A. Madden, Reedik Mägi, Tomi Mäki-Opas, Riccardo E. Marioni,
    Pedro Marques-Vidal, Gerardus A. Meddens, George McMahon, Christa Meisinger, Thomas
    Meitinger, Yusplitri Milaneschi, Lili Milani, Grant W. Montgomery, Ronny Myhre,
    Christopher P. Nelson, Dale R. Nyholt, William E. R. Ollier, Aarno Palotie, Lavinia
    Paternoster, Nancy L. Pedersen, Katja E. Petrovic, David J. Porteous, Katri Räikkönen,
    Susan M. Ring, Antonietta Robino, Olga Rostapshova, Igor Rudan, Aldo Rustichini,
    Veikko Salomaa, Alan R. Sanders, Antti-Pekka Sarin, Helena Schmidt, Rodney J.
    Scott, Blair H. Smith, Jennifer A. Smith, Jan A. Staessen, Elisabeth Steinhagen-Thiessen,
    Konstantin Strauch, Antonio Terracciano, Martin D. Tobin, Sheila Ulivi, Simona
    Vaccargiu, Lydia Quaye, Frank J. A. van Rooij, Cristina Venturini, Anna A. E.
    Vinkhuyzen, Uwe Völker, Henry Völzke, Judith M. Vonk, Diego Vozzi, Johannes Waage,
    Erin B. Ware, Gonneke Willemsen, John R. Attia, David A. Bennett, Klaus Berger,
    Lars Bertram, Hans Bisgaard, Dorret I. Boomsma, Ingrid B. Borecki, Ute Bültmann,
    Christopher F. Chabris, Francesco Cucca, Daniele Cusi, Ian J. Deary, George V.
    Dedoussis, Cornelia M. van Duijn, Johan G. Eriksson, Barbara Franke, Lude Franke,
    Paolo Gasparini, Pablo V. Gejman, Christian Gieger, Hans-Jörgen Grabe, Jacob Gratten,
    Patrick J. F. Groenen, Vilmundur Gudnason, Pim van der Harst, Caroline Hayward,
    David A. Hinds, Wolfgang Hoffmann, Elina Hyppönen, William G. Iacono, Bo Jacobsson,
    Marjo-Riitta Järvelin, Karl-Heinz Jöckel, Jaakko Kaprio, Sharon L. R. Kardia,
    Terho Lehtimäki, Steven F. Lehrer, Patrik K. E. Magnusson, Nicholas G. Martin,
    Matt McGue, Andres Metspalu, Neil Pendleton, Brenda W. J. H. Penninx, Markus Perola,
    Nicola Pirastu, Mario Pirastu, Ozren Polasek, Danielle Posthuma, Christine Power,
    Michael A. Province, Nilesh J. Samani, David Schlessinger, Reinhold Schmidt, Thorkild
    I. A. Sørensen, Tim D. Spector, Kari Stefansson, Unnur Thorsteinsdottir, A. Roy
    Thurik, Nicholas J. Timpson, Henning Tiemeier, Joyce Y. Tung, André G. Uitterlinden,
    Veronique Vitart, Peter Vollenweider, David R. Weir, James F. Wilson, Alan F.
    Wright, Dalton C. Conley, Robert F. Krueger, George Davey Smith, Albert Hofman,
    David I. Laibson, Sarah E. Medland, Michelle N. Meyer, Jian Yang, Magnus Johannesson,
    Tõnu Esko, Peter M. Visscher, Philipp D. Koellinger, David Cesarini, Daniel J.
    Benjamin
  - 2016-05-11
  - 10.1038/nature17671
  - Educational attainment is strongly influenced by social and other environmental
    factors, but genetic factors are estimated to account for at least 20% of the
    variation across individuals<sup><a href="/docs/iq/2013-rietveld.pdf">1</a></sup>.
    Here we report the results of a genome-wide association study (<span class="smallcaps-auto">GWAS</span>) for educational
    attainment that extends our earlier discovery sample<sup>1,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4375246/"
    title="Replicability and robustness of genome-wide-association studies for behavioral
    traits">2</a></sup> of 101,069 individuals to 293,723 individuals, and a replication
    study in an independent sample of 111,349 individuals from the UK Biobank. We
    identify 74 genome-wide significant loci associated with the number of years of
    schooling completed. Single-nucleotide polymorphisms associated with educational
    attainment are disproportionately found in genomic regions regulating gene expression
    in the fetal brain. Candidate genes are preferentially expressed in neural tissue,
    especially during the prenatal period, and enriched for biological pathways involved
    in neural development. Our findings demonstrate that, even for a behavioural phenotype
    that is mostly environmentally determined, a well-powered <span class="smallcaps-auto">GWAS</span> identifies replicable
    associated genetic variants that suggest biologically relevant pathways. Because
    educational attainment is measured in large numbers of individuals, it will continue
    to be useful as a proxy phenotype in efforts to characterize the genetic influences
    of related phenotypes, including cognition and neuropsychiatric diseases.
- - /docs/iq/2013-rietveld.pdf
  - GWAS of 126,559 Individuals Identifies Genetic Variants Associated with Educational
    Attainment
  - Cornelius A. Rietveld, Sarah E. Medland, Jaime Derringer, Jian Yang, Tõnu Esko,
    Nicolas W. Martin, Harm-Jan Westra, Konstantin Shakhbazov, Abdel Abdellaoui, Arpana
    Agrawal, Eva Albrecht, Behrooz Z. Alizadeh, Najaf Amin, John Barnard, Sebastian
    E. Baumeister, Kelly S. Benke, Lawrence F. Bielak, Jeffrey A. Boatman, Patricia
    A. Boyle, Gail Davies, Christiaan de Leeuw, Niina Eklund, Daniel S. Evans, Rudolf
    Ferhmann, Krista Fischer, Christian Gieger, Håkon K. Gjessing, Sara Hägg, Jennifer
    R. Harris, Caroline Hayward, Christina Holzapfel, Carla A. Ibrahim-Verbaas, Erik
    Ingelsson, Bo Jacobsson, Peter K. Joshi, Astanand Jugessur, Marika Kaakinen, Stavroula
    Kanoni, Juha Karjalainen, Ivana Kolcic, Kati Kristiansson, Zoltán Kutalik, Jari
    Lahti, Sang H. Lee, Peng Lin, Penelope A. Lind, Yongmei Liu, Kurt Lohman, Marisa
    Loitfelder, George McMahon, Pedro Marques Vidal, Osorio Meirelles, Lili Milani,
    Ronny Myhre, Marja-Liisa Nuotio, Christopher J. Oldmeadow, Katja E. Petrovic,
    Wouter J. Peyrot, Ozren Polašek, Lydia Quaye, Eva Reinmaa, John P. Rice, Thais
    S. Rizzi, Helena Schmidt, Reinhold Schmidt, Albert V. Smith, Jennifer A. Smith,
    Toshiko Tanaka, Antonio Terracciano, Matthijs J. H. M. van der Loos, Veronique
    Vitart, Henry Völzke, Jürgen Wellmann, Lei Yu, Wei Zhao, Jüri Allik, John R. Attia,
    Stefania Bandinelli, François Bastardot, Jonathan Beauchamp, David A. Bennett,
    Klaus Berger, Laura J. Bierut, Dorret I. Boomsma, Ute Bültmann, Harry Campbell,
    Christopher F. Chabris, Lynn Cherkas, Mina K. Chung, Francesco Cucca, Mariza de
    Andrade, Philip L. De Jager, Jan-Emmanuel De Neve, Ian J. Deary, George V. Dedoussis,
    Panos Deloukas, Maria Dimitriou, Guðný Eiríksdóttir, Martin F. Elderson, Johan
    G. Eriksson, David M. Evans, Jessica D. Faul, Luigi Ferrucci, Melissa E. Garcia,
    Henrik Grönberg, Vilmundur Guðnason, Per Hall, Juliette M. Harris, Tamara B. Harris,
    Nicholas D. Hastie, Andrew C. Heath, Dena G. Hernandez, Wolfgang Hoffmann, Adriaan
    Hofman, Rolf Holle, Elizabeth G. Holliday, Jouke-Jan Hottenga, William G. Iacono,
    Thomas Illig, Marjo-Riitta Järvelin, Mika Kähönen, Jaakko Kaprio, Robert M. Kirkpatrick,
    Matthew Kowgier, Antti Latvala, Lenore J. Launer, Debbie A. Lawlor, Terho Lehtimäki,
    Jingmei Li, Paul Lichtenstein, Peter Lichtner, David C. Liewald, Pamela A. Madden,
    Patrik K. E. Magnusson, Tomi E. Mäkinen, Marco Masala, Matt McGue, Andres Metspalu,
    Andreas Mielck, Michael B. Miller, Grant W. Montgomery, Sutapa Mukherjee, Dale
    R. Nyholt, Ben A. Oostra, Lyle J. Palmer, Aarno Palotie, Brenda W. J. H. Penninx,
    Markus Perola, Patricia A. Peyser, Martin Preisig, Katri Räikkönen, Olli T. Raitakari,
    Anu Realo, Susan M. Ring, Samuli Ripatti, Fernando Rivadeneira, Igor Rudan, Aldo
    Rustichini, Veikko Salomaa, Antti-Pekka Sarin, David Schlessinger, Rodney J. Scott,
    Harold Snieder, Beate St Pourcain, John M. Starr, Jae Hoon Sul, Ida Surakka, Rauli
    Svento, Alexander Teumer, The LifeLines Cohort Study, Henning Tiemeier, Frank
    J. A. van Rooij, David R. Van Wagoner, Erkki Vartiainen, Jorma Viikari, Peter
    Vollenweider, Judith M. Vonk, Gérard Waeber, David R. Weir, H.-Erich Wichmann,
    Elisabeth Widen, Gonneke Willemsen, James F. Wilson, Alan F. Wright, Dalton Conley,
    George Davey-Smith, Lude Franke, Patrick J. F. Groenen, Albert Hofman, Magnus
    Johannesson, Sharon L. R. Kardia, Robert F. Krueger, David Laibson, Nicholas G.
    Martin, Michelle N. Meyer, Danielle Posthuma, A. Roy Thurik, Nicholas J. Timpson,
    André G. Uitterlinden, Cornelia M. van Duijn, Peter M. Visscher, Daniel J. Benjamin,
    David Cesarini, Philipp D. Koellinger
  - 2013-06-21
  - 10.1126/science.1235488
  - ! '<p>A genome-wide association study (<span class="smallcaps-auto">GWAS</span>) of educational attainment was conducted
    in a discovery sample of 101,069 individuals and a replication sample of 25,490.
    Three independent single-nucleotide polymorphisms (<span class="smallcaps-auto">SNP</span>s) are genome-wide significant
    (rs9320913, rs11584700, rs4851266), and all three replicate. Estimated effects
    sizes are small (coefficient of determination R<sup>2</sup> ≈ 0.02%), approximately
    1 month of schooling per allele. A linear polygenic score from all measured <span class="smallcaps-auto">SNP</span>s
    accounts for ≈2% of the variance in both educational attainment and cognitive
    function. Genes in the region of the loci have previously been associated with
    health, cognitive, and central nervous system phenotypes, and bioinformatics analyses
    suggest the involvement of the anterior caudate nucleus. These findings provide
    promising candidate <span class="smallcaps-auto">SNP</span>s for follow-up work, and our effect size estimates can
    anchor power analyses in social-science genetics.</p><p>[A landmark study in behavioral
    genetics and intelligence: the first well-powered <span class="smallcaps-auto">GWAS</span> to detect genetic variants
    for intelligence and education which replicate out of sample and are proven to
    be causal in a between-sibling study.]</p>'
- - /docs/genetics/selection/2017-kong.pdf
  - Selection against variants in the genome associated with educational attainment
  - Augustine Kong, Michael L. Frigge, Gudmar Thorleifsson, Hreinn Stefansson, Alexander
    I. Young, Florian Zink, Gudrun A. Jonsdottir, Aysu Okbay, Patrick Sulem, Gisli
    Masson, Daniel F. Gudbjartsson, Agnar Helgason, Gyda Bjornsdottir, Unnur Thorsteinsdottir,
    Kari Stefansson
  - 2017-01-11
  - 10.1073/pnas.1612113114
  - <p>Epidemiological studies suggest that educational attainment is affected by
    genetic variants. Results from recent genetic studies allow us to construct a
    score from a person’s genotypes that captures a portion of this genetic component.
    Using data from Iceland that include a substantial fraction of the population
    we show that individuals with high scores tend to have fewer children, mainly
    because they have children later in life. Consequently, the average score has
    been decreasing over time in the population. The rate of decrease is small per
    generation but marked on an evolutionary timescale. Another important observation
    is that the association between the score and fertility remains highly significant
    after adjusting for the educational attainment of the individuals.</p> <p>Epidemiological
    and genetic association studies show that genetics play an important role in the
    attainment of education. Here, we investigate the effect of this genetic component
    on the reproductive history of 109,120 Icelanders and the consequent impact on
    the gene pool over time. We show that an educational attainment polygenic score,
    <span class="smallcaps-auto">POLY</span><sub><span class="smallcaps-auto">EDU</span></sub>, constructed from results of a recent study is associated with
    delayed reproduction (<em>p</em> &lt; 10<sup>−100</sup>) and fewer children overall.
    The effect is stronger for women and remains highly significant after adjusting
    for educational attainment. Based on 129,808 Icelanders born between 1910 and
    1990, we find that the average <span class="smallcaps-auto">POLY</span><sub><span class="smallcaps-auto">EDU</span></sub> has been declining at a rate
    of ∼0.010 standard units per decade, which is substantial on an evolutionary timescale.
    Most importantly, because <span class="smallcaps-auto">POLY</span><sub><span class="smallcaps-auto">EDU</span></sub> only captures a fraction of the overall
    underlying genetic component the latter could be declining at a rate that is two
    to three times faster.</p>
- - /docs/catnip/1999-bradshaw.pdf
  - ! 'Feral cats: their role in the population dynamics of <em>Felis catus</em>'
  - J.W.S. Bradshaw, G. F. Horsfield, J.A. Allen, I.H. Robinson
  - 1999-12
  - 10.1016/s0168-1591(99)00086-6
  - ! 'The so-called domestic cat occupies a unique position within the truly domestic
    animals since it freely interbreeds with feral populations, and there is considerable
    gene flow in both directions. This is possible because the likelihood of an individual
    cat forming a relationship with people is strongly affected by its experiences
    during the socialisation period (3–8 weeks of age), although this does not preclude
    differences between owned and feral populations in the relative frequencies of
    alleles which affect social behaviour towards humans. We suggest a hitherto unconsidered
    reason why a separate domesticated population of cats (apart from pedigree breeds)
    has not yet emerged: the unusual and stringent nutrient requirements of the cat
    may historically have militated against successful breeding on a completely human-provided
    diet, and led to the retention of the ability to achieve a nutritionally complete
    diet by scavenging and/or hunting. More recently, the widespread availability
    of nutritionally complete manufactured foods and veterinary care in western countries
    appears to be leading towards a rapid change in the population dynamics and population
    genetics of both owned and feral cats. [Keywords: Domestication, Feral populations,
    Population dynamics, Cat]'
- - http://www1.udel.edu/educ/gottfredson/reprints/1997whygmatters.pdf
  - ! 'Why <em>g</em> matters: The complexity of everyday life'
  - Linda S. Gottfredson
  - 1997-01
  - 10.1016/S0160-2896(97)90014-3
  - Personnel selection research provides much evidence that intelligence (g) is an
    important predictor of performance in training and on the job, especially in higher
    level work. This article provides evidence that <em>g</em> has pervasive utility
    in work settings because it is essentially the ability to deal with cognitive
    complexity, in particular, with complex information processing. The more complex
    a work task, the greater the advantages that higher <em>g</em> confers in performing
    it well. Everyday tasks, like job duties, also differ in their level of complexity.
    The importance of intelligence therefore differs systematically across different
    arenas of social life as well as economic endeavor. Data from the National Adult
    Literacy Survey are used to show how higher levels of cognitive ability systematically
    improve individual's odds of dealing successfully with the ordinary demands of
    modern life (such as banking, using maps and transportation schedules, reading
    and understanding forms, interpreting news articles). These and other data are
    summarized to illustrate how the advantages of higher <em>g</em>, even when they
    are small, cumulate to affect the overall life chances of individuals at different
    ranges of the IQ bell curve. The article concludes by suggesting ways to reduce
    the risks for low-IQ individuals of being left behind by an increasingly complex
    postindustrial economy.
- - http://movies2.nytimes.com/books/first/b/budiansky-lion.html
  - ! 'If a Lion Could Talk: Animal Intelligence and the Evolution of Consciousness'
  - Stephen Budiansky (<span class="smallcaps-auto">NYT</span>)
  - 1998-12-13
  - ''
  - ! '<p>[Excerpts from <a href="https://www.amazon.com/Lion-Could-Talk-Intelligence-Consciousness/dp/0684837102"><em>If
    a Lion Could Talk: Animal Intelligence and the Evolution of Consciousness</em></a>,
    Budiansky 1998 (<span class="smallcaps-auto">ISBN</span> 0684837102).]</p><p>How many of us have caught ourselves
    gazing into the eyes of a pet, wondering what thoughts lie behind those eyes?
    Or fallen into an argument over which is smarter, the dog or the cat? Scientists
    have conducted elaborate experiments trying to ascertain whether animals from
    chimps to pigeons can communicate, count, reason, or even lie. So does science
    tell us what we assume&mdash;that animals are pretty much like us, only not as
    smart? Simply, no. Now, in this superb book, Stephen Budiansky poses the fundamental
    question: "What is intelligence?" His answer takes us on the ultimate wildlife
    adventure to animal consciousness. Budiansky begins by exposing our tendency to
    see ourselves in animals. Our anthropomorphism allows us to perceive intelligence
    only in behavior that mimics our own. This prejudice, he argues, betrays a lack
    of imagination. Each species is so specialized that most of their abilities are
    simply not comparable. At the mercy of our anthropomorphic tendencies, we continue
    to puzzle over pointless issues like whether a wing or an arm is better, or whether
    night vision is better than day vision, rather than discovering the real world
    of a winged nighthawk, a thoroughbred horse, or an African lion. Budiansky investigates
    the sometimes bizarre research behind animal intelligence experiments: from horses
    who can count or ace history quizzes, and primates who seem fluent in sign language,
    to rats who seem to have become self-aware, he reveals that often these animals
    are responding to our tiny unconscious cues. And, while critically discussing
    scientists'' interpretations of animal intelligence, he is able to lay out their
    discoveries in terms of what we know about ourselves. For instance, by putting
    you in the minds of dogs or bees who travel by dead reckoning, he demonstrates
    that this is also how you find your way down a familiar street with almost no
    conscious awareness of your navigation system. Modern cognitive science and the
    new science of evolutionary ecology are beginning to show that thinking in animals
    is tremendously complex and wonderful in its variety. A pigeon''s ability to find
    its way home from almost anywhere has little to do with comparative intelligence;
    rather it is due to the pigeon''s very different perception of the world. That''s
    why, as Wittgenstein said, "If a lion could talk, we would not understand him."
    In this fascinating book, Budiansky frees us from the shackles of our ideas about
    the natural world, and opens a window to the astounding worlds of the animals
    that surround us.</p>'
- - /Complexity-vs-AI#technology-forecasting-errors-functional-fixedness-in-assuming-dependencies
  - ! 'Technology forecasting errors: functional fixedness in assuming dependencies'
  - Gwern Branwen
  - 2018-01-29
  - ''
  - <p>A classic cognitive bias in technological forecasting is motivated-stopping
    and lack of imagination in considering possibilities. Many people use a mental
    model of technologies in which they proceed in a serial sequential fashion and
    assume every step is necessary and only all together are they sufficient, and
    note that some particular step is difficult or unlikely to succeed and thus as
    a whole it will fail &amp; never happen. But in reality, few steps are truly required.
    A technology only needs to succeed in one way to succeed, and to fail it must
    fail in all ways. There may be many ways to work around, approximate, brute force,
    reduce the need for, or skip entirely a step, or redefine the problem to no longer
    involve that step at all. Examples of this include the parallel projects used
    by the Manhattan Project &amp; Apollo program, which reasoned that despite the
    formidable difficulties in each path to the end goal, at least one would work
    out—and they did. In forecasting, to counter this bias, one should make a strong
    effort to imagine <em>all</em> possible alternatives which could be pursued in
    parallel, and remember that overall failure requires <em>all</em> of them to fail.</p>
- - /docs/iq/2018-plomin.pdf
  - The new genetics of intelligence
  - Robert Plomin, Sophie von Stumm
  - '2018'
  - 10.1038/nrg.2017.104
  - Intelligence—the ability to learn, reason and solve problems—is at the forefront
    of behavioural genetic research. Intelligence is highly heritable and predicts
    important educational, occupational and health outcomes better than any other
    trait. Recent genome-wide association studies have successfully identified inherited
    genome sequence differences that account for 20% of the 50% heritability of intelligence.
    These findings open new avenues for research into the causes and consequences
    of intelligence using genome-wide polygenic scores that aggregate the effects
    of thousands of genetic variants.
- - /docs/iq/2017-sniekers.pdf
  - Genome-wide association meta-analysis of 78,308 individuals identifies new loci
    and genes influencing human intelligence
  - Suzanne Sniekers, Sven Stringer, Kyoko Watanabe, Philip R Jansen, Jonathan R I
    Coleman, Eva Krapohl, Erdogan Taskesen, Anke R Hammerschlag, Aysu Okbay, Delilah
    Zabaneh, Najaf Amin, Gerome Breen, David Cesarini, Christopher F Chabris, William
    G Iacono, M Arfan Ikram, Magnus Johannesson, Philipp Koellinger, James J Lee,
    Patrik K E Magnusson, Matt McGue, Mike B Miller, William E R Ollier, Antony Payton,
    Neil Pendleton, Robert Plomin, Cornelius A Rietveld, Henning Tiemeier, Cornelia
    M van Duijn, Danielle Posthuma
  - 2017-05-22
  - 10.1038/ng.3869
  - <p>Intelligence is associated with important economic and health-related life
    outcomes<sup>1</sup>. Despite intelligence having substantial heritability<sup>2</sup>
    (0.54) and a confirmed polygenic nature, initial genetic studies were mostly underpowered<sup>3,4,5</sup>.
    Here we report a meta-analysis for intelligence of 78,308 individuals. We identify
    336 associated <span class="smallcaps-auto">SNP</span>s (<span class="smallcaps-auto">METAL</span> <em>p</em> &lt; 5 × 10<sup>−8</sup>) in 18 genomic
    loci, of which 15 are new. Around half of the <span class="smallcaps-auto">SNP</span>s are located inside a gene,
    implicating 22 genes, of which 11 are new findings. Gene-based analyses identified
    an additional 30 genes (<span class="smallcaps-auto">MAGMA</span> <em>p</em> &lt; 2.73 × 10−<sup>6</sup>), of which
    all but one had not been implicated previously. We show that the identified genes
    are predominantly expressed in brain tissue, and pathway analysis indicates the
    involvement of genes regulating cell development (<span class="smallcaps-auto">MAGMA</span> competitive <em>p</em>
    = 3.5 × 10<sup>−6</sup>). Despite the well-known difference in twin-based heritability<sup>2</sup>
    for intelligence in childhood (0.45) and adulthood (0.80), we show substantial
    genetic correlation (<em>r<sub>g</sub></em> = 0.89, LD score regression <em>p</em>
    = 5.4 × 10<sup>−29</sup>). These findings provide new insight into the genetic
    architecture of intelligence.</p>
- - /docs/iodine/2015-monahan.pdf
  - ! 'Costs and benefits of iodine supplementation for pregnant women in a mildly
    to moderately iodine-deficient population: a modelling analysis'
  - Mark Monahan, Kristien Boelaert, Kate Jolly, Shiao Chan, Pelham Barton, Tracy
    E Roberts
  - 2015-08-10
  - 10.1016/S2213-8587(15)00212-0
  - ! '<p><em>Background</em>: Results from previous studies show that the cognitive
    ability of offspring might be irreversibly damaged as a result of their mother’s
    mild iodine deficiency during pregnancy. A reduced intelligence quotient (IQ)
    score has broad economic and societal cost implications because intelligence affects
    wellbeing, income, and education outcomes. Although pregnancy and lactation lead
    to increased iodine needs, no UK recommendations for iodine supplementation have
    been issued to pregnant women. We aimed to investigate the cost-effectiveness
    of iodine supplementation versus no supplementation for pregnant women in a mildly
    to moderately iodine-deficient population for which a population-based iodine
    supplementation programme—for example, universal salt iodisation—did not exist.</p><p><em>Methods</em>:
    We systematically searched <span class="smallcaps-auto">MEDLINE</span>, Embase, EconLit, and <span class="smallcaps-auto">NHS</span> <span class="smallcaps-auto">EED</span> for economic
    studies that linked IQ and income published in all languages until Aug 21, 2014.
    We took clinical data relating to iodine deficiency in pregnant women and the
    effect on IQ in their children aged 8–9 years from primary research. A decision
    tree was developed to compare the treatment strategies of iodine supplementation
    in tablet form with no iodine supplementation for pregnant women in the UK. Analyses
    were done from a health service perspective (analysis 1; taking direct health
    service costs into account) and societal perspective (analysis 2; taking education
    costs and the value of an IQ point itself into account), and presented in terms
    of cost (in sterling, relevant to 2013) per IQ point gained in the offspring.
    We made data-supported assumptions to complete these analyses, but used a conservative
    approach that limited the benefits of iodine supplementation and overestimated
    its potential harms.</p><p><em>Findings</em>: Our systematic search identified
    1361 published articles, of which eight were assessed to calculate the monetary
    value of an IQ point. A discounted lifetime value of an additional IQ point based
    on earnings was estimated to be £3297 (study estimates range from £1319 to £11 967)
    for the offspring cohort. Iodine supplementation was cost saving from both a health
    service perspective (saving £199 per pregnant woman [sensitivity analysis range
    –£42 to £229]) and societal perspective (saving £4476 per pregnant woman [sensitivity
    analysis range £540 to £4495]), with a net gain of 1·22 IQ points in each analysis.
    Base case results were robust to sensitivity analyses.</p><p><em>Interpretation</em>:
    Iodine supplementation for pregnant women in the UK is potentially cost saving.
    This finding also has implications for the 1·88 billion people in the 32 countries
    with iodine deficiency worldwide. Valuation of IQ points should consider non-earnings
    benefits—eg, health benefits associated with a higher IQ not germane to earnings.</p>'
- - https://bmcvetres.biomedcentral.com/articles/10.1186/s12917-017-0987-6
  - Responsiveness of cats (<em>Felidae</em>) to silver vine (<em>Actinidia polygama</em>),
    Tatarian honeysuckle (<em>Lonicera tatarica</em>), valerian (<em>Valeriana officinalis</em>)
    and catnip (<em>Nepeta cataria</em>)
  - Sebastiaan Bol, Jana Caspers, Lauren Buckingham, Gail Denise Anderson-Shelton,
    Carrie Ridgway, C. A. Tony Buffington, Stefan Schulz, Evelien M. Bunnik
  - 2017-03-16
  - 10.1186/s12917-017-0987-6
  - ! '<p><em>Background</em>: Olfactory stimulation is an often overlooked method
    of environmental enrichment for cats in captivity. The best known example of olfactory
    enrichment is the use of catnip, a plant that can cause an apparently euphoric
    reaction in domestic cats and most of the <em>Pantherinae</em>. It has long been
    known that some domestic cats and most tigers do not respond to catnip. Although
    many anecdotes exist of other plants with similar effects, data are lacking about
    the number of cats that respond to these plants, and if cats that do not respond
    to catnip respond to any of them. Furthermore, much is still unknown about which
    chemicals in these plants cause this response.</p><p><em>Methods</em>: We tested
    catnip, silver vine, Tatarian honeysuckle and valerian root on 100 domestic cats
    and observed their response. Each cat was offered all four plant materials and
    a control, multiple times. Catnip and silver vine also were offered to nine tigers.
    The plant materials were analyzed by gas chromatography coupled with mass spectrometry
    to quantify concentrations of compounds believed to exert stimulating effects
    on cats.</p><p><em>Results</em>: Nearly all domestic cats responded positively
    to olfactory enrichment. In agreement with previous studies, one out of every
    three cats did not respond to catnip. Almost 80% of the domestic cats responded
    to silver vine and about 50% to Tatarian honeysuckle and valerian root. Although
    cats predominantly responded to fruit galls of the silver vine plant, some also
    responded positively to its wood. Of the cats that did not respond to catnip,
    almost 75% did respond to silver vine and about one out of three to Tatarian honeysuckle.
    Unlike domestic cats, tigers were either not interested in silver vine or responded
    disapprovingly. The amount of nepetalactone was highest in catnip and only present
    at marginal levels in the other plants. Silver vine contained the highest concentrations
    of all other compounds tested.</p><p><em>Conclusions</em>: Olfactory enrichment
    for cats may have great potential. Silver vine powder from dried fruit galls and
    catnip were most popular among domestic cats. Silver vine and Tatarian honeysuckle
    appear to be good alternatives to catnip for domestic cats that do not respond
    to catnip.</p>'
- - /Amuse#loehlin-nichols-1976-a-study-of-850-sets-of-twins
  - ! 'Loehlin &amp; Nichols 1976: <em>A Study of 850 Sets of Twins</em>'
  - Gwern Branwen
  - 2018-05-19
  - ''
  - ! 'A discussion of extracting ~376 behavioral items relating to recreation/leisure
    from Loehlin &amp; Nichols 1976: <em>A Study of 850 Sets of Twins</em>, which
    reports comprehensive summary statistic twin correlations from an early large-scale
    twin study (canvassed via the National Merit Scholarship Qualifying Test, 1962).
    I transcribe them from the book, pool the weighted correlations by gender, and
    compute simple heritability estimates by Falconer''s formula for use in the recreation/leisure
    heritability literature review.'
- - https://www.pnas.org/content/early/2019/09/03/1821936116
  - Measuring actual learning versus feeling of learning in response to being actively
    engaged in the classroom
  - Louis Deslauriers, Logan S. McCarty, Kelly Miller, Kristina Callaghan, Greg Kestin
  - 2019-09-04
  - 10.1073/pnas.1821936116
  - ! '<p>Despite active learning being recognized as a superior method of instruction
    in the classroom, a major recent survey found that most college <span class="smallcaps-auto">STEM</span> instructors
    still choose traditional teaching methods. This article addresses the long-standing
    question of why students and faculty remain resistant to active learning. Comparing
    passive lectures with active learning using a randomized experimental approach
    and identical course materials, we find that students in the active classroom
    learn more, but they feel like they learn less. We show that this negative correlation
    is caused in part by the increased cognitive effort required during active learning.
    Faculty who adopt active learning are encouraged to intervene and address this
    misperception, and we describe a successful example of such an intervention.</p><p>We
    compared students’ self-reported perception of learning with their actual learning
    under controlled conditions in large-enrollment introductory college physics courses
    taught using (1) active instruction (following best practices in the discipline)
    and (2) passive instruction (lectures by experienced and highly rated instructors).
    Both groups received identical class content and handouts, students were randomly
    assigned, and the instructor made no effort to persuade students of the benefit
    of either method. Students in active classrooms learned more (as would be expected
    based on prior research), but their perception of learning, while positive, was
    lower than that of their peers in passive environments. This suggests that attempts
    to evaluate instruction based on students’ perceptions of learning could inadvertently
    promote inferior (passive) pedagogical methods. For instance, a superstar lecturer
    could create such a positive feeling of learning that students would choose those
    lectures over active learning. Most importantly, these results suggest that when
    students experience the increased cognitive effort associated with active learning,
    they initially take that effort to signify poorer learning. That disconnect may
    have a detrimental effect on students’ motivation, engagement, and ability to
    self-regulate their own learning. Although students can, on their own, discover
    the increased value of being actively engaged during a semester-long course, their
    learning may be impaired during the initial part of the course. We discuss strategies
    that instructors can use, early in the semester, to improve students’ response
    to being actively engaged in the classroom. [Keywords: scientific teaching, undergraduate
    education, evidence-based teaching, Constructivism]</p>'
- - /docs/melatonin/2002-cardinali.pdf
  - Melatonin in sleep disorders and jet-lag
  - Daniel P. Cardinali, Luis I. Brusco, Santiago Pérez Lloret, Analía M. Furio
  - '2002'
  - ''
  - In elderly insomniacs, melatonin treatment decreased sleep latency and increased
    sleep efficiency. This is particularly marked in Alzheimer’s disease (AD) patients.
    Melatonin is effective to reduce significantly benzodiazepine use. In addition,
    melatonin administration synchronizes the sleep-wake cycle in blind people and
    in individuals suffering from delayed sleep phase syndrome or jet lag. Urinary
    levels of 6-sulphatoxymelatonin decrease with age and in chronic diseases like
    AD or coronary heart disease. The effect of melatonin on sleep is probably the
    consequence of increasing sleep propensity (by inducing a fall in body temperature)
    and of a synchronizing effect on the circadian clock (chronobiotic effect).
- - /Timing#arpa-and-sci-surfing-ai-review-of-roland-shiman-2002
  - ! 'ARPA and SCI: Surfing AI (Review of Roland & Shiman 2002''s <em>Strategic Computing:
    DARPA and the Quest for Machine Intelligence, 1983&ndash;1993</em>)'
  - Gwern Branwen
  - 2018-08-01
  - ''
  - ! 'Review of <span class="smallcaps-auto">DARPA</span> history book, <em>Strategic Computing: <span class="smallcaps-auto">DARPA</span> and the Quest
    for Machine Intelligence, 1983&ndash;1993</em>, Roland & Shiman 2002, which reviews
    a large-scale <span class="smallcaps-auto">DARPA</span> effort to jumpstart real-world uses of AI in the 1980s by
    a multi-pronged research effort into more efficient computer chip R&D, supercomputing,
    robotics/self-driving cars, & expert system software. Roland & Shiman 2002 particularly
    focus on the various ''philosophies'' of technological forecasting & development,
    which guided <span class="smallcaps-auto">DARPA</span>''s strategy in different periods, ultimately endorsing a weak
    technological determinism where the bottlenecks are too large for a small (in
    comparison to the global economy & global R&D) organization best a <span class="smallcaps-auto">DARPA</span> can hope
    for is a largely agnostic & reactive strategy in which granters ''surf'' technological
    changes, rapidly exploiting new technology while investing their limited funds
    into targeted research patching up any gaps or lags that accidentally open up
    and block broader applications.'
- - /docs/sociology/2019-horowitz.pdf
  - ! 'Anthropology''s Science Wars: Insights from a New Survey'
  - Mark Horowitz, William Yaworsky, Kenneth Kickham
  - 2019-10
  - 10.1086/705409
  - In recent decades the field of anthropology has been characterized as sharply
    divided between pro-science and anti-science factions. The aim of this study is
    to empirically evaluate that characterization. We survey anthropologists in graduate
    programs in the United States regarding their views of science and advocacy, moral
    and epistemic relativism, and the merits of evolutionary biological explanations.
    We examine anthropologists’ views in concert with their varying appraisals of
    major controversies in the discipline (<a href="https://en.wikipedia.org/wiki/Napoleon_Chagnon">Chagnon/Tierney</a>,
    <a href="https://en.wikipedia.org/wiki/Margaret_Mead">Mead/Freeman</a>, and <a
    href="https://en.wikipedia.org/wiki/Rigoberta_Menchú#Controversies_about_her_testimony">Menchú/Stoll</a>).
    We find that disciplinary specialization and especially gender and political orientation
    are significant predictors of anthropologists’ views. We interpret our findings
    through the lens of an intuitionist social psychology that helps explain the dynamics
    of such controversies as well as ongoing ideological divisions in the field.
- - /docs/sr/2018-batikas.pdf
  - ! 'Entrepreneurs on the Darknet: Reaction to Negative Feedback'
  - Michail Batikas, Tobias Kretschmer
  - 2018-09-03
  - 10.2139/ssrn.3238141
  - ! 'Reputation is one of the key assets of a digital entrepreneur in markets for
    experience goods, especially in settings like Darknet and anonymous marketplaces.
    But what happens if this asset is diminished by a shock, i.e. negative feedback?
    We study how entrepreneurs on anonymous marketplaces respond to negative feedback
    by adjusting their product portfolio, or even exiting the market altogether. We
    find that the entrepreneurs are more likely to exit following negative feedback,
    but that a entrepreneur’s accumulated transactions experience on the market platform
    negatively moderates this. Interestingly, the entrepreneurs that do remain tend
    to expand their product portfolio. This effect, however, is again driven by entrepreneurs
    with relative high transactions experience, i.e. those with a high prior transactions
    volume. These results suggest that the reputation and the transactions experience
    of an entrepreneur interact in intricate ways to drive an entrepreneur’s choice
    of remaining in the market or adjusting her portfolio. We derive managerial and
    policy implications of these results. [Keywords: Digital Entrepreneurship, Reputation,
    Anonymous Marketplaces, Illicit Drugs, Darknet]'
- - /docs/sr/2013-aldridge.pdf
  - ! 'Not an ''Ebay for Drugs'': The Cryptomarket ''Silk Road'' as a Paradigm Shifting
    Criminal Innovation'
  - Judith Aldridge, David Décary-Hétu
  - 2014-05-15
  - 10.2139/ssrn.2436643
  - ! 'The online cryptomarket Silk Road has been oft-characterised as an ‘eBay for
    drugs’ with customers drug consumers making personal use-sized purchases. Our
    research demonstrates that this was not the case. Using a bespoke web crawler,
    we downloaded all drugs listings on Silk Road in September 2013. We found that
    a substantial proportion of transactions on Silk Road are best characterised as
    ‘business-to-business’, with sales in quantities and at prices typical of purchases
    made by drug dealers sourcing stock. High price-quantity sales generated between
    31-45% of revenue, making sales to drug dealers the key Silk Road drugs business.
    As such, Silk Road was what we refer to as a transformative, as opposed to incremental,
    criminal innovation. With the key Silk Road customers actually drug dealers sourcing
    stock for local street operations, we were witnessing a new breed of retail drug
    dealer, equipped with a technological subcultural capital skill set for sourcing
    stock. Sales on Silk Road increased from an estimate of $14.4 million in mid 2012
    to $89.7 million by our calculations. This is a more than 600% increase in just
    over a year, demonstrating the demand for this kind of illicit online marketplace.
    With Silk Road functioning to considerable degree at the wholesale/broker market
    level, its virtual location should reduce violence, intimidation and territorialism.
    Results are discussed in terms of the opportunities cryptomarkets provide for
    criminologists, who have thus far been reluctant to step outside of social surveys
    and administrative data to access the world of ‘webometric’ and ‘big data’. [Keywords:
    drug markets, cryptomarkets, webometrics, drug dealing]'
- - /docs/sr/2019-foley.pdf
  - ! 'Sex, Drugs, and Bitcoin: How Much Illegal Activity Is Financed through Cryptocurrencies?'
  - Sean Foley, Jonathan R. Karlsen, Tālis J. Putniņš
  - 2019-04-04
  - 10.1093/rfs/hhz015
  - Cryptocurrencies are among the largest unregulated markets in the world. We find
    that approximately one-quarter of bitcoin users are involved in illegal activity.
    We estimate that around $76 billion of illegal activity per year involve bitcoin
    (46% of bitcoin transactions), which is close to the scale of the U.S. and European
    markets for illegal drugs. The illegal share of bitcoin activity declines with
    mainstream interest in bitcoin and with the emergence of more opaque cryptocurrencies.
    The techniques developed in this paper have applications in cryptocurrency surveillance.
    Our findings suggest that cryptocurrencies are transforming the black markets
    by enabling “black e-commerce.”
- - https://osf.io/preprints/socarxiv/y4wgm/
  - ! 'Exit, Voice and Political Change: Evidence from Swedish Mass Migration to the
    United States'
  - Mounir Karadja, Erik Prawitz
  - 2019-09-06
  - 10.1086/701682
  - We study the political effects of mass emigration to the United States in the
    nineteenth century using data from Sweden. To instrument for total emigration
    over several decades, we exploit severe local frost shocks that sparked an initial
    wave of emigration, interacted with within-country travel costs. Our estimates
    show that emigration substantially increased the local demand for political change,
    as measured by labor movement membership, strike participation, and voting. Emigration
    also led to de facto political change, increasing welfare expenditures as well
    as the likelihood of adopting more inclusive political institutions.
- - /docs/sr/2019-du.pdf
  - ! 'Identifying High-Impact Opioid Products and Key Sellers in Dark Net Marketplaces:
    An Interpretable Text Analytics Approach'
  - Po-Yi Du, Mohammadreza Ebrahimi, Ning Zhang, Hsinchun Chen, Randall A. Brown,
    Sagar Samtani
  - 2019-07-01
  - 10.1109/ISI.2019.8823196
  - As the Internet based applications become more and more ubiquitous, drug retailing
    on Dark Net Marketplaces (<span class="smallcaps-auto">DNM</span>s) has raised public health and law enforcement concerns
    due to its highly accessible and anonymous nature. To combat illegal drug transaction
    among <span class="smallcaps-auto">DNM</span>s, authorities often require agents to impersonate <span class="smallcaps-auto">DNM</span> customers in order
    to identify key actors within the community. This process can be costly in time
    and resource. Research in <span class="smallcaps-auto">DNM</span>s have been conducted to provide better understanding
    of <span class="smallcaps-auto">DNM</span> characteristics and drug sellers’ behavior. Built upon the existing work,
    researchers can further leverage predictive analytics techniques to take proactive
    measures and reduce the associated costs. To this end, we propose a systematic
    analytical approach to identify key opioid sellers in <span class="smallcaps-auto">DNM</span>s. Utilizing machine
    learning and text analysis, this research provides prediction of high-impact opioid
    products in two major <span class="smallcaps-auto">DNM</span>s. Through linking the high-impact products and their
    sellers, we then identify the key opioid sellers among the communities. This work
    intends to help law enforcement authorities to formulate strategies by providing
    specific targets within the <span class="smallcaps-auto">DNM</span>s and reduce the time and resources required for
    prosecuting and eliminating the criminals from the market.
- - https://peerj.com/articles/6232/
  - ! 'Registered reports: an early example and analysis'
  - Richard Wiseman, Caroline Watt, Diana Kornbrot
  - 2019-01-16
  - 10.7717/peerj.6232
  - ! '<p>The recent ‘replication crisis’ in psychology has focused attention on ways
    of increasing methodological rigor within the behavioral sciences. Part of this
    work has involved promoting ‘Registered Reports’, wherein journals peer review
    papers prior to data collection and publication. Although this approach is usually
    seen as a relatively recent development, we note that a prototype of this publishing
    model was initiated in the mid-1970s by parapsychologist Martin Johnson in the
    <em>European Journal of Parapsychology</em> (<em><span class="smallcaps-auto">EJP</span></em>). A retrospective and
    observational comparison of Registered and non-Registered Reports published in
    the <span class="smallcaps-auto">EJP</span> during a seventeen-year period provides circumstantial evidence to suggest
    that the approach helped to reduce questionable research practices. This paper
    aims both to bring Johnson’s pioneering work to a wider audience, and to investigate
    the positive role that Registered Reports may play in helping to promote higher
    methodological and statistical standards.</p><p>…The final dataset contained
    60 papers: 25 RRs and 35 non-RRs. The RRs described 31 experiments that tested
    131 hypotheses, and the non-RRs described 60 experiments that tested 232 hypotheses.</p><p>28.4%
    of the statistical tests reported in non-RRs were significant (66/232: 95% CI
    [21.5%–36.4%]); compared to 8.4% of those in the RRs (11/131: 95% CI [4.0%–16.8%]).
    A simple 2 × 2 contingency analysis showed that this difference is highly statistically
    significant (Fisher’s exact test: <em>p</em> &lt; .0005, Pearson chi-square=20.1,
    Cohen’s <em>d</em> = .48).</p><p>…Parapsychologists investigate the possible existence
    of phenomena that, for many, have a low a priori likelihood of being genuine (see,
    e.g., Wagenmakers et al., 2011). This has often resulted in their work being subjected
    to a considerable amount of critical attention (from both within and outwith the
    field) that has led to them pioneering several methodological advances prior to
    their use within mainstream psychology, including the development of randomisation
    in experimental design (Hacking, 1988), the use of blinds (Kaptchuk, 1998), explorations
    into randomisation and statistical inference (Fisher, 1924), advances in replication
    issues (Rosenthal, 1986), the need for pre-specification in meta-analysis (Akers,
    1985; Milton, 1999; Kennedy, 2004), and the creation of a formal study registry
    (Watt, 2012; Watt &amp; Kennedy, 2015). Johnson’s work on RRs provides another
    striking illustration of this principle at work.</p>'
- - /docs/catnip/2002-hall.pdf
  - ! 'Object play in adult domestic cats: the roles of habituation and disinhibition'
  - Sarah L. Hall, John W.S. Bradshaw, Ian H. Robinson
  - 2002-11
  - 10.1016/S0168-1591(02)00153-3
  - ! 'We have investigated the role of habituation and disinhibition in the control
    of object (predatory) play by adult domestic cats Felis silvestris catus both
    with and without prior experience of hunting. We hypothesised that object play
    is terminated by rapid habituation to the sensory characteristics of the object
    played with, and therefore should be disinhibited if the sensory characteristics
    of the object are changed. Three sequential sessions of play with an unchanging
    object (a toy) caused almost complete habituation of the play response; replacing
    the toy with one of contrasting colours in a fourth session elicited intense disinhibited
    play, suggesting that motivation for play itself had not diminished substantially
    during the first three sessions. The time interval between sessions affected the
    extent of disinhibition. After a long delay (25–45 min) between each session play
    was less intense in the fourth session than in the first; if the interval was
    5 min, it was more intense, indicative of post-inhibitory rebound, possibly caused
    by initial positive feedback of play on its own performance. We suggest that object
    play by adult cats is controlled by two mechanisms derived from predatory behaviour:
    one responds to prey-like stimulus characteristics, such as texture and small
    size, which elicit play, while the second detects change in the toy. The behavioural
    default towards any object is initial interest if it possesses relevant stimulus
    characteristics, followed by rapid habituation unless these stimulus characteristics
    change.'
- - https://einstein.ai/presentations/ctrl.pdf
  - ! '<span class="smallcaps-auto">CTRL</span>: A Conditional Transformer Language Model For Controllable Generation'
  - Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, Richard Socher
    (Salesforce)
  - 2019-09-11
  - ''
  - Large-scale language models show promising text generation capabilities, but users
    cannot easily control particular aspects of the generated text. We release <span class="smallcaps-auto">CTRL</span>,
    a 1.6 billion-parameter conditional transformer language model, trained to condition
    on control codes that govern style, content, and task-specific behavior. Control
    codes were derived from structure that naturally co-occurs with raw text, preserving
    the advantages of unsupervised learning while providing more explicit control
    over text generation. These codes also allow <span class="smallcaps-auto">CTRL</span> to predict which parts of the
    training data are most likely given a sequence. This provides a potential method
    for analyzing large amounts of data via model-based source attribution. We have
    released multiple full-sized, pretrained versions of <span class="smallcaps-auto">CTRL</span> at <a href="https://github.com/salesforce/ctrl"><code>github.com/salesforce/ctrl</code></a>.
- - /docs/genetics/editing/2019-zheng.pdf
  - Controlled modelling of human epiblast and amnion development using stem cells
  - Yi Zheng, Xufeng Xue, Yue Shao, Sicong Wang, Sajedeh Nasr Esfahani, Zida Li, Jonathon
    M. Muncie, Johnathon N. Lakins, Valerie M. Weaver, Deborah L. Gumucio, Jianping
    Fu
  - 2019-09-11
  - 10.1038/s41586-019-1535-2
  - Early human embryonic development involves extensive lineage diversification,
    cell-fate specification and tissue patterning1. Despite its basic and clinical
    importance, early human embryonic development remains relatively unexplained owing
    to interspecies divergence<sup>2,3</sup> and limited accessibility to human embryo
    samples. Here we report that human pluripotent stem cells (h<span class="smallcaps-auto">PSC</span>s) in a microfluidic
    device recapitulate, in a highly controllable and scalable fashion, landmarks
    of the development of the epiblast and amniotic ectoderm parts of the conceptus,
    including lumenogenesis of the epiblast and the resultant pro-amniotic cavity,
    formation of a bipolar embryonic sac, and specification of primordial germ cells
    and primitive streak cells. We further show that amniotic ectoderm-like cells
    function as a signalling centre to trigger the onset of gastrulation-like events
    in h<span class="smallcaps-auto">PSC</span>s. Given its controllability and scalability, the microfluidic model provides
    a powerful experimental system to advance knowledge of human embryology and reproduction.
    This model could assist in the rational design of differentiation protocols of
    h<span class="smallcaps-auto">PSC</span>s for disease modelling and cell therapy, and in high-throughput drug and
    toxicity screens to prevent pregnancy failure and birth defects.
- - https://www.ukbiobank.ac.uk/2019/09/uk-biobank-leads-the-way-in-genetics-research-to-tackle-chronic-diseases/
  - UK Biobank leads the way in genetics research to tackle chronic diseases
  - UK Biobank
  - 2019-09-11
  - ''
  - <p>A £200 million investment from government, industry and charity cements UK
    Biobank’s reputation as a world-leading health resource to tackle the widest range
    of common and chronic diseases&mdash;including dementia, mental illness, cancer
    and heart disease. The investment provides for the whole genome sequencing of
    450,000 UK Biobank participants. A Vanguard study, funded by the Medical Research
    Council to sequence the first 50,000 individuals, is already underway.</p><p>…The
    ambitious project is funded with:</p><ul><li>£50 million by the UK Government’s
    research and innovation agency, UK Research and Innovation (<span class="smallcaps-auto">UKRI</span>) through the
    Industrial Strategy Challenge Fund;</li><li>£50 million from The Wellcome Trust
    charity;</li><li>£100 million in total from pharmaceutical companies Amgen, AstraZeneca,
    GlaxoSmithKline (<span class="smallcaps-auto">GSK</span>) and Johnson &amp; Johnson (J&amp;J).</li></ul><p>…At the
    end of May 2020, the consortium of pharmaceutical companies will be provided independently
    with access for analysis to the first tranche of sequence data (anticipated to
    be for about 125,000 participants) linked to all of the other data in the UK Biobank
    resource. After an exclusive access period of 9 months, the whole genome sequence
    data will be made available to all other approved researchers around the world.
    A similar exclusive access period will also apply on the completion of the sequencing.
    The period of exclusive access mirrors the arrangements that UK Biobank had with
    the exome sequencing project which is being undertaken by Regeneron in the US
    and other industry partners. The first tranche of exome data on 50,000 participants
    is now being used in more than 100 research projects worldwide.</p>
- - https://www.econstor.eu/bitstream/10419/71700/1/739716212.pdf
  - ! 'Star Wars: The Empirics Strike Back'
  - Abel Brodeur, Mathias Lé, Marc Sangnier, Yanos Zylberberg
  - 2013-03
  - ''
  - <p>Journals favor rejection of the null hypothesis. This selection upon tests
    may distort the behavior of researchers. Using 50,000 tests published between
    2005 and 2011 in the <em><span class="smallcaps-auto">AER</span></em>, <em><span class="smallcaps-auto">JPE</span></em>, and <em><span class="smallcaps-auto">QJE</span></em>, we identify
    a residual in the distribution of tests that cannot be explained by selection.
    The distribution of <em>p</em>-values exhibits a camel shape with abundant <em>p</em>-values
    above 0.25, a valley between 0.25 and 0.10 and a bump slightly below 0.05. The
    missing tests (with <em>p</em>-values between 0.25 and 0.10) can be retrieved
    just after the 0.05 threshold and represent 10% to 20% of marginally rejected
    tests. Our interpretation is that researchers might be tempted to <em>inflate</em>
    the value of those almost-rejected tests by choosing a “significant” specification.
    We propose a method to measure <em>inflation</em> and decompose it along articles’
    and authors’ characteristics.</p>
- - /docs/statistics/bias/2014-andreoliversbach.pdf
  - ! 'Open Access to Data: An Ideal Professed but Not Practised'
  - Patrick Andreoli-Versbach, Frank Mueller-Langer
  - '2014'
  - 10.1016/j.respol.2014.04.008
  - Data-sharing is an essential tool for replication, validation and extension of
    empirical results. Using a hand-collected data set describing the data-sharing
    behaviour of 488 randomly selected empirical researchers, we provide evidence
    that most researchers in economics and management do not share their data voluntarily.
    We derive testable hypotheses based on the theoretical literature on information-sharing
    and relate data-sharing to observable characteristics of researchers. We find
    empirical support for the hypotheses that voluntary data-sharing significantly
    increases with (a) academic tenure, (b) the quality of researchers, (c) the share
    of published articles subject to a mandatory data-disclosure policy of journals,
    and (d) personal attitudes towards “open science” principles. On the basis of
    our empirical evidence, we discuss a set of policy recommendations.
- - /docs/statistics/bias/2009-ljungqvist.pdf
  - Rewriting History
  - Alexander Ljungqvist, Christopher Malloy, Felicia Marston
  - 2009-07-16
  - 10.1111/j.1540-6261.2009.01484.x
  - ! 'We document widespread changes to the historical I/B/E/S analyst stock recommendations
    database. Across seven I/B/E/S downloads, obtained between 2000 and 2007, we find
    that between 6,580 (1.6%) and 97,582 (21.7%) of matched observations are different
    from one download to the next. The changes include alterations of recommendations,
    additions and deletions of records, and removal of analyst names. These changes
    are nonrandom, clustering by analyst reputation, broker size and status, and recommendation
    boldness, and affect trading signal classifications and back‐tests of three stylized
    facts: profitability of trading signals, profitability of consensus recommendation
    changes, and persistence in individual analyst stock‐picking ability.'
- - https://szociologia.tk.mta.hu/uploads/files/archive/john_et_al_2012.pdf
  - Measuring the Prevalence of Questionable Research Practices with Incentives for
    Truth-Telling
  - Leslie K. John, George Loewenstein, Drazen Prelec
  - '2012'
  - 10.1177/095679761143095
  - ! 'Cases of clear scientific misconduct have received significant media attention
    recently, but less flagrantly questionable research practices may be more prevalent
    and, ultimately, more damaging to the academic enterprise. Using an anonymous
    elicitation format supplemented by incentives for honest reporting, we surveyed
    over 2,000 psychologists about their involvement in questionable research practices.
    The impact of truth-telling incentives on self-admissions of questionable research
    practices was positive, and this impact was greater for practices that respondents
    judged to be less defensible. Combining three different estimation methods, we
    found that the percentage of respondents who have engaged in questionable practices
    was surprisingly high. This finding suggests that some questionable practices
    may constitute the prevailing research norm. [Keywords: professional standards,
    judgment, disclosure, methodology]'
- - /docs/statistics/decision/2006-drescher-goodandreal.pdf
  - ! '<em>Good and Real: Demystifying Paradoxes from Physics to Ethics</em>'
  - Gary Drescher
  - '2006'
  - ''
  - <p>In <a href="https://www.amazon.com/Good-Real-Demystifying-Paradoxes-Bradford/dp/0262042339"><em>Good
    and Real</em></a>, a tour-de-force of metaphysical naturalism, computer scientist
    <a href="https://en.wikipedia.org/wiki/Gary_Drescher">Gary Drescher</a> examines
    a series of provocative paradoxes about consciousness, choice, ethics, quantum
    mechanics, and other topics, in an effort to reconcile a purely mechanical view
    of the universe with key aspects of our subjective impressions of our own existence.</p><p>Many
    scientists suspect that the universe can ultimately be described by a simple (perhaps
    even deterministic) formalism; all that is real unfolds mechanically according
    to that formalism. But how, then, is it possible for us to be conscious, or to
    make genuine choices? And how can there be an ethical dimension to such choices?
    Drescher sketches computational models of consciousness, choice, and subjunctive
    reasoning—what would happen if this or that were to occur?—to show how such phenomena
    are compatible with a mechanical, even deterministic universe.</p><p>Analyses
    of <a href="https://en.wikipedia.org/wiki/Newcomb%27s_paradox">Newcomb’s Problem</a>
    (a paradox about choice) and the <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">Prisoner’s
    Dilemma</a> (a paradox about self-interest vs altruism, arguably reducible to
    Newcomb’s Problem) help bring the problems and proposed solutions into focus.
    Regarding quantum mechanics, Drescher builds on <a href="https://en.wikipedia.org/wiki/Many-worlds_interpretation">Everett’s
    relative-state formulation</a>—but presenting a simplified formalism, accessible
    to laypersons—to argue that, contrary to some popular impressions, quantum mechanics
    is compatible with an objective, deterministic physical reality, and that there
    is no special connection between quantum phenomena and consciousness.</p><p>In
    each of several disparate but intertwined topics ranging from physics to ethics,
    Drescher argues that a missing technical linchpin can make the quest for objectivity
    seem impossible, until the elusive technical fix is at hand.:</p><ul><li>Chapter
    2 explores how inanimate, mechanical matter could be conscious, just by virtue
    of being organized to perform the right kind of computation.</li><li>Chapter 3
    explains why conscious beings would experience an apparent inexorable forward
    flow of time, even in a universe who physical principles are time-symmetric and
    have no such flow, with everything sitting statically in spacetime.</li><li>Chapter
    4, following [Hugh] Everett, looks closely at the paradoxes of quantum mechanics,
    showing how some theorists came to conclude—mistakenly, I argue—that consciousness
    is part of the story of quantum phenomena, or vice versa. Chapter 4 also shows
    how quantum phenomena are consistent with determinism (even though so-called <a
    href="https://en.wikipedia.org/wiki/Hidden-variable_theory">hidden-variable theories</a>
    of quantum determinism are provably wrong).</li><li>Chapter 5 examines in detail
    how it can be that we make genuine choices in in a mechanical, deterministic universe.</li><li>Chapter
    6 analyzes Newcomb’s Problem, a startling paradox that elicits some counterintuitive
    conclusions about choice and causality.</li><li>Chapter 7 considers how our choices
    can have a moral component&mdash;that is, how even a mechanical, deterministic
    universe can provide a basis for distinguishing right from wrong.</li><li>Chapter
    8 wraps up the presentation and touches briefly on some concluding metaphysical
    questions.</li></ul>
- - https://www.cs.virginia.edu/~robins/YouAndYourResearch.html
  - You and Your Research
  - Richard Hamming
  - 1986-03-07
  - ''
  - ! '<p>[Transcript of a talk by mathematician and <a href="https://en.wikipedia.org/wiki/Bell_Labs">Bell
    Labs</a> manager <a href="https://en.wikipedia.org/wiki/Richard_Hamming">Richard
    Hamming</a> about what he had learned about computers and how to do effective
    research (republished in expanded form as <em>Art of Doing Science and Engineering:
    Learning to Learn</em>; <a href="https://www.youtube.com/watch?v=a1zDuOPkMSw" title="Hamming, "You and Your Research" (June 6, 1995)">1995 video</a>). It is one of the most famous and most-quoted such discussions
    ever.]</p><p>At a seminar in the Bell Communications Research Colloquia Series,
    Dr. Richard W. Hamming, a Professor at the Naval Postgraduate School in Monterey,
    California and a retired Bell Labs scientist, gave a very interesting and stimulating
    talk, ''You and Your Research'' to an overflow audience of some 200 Bellcore staff
    members and visitors at the Morris Research and Engineering Center on March 7,
    1986. This talk centered on Hamming''s observations and research on the question
    "Why do so few scientists make significant contributions and so many are forgotten
    in the long run?" From his more than forty years of experience, thirty of which
    were at Bell Laboratories, he has made a number of direct observations, asked
    very pointed questions of scientists about what, how, and why they did things,
    studied the lives of great scientists and great contributions, and has done introspection
    and studied theories of creativity. The talk is about what he has learned in terms
    of the properties of the individual scientists, their abilities, traits, working
    habits, attitudes, and philosophy.</p>'
- - https://old.reddit.com/r/reinforcementlearning/
  - ! 'Reddit: Reinforcement Learning subreddit'
  - 'NA'
  - 'NA'
  - ''
  - ! 'Subreddit devoted to discussion of reinforcement learning research and projects,
    particularly deep reinforcement learning (more specialized than <code>/r/MachineLearning</code>).
    Major themes include deep learning, model-based vs model-free RL, robotics, multi-agent
    RL, exploration, meta-reinforcement learning, imitation learning, the psychology
    of RL in biological organisms such as humans, and safety/AI risk. Moderate activity
    level (as of 11 September 2019): ~10k subscribers, 2k pageviews/daily'
- - https://www.nature.com/mp/journal/vaop/ncurrent/full/mp2017121a.html
  - A genome-wide association study for extremely high intelligence
  - D. Zabaneh, E. Krapohl, H. A. Gaspar, C. Curtis, S. H. Lee, H. Patel, S. Newhouse,
    H. M. Wu, M. A. Simpson, M. Putallaz, David Lubinski, Robert Plomin, G. Breen
  - 2017-07-04
  - 10.1038/mp.2017.121
  - We used a case–control genome-wide association (<span class="smallcaps-auto">GWA</span>) design with cases consisting
    of 1238 individuals from the top 0.0003 (~170 mean IQ) of the population distribution
    of intelligence and 8172 unselected population-based controls. The single-nucleotide
    polymorphism heritability for the extreme IQ trait was 0.33 (0.02), which is the
    highest so far for a cognitive phenotype, and significant genome-wide genetic
    correlations of 0.78 were observed with educational attainment and 0.86 with population
    IQ. Three variants in locus <span class="smallcaps-auto">ADAM</span>12 achieved genome-wide significance, although
    they did not replicate with published <span class="smallcaps-auto">GWA</span> analyses of normal-range IQ or educational
    attainment. A genome-wide polygenic score constructed from the <span class="smallcaps-auto">GWA</span> results accounted
    for 1.6% of the variance of intelligence in the normal range in an unselected
    sample of 3414 individuals, which is comparable to the variance explained by <span class="smallcaps-auto">GWA</span>
    studies of intelligence with substantially larger sample sizes. The gene family
    <em>plexins</em>, members of which are mutated in several monogenic neurodevelopmental
    disorders, was significantly enriched for associations with high IQ. This study
    shows the utility of extreme trait selection for genetic study of intelligence
    and suggests that extremely high intelligence is continuous genetically with normal-range
    intelligence in the population.
- - https://www.nature.com/articles/s41380-017-0001-5
  - A combined analysis of genetically correlated traits identifies 187 loci and a
    role for neurogenesis and myelination in intelligence
  - William D. Hill, Robert E. Marioni, O. Maghzian, Stuart J. Ritchie, Sarah P. Hagenaars,
    A. M. McIntosh, C. R. Gale, G. Davies, Ian J. Deary
  - 2018-01-11
  - 10.1038/s41380-017-0001-5
  - ! 'Intelligence, or general cognitive function, is phenotypically and genetically
    correlated with many traits, including a wide range of physical, and mental health
    variables. Education is strongly genetically correlated with intelligence (<em>r<sub>g</sub></em> = 0.70).
    We used these findings as foundations for our use of a novel approach—multi-trait
    analysis of genome-wide association studies (<span class="smallcaps-auto">MTAG</span>; Turley et al. 2017)—to combine
    two large genome-wide association studies (<span class="smallcaps-auto">GWAS</span>s) of education and intelligence,
    increasing statistical power and resulting in the largest <span class="smallcaps-auto">GWAS</span> of intelligence
    yet reported. Our study had four goals: first, to facilitate the discovery of
    new genetic loci associated with intelligence; second, to add to our understanding
    of the biology of intelligence differences; third, to examine whether combining
    genetically correlated traits in this way produces results consistent with the
    primary phenotype of intelligence; and, finally, to test how well this new meta-analytic
    data sample on intelligence predicts phenotypic intelligence in an independent
    sample. By combining datasets using <span class="smallcaps-auto">MTAG</span>, our functional sample size increased
    from 199,242 participants to 248,482. We found 187 independent loci associated
    with intelligence, implicating 538 genes, using both <span class="smallcaps-auto">SNP</span>-based and gene-based
    <span class="smallcaps-auto">GWAS</span>. We found evidence that neurogenesis and myelination—as well as genes expressed
    in the synapse, and those involved in the regulation of the nervous system—may
    explain some of the biological differences in intelligence. The results of our
    combined analysis demonstrated the same pattern of genetic correlations as those
    from previous <span class="smallcaps-auto">GWAS</span>s of intelligence, providing support for the meta-analysis of
    these genetically-related phenotypes.'
- - http://www.nature.com/tp/journal/v6/n9/full/tp2016155a.html
  - Genome-wide association study of antisocial personality disorder
  - M-R. Rautiainen, T. Paunio, E. Repo-Tiihonen, M. Virkkunen, H. M. Ollila, S. Sulkava,
    O. Jolanki, A. Palotie, J. Tiihonen
  - 2016-09-06
  - 10.1038/tp.2016.155
  - <p>The pathophysiology of antisocial personality disorder (<span class="smallcaps-auto">ASPD</span>) remains unclear.
    Although the most consistent biological finding is reduced grey matter volume
    in the frontal cortex, about 50% of the total liability to developing <span class="smallcaps-auto">ASPD</span> has
    been attributed to genetic factors. The contributing genes remain largely unknown.
    Therefore, we sought to study the genetic background of <span class="smallcaps-auto">ASPD</span>. We conducted a genome-wide
    association study (<span class="smallcaps-auto">GWAS</span>) and a replication analysis of Finnish criminal offenders
    fulfilling <span class="smallcaps-auto">DSM</span>-IV criteria for <span class="smallcaps-auto">ASPD</span> (<em>N</em>=370, <em>N</em>=5850 for controls,
    <span class="smallcaps-auto">GWAS</span>; <em>N</em>=173, <em>N</em>=3766 for controls and replication sample). The
    <span class="smallcaps-auto">GWAS</span> resulted in suggestive associations of two clusters of single-nucleotide
    polymorphisms at 6p21.2 and at 6p21.32 at the human leukocyte antigen (<span class="smallcaps-auto">HLA</span>) region.
    Imputation of <span class="smallcaps-auto">HLA</span> alleles revealed an independent association with <span class="smallcaps-auto">DRB</span>1*01:01
    (odds ratio (OR)=2.19 (1.53–3.14), <em>p</em>=1.9 × 10<sup>-5</sup>). Two polymorphisms
    at 6p21.2 <span class="smallcaps-auto">LINC</span>00951–<span class="smallcaps-auto">LRFN</span>2 gene region were replicated in a separate data set,
    and rs4714329 reached genome-wide significance (OR=1.59 (1.37–1.85), <em>p</em>=1.6 × 10<sup>−9</sup>)
    in the meta-analysis. The risk allele also associated with antisocial features
    in the general population conditioned for severe problems in childhood family
    (<em>β</em>=0.68, <em>p</em>=0.012). Functional analysis in brain tissue in open
    access <span class="smallcaps-auto">GTE</span>x and Braineac databases revealed e<span class="smallcaps-auto">QTL</span> associations of rs4714329 with
    <span class="smallcaps-auto">LINC</span>00951 and <span class="smallcaps-auto">LRFN</span>2 in cerebellum. In humans, <span class="smallcaps-auto">LINC</span>00951 and <span class="smallcaps-auto">LRFN</span>2 are both expressed
    in the brain, especially in the frontal cortex, which is intriguing considering
    the role of the frontal cortex in behavior and the neuroanatomical findings of
    reduced gray matter volume in <span class="smallcaps-auto">ASPD</span>. To our knowledge, this is the first study
    showing genome-wide significant and replicable findings on genetic variants associated
    with any personality disorder.</p>
- - https://karpathy.github.io/2015/05/21/rnn-effectiveness/
  - The Unreasonable Effectiveness of Recurrent Neural Networks
  - Andrej Karpathy
  - 2015-05-21
  - ''
  - ! '<p>[Exploration of char-<span class="smallcaps-auto">RNN</span> neural nets for generating text. Karpathy codes
    a simple recurrent NN which generates character-by-character, and discovers that
    it is able to generate remarkably plausible text (at the syntactic level) for
    Paul Graham, Shakespeare, Wikipedia, LaTeX, Linux C code, and baby names&mdash;all
    using the same generic architecture. Visualizing the internal activity of the
    char-<span class="smallcaps-auto">RNN</span>s, they seem to be genuinely understanding some of the recursive syntactic
    structure of the text in a way that other text-generation methods like n-grams
    cannot. Inspired by this post, I began <a href="/RNN-metadata">tinkering with
    char-<span class="smallcaps-auto">RNN</span>s for poetry</a> myself; as of 2019, char-<span class="smallcaps-auto">RNN</span>s have been largely obsoleted
    by the new <a href="/GPT-2"><em>Transformer architecture</em></a>, but recurrency
    will make a comeback and Karpathy''s post is still a valuable and fun read.]</p><p>There’s
    something magical about Recurrent Neural Networks (<span class="smallcaps-auto">RNN</span>s). I still remember when
    I trained my first recurrent network for Image Captioning. Within a few dozen
    minutes of training my first baby model (with rather arbitrarily-chosen hyperparameters)
    started to generate very nice looking descriptions of images that were on the
    edge of making sense. Sometimes the ratio of how simple your model is to the quality
    of the results you get out of it blows past your expectations, and this was one
    of those times. What made this result so shocking at the time was that the common
    wisdom was that <span class="smallcaps-auto">RNN</span>s were supposed to be difficult to train (with more experience
    I’ve in fact reached the opposite conclusion). Fast forward about a year: I’m
    training <span class="smallcaps-auto">RNN</span>s all the time and I’ve witnessed their power and robustness many
    times, and yet their magical outputs still find ways of amusing me. This post
    is about sharing some of that magic with you.<em>We’ll train <span class="smallcaps-auto">RNN</span>s to generate
    text character by character and ponder the question “how is that even possible?”</em></p>'
- - https://archive.org/details/eassayonthepsych006281mbp
  - <em>An Essay On The Psychology Of Invention In The Mathematical Field</em>
  - Jacques Hadamard
  - '1945'
  - ''
  - ! '[<p>Relevant to an <a href="/The-Existential-Risk-of-Mathematical-Error">essay
    of mine on mathematical error</a>—Hadamard’s book is one of the classics in the
    area of mathematical discovery, mentioned along with <a href="http://paradise.caltech.edu/ist4/lectures/Poincare_Reflections.pdf"
    title="&#39;Mathematical Creation&#39;, 1908">Poincaré’s lecture</a>.</p><p>With
    due allowance for style and age, Hadamard ably describes and defends the basic
    model of ‘work, incubation, illumination, verification’, with reference to his
    own discoveries, his many famous acquaintances, Poincaré’s lecture, and a very
    interesting survey of mathematicians. In fact, it’s a little depressing that we
    don’t seem to have gone much beyond that in the half-century since this was published
    back in 1945 or so. While at least we no longer need his defense of the unconscious
    as a meaningful part of cognition, much of the rest is depressingly familiar—for
    example, his acute observations on mental imagery &amp; people who solely think
    in words, and mention of Francis Galton’s survey (little-known outside of psychology),
    could be usefully read by many who commit the <a href="http://lesswrong.com/lw/dr/generalizing_from_one_example/">typical
    mind fallacy</a>.</p><p>If Hadamard comes to no hard and fast conclusions, but
    merely raises many interesting points and criticizes a number of theories, we
    can hardly hold that against him, as we can do little better and so it becomes
    our failing to followup, not his.</p>]'
- - https://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/
  - The Control Group Is Out Of Control
  - Scott Alexander
  - 2014-04-28
  - ''
  - <p>Allan Crossman calls parapsychology <a href="http://lesswrong.com/lw/1ib/parapsychology_the_control_group_for_science/">the
    control group for science</a>. That is, in let’s say a drug testing experiment,
    you give some people the drug and they recover. That doesn’t tell you much until
    you give some other people a placebo drug you <em>know</em> doesn’t work—but which
    they themselves believe in—and see how many of them recover. That number tells
    you how many people will recover whether the drug works or not. Unless people
    on your real drug do significantly better than people on the placebo drug, you
    haven’t found anything. On the meta-level, you’re studying some phenomenon and
    you get some positive findings. That doesn’t tell you much until you take some
    other researchers who are studying a phenomenon you know doesn’t exist—but which
    they themselves believe in—and see how many of <em>them</em> get positive findings.
    That number tells you how many studies will discover positive results whether
    the phenomenon is real or not. Unless studies of the real phenomenon do significantly
    better than studies of the placebo phenomenon, you haven’t found anything.</p><p>Trying
    to set up placebo science would be a logistical nightmare. You’d have to find
    a phenomenon that definitely doesn’t exist, somehow convince a whole community
    of scientists across the world that it does, and fund them to study it for a couple
    of decades without them figuring it out.</p><p>Luckily we have a natural experiment
    in terms of parapsychology—the study of psychic phenomena—which most reasonable
    people believe don’t exist, but which a community of practicing scientists believes
    in and publishes papers on all the time. The results are pretty dismal. Parapsychologists
    are able to produce experimental evidence for psychic phenomena about as easily
    as normal scientists are able to produce such evidence for normal, non-psychic
    phenomena. This suggests the existence of a very large “placebo effect” in science—ie
    with enough energy focused on a subject, you can <em>always</em> produce “experimental
    evidence” for it that meets the usual scientific standards. As <a href="https://www.lesswrong.com/posts/9qCN6tRBtksSyXfHu/frequentist-statistics-are-frequently-subjective"
    title="Frequentist Statistics are Frequently Subjective">Eliezer Yudkowsky puts
    it</a>:</p><blockquote><p>Parapsychologists are constantly protesting that they
    are playing by all the standard scientific rules, and yet their results are being
    ignored—that they are unfairly being held to higher standards than everyone else.
    I’m willing to believe that. It just means that the standard statistical methods
    of science are so weak and flawed as to permit a field of study to sustain itself
    in the complete absence of any subject matter.</p></blockquote>
- - http://www.terrierman.com/russianfoxfarmstudy.pdf
  - ! 'Early Canid Domestication: The Farm-Fox Experiment: Foxes bred for tamability
    in a 40-year experiment exhibit remarkable transformations that suggest an interplay
    between behavioral genetics and development'
  - Lyudmila N. Trut
  - 1999-03
  - 10.2307/27857815
  - ! '<p>[Popular review of the <a href="https://en.wikipedia.org/wiki/Domesticated_red_fox">domesticated
    red fox</a> by the lead researcher. Trut gives the history of Belyaev''s founding
    of the experiment in 1959, and how the results gradually proved his theory about
    ''domestication syndrome'': that domestication produces multiple simultaneous
    effects like floppy ears despite the foxes being bred solely for being willing
    to approach a strange human, suggesting an underlying common genetic mechanism]</p><p>Forty
    years into our unique lifelong experiment, we believe that Dmitry Belyaev would
    be pleased with its progress. By intense selective breeding, we have compressed
    into a few decades an ancient process that originally unfolded over thousands
    of years. Before our eyes, “the Beast” has turned into “Beauty,” as the aggressive
    behavior of our herd’s wild progenitors entirely disappeared. We have watched
    new morphological traits emerge, a process previously known only from archaeological
    evidence. Now we know that these changes can burst into a population early in
    domestication, triggered by the stresses of captivity, and that many of them result
    from changes in the timing of developmental processes. In some cases the changes
    in timing, such as earlier sexual maturity or retarded growth of somatic characters,
    resemble pedomorphosis. Some long-standing puzzles remain. We believed at the
    start that foxes could be made to reproduce twice a year and all year round, like
    dogs. We would like to understand why this has turned out not to be quite so.
    We are also curious about how the vocal repertoire of foxes changes under domestication.
    Some of the calls of our adult foxes resemble those of dogs and, like those of
    dogs, appear to be holdovers from puppyhood, but only further study will reveal
    the details. The biggest unanswered question is just how much further our selective-breeding
    experiment can go. The domestic fox is not a domestic dog, but we believe that
    it has the genetic potential to become more and more doglike.</p>'
- - https://www.nature.com/articles/mp201645
  - Genome-wide association study of cognitive functions and educational attainment
    in UK Biobank (<em>N</em>=112 151)
  - G. Davies, R. E. Marioni, D. C. Liewald, W. D. Hill, S. P. Hagenaars, S. E. Harris,
    S. J. Ritchie, M. Luciano, C. Fawns-Ritchie, D. Lyall, B. Cullen, S. R. Cox, C.
    Hayward, D. J. Porteous, J. Evans, A. M. McIntosh, J. Gallacher, N. Craddock,
    J. P. Pell, D. J. Smith, C. R. Gale, I. J. Deary
  - 2016-04-05
  - 10.1038/mp.2016.45
  - <p>People’s differences in cognitive functions are partly heritable and are associated
    with important life outcomes. Previous genome-wide association (<span class="smallcaps-auto">GWA</span>) studies of
    cognitive functions have found evidence for polygenic effects yet, to date, there
    are few replicated genetic associations. Here we use data from the UK Biobank
    sample to investigate the genetic contributions to variation in tests of three
    cognitive functions and in educational attainment. <span class="smallcaps-auto">GWA</span> analyses were performed
    for verbal–numerical reasoning (<em>N</em>=36 035), memory (<em>N</em>=112 067),
    reaction time (<em>N</em>=111 483) and for the attainment of a college or a university
    degree (<em>N</em>=111 114). We report genome-wide significant single-nucleotide
    polymorphism (<span class="smallcaps-auto">SNP</span>)-based associations in 20 genomic regions, and significant gene-based
    findings in 46 regions. These include findings in the <em><span class="smallcaps-auto">ATXN</span>2</em>, <em><span class="smallcaps-auto">CYP</span>2DG</em>,
    <em><span class="smallcaps-auto">APBA</span>1</em> and <em><span class="smallcaps-auto">CADM</span>2</em> genes. We report replication of these hits in
    published <span class="smallcaps-auto">GWA</span> studies of cognitive function, educational attainment and childhood
    intelligence. There is also replication, in UK Biobank, of <span class="smallcaps-auto">SNP</span> hits reported previously
    in <span class="smallcaps-auto">GWA</span> studies of educational attainment and cognitive function. <span class="smallcaps-auto">GCTA</span>-<span class="smallcaps-auto">GREML</span> analyses,
    using common <span class="smallcaps-auto">SNP</span>s (minor allele frequency&gt;0.01), indicated significant <span class="smallcaps-auto">SNP</span>-based
    heritabilities of 31% (s.e.m.=1.8%) for verbal–numerical reasoning, 5% (s.e.m.=0.6%)
    for memory, 11% (s.e.m.=0.6%) for reaction time and 21% (s.e.m.=0.6%) for educational
    attainment. Polygenic score analyses indicate that up to 5% of the variance in
    cognitive test scores can be predicted in an independent cohort. The genomic regions
    identified include several novel loci, some of which have been associated with
    intracranial volume, neurodegeneration, Alzheimer’s disease and schizophrenia.</p>
- - https://www.nature.com/articles/mp2016244
  - ! '<span class="smallcaps-auto">GWAS</span> meta-analysis reveals novel loci and genetic correlates for general cognitive
    function: a report from the <span class="smallcaps-auto">COGENT</span> consortium'
  - J. W. Trampush, M. L. Z. Yang, J. Yu, E. Knowles, G. Davies, D. C. Liewald, J.
    M. Starr, S. Djurovic, I. Melle, K. Sundet, A. Christoforou, I. Reinvang, P. DeRosse,
    A. J. Lundervold, V. M. Steen, T. Espeseth, K. Räikkönen, E. Widen, A. Palotie,
    J. G. Eriksson, I. Giegling, B. Konte, P. Roussos, S. Giakoumaki, K. E. Burdick,
    A. Payton, W. Ollier, M. Horan, O. Chiba-Falek, D. K. Attix, A. C. Need, E. T.
    Cirulli, A. N. Voineskos, N. C. Stefanis, D. Avramopoulos, A. Hatzimanolis, D.
    E. Arking, N. Smyrnis, R. M. Bilder, N. A. Freimer, T. D. Cannon, E. London, R.
    A. Poldrack, F. W. Sabb, E. Congdon, E. D. Conley, M. A. Scult, D. Dickinson,
    R. E. Straub, G. Donohoe, D. Morris, A. Corvin, M. Gill, A. R. Hariri, D. R. Weinberger,
    N. Pendleton, P. Bitsios, D. Rujescu, J. Lahti, S. Le Hellard, M. C. Keller, O.
    A. Andreassen, I. J. Deary, D. C. Glahn, A. K. Malhotra, T. Lencz
  - 2017-01-17
  - 10.1038/mp.2016.244
  - ! 'The complex nature of human cognition has resulted in cognitive genomics lagging
    behind many other fields in terms of gene discovery using genome-wide association
    study (<span class="smallcaps-auto">GWAS</span>) methods. In an attempt to overcome these barriers, the current study
    utilized <span class="smallcaps-auto">GWAS</span> meta-analysis to examine the association of common genetic variation
    (~8M single-nucleotide polymorphisms (<span class="smallcaps-auto">SNP</span>) with minor allele frequency ⩾1%) to
    general cognitive function in a sample of 35 298 healthy individuals of European
    ancestry across 24 cohorts in the Cognitive Genomics Consortium (<span class="smallcaps-auto">COGENT</span>). In addition,
    we utilized individual <span class="smallcaps-auto">SNP</span> lookups and polygenic score analyses to identify genetic
    overlap with other relevant neurobehavioral phenotypes. Our primary <span class="smallcaps-auto">GWAS</span> meta-analysis
    identified two novel <span class="smallcaps-auto">SNP</span> loci (top <span class="smallcaps-auto">SNP</span>s: rs76114856 in the <span class="smallcaps-auto">CENPO</span> gene on chromosome
    2 and rs6669072 near <span class="smallcaps-auto">LOC</span>105378853 on chromosome 1) associated with cognitive performance
    at the genome-wide significance level (<em>p</em><5 × 10^−8^). Gene-based analysis
    identified an additional three Bonferroni-corrected significant loci at chromosomes
    17q21.31, 17p13.1 and 1p13.3. Altogether, common variation across the genome resulted
    in a conservatively estimated <span class="smallcaps-auto">SNP</span> heritability of 21.5% (s.e.=0.01%) for general
    cognitive function. Integration with prior <span class="smallcaps-auto">GWAS</span> of cognitive performance and educational
    attainment yielded several additional significant loci. Finally, we found robust
    polygenic correlations between cognitive performance and educational attainment,
    several psychiatric disorders, birth length/weight and smoking behavior, as well
    as a novel genetic association to the personality trait of openness. These data
    provide new insight into the genetics of neurocognitive function with relevance
    to understanding the pathophysiology of neuropsychiatric illness.'
- - http://www.nature.com/mp/journal/v21/n3/full/mp20152a.html
  - Genetic link between family socioeconomic status and children’s educational achievement
    estimated from genome-wide SNPs
  - Eva Krapohl, Robert Plomin
  - 2015-03-10
  - 10.1038/mp.2015.2
  - One of the best predictors of children’s educational achievement is their family’s
    socioeconomic status (<span class="smallcaps-auto">SES</span>), but the degree to which this association is genetically
    mediated remains unclear. For 3000 UK-representative unrelated children we found
    that genome-wide single-nucleotide polymorphisms could explain a third of the
    variance of scores on an age-16 UK national examination of educational achievement
    and half of the correlation between their scores and family <span class="smallcaps-auto">SES</span>. Moreover, genome-wide
    polygenic scores based on a previously published genome-wide association meta-analysis
    of total number of years in education accounted for ~3.0% variance in educational
    achievement and ~2.5% in family <span class="smallcaps-auto">SES</span>. This study provides the first molecular evidence
    for substantial genetic influence on differences in children’s educational achievement
    and its association with family <span class="smallcaps-auto">SES</span>.
- - http://www.nature.com/mp/journal/v16/n10/full/mp201185a.html
  - Genome-wide association studies establish that human intelligence is highly heritable
    and polygenic
  - G. Davies, A. Tenesa, A. Payton, J. Yang, S. E. Harris, D. Liewald, X. Ke, S.
    Le Hellard, A. Christoforou, M. Luciano, K. McGhee, L. Lopez, A. J. Gow, J. Corley,
    P. Redmond, H. C. Fox, P. Haggarty, L. J. Whalley, G. McNeill, M. E. Goddard,
    T. Espeseth, A. J. Lundervold, I. Reinvang, A. Pickles, V. M. Steen, W. Ollier,
    D. J. Porteous, M. Horan, J. M. Starr, N. Pendleton, P. M. Visscher, I. J. Deary
  - 2011-08-09
  - 10.1038/mp.2011.85
  - General intelligence is an important human quantitative trait that accounts for
    much of the variation in diverse cognitive abilities. Individual differences in
    intelligence are strongly associated with many important life outcomes, including
    educational and occupational attainments, income, health and lifespan. Data from
    twin and family studies are consistent with a high heritability of intelligence,
    but this inference has been controversial. We conducted a genome-wide analysis
    of 3511 unrelated adults with data on 549 692 single nucleotide polymorphisms
    (<span class="smallcaps-auto">SNP</span>s) and detailed phenotypes on cognitive traits. We estimate that 40% of the
    variation in crystallized-type intelligence and 51% of the variation in fluid-type
    intelligence between individuals is accounted for by linkage disequilibrium between
    genotyped common <span class="smallcaps-auto">SNP</span> markers and unknown causal variants. These estimates provide
    lower bounds for the narrow-sense heritability of the traits. We partitioned genetic
    variation on individual chromosomes and found that, on average, longer chromosomes
    explain more variation. Finally, using just <span class="smallcaps-auto">SNP</span> data we predicted ∼1% of the variance
    of crystallized and fluid cognitive phenotypes in an independent sample (<em>p</em>=0.009
    and 0.028, respectively). Our results unequivocally confirm that a substantial
    proportion of individual differences in human intelligence is due to genetic variation,
    and are consistent with many genes of small effects underlying the additive genetic
    influences on intelligence.
- - http://www.mdpi.com/1660-4601/14/6/627/htm
  - ! 'Lithium in Drinking Water and Incidence of Suicide: A Nationwide Individual-Level
    Cohort Study with 22 Years of Follow-Up'
  - Nikoline N. Knudsen, Jörg Schullehner, Birgitte Hansen, Lisbeth F. Jørgensen,
    Søren M. Kristiansen, Denitza D. Voutchkova, Thomas A. Gerds, Per K. Andersen,
    Kristine Bihrmann, Morten Grønbæk, Lars V. Kessing, Annette K. Ersbøll
  - 2017-06-10
  - 10.3390/ijerph14060627
  - ! 'Suicide is a major public health concern. High-dose lithium is used to stabilize
    mood and prevent suicide in patients with affective disorders. Lithium occurs
    naturally in drinking water worldwide in much lower doses, but with large geographical
    variation. Several studies conducted at an aggregate level have suggested an association
    between lithium in drinking water and a reduced risk of suicide; however, a causal
    relation is uncertain. Individual-level register-based data on the entire Danish
    adult population (3.7 million individuals) from 1991 to 2012 were linked with
    a moving five-year time-weighted average (<span class="smallcaps-auto">TWA</span>) lithium exposure level from drinking
    water hypothesizing an inverse relationship. The mean lithium level was 11.6 μg/L
    ranging from 0.6 to 30.7 μg/L. The suicide rate decreased from 29.7 per 100,000
    person-years at risk in 1991 to 18.4 per 100,000 person-years in 2012. We found
    no significant indication of an association between increasing five-year <span class="smallcaps-auto">TWA</span> lithium
    exposure level and decreasing suicide rate. The comprehensiveness of using individual-level
    data and spatial analyses with 22 years of follow-up makes a pronounced contribution
    to previous findings. Our findings demonstrate that there does not seem to be
    a protective effect of exposure to lithium on the incidence of suicide with levels
    below 31 μg/L in drinking water. [Keywords: drinking water; lithium; suicide;
    individual-level data; spatial analysis; Denmark; exposure assessment]'
- - http://www.matthewckeller.com/16.Hatemi.et.al.2010.Nuc.fam.ajps.pdf
  - ! 'Not by Twins Alone: Using the Extended Family Design to Investigate Genetic
    Influence on Political Beliefs'
  - Peter K. Hatemi, John R. Hibbing, Sarah E. Medland, Matthew C. Keller, John R.
    Alford, Kevin B. Smith, Nicholas G. Martin, Lindon J. Eaves
  - 2010-06-10
  - 10.1111/j.1540-5907.2010.00461.x
  - Variance components estimates of political and social attitudes suggest a substantial
    level of genetic influence, but the results have been challenged because they
    rely on data from twins only. In this analysis, we include responses from parents
    and nontwin full siblings of twins, account for measurement error by using a panel
    design, and estimate genetic and environmental variance by maximum‐likelihood
    structural equation modeling. By doing so, we address the central concerns of
    critics, including that the twin‐only design offers no verification of either
    the equal environments or random mating assumptions. Moving beyond the twin‐only
    design leads to the conclusion that for most political and social attitudes, genetic
    influences account for an even greater proportion of individual differences than
    reported by studies using more limited data and more elementary estimation techniques.
    These findings make it increasingly difficult to deny that—however indirectly—genetics
    plays a role in the formation of political and social attitudes.
- - http://www.louischauvel.org/DAVIES2089714.pdf
  - Toward a Theory of Revolution
  - James C. Davie
  - 1962-02
  - 10.2307/2089714
  - Revolutions are most likely to occur when a prolonged period of objective economic
    and social development is followed by a short period of sharp reversal. People
    then subjectively fear that ground gained with great effort will be quite lost;
    their mood becomes revolutionary. The evidence from Dorr's Rebellion, the Russian
    Revolution, and the Egyptian Revolution supports this notion; tentatively, so
    do data on other civil disturbances. Various statistics&mdash;as on rural uprisings,
    industrial strikes, unemployment, and cost of living&mdash;may serve as crude
    indexes of popular mood. More useful, though less easy to obtain, are direct questions
    in cross-sectional interviews. The goal of predicting revolution is conceived
    but not yet born or mature
- - http://www.rand.org/pubs/monographs/MG1026.html
  - An Economic Analysis of the Financial Records of al-Qa'ida in Iraq
  - Benjamin Bahney, Howard J. Shatz, Carroll Ganier, Renny McPherson, Barbara Sude,
    Sara Beth Elson, Ghassan Schbley (<span class="smallcaps-auto">RAND</span>)
  - '2010'
  - ''
  - ! 'This monograph analyzes the finances of the militant group al-Qa''ida in Iraq
    (<span class="smallcaps-auto">AQI</span>) in Anbar province during 2005 and 2006, at the peak of the group''s power
    and influence. The authors draw on captured documents that give details on the
    daily financial transactions of one specific sector within Anbar province and
    of the financial transactions of the <span class="smallcaps-auto">AQI</span> provincial administration. Some of their
    conclusions are: <span class="smallcaps-auto">AQI</span> was a hierarchical organization with decentralized decision-making;
    <span class="smallcaps-auto">AQI</span> in Anbar was profitable enough to send substantial revenues out of the province
    in 2006; <span class="smallcaps-auto">AQI</span> relied on extortion, theft, and black market sales to fund its operations
    in Anbar; <span class="smallcaps-auto">AQI</span> needed large, regular revenue sources to fund its operations, but
    its administrative leaders did not hold much cash on hand. The authors'' interpretation
    of data on compensation practices and participants'' risk of death indicates that
    <span class="smallcaps-auto">AQI</span> members were poorly compensated and suggests that they were not motivated
    primarily by money to join the group. The authors also find that mounting attacks
    required organizational expenditures well beyond the cost of material used in
    attacks. One major conclusion is that disrupting <span class="smallcaps-auto">AQI</span>''s financial flows could
    disrupt the pace of their attacks.'
- - /Turing-complete#on-seeing-through-and-unseeing
  - ! 'On Seeing Through: The Security Mindset as Reductionism Run Amok'
  - Gwern Branwen
  - 2019-06-15
  - ''
  - ! '<p>What is the ‘hacker mindset’ or ‘security mentality’? What do accidentally
    Turing-complete systems and weird machines have in common with heist movies or
    cons or stage magic? They all share a specific paradigm whose essence is about
    <em>seeing through</em> illusions to a truer more reduced reality.</p><p>What
    they/OP/security/<a href="Wikipedia">speedrunning</a>/hacking/<a href="Wikipedia"
    title="Social engineering (security)">social-engineering</a> all have in common
    is that they show that the much-ballyhooed ‘hacker mindset’ is, fundamentally,
    a sort of reductionism run amok, where one <a href="/docs/philo/2012-sistery-tryingtoseethrough.html">‘sees
    through’</a> abstractions to a manipulable reality. Like Neo in the <em>Matrix</em>—a
    deeply cliche analogy for hacking, but cliche because it resonates—one achieves
    enlightenment by seeing through the surface illusions of objects and can now see
    the endless lines of green code which make up the Matrix.</p><p>In each case,
    the fundamental principle is that the hacker asks: “here I have a system W, which
    pretends to be made out of a few <a href="https://github.com/kdeldycke/awesome-falsehood"
    title="Falsehoods Programmers Believe About X">Xs</a>; however, it is <strong>really</strong>
    made out of many <em>Y</em>, which form an entirely different system, <em>Z</em>;
    I will now proceed to ignore the <em>X</em> and understand how <em>Z</em> works,
    so I may use the <em>Y</em> to thereby change <em>W</em> however I like”.</p>'
- - https://www.theatlantic.com/technology/archive/2012/05/the-perfect-milk-machine-how-big-data-transformed-the-dairy-industry/256423/
  - ! 'The Perfect Milk Machine: How Big Data Transformed the Dairy Industry: Dairy
    scientists are the Gregor Mendels of the genomics age, developing new methods
    for understanding the link between genes and living things, all while quadrupling
    the average cow''s milk production since your parents were born.'
  - Alexis C. Madrigal (The Atlantic)
  - 2012-05-01
  - ''
  - ! '<p>…Already, Badger-Bluff Fanny Freddie has 346 daughters who are on the books
    and thousands more that will be added to his progeny count when they start producing
    milk. This is quite a career for a young animal: He was only born in 2004.</p><p>There
    is a reason, of course, that the semen that Badger-Bluff Fanny Freddie produces
    has become such a hot commodity in what one artificial-insemination company calls
    “today’s fast paced cattle semen market.” In January of 2009, before he had a
    single daughter producing milk, the United States Department of Agriculture took
    a look at his lineage and more than 50,000 markers on his genome and declared
    him the best bull in the land. And, three years and 346 milk- and data-providing
    daughters later, it turns out that they were right. “When Freddie [as he is known]
    had no daughter records our equations predicted from his <span class="smallcaps-auto">DNA</span> that he would be
    the best bull,” <span class="smallcaps-auto">USDA</span> research geneticist Paul VanRaden emailed me with a detectable
    hint of pride. “Now he is the best progeny tested bull (as predicted).”</p><p>Data-driven
    predictions are responsible for a massive transformation of America’s dairy cows.
    While other industries are just catching on to this whole “big data” thing, the
    animal sciences—and dairy breeding in particular—have been using large amounts
    of data since long before VanRaden was calculating the outsized genetic impact
    of the most sought-after bulls with a pencil and paper in the 1980s. Dairy breeding
    is perfect for quantitative analysis. Pedigree records have been assiduously kept;
    relatively easy artificial insemination has helped centralized genetic information
    in a small number of key bulls since the 1960s; there are a relatively small and
    easily measurable number of traits—milk production, fat in the milk, protein in
    the milk, longevity, udder quality—that breeders want to optimize; each cow works
    for three or four years, which means that farmers invest thousands of dollars
    into each animal, so it’s worth it to get the best semen money can buy. The economics
    push breeders to use the genetics.</p><p>The bull market (heh) can be reduced
    to one key statistic, lifetime net merit, though there are many nuances that the
    single number cannot capture. Net merit denotes the likely additive value of a
    bull’s genetics. The number is actually denominated in dollars because it is an
    estimate of how much a bull’s genetic material will likely improve the revenue
    from a given cow. A very complicated equation weights all of the factors that
    go into dairy breeding and—voila—you come out with this single number. For example,
    a bull that could help a cow make an extra 1000 pounds of milk over her lifetime
    only gets an increase of $1 in net merit while a bull who will help that same
    cow produce a pound more protein will get $3.41 more in net merit. An increase
    of a single month of predicted productive life yields $35 more.</p><p>…In 1942,
    when my father was born, the average dairy cow produced less than 5,000 pounds
    of milk in its lifetime. Now, the average cow produces over 21,000 pounds of milk.
    At the same time, the number of dairy cows has decreased from a high of 25 million
    around the end of World War II to fewer than nine million today…a mere 70 years
    of quantitative breeding optimized to suit corporate imperatives quadrupled what
    all previous civilization had accomplished.</p><p>…John Cole, yet another <span class="smallcaps-auto">USDA</span>
    animal improvement scientist, <a title="''Use of haplotypes to estimate Mendelian
    sampling effects and selection limits'', Cole &amp; VanRaden 2011" href="https://www.aipl.arsusda.gov/publish/other/2011/Cole-VanRaden_JABG-EV_4-13-11.pdf">generated
    an estimate of the perfect bull</a> by choosing the optimal observed genetic sequences
    and hypothetically combining them. He found that the optimal bull would have a
    net merit value of $7,515, which absolutely blows any current bull out of the
    water. In other words, we’re nowhere near creating the perfect milk machine.</p>'
- - https://www.aipl.arsusda.gov/publish/other/2011/Cole-VanRaden_JABG-EV_4-13-11.pdf
  - Use of haplotypes to estimate Mendelian sampling effects and selection limits
  - J.B. Cole, P.M. VanRaden
  - '2011'
  - 10.1111/j.1439-0388.2011.00922.x
  - ! '<p>Limits to selection and Mendelian sampling (MS) terms can be calculated
    using haplotypes by summing the individual additive effects on each chromosome.
    Haplotypes were imputed for 43&thinsp;382 single nucleotide polymorphisms (<span class="smallcaps-auto">SNP</span>) in 1455
    Brown Swiss, 40&thinsp;351 Holstein and4064 Jersey bulls and cows using the Fortran program
    <code>findhap.f90</code>, which combines population and pedigree haplotyping methods.
    Lower and upper bounds of MS variance were calculated for daughter pregnancy rate
    (a measure of fertility), milk yield, lifetime net merit (a measure of profitability)
    and protein yield assuming either no or complete linkage among <span class="smallcaps-auto">SNP</span> on the same
    chromosome. Calculated selection limits were greater than the largest direct genomic
    values observed in all breeds studied. The best chromosomal genotypes generally
    consisted of two copies of the same haplotype even after adjustment for inbreeding.
    Selection of animals rather than chromosomes may result in slower progress, but
    limits may be the same because most chromosomes will become homozygous with either
    strategy. Selection on functions of MS could be used to change variances in later
    generations.</p><p>…<em>Lifetime net merit</em>: Lower selection limits for NM$
    with no adjustment for inbreeding were $3857 (BS), $7515 (HO) and $4678 (JE).
    Adjusted values were slightly smaller and were $3817 (BS), $7494 (HO) and $4606
    (JE). Upper bounds had values of $9140 (BS), $23&thinsp;588 (HO) and $11517 (JE) and
    were not adjusted for inbreeding because they were calculated from individual
    loci rather than complete haplotypes. The largest <span class="smallcaps-auto">DGV</span> among all genotyped animals
    in each breed were $1102 (BS), $2528 (HO) and $1556 (JE). The top active bulls
    (AI and foreign bulls with semen distributed in the US that are in or above the
    80<sup>th</sup> percentile, based on NM) in each breed following the August 2010 genetic
    evaluation had <span class="smallcaps-auto">GEBV</span> (Genomic estimated breeding value) for NM$ of +$1094 (BS:
    054BS00374), +$1588 (HO: 001HO08784) and +$1292 (JE: 236JE00146).</p><p>…If two
    copies of each of the 30 best haplotypes in the US Holstein population were combined
    in a single animal (Lower bounds of selection limit/SL<sub>C</sub> for NM$), it
    would have a <span class="smallcaps-auto">GEBV</span> for NM$ of +$7515 (Figure 5), approximately five times larger
    than that of the current best Holstein bull in the US, whose <span class="smallcaps-auto">GEBV</span> for NM$ are
    +1588.</p>'
- - /docs/genetics/selection/2017-wiggans.pdf
  - ! 'Genomic Selection in Dairy Cattle: The USDA Experience'
  - George R. Wiggans, John B. Cole, Suzanne M. Hubbard, Tad S. Sonstegard
  - '2017'
  - 10.1146/annurev-animal-021815-111422
  - ! 'Genomic selection has revolutionized dairy cattle breeding. Since 2000, assays
    have been developed to genotype large numbers of single-nucleotide polymorphisms
    (<span class="smallcaps-auto">SNP</span>s) at relatively low cost. The first commercial <span class="smallcaps-auto">SNP</span> genotyping chip was released
    with a set of 54,001 <span class="smallcaps-auto">SNP</span>s in December 2007. Over 15,000 genotypes were used to
    determine which <span class="smallcaps-auto">SNP</span>s should be used in genomic evaluation of US dairy cattle.
    Official <span class="smallcaps-auto">USDA</span> genomic evaluations were first released in January 2009 for Holsteins
    and Jerseys, in August 2009 for Brown Swiss, in April 2013 for Ayrshires, and
    in April 2016 for Guernseys. Producers have accepted genomic evaluations as accurate
    indications of a bull''s eventual daughter-based evaluation. The integration of
    <span class="smallcaps-auto">DNA</span> marker technology and genomics into the traditional evaluation system has
    doubled the rate of genetic progress for traits of economic importance, decreased
    generation interval, increased selection accuracy, reduced previous costs of progeny
    testing, and allowed identification of recessive lethals. [Keywords: genetic evaluation,
    single-nucleotide polymorphism, <span class="smallcaps-auto">SNP</span>, reliability, imputation, haplotype, genotype]'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.492.757&rep=rep1&type=pdf
  - Selection on Net Merit to Improve Lifetime Profit
  - P. M. VanRaden
  - '2004'
  - 10.3168/jds.S0022-0302(04)73447-5
  - Genetic selection has made dairy cows more profit-able producers of milk. Genetic
    evaluations began with 2 traits measured on a few cows but now include many traits
    measured on millions of cows. Selection indexes from <span class="smallcaps-auto">USDA</span> included yield traits
    beginning in 1971, productive life and somatic cell score beginning in 1994, conformation
    traits in 2000, and cow fertility and calving ease in 2003. This latest revision
    of net merit should result in 2% more progress, worth $5 million/yr nationally,
    with improved cow health and fitness, but slightly less progress for yield. Fertility
    and longevity evaluations have similar reliability because cows can have several
    fertility records, each with lower heritability, compared with one longevity record
    with higher heritability. Lifetime profit can be estimated more accurately if
    less heritable traits are evaluated and included instead of ignored. Milk volume
    has a positive value for fluid use, but a negative value for cheese production.
    Thus, multiple selection indexes are needed for different markets and production
    systems. Breeding programs should estimate future rather than current costs and
    prices. Many other nations have derived selection indexes similar to US net merit.
- - http://www.jonathanstray.com/papers/Langlois.pdf
  - Maxims or myths of beauty? A meta-analytic and theoretical review
  - Judith H. Langlois, Lisa Kalakanis, Adam J. Rubenstein, Andrea Larson, Monica
    Hallam, Monica Smoot
  - 2000-05
  - 10.1037//0033-2909.126.3.390
  - Common maxims about beauty suggest that attractiveness is not important in life.
    In contrast, both fitness-related evolutionary theory and socialization theory
    suggest that attractiveness influences development and interaction. In 11 meta-analyses,
    the authors evaluate these contradictory claims, demonstrating that (a) raters
    agree about who is and is not attractive, both within and across cultures; (b)
    attractive children and adults are judged more positively than unattractive children
    and adults, even by those who know them; (c) attractive children and adults are
    treated more positively than unattractive children and adults, even by those who
    know them; and (d) attractive children and adults exhibit more positive behaviors
    and traits than unattractive children and adults. Results are used to evaluate
    social and fitness-related evolutionary theories and the veracity of maxims about
    beauty.
- - http://www.pnas.org/content/early/2018/07/03/1801238115
  - Genetic analysis of social-class mobility in five longitudinal studies
  - Daniel W. Belsky, Benjamin W. Domingue, Robbee Wedow, Louise Arseneault, Jason
    D. Boardman, Avshalom Caspi, Dalton Conley, Jason M. Fletcher, Jeremy Freese,
    Pamela Herd, Terrie E. Moffitt, Richie Poulton, Kamil Sicinski, Jasmin Wertz,
    Kathleen Mullan Harris
  - 2018-07-31
  - 10.1073/pnas.1801238115
  - ! '<p>Genome-wide association study (<span class="smallcaps-auto">GWAS</span>) discoveries about educational attainment
    have raised questions about the meaning of the genetics of success. These discoveries
    could offer clues about biological mechanisms or, because children inherit genetics
    and social class from parents, education-linked genetics could be spurious correlates
    of socially transmitted advantages. To distinguish between these hypotheses, we
    studied social mobility in five cohorts from three countries. We found that people
    with more education-linked genetics were more successful compared with parents
    and siblings. We also found mothers’ education-linked genetics predicted their
    children’s attainment over and above the children’s own genetics, indicating an
    environmentally mediated genetic effect. Findings reject pure social-transmission
    explanations of education <span class="smallcaps-auto">GWAS</span> discoveries. Instead, genetics influences attainment
    directly through social mobility and indirectly through family environments.</p><p>A
    summary genetic measure, called a “polygenic score,” derived from a genome-wide
    association study (<span class="smallcaps-auto">GWAS</span>) of education can modestly predict a person’s educational
    and economic success. This prediction could signal a biological mechanism: Education-linked
    genetics could encode characteristics that help people get ahead in life. Alternatively,
    prediction could reflect social history: People from well-off families might stay
    well-off for social reasons, and these families might also look alike genetically.
    A key test to distinguish biological mechanism from social history is if people
    with higher education polygenic scores tend to climb the social ladder beyond
    their parents’ position. Upward mobility would indicate education-linked genetics
    encodes characteristics that foster success. We tested if education-linked polygenic
    scores predicted social mobility in >20,000 individuals in five longitudinal studies
    in the United States, Britain, and New Zealand. Participants with higher polygenic
    scores achieved more education and career success and accumulated more wealth.
    However, they also tended to come from better-off families. In the key test, participants
    with higher polygenic scores tended to be upwardly mobile compared with their
    parents. Moreover, in sibling-difference analysis, the sibling with the higher
    polygenic score was more upwardly mobile. Thus, education <span class="smallcaps-auto">GWAS</span> discoveries are
    not mere correlates of privilege; they influence social mobility within a life.
    Additional analyses revealed that a mother’s polygenic score predicted her child’s
    attainment over and above the child’s own polygenic score, suggesting parents’
    genetics can also affect their children’s attainment through environmental pathways.
    Education <span class="smallcaps-auto">GWAS</span> discoveries affect socioeconomic attainment through influence on
    individuals’ family-of-origin environments and their social mobility. [Keywords:  genetics,
    social class, social mobility, sociogenomics, polygenic score]</p>'
- - https://www.pnas.org/content/early/2016/05/25/1523592113.full
  - Assortative mating and differential fertility by phenotype and genotype across
    the 20<sup>th</sup> century
  - Dalton Conley, Thomas Laidley, Daniel W. Belsky, Jason M. Fletcher, Jason D. Boardman,
    Benjamin W. Domingue
  - 2016-05-31
  - 10.1073/pnas.1523592113
  - ! '<p>We describe dynamics in assortative mating and fertility patterns by polygenic
    scores associated with anthropometric traits, depression, and educational attainment
    across birth cohorts from 1920 to 1955. We find that, for example, increases in
    assortative mating at the phenotypic level for education are not matched at the
    genotypic level. We also show that genes related to height are positively associated
    with fertility and that, despite a widening gap between the more and less educated
    with respect to fertility, there is no evidence that this trend is associated
    with genes. These findings are important to our understanding of the roots of
    shifting distributions of health and behavior across generations in US society.</p><p>This
    study asks two related questions about the shifting landscape of marriage and
    reproduction in US society over the course of the last century with respect to
    a range of health and behavioral phenotypes and their associated genetic architecture:
    (i) Has assortment on measured genetic factors influencing reproductive and social
    fitness traits changed over the course of the 20<sup>th</sup> century? (ii) Has the genetic
    covariance between fitness (as measured by total fertility) and other traits changed
    over time? The answers to these questions inform our understanding of how the
    genetic landscape of American society has changed over the past century and have
    implications for population trends. We show that husbands and wives carry similar
    loadings for genetic factors related to education and height. However, the magnitude
    of this similarity is modest and has been fairly consistent over the course of
    the 20<sup>th</sup> century. This consistency is particularly notable in the case of education,
    for which phenotypic similarity among spouses has increased in recent years. Likewise,
    changing patterns of the number of children ever born by phenotype are not matched
    by shifts in genotype–fertility relationships over time. Taken together, these
    trends provide no evidence that social sorting is becoming increasingly genetic
    in nature or that dysgenic dynamics have accelerated. [Keywords: assortative mating,
    fertility, polygenic scores, cohort trends]</p>'
- - /docs/iq/2011-gensowski.pdf
  - The Effects of Education, Personality, and IQ on Earnings of High-Ability Men
  - Miriam Gensowski, James Heckman, Peter Savelyev
  - 2011-01-24
  - ''
  - ! '<p>[Preprint version of <a href="/docs/iq/2018-gensowski.pdf">Gensowski 2018</a>]</p><p>This
    paper estimates the internal rate of return (<span class="smallcaps-auto">IRR</span>) to education for men and women
    of the Terman sample, a 70-year long prospective cohort study of high-ability
    individuals. The Terman data is unique in that it not only provides full working-life
    earnings histories of the participants, but it also includes detailed profiles
    of each subject, including IQ and measures of latent personality traits. Having
    information on latent personality traits is significant as it allows us to measure
    the importance of personality on educational attainment and lifetime earnings.</p><p>Our
    analysis addresses two problems of the literature on returns to education: First,
    we establish causality of the treatment effect of education on earnings by implementing
    generalized matching on a full set of observable individual characteristics and
    unobserved personality traits. Second, since we observe lifetime earnings data,
    our estimates of the <span class="smallcaps-auto">IRR</span> are direct and do not depend on the assumptions that
    are usually made in order to justify the interpretation of regression coefficients
    as rates of return.</p><p>For the males, the returns to education beyond high
    school are sizeable. For example, the <span class="smallcaps-auto">IRR</span> for obtaining a bachelor’s degree over
    a high school diploma is 11.1%, and for a doctoral degree over a bachelor’s degree
    it is 6.7%. These results are unique because they highlight the returns to high-ability
    and high-education individuals, who are not well-represented in regular data sets.</p><p>Our
    results highlight the importance of personality and intelligence on our outcome
    variables. We find that personality traits similar to the Big Five personality
    traits are significant factors that help determine educational attainment and
    lifetime earnings. Even holding the level of education constant, measures of personality
    traits have significant effects on earnings. Similarly, IQ is rewarded in the
    labor market, independently of education. Most of the effect of personality and
    IQ on life-time earnings arise late in life, during the prime working years. Therefore,
    estimates from samples with shorter durations underestimate the treatment effects.</p>'
- - /docs/iq/2018-gensowski.pdf
  - Personality, IQ, and lifetime earnings
  - Miriam Gensowski
  - 2018-04
  - 10.1016/j.labeco.2017.12.004
  - ! '<p>[Published version of <a href="/docs/iq/2011-gensowski.pdf">Gensowski et
    al 2011</a>]</p><ul><li>This paper estimates the effects of personality traits
    and IQ on lifetime earnings, both as a sum and individually by age.</li><li>The
    payoffs to personality traits display a concave life-cycle pattern, with the largest
    effects between the ages of 40 and 60.</li><li>The largest effects on earnings
    are found for Conscientiousness, Extraversion, and Agreeableness (negative).</li><li>An
    interaction of traits with education reveals that personality matters most for
    highly educated men.</li><li>The overall effect of Conscientiousness operates
    partly through education, which also has significant returns.</li></ul><p>This
    paper estimates the effects of personality traits and IQ on lifetime earnings
    of the men and women of the Terman study, a high-IQ U.S. sample. Age-by-age earnings
    profiles allow a study of <em>when</em> personality traits affect earnings most,
    and for <em>whom</em> the effects are strongest. I document a concave life-cycle
    pattern in the payoffs to personality traits, with the largest effects between
    the ages of 40 and 60. An interaction of traits with education reveals that personality
    matters most for highly educated men. The largest effects are found for Conscientiousness,
    Extraversion, and Agreeableness (negative), where Conscientiousness operates partly
    through education, which also has significant returns. [Keywords: Personality
    traits, Socio-emotional skills, Cognitive skills, Returns to education, Lifetime
    earnings, Big Five, Human capital, Factor analysis]</p>'
- - https://research.mozilla.org/files/2018/04/The-Effect-of-Ad-Blocking-on-User-Engagement-with-the-Web.pdf
  - The Effect of Ad Blocking on User Engagement with the Web
  - Ben Miroglio, David Zeber, Jofish Kaye, Rebecca Weiss
  - 2018-04-23
  - 10.1145/3178876.3186162
  - Web users are increasingly turning to ad blockers to avoid ads, which are often
    perceived as annoying or an invasion of privacy. While there has been significant
    research into the factors driving ad blocker adoption and the detrimental effect
    to ad publishers on the Web, the resulting effects of ad blocker usage on Web
    users' browsing experience is not well understood. To approach this problem, we
    conduct a retrospective natural field experiment using Firefox browser usage data,
    with the goal of estimating the effect of adblocking on user engagement with the
    Web. We focus on new users who installed an ad blocker after a baseline observation
    period, to avoid comparing different populations. Their subsequent browser activity
    is compared against that of a control group, whose members do not use ad blockers,
    over a corresponding observation period, controlling for prior baseline usage.
    In order to estimate causal effects, we employ propensity score matching on a
    number of other features recorded during the baseline period. In the group that
    installed an ad blocker, we find significant increases in both active time spent
    in the browser (+28% over control) and the number of pages viewed (+15% over control),
    while seeing no change in the number of searches. Additionally, by reapplying
    the same methodology to other popular Firefox browser extensions, we show that
    these effects are specific to ad blockers. We conclude that ad blocking has a
    positive impact on user engagement with the Web, suggesting that any costs of
    using ad blockers to users' browsing experience are largely drowned out by the
    utility that they offer.
- - https://nicholaswpapageorge.files.wordpress.com/2018/05/genes_wealth.pdf
  - Genetic Endowments and Wealth Inequality
  - Daniel Barth, Nicholas W. Papageorge, Kevin Thom
  - 2018-05-16
  - 10.3386/w24642
  - We show that genetic endowments linked to educational attainment strongly and
    robustly predict wealth at retirement. The estimated relationship is not fully
    explained by flexibly controlling for education and labor income. We therefore
    investigate a host of additional mechanisms that could help to explain the gene-wealth
    gradient, including inheritances, mortality, savings, risk preferences, portfolio
    decisions, beliefs about the probabilities of macroeconomic events, and planning
    horizons. The associations we report provide preliminary evidence that genetic
    endowments related to human capital accumulation are associated with wealth not
    only through educational attainment and labor income, but also through a facility
    with complex financial decision-making. Our study illustrates how economic research
    seeking to understand sources of inequality can benefit from recent advances in
    behavioral genetics linking specific observed genetic endowments to economic outcomes.
- - https://slatestarcodex.com/2018/10/30/sort-by-controversial/
  - Sort By Controversial
  - Scott Alexander
  - 2018-10-30
  - ''
  - ! '[Contemporary SF short story; inspired by NN text generation, social media
    dynamics, clickbait, and debates like <a href="https://en.wikipedia.org/wiki/The_dress">''the
    dress''</a>; imagines AI natural language processing systems run amok after being
    trained to maximize user reactions to create clickbait, leading to learning ''scissor
    statements'', claims which are maximally controversial and divide the population
    50-50 between those who find the statement obviously correct and moral, and those
    who find it equally obviously false and immoral, leading to intractable polarizing
    debates, contempt, and warfare.]'
- - http://researchdmr.com/ProbabilityTotalError.pdf
  - Disentangling Bias and Variance in Election Polls
  - Houshmand Shirani-Mehr, David Rothschild, Sharad Goel, Andrew Gelman
  - 2018-07-25
  - 10.1080/01621459.2018.1448823
  - ! 'It is well known among researchers and practitioners that election polls suffer
    from a variety of sampling and nonsampling errors, often collectively referred
    to as total survey error. Reported margins of error typically only capture sampling
    variability, and in particular, generally ignore nonsampling errors in defining
    the target population (e.g., errors due to uncertainty in who will vote). Here,
    we empirically analyze 4221 polls for 608 state-level presidential, senatorial,
    and gubernatorial elections between 1998 and 2014, all of which were conducted
    during the final three weeks of the campaigns. Comparing to the actual election
    outcomes, we find that average survey error as measured by root mean square error
    is approximately 3.5 percentage points, about twice as large as that implied by
    most reported margins of error. We decompose survey error into election-level
    bias and variance terms. We find that average absolute election-level bias is
    about 2 percentage points, indicating that polls for a given election often share
    a common component of error. This shared error may stem from the fact that polling
    organizations often face similar difficulties in reaching various subgroups of
    the population, and that they rely on similar screening rules when estimating
    who will vote. We also find that average election-level variance is higher than
    implied by simple random sampling, in part because polling organizations often
    use complex sampling designs and adjustment procedures. We conclude by discussing
    how these results help explain polling failures in the 2016 U.S. presidential
    election, and offer recommendations to improve polling practice. [Keywords: Margin
    of error, Non-sampling error, Polling bias, Total survey error]'
- - http://people.csail.mit.edu/andyd/rec_method.pdf
  - ! 'Multiplying 10-digit numbers using Flickr: The power of recognition memory'
  - Andrew Drucker
  - '2011'
  - ''
  - ! '<p>In this informal article, I’ll describe the “recognition method”—a simple,
    powerful technique for memorization and mental calculation. Compared to traditional
    memorization techniques, which use elaborate encoding and visualization processes
    [1], the recognition method is easy to learn and requires relatively little effort…The
    method <em>works</em>: using it, I was able to mentally multiply two random 10-digit
    numbers, by the usual grade-school algorithm, on my first attempt! I have a normal,
    untrained memory, and the task would have been impossible by a direct approach.
    (I can’t claim I was speedy: I worked slowly and carefully, using about 7 hours
    plus rest breaks. I practiced twice with 5-digit numbers beforehand.)</p><p>…It
    turns out that ordinary people are incredibly good at this task [recognizing whether
    a photograph has been seen before]. In one of the most widely-cited studies on
    recognition memory, <a href="https://www.sas.upenn.edu/psych/rust-lab/publications/standing_73.pdf"
    title="Learning 10000 pictures">Standing [2]</a> showed participants an epic 10,000
    photographs over the course of 5 days, with 5 seconds’ exposure per image. He
    then tested their familiarity, essentially as described above. The participants
    showed an 83% success rate, suggesting that they had become familiar with about
    6,600 images during their ordeal. Other volunteers, trained on a smaller collection
    of 1,000 images selected for vividness, had a 94% success rate.</p>'
- - https://www.cs.dartmouth.edu/~sergey/wm/
  - What are Weird Machines?
  - Sergey Bratus
  - '2015'
  - ''
  - <p>The expression <strong>"weird machines"</strong> was first used in the <a href="http://www.cs.dartmouth.edu/~sergey/hc/rss-hacker-research.pdf"><span class="smallcaps-auto">RSS</span>
    2009 talk</a>. It referred to state-of-the-art exploitation as finding and programming
    an execution model (a machine, such as a virtual automaton) within the target
    via crafted inputs. It was soon extended to other methods of reliably or probabilistically
    influencing the target's state. A compressed version of that original talk was
    given at the Chaos Computing Congress 27c3 <a href="http://events.ccc.de/congress/2010/Fahrplan/attachments/1807_ccc-hacker-research.pdf">[slides]</a>,
    <a href="http://www.youtube.com/watch?v=4sUmANLFD8s">[video]</a>.</p><p>The concept
    was further elaborated in <a href="http://immunityinc.com/infiltrate/archives/Fundamentals_of_exploitation_revisited.pdf">Exploitation
    and State Machines</a> by Thomas Dullien / Halvar Flake at Infiltrate 2011, <a
    href="http://census-labs.com/media/heap-owasp-appsec-2012.pdf">Heap Exploitation
    Abstraction by Example</a> by Census Labs at <a href="http://log.cedricbonhomme.org/44d3fc878b97103d1ffd5dff7548ba0f0f6de05d/007b37438f20d1dad6e8c92bc5a7af6e414b2c08.html"><span class="smallcaps-auto">OWASP</span>
    2012</a>, and others. A historical sketch can be found in <a href="http://langsec.org/papers/Bratus.pdf">From
    Buffer Overflows to "Weird Machines"</a> by Bratus et al.</p><p>Effort is underway
    to produce formal descriptions of weird machine classes in various computing environments.
    Thomas Dullien's 2017 paper <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8226852">Weird
    machines, exploitability, and provable unexploitability</a> is the most notable
    recent development (see <a href="https://www.cs.dartmouth.edu/~sergey/wm/#formalisms">Formalisms</a> below). The <a href="http://langsec.org">LangSec</a>
    effort is aimed at describing and eliminating broad classes of input-related bugs
    and associated weird machines.</p>
- - https://pdfs.semanticscholar.org/5bbe/46d0d07f1371cd8fa54bd05d9dccca9b3a58.pdf
  - Weird machines, exploitability, and provable unexploitability
  - Thomas Dullien
  - 2017-12-19
  - 10.1109/TETC.2017.2785299
  - ! '<p>The concept of <em>exploit</em> is central to computer security, particularly
    in the context of <em>memory corruptions</em>. Yet, in spite of the centrality
    of the concept and voluminous descriptions of various exploitation techniques
    or countermeasures, a good theoretical framework for describing and reasoning
    about exploitation has not yet been put forward.</p><p>A body of concepts and
    folk theorems exists in the community of exploitation practitioners; unfortunately,
    these concepts are rarely written down or made sufficiently precise for people
    outside of this community to benefit from them. This paper clarifies a number
    of these concepts, provides a clear definition of exploit, a clear definition
    of the concept of a <em>weird machine</em>, and how programming of a weird machine
    leads to exploitation. The papers also shows, somewhat counterintuitively, that
    it is feasible to design some software in a way that even powerful attackers&mdash;with
    the ability to corrupt memory once&mdash;cannot gain an advantage.</p><p>The approach
    in this paper is focused on <em>memory corruptions</em>. While it can be applied
    to many security vulnerabilities introduced by other programming mistakes, it
    does not address <em>side channel attacks</em>, <em>protocol weaknesses</em>,
    or security problems that are present by design. [Keywords: Computer Security,
    Computer hacking, Computation Theory, Information security, Language-theoretic
    security]</p>'
- - /docs/traffic/2019-shapiro.pdf
  - Generalizable and Robust TV Advertising Effects
  - Bradley Shapiro, Günter J. Hitsch, Anna Tuchman
  - 2019-06-11
  - 10.2139/ssrn.3273476
  - ! 'We provide generalizable and robust results on the causal sales effect of TV
    advertising based on the distribution of advertising elasticities for a large
    number of products (brands) in many categories. Such generalizable results provide
    a prior distribution that can improve the advertising decisions made by firms
    and the analysis and recommendations of anti-trust and public policy makers. A
    single case study cannot provide generalizable results, and hence the marketing
    literature provides several meta-analyses based on published case studies of advertising
    effects. However, <em>publication bias</em> results if the research or review
    process systematically rejects estimates of small, statistically insignificant,
    or “unexpected” advertising elasticities. Consequently, if there is publication
    bias, the results of a meta-analysis will not reflect the true population distribution
    of advertising effects. To provide <em>generalizable</em> results, we base our
    analysis on a large number of products and clearly lay out the research protocol
    used to select the products. We characterize the distribution of <em>all</em>
    estimates, irrespective of sign, size, or statistical significance. To ensure
    generalizability we document the <em>robustness</em> of the estimates. First,
    we examine the sensitivity of the results to the approach and assumptions made
    when constructing the data used in estimation from the raw sources. Second, as
    we aim to provide causal estimates, we document if the estimated effects are sensitive
    to the identification strategies that we use to claim causality based on observational
    data. Our results reveal substantially smaller effects of own-advertising compared
    to the results documented in the extant literature, as well as a sizable percentage
    of statistically insignificant or negative estimates. If we only select products
    with statistically significant and positive estimates, the mean or median of the
    advertising effect distribution increases by a factor of about five. The results
    are robust to various identifying assumptions, and are consistent with both publication
    bias and bias due to non-robust identification strategies to obtain causal estimates
    in the literature. [Keywords: Advertising, Publication Bias, Generalizability]'
- - /docs/traffic/2018-04-10-tavan-isadblockingtenpercenthigherthancommonlymeasured.html
  - Is Ad Blocking 10% Higher Than Commonly Measured?
  - Christoph Tavan (contentpass)
  - 2018-04-10
  - ''
  - ! '<p>A recent study by contentpass indicates that more than 25% of all ad blockers
    on desktop devices use the EasyPrivacy blocklist and are therefore invisible to
    common website analytics software…The by far most popular filter list to block
    ads is the so-called “Easylist”. It is activated by default in popular ad blockers
    like Adblock Plus, Adblock or uBlock Origin and focuses on blocking ads both on
    a network&mdash;and on a visual level. Even the built-in ad blocker of Google
    Chrome uses this list.</p><p>While EasyPrivacy users are now “invisible” to our
    service as well, we recently integrated our solution under the first party domain
    on a popular German IT news website. As a consequence of this first party integration
    the statistics about ad blocker usage were sent to a different <span class="smallcaps-auto">URL</span>, which was
    initially not being blocked by EasyPrivacy. It took about two weeks for the EasyPrivacy
    community to put the statistics <span class="smallcaps-auto">URL</span> of the first party domain on a filter list
    again.</p><p>These two weeks of unfiltered data allow us to get an idea of how
    many people use an ad blocker with EasyPrivacy activated (be it Adblock Plus/Adblock
    where the user manually activated EasyPrivacy or uBlock Origin where EasyPrivacy
    is activated by default).</p><p>Our data suggests that over 25% of all users with
    active ad blocking software on desktop devices use EasyPrivacy and are thus invisible
    to major web analytics software. In this specific case the <em>true</em> ad blocking
    rate on desktop was 37% while analytics software that is blocked by EasyPrivacy
    would only report what corresponds to 27% of ad blocking. Or from a different
    perspective: 10% of the total desktop traffic on this website is not analyzed
    and counted by common third party analytics software. Historical data from the
    time where our service was initially added to EasyPrivacy suggests similar proportions
    on other sites and verticals.</p>'
- - /docs/traffic/1991-abernethy.pdf
  - ! 'Television Exposure: Programs vs. Advertising'
  - Avery M. Abernethy
  - '1991'
  - 10.1080/01633392.1991.10504959
  - Although it is generally accepted that television program ratings are greater
    than the audience's exposure to the advertising, the key issue is the actual size
    of the difference. A review of advertising, marketing, communication, and sociology
    literature yields some indications of the degree of difference between ad and
    program exposure and factors in the viewing environment which could influence
    audience commercial avoidance.
- - /docs/traffic/2002-edwards.pdf
  - ! 'Forced Exposure and Psychological Reactance: Antecedents and Consequences of
    the Perceived Intrusiveness of Pop-Up Ads'
  - Steven M. Edwards, Hairong Li, Joo-Hyun Lee
  - '2002'
  - 10.1080/00913367.2002.10673678
  - This paper explores forced viewing of “pop-up ads” on the Internet to understand
    better how viewers come to define ads as irritating and decide to avoid them.
    Perceived intrusiveness was suggested as the underlying mechanism by which the
    process occurs. Antecedents of intrusiveness were identified that affect perceptions
    of ads as interruptions, including congruence of the advertisement content with
    the current task and intensity of cognition at the moment the ad pops up. The
    consequences of intrusiveness were shown to be caused by feelings of irritation
    and ad avoidance. The results provide an understanding of how consumers experience
    forced exposure situations in interactive environments and highlight implications
    for advertisers seeking to increase the effectiveness of on-line advertising.
- - /docs/traffic/2004-galletta.pdf
  - ! 'Web Site Delays: How Tolerant are Users?'
  - Dennis F. Galletta, Raymond Henry, Scott McCoy, Peter Polak
  - '2004'
  - ''
  - Web page loading speed continues to vex users, even as broadband adoption increases.
    Several studies have addressed delays in the context of Web sites as well as interactive
    corporate systems, and have recommended a wide range of 'rules of thumb'. Some
    studies conclude that response times should be no greater than 2 seconds while
    other studies caution on delays of 12 seconds or more. One of the strongest conclusions
    was that complex tasks seemed to allow longer response times. This study examined
    delay times of 0, 2, 4, 6, 8, 10, and 12 seconds using 196 undergraduate students
    in an experiment. Randomly assigned a constant delay time, subjects were asked
    to complete 9 search tasks, exploring a familiar and an unfamiliar site. Plots
    of the dependent variables performance, attitudes, and behavioral intentions,
    along those delays, suggested the use of non-linear regression, and the explained
    variance was in the neighborhood of 2%, 5%, and 7%, respectively. Focusing only
    on the familiar site, explained variance in attitudes and behavioral intentions
    grew to about 16%. A sensitivity analysis implies that decreases in performance
    and behavioral intentions begin to flatten when the delays extend to 4 seconds
    or longer, and attitudes flatten when the delays extend to 8 seconds or longer.
    Future research should include other factors such as expectations, variability,
    and feedback, and other outcomes such as actual purchasing behavior, to more fully
    understand the effects of delays in today's Web environment.
- - /docs/traffic/2000-bayles-justhowblindarewetoadvertisingbannersontheweb.html
  - Just How 'Blind' Are We to Advertising Banners on the Web?
  - Michelle Bayles
  - 2000-07
  - ''
  - ! '<p>Moreover, Benway (1998) showed that extremely colorful and obvious banners
    tend to be ignored by users. When participants in this study were asked to find
    specific information on a web page, the information was not found if it was embedded
    in a banner. Benway consequently named this phenomenon “banner blindness.” Benway
    also found that banners located at the top of the page (away from other links),
    tended to be ignored more often than banners located lower down the page (closer
    to other important links). This finding is supported by another study which showed
    a 77% increased click-through rate for advertisements placed <math display="inline"
    xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mn>3</mn></mfrac><annotation
    encoding="application/x-tex">\frac{1}{3}</annotation></semantics></math> of
    the way down the page (Athenia Assoc., 1997).</p><p>…In our study, we were curious
    to simply explore how much users remember about a web page after viewing it –
    in particular, we were interested in investigating user memory of banner advertisements:</p><ol
    type="1"><li>How well can users’ recall a banner advertisement on a web page?</li><li>How
    well can users’ recognize a banner advertisement on a web page?</li><li>Does animation
    affect user recall or recognition of an advertising banner?</li></ol><p>…Very
    few participants were able to complete both the recognition and recall tasks correctly.
    Only 3 (9%) of participants were able to correctly recall both advertisements,
    recognize both companies, and correctly recall and recognize the state in which
    they were presented. On the other hand, participants who were unable to recall
    anything for either company banner or correctly indicate the animation state of
    the banner (40%) had a surprisingly high recognition rate of 79% for two correctly
    recognized ads. Results also show that of the 26% who recognized only one ad,
    the banner recognized was typically presented in the animated state. In other
    words, 7 out of 9 times the single banner correctly recognized was in the animated
    state. This indicates that animation may have some effect on recognition.</p><p>Results
    from this study indicate that recognition of the banner advertisements were fairly
    high (74% for both banners). In addition, about half of the participants were
    able to recall at least seeing an advertisement on the page—and many of these
    actually recalled the name of the company. These results show that most users
    did notice and remember the banners even though they were not part of the search
    tasks they were performing.</p>'
- - /docs/traffic/2007-mccoy.pdf
  - ! 'The Effects Of Online Advertising: Consumers’ first impressions (and loyalties)
    are made in the opening moments of a Web site visit and the degree to which that
    visit may be intruded by pop-ups, pop-unders, and banner ads'
  - Scott McCoy, Andrea Everard, Peter Polak, Dennis F. Galletta
  - '2007'
  - 10.1145/1226736.1226740
  - <p>We conducted an experiment with different forms and types of ads. An artificial
    Web site was created for the experiment that contained images, prices, and descriptions
    of familiar products and product categories. The products were those that would
    be carried by a general store and included food, health care, and household products.
    Nine search tasks were assigned to participants that would force them to traverse
    a variety of portions of the site…The experimental websites were accessed over
    the Internet in a controlled laboratory setting by 536 undergraduate students.</p><p>…This
    study provides clear support for an assertion that users will adopt more negative
    intentions when a site displays advertisements than when the site does not. It
    is also clear that advertisements interfere with retention of site content and
    that features of advertisements also have important effects on retaining both
    site and ad content. Inline ads permit both site and ad content to be remembered
    more clearly than popups and popunders, a finding that is most interesting because
    it suggests the action of closing the advertisement window distracts users from
    the site, and further, it is visible for a shorter time. When ads are markedly
    different from the content of the site, they theoretically stimulate more effort
    as users work toward an important goal, and users remember more about both the
    Web site and the advertisement. It is interesting to note that while these effects
    might on the surface appear small, they are quite consistent and highly significant.
    Extrapolating to millions of site visitors, even small differences can amount
    to an urgent problem for management. Finally, it is also clear that popups and
    popunders are considered to be more intrusive than inline ads. Users seem to prefer
    not to have to divert their attention from their searching task or take additional
    steps to close the popup or pop-under windows.</p>
- - https://classic.esquire.com/article/1971/10/1/secrets-of-the-blue-box
  - ! 'Secrets of the Little Blue Box: A story so incredible it may even make you
    feel sorry for the phone company'
  - Ron Rosenbaum (Esquire)
  - 1971-10-01
  - ''
  - <p>[Early account of <a href="https://en.wikipedia.org/wiki/Phreaking">“phone
    phreakers”</a> and their most famous hacking device, the <a href="https://en.wikipedia.org/wiki/Blue_box">blue
    box</a>, used to control the Bell Phone System and enable free long-distance calls
    (then exorbitantly expensive); the blue box was famously based on an AT&amp;T
    research paper describing the tone frequencies and how they control the phone
    switching system. The author hangs out with phreaks such as <a href="https://en.wikipedia.org/wiki/John_Draper">Captain
    Crunch</a> to see how it all works.</p><p>After reading Rosenbaum’s article, Steve
    Jobs and his partner in founding Apple, Steve Wozniak, “collaborated on building
    and selling blue boxes, devices that were widely used for making free—and illegal—phone
    calls. They raised a total of $6,000 from the effort.”]</p>
- - /Inflation.hs
  - InflationAdjuster
  - Gwern Branwen
  - 2019-03-27
  - ''
  - ! '<p>Experimental Pandoc module for implementing automatic inflation adjustment
    of nominal date-stamped dollar or Bitcoin amounts to provide real prices; Bitcoin’s
    exchange rate has moved by multiple orders of magnitude over its early years (rendering
    nominal amounts deeply unintuitive), and this is particularly critical in any
    economics or technology discussion where a nominal price from 1950 is 11x the
    2019 real price!</p><p>Years/dates are specified in a variant of my interwiki
    link syntax; for example: <code>[$50]($2000)</code> or <code>[₿0.5]($2017-01-01)</code>,
    giving link adjustments which look like "<span class="inflationAdjusted" data-originalYear="2017-01-01"
    data-originalAmount="50.50" data-currentYear="2019" data-currentAmount="50,500">₿50.50<span
    class="math inline"><em></em><sub>2017</sub><sup>$50,500</sup></span></span>".
    Dollar amounts use year, and Bitcoins use full dates, as the greater temporal
    resolution is necessary. Inflation rates/exchange rates are specified in Inflation.hs
    and need to be manually updated every once in a while; if out of date, the last
    available rate is carried forward for future adjustments.</p>'
- - https://www.nature.com/articles/npp2011276
  - Is Cognitive Functioning Impaired in Methamphetamine Users? A Critical Review
  - Carl L. Hart, Caroline B. Marvin, Rae Silver, Edward E. Smith
  - 2011-11-16
  - 10.1038/npp.2011.276
  - The prevailing view is that recreational methamphetamine use causes a broad range
    of severe cognitive deficits, despite the fact that concerns have been raised
    about interpretations drawn from the published literature. This article addresses
    an important gap in our knowledge by providing a critical review of findings from
    recent research investigating the impact of recreational methamphetamine use on
    human cognition. Included in the discussion are findings from studies that have
    assessed the acute and long-term effects of methamphetamine on several domains
    of cognition, including visuospatial perception, attention, inhibition, working
    memory, long-term memory, and learning. In addition, relevant neuroimaging data
    are reviewed in an effort to better understand neural mechanisms underlying methamphetamine-related
    effects on cognitive functioning. In general, the data on acute effects show that
    methamphetamine improves cognitive performance in selected domains, that is, visuospatial
    perception, attention, and inhibition. Regarding long-term effects on cognitive
    performance and brain-imaging measures, statistically significant differences
    between methamphetamine users and control participants have been observed on a
    minority of measures. More importantly, however, the clinical significance of
    these findings may be limited because cognitive functioning overwhelmingly falls
    within the normal range when compared against normative data. In spite of these
    observations, there seems to be a propensity to interpret any cognitive and/or
    brain difference(s) as a clinically significant abnormality. The implications
    of this situation are multiple, with consequences for scientific research, substance-abuse
    treatment, and public policy.
- - /docs/catnip/2019-jones.pdf
  - ! 'Black Cat Bias: Prevalence and Predictors'
  - Haylie D. Jones, Christian L. Hart
  - 2019-04-29
  - 10.1177/0033294119844982
  - There is anecdotal and empirical evidence for black cat bias, the phenomenon where
    cats (<em>Felis silvestris catus</em>) with black coats are viewed more negatively,
    adopted less often, and euthanized more often than lighter colored cats. Despite
    the anecdotal claims, there is scarce empirical evidence for black cat bias. Using
    evaluations of cat photos, the researchers examined differences in people’s attitudes
    toward black and non-black cats of various colorations on measures of perceived
    aggression, perceived friendliness, and willingness to adopt. The researchers
    also explored whether participants’ levels of religiosity, superstitious beliefs,
    and prejudicial racial attitudes were related to black cat bias. Finally, the
    researchers explored whether black cat bias was related to difficulties people
    had in reading the emotions of black cats compared to non-black cats. This study
    provided evidence of black cat bias in the sample. People exhibiting higher degrees
    of black cat bias had higher levels of superstition, but not religiosity or racial
    prejudice. Additionally, people who had difficulty reading the emotions of black
    cats tended to exhibit a stronger bias against adopting black cats.
- - https://kk.org/thetechnium/the-unabomber-w/
  - The Unabomber Was Right
  - Kevin Kelly
  - 2009-02-18
  - ''
  - ! '<p>Ted Kaczynski, the convicted bomber who blew up dozens of technophilic professionals,
    was right about one thing: technology has its own agenda. The technium is not,
    as most people think, a series of individual artifacts and gadgets for sale. Rather,
    Kaczynski, speaking as the Unabomber, argued that technology is a dynamic holistic
    system. It is not mere hardware; rather it is more akin to an organism. It is
    not inert, nor passive; rather the technium seeks and grabs resources for its
    own expansion. It is not merely the sum of human action, but in fact it transcends
    human actions and desires. I think Kaczynski was right about these claims. In
    his own words the Unabomber says: “The system does not and cannot exist to satisfy
    human needs. Instead, it is human behavior that has to be modified to fit the
    needs of the system. This has nothing to do with the political or social ideology
    that may pretend to guide the technological system. It is the fault of technology,
    because the system is guided not by ideology but by technical necessity.”</p><p>…As
    best I understand, the Unabomber’s argument goes like this:</p><ul><li>Personal
    freedoms are constrained by society, as they must be.</li><li>The stronger that
    technology makes society, the less freedoms.</li><li>Technology destroys nature,
    which strengthens technology further.</li><li>This ratchet of technological self-amplification
    is stronger than politics.</li><li>Any attempt to use technology or politics to
    tame the system only strengthens it.</li><li>Therefore technological civilization
    must be destroyed, rather than reformed.</li><li>Since it cannot be destroyed
    by tech or politics, humans must push industrial society towards its inevitable
    end of self-collapse.</li><li>Then pounce on it when it is down and kill it before
    it rises again.</li></ul><p>…The problem is that Kaczynski’s most basic premise,
    the first axiom in his argument, is not true. The Unabomber claims that technology
    robs people of freedom. But most people of the world find the opposite. They gravitate
    towards venues of increasing technology because they recognize they have more
    freedoms when they are empowered with it. They (that is we) realistically weigh
    the fact that yes, indeed, some options are closed off when adopting new technology,
    but many others are opened, so that the net gain is a plus of freedom, choices,
    and possibilities…It is possible that the technium has brainwashed us all, except
    for a few clear-eyed anarcho-primitivists who like to blow up stuff. I would be
    inclined to believe in the anarchy if the Unabomber’s alternative to civilization
    was more clear. After we destroy civilization, then what?</p>'
- - https://www.nybooks.com/articles/2012/09/27/philosopher-defends-religion/?pagination=false
  - A Philosopher Defends Religion [review of Plantinga, <em>Where the Conflict Really
    Lies</em>]
  - Thomas Nagel
  - 2012-09-27
  - ''
  - ! '<p>The gulf in outlook between atheists and adherents of the monotheistic religions
    is profound. We are fortunate to live under a constitutional system and a code
    of manners that by and large keep it from disturbing the social peace; usually
    the parties ignore each other. But sometimes the conflict surfaces and heats up
    into a public debate. The present is such a time.</p><p>… In his absorbing new
    book, <em>Where the Conflict Really Lies</em>, Alvin Plantinga, a distinguished
    analytic philosopher known for his contributions to metaphysics and theory of
    knowledge as well as to the philosophy of religion, turns this alleged opposition
    on its head. His overall claim is that “there is superficial conflict but deep
    concord between science and theistic religion, but superficial concord and deep
    conflict between science and naturalism.” By naturalism he means the view that
    the world describable by the natural sciences is all that exists, and that there
    is no such person as God, or anything like God. Plantinga’s religion is the real
    thing, not just an intellectual deism that gives God nothing to do in the world.
    He himself is an evangelical Protestant, but he conducts his argument with respect
    to a version of Christianity that is the “rough intersection of the great Christian
    creeds”—ranging from the Apostle’s Creed to the Anglican Thirty-Nine Articles—according
    to which God is a person who not only created and maintains the universe and its
    laws, but also intervenes specially in the world, with the miracles related in
    the Bible and in other ways. It is of great interest to be presented with a lucid
    and sophisticated account of how someone who holds these beliefs understands them
    to harmonize with and indeed to provide crucial support for the methods and results
    of the natural sciences…Faith, according to Plantinga, is another basic way of
    forming beliefs, distinct from but not in competition with reason, perception,
    memory, and the others. However, it is</p><blockquote><p>a wholly different kettle
    of fish: according to the Christian tradition (including both Thomas Aquinas and
    John Calvin), faith is a special gift from God, not part of our ordinary epistemic
    equipment. Faith is a source of belief, a source that goes beyond the faculties
    included in reason.</p></blockquote><p>God endows human beings with a <em>sensus
    divinitatis</em> that ordinarily leads them to believe in him. (In atheists the
    <em>sensus divinitatis</em> is either blocked or not functioning properly.)<sup>2</sup>
    In addition, God acts in the world more selectively by “enabling Christians to
    see the truth of the central teachings of the Gospel.”</p><p>If all this is true,
    then by Plantinga’s standard of reliability and proper function, faith is a kind
    of cause that provides a warrant for theistic belief, even though it is a gift,
    and not a universal human faculty. (Plantinga recognizes that rational arguments
    have also been offered for the existence of God, but he thinks it is not necessary
    to rely on these, any more than it is necessary to rely on rational proofs of
    the existence of the external world to know just by looking that there is beer
    in the refrigerator.) It is illuminating to have the starkness of the opposition
    between Plantinga’s theism and the secular outlook so clearly explained. My instinctively
    atheistic perspective implies that if I ever found myself flooded with the conviction
    that what the Nicene Creed says is true, the most likely explanation would be
    that I was losing my mind, not that I was being granted the gift of faith. From
    Plantinga’s point of view, by contrast, I suffer from a kind of spiritual blindness
    from which I am unwilling to be cured. This is a huge epistemological gulf, and
    it cannot be overcome by the cooperative employment of the cognitive faculties
    that we share, as is the hope with scientific disagreements….The interest of this
    book, especially for secular readers, is its presentation from the inside of the
    point of view of a philosophically subtle and scientifically informed theist—an
    outlook with which many of them will not be familiar. Plantinga writes clearly
    and accessibly, and sometimes acidly—in response to aggressive critics of religion
    like Dawkins and Daniel Dennett. His comprehensive stand is a valuable contribution
    to this debate.</p>'
- - http://www.larspenke.eu/pdfs/Penke_&_Jokela_in_press_-_Evolutionary_Genetics_of_Personality_Revisited.pdf
  - The Evolutionary Genetics of Personality Revisited
  - Lars Penke, Markus Jokela
  - 2016-02
  - 10.1016/j.copsyc.2015.08.021
  - <ul><li>Evolutionary forces that maintain genetic variance in traits can be inferred
    from their genetic architecture and fitness correlates.</li><li>A substantial
    amount of new data on the genomics and reproductive success associated with personality
    traits and intelligence has recently become available.</li><li>Intelligence differences
    seem to have been selected for robustness against mutations.</li><li>Human tendencies
    to select, create and adapt to environments might support the maintenance of personality
    traits through balancing selection.</li></ul><p>Like all human individual differences,
    personality traits and intelligence are substantially heritable. From an evolutionary
    perspective, this poses the question what evolutionary forces maintain their genetic
    variation. Information about the genetic architecture and associations with evolutionary
    fitness permit inferences about these evolutionary forces. As our understanding
    of the genomics of personality and its associations with reproductive success
    have grown considerably in recent years, it is time to revisit this question.
    While mutations clearly affect the very low end of the intelligence continuum,
    individual differences in the normal intelligence range seem to be surprisingly
    robust against mutations, suggesting that they might have been canalized to withstand
    such perturbations. Most personality traits, by contrast, seem to be neither neutral
    to selection nor under consistent directional or stabilizing selection. Instead
    evidence is in line with balancing selection acting on personality traits, probably
    supported by human tendencies to seek out, construct and adapt to fitting environments.</p>
- - http://www.joelonsoftware.com/articles/StrategyLetterV.html
  - ! 'Joel on Software: Strategy Letter V'
  - Joel Spolsky
  - 2002-06-11
  - ''
  - ! '<p>Every product in the marketplace has <em>substitutes</em> and <em>complements</em>.
    A substitute is another product you might buy if the first product is too expensive.
    Chicken is a substitute for beef. If you’re a chicken farmer and the price of
    beef goes up, the people will want more chicken, and you will sell more. A complement
    is a product that you usually buy together with another product. Gas and cars
    are complements. Computer hardware is a classic complement of computer operating
    systems. And babysitters are a complement of dinner at fine restaurants. In a
    small town, when the local five star restaurant has a two-for-one Valentine’s
    day special, the local babysitters double their rates. (Actually, the nine-year-olds
    get roped into early service.) All else being equal, demand for a product increases
    when the prices of its complements decrease.</p><p>Let me repeat that because
    you might have dozed off, and it’s important. Demand for a product increases when
    the prices of its complements decrease. For example, if flights to Miami become
    cheaper, demand for hotel rooms in Miami goes up—because more people are flying
    to Miami and need a room. When computers become cheaper, more people buy them,
    and they all need operating systems, so demand for operating systems goes up,
    which means the price of operating systems can go up.</p><p>…Once again: demand
    for a product increases when the price of its complements decreases. In general,
    a company’s strategic interest is going to be to get the price of their complements
    as low as possible. The lowest theoretically sustainable price would be the “commodity
    price”—the price that arises when you have a bunch of competitors offering indistinguishable
    goods. So:</p><p><strong><em>Smart companies try to commoditize their products’
    complements.</em></strong></p><p>If you can do this, demand for your product will
    increase and you will be able to charge more and make more.</p>'
- - http://www.apa.org/pubs/journals/releases/dev-49-2-270.pdf
  - Is Working Memory Training Effective? A Meta-Analytic Review
  - Monica Melby-Lervåg, Charles Hulme
  - 2013-02
  - 10.1037/a002822
  - ! 'It has been suggested that working memory training programs are effective both
    as treatments for attention-deficit/hyperactivity disorder (<span class="smallcaps-auto">ADHD</span>) and other cognitive
    disorders in children and as a tool to improve cognitive ability and scholastic
    attainment in typically developing children and adults. However, effects across
    studies appear to be variable, and a systematic meta-analytic review was undertaken.
    To be included in the review, studies had to be randomized controlled trials or
    quasi-experiments without randomization, have a treatment, and have either a treated
    group or an untreated control group. 23 studies with 30 group comparisons met
    the criteria for inclusion. The studies included involved clinical samples and
    samples of typically developing children and adults. Meta-analyses indicated that
    the programs produced reliable short-term improvements in working memory skills.
    For verbal working memory, these near-transfer effects were not sustained at follow-up,
    whereas for visuospatial working memory, limited evidence suggested that such
    effects might be maintained. More importantly, there was no convincing evidence
    of the generalization of working memory training to other skills (nonverbal and
    verbal ability, inhibitory processes in attention, word decoding, and arithmetic).
    The authors conclude that memory training programs appear to produce short-term,
    specific training effects that do not generalize. Possible limitations of the
    review (including age differences in the samples and the variety of different
    clinical conditions included) are noted. However, current findings cast doubt
    on both the clinical relevance of working memory training programs and their utility
    as methods of enhancing cognitive functioning in typically developing children
    and healthy adults. [Keywords: working memory training, <span class="smallcaps-auto">ADHD</span>, attention, learning
    disabilities.]'
- - http://users.econ.umn.edu/~rusti001/Research/Genetics/Polygenic_Analysis.pdf
  - Polygenic Score Analysis Of Educational Achievement And Intergenerational Mobility
  - Aldo Rustichini, William G. Iacono, James Lee, Matt McGue
  - 2019-09-17
  - ''
  - <p>A Genome-wide association study (<em><span class="smallcaps-auto">GWAS</span></em>) estimates size and significance
    of the effect of common genetic variants on a phenotype of interest. A Polygenic
    Score (<em><span class="smallcaps-auto">PGS</span></em>) is a score, computed for each individual, summarizing the
    expected value of a phenotype on the basis of the individual’s genotype. The <em><span class="smallcaps-auto">PGS</span></em>
    is computed as a weighted sum of the values of the individual’s genetic variants,
    using as weights the <em><span class="smallcaps-auto">GWAS</span></em> estimated coefficients from a training sample.
    Thus, <em><span class="smallcaps-auto">PGS</span></em> carries information on the genotype, and only on the genotype,
    of an individual. In our case phenotypes of interest are measures of educational
    achievement, such as having a college degree, or the education years, in a sample
    of approximately 2700 adult twins and their parents.</p><p>We set up the analysis
    in a standard model of optimal parental investment and intergenerational mobility,
    extended to include a fully specified genetic analysis of skill transmission,
    and show that the model’s predictions on mobility differ substantially from those
    of the standard model. For instance, the coefficient of intergenerational income
    elasticity maybe larger, and may differ across countries because the distribution
    of the genotype is different, completely independently of any difference in institution,
    technology or preferences.</p><p>We then study how much of the educational achievement
    is explained by the <em><span class="smallcaps-auto">PGS</span></em> for education, thus estimating how much of the
    variance of education can be explained by genetic factors alone. We find a substantial
    effect of <em><span class="smallcaps-auto">PGS</span></em> on performance in school, years of education and college.</p><p>Finally
    we study the channels between <em><span class="smallcaps-auto">PGS</span></em> and the educational achievement, distinguishing
    how much is due to cognitive skills and to personality traits. We show that the
    effect of <em><span class="smallcaps-auto">PGS</span></em> is substantially stronger on Intelligence than on other
    traits, like Constraint, which seem natural explanatory factors of educational
    success. For educational achievement, both cognitive and non cognitive skills
    are important, although the larger fraction of success is channeled by Intelligence.</p>
- - http://www.paulgraham.com/nerds.html
  - Why Nerds Are Unpopular
  - Paul Graham
  - 2003-02
  - ''
  - ! '<p>I know a lot of people who were nerds in school, and they all tell the same
    story: there is a strong correlation between being smart and being a nerd, and
    an even stronger inverse correlation between being a nerd and being popular. Being
    smart seems to <em>make</em> you unpopular. Why? To someone in school now, that
    may seem an odd question to ask. The mere fact is so overwhelming that it may
    seem strange to imagine that it could be any other way. But it could. Being smart
    doesn’t make you an outcast in elementary school. Nor does it harm you in the
    real world. Nor, as far as I can tell, is the problem so bad in most other countries.
    But in a typical American secondary school, being smart is likely to make your
    life difficult. Why?</p><p>The answer, I think, is that they don’t really want
    to be popular. If someone had told me that at the time, I would have laughed at
    him. Being unpopular in school makes kids miserable, some of them so miserable
    that they commit suicide. Telling me that I didn’t want to be popular would have
    seemed like telling someone dying of thirst in a desert that he didn’t want a
    glass of water. Of course I wanted to be popular. But in fact I didn’t, not enough.
    There was something else I wanted more: to be smart. Not simply to do well in
    school, though that counted for something, but to design beautiful rockets, or
    to write well, or to understand how to program computers. In general, to make
    great things. At the time I never tried to separate my wants and weigh them against
    one another. If I had, I would have seen that being smart was more important.
    If someone had offered me the chance to be the most popular kid in school, but
    only at the price of being of average intelligence (humor me here), I wouldn’t
    have taken it.</p><p>Much as they suffer from their unpopularity, I don’t think
    many nerds would. To them the thought of average intelligence is unbearable. But
    most kids would take that deal. For half of them, it would be a step up. Even
    for someone in the eightieth percentile (assuming, as everyone seemed to then,
    that intelligence is a scalar), who wouldn’t drop thirty points in exchange for
    being loved and admired by everyone? And that, I think, is the root of the problem.
    Nerds serve two masters. They want to be popular, certainly, but they want even
    more to be smart. And popularity is not something you can do in your spare time,
    not in the fiercely competitive environment of an American secondary school.</p><p>…This
    is the sort of society that gets created in American secondary schools. And it
    happens because these schools have no real purpose beyond keeping the kids all
    in one place for a certain number of hours each day. What I didn’t realize at
    the time, and in fact didn’t realize till very recently, is that the twin horrors
    of school life, the cruelty and the boredom, both have the same cause.</p>'
- - http://nonsymbolic.org/PNSE-Article.pdf
  - Clusters of Individual Experiences form a Continuum of Persistent Non-Symbolic
    Experiences [PNSE] in Adults
  - Jeffery A. Martin
  - '2013'
  - ''
  - ! '<p>Persistent forms of nondual awareness, enlightenment, mystical experience,
    and so forth (Persistent Non-Symbolic Experience) have been reported since antiquity.
    Though sporadic research has been performed on them, the research reported here
    represents the initial report from the first larger scale cognitive psychology
    study of this population.</p><p><em>Method</em>: Assessment of the subjective
    experience of fifty adult participants reporting persistent non-symbolic experience
    was undertaken using 6–12 hour semi-structured interviews and evaluated using
    thematic analysis. Additional assessment was performed using psychometric measures,
    physiological measurement, and experimentation.</p><p><em>Results</em>: Five core,
    consistent categories of change were uncovered: sense-of-self, cognition, emotion,
    perception, and memory. Participants’ reports formed clusters in which the types
    of change in each of these categories were consistent. Multiple clusters were
    uncovered that formed a range of possible experiences. The variety of these experiences
    and their underlying categories may inform the debate between constructivist,
    common core, and participatory theorists.</p><p>…Over the course of a week, his
    father died followed very rapidly by his sister. He was also going through a significant
    issue with one of his children. Over dinner I asked him about his internal state,
    which he reported as deeply peaceful and positive despite everything that was
    happening. Having known that the participant was bringing his longtime girlfriend,
    I’d taken an associate researcher with me to the meeting to independently collect
    the observations from her. My fellow researcher isolated the participant’s girlfriend
    at the bar and interviewed her about any signs of stress that the participant
    might be exhibiting. I casually asked the same questions to the participant as
    we continued our dinner conversation. Their answers couldn’t have been more different.
    While the participant reported no stress, his partner had been observing many
    telltale signs: he wasn’t sleeping well, his appetite was off, his mood was noticeably
    different, his muscles were much tenser than normal, his sex drive was reduced,
    his health was suffering, and so forth…It was not uncommon for participants to
    state that they had gained increased bodily awareness upon their transition into
    <span class="smallcaps-auto">PNSE</span>. I arranged and observed private yoga sessions with a series of participants
    as part of a larger inquiry into their bodily awareness. During these sessions
    it became clear that participants believed they were far more aware of their body
    than they actually were…Many participants discussed the thought, just after their
    transition to <span class="smallcaps-auto">PNSE</span>, that they would have to go to work and explain the difference
    in themselves to co-workers. They went on to describe a puzzled drive home after
    a full day of work when no one seemed to notice anything different about them.
    Quite a few chose to never discuss the change that had occurred in them with their
    families and friends and stated that no one seemed to notice much of a difference.</p><p>There
    was also a progressively decreasing sense of agency. In the final stage, Location
    4, he reports: “These participants reported having no sense of agency or any ability
    to make a decision. It felt as if life was simply unfolding and they were watching
    the process happen. Severe memory deficits were common in these participants,
    including the inability to recall scheduled events that were not regular and ongoing.”
    And yet, almost all of the subjects reported it as a positive experience. The
    subjects, at whatever point they were in the scale, were often completely certain
    about the nature of the experience: “<span class="smallcaps-auto">PNSE</span> was often accompanied by a tremendous
    sense of certainty that participants were experiencing a ‘deeper’ or ‘more true’
    reality. As time passed, this often increased in strength.” They also tended to
    be dogmatic about their <span class="smallcaps-auto">PNSE</span> being the real thing (whichever location they were
    at) and descriptions of other people’s different <span class="smallcaps-auto">PNSE</span>s as not the real thing.
    Another way to say “completely certain” is “unable to doubt”.</p>'
- - /docs/traffic/2015-hohnhold.pdf
  - ! 'Focusing on the Long-term: It’s Good for Users and Business'
  - Henning Hohnhold, Deirdre O’Brien, Diane Tang
  - '2015'
  - 10.1145/2783258.2788583
  - ! '<p>Over the past 10+ years, online companies large and small have adopted widespread
    A/B testing as a robust data-based method for evaluating potential product improvements.
    In online experimentation, it is straightforward to measure the short-term effect,
    i.e., the impact observed during the experiment. However, the short-term effect
    is not always predictive of the long-term effect, i.e., the final impact once
    the product has fully launched and users have changed their behavior in response.
    Thus, the challenge is how to determine the long-term user impact while still
    being able to make decisions in a timely manner.</p><p>We tackle that challenge
    in this paper by first developing experiment methodology for quantifying long-term
    user learning. We then apply this methodology to ads shown on Google search, more
    specifically, to determine and quantify the drivers of ads blindness and sightedness,
    the phenomenon of users changing their inherent propensity to click on or interact
    with ads.</p><p>We use these results to create a model that uses metrics measurable
    in the short-term to predict the long-term. We learn that user satisfaction is
    paramount: ads blindness and sightedness are driven by the quality of previously
    viewed or clicked ads, as measured by both ad relevance and landing page quality.
    Focusing on user satisfaction both ensures happier users but also makes business
    sense, as our results illustrate. We describe two major applications of our findings:
    a conceptual change to our search ads auction that further increased the importance
    of ads quality, and a 50% reduction of the ad load on Google’s mobile search interface.</p><p>The
    results presented in this paper are generalizable in two major ways. First, the
    methodology may be used to quantify user learning effects and to evaluate online
    experiments in contexts other than ads. Second, the ads blindness/sightedness
    results indicate that a focus on user satisfaction could help to reduce the ad
    load on the internet at large with long-term neutral, or even positive, business
    impact. [Keywords: Controlled experiments; A/B testing; predictive modeling; overall
    evaluation criterion]</p>'
- - http://www.ushakrisna.com/cogability_proof.pdf
  - Cognitive Abilities and Household Financial Decision Making
  - Sumit Agarwal, Bhashkar Mazumder
  - '2013'
  - 10.1257/app.5.1.193
  - We analyze the effects of cognitive abilities [<span class="smallcaps-auto">AFQT</span>] on two examples of consumer
    financial decisions where suboptimal behavior is well defined. The first example
    features the optimal use of credit cards for convenience transactions after a
    balance transfer and the second involves a financial mistake on a home equity
    loan application. We find that consumers with higher overall test scores, and
    specifically those with higher math scores, are substantially less likely to make
    a financial mistake. These mistakes are generally not associated with nonmath
    test scores.
- - https://d4mucfpksywv.cloudfront.net/emergent-tool-use/paper/Multi_Agent_Emergence_2019.pdf#openai
  - Emergent Tool Use From Multi-Agent Autocurricula
  - Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob McGrew,
    Igor Mordatch
  - 2019-09-17
  - ''
  - Through multi-agent competition, the simple objective of <em>hide-and-seek</em>,
    and standard reinforcement learning algorithms at scale, we find that agents create
    a self-supervised autocurriculum inducing multiple distinct rounds of emergent
    strategy, many of which require sophisticated tool use and coordination. We find
    clear evidence of six emergent phases in agent strategy in our environment, each
    of which creates a new pressure for the opposing team to adapt; for instance,
    agents learn to build multi-object shelters using movable boxes which in turn
    leads to agents discovering that they can overcome obstacles using ramps. We further
    provide evidence that multi-agent competition may scale better with increasing
    environment complexity and leads to behavior that centers around far more human-relevant
    skills than other self-supervised reinforcement learning methods such as intrinsic
    motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively
    evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic
    motivation and random initialization baselines in a suite of domain-specific intelligence
    tests.
- - https://statmodeling.stat.columbia.edu/2019/09/17/statistical-inference-enables-bad-science-statistical-thinking-enables-good-science/
  - On 'Statistical Inference Enables Bad Science; Statistical Thinking Enables Good
    Science', Tong 2019
  - Andrew Gelman
  - 2019-09-17
  - ''
  - ! '<p>First, the title, which makes an excellent point. It can be valuable to
    <em>think</em> about measurement, comparison, and variation, even if commonly-used
    statistical methods can mislead.</p> <p>This reminds me of the idea in decision
    analysis that the most important thing is not the solution of the decision tree
    but rather what you decide to put in the tree in the first place, or even, stepping
    back, what are your goals. The idea is that the threat of decision analysis is
    more powerful than its execution (as Chrissy Hesse might say): the decision-analytic
    thinking pushes you to think about costs and uncertainties and alternatives and
    opportunity costs, and that’s all valuable even if you never get around to performing
    the formal analysis. Similarly, I take Tong’s point that statistical thinking
    motivates you to consider design, data quality, bias, variance, conditioning,
    causal inference, and other concerns that will be relevant, whether or not they
    all go into a formal analysis.</p> <p>That said, I have one concern, which is
    that “the threat is more powerful than the execution” only works if the threat
    is plausible. If you rule out the possibility of the execution, then the threat
    is empty. Similarly, while I understand the appeal of “Statistical Inference Enables
    Bad Science; Statistical Thinking Enables Good Science,” I think this might be
    good static advice, applicable right now, but not good <em>dynamic</em> advice:
    if we do away with statistical inference entirely (except in the very rare cases
    when no external assumptions are required to perform statistical modeling), then
    there may be less of a sense of the need for statistical thinking.</p> <p>Overall,
    though, I agree with Tong’s message, and I think everybody should read his article.</p>'
- - http://www.slate.com/articles/health_and_science/medical_examiner/2017/09/genetic_testing_data_reveals_the_irrationality_of_human_behavior.html
  - ! 'We Don’t Want to Know What Will Kill Us: Years of data on genetic testing reveal
    that when given the option, most people want less information, not more'
  - Laura Spinney
  - 2017-09-27
  - ''
  - ! '<p>In the three decades since the first predictive genetic tests became available,
    a great deal of data has accumulated to show how people respond to knowing previously
    unknowable things. The rise of genetic testing has presented scientists with a
    30-year experiment that has yielded some surprising insights into human behavior.
    The data suggest that the vast majority react in ways that at first seem counterintuitive,
    or at least flout what experts predicted. But as genetic testing becomes more
    widespread, the irrational behavior of a frightened few might start to look like
    the rational behavior of an enlightened majority. Doctors’ repeatedly failed attempts
    to anticipate people’s responses to genetic testing is not for want of preparation.
    Starting in the 1980s, they conducted surveys in which they asked how people might
    approach the test, were one available. They noted the answers and planned accordingly.
    The trouble was, when the test became a reality, their respondents didn’t do what
    they had said they would.</p><p>… In those preparatory surveys, roughly 70% of
    those at risk of Huntington’s said they would take a test if it existed. In fact,
    only around 15% do—a proportion that has proved stable across countries and decades.
    A similar pattern emerged when tests became available for other incurable brain
    diseases…Prenatal genetic testing is widely available, but the uptake by expecting
    couples in which one partner is a known carrier of an incurable disease is even
    lower than that of testing among at-risk adults. Most opt to have a child whose
    risk of developing that disease is the same as theirs was at birth. Why do people
    act in this seemingly irresponsible way with respect to their offspring?</p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5110058/" title="‘Prenatal testing in Huntington disease: after the test, choices recommence’,
    Bouchghoul et al 2016">A unique longitudinal study published in 2016 by Hanane Bouchghoul</a>
    and colleagues at the Pitié-Salpêtrière Hospital in Paris
    unpacks that decision-making process. They interviewed 54 women—either Huntington’s
    carriers or wives of carriers—and found that if a couple received a favorable
    result in a first prenatal test, the majority had the child and stopped there.
    Most of those who got an unfavorable result terminated the pregnancy and tried
    again. If a second prenatal test produced a “good” result, they had the child
    and stopped. But if it produced a “bad” result and another termination, most changed
    strategy. Some opted for preimplantation genetic diagnosis, removing the need
    for termination, since only mutation-free embryos are implanted. Some abandoned
    the idea of having a child altogether. But nearly half, 45%, conceived naturally
    again, and this time they did not seek prenatal testing. Summarizing the findings,
    the geneticist on the team, Alexandra Dürr, says, “The desire to have a child
    overrides all else.”</p><p>… In a study that has yet to be published, Tibben has
    corroborated the French group’s conclusion. He followed 13 couples who, following
    counseling but prior to taking a prenatal test, agreed they would terminate in
    the case of an unfavorable result. None of them did so when they got that result.
    “That means there are 13 children alive in the Netherlands today, whom we can
    be 100% sure are [Huntington’s] carriers,” he says.</p>'
- - http://www.overcomingbias.com/2012/01/dear-young-eccentric.html
  - Dear Young Eccentric
  - Robin Hanson
  - 2012-01-05
  - ''
  - Weird folks are often tempted to give up on grand ambitions, thinking there is
    little chance the world will let them succeed. Turns out, however, it isn’t as
    bad as all that. Especially if your main weirdness is in the realm of ideas…I’ve
    known some very successful people with quite weird ideas. But these folks mostly
    keep regular schedules of sleep and bathing. Their dress and hairstyles are modest,
    they show up on time for meetings, and they finish assignments by deadline. They
    are willing to pay dues and work on what others think are important for a while,
    and they have many odd ideas they’d pursue if given a chance, instead of just
    one overwhelming obsession. They are willing to keep changing fields, careers,
    and jobs until they find one that works for them…if you are not overtly rebellious,
    you can get away with a lot of abstract idea rebellion—few folks will even notice
    such deviations, and fewer still will care. So, ask yourself, do you want to <em>look</em>
    like a rebel, or do you want to <em>be</em> a rebel?
- - https://escholarship.org/content/qt68h9h675/qt68h9h675.pdf#page=2
  - Dumb or smart asses? Donkey's (<em>Equus asinus</em>) cognitive capabilities share
    the heritability and variation patterns of human's (<em>Homo sapiens</em>) cognitive
    capabilities
  - Francisco Javier Navas González, Jordi Jordana Vidal, José Manuel León Jurado,
    Amy Katherine McLean, Juan Vicente Delgado Bermejo
  - 2019-09
  - 10.1016/j.jveb.2019.06.007
  - ! 'Scientific evidence for intelligence in donkeys could expose their historical
    unmerited cognitive derogatory status. Psychometric testing enables quantifying
    animal cognitive capabilities and their genetic background. Owing to the impossibility
    to use the language-dependent scales that are widely used to measure intelligence
    in humans, we used a nonverbal operant-conditioning problem-solving test to compute
    a human-analogous IQ, scoring the information of thirteen cognitive processes
    from 300 genetically tested donkeys. Principal components and Bayesian analyses
    were used to compute the variation in cognitive capabilities explained by the
    cognitive processes tested and their genetic parameters, respectively. According
    to our results, IQ may explain over 62% of the cognitive variance, and 0.06 to
    0.38 heritabilities suggest that we could ascribe a significant proportion to
    interacting genes describing the same patterns previously reported for humans
    and other animal species. Our results address the existence of a human-analogous
    heritable component and mechanisms underneath intelligence and cognition in probably
    one of the most traditionally misunderstood species from a cognitive perspective.
    [Keywords: cognition, <em>g</em>, genetic parameters, asses, intelligence quotient]'
- - https://www.math.uchicago.edu/~fcale/CCC/DC.pdf
  - Methods for Studying Coincidences
  - Persi Diaconis, Frederick Mosteller
  - 1989-12
  - 10.1080/01621459.1989.10478847
  - ! 'This article illustrates basic statistical techniques for studying coincidences.
    These include data-gathering methods (informal anecdotes, case studies, observational
    studies, and experiments) and methods of analysis (exploratory and confirmatory
    data analysis, special analytic techniques, and probabilistic modeling, both general
    and special purpose). We develop a version of the birthday problem general enough
    to include dependence, inhomogeneity, and almost and multiple matches. We review
    Fisher''s techniques for giving partial credit for close matches. We develop a
    model for studying coincidences involving newly learned words. Once we set aside
    coincidences having apparent causes, four principles account for large numbers
    of remaining coincidences: hidden cause; psychology, including memory and perception;
    multiplicity of endpoints, including the counting of “close” or nearly alike events
    as if they were identical; and the law of truly large numbers, which says that
    when enormous numbers of events and people and their interactions cumulate over
    time, almost any outrageous event is bound to occur. These sources account for
    much of the force of synchronicity. [Keywords: Birthday problems, Extrasensory
    perception, Jung, Kammerer, Multiple endpoints, Rare events, Synchronicity, Baader-Meinhof
    Effect, spaced repetition]'
- - http://www.ic.unicamp.br/~celio/peer2peer/math/mitzenmacher-power-of-two.pdf
  - ! 'The Power of Two Random Choices: A Survey of Techniques and Results'
  - Michael Mitzenmacher, Andrea W. Richa, Ramesh Sitaraman
  - '2001'
  - ''
  - ! '<p>…we begin with a simple problem that demonstrates a powerful fundamental
    idea. Suppose that <em>n</em> balls are thrown into <em>n</em> bins, with each
    ball choosing a bin independently and uniformly at random. Then the <em>maximum
    load</em>, or the largest number of balls in any bins, is approximately log <em>n</em>
    / log log <em>n</em> with high probability. Now suppose instead that the balls
    are placed sequentially, and each ball is placed in the least loaded of <em>d</em>≥2
    bins chosen independently and uniformly at random. <a href="http://users.eecs.northwestern.edu/~nickle/randAlg/AzarBKU99.pdf"
    title="Balanced Allocations">Azar et al 1999</a> showed that in this case, the
    maximum load is log log <em>n</em> / log <em>d</em> + Θ(1) with high probability.</p><p>The
    important implication of this result is that even a small amount of choice can
    lead to drastically different results in load balancing. Indeed, having just two
    random choices (ie <em>d</em>=2) yields a large reduction in the maximum load
    by just a constant factor. Over the past several years, there has been a great
    deal of research investigating this phenomenon. The picture that has emerged from
    this research is that the power of two choices is not simply an artifact of the
    simple balls-and-bins model, but a general and robust phenomenon applicable to
    a wide variety of situations. Indeed, this <em>two-choice paradigm</em> continues
    to be applied and refined, and new results appear frequently. <em>Applications
    of the two-choice paradigm</em>:… Hashing, Shared memory emulations, load balancing,
    low-congestion circuit routing.</p><p>[See also <a href="https://www.eecs.harvard.edu/~michaelm/postscripts/mythesis.pdf">“The
    Power of Two Choices in Randomized Load Balancing”</a>, Mitzenmacher 1996; <a
    href="https://www.nginx.com/blog/nginx-power-of-two-choices-load-balancing-algorithm/"
    title="&#39;NGINX and the &#39;Power of Two Choices&#39; Load-Balancing Algorithm&#39;,
    Garrett 2018">Nginx</a>/<a href="https://www.haproxy.com/blog/power-of-two-load-balancing/"
    title="&#39;Test Driving`&#39;Power of Two Random Choices` Load Balancing&#39;,
    Tarreau 2019"><span class="smallcaps-auto">HAP</span>roxy</a>, <a href="https://brooker.co.za/blog/2012/01/17/two-random.html"
    title="The power of two random choices: Using less information to make better
    decisions">Marc Brooker</a>.]</p>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.8275&rep=rep1&type=pdf
  - ! 'Trustworthy online controlled experiments: Five puzzling outcomes explained'
  - Ron Kohavi, Alex Deng, Brian Frasca, Roger Longbotham, Toby Walker, Ya Xu
  - 2012-08-12
  - 10.1145/2339530.2339653
  - ! 'Online controlled experiments are often utilized to make data-driven decisions
    at Amazon, Microsoft, eBay, Facebook, Google, Yahoo, Zynga, and at many other
    companies. While the theory of a controlled experiment is simple, and dates back
    to Sir Ronald A. Fisher''s experiments at the Rothamsted Agricultural Experimental
    Station in England in the 1920s, the deployment and mining of online controlled
    experiments at scale—thousands of experiments now—has taught us many lessons.
    These exemplify the proverb that the difference between theory and practice is
    greater in practice than in theory. We present our learnings as they happened:
    puzzling outcomes of controlled experiments that we analyzed deeply to understand
    and explain. Each of these took multiple-person weeks to months to properly analyze
    and get to the often surprising root cause. The root causes behind these puzzling
    results are not isolated incidents; these issues generalized to multiple experiments.
    The heightened awareness should help readers increase the trustworthiness of the
    results coming out of controlled experiments. At Microsoft''s Bing, it is not
    uncommon to see experiments that impact annual revenue by millions of dollars,
    thus getting trustworthy results is critical and investing in understanding anomalies
    has tremendous payoff: reversing a single incorrect decision based on the results
    of an experiment can fund a whole team of analysts. The topics we cover include:
    the <span class="smallcaps-auto">OEC</span> (Overall Evaluation Criterion), click tracking, effect trends, experiment
    length and power, and carryover effects.'
- - https://www.nytimes.com/1990/12/29/arts/japan-sings-along-with-beethoven.html
  - Japan Sings Along With Beethoven
  - Steven R. Weisman
  - 1990-12-29
  - ''
  - <p>December in Japan is a festive season, filled with gift-giving, prayers for
    the new year, bamboo and pine branches in front of houses, office parties and
    Beethoven’s Ninth.</p><p>Beethoven’s Ninth? No one is sure how it happened, but
    indeed, Ludwig van Beethoven’s Choral Symphony is as much a staple of the season
    as dry weather and maddeningly short days. The symphony is being performed at
    least 170 times this month by professional and amateur groups throughout the country.
    Some orchestras play it several times in a row. The <span class="smallcaps-auto">NHK</span> Symphony Orchestra has
    performed what the Japanese call the Daiku, or Big Nine, five times this month,
    the Tokyo Symphony Orchestra 13 times and the Japan Philharmonic Symphony Orchestra
    11 times.</p><p>“For Japanese, listening to Beethoven’s Ninth at the end of the
    year is a semi-religious experience,” said Naoyuki Miura, the artistic director
    of Music from Japan, which sponsors concerts abroad. “People feel they have not
    completed the year spiritually until they hear it.” Like the Christmastime sing-alongs
    of Handel’s <em>Messiah</em> in the West, Beethoven’s Ninth also draws audiences
    to sing-along performances at which the audiences lustily join in the choruses
    of Schiller’s “Ode to Joy,” singing German words they barely understand.</p>
- - /docs/iq/2018-mansson.pdf
  - Agreement Between Bayley-III Measurements and WISC-IV Measurements in Typically
    Developing Children
  - Johanna Månsson, Karin Stjernqvist, Fredrik Serenius, Ulrika Ådén, Karin Källén
  - 2018-06-28
  - 10.1177/0734282918781431
  - The study aim was to explore the relationship between a developmental assessment
    at preschool age and an intelligence quotient (IQ) assessment at school age. One
    hundred sixty-two children were assessed at 2.5 years with the Bayley Scales of
    Infant and Toddler Development—Third Edition (Bayley-<span class="smallcaps-auto">III</span>) and then at 6.5 years
    with the Wechsler Intelligence Scale for Children—Fourth Edition (<span class="smallcaps-auto">WISC</span>-IV). The
    Bayley-<span class="smallcaps-auto">III</span> Cognitive Index score was the Bayley entity that showed the highest
    correlation with <span class="smallcaps-auto">WISC</span>-IV Full-Scale IQ (<span class="smallcaps-auto">FSIQ</span>; r = .41). There was a significant
    difference between the individual <span class="smallcaps-auto">WISC</span>-IV <span class="smallcaps-auto">FSIQ</span> and the Bayley-<span class="smallcaps-auto">III</span> Cognitive Index
    scores. Analyses showed an average difference of −4 units and 95% limits of agreement
    of −18.5 to 26.4 units. A multivariate model identified the Bayley-<span class="smallcaps-auto">III</span> Cognitive
    Index score as the most important predictor for <span class="smallcaps-auto">FSIQ</span> and General Ability Index
    (<span class="smallcaps-auto">GAI</span>), respectively, in comparison with demographic factors. The model explained
    24% of the total <span class="smallcaps-auto">FSIQ</span> variation and 26% of the <span class="smallcaps-auto">GAI</span> variation. It was concluded
    that the Bayley-<span class="smallcaps-auto">III</span> measurement was an insufficient predictor of later IQ.
- - https://rifters.com/real/articles/Sinclair%20ZX80%20spiders.pdf
  - Smarter than the average bug [<em>Portia</em>]
  - John McCrone (New Scientist)
  - 2006-05-27
  - ''
  - ! '<p>So perched on its branch, Portia begins to plot. For a good quarter of an
    hour it scans the undergrowth, its tiny brain working out possible pathways across
    boulders and branches. The retinas of its two principal eyes have only a few thousand
    photoreceptors, compared to the 200 million or so in a human eye. But Portia can
    swivel these tiny eyes across the scene in a systematic fashion, patiently building
    up an image. Eventually Portia makes up its mind and disappears from sight. A
    couple of hours later, the silent assassin is back, dropping down onto Scytodes
    on a silk dragline attached to a rocky overhang, like something out of <em>Mission:
    Impossible</em>. Once again, Portia’s guile wins the day…While Portia’s deception
    skills are impressive, what is most remarkable is its ability to plot a path to
    its victim. For an animal operating on instinct, out of sight is usually out of
    mind. Yet Portia can take several hours to get into the right spot, even if that
    means losing sight of its prey for long periods.</p><p>…One of Portia’s principal
    skills is luring other spiders from the safety of their webs. Portia will pluck
    out rhythms at the edge of a web to mimic a trapped insect or a hostile intruder.
    If it has encountered the resident spider before, it sometimes knows what rhythm
    to use—a remarkable ability in itself. If it hasn’t, Portia will try out various
    patterns by trial and error. It can tickle the web lightly, strum it vigorously,
    bob up and down as if on a trampoline—whatever it takes to persuade its target
    to move into the right position for an attack. Sometimes the foe will be two to
    three times Portia’s size. The trick is then to arouse its curiosity without provoking
    a full-blooded rush.</p><p>…Crazy talk, obviously. There just isn’t room in Portia’s
    head for anything approaching an inner mental life. The human brain has some 100
    billion brain cells, and a mouse has around 70 million. Harland says no one has
    done a precise count on Portia but it is reckoned to have a midway between the
    housefly’s 250,000 and the honeybee’s one million.So what do the researchers conclude?
    Does Portia have some inkling of a mind? Or can every behaviour be explained away
    in terms of instinctive responses? Harland says many of Portia’s cognitive abilities
    may eventually be explained by the design of its eyes—specifically by their inbuilt
    limitations. All jumping spiders have excellent vision and Portia’s is 10 times
    better than the average, making it sharper than that of most mammals. Being so
    small, though, there is a trade-off: Portia can only focus on one view at a time.
    It has to build up a picture of the world by scanning a scene point by point,
    as if peering through a keyhole. Harland thinks that understanding the serial
    nature of the spider’s vision makes it easier to imagine how prey recognition
    and other processes could be controlled by hard-wired programs. When Portia is
    looking for an egg sac, for example, it wouldn’t need to deal with the scene as
    a visual whole. Instead it could check a template, ticking off critical features
    in a sequence of fixations. Perhaps the less the eye sees with each fixation the
    better.</p>'
- - https://keinanlab.cb.bscb.cornell.edu/content/crowdsourcing-big-data-research-human-history-and-health-genealogies-genomes-and-back-again
  - ! 'Crowdsourcing big data research on human history and health: from genealogies
    to genomes and back again'
  - Alon Keinan, Alexandre Lussier
  - 2018-04-12
  - ''
  - Genealogies are likely the first, centuries-old “big data”, with their construction
    as old as human civilization itself. Globalization, and the identity crisis that
    ensued, turned many to online services, building family trees and investigating
    connections to historical records and other family trees [1]. An explosion has
    been underway since the beginning of the century in the number and usage of websites
    offering such genealogical services. About 130 million users combine to have created
    almost four billion profiles for family members across the three most popular
    websites of genealogy enthusiasts, Ancestry.com, MyHeritage, and Geni. More recent
    years have witnessed a similar rapid increase of genetic-based services that address
    the same need to learn about familial relationships and ancestry. These vast amounts
    of crowdsourced—and often crowdfunded (as users often pay for these services)—data
    offers ample scientific research opportunities that would otherwise require expansive
    collection. In a paper published today in Science, Kaplanis et al. [2, 3] introduce
    a genealogical dataset based on processing 86 million public Geni profiles. Armed
    with this crowdsourced dataset, they address fundamental research questions.
- - https://openai.com/blog/better-language-models/
  - ! 'Better Language Models and Their Implications: We''ve trained a large-scale
    unsupervised language model [<span class="smallcaps-auto">GPT</span>-2] which generates coherent paragraphs of text,
    achieves state-of-the-art performance on many language modeling benchmarks, and
    performs rudimentary reading comprehension, machine translation, question answering,
    and summarization—all without task-specific training'
  - Alec Radford, Jeffrey Wu, Dario Amodei, Daniela Amodei, Jack Clark, Miles Brundage,
    Ilya Sutskever (OpenAI)
  - 2019-02-14
  - ''
  - ! '<p>Our model, called <span class="smallcaps-auto">GPT</span>-2 (a successor to <span class="smallcaps-auto">GPT</span>), was trained simply to predict
    the next word in 40GB of Internet text. Due to our concerns about malicious applications
    of the technology, we are not releasing the trained model. As an experiment in
    responsible disclosure, we are instead releasing a much <a href="https://github.com/openai/gpt-2">smaller
    model</a> for researchers to experiment with, as well as a <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">technical
    paper</a>.</p><p><span class="smallcaps-auto">GPT</span>-2 is a large <a href="https://arxiv.org/abs/1706.03762">Transformer</a>-based
    language model with 1.5 billion parameters, trained on a dataset of 8 million
    web pages. <span class="smallcaps-auto">GPT</span>-2 is trained with a simple objective: predict the next word, given
    all of the previous words within some text. The diversity of the dataset causes
    this simple goal to contain naturally occurring demonstrations of many tasks across
    diverse domains. <span class="smallcaps-auto">GPT</span>-2 is a direct scale-up of <span class="smallcaps-auto">GPT</span>, with more than 10X the parameters
    and trained on more than 10X the amount of data.</p><p><span class="smallcaps-auto">GPT</span>-2 displays a broad
    set of capabilities, including the ability to generate conditional synthetic text
    samples of unprecedented quality, where we prime the model with an input and have
    it generate a lengthy continuation. In addition, <span class="smallcaps-auto">GPT</span>-2 outperforms other language
    models trained on specific domains (like Wikipedia, news, or books) without needing
    to use these domain-specific training datasets. On language tasks like question
    answering, reading comprehension, summarization, and translation, <span class="smallcaps-auto">GPT</span>-2 begins
    to learn these tasks from the raw text, using no task-specific training data.
    While scores on these downstream tasks are far from state-of-the-art, they suggest
    that the tasks can benefit from unsupervised techniques, given sufficient (unlabeled)
    data and compute.</p>'
- - https://danwang.co/college-girardian-terror/
  - ! 'Violence and the Sacred: College as an incubator of Girardian terror'
  - Dan Wang
  - 2017-06-25
  - ''
  - ! '<p>…competition is fiercer the more that competitors resemble each other. When
    we’re not so different from people around us, it’s irresistible to become obsessed
    about beating others.</p><p>It’s hard to construct a more perfect incubator for
    mimetic contagion than the American college campus. Most 18-year-olds are not
    super differentiated from each other. By construction, whatever distinctions any
    does have are usually earned through brutal, zero-sum competitions. These tournament-type
    distinctions include: <span class="smallcaps-auto">SAT</span> scores at or near perfection; being a top player on
    a sports team; gaining master status from chess matches; playing first instrument
    in state orchestra; earning high rankings in Math Olympiad; and so on, culminating
    in gaining admission to a particular college. Once people enter college, they
    get socialized into group environments that usually continue to operate in zero-sum
    competitive dynamics. These include orchestras and sport teams; fraternities and
    sororities; and many types of clubs. The biggest source of mimetic pressures are
    the classes. Everyone starts out by taking the same intro classes; those seeking
    distinction throw themselves into the hardest classes, or seek tutelage from star
    professors, and try to earn the highest grades.</p><p>There’s very little external
    intermediation, instead all competitive dynamics are internally mediated…Once
    internal rivalries are sorted out, people coalesce into groups united against
    something foreign. These tendencies help explain why events on campus so often
    make the news—it seems like every other week we see some campus activity being
    labeled a “witch hunt,” “riot,” or something else that involves violence, implied
    or explicit. I don’t care to link to these events, they’re so easy to find. It’s
    interesting to see that academics are increasingly becoming the target of student
    activities. The <a href="https://en.wikipedia.org/wiki/Ren%C3%A9_Girard">Girardian</a>
    terror devours its children first, who have tolerated or fanned mimetic contagion
    for so long.</p><p>…I’ll end with a quote from <a href="https://www.amazon.com/See-Satan-Fall-Like-Lightning/dp/1570753199"><em>I
    See Satan Fall Like Lightning</em></a>: <strong>“Mimetic desire enables us to
    escape from the animal realm. It is responsible for the best and the worst in
    us, for what lowers us below the animal level as well as what elevates us above
    it. Our unending discords are the ransom of our freedom.”</strong></p>'
- - /docs/statistics/causality/2001-ioannidis.pdf
  - Comparison of Evidence of Treatment Effects in Randomized and Nonrandomized Studies
  - John P. A. Ioannidis, Anna-Bettina Haidich, Maroudia Pappa, Nikos Pantazis, Styliani
    I. Kokori, Maria G. Tektonidou, Despina G. Contopoulos-Ioannidis, Joseph Lau
  - 2001-08-01
  - 10.1001/jama.286.7.821
  - ! '<p><strong>Context</strong>: There is substantial debate about whether the
    results of nonrandomized studies are consistent with the results of randomized
    controlled trials on the same topic.</p><p><strong>Objectives</strong>: To compare
    results of randomized and nonrandomized studies that evaluated medical interventions
    and to examine characteristics that may explain discrepancies between randomized
    and nonrandomized studies.</p><p><strong>Data Sources</strong>: <span class="smallcaps-auto">MEDLINE</span> (1966–March
    2000), the Cochrane Library (Issue 3, 2000), and major journals were searched.</p><p><strong>Study
    Selection</strong>: Forty-five diverse topics were identified for which both randomized
    trials (<em>n</em>=240) and nonrandomized studies (<em>n</em>=168) had been performed
    and had been considered in meta-analyses of binary outcomes.</p><p><strong>Data
    Extraction</strong>: Data on events per patient in each study arm and design and
    characteristics of each study considered in each meta-analysis were extracted
    and synthesized separately for randomized and nonrandomized studies.</p><p><strong>Data
    Synthesis</strong>: Very good correlation was observed between the summary odds
    ratios of randomized and nonrandomized studies (<em>r</em> = 0.75; <em>p</em>&lt;.001);
    however, nonrandomized studies tended to show larger treatment effects (28 vs
    11; <em>p</em>=.009). Between-study heterogeneity was frequent among randomized
    trials alone (23%) and very frequent among nonrandomized studies alone (41%).
    The summary results of the 2 types of designs differed beyond chance in 7 cases
    (16%). Discrepancies beyond chance were less common when only prospective studies
    were considered (8%). Occasional differences in sample size and timing of publication
    were also noted between discrepant randomized and nonrandomized studies. In 28
    cases (62%), the natural logarithm of the odds ratio differed by at least 50%,
    and in 15 cases (33%), the odds ratio varied at least 2-fold between nonrandomized
    studies and randomized trials.</p><p><strong>Conclusions</strong>: Despite good
    correlation between randomized trials and nonrandomized studies—in particular,
    prospective studies—discrepancies beyond chance do occur and differences in estimated
    magnitude of treatment effect are very common.</p>'
- - /docs/statistics/2015-gaukler.pdf
  - Low-dose paroxetine exposure causes lifetime declines in male mouse body weight,
    reproduction and competitive ability as measured by the novel organismal performance
    assay
  - James S. Ruff, Tessa Galland, Kirstie A. Kandaris, Tristan K. Underwood, Nicole
    M. Liu, Elizabeth L. Young, Linda C. Morrison, Garold S. Yost, Wayne K. Potts
  - '2015'
  - 10.1016/j.ntt.2014.11.002
  - ! 'Paroxetine is a selective serotonin reuptake inhibitor (<span class="smallcaps-auto">SSRI</span>) that is currently
    available on the market and is suspected of causing congenital malformations in
    babies born to mothers who take the drug during the first trimester of pregnancy.
    We utilized organismal performance assays (<span class="smallcaps-auto">OPA</span>s), a novel toxicity assessment
    method, to assess the safety of paroxetine during pregnancy in a rodent model.
    <span class="smallcaps-auto">OPA</span>s utilize genetically diverse wild mice (Mus musculus) to evaluate competitive
    performance between experimental and control animals as they compete amongst each
    other for limited resources in semi-natural enclosures. Performance measures included
    reproductive success, male competitive ability and survivorship. Paroxetine-exposed
    males weighed 13% less, had 44% fewer offspring, dominated 53% fewer territories
    and experienced a 2.5-fold increased trend in mortality, when compared with controls.
    Paroxetine-exposed females had 65% fewer offspring early in the study, but rebounded
    at later time points. In cages, paroxetine-exposed breeders took 2.3 times longer
    to produce their first litter and pups of both sexes experienced reduced weight
    when compared with controls. Low-dose paroxetine-induced health declines detected
    in this study were undetected in preclinical trials with dose 2.5-8 times higher
    than human therapeutic doses. These data indicate that <span class="smallcaps-auto">OPA</span>s detect phenotypic
    adversity and provide unique information that could useful towards safety testing
    during pharmaceutical development. [Keywords: intraspecific competition, pharmacodynamics,
    reproductive success, semi-natural enclosures, <span class="smallcaps-auto">SSRI</span>, toxicity assessment.]'
- - /docs/psychology/writing/1993-ericsson.pdf
  - The role of deliberate practice in the acquisition of expert performance
  - K. Anders Ericsson, Ralf T. Krampe, Clemens Tesch-Römer
  - 1993-07
  - 10.1037/0033-295x.100.3.363
  - The theoretical framework presented in this article explains expert performance
    as the end result of individuals' prolonged efforts to improve performance while
    negotiating motivational and external constraints. In most domains of expertise,
    individuals begin in their childhood a regimen of effortful activities (deliberate
    practice) designed to optimize improvement. Individual differences, even among
    elite performers, are closely related to assessed amounts of deliberate practice.
    Many characteristics once believed to reflect innate talent are actually the result
    of intense practice extended for a minimum of 10 yrs. Analysis of expert performance
    provides unique evidence on the potential and limits of extreme environmental
    adaptation and learning.
- - http://www.vpri.org/pdf/tr2012001_steps.pdf#page=2
  - ! 'STEPS Toward Expressive Programming Systems: ''A Science Experiment'''
  - Yoshiki Ohshima, Dan Amelang, Ted Kaehler, Bert Freudenberg, Aran Lunzer, Alan
    Kay, Ian Piumarta, Takashi Yamamiya, Alan Borning, Hesam Samimi, Bret Victor,
    Kim Rose
  - '2012'
  - ''
  - ! '<p>[Technical report from a research project aiming at writing a <span class="smallcaps-auto">GUI</span> OS in
    20k LoC; tricks include <a href="http://www.moserware.com/2008/04/towards-moores-law-software-part-3-of-3.html"><span class="smallcaps-auto">ASCII</span>
    art networking <span class="smallcaps-auto">DSL</span>s & generic optimization for text layout</a>, which lets them
    implement a full OS, sound, <span class="smallcaps-auto">GUI</span> desktops, Internet networking & web browsers,
    a text/document editor etc, all in less lines of code that most OSes need for
    small parts of any of those.]</p> <p>…Many software systems today are made from
    millions to hundreds of millions of lines of program code that is too large, complex
    and fragile to be improved, fixed, or integrated. (One hundred million lines of
    code at 50 lines per page is 5000 books of 400 pages each! This is beyond human
    scale.) What if this could be made literally 1000 times smaller&mdash;or more?
    And made more powerful, clear, simple and robust?…The ''<span class="smallcaps-auto">STEPS</span> Towards Expressive
    Programming Systems'' project is taking the familiar world of personal computing
    used by more than a billion people every day&mdash;currently requiring hundreds
    of millions of lines of code to make and sustain&mdash;and substantially recreating
    it using new programming techniques and ''architectures'' in dramatically smaller
    amounts of program code. This is made possible by new advances in design, programming,
    programming languages, systems organizations, and the use of science to analyze
    and create models of software artifacts.</p><p><em><span class="smallcaps-auto">STEPS</span> Aims At ''Personal Computing''</em>&mdash;<span class="smallcaps-auto">STEPS</span>
    takes as its prime focus the dynamic modeling of ''personal computing'' as most
    people think of it…word processor, spreadsheet, Internet browser, other productivity
    SW; User Interface and Command Listeners: windows, menus, alerts, scroll bars
    and other controls, etc.; Graphics and Sound Engine: physical display, sprites,
    fonts, compositing, rendering, sampling, playing; Systems Services: development
    system, database query languages, etc.; Systems Utilities: file copy, desk accessories,
    control panels, etc.; Logical Level of OS: e.g. file management, Internet, and
    networking facilities, etc.; Hardware Level of OS: e.g. memory manager, process
    manager, device drivers, etc.</p>'
- - /docs/longevity/2019-zeraatkar.pdf
  - ! 'Effect of Lower Versus Higher Red Meat Intake on Cardiometabolic and Cancer
    Outcomes: A Systematic Review of Randomized Trials'
  - Dena Zeraatkar, Bradley C. Johnston, Jessica Bartoszko, Kevin Cheung, Malgorzata
    M. Bala, Claudia Valli, Montserrat Rabassa, Deagan Sit, Kirolos Milio, Behnam
    Sadeghirad, Arnav Agarwal, Adriana M. Zea, Yung Lee, Mi Ah Han, Robin W.M. Vernooij,
    Pablo Alonso-Coello, Gordon H. Guyatt, Regina El Dib
  - 2019-10-01
  - 10.7326/M19-0622
  - ! '<p><strong>Background</strong>: Few randomized trials have evaluated the effect
    of reducing red meat intake on clinically important outcomes.</p><p><strong>Purpose</strong>:
    To summarize the effect of lower versus higher red meat intake on the incidence
    of cardiometabolic and cancer outcomes in adults.</p><p><strong>Data Sources</strong>:
    <span class="smallcaps-auto">EMBASE</span>, <span class="smallcaps-auto">CENTRAL</span>, <span class="smallcaps-auto">CINAHL</span>, Web of Science, and ProQuest from inception to July 2018
    and <span class="smallcaps-auto">MEDLINE</span> from inception to April 2019, without language restrictions.</p><p><strong>Study
    Selection</strong>: Randomized trials (published in any language) comparing diets
    lower in red meat with diets higher in red meat that differed by a gradient of
    at least 1 serving per week for 6 months or more.</p><p><strong>Data Extraction</strong>:
    Teams of 2 reviewers independently extracted data and assessed the risk of bias
    and the certainty of the evidence.</p><p><strong>Data Synthesis</strong>: Of 12
    eligible trials, a single trial enrolling 48&thinsp;835 women provided the most credible,
    though still low-certainty, evidence that diets lower in red meat may have little
    or no effect on all-cause mortality (hazard ratio [HR], 0.99 [95% CI, 0.95 to
    1.03], cardiovascular mortality (HR, 0.98 [CI, 0.91 to 1.06]), and cardiovascular
    disease (HR, 0.99 [CI, 0.94 to 1.05]). That trial also provided low- to very-low-certainty
    evidence that diets lower in red meat may have little or no effect on total cancer
    mortality (HR, 0.95 [CI, 0.89 to 1.01]) and the incidence of cancer, including
    colorectal cancer (HR, 1.04 [CI, 0.90 to 1.20]) and breast cancer (HR, 0.97 [0.90
    to 1.04]).</p><p><strong>Limitations</strong>: There were few trials, most addressing
    only surrogate outcomes, with heterogeneous comparators and small gradients in
    red meat consumption between lower versus higher intake groups.</p><p><strong>Conclusion</strong>:
    Low- to very-low-certainty evidence suggests that diets restricted in red meat
    may have little or no effect on major cardiometabolic outcomes and cancer mortality
    and incidence.</p>'
- - https://blogs.msdn.microsoft.com/larryosterman/2004/03/30/one-in-a-million-is-next-tuesday/
  - ! '''One in a million'' is next Tuesday'
  - Larry Osterman
  - 2004-03-30
  - ''
  - ! '<p>I was looking into a bug with Gordon Letwin, the architect for <span class="smallcaps-auto">DOS</span> 4. I
    looked at the code and commented “Maybe this is what was happening? But if that
    were the case, it’d take a one in a million chance for it to happen”.</p><p>Gordon’s
    response was simply: “In our business, one in a million is next Tuesday”. He then
    went on to comment that at the speeds which modern computers operate (&gt;4.77
    MHz, remember), things happened so quickly that something with a one in a million
    chance of occurrence is likely to happen in the next day or so.</p><p>I’m not
    sure I’ve ever received better advice in my career. It has absolutely stood the
    test of time–no matter how small the chance of something happening, with modern
    computers and modern operating systems, essentially every possible race condition
    or deadlock will be found within a reasonable period of time. And I’ve seen some
    absolute doozies in my time–race conditions on MP machines where a non interlocked
    increment occurred (one variant of Michael Grier’s <code>i = i + 1</code> bug).
    Data corruptions because you have one non protected access to a data structure.
    I’m continually amazed at the NT scheduler’s uncanny ability to context switch
    my application at just the right time as to expose my data synchronization bug.
    Or to show just how I can get my data structures deadlocked in hideous ways.</p><p>So
    nowadays, whenever anyone comments on how unlikely it is for some event to occur,
    my answer is simply: “One in a million is next Tuesday”.</p>'
- - https://slate.com/news-and-politics/2017/03/outrageous-trial-transcript-fees-are-bad-for-defendants-journalists-and-democracy.html
  - ! 'Public Record, Astronomical Price: Court reporters charge outrageous fees to
    reproduce trial transcripts. That’s bad for defendants, journalists, and democracy.'
  - Emma Copley Eisenberg (Slate)
  - 2017-03-22
  - ''
  - <p>The trial transcripts were there, 12 neatly bound volumes…I needed a copy,
    I said. “Sure,” she replied warmly before noting that all transcript copies must
    come directly from the court reporter at a price of $1 per page. The transcript
    I wanted was 2,400 pages.</p><p>The court reporter, Twyla, picked up on the first
    ring. I pleaded poor journalist and poor grad student, but she, a veteran of the
    field, was unmoved. Twyla informed me that the rate was governed by law, and besides,
    she was entitled to that money—in fact, she needed it to be fairly compensated
    for her work. Could that be? It could. The West Virginia State Code of Civil Procedure
    dictates that a court reporter must provide on request a trial transcript for
    $2.85 per page, with any subsequent copies of that same transcript to be supplied
    for $1 per page. The cost is even higher in other states. In Georgia, for instance,
    the rate is $6 per page.</p><p>The rates are set that way to compensate court
    reporters for expenses they must pay themselves. Twyla explained to me that, while
    the state of West Virginia provides an office in the courthouse and a telephone
    for court reporters, it does not pay for most of the tools and equipment she needs
    to do her job. Laptops, note-taking machines and software, paper, and pencils
    are necessary items for professional transcription. All of it—which could cost
    as much as $13,000 a year—comes out of court reporters’ pockets, she said. It’s
    a huge expense for professionals earning an average $50,000 per year but can be
    worth it if a court reporter sells one or two copies of her transcripts. Twyla
    says she’s heard of some women (89 percent of court reporters in the United States
    are female) making up to $90,000 a year between their salaries and the sale of
    transcripts they’ve created—more than decent pay in a rural area like Greenbrier
    County, where the median household income is just shy of $40,000.</p><p>Using
    fees to subsidize court reporter pay works in theory, but in practice it makes
    trial transcripts too expensive for an average citizen or journalist to afford.
    It also can put a barrier between trial transcripts and individuals who should
    be entitled to them. I learned later that the defendant in the case I was researching
    paid more than $7,000 to obtain a copy of the transcript from his own trial so
    his lawyers could analyze it for grounds for appeal…For Twyla, the current law
    demands that she jealously guard each page of her work to ensure she makes a decent
    living. For those tried and convicted of crimes, this means ponying up thousands
    of dollars for a record of their experience in the courts. For journalists like
    me, it means not learning why a jury of a man’s peers found him guilty of murder—unless
    we can spare $2,400, which I still can’t.</p><p>The trial transcripts were there,
    12 neatly bound volumes…I needed a copy, I said. “Sure,” she replied warmly before
    noting that all transcript copies must come directly from the court reporter at
    a price of $1 per page. The transcript I wanted was 2,400 pages.</p><p>The court
    reporter, Twyla, picked up on the first ring. I pleaded poor journalist and poor
    grad student, but she, a veteran of the field, was unmoved. Twyla informed me
    that the rate was governed by law, and besides, she was entitled to that money—in
    fact, she needed it to be fairly compensated for her work. Could that be? It could.
    The West Virginia State Code of Civil Procedure dictates that a court reporter
    must provide on request a trial transcript for $2.85 per page, with any subsequent
    copies of that same transcript to be supplied for $1 per page. The cost is even
    higher in other states. In Georgia, for instance, the rate is $6 per page.</p><p>The
    rates are set that way to compensate court reporters for expenses they must pay
    themselves. Twyla explained to me that, while the state of West Virginia provides
    an office in the courthouse and a telephone for court reporters, it does not pay
    for most of the tools and equipment she needs to do her job. Laptops, note-taking
    machines and software, paper, and pencils are necessary items for professional
    transcription. All of it—which could cost as much as $13,000 a year—comes out
    of court reporters’ pockets, she said. It’s a huge expense for professionals earning
    an average $50,000 per year but can be worth it if a court reporter sells one
    or two copies of her transcripts. Twyla says she’s heard of some women (89% of
    court reporters in the United States are female) making up to $90,000 a year between
    their salaries and the sale of transcripts they’ve created—more than decent pay
    in a rural area like Greenbrier County, where the median household income is just
    shy of $40,000.</p><p>Using fees to subsidize court reporter pay works in theory,
    but in practice it makes trial transcripts too expensive for an average citizen
    or journalist to afford. It also can put a barrier between trial transcripts and
    individuals who should be entitled to them. I learned later that the defendant
    in the case I was researching paid more than $7,000 to obtain a copy of the transcript
    from his own trial so his lawyers could analyze it for grounds for appeal…For
    Twyla, the current law demands that she jealously guard each page of her work
    to ensure she makes a decent living. For those tried and convicted of crimes,
    this means ponying up thousands of dollars for a record of their experience in
    the courts. For journalists like me, it means not learning why a jury of a man’s
    peers found him guilty of murder—unless we can spare $2,400, which I still can’t.</p>
- - https://openreview.net/forum?id=Bkl8YR4YDB
  - Large-scale Pretraining for Neural Machine Translation with Tens of Billions of
    Sentence Pairs
  - Anonymous et al 2019
  - 2019-09-25
  - ''
  - In this paper, we investigate the problem of training neural machine translation
    (<span class="smallcaps-auto">NMT</span>) systems with a dataset of more than 40 billion bilingual sentence pairs,
    which is larger than the largest dataset to date by orders of magnitude. Unprecedented
    challenges emerge in this situation compared to previous <span class="smallcaps-auto">NMT</span> work, including severe
    noise in the data and prohibitively long training time. We propose practical solutions
    to handle these issues and demonstrate that large-scale pretraining significantly
    improves <span class="smallcaps-auto">NMT</span> performance. We are able to push the <span class="smallcaps-auto">BLEU</span> score of <span class="smallcaps-auto">WMT</span>17 Chinese-English
    dataset to 32.3, with a significant performance boost of +3.2 over existing state-of-the-art
    results.
- - https://www.usenix.org/system/files/conference/woot16/woot16-paper-wustrow.pdf
  - ! 'DDoSCoin: Cryptocurrency with a Malicious Proof-of-Work'
  - Eric Wustrow, Benjamin VanderSloot
  - 2016-08-08
  - ''
  - <p>[<span class="smallcaps-auto">HTTPS</span> connections can provide third-party-verifiable signatures and so <span class="smallcaps-auto">HTTPS</span>
    is a valid Proof-of-Work and one can incentivize creating <span class="smallcaps-auto">HTTPS</span> connections and
    hence DDoSes. This could also be used non-maliciously to create a distributed
    anonymous uptime-checking service, by incentivizing only a few connections each
    time period for small bounties.]</p> <p>Since its creation in 2009, Bitcoin has
    used a hash-based proof-of-work to generate new blocks, and create a single public
    ledger of transactions. The hash-based computational puzzle employed by Bitcoin
    is instrumental to its security, preventing Sybil attacks and making double-spending
    attacks more difficult. However, there have been concerns over the efficiency
    of this proof-of-work puzzle, and alternative “useful” proofs have been proposed.
    In this paper, we present DDoSCoin, which is a cryptocurrency with a <em>malicious</em>
    proof-of-work. DDoSCoin allows miners to prove that they have contributed to a
    distributed denial of service attack against specific target servers. This proof
    involves making a large number of <span class="smallcaps-auto">TLS</span> connections to a target server, and using
    cryptographic responses to prove that a large number of connections has been made.
    Like proof-of-work puzzles, these proofs are inexpensive to verify, and can be
    made arbitrarily difficult to solve.</p>
- - https://newcriterion.com/issues/2019/10/leninthink
  - ! 'Leninthink: On the practice behind the theory of Marxism-Leninism'
  - Gary Saul Morson
  - 2019-10
  - ''
  - ! '[This re-appraisal of Lenin is just about as damning as any re-appraisal of
    anybody could possibly be. “He invented a form of government we have come to call
    totalitarian, which rejected in principle the idea of any private sphere outside
    of state control. He invented the one-party state, a term that would previously
    have seemed self-contradictory since a party was, by definition, a part. He believed
    that state power had to be based on sheer terror, and so he created the terrorist
    state. Violence was a goal in itself”]'
- - http://cabinetmagazine.org/issues/33/allen.php
  - Mark of Integrity
  - Jonathan Allen
  - 2009-02
  - ''
  - <p>[Card marking is a venerable and sophisticated art. Jonathan Allen on juiced
    cards, luminous readers, sunning the deck, and other sharpers’ tricks <a href="https://en.wikipedia.org/wiki/Card_marking">card
    marking</a>)]</p><p>The history of the marked playing card, perhaps as old as
    the playing card itself, is a miscellany of inventive guile. “The systems of card-marking
    are as numerous as they are ingenious,” wrote John Nevil Maskelyne in 1894. “Card
    doctoring,” to use Erdnase’s term, covers many forms of subterfuge, but in the
    brief survey that follows, we shall focus our attention upon what might more usefully
    be termed the “language” of the marked card.</p><p>…“Luminous readers” are cards
    treated in such a way that pale green ink traces become clearly visible when viewed
    through red-filtered spectacles or contact lenses. The technology caused alarm
    upon its discovery but, due to its limited effectiveness and its reliance upon
    somewhat vampiric eye adornment, has remained more of a popular novelty than a
    serious subterfuge.<sup>11</sup> “Juiced cards,” on the other hand, do not need
    lens-based viewing, instead requiring the reader to defocus his or her eyes and
    spot liminal fluid-residue marks on an opponent’s distant cards (juiced cards
    are also known as “distance readers”). To many players, juicing, and its recent
    high-tech offshoot, “video juicing,” are the most effective real-world card-marking
    system available, and the considerable price of the closely guarded fluid recipe
    and application technique reflects this growing reputation.</p>
- - https://www.g3journal.org/content/9/9/2863
  - A Prospective Analysis of Genetic Variants Associated with Human Lifespan
  - Kevin M. Wright, Kristin A. Rand, Amir Kermany, Keith Noto, Don Curtis, Daniel
    Garrigan, Dmitri Slinkov, Ilya Dorfman, Julie M. Granka, Jake Byrnes, Natalie
    Myres, Catherine A. Ball, J. Graham Ruby
  - 2019-09
  - 10.1534/g3.119.400448
  - We present a massive investigation into the genetic basis of human lifespan. Beginning
    with a genome-wide association (<span class="smallcaps-auto">GWA</span>) study using a de-identified snapshot of the
    unique Ancestry<span class="smallcaps-auto">DNA</span> database–more than 300,000 genotyped individuals linked to
    pedigrees of over 400,000,000 people–we mapped six genome-wide significant loci
    associated with parental lifespan. We compared these results to a <span class="smallcaps-auto">GWA</span> analysis
    of the traditional lifespan proxy trait, age, and found only one locus, <span class="smallcaps-auto">APOE</span>,
    to be associated with both age and lifespan. By combining the Ancestry<span class="smallcaps-auto">DNA</span> results
    with those of an independent UK Biobank dataset, we conducted a meta-analysis
    of more than 650,000 individuals and identified fifteen parental lifespan-associated
    loci. Beyond just those significant loci, our genome-wide set of polymorphisms
    accounts for up to 8% of the variance in human lifespan; this value represents
    a large fraction of the heritability estimated from phenotypic correlations between
    relatives.
- - /docs/economics/2014-lewis.pdf
  - ! 'Managing an iconic old luxury brand in a new luxury economy: Hermès handbags
    in the US market'
  - Tasha L. Lewis, Brittany Haas
  - 2014-03
  - 10.1386/gfb.1.1.167_1
  - The Hermès brand is synonymous with a wealthy global elite clientele and its products
    have maintained an enduring heritage of craftsmanship that has distinguished it
    among competing luxury brands in the global market. Hermès has remained a family
    business for generations and has successfully avoided recent acquisition attempts
    by luxury group <span class="smallcaps-auto">LVMH</span>. Almost half of the luxury firm’s revenue ($1.5B in 2012)
    is derived from the sale of its leather goods and saddlery, which includes its
    handbags. A large contributor to sales is global demand for one of its leather
    accessories, the Birkin bag, ranging in price from $10,000 to $250,000. Increased
    demand for the bag in the United States since 2002 resulted in an extensive customer
    waitlist lasting from months to a few years. Hermès retired the famed waitlist
    (sometimes called the ‘dream list’) in the United States in 2010, and while the
    waitlist has been removed, demand for the Birkin bag has not diminished and making
    the bag available to luxury consumers requires extensive, careful distribution
    management. In addition to inventory constraints related to demand for the Birkin
    bag in the United States, Hermès must also manage a range of other factors in
    the US market. These factors include competition with ‘affordable’ luxury brands
    like Coach, monitoring of unsolicited brand endorsers as well as counterfeit goods
    and resellers. This article examines some of the allocation practices used to
    carefully manage the Hermès brand in the US market.
- - https://www.newyorker.com/magazine/2010/11/22/natures-spoils
  - ! 'Nature''s Spoils: The underground food movement ferments revolution'
  - Burkhard Bilger (New Yorker)
  - 2010-11-22
  - ''
  - ! '<p>[Discussion of food subcultures: dumpster divers, raw food enthusiasts,
    fermenters, roadkill, and ''high'' (fully rotten meat) food advocates, with visits
    to gay commune Hickory Knoll and raw milk dairies. The author ultimately draws
    the line at trying high game, however.]</p><p>When Torma unclamped his jar, a
    sickly-sweet miasma filled the air—an odor as natural as it was repellent. Decaying
    meat produces its own peculiar scent molecules, I later learned, with names like
    putrescine and cadaverine. I could still smell them on my clothes hours later.
    Torma stuck two fingers down the jar and fished out a long, wet sliver. “Want
    a taste?” he said.</p> <p>It was the end of a long day. I’d spent most of it consuming
    everything set before me: ants, acorns, raw milk, dumpster stew, and seven kinds
    of mead, among other delicacies. But even Katz took a pass on high meat. While
    Torma threw back his head and dropped in his portion, like a seal swallowing a
    mackerel, we quietly took our leave. “You have to trust your senses,” Katz said,
    as we were driving away. “To me, that smelled like death.”</p>'
- - https://www.karger.com/Article/FullText/502257
  - ! 'Metformin and Aging: A Review'
  - Hartmut H. Glossmann, O.M. Lutz
  - 2019-09-13
  - 10.1159/000502257
  - ! '<p>Metformin is sometimes proposed to be an “anti-aging” drug, based on preclinical
    experiments with lower-order organisms and numerous retrospective data on beneficial
    health outcomes for type 2 diabetics. Large prospective, placebo-controlled trials
    are planned, in pilot stage or running, to find a new use (or indication) for
    an aging population. As one of the metformin trials has “frailty” as its endpoint,
    similar to a trial with a plant-derived senolytic, the latter class of novel anti-aging
    drugs is briefly discussed. Concerns exist not only for vitamin B12 and B6 deficiencies,
    but also about whether there are adverse effects of metformin on individuals who
    try to remain healthy by maintaining cardiovascular fitness via exercise.</p><p>…<em>Conclusions,
    Recommendations, and Perspectives</em>: The rationale for the ongoing or planned
    metformin trials is almost exclusively based on observations (associations) of
    potential benefits in a diabetic (or prediabetic) population. Its efficacy even
    in an at-risk cohort of aged people has not yet been proven. Metformin is associated
    with a higher risk of vitamin B12 and vitamin B6 deficiency, which may result
    in an increased risk of cognitive dysfunction [98]. Supplementation is strongly
    recommended to metformin users.</p> <p>Of greater concern are the results of small
    trials in which the effects of metformin on metabolic responses to exercise or
    on cardiorespiratory fitness were tested. In a placebo-controlled, double-blind,
    crossover trial with healthy young subjects, metformin caused a small but significant
    decline in maximal aerobic capacity [99]. A double-blind, placebo-controlled landmark
    trial with older adults with one risk factor for T2D investigated the effects
    of metformin and 12 weeks of aerobic exercise [100]. Contrary to expectations–namely,
    that the effects of exercise and the drug would be additive–“metformin attenuated
    the increase in whole-body insulin sensitivity and abrogated the exercise-mediated
    increase in skeletal muscle mitochondrial respiration.” The results of the (repurposing)
    <span class="smallcaps-auto">MASTERS</span> trial (<span class="smallcaps-auto">NCT</span>02308228; Metformin to Augment Strength Training Effective Response
    in Seniors) [100] will be instructive. <span class="smallcaps-auto">MASTERS</span> is testing the hypothesis that
    older individuals’ long-term treatment with metformin augments the effects of
    resistance exercise, especially in the “nonresponder” aging population.</p>'
- - /docs/history/2019-risi.pdf
  - Predicting History
  - Joseph Risi, Amit Sharma, Rohan Shah, Matthew Connelly, Duncan J. Watts
  - 2019-06-03
  - 10.1038/s41562-019-0620-8
  - Can events be accurately described as historic at the time they are happening?
    Claims of this sort are in effect predictions about the evaluations of future
    historians; that is, that they will regard the events in question as significant.
    Here we provide empirical evidence in support of earlier philosophical arguments<sup>1</sup>
    that such claims are likely to be spurious and that, conversely, many events that
    will one day be viewed as historic attract little attention at the time. We introduce
    a conceptual and methodological framework for applying machine learning prediction
    models to large corpora of digitized historical archives. We find that although
    such models can correctly identify some historically important documents, they
    tend to over-predict historical significance while also failing to identify many
    documents that will later be deemed important, where both types of error increase
    monotonically with the number of documents under consideration. On balance, we
    conclude that historical significance is extremely difficult to predict, consistent
    with other recent work on intrinsic limits to predictability in complex social
    systems<sup>2,3</sup>. However, the results also indicate the feasibility of developing
    ‘artificial archivists’ to identify potentially historic documents in very large
    digital corpora.
- - https://www.goodreads.com/review/show/396645245
  - ! 'Bakker''s <em>Second Apocalypse</em> & Frank Herbert''s <em>Dune</em>: time
    loops &amp; finding freedom in an unfree universe'
  - Gwern Branwen
  - 2019-08-30
  - ''
  - ! '<p>Review of SF/F author <a href="https://en.wikipedia.org/wiki/R._Scott_Bakker">R.
    Scott Bakker</a>‘s long-running <em>Second Apocalypse</em> series, which finished
    in 2017. The series, a loose retelling of the Crusades, set in a fallen-SF fantasy
    environment, has drawn attention for its ambitious scope and obscure philosophical
    message centering around determinism, free will, moral nihilism, eliminativism
    of cognitive states, and the interaction of technology &amp; ethics (which Bakker
    terms the ’Semantic Apocalypse’). In this series, the protagonist attempts to
    stop the apocalypse and ultimately accidentally causes it.</p><p>I highlight that
    Frank Herbert’s <em>Dune</em> universe is far more influential on Bakker than
    reviewers of Bakker have appreciated: countless elements are reflected in Bakker,
    and the very name of the primary antagonist, the ‘No-God’, uses a naming pattern
    from <em>Dune</em> and operates similarly. Further, both <em>Dune</em> and the
    <em>Second Apocalypse</em> are deeply concerned with the nature of time and temporal
    loops controlling ‘free’ behavior. Where they diverge is in what is to be done
    about the human lack of freedom and manipulability by external environments, and
    have radically different views about what is desirable: in <em>Dune</em>, humanity
    gradually grows up and achieves freedom from the time loops by the creation of
    a large time loop whose stable fixed point is the destruction of all time loops,
    ensuring that humanity will go on existing in some form forever; in the <em>Second
    Apocalypse</em>, liberation is achieved only through death.</p>'
- - https://www.nature.com/articles/s41534-019-0141-3
  - Universal quantum control through deep reinforcement learning
  - Murphy Yuezhen Niu, Sergio Boixo, Vadim N. Smelyanskiy, Hartmut Neven
  - 2019-04-23
  - 10.1038/s41534-019-0141-3
  - Emerging reinforcement learning techniques using deep neural networks have shown
    great promise in control optimization. They harness non-local regularities of
    noisy control trajectories and facilitate transfer learning between tasks. To
    leverage these powerful capabilities for quantum control optimization, we propose
    a new control framework to simultaneously optimize the speed and fidelity of quantum
    computation against both leakage and stochastic control errors. For a broad family
    of two-qubit unitary gates that are important for quantum simulation of many-electron
    systems, we improve the control robustness by adding control noise into training
    environments for reinforcement learning agents trained with trusted-region-policy-optimization.
    The agent control solutions demonstrate a two-order-of-magnitude reduction in
    average-gate-error over baseline stochastic-gradient-descent solutions and up
    to a one-order-of-magnitude reduction in gate time from optimal gate synthesis
    counterparts. These significant improvements in both fidelity and runtime are
    achieved by combining new physical understandings and state-of-the-art machine
    learning techniques. Our results open a venue for wider applications in quantum
    simulation, quantum chemistry and quantum supremacy tests using near-term quantum
    devices.
- - https://www.c82.net/blog/?id=79
  - Making of Byrne’s Euclid
  - Nicholas Rougeux
  - 2018-12-16
  - ''
  - <p>Creating a faithful online reproduction of a book considered one of the most
    beautiful and unusual publications ever published is a daunting task. <em>Byrne’s
    Euclid</em> is my tribute to Oliver Byrne’s most celebrated publication from 1847
    that illustrated the geometric principles established in Euclid’s original <em>Elements</em>
    from 300 BC.</p><p>In 1847, Irish mathematics professor Oliver Byrne worked closely
    with publisher William Pickering in London to publish his unique edition titled
    <em>The First Six Books of the Elements of Euclid in which Coloured Diagrams and
    Symbols are Used Instead of Letters for the Greater Ease of Learners</em>—or more
    simply, <em>Byrne’s Euclid</em>. Byrne’s edition was one of the first multicolor
    printed books and is known for its unique take on Euclid’s original work using
    colorful illustrations rather than letters when referring to diagrams. The precise
    use of colors and diagrams meant that the book was very challenging and expensive
    to reproduce. Little is known about why Byrne only designed 6 of the 13 books
    but it was could have been due to time and cost involved…I knew of other projects
    like Sergey Slyusarev’s ConTeXt rendition and Kronecker Wallis’ modern redesign
    but I hadn’t seen anyone reproduce the 1847 edition online in its entirety and
    with a design true to the original. This was my goal and I knew it was going to
    be a fun challenge.</p><figure><img src="/images/design/nicholasrougeux-2018-bryneseuclid-book1-diagrams.jpg"
    alt="Diagrams from Book 1 (https://www.c82.net/images/blog/euclid-book1-diagrams.jpg)" /><figcaption>Diagrams from Book 1</figcaption></figure><p>[Detailed
    discussion of how to use Adobe Illustrator to redraw the modernist art-like primary
    color diagrams from Bryne in scalable vector graphics (<span class="smallcaps-auto">SVG</span>) for use in interactive
    <span class="smallcaps-auto">HTML</span> pages, creation of a custom <a href="https://en.wikipedia.org/wiki/Initial#Types_of_initial">drop
    caps/initials font</a> to replicate Bryne, his (questionable) efforts to use the
    <a href="https://en.wikipedia.org/wiki/Long_s">‘long s’</a> for greater authenticity,
    rendering the math using MathJax, and creating posters demonstrating all diagrams
    from the project for offline viewing.]</p>
- - https://www.math.ubc.ca/~cass/Euclid/byrne.html
  - Oliver Byrne's edition of Euclid [Scans]
  - Bill Casselman et al (University of British Columbia)
  - ''
  - ''
  - Online scanned edition; part of a set of Euclid editions.
- - /docs/statistics/1990-tufte-envisioninginformation-ch5-bryneseuclid.pdf
  - ! '<em>Envisioning Information</em>: chapter 5, ''Color and Information'', pg83-86
    [on Oliver Bryne''s color diagram version of Euclid''s <em>Elements</em>]'
  - Edward Tufte
  - '1990'
  - ''
  - ! '[Extracts from Tufte textbook on graphing information and visual design, where
    he revives & popularizes Oliver Bryne''s obscure Euclid edition, noting how effectively
    Bryne converts lengthy proofs into short sequences of cleanly-designed diagrams
    exploiting primary colors for legibility, and the curious anticipation of modernist
    design movements like De Stijl.]'
- - https://habr.com/ru/post/452520/
  - Fancy Euclid's <em>Elements</em> in T<sub>e</sub>X
  - Sergey Slyusarev
  - 2019-03-19
  - ''
  - <p>The most obvious option—to draw all the illustrations in Illustrator and compose
    the whole thing in InDesign—was promptly rejected. Geometrical constructions are
    not exactly the easiest thing to do in Illustrator, and no obvious way to automatically
    connect the main image to miniatures came to my mind. As for InDesign, although
    it's very good at dealing with such visually rich layouts, it promised to scare
    the hell out of me by the overcrowded “Links” panel. So, without thinking twice,
    I decided to use other tools that I was familiar with—MetaPost, which made it
    relatively easy to deal with geometry, and LaTeX, which I knew could do the job.
    Due to some problems with MetaPost libs for LaTeX, I replaced the latter with
    <a href="https://en.wikipedia.org/wiki/ConTeXt">ConTeXt</a> that enjoys an out-of-the-box
    merry relationship with MetaPost.</p><p><img src="/images/design/2019-slyusarev-euclidintex-convertingtocontext.jpg"
    alt="Converting a Bryne Euclid diagram to ConTeXt vector graphics (https://hsto.org/webt/b9/xj/sq/b9xjsqwlk_6vlrkagvbpb2yfej0.jpeg)"></p><p>…
    There are also initials and vignettes in the original edition. On one hand, they
    were reasonably easy to recreate (at least, it wouldn't take a lot of thought
    to do this), but I decided to go with a more interesting (albeit hopeless) option—automatically
    generating the initials and vignettes with a random ornament. Not only is it fun,
    but also, the Russian translation would require adapting the style of the original
    initials to the Cyrillic script, which was not something I'd prefer to do. So,
    long story short, when you compile the book, a list of initial letters is written
    to the disk, and a separate MetaPost script can process it (very slowly) to produce
    the initials and vignettes. No two of them have the exact same ornament.</p>
- - /docs/statistics/peerreview/1975-johnson.pdf
  - Models of Control and Control of Bias
  - Martin U. Johnson
  - '1975'
  - ''
  - <p>The author discusses how to increase the quality and reliability of the research
    and reporting process in experimental parapsychology. Three levels of bias and
    control of bias are discussed. The levels are referred to as Model 1, Model 2
    and Model 3 respectively.</p><ol type="1"><li>Model 1 is characterized by its
    very low level of intersubjective control. The reliability of the results depends
    to a very great extent upon the reliability of the investigator and the editor.</li><li>Model
    2 is relevant to the case when the experimenter is aware of the potential risk
    of making both errors of observation and recording and tries to control this bias.
    However, this model of control does not make allowances for the case when data
    are intentionally manipulated.</li><li>Model 3 depicts a rather sophisticated
    system of control. One feature of this model is, that selective reporting will
    become harder since the editor has to make his decision as regards the acceptance
    or rejection of an experimental article prior to the results being obtained, and
    subsequently based upon the quality of the outline of the experiment. However,
    it should be stressed, that not even this model provides a fool-proof guarantee
    against deliberate fraud.</li></ol><p>It is assumed that the models of bias and
    control of bias under discussion are relevant to most branches of the behavioral
    sciences.</p>
- - /docs/statistics/peerreview/1975-johnson-2.pdf
  - Editorial [EJP editorial on registered reports]
  - Martin U. Johnson
  - '1975'
  - ''
  - ! 'This copy represents our first ''real'' issue of the <em>European Journal of
    Parapsychology</em>…As far as experimental articles are concerned, we would
    like to ask potential contributors to try and adhere to the publishing policy
    which we have outlined in the editorial of the demonstration copy, and which is
    also discussed at some length in the article: ''Models of Bias and Control of
    Bias'' [Johnson 1975a], in this issue. In short we shall try to avoid selective
    reporting and yet at the same time we shall try to refrain from making our journal
    a graveyard for all those studies which did not ''turn out''. These objectives
    may be fulfilled by the editorial rule of basing our judgment entirely on our
    impressions of the quality of the design and methodology of the planned study.
    The acceptance or rejection of a manuscript should if possible take place prior
    to the carrying out and the evaluation of the results of the study.'
- - /docs/statistics/peerreview/1976-johnson.pdf
  - ! 'On Publication Policy Regarding Non-Significant Results: Some comments on Dr.
    J.B. Rhine''s article in the comments section of the J.P., 39, No 2, 135-142'
  - Martin U. Johnson
  - '1976'
  - ''
  - ! '<p>…even the most proper use of statistics may lead to spurious correlations
    or conclusions if there are inadequacies regarding the research process itself.
    One of these sources of error in the research process is related to selective
    reporting; another to human limitations with regard to the ability to make reliable
    observations or evaluations. <a href="/docs/statistics/bias/1966-dunnette.pdf"
    title="Fads, Fashions, and Folderols in Psychology">Dunette (1)</a> says:</p><blockquote><p>The
    most common variant is, of course, the tendency to bury negative results. I only
    recently became aware of the massive size of this great graveyard for dead studies
    when a colleague expressed gratification that only a third of his studies ‘turned
    out’—as he put it. Recently, a second variant of this secret game was discovered,
    quite inadvertently, by <a href="/docs/statistics/bias/1962-wolins.pdf"
    title="Responsibility for raw data">Wolins 1962</a>, when he wrote to 37 authors
    to ask for the raw-data on which they had based recent journal articles. Wolins
    found that of the 37 who replied, 21 reported their data to be either misplaced,
    lost, or inadvertently destroyed. Finally, after some negotiation, Wolins was
    able to complete 7 re-analyses on the data supplied from 5 authors. Of the 7,
    he found gross errors in 3—errors so great as to clearly change the outcome of
    the experiments already reported.</p></blockquote><p>It should also be stressed
    that Rosenthal and others have demonstrated that experimenters tend to arrive
    at results found to be in full agreement with their expectancies, or with the
    expectancies of those within the scientific establishment in charge of the rewards.
    Even if some of Rosenthal’s results have been questioned [especially the ‘Pygmalion
    effect’] the general tendency seems to be unaffected.</p><p>I guess we can all
    agree upon the fact that selective reporting in studies on the reliability and
    validity, of for instance a personality test, is a bad thing. But what could be
    the reason for selective reporting? Why does a research worker manipulate his
    dead? Is it only because the research worker has a ‘weak’ mind or does there exist
    some kind of ‘steering field’ that exerts such an influence that improper behavior
    on the part of the research worker occurs?</p><p>It seems rather reasonable to
    assume that the editors of professional journals or research leaders in general
    could exert a certain harmful influence in this connection…There is no doubt at
    all in my mind about the ‘filtering’ or ‘shaping’ effect an editor may exert upon
    the output of his journal…As I see it, the major risk of selective reporting is
    not primarily a statistical one, but rather the research climate which the underlying
    policy create (“you are ‘good’ if you obtain supporting results; you are”no-good"
    if you only arrive at chance results").</p><p>…The analysis I carried out has
    had practical implications for the publication policy which we have stated as
    an ideal for our new journal: the <em>European Journal of Parapsychology</em>.</p>'
- - /docs/statistics/bias/1962-wolins.pdf
  - Responsibility for Raw Data
  - Leroy Wolins
  - 1962-09
  - 10.1037/h0038819
  - Comments on a Iowa State University graduate student's endeavor of requiring data
    of a particular kind in order to carry out a study for his master's thesis. This
    student wrote to 37 authors whose journal articles appeared in <span class="smallcaps-auto">APA</span> journals between
    1959 and 1961. Of these authors, 32 replied. 21 of those reported the data misplaced,
    lost, or inadvertently destroyed. 2 of the remaining 11 offered their data on
    the conditions that they be notified of our intended use of their data, and stated
    that they have control of anything that we would publish involving these data.
    Errors were found in some of the raw data that was obtained which caused a dilemma
    of either reporting the errors or not. The commentator states that if it were
    clearly set forth by the <span class="smallcaps-auto">APA</span> that the responsibility for retaining raw data and
    submitting them for scrutiny upon request lies with the author, this dilemma would
    not exist. The commentator suggests that a possibly more effective means of controlling
    quality of publication would be to institute a system of quality control whereby
    random samples of raw data from submitted journal articles would be requested
    by editors and scrutinized for accuracy and the appropriateness of the analysis
    performed.
- - /docs/statistics/bias/1966-dunnette.pdf
  - Fads, fashions, and folderol in psychology
  - Marvin D. Dunnette
  - '1966'
  - 10.1037/h0023535
  - ! '<p>[Influential early critique of academic psychology: weak theories, no predictions,
    poor measurements, poor replicability, high levels of publication bias, non-progressive
    theory building, and constant churn; many of these criticisms would be taken up
    by the ''Minnesota school'' of Bouchard/Meehl/Lykken/etc.]</p> <p>Fads include
    brain-storming, Q technique, level of aspiration, forced choice, critical incidents,
    semantic differential, role playing, and need theory. Fashions include theorizing
    and theory building, criterion fixation, model building, null-hypothesis testing,
    and sensitivity training. Folderol includes tendencies to be fixated on theories,
    methods, and points of view, conducting "little" studies with great precision,
    attaching dramatic but unnecessary trappings to experiments, grantsmanship, coining
    new names for old concepts, fixation on methods and apparatus, etc.</p>'
- - https://nostalgebraist.livejournal.com/68532.html
  - About Henry Darger
  - Nostalgebraist
  - 2011-05-26
  - ''
  - ! '<p>[On why <a href="https://en.wikipedia.org/wiki/Henry_Darger">Henry Darger</a>,
    a elderly, solitary dishwasher, wrote and illustrated a 15,000+ page unpublished
    fantasy novel.]</p><p>I’m here today to tell you about a book I read recently,
    namely <em>Henry Darger: In The Realms Of The Unreal</em>, by John MacGregor.
    It’s a study of <a href="http://en.wikipedia.org/wiki/Henry_Darger">Henry Darger</a>,
    a man I instantly became obsessed with upon encountering his Wikipedia entry sometime
    last fall.</p><p>Here’s a quick sketch of who Darger was, which will hopefully
    give you an idea of why I find him so fascinating. He was a reclusive man who
    worked various dishwashing jobs for most of his life. He only had one real friend
    in the course of his life, and although he occasionally interacted with the other
    residents of his apartment complex, they just saw him as a peculiar, taciturn
    eccentric. But when Darger was on his deathbed, his landlord Nathan Lerner began
    to clean out his room and discovered something incredible. Unknown to everyone
    around him, Darger had been writing and painting. Writing and painting <em>a lot</em>.
    Among the objects Lerner discovered were fifteen massive volumes comprising one
    continuous fictional work entitled <em>The Story of the Vivian Girls, in What
    is Known as the Realms of the Unreal, of the Glandeco-Angelinian War Storm Caused
    by the Child Slave Rebellion</em>. In total, the typed, single-spaced text was
    15,145 pages long—one of the longest fictional works ever produced by a human
    being, if not the longest. (Whether it is the longest or not depends on what counts
    as a single work; there are some long works of serial pulp fiction that, in total,
    are longer, but that’s only if you add up the length of hundreds of installments.)
    This was not Darger’s only writing project. There was also a sort of sequel, <em>Crazy
    House</em>, which ran to around 10,000 pages, and the 5000-page autobiography
    <em>The History of My Life</em>, as well as numerous journals and other miscellany.
    And then there were the paintings, hundreds of huge, odd-looking, compositions
    depicting battles, scenes of torture, and heroic adventures. (You can see some
    of Darger’s art thanks to Google Image Search <a href="http://images.google.com/images?hl=en&amp;q=henry+darger&amp;gbv=2&amp;biw=1218&amp;bih=673">here</a>).</p><p>It
    turned out that the paintings were illustrations for Darger’s 15,145-page masterwork,
    called <em>In The Realms Of The Unreal</em> for short. <em>In The Realms Of The
    Unreal</em> is, in some very broad sense, a fantasy novel. It takes place on a
    planet far larger than Earth, which Earth is said to orbit as a moon. This planet
    is mostly composed of Catholic nations, of which the most important to the plot
    are Angelinia, Calverinia and Abbieannia. (Protestants do not appear to exist
    in this world, though—confusingly enough—one of the Catholic nations is called
    Protestantia.) The story is about a war between the Catholic nations and the atheist
    nation Glandelinia, which is inhabited by evil, sadistic people who practice institutionalized
    child slavery. Shortly before the time period described in the text, some of the
    child slaves mounted a rebellion, led by a heroic 10-year-old named Annie Aronburg.
    The Glandelineans quashed the rebellion and killed Aronburg, but this started
    a chain of events that led to a Glandelinean invasion of Calverinia and eventually
    a full-scale war between the Catholic nations and Glandelinia. <em>In The Realms
    Of The Unreal</em> tells the story of this war, an incredibly long succession
    of huge battles, espionage missions, scenes of torture in the Glandelinean slave
    camps, and so on. The protagonists, curiously enough, are a set of seven prepubescent
    sisters—the titular Vivian girls—who follow the Christian armies, spy on the Glandelineans,
    and narrowly escape mortal danger on innumerable occasions. The battles are mostly
    realistic in nature—though they involve millions of combatants—but the world is
    an enchanted one, filled with chimeric beasts called “Blengiglomenean creatures”
    (or “Blengins,” for short) which assist and protect the Vivian girls.</p><p>…The
    problem comes when MacGregor tries to interpret the text psychologically, which
    happens often. MacGregor is a Freudian analyst—he studied with Anna Freud, in
    fact—and he is mainly interested in Darger as a psychological subject. Now, this
    is not the time or place to hash out whether Freudian psychology does or doesn’t
    succeed, generally speaking, at explaining the human mind. But even if I withhold
    judgment on MacGregor’s Freudian premises, his account of Darger’s psychology
    is just really, really bad and frustrating….So, without further ado, here are
    some interesting things about Henry Darger:</p><ul><li>In the <em>Realms</em>,
    there are numerous characters named after Darger…These Dargers do not all seem
    to be distinct in the author’s mind, and it’s often confusing which one is being
    referred to in any given instance.</li><li>Darger’s paintings are filled with
    prepubescent girls—usually the Vivian girls, but there are also sometimes anonymous
    child slaves, etc. They are usually depicted naked, even when there is no good
    reason for this…The little girls usually, but not always, have penises…</li><li>Darger
    collected lots of random junk in the course of his menial job. He was particularly
    fond of photographs of children…</li><li>The inspiration for writing the <em>Realms</em>
    was the loss of a particular newspaper clipping, a photo of Elsie Paroubek, a
    little girl who had been murdered, and whose murder was all over the Chicago papers
    for a short time. Darger’s journals express no particular interest in this picture
    <em>until</em> he discovered that he had lost it. After that, he spent much of
    the rest of his life in a profound state of anger at God, who he believed had
    taken the picture from him. He saw the fictional war between Christians and Glandelineans
    as a way of punishing God for taking the picture by causing harm to millions of
    (fictional?) Christians.</li><li>…Darger’s 5000-page work <em>The History Of My
    Life</em> is putatively an autobiography. However, that word does not accurately
    describe the vast majority of its contents. The first several hundred pages of
    the work are indeed an account of Darger’s early life. However, after describing
    a scene in which his younger self is entranced by the sight of a powerful storm,
    he apparently <em>gets distracted</em> by the storm and spends the remaining 4000-some
    pages of the text describing the wake of destruction caused by a fictional twister
    called “Sweetie Pie,” with no further mention of his own life whatsoever.</li><li>…Near
    the end of his life, Darger apparently spent a lot of time playing with string.
    In his journal he recounts collecting string and coiling and uncoiling it, and
    huge amounts of string were found in his room after his death.</li></ul><p>…Any
    account of Darger’s psychology is going to have to explain this weirdness. This
    is what, I contend, John MacGregor’s account fails to do. Fails pretty massively,
    in fact—massively enough that Darger seems less, rather than more, comprehensible
    after you read MacGregor try to “explain” him…But MacGregor also tells us that
    the battles sometimes lasted for hundreds of pages, and that they include vast
    amounts of bureaucratic detail (about particular regiments, commanders, tactical
    maneuvers, etc.—lots and lots of proper names), but that none of this detail is
    in any way self-consistent (so that it is impossible, for instance, to form a
    mental picture of the shape of the battlefield that does not distort over time).
    And that Darger is obsessed with what some might consider the more “boring” details
    of war—he spends huge amounts of time describing the way the supply lines work,
    for instance. It’s still conceivable that this sort of ridiculously long bureaucratic
    catalogue could be an expression of pent-up rage, but if so, it’s a very odd one,
    and naturally raises the question of <em>just what sort of guy</em> would deal
    with his frustrations by going home from his job every night and writing about
    the tedious technical details of a fictional war. But that’s exactly the question
    MacGregor does not want to answer… If writing this stuff was somehow pornographic
    for Darger, then how is it that so much of the text is composed of moralizing
    about the glorious Christians and the wicked Glandelineans, describing military
    maneuvers in mind-numbing detail, and so on, rather than talking about anything
    that smacks in any way of overt sexuality? Remember that this is a 15,000-page
    text in which no one ever gets it on; if we’re looking at a sexual fantasy, it
    must be <em>the coyest sexual fantasy ever produced by the human race</em>.</p>'
- - https://www.econstor.eu/bitstream/10419/204468/1/VfS-2019-Kerkhof-YouTube.pdf#page=2
  - ! 'Advertising and Content Differentiation: Evidence from YouTube'
  - Anna Kerkhof
  - 2019-09-04
  - ''
  - ! '<p>Does advertising revenue increase or diminish content differentiation in
    media markets? This paper shows that an increase in the technically feasible number
    of ad breaks per video leads to an increase in content differentiation between
    several thousand YouTube channels. I exploit two institutional features of YouTube''s
    monetization policy to identify the causal effect of advertising on the YouTubers''
    content choice. The analysis of around one million YouTube videos shows that advertising
    leads to a twenty percentage point reduction in the YouTubers'' probability to
    duplicate popular content, i.e., content in high demand by the audience. I also
    provide evidence of the economic mechanism behind the result: popular content
    is covered by many competing YouTubers; hence, viewers who perceive advertising
    as a nuisance could easily switch to a competitor if a YouTuber increased her
    number of ad-breaks per video. This is less likely, however, when the YouTuber
    differentiates her content from her competitors. [Keywords: advertising, content
    differentiation, economics of digitization, horizontal product differentiation,
    long tail, media diversity, user-generated content, YouTube]</p><p>…The analysis
    of around one million YouTube videos shows that an increase in the feasible number
    of ad breaks per video leads to a twenty percentage point reduction in the YouTubers''
    probability to duplicate popular content. The effect size is considerable: it
    corresponds to around 40% of a standard deviation in the dependent variable and
    to around 50% of its baseline value. The large sample size allows me to conduct
    several sub-group analyses to study effect heterogeneity. I find that the positive
    effect of advertising on content differentiation is driven by the YouTubers who
    have at least 1,000 subscribers,i.e., the YouTubers whose additional ad revenue
    is likely to exceed the costs from adapt-ing their videos'' content. In addition,
    I find heterogeneity along video categories: some categories are more flexible
    in terms of their typical video duration than others, hence, exploiting the ten
    minutes trick is more easy (e.g., a music clip is typically between three and
    five minutes long and cannot be easily extended). A battery of robustness checks
    confirms these results…Moreover, I show that ad revenue does not necessarily
    improve the YouTubers'' video quality. Although the number of views goes up when
    a video has more ad breaks, the relative number of likes decreases…Table 5 shows
    the results. The size of the estimates for δ′′(columns 1 to 3), though statistically
    significant at the 1%-level, is negligible: a one second increase in video duration
    corresponds to a 0.0001 percentage point increase in the fraction of likes. The
    estimates for δ′′′ in columns 4 to 6, though, are relatively large and statistically
    significant at the 1%-level, too. According to these estimates, one further second
    in video duration leads on average to about 1.5 percent more views. These estimates
    may reflect the algorithmic drift discussed in Section 9.2. YouTube wants to keep
    its viewers as long as possible on the platform to show as many ads as possible
    to them. As a result, longer videos get higher rankings and are watched more often.'
- - /docs/rotten.com/library/index.html
  - The Rotten Library archives
  - Rotten.com
  - 2019-1005
  - ''
  - ! '<p>Old Internet users will remember <a href="https://en.wikipedia.org/wiki/Rotten.com">Rotten.com</a>.
    I didn’t much care for the main site, but I enjoyed their writeups in the ‘Rotten
    Library’ section. The website has been offline for years now and shows no sign
    of coming back, so I have put up a mirror of the <a href="/docs/rotten.com/library/index.html">Rotten
    Library</a> (<a href="/docs/rotten.com/library/whatsnew/index.html">What’s
    New</a>).</p><p>You can now enjoy such classic entries as <a href="/docs/rotten.com/library/sex/penis-cakes/index.html">Penis
    Cakes</a>, <a href="/docs/rotten.com/library/crime/drugs/lsd-blotters/index.html"><span class="smallcaps-auto">LSD</span>
    blotters</a>, <a href="/docs/rotten.com/library/history/mountain-meadows-massacre/index.html">the
    Mountain Meadows Massacre</a>, <a href="/docs/rotten.com/library/sex/masturbation/kelloggs-cornflakes/index.html">Kellogg
    cornflakes</a>, <a href="/docs/rotten.com/library/hoaxes/kinderhook-plates/index.html">Kinderhook
    plates</a>, <a href="/docs/rotten.com/library/bio/crime/mafia/lucky-luciano/index.html">Lucky
    Luciano</a>, <a href="/docs/rotten.com/library/bio/hackers/kevin-mitnick/index.html">Kevin
    Mitnick</a>, <a href="/docs/rotten.com/library/culture/banned-cartoons/index.html">on
    banned cartoons</a>, &amp; <a href="/docs/rotten.com/library/bio/hackers/steve-wozniak/index.html">Steve
    Wozniak</a>.</p><p>(I used <a href="https://github.com/zscole/rotten.com">zscole’s
    archive</a>, compressed the <span class="smallcaps-auto">JPEG</span>s, and rewrote all the absolute links to make
    it work on <code>gwern.net</code>, and fixed a few errors I found along the way—principally
    broken links and links to entries which appear to’ve never been written.)</p><p>Alternate
    mirror: <a href="https://www.rottenlibrary.net/"><code>rottenlibrary.net</code></a>.</p>'
- - https://www.wired.com/2016/04/susie-mckinnon-autobiographical-memory-sdam/
  - ! 'In A Perpetual Present: The Strange Case of the Woman Who Can’t Remember Her
    Past—Or Imagine Her Future'
  - Erika Hayasaki
  - 2016-04-10
  - ''
  - ! '<p>As they regale me with talk of their younger selves and their trips to Jamaica,
    Aruba, Cozumel, and Mazatlán, they present the very picture of well-adjusted adulthood
    on the verge of retirement. Except for one fairly major thing. As we chat, McKinnon
    makes clear that she has no memories of all those cruises. No memories of buying
    the lizard or finding that oilcloth collage. She doesn’t remember any vacation
    she’s ever taken. In fact, she cannot recall a single moment in her marriage to
    Green or before it.</p> <p>For decades, scientists suspected that someone like
    Susie McKinnon might exist. They figured she was probably out there, living an
    ordinary life—hard to tell apart from the next person in line at the grocery store,
    yet fundamentally different from the rest of us. And sure enough, they found her
    (or rather, she found them) in 2006. “I don’t remember being smaller or having
    to reach up for things. I have no impressions of myself as a kid.” McKinnon is
    the first person ever identified with a condition called severely deficient autobiographical
    memory. She knows plenty of facts about her life, but she lacks the ability to
    mentally relive any of it, the way you or I might meander back in our minds and
    evoke a particular afternoon. She has no episodic memories—none of those impressionistic
    recollections that feel a bit like scenes from a movie, always filmed from your
    perspective. To switch metaphors: Think of memory as a favorite book with pages
    that you return to again and again. Now imagine having access only to the index.
    Or the Wikipedia entry.</p> <p>…McKinnon first began to realize that her memory
    was not the same as everyone else’s back in 1977, when a friend from high school,
    who was studying to be a physician’s assistant, asked if she would participate
    in a memory test as part of a school assignment. When her friend asked basic questions
    about her childhood as part of the test, McKinnon would reply, “Why are you asking
    stuff like this? No one remembers that!” She knew that other people claimed to
    have detailed memories, but she always thought they embellished and made stuff
    up—just like she did. McKinnon’s friend was so disturbed by her responses that
    she suggested McKinnon get her memory checked by a professional. McKinnon put
    the exchange aside for almost three decades. Then one day in 2004, she came across
    an article about Endel Tulving, the researcher who had originally characterized
    the difference between episodic and semantic memory.</p>'
- - https://old.reddit.com/r/SDAM/
  - /r/<span class="smallcaps-auto">SDAM</span>
  - Reddit
  - 2017-11-10
  - ''
  - <span class="smallcaps-auto">SDAM</span> (Severely Deficient Autobiographical Memory) is a relatively new discovery
    of the inability of a person to recall events in the past. It is not memory loss,
    Alzheimer's, or dementia. It is associated with the inability to vividly recall
    experiences, such as not having many, if any at all, childhood memories. Another
    example would be not remembering many details about your wedding day. <span class="smallcaps-auto">SDAM</span> seems
    to be related somewhat with Aphantasia (the inability to vividly picture things
    in your mind). Both, though, seem to exist on a spectrum. Obviously it does not
    seem to limit normal functioning or learning ability. We are here to find out
    more about it and its impacts.
- - https://www.sciencedirect.com/science/article/pii/S002839321500158X
  - ! 'Severely deficient autobiographical memory (<span class="smallcaps-auto">SDAM</span>) in healthy adults: A new
    mnemonic syndrome'
  - Daniela J. Palombo, Claude Alain, Hedvig Söderlund, Wayne Khuu, Brian Levine
  - 2015-06
  - 10.1016/j.neuropsychologia.2015.04.012
  - ! '<p><em>Highlights:</em></p><ul><li>Profoundly impaired autobiographical re-experiencing
    in healthy adults.</li><li>Deficit specific to episodic (especially visual), rather
    than semantic processes.</li><li>Impaired activation of midline structures during
    autobiographical memory retrieval.</li><li>Absence of late positive component
    with intact recognition.</li><li>Performance on everyday mnemonic tasks mediated
    by non-episodic processes.</li></ul><p><em>Abstract</em>: Recollection of previously
    experienced events is a key element of human memory that entails recovery of spatial,
    perceptual, and mental state details. While deficits in this capacity in association
    with brain disease have serious functional consequences, little is known about
    individual differences in autobiographical memory (AM) in healthy individuals.
    Recently, healthy adults with highly superior autobiographical capacities have
    been identified (e.g., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3764458/"
    title="Behavioral and neuroanatomical investigation of Highly Superior Autobiographical
    Memory (HSAM)">LePort et al 2012</a>. Here we report data from three healthy,
    high functioning adults with the reverse pattern: lifelong severely deficient
    autobiographical memory (<span class="smallcaps-auto">SDAM</span>) with otherwise preserved cognitive function. Their
    self-reported selective inability to vividly recollect personally experienced
    events from a first-person perspective was corroborated by absence of functional
    magnetic resonance imaging (f<span class="smallcaps-auto">MRI</span>) and event-related potential (<span class="smallcaps-auto">ERP</span>) biomarkers
    associated with naturalistic and laboratory episodic recollection, as well as
    by behavioral evidence of impaired episodic retrieval, particularly for visual
    information. Yet learning and memory were otherwise intact, as long as these tasks
    could be accomplished by non-episodic processes. Thus these individuals function
    normally in day-to-day life, even though their past is experienced in the absence
    of recollection. [Keywords: Episodic memory, Autobiographical memory, Hippocampus,
    Case study.]</p>'
- - https://osf.io/qr4f9/download?format=pdf
  - Individual differences in autobiographical memory
  - Daniela J. Palombo, Signy Sheldon, Brian Levine
  - 2018-07
  - 10.1016/j.tics.2018.04.007
  - ! '<p><em>Highlights</em>:</p><ul><li>The syndromes of highly superior autobiographical
    memory (<span class="smallcaps-auto">HSAM</span>) and severely deficient autobiographical memory (<span class="smallcaps-auto">SDAM</span>) have come
    under recent investigation. These syndromes pose challenges for theories of memory.</li><li>Research
    on individual differences in autobiographical memory across the spectrum have
    also emerged, complementing prior work involving individual differences in laboratory-based
    episodic memory.</li><li>Additional research that is focused on <span class="smallcaps-auto">HSAM</span> and <span class="smallcaps-auto">SDAM</span>,
    particularly those involving larger sample sizes, will provide a novel platform
    for understanding the cognitive and neural factors that are associated with the
    formation and retention of autobiographical memories.</li></ul><p>Although humans
    have a remarkable capacity to recall a wealth of detail from the past, there are
    marked interindividual differences in the quantity and quality of our mnemonic
    experiences. Such differences in autobiographical memory may appear self-evident,
    yet there has been little research on this topic. In this review, we synthesize
    an emerging body of research regarding individual differences in autobiographical
    memory. We focus on two syndromes that fall at the extremes of the ‘remembering’
    dimension: highly superior autobiographical memory (<span class="smallcaps-auto">HSAM</span>) and severely deficient
    autobiographical memory (<span class="smallcaps-auto">SDAM</span>). We also discuss findings from research on less
    extreme individual differences in autobiographical memory. This avenue of research
    is pivotal for a full description of the behavioral and neural substrates of autobiographical
    memory. [Keywords: Episodic memory, highly superior autobiographical memory, severely
    deficient autobiographical memory]</p>'
- - https://pureapps2.hw.ac.uk/ws/portalfiles/portal/8873489/Lives_without_imagery_1.pdf
  - Lives without imagery—Congenital aphantasia
  - Adam Zeman, Michaela Dewar, Sergio Della Sala
  - '2015'
  - 10.1016/j.cortex.2015.05.019
  - Presents a case report of 65 year old man. He became unable to summon images to
    the mind's eye after coronary angioplasty. Following a popular description of
    their paper, they were contacted by over twenty individuals who recognized themselves
    in the article's account of 'blind imagination', with the important difference
    that their imagery impairment had been lifelong. Here they describe the features
    of their condition, elicited by a questionnaire, and suggest a name—aphantasia—for
    this poorly recognized phenomenon. 21 individuals contacted them because of their
    lifelong reduction of visual imagery. They explored the features of their condition
    with a questionnaire devised for the purpose and the Vividness of Visual Imagery
    Questionnaire (<span class="smallcaps-auto">VVIQ</span>). Participants typically became aware of their condition in
    their teens or twenties when, through conversation or reading, they realized that
    most people who 'saw things in the mind's eye', unlike our participants, enjoyed
    a quasi-visual experience.
- - /docs/psychology/2019-wilkins.pdf
  - Reflections on the spoon test
  - Clive Wilkins, Nicola Clayton
  - '2019'
  - 10.1016/j.neuropsychologia.2019.107221
  - ! 'In this paper, we shall use Tulving''s seminal empirical and theoretical research
    including the ‘Spoon Test’ to explore memory and mental time travel and its origins
    and role in planning for the future. We will review the comparative research on
    future planning and episodic foresight in pre-verbal children and non-verbal animals
    to explore how this may be manifest as wordless thoughts. [Keywords: Mental time
    travel, episodic memory, convergent evolution of cognition, corvids, child development,
    subjective experience of thinking.]'
- - https://www.aiga.org/the-mostly-true-story-of-helvetica-and-the-new-york-city-subway
  - The (Mostly) True Story of Helvetica and the New York City Subway
  - Paul Shaw
  - 2008-11-18
  - ''
  - ! '<p>There is a commonly held belief that <a href="https://en.wikipedia.org/wiki/Helvetica">Helvetica</a>
    is <em>the</em> signage typeface of the New York City subway system, a belief
    reinforced by <a href="https://en.wikipedia.org/wiki/Helvetica_(film)"><em>Helvetica</em></a>,
    Gary Hustwit’s popular 2007 documentary about the typeface. But it is not true—or
    rather, it is only somewhat true. Helvetica is the official typeface of the <a
    href="https://en.wikipedia.org/wiki/Metropolitan_Transportation_Authority"><span class="smallcaps-auto">MTA</span></a>
    today, but it was not the typeface specified by <a href="https://en.wikipedia.org/wiki/Unimark_International">Unimark
    International</a> when it created a new signage system at the end of the 1960s.
    Why was Helvetica not chosen originally? What was chosen in its place? Why is
    Helvetica used now, and when did the changeover occur? To answer those questions
    this essay explores several important histories: of the <a href="https://en.wikipedia.org/wiki/New_York_City_Subway">New
    York City subway system</a>, transportation signage in the 1960s, Unimark International
    and, of course, Helvetica. These four strands are woven together, over nine pages,
    to tell a story that ultimately transcends the simple issue of Helvetica and the
    subway.</p><p>…The sign system that Noorda and <a href="https://en.wikipedia.org/wiki/Massimo_Vignelli">Vignelli</a>
    first proposed to the <span class="smallcaps-auto">NYCTA</span> in 1966 has proved remarkably resilient. It endures
    today despite a number of severe changes that make one wonder if it can even be
    attributed to them and Unimark anymore. Their modular system survives but only
    as graphic units rather than physical components. The black stripe, mistakenly
    created by the sign shop but then integrated into the 1970 standards manual, exists
    in a variety of colors and iterations. The black-on-white color scheme is now
    reversed. The colored disks are still used—some with the original artwork—but
    the colors themselves have changed. Finally, Standard Medium has given way to
    Helvetica Medium—or, more accurately, to Neue Helvetica 65. Yet not only is the
    Unimark <span class="smallcaps-auto">DNA</span> still in evidence but it has served as the basis for a much broader
    transportation system identity. So, the answer to whether or not Helvetica is
    the typeface of the New York City subway system is that it is—but that it was
    not.</p>'
- - http://discovery.ucl.ac.uk/10080409/8/Bradley_10080409_thesis.pdf
  - On the Resilience of the Dark Net Market Ecosystem to Law Enforcement Intervention
  - Cerys Bradley
  - 2019-08
  - ''
  - <p>Dark Net Markets (<span class="smallcaps-auto">DNM</span>s) are websites found on the Dark Net that facilitate
    the anonymous trade of illegal items such as drugs and weapons. Despite repeated
    law enforcement interventions on <span class="smallcaps-auto">DNM</span>s, the ecosystem has continued to grow since
    the first <span class="smallcaps-auto">DNM</span>, Silk Road, in 2011. This research project investigates the resilience
    of the ecosystem and tries to understand which characteristics allow it to evade
    law enforcement.</p><p>This thesis is comprised of three studies. The first uses
    a dataset contained publicly available, scraped data from 34 <span class="smallcaps-auto">DNM</span>s to quantitatively
    measure the impact of a large-scale law enforcement operation, Operation Onymous,
    on the vendor population. This impact is compared to the impact of the closure
    of the <span class="smallcaps-auto">DNM</span> Evolution in an exit scam. For both events, the impact on different
    vendor populations (for example those who are directly affected and those who
    aren’t) are compared and the characteristics that make vendors resilient to each
    event are investigated.</p><p>In the second study, a dataset acquired from the
    server of the <span class="smallcaps-auto">DNM</span> Silk Road 2.0 [by UK <span class="smallcaps-auto">LEA</span>] is used to better understand the relationships
    between buyers and vendors. Network analysis and statistical techniques are used
    to explore when buyers trade and who with. This dataset is also used to measure
    the impact of a hack on Silk Road 2.0 on its population.</p><p>In the final study,
    discussions from the forum site Reddit were used to qualitatively assess user
    perceptions of two law enforcement interventions. These interventions were distinct
    in nature&mdash;one, Operation Hyperion, involved warning users and arresting
    individuals and the second, Operation Bayonet, actively closed a <span class="smallcaps-auto">DNM</span>. Grounded
    Theory was used to identify topics of conversation and directly compare the opinions
    held by users on each intervention.</p><p>These studies were used to evaluate
    hypotheses incorporated into two models of resilience. One model focuses on individual
    users and one on the ecosystem as a whole. The models were then used to discuss
    current law enforcement approaches on combating <span class="smallcaps-auto">DNM</span>s and how they might be improved.</p>
    <p>In the first study of this thesis, several methodologies for data preparation
    and validation within the study of <span class="smallcaps-auto">DNM</span>s were developed. In particular, this work
    presents a new technique for validating a publicly available dataset that has
    been used in multiple studies in this field. This is the first attempt to formally
    validate the dataset and determine what can reasonably used for research. The
    discussion of the dataset has implications for research already using the dataset
    and future research on datasets collected using the same methodology.</p><p>In
    order to conduct the second study in this thesis, a dataset was acquired from
    a law enforcement agency. This dataset gives a new insight on how buyers behave
    on <span class="smallcaps-auto">DNM</span>s. Buyers are an unstudied group because their activities are often hidden
    and so analysis of this dataset reveals new insights into the behaviour of these
    users. The results of this study have been used to comment on existing work using
    less complete datasets and contribute new findings.</p><p>The third study in this
    thesis presents a qualitative analysis of two law enforcement interventions. This
    is the first work to assess the impact of either intervention and so provides
    new insights into how they were received by the <span class="smallcaps-auto">DNM</span> ecosystem. It uses qualitative
    techniques which are rare within this discipline and so provides a different perspective,
    for example by revealing how individuals perceive the harms of law enforcement
    interventions on <span class="smallcaps-auto">DNM</span>s. The value of this work has been recognised through its
    acceptance at a workshop at the <span class="smallcaps-auto">IEEE</span> European Symposium on Security and Privacy,
    2019.</p><p>Part of this research has been conducted in consultation with a [UK]
    law enforcement agency who provided data for this research. The results of this
    research are framed specifically for this agency and other law enforcement groups
    currently investigating <span class="smallcaps-auto">DNM</span>s. Several suggestions are made on how to improve the
    efficacy of law enforcement interventions on <span class="smallcaps-auto">DNM</span>s</p><p>…A response to the criticisms
    of (Dolliver (2015a)) has been presented in (Dolliver (2015b)). Here, Dolliver
    (2015b) attempts to provide further evidence that Silk Road 2.0 overestimated
    the number of listings advertised by including the results of a manual inspection
    of the site (Dolliver (2015b)). The response also calls into question the use
    of the Branwen dataset which was collected by an independent researcher and has
    not been peer-reviewed. Dolliver (2015b) claims that the “manually crawling approach”
    adopted by Van Buskirk et al. (2015) is also problematic as it will miss listings
    that are uploaded and removed during the time it takes to crawl the site. Finally,
    other, unpublished datasets cited in (Dolliver (2015b)) also point to Silk Road
    2.0 being especially volatile in nature before it was closed down and show that
    the number of listings varied by thousands from week to week. This volatility
    could potentially explain the contradicting depictions of Silk Road 2.0 given
    by (Dolliver (2015a)) and (Munksgaard et al. (2016)) and allow for both studies
    to have accurately described the site. However, empirical evidence in the form
    of police reports that describe the size of Silk Road 2.0 after its closure shows
    that the data collected by Dolliver (2015a) is an underestimate. Indeed, new data
    presented in this body of work also demonstrates that Silk Road 2.0 was bigger
    than Dolliver (2015a) claims, even at the beginning of its lifetime.</p>
- - /docs/economics/2018-buterin.pdf
  - ! 'Liberal Radicalism: A Flexible Design For Philanthropic Matching Funds'
  - Vitalik Buterin, Zoë Hitzig, E. Glen Weyl
  - 2018-12-31
  - 10.2139/ssrn.3243656
  - ! 'We propose a design for philanthropic or publicly-funded seeding to allow (near)
    optimal provision of a decentralized, self-organizing ecosystem of public goods.
    The concept extends ideas from <a href="https://www8.gsb.columbia.edu/faculty-research/sites/faculty-research/files/finance/QV_Intro_Final.pdf"
    title="''Quadratic Voting and the Public Good: Introduction'', Posner & Weyl 2017">Quadratic
    Voting</a> to a funding mechanism for endogenous community formation. Citizens
    make public goods contributions to projects of value to them. The amount received
    by the project is (proportional to) the square of the sum of the square roots
    of contributions received. Under the "standard model" this yields first best public
    goods provision. Variations can limit the cost, help protect against collusion
    and aid coordination. We discuss applications to campaign finance, open source
    software ecosystems, news media finance and urban public projects. More broadly,
    we relate our mechanism to political theory, discussing how this solution to the
    public goods problem may furnish neutral and non-authoritarian rules for society
    that nonetheless support collective organization.'
- - https://www.fordfoundation.org/media/2976/roads-and-bridges-the-unseen-labor-behind-our-digital-infrastructure.pdf
  - ! 'Roads and Bridges: The Unseen Labor Behind Our Digital Infrastructure'
  - Nadia Eghbal
  - 2016-06-08
  - ''
  - ! '<p>[Post-<a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a>/<a
    href="https://en.wikipedia.org/wiki/Shellshock_(software_bug)">Shellshock</a>
    discussion of the economics of funding open source software: universally used
    &amp; economically invaluable as a public good anyone can &amp; does use, it is
    also essentially completely unfunded, leading to serious problems in long-term
    maintenance &amp; improvement, exemplified by the Heartbleed bug—core cryptographic
    code run by almost every networked device on the planet could not fund more than
    a part-time developer.]</p><p>Our modern society—everything from hospitals to
    stock markets to newspapers to social media—runs on software. But take a closer
    look, and you’ll find that the tools we use to build software are buckling under
    demand…Nearly all software today relies on free, public code (called “open source”
    code), written and maintained by communities of developers and other talent. Much
    like roads or bridges, which anyone can walk or drive on, open source code can
    be used by anyone—from companies to individuals—to build software. This type of
    code makes up the digital infrastructure of our society today. Just like physical
    infrastructure, digital infrastructure needs regular upkeep and maintenance. In
    the United States, over half of government spending on transportation and water
    infrastructure goes just to maintenance.<sup>1</sup> But financial support for
    digital infrastructure is much harder to come by. Currently, any financial support
    usually comes through sponsorships, direct or indirect, from software companies.
    Maintaining open source code used to be more manageable. Following the personal
    computer revolution of the early 1980s, most commercial software was proprietary,
    not shared. Software tools were built and used internally by companies, and their
    products were licensed to customers. Many companies felt that open source code
    was too nascent and unreliable for commercial use. In their view, software was
    meant to be charged for, not given away for free. Today, everybody uses open source
    code, including Fortune 500 companies, government, major software companies and
    startups. Sharing, rather than building proprietary code, turned out to be cheaper,
    easier, and more efficient.</p><p>This increased demand puts additional strain
    on those who maintain this infrastructure, yet because these communities are not
    highly visible, the rest of the world has been slow to notice. Most of us take
    opening a software application for granted, the way we take turning on the lights
    for granted. We don’t think about the human capital necessary to make that happen.
    In the face of unprecedented demand, the costs of not supporting our digital infrastructure
    are numerous. On the risk side, there are security breaches and interruptions
    in service, due to infrastructure maintainers not being able to provide adequate
    support. On the opportunity side, we need to maintain and improve these software
    tools in order to support today’s startup renaissance, which relies heavily on
    this infrastructure. Additionally, open source work builds developers’ portfolios
    and helps them get hired, but the talent pool is remarkably less diverse than
    in tech overall. Expanding the pool of contributors can positively affect who
    participates in the tech industry at large.</p><p>No individual company or organization
    is incentivized to address the problem alone, because open source code is a public
    good. In order to support our digital infrastructure, we must find ways to work
    together. Current examples of efforts to support digital infrastructure include
    the Linux Foundation’s Core Infrastructure Initiative and Mozilla’s Open Source
    Support (<span class="smallcaps-auto">MOSS</span>) program, as well as numerous software companies in various capacities.
    Sustaining our digital infrastructure is a new topic for many, and the challenges
    are not well understood. In addition, infrastructure projects are distributed
    across many people and organizations, defying common governance models. Many infrastructure
    projects have no legal entity at all. Any support strategy needs to accept and
    work with the decentralized, community-centric qualities of open source code.
    Increasing awareness of the problem, making it easier for institutions to contribute
    time and money, expanding the pool of open source contributors, and developing
    best practices and policies across infrastructure projects will all go a long
    way in building a healthy and sustainable ecosystem.</p>'
- - https://gitcoin.co/blog/gitcoin-grants-clr-matching/
  - ! 'Gitcoin Grants: <span class="smallcaps-auto">CLR</span> Matching—Matching contributions with up to $25,000 in funding,
    in <span class="smallcaps-auto">ETH</span>'
  - Vivek Singh
  - 2019-02-01
  - ''
  - ! '<p>Gitcoin is excited to announce our first formal experiment with <span class="smallcaps-auto">CLR</span>, with
    $25,000 in matching contributions from Gitcoin’s <span class="smallcaps-auto">CLR</span> Fund. Our sponsors for this
    fund include the Ethereum Foundation and ConsenSys, via their respective grants
    programs, and unnamed donors in the Ethereum ecosystem.</p><p>As outlined in <a
    href="https://gitcoin.co/blog/experiments-with-liberal-radicalism/" title="Experiments
    With Liberal Radicalism: A crowdfund matching mechanism for public goods, like
    open source">our recent post</a>, the <span class="smallcaps-auto">CLR</span> mechanism is a concrete proposal for
    turning your small donations into something much larger. It requires a simple
    formula to achieve this goal.</p><ol type="1"><li><strong>Crowdfund</strong> individual
    donations towards open source projects.</li><li>A <strong>match</strong> from
    governments, grant programs, or private philanthropists</li></ol><p>We are providing
    the $25,000 match…<span class="smallcaps-auto">EDIT</span> 2019/02/23: Results announced <a href="https://gitcoin.co/blog/radical-results-gitcoins-25k-match/"
    title="Radical Results: Gitcoin&#39;s $25K Match—Results and lessons learned from
    our first $25K in matching"><em>here</em></a>.</p>'
- - https://gitcoin.co/blog/experiments-with-liberal-radicalism/
  - ! 'Experiments With Liberal Radicalism: A crowdfund matching mechanism for public
    goods, like open source'
  - Vivek Singh
  - 2019-01-16
  - ''
  - ! '<p>By making an individual donation, you contribute to a public good. This
    funding is guaranteed to be met by matching funding, widening the reach of your
    donation. What you do becomes “law.” By donating with one to one matching, you
    increase the power of any single donation in direct proportion to the size of
    the donation, making people more likely to feel like their money is having an
    impact. This is the premise of “Donate $1, [Company X] will match $1” programs.
    <span class="smallcaps-auto">CLR</span> takes this one step further, by emphasizing the importance of unique, individual
    contributors—even if they each only contribute a small amount. In short, while
    matching programs have traditionally chosen ‘equal matching’ by default, <span class="smallcaps-auto">CLR</span> tries
    to answer the question: When funding public goods, what is the ‘optimal’ match
    to maximize individual donations?</p><p>There’s a great amount of experimentation
    in sustaining open source (the Lemonade Stand by Nadia Eghbal is a seminal resource,
    for those interested). Yet, naturally, it’s hard to solve the problem from the
    ground up. Public goods are simply <em>hard</em> to fund. If we <em>could</em>
    find ‘ground up’ solutions, we can shift our open source conversations from ‘sustaining
    open source’ (all we can ask for, today) to ‘growing open source’ to promote a
    thriving, healthy internet infrastructure. The <span class="smallcaps-auto">CLR</span> mechanism is a concrete proposal
    for making grassroots donations something much larger. It requires a simple formula
    to achieve this goal.</p><ol type="1"><li>Crowdfund individual donations towards
    open source projects.</li><li>‘Match’ or ‘top-off’ the contributions of individuals
    from government, grant, or private philanthropy funding</li></ol><p>This is something
    we’re obviously interested in at Gitcoin. It just so happens we’ve launched a
    crowdfunding platform aiming contributions towards open source projects with Gitcoin
    Grants. The timing to explore <span class="smallcaps-auto">CLR</span> couldn’t be better.</p><p>…Gitcoin Grants, given
    Sybil / resistance via our Github integration, may be one of the best suited parties
    to help implement <a href="/docs/economics/2018-buterin.pdf">"Liberal
    Radicalism"</a> ideas in a real and constructive way, within open source communities.
    These experiments fit quite well with what we’re doing both at Gitcoin Labs and
    Gitcoin Grants. We plan to carry on with <span class="smallcaps-auto">CLR</span> experiments. Please feel join our
    public Discourse around the topic and share with anyone who you think might be
    interested in contributing to the discussion. We don’t expect Liberal Radicalism
    to be a panacea, but are excited to engage in conversation and experimentation
    along the way. We look forward to continued conversation with the RadicalxChange
    community as we continue our research into structural support for a more resilient,
    open internet.</p>'
- - https://gitcoin.co/blog/radical-results-gitcoins-25k-match/
  - ! 'Radical Results: Gitcoin’s $25K Match—Results and lessons learned from our
    first $25K in matching'
  - Vivek Singh
  - 2019-02-22
  - ''
  - <p>A few weeks ago, we announced a radical experiment in Open Source Funding.
    Using the matching method outlined in <a href="/docs/economics/2018-buterin.pdf">“Liberal
    Radicalism”</a>—a paper by Glen Weyl, Vitalik Buterin, and Zoë Hitzig—we announced
    a $25K fund to match any contributions made to 25 Ethereum infrastructure projects.</p><p>Gitcoin’s
    <span class="smallcaps-auto">CLR</span> Matching, By The Numbers</p><ul><li>The top three projects in matching funding
    for this round were <em>Prysmatic Labs</em>, <em>Moloch <span class="smallcaps-auto">DAO</span></em>, and <em>Uniswap</em></li><li><em>$13,242</em>
    was contributed by <em>132 unique</em> contributors across <em>26 projects</em></li><li>The
    <em>top 10</em> projects all received over <em>$1,000</em> in matching donations
    from the <span class="smallcaps-auto">CLR</span> fund</li><li>A total of <em>$38,242</em> was contributed to Ethereum
    <span class="smallcaps-auto">OSS</span> infrastructure in two weeks</li></ul><p>…We are encouraged by the results
    made in the first round of <span class="smallcaps-auto">CLR</span> matching and are hopeful for the emergence of new
    mechanisms to enable funding to public goods. We’ll explore a few of these in
    future rounds, and are especially interested in inflation funding mechanisms to
    fund public infrastructure.</p>
- - https://numinous.productions/ttft/
  - How Can We Develop Transformative Tools For Thought?
  - <a href="https://andymatuschak.org/">Andy Matuschak</a>, <a href="http://michaelnielsen.org/">Michael
    Nielsen</a>
  - 2019-10
  - ''
  - ! '<p>[Long writeup on experiment in integrating <a href="/Spaced-repetition">spaced
    repetition systems</a> with a tutorial on quantum computing, <a href="https://quantum.country/qcvc"
    title="Presented in a new mnemonic medium which makes it almost effortless to
    remember what you read."><em>Quantum Country: Quantum Computing For The Very Curious</em></a>
    By combining explanation with spaced testing, a notoriously thorny subject may
    be learned more easily and then actually remembered—such a system demonstrating
    a possible ‘tool for thought’. Early results indicate users do indeed remember
    the quiz answers, and feedback has been positive.]</p><p><strong>Part I: Memory
    systems</strong></p><ul><li>Introducing the mnemonic medium</li><li>The early
    impact of the prototype mnemonic medium</li><li>Expanding the scope of memory
    systems: what types of understanding can they be used for?</li><li>Improving the
    mnemonic medium: making better cards</li><li>Two cheers for mnemonic techniques</li><li>How
    important is memory, anyway?</li><li>How to invent Hindu-Arabic numerals?</li></ul><p><strong>Part
    II: Exploring tools for thought more broadly</strong>:</p><ul><li><p>Mnemonic
    video</p></li><li><p>Why isn’t there more work on tools for thought today?</p></li><li><p>Questioning
    our basic premises</p><ul><li>What if the best tools for thought have already
    been discovered?</li><li>Isn’t this what the tech industry does? Isn’t there a
    lot of ongoing progress on tools for thought?</li><li>Why not work on <span class="smallcaps-auto">AGI</span> or <span class="smallcaps-auto">BCI</span>
    instead?</li></ul></li><li><p>Executable books</p><ul><li>Serious work and the
    aspiration to canonical content</li><li>Stronger emotional connection through
    an inverted writing structure</li></ul></li></ul><p><strong>Summary and Conclusion</strong></p><p>…
    in <em>Quantum Country</em> an expert writes the cards, an expert who is skilled
    not only in the subject matter of the essay, but also in strategies which can
    be used to encode abstract, conceptual knowledge. And so <em>Quantum Country</em>
    provides a much more scalable approach to using memory systems to do abstract,
    conceptual learning. In some sense, <em>Quantum Country</em> aims to expand the
    range of subjects users can comprehend at all. In that, it has very different
    aspirations to all prior memory systems.</p><p>More generally, we believe memory
    systems are a far richer space than has previously been realized. Existing memory
    systems barely scratch the surface of what is possible. We’ve taken to thinking
    of <em>Quantum Country</em> as a <em>memory laboratory</em>. That is, it’s a system
    which can be used both to better understand how memory works, and also to develop
    new kinds of memory system. We’d like to answer questions such as:</p><ul><li>What
    are new ways memory systems can be applied, beyond the simple, declarative knowledge
    of past systems?</li><li>How deep can the understanding developed through a memory
    system be? What patterns will help users deepen their understanding as much as
    possible?</li><li>How far can we raise the human capacity for memory? And with
    how much ease? What are the benefits and drawbacks?</li><li>Might it be that one
    day most human beings will have a regular <em>memory practice</em>, as part of
    their everyday lives? Can we make it so memory becomes a choice; is it possible
    to in some sense solve the problem of memory?</li></ul>'
- - https://github.com/lllyasviel/style2paints
  - Style2Paints GitHub repository
  - Lvmin Zhang, Chengze Li, Tien-Tsin Wong, Yi Ji, Chunping Liu
  - 2018-05-04
  - ''
  - <p>Github repo with screenshot samples of <em>style2paints</em>, a neural network
    for colorizing anime-style illustrations (trained on Danbooru2018), with or without
    user color hints, which was available as an online service in 2018. style2paints
    produces high-quality colorizations often on par with human colorizations. Many
    examples can be seen on <a href="https://twitter.com/iliiliiillillii">Twitter</a>
    or the Github repo:</p><figure><img src="/images/gan/2018-zhang-style2paints-colorizationexample-hana.jpg"
    alt="Example style2paints colorization of a character from the anime <em>Prison School</em> (https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/show/8.jpg)" /><figcaption>Example
    style2paints colorization of a character from <em>Prison School</em></figcaption></figure><p>style2paints
    has been described in more detail in <a href="/docs/anime/2018-zhang.pdf">“Two-Stage
    Sketch Colorization”</a>, Zhang et al 2018:</p><blockquote><p>Sketch or line art
    colorization is a research field with significant market demand. Different from
    photo colorization which strongly relies on texture information, sketch colorization
    is more challenging as sketches may not have texture. Even worse, color, texture,
    and gradient have to be generated from the abstract sketch lines. In this paper,
    we propose a semi-automatic learning-based framework to colorize sketches with
    proper color, texture as well as gradient. Our framework consists of two stages.
    In the first drafting stage, our model guesses color regions and splashes a rich
    variety of colors over the sketch to obtain a color draft. In the second refinement
    stage, it detects the unnatural colors and artifacts, and try to fix and refine
    the result.Comparing to existing approaches, this two-stage design effectively
    divides the complex colorization task into two simpler and goal-clearer subtasks. This
    eases the learning and raises the quality of colorization. Our model resolves
    the artifacts such as water-color blurring, color distortion, and dull textures.</p><p>We
    build an interactive software based on our model for evaluation. Users can iteratively
    edit and refine the colorization. We evaluate our learning model and the interactive
    system through an extensive user study. Statistics shows that our method outperforms
    the state-of-art techniques and industrial applications in several aspects including,
    the visual quality, the ability of user control, user experience, and other metric</p></blockquote>
- - https://openai.com/blog/solving-rubiks-cube/
  - Solving Rubik's Cube with a Robot Hand
  - OpenAI et al 2019
  - 2019-10-15
  - ''
  - <p>[On <a title="Solving Rubik's Cube with a Robot Hand" href="https://arxiv.org/abs/1910.07113#openai">Akkaya
    et al 2019</a>.]</p> <p>We’ve trained a pair of neural networks to solve the Rubik’s
    Cube with a human-like robot hand. The neural networks are trained entirely in
    simulation, using the same reinforcement learning code as OpenAI Five paired with
    a new technique called Automatic Domain Randomization (<span class="smallcaps-auto">ADR</span>). The system can handle
    situations it never saw during training, such as being prodded by a stuffed giraffe.
    This shows that reinforcement learning isn’t just a tool for virtual tasks, but
    can solve physical-world problems requiring unprecedented dexterity.</p> <p>…Since
    May 2017, we’ve been trying to train a human-like robotic hand to solve the Rubik’s
    Cube. We set this goal because we believe that successfully training such a robotic
    hand to do complex manipulation tasks lays the foundation for general-purpose
    robots. We solved the Rubik’s Cube in simulation in July 2017. But as of July
    2018, we could only manipulate a block on the robot. Now, we’ve reached our initial
    goal. Solving a Rubik’s Cube one-handed is a challenging task even for humans,
    and it takes children several years to gain the dexterity required to master it.
    Our robot still hasn’t perfected its technique though, as it solves the Rubik’s
    Cube 60% of the time (and only 20% of the time for a maximally difficult scramble).</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.8670&rep=rep1&type=pdf
  - Chess Masters' Hypothesis Testing
  - Michelle Cowley, Ruth M. J. Byrne
  - '2004'
  - ''
  - Falsification may demarcate science from non-science as the rational way to test
    the truth of hypotheses. But experimental evidence from studies of reasoning shows
    that people often find falsification difficult. We suggest that domain expertise
    may facilitate falsification. We consider new experimental data about chess experts’
    hypothesis testing. The results show that chess masters were readily able to falsify
    their plans. They generated move sequences that falsified their plans more readily
    than novice players, who tended to confirm their plans. The finding that experts
    in a domain are more likely to falsify their hypotheses has important implications
    for the debate about human rationality.
- - http://r.cs.purdue.edu/pub/ecoop12.pdf
  - ! 'Evaluating the Design of the R Language: Objects and Functions for Data Analysis'
  - Floreal Morandat, Brandon Hill, Leo Osvald, Jan Vitek
  - 2012-06-11
  - 10.1007/978-3-642-31057-7_6
  - ! '<p>[Parsing <span class="smallcaps-auto">CRAN</span> to see what in the strange set of R features are actually
    used in the real world—not <a href="https://en.wikipedia.org/wiki/Lazy_evaluation">laziness</a>
    or its weirdo context-dependent <a href="https://en.wikipedia.org/wiki/Scope_(computer_science)">scoping</a>,
    turns out.]</p><p>R is a dynamic language for statistical computing that combines
    lazy functional features and object-oriented programming. This rather unlikely
    linguistic cocktail would probably never have been prepared by computer scientists,
    yet the language has become surprisingly popular. With millions of lines of R
    code available in repositories, we have an opportunity to evaluate the fundamental
    choices underlying the R language design. Using a combination of static and dynamic
    program analysis we assess the success of different language features.</p><ul><li>…<em>Corpus
    Gathering</em>: We curated a large corpus of R programs composed of over 1000
    executable R packages from the Bioconductor and <span class="smallcaps-auto">CRAN</span> repositories, as well as
    hand picked end-user codes and small performance benchmark programs that we wrote
    ourselves.</li><li><em>Implementation Evaluation</em>: We evaluate the status
    of the R implementation. While its speed is not acceptable for use in production
    systems, many end users report being vastly more productive in R than in other
    languages. R is decidedly single-threaded, its semantics has no provisions for
    concurrency, and its implementation is hopelessly non-thread safe. Memory usage
    is also an issue; even small programs have been shown to use immoderate amounts
    of heap for data and meta-data. Improving speed and memory usage will require
    radical changes to the implementation, and a tightening of the language definition.</li><li><em>Language
    Evaluation</em>: We examine the usage and adoption of different language features.
    R permits many programming styles, access to implementation details, and little
    enforcement of data encapsulation. Given the large corpus at hand, we look at
    the usage impacts of these design decisions.</li></ul><p>…Given the nature of
    R, many numerical functions are written in C or Fortran; one could thus expect
    execution time to be dominated by native libraries. The time spent in calls to
    foreign functions, on average 22%, shows that this is clearly not the case.</p><p>…As
    a language, R is like French; it has an elegant core, but every rule comes with
    a set of ad-hoc exceptions that directly contradict it.</p>'
- - https://fontsinuse.com/uses/28760/neon-genesis-evangelion
  - ! '<em>Neon Genesis Evangelion</em>: Graphic designer Peiran Tan plumbs the typographic
    psyche of the celebrated anime franchise'
  - Peiran Tan
  - 2019-10-17
  - ''
  - ! '<p>[A look into the signature typefaces of <em>Evangelion</em>: Matisse EB,
    mechanical compression for distorted resizing, and <a href="https://en.wikipedia.org/wiki/Intertitle">title
    cards</a>. Covered typefaces: Matisse/Helvetica/Neue Helvetica/Times/Helvetica
    Condensed/Chicago/Cataneo/Futura/Eurostile/<span class="smallcaps-auto">ITC</span> Avant Garde Gothic/Gill Sans.]</p>
    <p><em>Evangelion</em> was among the first anime to create a consistent typographic
    identity across its visual universe, from title cards to <span class="smallcaps-auto">NERV</span>’s user interfaces.
    Subcontractors usually painted anything type-related in an anime by hand, so it
    was a novel idea at the time for a director to use desktop typesetting to exert
    typographic control. Although sci-fi anime tended to use either sans serifs or
    hand lettering that mimicked sans serifs in 1995, Anno decided to buck that trend,
    choosing a display serif for stronger visual impact. After flipping through iFontworks’
    specimen catalog, he personally selected the extra-bold (EB) weight of <strong>Matisse</strong>
    (マティス), a Mincho-style serif family… A combination of haste and inexperience gave
    Matisse a plain look and feel, which turned out to make sense for <em>Evangelion</em>.
    The conservative skeletal construction restrained the characters’ personality
    so it wouldn’t compete with the animation; the extreme stroke contrast delivered
    the desired visual punch. Despite the fact that Matisse was drawn on the computer,
    many of its stroke corners were rounded, giving it a hand-drawn, <em>fin-de-siècle</em>
    quality.</p><p>…In addition to a thorough graphic identity, <em>Evangelion</em>
    also pioneered a deep integration of typography as a part of animated storytelling—a
    technique soon to be imitated by later anime. Prime examples are the show’s title
    cards and flashing type-only frames mixed in with the animation. The title cards
    contain nothing but crude, black-and-white Matisse EB, and are often mechanically
    compressed to fit into interlocking compositions. This brutal treatment started
    as a hidden homage to the title cards in old Toho movies from the sixties and
    seventies, but soon became visually synonymous with <em>Evangelion</em> after
    the show first aired. Innovating on the media of animated storytelling, <em>Evangelion</em>
    also integrates type-only flashes. Back then, these black-and-white, split-second
    frames were Anno’s attempt at imprinting subliminal messages onto the viewer,
    but have since become Easter eggs for die-hard <em>Evangelion</em> fans as well
    as motion signatures for the entire franchise.</p><p>…Established in title cards,
    this combination of Matisse EB and all-caps Helvetica soon bled into various aspects
    of <em>Evangelion</em>, most notably the <span class="smallcaps-auto">HUD</span> user interfaces in <span class="smallcaps-auto">NERV</span>. Although
    it would be possible to attribute the mechanical compression to technical limitations
    or typographic ignorance, its ubiquitous occurrence did evoke haste and, at times,
    despair—an emotional motif perfectly suited to a post-apocalyptic story with existentialist
    themes.</p>'
- - http://klenow.com/Jones_Klenow.pdf
  - Beyond GDP? Welfare across Countries and Time
  - Charles I. Jones, Peter J. Klenow
  - '2016'
  - 10.1257/aer.20110236
  - ! '<p>We propose a summary statistic for the economic well-being of people in
    a country. Our measure incorporates consumption, leisure, mortality, and inequality,
    first for a narrow set of countries using detailed micro data, and then more broadly
    using multi-country datasets. While welfare is highly correlated with <span class="smallcaps-auto">GDP</span> per
    capita, deviations are often large. Western Europe looks considerably closer to
    the United States, emerging Asia has not caught up as much, and many developing
    countries are further behind. Each component we introduce plays a significant
    role in accounting for these differences, with mortality being most important.</p><p><strong>Key
    Point</strong> 1: <em><span class="smallcaps-auto">GDP</span> per person is an excellent indicator of welfare across
    the broad range of countries: the two measures have a correlation of 0.98. Nevertheless,for
    any given country, the difference between the two measures can be important. Across
    13 countries, the median deviation is about 35%.</em></p><p>Figure 5 illustrates
    this first point. The top panel plots the welfare measure, λ, against <span class="smallcaps-auto">GDP</span> per
    person. What emerges prominently is that the two measures are highly correlated,
    with a correlation coefficient (for the logs) of 0.98. Thus per capita <span class="smallcaps-auto">GDP</span> is
    a good proxy for welfare under our assumptions. At the same time, there are clear
    departures from the 45° line. In particular, many countries with very low <span class="smallcaps-auto">GDP</span>
    per capita exhibit even lower welfare. As a result, welfare is more dispersed
    (standard deviation of 1.51 in logs) than is income (standard deviation of 1.27
    in logs).</p><p>The bottom panel provides a closer look at the deviations. This
    figure plots the ratio of welfare to per capita <span class="smallcaps-auto">GDP</span> across countries. The European
    countries have welfare measures 22% higher than their incomes. The remaining countries,
    in contrast, have welfare levels that are typically 25–50% below their incomes.
    The way to reconcile these large deviations with the high correlation between
    welfare and income is that the “scales” are so different. Incomes vary by more
    than a factor of 64 in our sample, i.e., 6,300%, whereas the deviations are on
    the order of 25–50%.</p>'
- - https://alexandercoppock.com/papers/CHV_ads.pdf
  - ! 'Persuasive Effects of Presidential Campaign Advertising: Results of 53 Real-time
    Experiments in 2016'
  - Alexander Coppock, Seth J. Hill, Lynn Vavreck
  - 2019-08-23
  - ''
  - <p>In this letter, we report the results of 53 randomized advertising experiments
    conducted over 29 weeks on 34,000 people during the US 2016 Presidential election.
    Our treatments were drawn in real time from advertisements on air each week. The
    ads vary on many dimensions:election type (primary or general), tone (attack or
    promotional), sponsor (candidates or Super<span class="smallcaps-auto">PACS</span>), context (timing), and content
    (topics). We manipulate which ads respondents see, when they see them, whether
    they see more than one ad, which ad they see first, and whether they see competing,
    reinforcing, or no additional information. Owing to the large size of our study,
    the meta-analytic estimates of the average treatment effects on favorability and
    vote choice are sometimes distinguishable from zero, but are always quite modest,
    even accounting for variation across advertisements and contexts…We conducted
    53 survey experiments over 29 weeks on nationally representative samples totaling
    34,000 people over 8 months of 2016 campaign.</p><p>…We conducted 53 survey experiments
    over 29 weeks on nationally-representative samples totaling 34,000 people over
    8 months of 2016 campaign. The ads we test are actual presidential advertisements
    resulting from strategies of presidential candidates trying to win the highest
    office in the land over the entire campaign. In this sense, our treatments—both
    content and timing—are determined by the equilibrium strategies of people who
    are highly motivated to persuade voters and win campaigns. This unique design
    (a) tests the ads that the best in the business thought would be effective and
    (b) maximizes external validity because these were the actual ads seen by voters
    delivered contemporaneously by the campaign.</p><p>Week after week, ad after ad,
    our experiments return modest effects. The estimated effects are <em>consistently</em>
    modest across many variations in tone, content, sponsor, election type, context,
    information environments, and characteristics of people. On some outcomes (respondents’
    positions on the issues in the ads, the importance of the topics in the ads) we
    find effects that are so small they are essentially non-existent even though we
    can estimate them very precisely. On candidate favorability and vote choice, we
    find slightly larger effects that we can sometimes isolate from zero, but that
    look remarkably similar in magnitude across candidates and features of ads.</p>
- - /Statistical-notes#program-for-non-spaced-repetition-review-of-past-written-materials-for-serendipity-rediscovery-archive-revisiter
  - ! 'Anti-Spaced Repetition: A Program For Non-Spaced-Repetition Review Of Past
    Written Materials For Serendipity & Rediscovery In Personal Archives'
  - Gwern Branwen
  - 2017-03-25
  - ''
  - ! '<p><a href="/Spaced-repetition">“Spaced repetition”</a>
    helps one remember facts by creating discrete flashcards which one tests oneself
    on at increasingly distant ‘spaced’ time periods, repeating the fact just before
    one probably would have forgotten it; using software to track &amp; automate tests
    &amp; review scheduling, spaced repetition can scale to hundreds of thousands
    of discrete items.</p><p>If spacing out facts can help one remember by repeating
    items just <em>before</em> they are forgotten, is there any use for an “anti-spaced
    repetition” with the opposite method of repeating items only <em>after</em>
    they are probably forgotten?</p><p>I can think of two: first, it could be used
    to plan <a href="/Media-RL">consumption of media such as
    movies</a> by eg tracking one’s favorite movies of all time and scheduling a rewatch
    whenever one is predicted to have forgotten enough to make them novel &amp; highly
    enjoyable again. Second, and more interestingly, it could be used as a <em>serendipity
    generator</em> by allowing efficient processing of notes or excerpts or old writings.</p><p>In
    rereading such materials many years later, one often gains a new perspective or
    learns something useful because one forgot something: one didn’t understand something
    about it at the time, or new material has radically changed one’s interpretation,
    and since it’d been forgotten, no use could be made of it. Unfortunately, using
    spaced repetition to memorize such material, while ensuring any serendipitous
    connections get made as soon as possible, would be radically infeasible for bulky
    items (a single lengthy text excerpt might correspond to hundreds of discrete
    items, quickly overloading even <span class="smallcaps-auto">SRS</span> systems) and for almost all items, useless.
    One can justify rereading old material once or perhaps twice, but not many rereads
    nor full memorization. But rereading haphazardly is likely to inefficiently cover
    some material many times while neglecting others, and such rereads will often
    be far too early in time (or—a lesser concern here—too late).</p><p>Instead of
    spaced repetition, one would instead use <em>anti-spaced repetition</em>: each
    item would be tracked and reviewed and its expected forgetting time predicted,
    as in spaced repetition, but instead of scheduling a review <em>before</em> forgetting,
    a review is scheduled for some time (probably long afterwards) <em>after</em>
    forgetting. The total number of reviews of each item per user lifetime would be
    set to a small number, perhaps 1–4, bounding the time consumption at a feasible
    amount.</p><p>Such an anti-spaced repetition system could be used with hundreds
    of thousands of notes or clippings which a person might accumulate over a lifetime,
    and enable them to invest a few minutes a day into reading old notes, occasionally
    coming up with new insights, while ensuring they don’t waste time reading notes
    too many times or reading notes they likely already remember &amp; have exhausted.</p>'
- - https://pdos.csail.mit.edu/6.828/2008/readings/engler95exokernel.pdf
  - ! 'Exokernel: An Operating System Architecture for Application-Level Resource
    Management'
  - Dawson R. Engler, M. Frans Kaashoek, James O’Toole Jr.
  - 1995-12-03
  - 10.1145/224057.224076
  - <p>Traditional operating systems limit the performance, flexibility, and functionality
    of applications by fixing the interface and implementation of operating system
    abstractions such as interprocess communication and virtual memory. The <em>exokernel</em>
    operating system architecture addresses this problem by providing application-level
    management of physical resources. In the exokernel architecture, a small kernel
    securely exports all hardware resources through a low-level interface to untrusted
    library operating systems. Library operating systems use this interface to implement
    system objects and policies. This separation of resource protection from management
    allows application-specific customization of traditional operating system abstractions
    by extending, specializing, or even replacing libraries.</p><p>We have implemented
    a prototype exokernel operating system. Measurements show that most primitive
    kernel operations (such as exception handling and protected control transfer)
    are 10 to 100 times faster than in Ultrix, a mature monolithic <span class="smallcaps-auto">UNIX</span> operating
    system. In addition, we demonstrate that an exokernel allows applications to control
    machine resources in ways not possible in traditional operating systems. For instance,
    virtual memory and interprocess communication abstractions are implemented entirely
    within an application-level library. Measurements show that application-level
    virtual memory and interprocess communication primitives are 5 to 40 times faster
    than Ultrix's kernel primitives. Compared to state-of-the-art implementations
    from the literature, the prototype exokernel system is at least 5 times faster
    on operations such as exception dispatching and interprocess communication.</p>
- - http://web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf
  - End-To-End Arguments In System Design
  - J.H. Saltzer, D.P. Reed, D.D. Clark
  - '1984'
  - ''
  - This paper presents a design principle that helps guide placement of functions
    among the modules of a distributed computer system. The principle, called 'the
    end-to-end argument', suggests that functions placed at low levels of a system
    may be redundant or of little value when compared with the cost of providing them
    at that low level. Examples discussed in the paper include bit error recovery,
    security using encryption, duplicate message suppression, recovery from system
    crashes, and delivery acknowledgement. Low level mechanisms to support these functions
    are justified only as performance enhancements.
- - /docs/sr/2019-miller.pdf
  - ! 'The War On Drugs 2.0: Darknet Fentanyl''s Rise And The Effects Of Regulatory
    And Law Enforcement Action'
  - Jacob N. Miller
  - 2019-10-08
  - 10.1111/coep.12447
  - U.S. overdose deaths attributed to synthetic opioids, such as fentanyl, have increased
    from under 3,000 in 2013 to nearly 20,000 in 2016, making up half of all opioid-related
    overdose deaths. Using web scrapes of darknet markets from 2014 to 2016, I provide
    historical prices for fentanyl and its most popular analogues and find that fentanyl
    vendors priced fentanyl in 2014 at a 90% discount compared to an equivalent dose
    of heroin. Using regression discontinuity, I evaluate the effects of two major
    law enforcement and regulatory events. I find minimal lasting effects of U.S.
    legal actions intended to disrupt darknet markets, but there are statistically
    significant indications of a price increase corresponding with regulatory action
    in China. Despite these indications of some regulatory success, fentanyl prices
    remained approximately 90% cheaper than heroin.
- - https://www2.psy.uq.edu.au/~uqbziets/Mosing%20et%20al%202015%20Did%20sexual%20selection%20shape%20human%20music.pdf
  - Did sexual selection shape human music? Testing predictions from the sexual selection
    hypothesis of music evolution using a large genetically informative sample of
    over 10,000 twins
  - Miriam A. Mosing, Karin J.H. Verweij, Guy Madison, Nancy L. Pedersen, Brendan
    P. Zietsch, Fredrik Ullén
  - '2015'
  - 10.1016/j.evolhumbehav.2015.02.004
  - Although music is a universal feature of human culture, little is known about
    its origins and functions. A prominent theory of music evolution is the sexual
    selection hypothesis, which proposes that music evolved as a signal of genetic
    quality to potential mates. The sexual selection hypothesis offers several empirically
    testable predictions. First, musically skilled and active individuals should have
    greater mating success than less-skilled individuals. Second, if musical ability
    functions as an indicator of genetic quality, it is expected to be associated
    with other traits putatively related to genetic quality. Third, associations as
    per the first and second predictions are expected to be at least partly due to
    overlapping genetic influences. We tested these predictions in a large genetically
    informative sample of 10,975 Swedish twin individuals aged between 27 and 54 years
    (M = 40.1, SD = 7.7), using musical aptitude and music achievement as measures
    of musical ability. To assess mating success we examined number of sex-partners,
    age of first intercourse, sociosexuality, and number of offspring. General intelligence,
    simple reaction time, and height were used to investigate relationships with traits
    putatively related to genetic quality. Twin modeling showed moderate genetic influences
    on musical aptitude for both sexes (heritability estimates were 38% for males
    and 51% for females). Music achievement was also moderately influenced by genetic
    influences in males (heritability = 57%), but the genetic influences were low
    and nonsignificant for females (heritability = 9%). Contrary to predictions, the
    majority of phenotypic associations between musical ability and music achievement
    with mating success were nonsignificant or significant in the other direction,
    with those with greater musical ability scoring lower on the measures of mating
    success. Genetic correlations between these measures were also nonsignificant.
    Most correlations of musical aptitude and music achievement with genetic quality
    measures were significant, including correlations with general intelligence, simple
    reaction time, and, in females, height (but only for aptitude). However, only
    the correlation between musical aptitude and general intelligence in men was significantly
    driven by overlapping genetic influences. Our findings provide little support
    for a role of sexual selection in the evolution of musical ability. Alternative
    explanations and limitations are discussed.
- - http://ftp.iza.org/dp12687.pdf#page=3)
  - ! 'Be Cautious with the Precautionary Principle: Evidence from Fukushima Daiichi
    Nuclear Accident'
  - Matthew Neidell
  - 2019-10
  - 10.3386/w26395
  - This paper provides a large scale, empirical evaluation of unintended effects
    from invoking the precautionary principle after the Fukushima Daiichi nuclear
    accident. After the accident, all nuclear power stations ceased operation and
    nuclear power was replaced by fossil fuels, causing an exogenous increase in electricity
    prices. This increase led to a reduction in energy consumption, which caused an
    increase in mortality during very cold temperatures. We estimate that the increase
    in mortality from higher electricity prices outnumbers the mortality from the
    accident itself, suggesting the decision to cease nuclear production has contributed
    to more deaths than the accident itself.
- - https://veridici.com/how-airbnb-is-silently-changing-himalayan-villages/
  - How Airbnb Is Silently Changing Himalayan Villages
  - Shanu Athiparambath
  - 2019-10-21
  - ''
  - <p>[Letter from the eastern Himalayas about the social and economic impact of
    Airbnb.]</p> <p>It’s expensive to farm in Himalayan villages like mine. The farms
    are small and cannot leverage economies of scale. Hill people see the process
    of selling land as a humiliating ordeal they would never consider. Everybody chips
    in to cultivate the land. Women spend many hours a day cutting grass for their
    cows. This is not yet a division of labour society. It is this world that Airbnb
    has penetrated, turning it upside down.</p><p>Millions of people stay in Airbnb
    homes every night. It’s not trust which makes this possible. My pup is fearless
    when he sleeps with the door wide open, in a cottage in the woods. There are leopards
    around. Dogs here don’t live very long. He doesn’t trust leopards, but he knows
    they are afraid of humans. My pup sleeps on my bed, and so is well-protected from
    the vicissitudes of life. But I’m not the living proof that dogs can trust leopards.
    Dogs wouldn’t need humans to guard them if they could trust leopards. Similarly,
    Airbnb puts hosts and guests in a position where behaving badly would ruin their
    reputations. In one of my bad moods, I held my pup quite firmly. At midnight,
    he ran out of the cottage and barked for hours. I couldn’t bring him back to my
    bed. I did something he thought I wouldn’t consider. He felt I betrayed his trust
    in me. I’m, here, talking about a more meaningful form of trust. Intellectuals
    miss this obvious distinction, because they’re not the wonderful people they think
    they are. The distinction between trust and assurance is all too obvious. But
    if doing wrong doesn’t fill you with moral horror, you won’t get it. You can’t
    trust anybody who doesn’t feel that way, and there are not many such people. Unconditional
    trustworthiness is one of the rarest things in the world. Institutions can’t produce
    this kind of trust, because people aren’t conditionable beyond a point. In any
    case, how do you produce something you don’t even understand?</p>
- - /Questions#cats-earwax
  - On Cats' Love of Earwax
  - Gwern Branwen
  - 2019-11-05
  - ''
  - While petting cats, I accidentally discovered cats are fascinated by the smell
    & taste of earwax, particularly that of humans, and this interest can last indefinitely.
    Dogs & humans, for comparison, are not. A number of anecdotes have reported this
    over the years, but no formal research appears to have been done on this. What
    makes earwax attractive to cats? Pheromones? Some nutrient?
- - http://ide.mit.edu/sites/default/files/publications/Multi-Sided%20Platform%20Strategy%2C%20Taxation%20and%20Regulation%20October%202019.pdf#page=14
  - ! 'Multi-Sided Platform Strategy, Taxation, and Regulation: A Quantitative Model
    and Application to Facebook'
  - Seth G. Benzell, Avinash Collis
  - 2019-10-12
  - ''
  - Digital platforms, such as Facebook, Uber, and AirBnB, create value by connecting
    users, creators, and contractors of different types. Their rapid growth, untraditional
    business model, and disruptive nature presents challenges for managers and asset
    pricers. These features also, arguably, make them natural monopolies, leading
    to increasing calls for special regulations and taxes. We construct and illustrate
    a approach for modeling digital platforms. The model allows for heterogeneity
    in elasticity of demand and heterogeneous network effects across different users.
    We parameterize our model using a survey of over 40,000 US internet users on their
    demand for Facebook. Facebook creates about 11.2 billion dollars in consumer surplus
    a month for US users age 25 or over, in line with previous estimates. We find
    Facebook has too low a level of advertising relative to their revenue maximizing
    strategy, suggesting that they also value maintaining a large user base. We simulate
    six proposed government policies for digital platforms, taking Facebook’s optimal
    response into account. Taxes only slightly change consumer surplus. Three more
    radical proposals, including ‘data as labor’ and nationalization, have the potential
    to raise consumer surplus by up to 42%. But a botched regulation that left the
    US with two smaller, non-competitive social media monopolies would decrease consumer
    surplus by 44%.
- - http://pawsoflife-org.k9handleracademy.com/Library/Scent/Porter2006.pdf
  - Mechanisms of scent-tracking in humans
  - Jess Porter, Brent Craven, Rehan M Khan, Shao-Ju Chang, Irene Kang, Benjamin Judkewitz,
    Jason Volpe, Gary Settles, Noam Sobel
  - 2006-12-17
  - 10.1038/nn1819
  - Whether mammalian scent-tracking is aided by inter-nostril comparisons is unknown.
    We assessed this in humans and found that (i) humans can scent-track, (ii) they
    improve with practice, (iii) the human nostrils sample spatially distinct regions
    separated by ∼3.5 cm and, critically, (iv) scent-tracking is aided by inter-nostril
    comparisons. These findings reveal fundamental mechanisms of scent-tracking and
    suggest that the poor reputation of human olfaction may reflect, in part, behavioral
    demands rather than ultimate abilities.
- - /docs/economics/2019-hoynes.pdf
  - Universal Basic Income in the United States and Advanced Countries
  - Hilary Hoynes, Jesse Rothstein
  - 2019-08
  - 10.1146/annurev-ec-11
  - ! 'We discuss the potential role of universal basic incomes (<span class="smallcaps-auto">UBI</span>s) in advanced
    countries. A feature of advanced economies that distinguishes them from developing
    countries is the existence of well-developed, if often incomplete, safety nets.
    We develop a framework for describing transfer programs that is flexible enough
    to encompass most existing programs as well as <span class="smallcaps-auto">UBI</span>s, and we use this framework
    to compare various <span class="smallcaps-auto">UBI</span>s to the existing constellation of programs in the United
    States. A <span class="smallcaps-auto">UBI</span> would direct much larger shares of transfers to childless, nonelderly,
    nondisabled households than existing programs, and much more to middle-income
    rather than poor households. A <span class="smallcaps-auto">UBI</span> large enough to increase transfers to low-income
    families would be enormously expensive. We review the labor supply literature
    for evidence on the likely impacts of a <span class="smallcaps-auto">UBI</span>. We argue that the ongoing <span class="smallcaps-auto">UBI</span> pilot
    studies will do little to resolve the major outstanding questions. [Keywords:
    safety net, income transfer, universal basic income, labor supply, <span class="smallcaps-auto">JEL</span> I38, <span class="smallcaps-auto">JEL</span>H24]'
- - /docs/sociology/2019-lichter.pdf
  - Mismatches in the Marriage Market
  - Daniel T. Lichter, Joseph P. Price, Jeffrey M. Swigert
  - 2019-09-04
  - 10.1111/jomf.12603
  - ! '<p><em>Objective</em>: This article provides an assessment of whether unmarried
    women currently face demographic shortages of marital partners in the U.S. marriage
    market.</p><p><em>Background</em>: One explanation for the declines in marriage
    is the putative shortage of economically attractive partners for unmarried women
    to marry. Previous studies provide mixed results but are usually focused narrowly
    on sex ratio imbalances rather than identifying shortages on the multiple socioeconomic
    characteristics that typically sort women and men into marriages.</p><p><em>Methods</em>:
    This study identifies recent marriages from the 2008 to 2012 and 2013 to 2017
    cumulative 5-year files of the American Community Survey. Data imputation methods
    provide estimates of the sociodemographic characteristics of unmarried women’s
    potential (or synthetic) spouses who resemble the husbands of otherwise comparable
    married women. These estimates are compared with the actual distribution of unmarried
    men at the national, state, and local area levels to identify marriage market
    imbalances.</p><p><em>Results</em>: These synthetic husbands have an average income
    that is about 58% higher than the actual unmarried men that are currently available
    to unmarried women. They also are 30% more likely to be employed (90% vs. 70%)
    and 19% more likely to have a college degree (30% vs. 25%). Racial and ethnic
    minorities, especially Black women, face serious shortages of potential marital
    partners, as do low socioeconomic status and high socioeconomic status unmarried
    women, both at the national and subnational levels.</p><p><em>Conclusions</em>:
    This study reveals large deficits in the supply of potential male spouses. One
    implication is that the unmarried may remain unmarried or marry less well-suited
    partners.</p>'
- - /docs/sociology/2012-henrich.pdf
  - The puzzle of monogamous marriage
  - Joseph Henrich, Robert Boyd, Peter J. Richerson
  - '2012'
  - 10.1098/rstb.2011.0290
  - ! 'The anthropological record indicates that approximately 85% of human societies
    have permitted men to have more than one wife (polygynous marriage), and both
    empirical and evolutionary considerations suggest that large absolute differences
    in wealth should favour more polygynous marriages. Yet, monogamous marriage has
    spread across Europe, and more recently across the globe, even as absolute wealth
    differences have expanded. Here, we develop and explore the hypothesis that the
    norms and institutions that compose the modern package of monogamous marriage
    have been favoured by cultural evolution because of their group-beneficial effects—promoting
    success in inter-group competition. In suppressing intrasexual competition and
    reducing the size of the pool of unmarried men, normative monogamy reduces crime
    rates, including rape, murder, assault, robbery and fraud, as well as decreasing
    personal abuses. By assuaging the competition for younger brides, normative monogamy
    decreases (i) the spousal age gap, (ii) fertility, and (iii) gender inequality.
    By shifting male efforts from seeking wives to paternal investment, normative
    monogamy increases savings, child investment and economic productivity. By increasing
    the relatedness within households, normative monogamy reduces intra-household
    conflict, leading to lower rates of child neglect, abuse, accidental death and
    homicide. These predictions are tested using converging lines of evidence from
    across the human sciences. [Keywords: cultural group selection; monogamy; polygyny;
    marriage; norms; institutional evolution]'
- - https://www.nature.com/articles/s41467-019-12283-6
  - Associations of autozygosity with a broad range of human phenotypes
  - David W. Clark, Yukinori Okada, Kristjan H. S. Moore, Dan Mason, Nicola Pirastu,
    Ilaria Gandin, Hannele Mattsson, Catriona L. K. Barnes, Kuang Lin, Jing Hua Zhao,
    Patrick Deelen, Rebecca Rohde, Claudia Schurmann, Xiuqing Guo, Franco Giulianini,
    Weihua Zhang, Carolina Medina-Gomez, Robert Karlsson, Yanchun Bao, Traci M Bartz,
    Clemens Baumbach, Ginevra Biino, Matthew J Bixley, Marco Brumat, Jin-Fang Chai,
    Tanguy Corre, Diana L Cousminer, Annelot M Dekker, David A Eccles, Kristel R van
    Eijk, Christian Fuchsberger, He Gao, Marine Germain, Scott D Gordon, Hugoline
    G de Haan, Sarah E Harris, Edith Hofer, Alicia Huerta-Chagoya, Catherine Igartua,
    Iris E Jansen, Yucheng Jia, Tim Kacprowski, Torgny Karlsson, Marcus E Kleber,
    Shengchao Alfred Li, Ruifang Li-Gao, Anubha Mahajan, Koichi Matsuda, Karina Meidtner,
    Weihua Meng, May E Montasser, Peter J van der Most, Matthias Munz, Teresa Nutile,
    Teemu Palviainen, Gauri Prasad, Rashmi B Prasad, Tallapragada Divya Sri Priyanka,
    Federica Rizzi, Erika Salvi, Bishwa R Sapkota, Daniel Shriner, Line Skotte, Melissa
    C Smart, Albert Vernon Smith, Ashley van der Spek, Cassandra N Spracklen, Rona
    J Strawbridge, Salman M Tajuddin, Stella Trompet, Constance Turman, Niek Verweij,
    Clara Viberti, Lihua Wang, Helen R Warren, Robyn E Wootton, Lisa R Yanek, Jie
    Yao, Noha A Yousri, Wei Zhao, Adebowale A Adeyemo, Saima Afaq, Carlos Alberto
    Aguilar-Salinas, Masato Akiyama, Matthew L Albert, Matthew A Allison, Maris Alver,
    Tin Aung, Fereidoun Azizi, Amy R Bentley, Heiner Boeing, Eric Boerwinkle, Judith
    B Borja, Gert J de Borst, Erwin P Bottinger, Linda Broer, Harry Campbell, Stephen
    Chanock, Miao-Li Chee, Guanjie Chen, Yii-Der I Chen, Zhengming Chen, Yen-Feng
    Chiu, Massimiliano Cocca, Francis S Collins, Maria Pina Concas, Janie Corley,
    Giovanni Cugliari, Rob M van Dam, Anna Damulina, Maryam S Daneshpour, Felix R
    Day, Graciela E Delgado, Klodian Dhana, Alexander S F Doney, Marcus Dörr, Ayo
    P Doumatey, Nduna Dzimiri, S Sunna Ebenesersdóttir, Joshua Elliott, Paul Elliott,
    Ralf Ewert, Janine F Felix, Krista Fischer, Barry I Freedman, Giorgia Girotto,
    Anuj Goel, Martin Gögele, Mark O Goodarzi, Mariaelisa Graff, Einat Granot-Hershkovitz,
    Francine Grodstein, Simonetta Guarrera, Daniel F Gudbjartsson, Kamran Guity, Bjarni
    Gunnarsson, Yu Guo, Saskia P Hagenaars, Christopher A Haiman, Avner Halevy, Tamara
    B Harris, Mehdi Hedayati, David A van Heel, Makoto Hirata, Imo Höfer, Chao Agnes
    Hsiung, Jinyan Huang, Yi-Jen Hung, M Arfan Ikram, Anuradha Jagadeesan, Pekka Jousilahti,
    Yoichiro Kamatani, Masahiro Kanai, Nicola D Kerrison, Thorsten Kessler, Kay-Tee
    Khaw, Chiea Chuen Khor, Dominique P V de Kleijn, Woon-Puay Koh, Ivana Kolcic,
    Peter Kraft, Bernhard K Krämer, Zoltán Kutalik, Johanna Kuusisto, Claudia Langenberg,
    Lenore J Launer, Deborah A Lawlor, I-Te Lee, Wen-Jane Lee, Markus M Lerch, Liming
    Li, Jianjun Liu, Marie Loh, Stephanie J London, Stephanie Loomis, Yingchang Lu,
    Jian’an Luan, Reedik Mägi, Ani W Manichaikul, Paolo Manunta, Gísli Másson, Nana
    Matoba, Xue W Mei, Christa Meisinger, Thomas Meitinger, Massimo Mezzavilla, Lili
    Milani, Iona Y Millwood, Yukihide Momozawa, Amy Moore, Pierre-Emmanuel Morange,
    Hortensia Moreno-Macías, Trevor A Mori, Alanna C Morrison, Taulant Muka, Yoshinori
    Murakami, Alison D Murray, Renée de Mutsert, Josyf C Mychaleckyj, Mike A Nalls,
    Matthias Nauck, Matt J Neville, Ilja M Nolte, Ken K Ong, Lorena Orozco, Sandosh
    Padmanabhan, Gunnar Pálsson, James S Pankow, Cristian Pattaro, Alison Pattie,
    Ozren Polasek, Neil Poulter, Peter P Pramstaller, Lluis Quintana-Murci, Katri
    Räikkönen, Sarju Ralhan, Dabeeru C Rao, Wouter van Rheenen, Stephen S Rich, Paul
    M Ridker, Cornelius A Rietveld, Antonietta Robino, Frank J A van Rooij, Daniela
    Ruggiero, Yasaman Saba, Charumathi Sabanayagam, Maria Sabater-Lleal, Cinzia Felicita
    Sala, Veikko Salomaa, Kevin Sandow, Helena Schmidt, Laura J Scott, William R Scott,
    Bahareh Sedaghati-Khayat, Bengt Sennblad, Jessica van Setten, Peter J Sever, Wayne
    H-H Sheu, Yuan Shi, Smeeta Shrestha, Sharvari Rahul Shukla, Jon K Sigurdsson,
    Timo Tonis Sikka, Jai Rup Singh, Blair H. Smith, Alena Stančáková, Alice Stanton,
    John M Starr, Lilja Stefansdottir, Leon Straker, Patrick Sulem, Gardar Sveinbjornsson,
    Morris A Swertz, Adele M Taylor, Kent D Taylor, Natalie Terzikhan, Yih-Chung Tham,
    Gudmar Thorleifsson, Unnur Thorsteinsdottir, Annika Tillander, Russell P Tracy,
    Teresa Tusié-Luna, Ioanna Tzoulaki, Simona Vaccargiu, Jagadish Vangipurapu, Jan
    H. Veldink, Veronique Vitart, Uwe Völker, Eero Vuoksimaa, Salma M Wakil, Melanie
    Waldenberger, Gurpreet S Wander, Ya Xing Wang, Nicholas J Wareham, Sarah Wild,
    Chittaranjan S Yajnik, Jian-Min Yuan, Lingyao Zeng, Liang Zhang, Jie Zhou, Najaf
    Amin, Folkert W Asselbergs, Stephan J. L. Bakker, Diane M Becker, Benjamin Lehne,
    David A Bennett, Leonard H. van den Berg, Sonja I Berndt, Dwaipayan Bharadwaj,
    Lawrence F Bielak, Murielle Bochud, Mike Boehnke, Claude Bouchard, Jonathan P
    Bradfield, Jennifer A Brody, Archie Campbell, Shai Carmi, Mark J Caulfield, David
    Cesarini, John C Chambers, Giriraj Ratan Chandak, Ching-Yu Cheng, Marina Ciullo,
    Marilyn Cornelis, Daniele Cusi, George Davey Smith, Ian J Deary, Rajkumar Dorajoo,
    Cornelia M van Duijn, David Ellinghaus, Jeanette Erdmann, Johan G Eriksson, Evangelos
    Evangelou, Michele K Evans, Jessica D Faul, Bjarke Feenstra, Mary Feitosa, Sylvain
    Foisy, Andre Franke, Yechiel Friedlander, Paolo Gasparini, Christian Gieger, Clicerio
    Gonzalez, Philippe Goyette, Struan F A Grant, Lyn R Griffiths, Leif Groop, Vilmundur
    Gudnason, Ulf Gyllensten, Hakon Hakonarson, Anders Hamsten, Pim van der Harst,
    Chew-Kiat Heng, Andrew A Hicks, Hagit Hochner, Heikki Huikuri, Steven C Hunt,
    Vincent W V Jaddoe, Philip L De Jager, Magnus Johannesson, Åsa Johansson, Jost
    B Jonas, J Wouter Jukema, Juhani Junttila, Jaakko Kaprio, Sharon L. R. Kardia,
    Fredrik Karpe, Meena Kumari, Markku Laakso, Sander W van der Laan, Jari Lahti,
    Matthias Laudes, Rodney A Lea, Wolfgang Lieb, Thomas Lumley, Nicholas G Martin,
    Winfried März, Giuseppe Matullo, Mark I McCarthy, Sarah E Medland, Tony R Merriman,
    Andres Metspalu, Brian F Meyer, Karen L Mohlke, Grant W Montgomery, Dennis Mook-Kanamori,
    Patricia B Munroe, Kari E North, Dale R Nyholt, Jeffery R O’connell, Carole Ober,
    Albertine J Oldehinkel, Walter Palmas, Colin Palmer, Gerard G Pasterkamp, Etienne
    Patin, Craig E Pennell, Louis Perusse, Patricia A Peyser, Mario Pirastu, Tinca
    J. C. Polderman, David J Porteous, Danielle Posthuma, Bruce M Psaty, John D Rioux,
    Fernando Rivadeneira, Charles Rotimi, Jerome I Rotter, Igor Rudan, Hester M Den
    Ruijter, Dharambir K Sanghera, Naveed Sattar, Reinhold Schmidt, Matthias B Schulze,
    Heribert Schunkert, Robert A Scott, Alan R Shuldiner, Xueling Sim, Neil Small,
    Jennifer A Smith, Nona Sotoodehnia, E-Shyong Tai, Alexander Teumer, Nicholas J
    Timpson, Daniela Toniolo, David-Alexandre Tregouet, Tiinamaija Tuomi, Peter Vollenweider,
    Carol A Wang, David R Weir, John B Whitfield, Cisca Wijmenga, Tien-Yin Wong, John
    Wright, Jingyun Yang, Lei Yu, Babette S Zemel, Alan B Zonderman, Markus Perola,
    Patrik K. E. Magnusson, André G Uitterlinden, Jaspal S Kooner, Daniel I Chasman,
    Ruth J. F. Loos, Nora Franceschini, Lude Franke, Chris S Haley, Caroline Hayward,
    Robin G Walters, John R. B. Perry, Tōnu Esko, Agnar Helgason, Kari Stefansson,
    Peter K Joshi, Michiaki Kubo, James F Wilson
  - 2019-10-31
  - 10.1038/s41467-019-12283-6
  - ! '<p>In many species, the offspring of related parents suffer reduced reproductive
    success, a phenomenon known as inbreeding depression. In humans, the importance
    of this effect has remained unclear, partly because reproduction between close
    relatives is both rare and frequently associated with confounding social factors.
    Here, using genomic inbreeding coefficients (<em>F<sub><span class="smallcaps-auto">ROH</span></sub></em>) for &gt;1.4
    million individuals, we show that <em>F<sub><span class="smallcaps-auto">ROH</span></sub></em> is significantly associated
    (<em>p</em>&lt; 0.0005) with apparently deleterious changes in 32 out of 100 traits
    analysed. These changes are associated with runs of homozygosity (<span class="smallcaps-auto">ROH</span>), but not
    with common variant homozygosity, suggesting that genetic variants associated
    with inbreeding depression are predominantly rare. The effect on fertility is
    striking: <em>F<sub><span class="smallcaps-auto">ROH</span></sub></em> equivalent to the offspring of first cousins
    is associated with a 55% decrease [95% CI 44–66%] in the odds of having children.
    Finally, the effects of <em>F<sub><span class="smallcaps-auto">ROH</span></sub></em> are confirmed within full-sibling
    pairs, where the variation in <em>F<sub><span class="smallcaps-auto">ROH</span></sub></em> is independent of all environmental
    confounding.</p>'
- - /docs/rl/2019-vinyals.pdf#deepmind
  - Grandmaster level in StarCraft II using multi-agent reinforcement learning
  - Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, Michaël Mathieu, Andrew
    Dudzik, Junyoung Chung, David H. Choi, Richard Powell, Timo Ewalds, Petko Georgiev,
    Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang, Laurent Sifre,
    Trevor Cai, John P. Agapiou, Max Jaderberg, Alexander S. Vezhnevets, Rémi Leblond,
    Tobias Pohlen, Valentin Dalibard, David Budden, Yury Sulsky, James Molloy, Tom
    L. Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani
    Yogatama, Dario Wünsch, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap,
    Koray Kavukcuoglu, Demis Hassabis, Chris Apps, David Silver
  - 2019-10-30
  - 10.1038/s41586-019-1724-z
  - ! 'Many real-world applications require artificial agents to compete and coordinate
    with other agents in complex environments. As a stepping stone to this goal, the
    domain of StarCraft has emerged as an important challenge for artificial intelligence
    research, owing to its iconic and enduring status among the most difficult professional
    e-sports and its relevance to the real world in terms of its raw complexity and
    multi-agent challenges. Over the course of a decade and numerous competitions,
    the strongest agents have simplified important aspects of the game, utilized superhuman
    capabilities, or employed hand-crafted sub-systems. Despite these advantages,
    no previous agent has come close to matching the overall skill of top StarCraft
    players. We chose to address the challenge of StarCraft using general-purpose
    learning methods that are in principle applicable to other complex domains: a
    multi-agent reinforcement learning algorithm that uses data from both human and
    agent games within a diverse league of continually adapting strategies and counter-strategies,
    each represented by deep neural networks. We evaluated our agent, AlphaStar,
    in the full game of StarCraft II, through a series of online games against human
    players. AlphaStar was rated at Grandmaster level for all three StarCraft races
    and above 99.8% of officially ranked human players.'
- - https://www.fhi.ox.ac.uk/reports/2012-1.pdf
  - Indefinite survival through backup copies
  - Anders Sandberg, Stuart Armstrong
  - 2012-06-06
  - ''
  - ! 'If an individual entity endures a fixed probability μ <1 of disappearing ("dying") in a given fixed time period, then, as time approaches infinity, the probability of death approaches certainty. One approach to avoid this fate is for individuals to copy themselves into different locations; if the copies each have an independent probability of dying, then the total risk is much reduced.  However, to avoid the same ultimate fate, the entity must continue copying itself to continually reduce the risk of death. In this paper, we show that to get a non-zero probability of ultimate survival, it suffices that the number of copies grows logarithmically with time. Accounting for expected copy casualties, the required rate of copying is hence bounded.'
- - http://jcsm.aasm.org/ViewAbstract.aspx?pid=31280
  - Stevens-Johnson Syndrome After Armodafinil Use
  - Steven Holfinger, Asim Roy, Markus Schmidt
  - 2018-05-15
  - 10.5664/jcsm.7132
  - "We present the case of a 21-year-old woman in whom Stevens-Johnson syndrome (SJS) developed after initiation of armodafinil. Although this rare and life-threatening reaction is listed on armodafinil's label, no cases have been reported in the literature. This case, in addition to an update of the drug's label after post-marketing research, both support the link between armodafinil and SJS. Providers should maintain a high clinical suspicion for SJS when starting therapy to minimize associated morbidity and mortality by discontinuing armodafinil at the onset of first symptoms."
- - /docs/genetics/selection/2019-karavani.pdf
  - Screening Human Embryos for Polygenic Traits Has Limited Utility
  - Ehud Karavani, Or Zuk, Danny Zeevi, Nir Barzilai, Nikos C. Stefanis, Alex Hatzimanolis, Nikolaos Smyrnis, Dimitrios Avramopoulos, Leonid Kruglyak, Gil Atzmon, Max Lam, Todd Lencz
  - 2019-11-21
  - 10.1016/j.cell.2019.10.033
  - ! '<ul><li>IVF embryos could be profiled with polygenic scores for traits such as height or IQ</li><li>The top-scoring embryo is expected to be ≈2.5 cm or ≈2.5 IQ points above the average</li><li>The adult trait value of the top-scoring embryo would remain widely distributed</li><li>Multiple ethical and other factors impose practical limits on the actual gain</li></ul><p>The increasing proportion of variance in human complex traits explained by polygenic scores, along with progress in preimplantation genetic diagnosis, suggests the possibility of screening embryos for traits such as height or cognitive ability. However, the expected outcomes of embryo screening are unclear, which undermines discussion of associated ethical concerns. Here, we use theory, simulations, and real data to evaluate the potential gain of embryo screening, defined as the difference in trait value between the top-scoring embryo and the average embryo. The gain increases very slowly with the number of embryos but more rapidly with the variance explained by the score. Given current technology, the average gain due to screening would be ≈2.5 cm for height and ≈2.5 IQ points for cognitive ability. These mean values are accompanied by wide prediction intervals, and indeed, in large nuclear families, the majority of children top-scoring for height are not the tallest.</p>'
- - http://www.emcdda.europa.eu/system/files/attachments/12104/EDMR2019_BackgroundReport_Darknet.pdf
  - "Analysis of the supply of drugs and new psychoactive substances by Europe-based vendors via darknet markets in 2017–18: Background paper commissioned by the EMCDDA for the EU Drug Markets Report 2019"
  - Nicolas Christin, Jeremy Thomas
  - 2019-11-21
  - ''
  - ! '<p>Online anonymous marketplaces are a relatively recent technological development that enables sellers and buyers to transact online with far stronger anonymity guarantees than are available on traditional electronic commerce platforms. This has led certain individuals to engage in transactions of illicit or illegal goods. We investigated how commerce on online anonymous marketplaces evolved after the takedown of the AlphaBay marketplace. Namely, we studied, over the summers of 2017 and 2018, a collection of market-places—Dream Market, TradeRoute, Berlusconi, and Valhalla. In this report, we present an analysis of sales,with a focus on the drug supply coming from the European Union (EU). Keeping in mind the limitations inherent to such data collection, we found that, for the period and the marketplaces considered:</p><ul><li>The overall ecosystem appears to have (slightly) grown again since the combined takedown of the AlphaBay and Hansa marketplaces, and now exceeds EUR 750&thinsp;000 euros per day. This calls into question the long-term impact of such takedowns on the overall online anonymous marketplace ecosystem.</li><li>Dream Market is overwhelmingly the dominant marketplace, and its daily volume exceeds previous numbers gathered for AlphaBay (Christin, 2017).</li><li>EU-based suppliers represent approximately 43% of all drug sales; this is in line with the 46% for marketplaces previously studied (Christin, 2016) in the 2011–15 period, and a marked increase compared with the roughly 25% observed in the subsequent AlphaBay study (Christin, 2017).</li><li>EU-originating drugs continued to come primarily from Germany, the Netherlands, and the United Kingdom.</li><li>Cannabis, cocaine and other stimulants altogether continued to represent the majority of all EU-based drug sales.</li><li>The supply of new psychoactive substances (NPS) remained modest with revenues below EUR 10&thinsp;000 per day at market peak, but these slightly increased compared with our previous measurements.</li><li>As in our previous studies, marketplace vendors primarily operated in the retail space, but there was evidence of larger (bulk) sales. Volume-based discounting tended to occur, albeit at relatively modest levels.</li><li>As in our previous studies, half of the vendors specialised in one type of drug, and half of the drug sellers tended to stick to a given weight category.</li><li>Most of the trends observed in this report confirm what we had previously found for other market-places in the 2011–17 period (Christin, 2016, 2017). In other words, despite takedowns and scams, the ecosystem, as a whole, appears relatively stable over time, with the fluctuation in the European sales share noted above indicating an exception.</li></ul><p>…we collected 35 scrapes of four markets—Dream Market, Traderoute, Valhalla, and Berlusconi Market—between summer 2017 and summer 2018.</p><p>[Full report: <a href="http://www.emcdda.europa.eu/system/files/publications/12078/20192630_TD0319332ENN_PDF.pdf">“EU Drug Markets Report: 2019”</a>, DOI: <code>10.2810/561192</code>.]</p>'
- - https://alexdanco.com/2019/11/27/the-social-subsidy-of-angel-investing/
  - The Social Subsidy of Angel Investing
  - Alex Danco
  - 2019-11-27
  - ''
  - ! '<p>The difference in angel investing between Silicon Valley and everywhere else isn’t just a difference in perceived risk/reward or a difference in FOMO. It’s that angel investing fulfils a completely different purpose in Silicon Valley than it does elsewhere. It’s not just a financial activity; it’s a social status exercise.</p><p><strong>Angel Investors in the Bay Area aren’t just in it for the financial returns; they’re also in it for the social returns.</strong></p><p>The Bay Area tech ecosystem has been so successful that startup-related news has become the principal determinant of social status in San Francisco. In other cities, you acquire and flex social status by joining exclusive neighbourhoods or country clubs, or through philanthropic gestures, or even something as simple as what car you drive. In San Francisco, it’s angel investing. Other than founding a successful startup yourself, there’s not much higher-status in the Bay Area than backing founders that go on to build Uber or Stripe…The end result is that the Bay Area has a critical density of people who are willing to offer founders a term sheet for enough investment, and at attractive enough valuations, that it makes sense for the founder to actually accept them. I honestly believe that without this social “subsidy”, a lot of angel investing stops working. If investors were being purely rational, they could only offer something like a $2 million valuation for founders’ first cheques. And if entrepreneurs are smart, they know they can’t accept it; it makes them un-fundable from that day forward.</p><p><strong>The social rewards of angel investing solve an important chicken-and-egg problem in early stage fundraising that financial rewards does not.</strong></p><p>One of the biggest frustrations you face as a founder out fundraising is the refrain: “This sounds really interesting. I love it. Let me know when there are a bunch of other people investing, and then I’ll invest too.” From far away, it’s easy to label this behaviour as cowardly investing. But it happens for a reason…The social returns to angel investing resolve our chicken/egg problem: they turn angel investing into a kind of “race to be first” that is much more aligned with the founder, and more conducive to breaking inertia and completing deals. The founder wants you to move first, and so do you.</p><p><strong>The social returns to angel investing have a strong geographical network effect, because they require a threshold density in order to kick in.</strong></p><p>…If you can assemble enough early stage investors together, it should conceptually become self-sustaining. Once you have that sufficient density of people who care about the social return to angel investing, and you establish a genuine “early stage capital market” that is subsidized in part by the social and emotional job that it’s doing for its angel members, you create something really special. You get the rare conditions where capital is available for founders at high enough valuations, with no strings attached, and by investors who are evaluating them “the right way”, that you actually sustain a scene that produces startups in sufficient numbers to generate those few unlikely mega-winners that replenish angels’ bank accounts and keep the cycle going.</p>'
- - /docs/catnip/1962-todd.pdf
  - Inheritance of the catnip response in domestic cats
  - Neil B. Todd
  - '1962'
  - 10.1093/oxfordjournals.jhered.a107121
  - ! '<p>Four behavioral components of the catnip response are described briefly. The analysis of a pedigree indicates that responding is inherited as an autosomal dominant. Other aspects of inheritance of the catnip response are discussed.</p><p>An essential oil, nepetalactone, was isolated from the catnip plant <em>(Nepeta cataria)</em> by McElvain et al. <sup>2</sup>, <sup>3</sup>, <sup>4</sup> and Meinwald <sup>5</sup>. McElvain<sup>2</sup> demonstrated with lions that the oil is the substance which is responsible for the attraction of cats to the plant and the only constituent capable of inducing a response. This familiar response has been broken down into four components, <em>viz</em>, 1. sniffing, 2. licking and chewing with head shaking, 3. chin and cheek rubbing and 4. head-over roll and body rubbing. None of these automatisms is unique to catnip, each of them apparently belonging normally to sexual or ingestive behavior<sup>1</sup>. These components almost invariably appear in the above sequence. In fact, among 58 responding cats, all tested with dried leaves, only 3 individuals deviated from this sequence and omitted the licking and chewing with head shaking. These animals went immediately into the rolling phase, which seemed to be exceptionally violent. Component four may last from three to six minutes before all response is extinguished. Additional behavior patterns noted occasionally are claw sharpening and washing, both of which occur as displacement activities in the ethological sense in sexual behavior<sup>1</sup>.</p><p>Among responding animals the response may occasionally be inhibited for obscure reasons, necessitating repeated testing of non-responders before drawing conclusions. Also, the response is not manifested in kittens under 6 to 8 weeks of age and may not develop fully until three months of age. In fact, catnip often produces a distinct avoidance response in young kittens which is gradually replaced by indifference in non-responders and by heightened curiosity in responders. Whether nursing is in any way connected with inhibiting the response has not yet been determined. In one case a 6- to 7-week-old nursing kitten gave a total response, but this seems exceptional. A distressed or enraged animal may still respond, and neutering appears to have no effect on behavior towards catnip.</p>'
- - /docs/culture/2005-moretti-graphsmapstrees-3-trees.pdf
  - ! '<em>Graphs, Maps, Trees: Abstract Models for a Literary History</em>, ch. 3: Trees'
  - Franco Moretti
  - ! '2005'
  - ! ''
  - ! '<p>After the quantitative diagrams of the first chapter, and the spatial ones of the second, evolutionary trees constitute <em>morphological</em> diagrams, where history is systematically correlated with form. And indeed, in contrast to literary studies—where theories of form are usually blind to history, and historical work blind to form—for evolutionary thought morphology and history are truly the two dimensions of the same tree: where the vertical axis charts, from the bottom up, the regular passage of time (every interval, writes Darwin, ‘one thousand generations’), while the horizontal one follows the formal diversification (‘the little fans of diverging dotted lines’) that will eventually lead to ‘well-marked varieties’, or to entirely new species.</p><p>The horizontal axis follows formal diversification . . . But Darwin’s words are stronger: he speaks of ‘this rather perplexing subject’—elsewhere, ‘perplexing &amp; unintelligible’ <sup>4</sup>—whereby forms don’t just ‘change’, but change by always <em>diverging</em> from each other (remember, we are in the section on ‘Divergence of Character’).<sup>5</sup> Whether as a result of historical accidents, then, or under the action of a specific ‘principle’, <sup>6</sup> the reality of divergence pervades the history of life, defining its morphospace—its space-of-forms: an important concept, in the pages that follow—as an intrinsically expanding one.</p><p>From a single common origin, to an immense variety of solutions: it is this incessant growing-apart of life forms that the branches of a morphological tree capture with such intuitive force. ‘A tree can be viewed <em>as a simplified description of a matrix of distances</em>’, write Cavalli-Sforza, Menozzi and Piazza in the methodological prelude to their <em>History and Geography of Human Genes</em>; and figure 29, with its mirror-like alignment of genetic groups and linguistic families drifting away from each other (in a ‘correspondence [that] is remarkably high but not perfect’, as they note with aristocratic aplomb), <sup>7</sup> makes clear what they mean: a tree is a way of sketching <em>how far</em> a certain language has moved from another one, or from their common point of origin.</p><p>And if language evolves by diverging, why not literature too?</p>'
- - /docs/genetics/correlation/2015-power.pdf
  - Polygenic risk scores for schizophrenia and bipolar disorder predict creativity
  - Robert A Power, Stacy Steinberg, Gyda Bjornsdottir, Cornelius A Rietveld, Abdel Abdellaoui, Michel M Nivard, Magnus Johannesson, Tessel E Galesloot, Jouke J Hottenga, Gonneke Willemsen, David Cesarini, Daniel J Benjamin, Patrik K E Magnusson, Fredrik Ullén, Henning Tiemeier, Albert Hofman, Frank J A van Rooij, G Bragi Walters, Engilbert Sigurdsson, Thorgeir E Thorgeirsson, Andres Ingason, Agnar Helgason, Augustine Kong, Lambertus A Kiemeney, Philipp Koellinger, Dorret I Boomsma, Daniel Gudbjartsson, Hreinn Stefansson & Kari Stefansson
  - 2015-06-08
  - 10.1038/nn.4040
  - ! '<p>We tested whether polygenic risk scores for schizophrenia and bipolar disorder would predict creativity. Higher scores were associated with artistic society membership or creative profession in both Icelandic (<em>p</em> = 5.2 × 10<sup>−6</sup> and 3.8 × 10<sup>−6</sup> for schizophrenia and bipolar disorder scores, respectively) and replication cohorts (<em>p</em> = 0.0021 and 0.00086). This could not be accounted for by increased relatedness between creative individuals and those with psychoses, indicating that creativity and psychosis share genetic roots.</p>'
- - /docs/genetics/correlation/2016-day.pdf
  - Physical and neurobehavioral determinants of reproductive onset and success
  - Felix R Day, Hannes Helgason, Daniel I Chasman, Lynda M Rose, Po-Ru Loh, Robert A Scott, Agnar Helgason, Augustine Kong, Gisli Masson, Olafur Th Magnusson, Daniel Gudbjartsson, Unnur Thorsteinsdottir, Julie E Buring, Paul M Ridker, Patrick Sulem, Kari Stefansson, Ken K Ong & John R B Perry
  - 2016-04-18
  - 10.1038/ng.3551
  - ! '<p>The ages of puberty, first sexual intercourse and first birth signify the onset of reproductive ability, behavior and success, respectively. In a genome-wide association study of 125,667 UK Biobank participants, we identify 38 loci associated (<em>p</em> &lt; 5 × 10<sup>−8</sup>) with age at first sexual intercourse. These findings were taken forward in 241,910 men and women from Iceland and 20,187 women from the Women’s Genome Health Study. Several of the identified loci also exhibit associations (<em>p</em> &lt; 5 × 10<sup>−8</sup>) with other reproductive and behavioral traits, including age at first birth (variants in or near <em>ESR1</em> and <em>RBM6–SEMA3F</em>), number of children (<em>CADM2</em> and <em>ESR1</em>), irritable temperament (<em>MSRA</em>) and risk-taking propensity (<em>CADM2</em>). Mendelian randomization analyses infer causal influences of earlier puberty timing on earlier first sexual intercourse, earlier first birth and lower educational attainment. In turn, likely causal consequences of earlier first sexual intercourse include reproductive, educational, psychiatric and cardiometabolic outcomes.</p>'
- - /docs/genetics/correlation/2018-turley.pdf
  - Multi-trait analysis of genome-wide association summary statistics using MTAG
  - Patrick Turley, Raymond K. Walters, Omeed Maghzian, Aysu Okbay, James J. Lee, Mark Alan Fontana, Tuan Anh Nguyen-Viet, Robbee Wedow, Meghan Zacher, Nicholas A. Furlotte, 23andMe Research Team, Social Science Genetic Association Consortium, Patrik Magnusson, Sven Oskarsson, Magnus Johannesson, Peter M. Visscher, David Laibson, David Cesarini, Benjamin M. Neale, Daniel J. Benjamin
  - ! '2017-10-23'
  - ! '10.1038/s41588-017-0009-4'
  - ! 'We introduce multi-trait analysis of GWAS (MTAG), a method for joint analysis of summary statistics from genome-wide association studies (GWAS) of different traits, possibly from overlapping samples. We apply MTAG to summary statistics for depressive symptoms (<em>N</em><sub>eff</sub>= 354,862), neuroticism (<em>N</em>= 168,105), and subjective well-being (<em>N</em>= 388,538). As compared to the 32, 9, and 13 genome-wide significant loci identified in the single-trait GWAS (most of which are themselves novel), MTAG increases the number of associated loci to 64, 37, and 49, respectively. Moreover, association statistics from MTAG yield more informative bioinformatics analyses and increase the variance explained by polygenic scores by approximately 25%, matching theoretical expectations.'
- - /docs/genetics/heritable/1976-loehlin-heredityenvironmentandpersonality.pdf
  - ! '<em>Heredity, Environment, & Personality: A Study of 850 Sets of Twins</em>'
  - John C. Loehlin, Robert C. Nichols
  - ! '1976'
  - ''
  - ! '<p>This volume reports on a study of 850 pairs of twins who were tested to determine the influence of heredity and environment on individual differences in personality, ability, and interests. It presents the background, research design, and procedures of the study, a complete tabulation of the test results, and the authors’ extensive analysis of their findings. Based on one of the largest studies of twin behavior ever conducted, the book challenges a number of traditional beliefs about genetic and environmental contributions to personality development.</p> <p>The subjects were chosen from participants in the National Merit Scholarship Qualifying Test of 1962 and were mailed a battery of personality and interest questionnaires. In addition, parents of the twins were sent questionnaires asking about the twins’ early experiences. A similar sample of nontwin students who had taken the merit exam provided a comparison group. The questions investigated included how twins are similar to or different from non-twins, how identical twins are similar to or different from fraternal twins, how the personalities and interests of twins reflect genetic factors, how the personalities and interests of twins reflect early environmental factors, and what implications these questions have for the general issue of how heredity and environment influence the development of psychological characteristics. In attempting to answer these questions, the authors shed new light on the importance of both genes and environment and have formed the basis for new approaches in behavior genetic research.</p>'
- - /docs/genetics/heritable/2017-visscher.pdf
  - '10 Years of GWAS Discovery: Biology, Function, and Translation'
  - Peter M. Visscher, Naomi R. Wray, Qian Zhang, Pamela Sklar, Mark I. McCarthy, Matthew A. Brown, and Jian Yang
  - '2017-07-06'
  - '10.1016/j.ajhg.2017.06.005'
  - ! 'Application of the experimental design of genome-wide association studies (GWASs) is now 10 years old (young), and here we review the remarkable range of discoveries it has facilitated in population and complex-trait genetics, the biology of diseases, and translation toward new therapeutics. We predict the likely discoveries in the next 10 years, when GWASs will be based on millions of samples with array data imputed to a large fully sequenced reference panel and on hundreds of thousands of samples with whole-genome sequencing data.'
- - /docs/genetics/heritable/2018-papageorge.pdf
  - 'Genes, Education, and Labor Market Outcomes: Evidence from the Health and Retirement Study'
  - Nicholas W. Papageorge, Kevin Thom
  - 2018-09
  - 10.3386/w25114
  - ! 'Recent advances have led to the discovery of specific genetic variants that predict educational attainment. We study how these variants, summarized as a linear index—known as a polygenic score—are associated with human capital accumulation and labor market outcomes in the Health and Retirement Study (HRS). We present two main sets of results. First, we find evidence that the genetic factors measured by this score interact strongly with childhood socioeconomic status in determining educational outcomes. In particular, while the polygenic score predicts higher rates of college graduation on average, this relationship is substantially stronger for individuals who grew up in households with higher socioeconomic status relative to those who grew up in poorer households. Second, the polygenic score predicts labor earnings even after adjusting for completed education, with larger returns in more recent decades. These patterns suggest that the genetic traits that promote education might allow workers to better accommodate ongoing skill biased technological change. Consistent with this interpretation, we find a positive association between the polygenic score and non-routine analytic tasks that have benefited from the introduction of new technologies. Nonetheless, the college premium remains the dominant determinant of earnings differences at all levels of the polygenic score. Given the role of childhood SES in predicting college attainment, this raises concerns about wasted potential arising from limited household resources.'
- - /docs/genetics/selection/2014-montague.pdf
  - Comparative analysis of the domestic cat genome reveals genetic signatures underlying feline biology and domestication
  - Michael J. Montague, Gang Li, Barbara Gandolfi, Razib Khan, Bronwen L. Aken, Steven M. J. Searle, Patrick Minx, LaDeana W. Hillier, Daniel C. Koboldt, Brian W. Davis, Carlos A. Driscoll, Christina S. Barr, Kevin Blackistone, Javier Quilez, Belen Lorente-Galdos, Tomas Marques-Bonet, Can Alkan, Gregg W. C. Thomas, Matthew W. Hahn, Marilyn Menotti-Raymond, Stephen J. O’Brien, Richard K. Wilson, Leslie A. Lyons, William J. Murphy, and Wesley C. Warren
  - 2014-10-03
  - 10.1073/pnas.1410083111
  - ! 'Little is known about the genetic changes that distinguish domestic cat populations from their wild progenitors. Here we describe a high-quality domestic cat reference genome assembly and comparative inferences made with other cat breeds, wildcats, and other mammals. Based upon these comparisons, we identified positively selected genes enriched for genes involved in lipid metabolism that underpin adaptations to a hypercarnivorous diet. We also found positive selection signals within genes underlying sensory processes, especially those affecting vision and hearing in the carnivore lineage. We observed an evolutionary tradeoff between functional olfactory and vomeronasal receptor gene repertoires in the cat and dog genomes, with an expansion of the feline chemosensory system for detecting pheromones at the expense of odorant detection. Genomic regions harboring signatures of natural selection that distinguish domestic cats from their wild congeners are enriched in neural crest-related genes associated with behavior and reward in mouse models, as predicted by the domestication syndrome hypothesis. Our description of a previously unidentified allele for the gloving pigmentation pattern found in the Birman breed supports the hypothesis that cat breeds experienced strong selection on specific mutations drawn from random bred populations. Collectively, these findings provide insight into how the process of domestication altered the ancestral wildcat genome and build a resource for future disease mapping and phylogenomic studies across all members of the <em>Felidae</em>.'
- - /docs/genetics/selection/2015-robinson.pdf
  - Population genetic differentiation of height and body mass index across Europe
  - Matthew R Robinson, Gibran Hemani, Carolina Medina-Gomez, Massimo Mezzavilla, Tonu Esko, Konstantin Shakhbazov, Joseph E Powell, Anna Vinkhuyzen, Sonja I Berndt, Stefan Gustafsson, Anne E Justice, Bratati Kahali, Adam E Locke, Tune H. Pers, Sailaja Vedantam, Andrew R. Wood, Wouter van Rheenen, Ole A Andreassen, Paolo Gasparini, Andres Metspalu, Leonard H. van den Berg, Jan H. Veldink, Fernando Rivadeneira, Thomas M. Werge, Goncalo R. Abecasis, Dorret I. Boomsma, Daniel I. Chasman, Eco J. C. de Geus, Timothy M. Frayling, Joel N. Hirschhorn, Jouke Jan Hottenga, Erik Ingelsson, Ruth J. F. Loos, Patrik K. E. Magnusson, Nicholas G. Martin, Grant W. Montgomery, Kari E. North, Nancy L. Pedersen, Timothy D. Spector, Elizabeth K. Speliotes, Michael E. Goddard, Jian Yang, Peter M. Visscher
  - 2015-09-14
  - 10.1038/ng.3401
  - ! '<p>Across-nation differences in the mean values for complex traits are common<sup>1–8</sup>, but the reasons for these differences are unknown. Here we find that many independent loci contribute to population genetic differences in height and body mass index (BMI) in 9,416 individuals across 14 European countries. Using discovery data on over 250,000 individuals and unbiased effect size estimates from 17,500 sibling pairs, we estimate that 24% (95% credible interval (CI) = 9%, 41%) and 8% (95% CI = 4%, 16%) of the captured additive genetic variance for height and BMI, respectively, reflect population genetic differences. Population genetic divergence differed significantly from that in a null model (height, <em>P</em> &lt; 3.94 × 10<sup>−8</sup>; BMI, <em>P</em> &lt; 5.95 × 10<sup>−4</sup>), and we find an among-population genetic correlation for tall and slender individuals (<em>r</em> = −0.80, 95% CI = −0.95, −0.60), consistent with correlated selection for both phenotypes. Observed differences in height among populations reflected the predicted genetic means (<em>r</em> = 0.51; <em>P</em> &lt; 0.001), but environmental differences across Europe masked genetic differentiation for BMI (<em>P</em> &lt; 0.58).</p>'
- - /docs/genetics/selection/2017-gazal.pdf
  - Linkage disequilibrium–dependent architecture of human complex traits shows action of negative selection
  - Steven Gazal, Hilary K Finucane, Nicholas A Furlotte, Po-Ru Loh, Pier Francesco Palamara, Xuanyao Liu, Armin Schoech, Brendan Bulik-Sullivan, Benjamin M Neale, Alexander Gusev, Alkes L Price
  - 2017-09-11
  - 10.1038/ng.3954
  - ! 'Recent work has hinted at the linkage disequilibrium (LD)-dependent architecture of human complex traits, where SNPs with low levels of LD (LLD) have larger per-SNP heritability. Here we analyzed summary statistics from 56 complex traits (average <em>n</em> = 101,401) by extending stratified LD score regression to continuous annotations. We determined that SNPs with low LLD have significantly larger per-SNP heritability and that roughly half of this effect can be explained by functional annotations negatively correlated with LLD, such as DNase I hypersensitivity sites (DHSs). The remaining signal is largely driven by our finding that more recent common variants tend to have lower LLD and to explain more heritability (<em>p</em> = 2.38 × 10^−104^); the youngest 20% of common SNPs explain 3.9 times more heritability than the oldest 20%, consistent with the action of negative selection. We also inferred jointly significant effects of other LD-related annotations and confirmed via forward simulations that they jointly predict deleterious effects.'
- - /docs/genetics/selection/2018-pardinas.pdf
  - Common schizophrenia alleles are enriched in mutation-intolerant genes and in regions under strong background selection
  - Antonio F. Pardiñas, Peter Holmans, Andrew J. Pocklington, Valentina Escott-Price, Stephan Ripke, Noa Carrera, Sophie E. Legge, Sophie Bishop, Darren Cameron, Marian L. Hamshere, Jun Han, Leon Hubbard, Amy Lynham, Kiran Mantripragada, Elliott Rees, James H. MacCabe, Steven A. McCarroll, Bernhard T. Baune, Gerome Breen, Enda M. Byrne, Udo Dannlowski, Thalia C. Eley, Caroline Hayward, Nicholas G. Martin, Andrew M. McIntosh, Robert Plomin, David J. Porteous, Naomi R. Wray, Armando Caballero, Daniel H. Geschwind, Laura M. Huckins, Douglas M. Ruderfer, Enrique Santiago, Pamela Sklar, Eli A. Stahl, Hyejung Won, Esben Agerbo, Thomas D. Als, Ole A. Andreassen, Marie Bækvad-Hansen, Preben Bo Mortensen, Carsten Bøcker Pedersen, Anders D. Børglum, Jonas Bybjerg-Grauholm, Srdjan Djurovic, Naser Durmishi, Marianne Giørtz Pedersen, Vera Golimbet, Jakob Grove, David M. Hougaard, Manuel Mattheisen, Espen Molden, Ole Mors, Merete Nordentoft, Milica Pejovic-Milovancevic, Engilbert Sigurdsson, Teimuraz Silagadze, Christine Søholm Hansen, Kari Stefansson, Hreinn Stefansson, Stacy Steinberg, Sarah Tosato, Thomas Werge, GERAD1 Consortium, CRESTAR Consortium, David A. Collier, Dan Rujescu, George Kirov, Michael J. Owen, Michael C. O’Donovan and James T. R. Walters
  - '2018'
  - 10.1038/s41588-018-0059-2
  - ! 'Schizophrenia is a debilitating psychiatric condition often associated with poor quality of life and decreased life expectancy. Lack of progress in improving treatment outcomes has been attributed to limited knowledge of the underlying biology, although large-scale genomic studies have begun to provide insights. We report a new genome-wide association study of schizophrenia (11,260 cases and 24,542 controls), and through meta-analysis with existing data we identify 50 novel associated loci and 145 loci in total. Through integrating genomic fine-mapping with brain expression and chromosome conformation data, we identify candidate causal genes within 33 loci. We also show for the first time that the common variant association signal is highly enriched among genes that are under strong selective pressures. These findings provide new insights into the biology and genetic architecture of schizophrenia, highlight the importance of mutation-intolerant genes and suggest a mechanism by which common risk variants persist in the population.'
- - /docs/iq/2014-benyamin.pdf
  - Childhood intelligence is heritable, highly polygenic and associated with <em>FNBP1L</em>
  - B. Benyamin, B.St Pourcain, O.S. Davis, G. Davies, N.K. Hansell, M-J.A. Brion, R.M. Kirkpatrick, R.A.M. Cents, S. Franić, M.B. Miller, C.M.A. Haworth, E. Meaburn, T.S. Price, D.M. Evans, N. Timpson, J. Kemp, S. Ring, W. McArdle, S.E. Medland, J. Yang, S.E. Harris, D.C. Liewald, P. Scheet, X. Xiao, J.J. Hudziak, E.J.C. de Geus, Wellcome Trust Case Control Consortium 2 (WTCCC2), V.W.V. Jaddoe, J.M. Starr, F.C. Verhulst, C. Pennell, H. Tiemeier, W.G. Iacono, L.J. Palmer, G.W. Montgomery, N.G. Martin, D.I. Boomsma, D. Posthuma, M. McGue, M.J. Wright, G. Davey Smith, I.J. Deary, R. Plomin, P.M. Visscher
  - 2013-01-29
  - 10.1038/mp.2012.184
  - ! '<p>Intelligence in childhood, as measured by psychometric cognitive tests, is a strong predictor of many important life outcomes, including educational attainment, income, health and lifespan. Results from twin, family and adoption studies are consistent with general intelligence being highly heritable and genetically stable throughout the life course. No robustly associated genetic loci or variants for childhood intelligence have been reported. Here, we report the first genome-wide association study (GWAS) on childhood intelligence (age range 6–18 years) from 17&thinsp;989 individuals in six discovery and three replication samples. Although no individual single-nucleotide polymorphisms (SNPs) were detected with genome-wide significance, we show that the aggregate effects of common SNPs explain 22–46% of phenotypic variation in childhood intelligence in the three largest cohorts (<em>P</em> = 3.9 x 10<sup>-15</sup>, 0.014 and 0.028). <em>FNBP1L</em>, previously reported to be the most significantly associated gene for adult intelligence, was also significantly associated with childhood intelligence (<em>P</em> = 0.003). Polygenic prediction analyses resulted in a significant correlation between predictor and outcome in all replication cohorts. The proportion of childhood intelligence explained by the predictor reached 1.2% (<em>P</em> = 6 x 10<sup>-5</sup>), 3.5% (<em>P</em> = 10<sup>-3</sup>) and 0.5% (<em>P</em> = 6 x 10<sup>-5</sup>) in three independent validation cohorts. Given the sample sizes, these genetic prediction results are consistent with expectations if the genetic architecture of childhood intelligence is like that of body mass index or height. Our study provides molecular support for the heritability and polygenic nature of childhood intelligence. Larger sample sizes will be required to detect individual variants with genome-wide significance.</p>'
- - /docs/genetics/selection/2017-wehby.pdf
  - Genetic Predisposition to Obesity and Medicare Expenditures
  - George L. Wehby, Benjamin W. Domingue, Fred Ullrich, and Fredric D. Wolinsky
  - 2017-05-10
  - 10.1093/gerona/glx062
  - ! 'Background: The relationship between obesity and health expenditures is not well understood. We examined the relationship between genetic predisposition to obesity measured by a polygenic risk score for body mass index (BMI) and Medicare expenditures. Methods: Biennial interview data from the Health and Retirement Survey for a nationally representative sample of older adults enrolled in fee-for-service Medicare were obtained from 1991 through 2010 and linked to Medicare claims for the same period and to Genome-Wide Association Study (GWAS) data. The study included 6,628 Medicare beneficiaries who provided 68,627 complete person-year observations during the study period. Outcomes were total and service-specific Medicare expenditures and indicators for expenditures exceeding the 75<sup>th</sup> and 90<sup>th</sup> percentiles. The BMI polygenic risk score was derived from GWAS data. Regression models were used to examine how the BMI polygenic risk score was related to health expenditures adjusting for demographic factors and GWAS-derived ancestry. Results: Greater genetic predisposition to obesity was associated with higher Medicare expenditures. Specifically, a 1 SD increase in the BMI polygenic risk score was associated with a $805 (<em>p</em> &lt; .001) increase in annual Medicare expenditures per person in 2010 dollars (~15% increase), a $370 (<em>p</em> &lt; .001) increase in inpatient expenses, and a $246 (<em>p</em> &lt; .001) increase in outpatient services. A 1 SD increase in the polygenic risk score was also related to increased likelihood of expenditures exceeding the 75<sup>th</sup> percentile by 18% (95% CI: 10%–28%) and the 90<sup>th</sup> percentile by 27% (95% CI: 15%–40%). Conclusion: Greater genetic predisposition to obesity is associated with higher Medicare expenditures.'
- - /docs/genetics/selection/2017-mcrae.pdf
  - Prevalence and architecture of de novo mutations in developmental disorders
  - Jeremy F. McRae, Stephen Clayton, Tomas W. Fitzgerald, Joanna Kaplanis, Elena Prigmore, Diana Rajan, Alejandro Sifrim, Stuart Aitken, Nadia Akawi, Mohsan Alvi, Kirsty Ambridge, Daniel M. Barrett, Tanya Bayzetinova, Philip Jones, Wendy D. Jones, Daniel King, Netravathi Krishnappa, Laura E. Mason, Tarjinder Singh, Adrian R. Tivey, Munaza Ahmed, Uruj Anjum, Hayley Archer, Ruth Armstrong, Jana Awada, Meena Balasubramanian, Siddharth Banka, Diana Baralle, Angela Barnicoat, Paul Batstone, David Baty, Chris Bennett, Jonathan Berg, Birgitta Bernhard, A. Paul Bevan, Maria BitnerGlindzicz, Edward Blair, Moira Blyth, David Bohanna, Louise Bourdon, David Bourn, Lisa Bradley, Angela Brady, Simon Brent, Carole Brewer, Kate Brunstrom, David J. Bunyan, John Burn, Natalie Canham, Bruce Castle, Kate Chandler, Elena Chatzimichali, Deirdre Cilliers, Angus Clarke, Susan Clasper, Jill ClaytonSmith, Virginia Clowes, Andrea Coates, Trevor Cole, Irina Colgiu, Amanda Collins, Morag N. Collinson, Fiona Connell, Nicola Cooper, Helen Cox, Lara Cresswell, Gareth Cross, Yanick Crow, Mariella DAlessandro, Tabib Dabir, Rosemarie Davidson, Sally Davies, Dylan de Vries, John Dean, Charu Deshpande, Gemma Devlin, Abhijit Dixit, Angus Dobbie, Alan Donaldson, Dian Donnai, Deirdre Donnelly, Carina Donnelly, Angela Douglas, Sofia Douzgou, Alexis Duncan, Jacqueline Eason, Sian Ellard, Ian Ellis, Frances Elmslie, Karenza Evans, Sarah Everest, Tina Fendick, Richard Fisher, Frances Flinter, Nicola Foulds, Andrew Fry, Alan Fryer, Carol Gardiner, Lorraine Gaunt, Neeti Ghali, Richard Gibbons, Harinder Gill, Judith Goodship, David Goudie, Emma Gray, Andrew Green, Philip Greene, Lynn Greenhalgh, Susan Gribble, Rachel Harrison, Lucy Harrison, Victoria Harrison, Rose Hawkins, Liu He, Stephen Hellens, Alex Henderson, Sarah Hewitt, Lucy Hildyard, Emma Hobson, Simon Holden, Muriel Holder, Susan Holder, Georgina Hollingsworth, Tessa Homfray, Mervyn Humphreys, Jane Hurst,  Ben Hutton, Stuart Ingram, Melita Irving, Lily Islam, Andrew Jackson, Joanna Jarvis, Lucy Jenkins, Diana Johnson, Elizabeth Jones, Dragana Josifova, Shelagh Joss, Beckie Kaemba, Sandra Kazembe, Rosemary Kelsell, Bronwyn Kerr, Helen Kingston, Usha Kini, Esther Kinning, Gail Kirby, Claire Kirk, Emma Kivuva, Alison Kraus, Dhavendra Kumar, V. K. Ajith Kumar, Katherine Lachlan, Wayne Lam, Anne Lampe, Caroline Langman, Melissa Lees, Derek Lim, Cheryl Longman, Gordon Lowther, Sally A. Lynch, Alex Magee, Eddy Maher, Alison Male, Sahar Mansour, Karen Marks, Katherine Martin, Una Maye, Emma McCann, Vivienne McConnell, Meriel McEntagart, Ruth McGowan, Kirsten McKay, Shane McKee, Dominic J. McMullan, Susan McNerlan, Catherine McWilliam, Sarju Mehta, Kay Metcalfe, Anna Middleton, Zosia Miedzybrodzka, Emma Miles, Shehla Mohammed, Tara Montgomery, David Moore, Sian Morgan, Jenny Morton, Hood Mugalaasi, Victoria Murday, Helen Murphy, Swati Naik, Andrea Nemeth, Louise Nevitt, Ruth NewburyEcob, Andrew Norman, Rosie OShea, Caroline Ogilvie, KaiRen Ong, SooMi Park, Michael J. Parker, Chirag Patel, Joan Paterson, Stewart Payne, Daniel Perrett, Julie Phipps, Daniela T. Pilz, Martin Pollard, Caroline Pottinger, Joanna Poulton, Norman Pratt, Katrina Prescott, Sue Price, Abigail Pridham, Annie Procter, Hellen Purnell, Oliver Quarrell, Nicola Ragge, Raheleh Rahbari, Josh Randall, Julia Rankin, Lucy Raymond, Debbie Rice, Leema Robert, Eileen Roberts, Jonathan Roberts, Paul Roberts, Gillian Roberts, Alison Ross, Elisabeth Rosser, Anand Saggar, Shalaka Samant, Julian Sampson, Richard Sandford, Ajoy Sarkar, Susann Schweiger, Richard Scott, Ingrid Scurr, Ann Selby, Anneke Seller, Cheryl Sequeira, Nora Shannon, Saba Sharif, Charles ShawSmith, Emma Shearing, Debbie Shears, Eamonn Sheridan, Ingrid Simonic, Roldan Singzon, Zara Skitt, Audrey Smith, Kath Smith, Sarah Smithson, Linda Sneddon, Miranda Splitt, Miranda Squires, Fiona Stewart, Helen Stewart, Volker Straub, Mohnish Suri, Vivienne Sutton, Ganesh Jawahar Swaminathan, Elizabeth Sweeney, Kate TattonBrown, Cat Taylor, Rohan Taylor, Mark Tein, I. Karen Temple, Jenny Thomson, Marc Tischkowitz, Susan Tomkins, Audrey Torokwa, Becky Treacy, Claire Turner, Peter Turnpenny, Carolyn Tysoe, Anthony Vandersteen, Vinod Varghese, Pradeep Vasudevan, Parthiban Vijayarangakannan, Julie Vogt, Emma Wakeling, Sarah Wallwark, Jonathon Waters, Astrid Weber, Diana Wellesley, Margo Whiteford, Sara Widaa, Sarah Wilcox, Emily Wilkinson, Denise Williams, Nicola Williams, Louise Wilson, Geoff Woods, Christopher Wragg, Michael Wright, Laura Yates, Michael Yau, Chris Nellker, Michael Parker, Helen V. Firth, Caroline F. Wright, David R. FitzPatrick, Jeffrey C. Barrett  Matthew E. Hurles
  - 2017-01-25
  - 10.1038/nature21062
  - ! 'The genomes of individuals with severe, undiagnosed developmental disorders are enriched in damaging de novo mutations (DNMs) in developmentally important genes. Here we have sequenced the exomes of 4,293 families containing individuals with developmental disorders, and meta-analysed these data with data from another 3,287 individuals with similar disorders. We show that the most important factors influencing the diagnostic yield of DNMs are the sex of the affected individual, the relatedness of their parents, whether close relatives are affected and the parental ages. We identified 94 genes enriched in damaging DNMs, including 14 that previously lacked compelling evidence of involvement in developmental disorders. We have also characterized the phenotypic diversity among these disorders. We estimate that 42% of our cohort carry pathogenic DNMs in coding sequences; approximately half of these DNMs disrupt gene function and the remainder result in altered protein function. We estimate that developmental disorders caused by DNMs have an average prevalence of 1 in 213 to 1 in 448 births, depending on parental age. Given current global demographics, this equates to almost 400,000 children born per year.'
- - /docs/genetics/selection/2015-gianola.pdf
  - One Hundred Years of Statistical Developments in Animal Breeding
  - Daniel Gianola, Guilherme J.M. Rosa
  - 2014-11-03
  - 10.1146/annurev-animal-022114-110733
  - 'Statistical methodology has played a key role in scientific animal breeding. Approximately one hundred years of statistical developments in animal breeding are reviewed. Some of the scientific foundations of the field are discussed, and many milestones are examined from historical and critical perspectives. The review concludes with a discussion of some future challenges and opportunities arising from the massive amount of data generated by livestock, plant, and human genome projects.'
- - /docs/genetics/heritable/2018-kaplanis.pdf
  - Quantitative analysis of population-scale family trees with millions of relatives
  - Joanna Kaplanis, Assaf Gordon, Tal Shor, Omer Weissbrod, Dan Geiger, Mary Wahl, Michael Gershovits, Barak Markus, Mona Sheikh, Melissa Gymrek, Gaurav Bhatia, Daniel G. MacArthur, Alkes L. Price, Yaniv Erlich
  - 2018-03-01
  - 10.1126/science.aam9309
  - 'Family trees have vast applications in multiple fields from genetics to anthropology and economics. However, the collection of extended family trees is tedious and usually relies on resources with limited geographical scope and complex data usage restrictions. Here, we collected 86 million profiles from publicly-available online data shared by genealogy enthusiasts. After extensive cleaning and validation, we obtained population-scale family trees, including a single pedigree of 13 million individuals. We leveraged the data to partition the genetic architecture of longevity by inspecting millions of relative pairs and to provide insights into the geographical dispersion of families. We also report a simple digital procedure to overlay other datasets with our resource in order to empower studies with population-scale genealogical data.'
- - /docs/genetics/heritable/2015-yang.pdf
  - Genetic variance estimation with imputed variants finds negligible missing heritability for human height and body mass index
  - Jian Yang, Andrew Bakshi, Zhihong Zhu, Gibran Hemani, Anna A E Vinkhuyzen, Sang Hong Lee, Matthew R Robinson, John R B Perry, Ilja M Nolte, Jana V van VlietOstaptchouk, Harold Snieder, The LifeLines Cohort Study, Tonu Esko, Lili Milani, Reedik Mgi, Andres Metspalu, Anders Hamsten, Patrik K E Magnusson, Nancy L Pedersen, Erik Ingelsson, Nicole Soranzo, Matthew C Keller, Naomi R Wray, Michael E Goddard, Peter M Visscher
  - 2015-08-31
  - 10.1038/ng.3390
  - ! 'We propose a method (GREML-LDMS) to estimate heritability for human complex traits in unrelated individuals using whole-genome sequencing data. We demonstrate using simulations based on whole-genome sequencing data that ~97% and ~68% of variation at common and rare variants, respectively, can be captured by imputation. Using the GREML-LDMS method, we estimate from 44,126 unrelated individuals that all ~17 million imputed variants explain 56% (standard error (s.e.) = 2.3%) of variance for height and 27% (s.e. = 2.5%) of variance for body mass index (BMI), and we find evidence that height- and BMI-associated variants have been under natural selection. Considering the imperfect tagging of imputation and potential overestimation of heritability from previous family-based studies, heritability is likely to be 60–70% for height and 30–40% for BMI. Therefore, the missing heritability is small for both traits. For further discovery of genes associated with complex traits, a study design with SNP arrays followed by imputation is more cost-effective than whole-genome sequencing at current prices.'
- - /docs/genetics/heritable/2012-vandongen.pdf
  - The continuing value of twin studies in the omics era
  - Jenny van Dongen, P. Eline Slagboom, Harmen H. M. Draisma, Nicholas G. Martin, Dorret I. Boomsma
  - 2012-07-31
  - 10.1038/nrg3243
  - 'The classical twin study has been a powerful heuristic in biomedical, psychiatric and behavioural research for decades. Twin registries worldwide have collected biological material and longitudinal phenotypic data on tens of thousands of twins, providing a valuable resource for studying complex phenotypes and their underlying biology. In this Review, we consider the continuing value of twin studies in the current era of molecular genetic studies. We conclude that classical twin methods combined with novel technologies represent a powerful approach towards identifying and understanding the molecular pathways that underlie complex traits.'
- - /docs/genetics/editing/2017-niu.pdf
  - Inactivation of porcine endogenous retrovirus in pigs using CRISPR-Cas9
  - Dong Niu, HongJiang Wei, Lin Lin, Haydy George, Tao Wang, IHsiu Lee, HongYe Zhao, Yong Wang, Yinan Kan, Ellen Shrock, Emal Lesha, Gang Wang, Yonglun Luo, Yubo Qing, Deling Jiao, Heng Zhao, Xiaoyang Zhou, Shouqi Wang, Hong Wei, Marc Gell, George M. Church, Luhan Yang
  - 2017-08-10
  - 10.1126/science.aan4187
  - 'Xenotransplantation is a promising strategy to alleviate the shortage of organs for human transplantation. In addition to the concern on pig-to-human immunological compatibility, the risk of cross-species transmission of porcine endogenous retroviruses (PERVs) has impeded the clinical application of this approach. Earlier, we demonstrated the feasibility of inactivating PERV activity in an immortalized pig cell line. Here, we confirmed that PERVs infect human cells, and observed the horizontal transfer of PERVs among human cells. Using CRISPR-Cas9, we inactivated all the PERVs in a porcine primary cell line and generated PERV-inactivated pigs via somatic cell nuclear transfer. Our study highlighted the value of PERV inactivation to prevent cross-species viral transmission and demonstrated the successful production of PERV-inactivated animals to address the safety concern in clinical xenotransplantation.'
- - /docs/genetics/correlation/2017-xu.pdf
  - Genetic and Environmental Influences on Household Financial Distress
  - Yilan Xu, Daniel A. Briley, Jeffrey R. Brown, William G. Karnes, Brent W. Roberts
  - 2017-01-08
  - 10.1016/j.jebo.2017.08.001
  - ! 'Heterogeneity of household financial outcomes emerges from various individual and environmental factors, including personality, cognitive ability, and socioeconomic status (SES), among others. Using a genetically informative data set, we decompose the variation in financial management behavior into genetic, shared environmental and non-shared environmental factors. We find that about half of the variation in financial distress is genetically influenced, and personality and cognitive ability are associated with financial distress through genetic and within-family pathways. Moreover, the genetic influences of financial distress are highest at the extremes of SES, which in part can be explained by neuroticism and cognitive ability being more important predictors of financial distress at low and high levels of SES, respectively.'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5971142/
  - Polygenic prediction of the phenome, across ancestry, in emerging adulthood
  - Anna R. Docherty, Arden Moscati, Danielle Dick, Jeanne E. Savage, Jessica E. Salvatore, Megan Cooke, Fazil Aliev, Ashlee A. Moore, Alexis C. Edwards, Brien P. Riley, Daniel E. Adkins, Roseann Peterson, Bradley T. Webb, Silviu A. Bacanu, and Kenneth S. Kendler
  - 2017-11-27
  - 10.1017/S0033291717003312
  - ! '<em>Background</em>: Identifying genetic relationships between complex traits in emerging adulthood can provide useful etiological insights into risk for psychopathology. College-age individuals are under-represented in genomic analyses thus far, and the majority of work has focused on the clinical disorder or cognitive abilities rather than normal-range behavioral outcomes. <em>Methods</em>: This study examined a sample of emerging adults 18–22 years of age (<em>N</em> = 5947) to construct an atlas of polygenic risk for 33 traits predicting relevant phenotypic outcomes. 28 hypotheses were tested based on the previous literature on samples of European ancestry, and the availability of rich assessment data allowed for polygenic predictions across 55 psychological and medical phenotypes. <em<Results</em>: Polygenic risk for schizophrenia (SZ) in emerging adults predicted anxiety, depression, nicotine use, trauma, and family history of psychological disorders. Polygenic risk for neuroticism predicted anxiety, depression, phobia, panic, neuroticism, and was correlated with polygenic risk for cardiovascular disease.  <em>Conclusions</em: These results demonstrate the extensive impact of genetic risk for SZ, neuroticism, and major depression on a range of health outcomes in early adulthood. Minimal cross-ancestry replication of these phenomic patterns of polygenic influence underscores the need for more genome-wide association studies of non-European populations.'
- - /docs/genetics/correlation/2017-akiyama.pdf
  - Genome-wide association study identifies 112 new loci for body mass index in the Japanese population
  - Masato Akiyama, Yukinori Okada, Masahiro Kanai, Atsushi Takahashi, Yukihide Momozawa, Masashi Ikeda, Nakao Iwata, Shiro Ikegawa, Makoto Hirata, Koichi Matsuda, Motoki Iwasaki, Taiki Yamaji, Norie Sawada, Tsuyoshi Hachiya, Kozo Tanno, Atsushi Shimizu, Atsushi Hozawa, Naoko Minegishi, Shoichiro Tsugane, Masayuki Yamamoto, Michiaki Kubo Yoichiro Kamatani
  - 2017-09-11
  - 10.1038/ng.3951
  - ! 'Obesity is a risk factor for a wide variety of health problems. In a genome-wide association study (GWAS) of body mass index (BMI) in Japanese people (<em>n</em> = 173,430), we found 85 loci significantly associated with obesity (<em>P</em> &lt; 5.0 × 10<sup>−8</sup>), of which 51 were previously unknown. We conducted trans-ancestral meta-analyses by integrating these results with the results from a GWAS of Europeans and identified 61 additional new loci. In total, this study identifies 112 novel loci, doubling the number of previously known BMI-associated loci. By annotating associated variants with cell-type-specific regulatory marks, we found enrichment of variants in CD19+ cells. We also found significant genetic correlations between BMI and lymphocyte count (<em>P</em> = 6.46 × 10<sup>−5</sup>, <em>r<sub>g</sub></em> = 0.18) and between BMI and multiple complex diseases. These findings provide genetic evidence that lymphocytes are relevant to body weight regulation and offer insights into the pathogenesis of obesity.'
- - /docs/genetics/correlation/2016-hyde.pdf
  - Identification of 15 genetic loci associated with risk of major depression in individuals of European descent
  - Craig L. Hyde, Michael W. Nagle, Chao Tian, Xing Chen, Sara A. Paciga, Jens R. Wendland, Joyce Y. Tung, David A. Hinds, Roy H. Perlis, Ashley R. Winslow
  - 2016-08-01
  - 10.1038/ng.3623
  - ! 'Despite strong evidence supporting the heritability of major depressive disorder (MDD), previous genome-wide studies were unable to identify risk loci among individuals of European descent. We used self-report data from 75,607 individuals reporting clinical diagnosis of depression and 231,747 individuals reporting no history of depression through 23andMe and carried out meta-analysis of these results with published MDD genome-wide association study results. We identified five independent variants from four regions associated with self-report of clinical diagnosis or treatment for depression. Loci with a <em>P</em> value &lt;1.0 × 10<sup>−5</sup> in the meta-analysis were further analyzed in a replication data set (45,773 cases and 106,354 controls) from 23andMe. A total of 17 independent SNPs from 15 regions reached genome-wide significance after joint analysis over all three data sets. Some of these loci were also implicated in genome-wide association studies of related psychiatric traits. These studies provide evidence for large-scale consumer genomic data as a powerful and efficient complement to data collected from traditional means of ascertainment for neuropsychiatric disease genomics.'
- - /docs/genetics/correlation/2016-barban.pdf
  - Genome-wide analysis identifies 12 loci influencing human reproductive behavior
  - Nicola Barban, Rick Jansen, Ronald de Vlaming, Ahmad Vaez, Jornt J Mandemakers, Felix C Tropf, Xia Shen, James F Wilson, Daniel I Chasman, Ilja M Nolte, Vinicius Tragante, Sander W van der Laan, John R B Perry, Augustine Kong, BIOS Consortium, Tarunveer S Ahluwalia, Eva Albrecht, Laura YergesArmstrong, Gil Atzmon, Kirsi Auro, Kristin Ayers, Andrew Bakshi, Danny BenAvraham, Klaus Berger, Aviv Bergman, Lars Bertram, Lawrence F Bielak, Gyda Bjornsdottir, Marc Jan Bonder, Linda Broer, Minh Bui, Caterina Barbieri, Alana Cavadino, Jorge E Chavarro, Constance Turman, Maria Pina Concas, Heather J Cordell, Gail Davies, Peter Eibich, Nicholas Eriksson, Tõnu Esko, Joel Eriksson, Fahimeh Falahi, Janine F Felix, Mark Alan Fontana, Lude Franke, Ilaria Gandin, Audrey J Gaskins, Christian Gieger, Erica P Gunderson, Xiuqing Guo, Caroline Hayward, Chunyan He, Edith Hofer, Hongyan Huang, Peter K Joshi, Stavroula Kanoni, Robert Karlsson, Stefan Kiechl, Annette Kifley, Alexander Kluttig, Peter Kraft, Vasiliki Lagou, Cecile Lecoeur, Jari Lahti, Ruifang LiGao, Penelope A Lind, Tian Liu, Enes Makalic, Crysovalanto Mamasoula, Lindsay Matteson, Hamdi Mbarek, Patrick F McArdle, George McMahon, S Fleur W Meddens, Evelin Mihailov, Mike Miller, Stacey A Missmer, Claire Monnereau, Peter J van der Most, Ronny Myhre, Mike A Nalls, Teresa Nutile, Ioanna Panagiota Kalafati, Eleonora Porcu, Inga Prokopenko, Kumar B Rajan, Janet RichEdwards, Cornelius A Rietveld, Antonietta Robino, Lynda M Rose, Rico Rueedi, Kathleen A Ryan, Yasaman Saba, Daniel Schmidt, Jennifer A Smith, Lisette Stolk, Elizabeth Streeten, Anke Tönjes, Gudmar Thorleifsson, Sheila Ulivi, Juho Wedenoja, Juergen Wellmann, Peter Willeit, Jie Yao, Loic Yengo, Jing Hua Zhao, Wei Zhao, Daria V Zhernakova, Najaf Amin, Howard Andrews, Beverley Balkau, Nir Barzilai, Sven Bergmann, Ginevra Biino, Hans Bisgaard, Klaus Bønnelykke, Dorret I Boomsma, Julie E Buring, Harry Campbell, Stefania Cappellani, Marina Ciullo, Simon R Cox, Francesco Cucca, Daniela Toniolo, George DaveySmith, Ian J Deary, George Dedoussis, Panos Deloukas, Cornelia M van Duijn, Eco J C de Geus, Johan G Eriksson, Denis A Evans, Jessica D Faul, Cinzia Felicita Sala, Philippe Froguel, Paolo Gasparini, Giorgia Girotto, HansJörgen Grabe, Karin Halina Greiser, Patrick J F Groenen, Hugoline G de Haan, Johannes Haerting, Tamara B Harris, Andrew C Heath, Kauko Heikkilä, Albert Hofman, Georg Homuth, Elizabeth G Holliday, John Hopper, Elina Hyppönen, Bo Jacobsson, Vincent W V Jaddoe, Magnus Johannesson, Astanand Jugessur, Mika Kähönen, Eero Kajantie, Sharon L R Kardia, Bernard Keavney, Ivana Kolcic, Päivikki Koponen, Peter Kovacs, Florian Kronenberg, Zoltan Kutalik, Martina La Bianca, Genevieve Lachance, William G Iacono, Sandra Lai, Terho Lehtimäki, David CLiewald, LifeLines Cohort Study, Cecilia M Lindgren, Yongmei Liu, Robert Luben, Michael Lucht, Riitta Luoto, Per Magnus, Patrik K E Magnusson, Nicholas G Martin, Matt McGue, Ruth McQuillan, Sarah E Medland, Christa Meisinger, Dan Mellström, Andres Metspalu, Michela Traglia, Lili Milani, Paul Mitchell, Grant W Montgomery, Dennis MookKanamori, Renée de Mutsert, Ellen A Nohr, Claes Ohlsson, Jørn Olsen, Ken K Ong, Lavinia Paternoster, Alison Pattie, Brenda W. J. H. Penninx, Markus Perola, Patricia A Peyser, Mario Pirastu, Ozren Polasek, Chris Power, Jaakko Kaprio, Leslie J Raffel, Katri Räikkönen, Olli Raitakari, Paul M Ridker, Susan M Ring, Kathryn Roll, Igor Rudan, Daniela Ruggiero, Dan Rujescu, Veikko Salomaa, David Schlessinger, Helena Schmidt, Reinhold Schmidt, Nicole Schupf, Johannes Smit, Rossella Sorice, Tim D Spector, John M Starr, Doris Stöckl, Konstantin Strauch, Michael Stumvoll, Morris A Swertz, Unnur Thorsteinsdottir, A Roy Thurik, Nicholas J Timpson, Joyce Y Tung, André G Uitterlinden, Simona Vaccargiu, Jorma Viikari, Veronique Vitart, Henry Völzke, Peter Vollenweider, Dragana Vuckovic, Johannes Waage, Gert G Wagner, Jie Jin Wang, Nicholas J Wareham, David R Weir, Gonneke Willemsen, Johann Willeit, Alan F Wright, Krina T Zondervan, Kari Stefansson, Robert F Krueger, James J Lee, Daniel J Benjamin, David Cesarini, Philipp D Koellinger, Marcel den Hoed, Harold Snieder, Melinda C Mills
  - 2016-10-31
  - 10.1038/ng.3698
  - ! 'The genetic architecture of human reproductive behavior—age at first birth (AFB) and number of children ever born (NEB)—has a strong relationship with fitness, human development, infertility and risk of neuropsychiatric disorders. However, very few genetic loci have been identified, and the underlying mechanisms of AFB and NEB are poorly understood. We report a large genome-wide association study of both sexes including 251,151 individuals for AFB and 343,072 individuals for NEB. We identified 12 independent loci that are significantly associated with AFB and/or NEB in a SNP-based genome-wide association study and 4 additional loci associated in a gene-based effort. These loci harbor genes that are likely to have a role, either directly or by affecting non-local gene expression, in human reproduction and infertility, thereby increasing understanding of these complex traits.'
- - /docs/genetics/correlation/2014-sariaslan-2.pdf
  - ! 'Does Population Density and Neighborhood Deprivation Predict Schizophrenia? A Nationwide Swedish Family-Based Study of 2.4 Million Individuals'
  - ! 'Amir Sariaslan, Henrik Larsson, Brian D’Onofrio, Niklas Långström, Seena Fazel, Paul Lichtenstein'
  - ! '2014-07-22'
  - ! '10.1093/schbul/sbu105'
  - ! 'People living in densely populated and socially disorganized areas have higher rates of psychiatric morbidity, but the potential causal status of such factors is uncertain. We used nationwide Swedish longitudinal registry data to identify all children born 1967–1989 (<em>n</em> = 2361585), including separate datasets for all cousins (<em>n</em> = 1&thinsp;715&thinsp;059) and siblings (<em>n</em> = 1667&thinsp;894). The nature of the associations between population density and neighborhood deprivation and individual risk for a schizophrenia diagnosis was investigated while adjusting for unobserved familial risk factors (through cousin and sibling comparisons) and then compared with similar associations for depression. We generated familial pedigree structures using the Multi-Generation Registry and identified study participants with schizophrenia and depression using the National Patient Registry. Fixed-effects logistic regression models were used to study within-family estimates. Population density, measured as ln(population size/km<sup>2</sup>), at age 15 predicted subsequent schizophrenia in the population (OR = 1.10; 95% CI: 1.09; 1.11). Unobserved familial risk factors shared by cousins within extended families attenuated the association (1.06; 1.03; 1.10), and the link disappeared entirely within nuclear families (1.02; 0.97; 1.08). Similar results were found for neighborhood deprivation as predictor and for depression as outcome. Sensitivity tests demonstrated that timing and accumulation effects of the exposures (mean scores across birth, ages 1–5, 6–10, and 11–15 years) did not alter the findings. Excess risks of psychiatric morbidity, particularly schizophrenia, in densely populated and socioeconomically deprived Swedish neighborhoods appear, therefore, to result primarily from unobserved familial selection factors. Previous studies may have overemphasized the etiological importance of these environmental factors.'
- - /docs/economics/2001-warner.pdf
  - ! 'The Personal Discount Rate: Evidence from Military Downsizing Programs'
  - John T. Warner, Saul Pleeter
  - ! '2001-03'
  - ''
  - ! 'The military drawdown program of the early 1990’s provides an opportunity to obtain estimates of personal discount rates based on large numbers of people making real choices involving large sums. The program offered over 65,000 separatees the choice between an annuity and a lump-sum payment. Despite break-even discount rates exceeding 17%, most of the separatees selected the lump sum—saving taxpayers $1.7 billion in separation costs. Estimates of discount rates range from 0 to over 30% and vary with education, age, race, sex, number of dependents, ability test score, and the size of payment.'
- - /docs/culture/2010-dobelli.pdf
  - 'Avoid News: Towards a Healthy News Diet'
  - Rolf Dobelli
  - '2010'
  - ''
  - ! 'This article is the antidote to news. It is long, and you probably won’t be able to skim it. Thanks to heavy news consumption, many people have lost the reading habit and struggle to absorb more than four pages straight. This article will show you how to get out of this trap–if you are not already too deeply in it.'
- - /docs/borges/1951-borges-theargentinewriterandtradition.pdf
  - The Argentine Writer and Tradition
  - Jorge Luis Borges
  - '1951'
  - ''
  - ! 'Borges considers the problem of whether Argentinian writing on non-Argentinian subjects can still be truly "Argentine."  His conclusion: ...We should not be alarmed and that we should feel that our patrimony is the universe; we should essay all themes, and we cannot limit ourselves to purely Argentine subjects in order to be Argentine; for either being Argentine is an inescapable act of fate—and in that case we shall be so in all events—or being Argentine is a mere affectation, a mask. I believe that if we surrender ourselves to that voluntary dream which is artistic creation, we shall be Argentine and we shall also be good or tolerable writers.'
- - https://www1.udel.edu/educ/gottfredson/reprints/1997whygmatters.pdf
  - 'Why <em>g</em> Matters: The Complexity of Everyday Life'
  - Linda S. Gottfredson
  - '1997'
  - ''
  - ! 'Personnel selection research provides much evidence that intelligence (<em>g</em>) is an important predictor of performance in training and on the job, especially in higher level work. This article provides evidence that g has pervasive utility in work settings because it is essentially the ability to deal with cognitive complexity, in particular, with complex information processing. The more complex a work task, the greater the advantages that higher g confers in performing it well. Everyday tasks, like job duties, also differ in their level of complexity. The importance of intelligence therefore differs systematically across different arenas of social life as well as economic endeavor. Data from the National Adult Literacy Survey are used to show how higher levels of cognitive ability systematically improve individuals’ odds of dealing successfully with the ordinary demands of modem life (such as banking, using maps and transportation schedules, reading and understanding forms, interpreting news articles). These and other data are summarized to illustrate how the advantages of higher <em>g</em>, even when they are small, cumulate to affect the overall life chances of individuals at different ranges of the IQ bell curve. The article concludes by suggesting ways to reduce the risks for low-IQ individuals of being left behind by an increasingly complex postindustrial economy.'
- - https://www.sociologicalscience.com/download/volume-2/february/SocSci_v2_82to105.pdf
  - Is the Effect of Parental Education on Offspring Biased or Moderated by Genotype?
  - Dalton Conley, Benjamin W. Domingue, David Cesarini, Christopher Dawes, Cornelius A. Rietveld, Jason D. Boardman
  - 2015-02-25
  - 10.15195/v2.a6
  - ! 'Parental education is the strongest measured predictor of offspring education, and thus many scholars see the parent–child correlation in educational attainment as an important measure of social mobility. But if social changes or policy interventions are going to have dynastic effects, we need to know what accounts for this intergenerational association, that is, whether it is primarily environmental or genetic in origin. Thus, to understand whether the estimated social influence of parental education on offspring education is biased owing to genetic inheritance (or moderated by it), we exploit the findings from a recent large genome-wide association study of educational attainment to construct a genetic score designed to predict educational attainment. Using data from two independent samples, we find that our genetic score significantly predicts years of schooling in both between-family and within-family analyses. We report three findings that should be of interest to scholars in the stratification and education fields. First, raw parent–child correlations in education may reflect one-sixth genetic transmission and five-sixths social inheritance. Second, conditional on a child’s genetic score, a parental genetic score has no statistically significant relationship to the child’s educational attainment. Third, the effects of offspring genotype do not seem to be moderated by measured sociodemographic variables at the parental level (but parent–child genetic interaction effects are significant). These results are consistent with the existence of two separate systems of ascription: genetic inheritance (a random lottery within families) and social inheritance (across-family ascription). We caution, however, that at the presently attainable levels of explanatory power, these results are preliminary and may change when better-powered genetic risk scores are developed.'
- - https://www.psychologytoday.com/files/attachments/56143/wai-americas-elite-2013.pdf
  - ! "Investigating America's elite: Cognitive ability, education, and sex differences"
  - Jonathan Wai
  - 2013-03-25
  - '10.1016/j.intell.2013.03.005'
  - ! "Are the American elite drawn from the cognitive elite? To address this, five groups of America's elite (total <em>N</em> = 2254) were examined: Fortune 500 CEOs, federal judges, billionaires, Senators, and members of the House of Representatives. Within each of these groups, nearly all had attended college with the majority having attended either a highly selective undergraduate institution or graduate school of some kind. High average test scores required for admission to these institutions indicated those who rise to or are selected for these positions are highly filtered for ability. Ability and education level differences were found across various sectors in which the billionaires earned their wealth (e.g., technology vs. fashion and retail); even within billionaires and CEOs wealth was found to be connected to ability and education. Within the Senate and House, Democrats had a higher level of ability and education than Republicans. Females were underrepresented among all groups, but to a lesser degree among federal judges and Democrats and to a larger degree among Republicans and CEOs. America's elite are largely drawn from the intellectually gifted, with many in the top 1% of ability."
- - https://www.pawsoflife.org/Library/Temperment/Sinn%202010.pdf
  - 'Personality and performance in military working dogs: Reliability and predictive validity of behavioral tests'
  - David L. Sinna, Samuel D. Goslinga, Stewart Hilliard
  - 2010-09-09
  - 10.1016/j.applanim.2010.08.007
  - ! 'Quantification and description of individual differences in behavior, or personality differences, is now well-established in the working dog literature. What is less well-known is the predictive relationship between particular dog behavioral traits (if any) and important working outcomes. Here we evaluate the validity of a dog behavioral test instrument given to military working dogs (MWDs) from the 341<sup>st</sup> Training Squadron, USA Department of Defense (DoD); the test instrument has been used historically to select dogs to be trained for deployment. A 15-item instrument was applied on three separate occasions prior to training in patrol and detection tasks, after which dogs were given patrol-only, detection-only, or dual-certification status. On average, inter-rater reliability for all 15 items was high (mean = 0.77), but within this overall pattern, some behavioral items showed lower inter-rater reliability at some time points (&lt;0.40). Test–retest reliability for most (but not all) single item behaviors was strong (&gt;0.50) across shorter test intervals, but decreased with increasing test interval (&lt;0.40). Principal components analysis revealed four underlying dimensions that summarized test behavior, termed here ‘object focus’, ‘sharpness’, ‘human focus’, and ‘search focus’. These four aggregate behavioral traits also had the same pattern of short-, but not long-term test–retest reliability as that observed for single item behaviors. Prediction of certification outcomes using an independent test data set revealed that certification outcomes could not be predicted by breed, sex, or early test behaviors. However, prediction was improved by models that included two aggregate behavioral trait scores and three single item behaviors measured at the final test period, with 1 unit increases in these scores resulting in 1.7–2.8 increased odds of successful dual- and patrol-only certification outcomes. No improvements to odor-detection certification outcomes were made by any model. While only modest model improvements in prediction error were made by using behavioral parameters (2–7%), model predictions were based on data from dogs that had successfully completed all three test periods only, and therefore did not include data from dogs that were rejected during testing or training due to behavioral or medical reasons. Thus, future improvements to predictive models may be more substantial using independent predictors with less restrictions in range. Reports of the reliability and validity estimates of behavioral instruments currently used to select MWDs are scarce, and we discuss these results in terms of improving the efficiency by which working dog programs may select dogs for patrol and odor-detection duties using behavioral pre-screening instruments.'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4183313/bin/pnas.1404623111.sapp.pdf
  - Proxy-Phenotype Method Identifies Common Genetic Variants Associated with Cognitive Performance
  - Rietveld et al 2014
  - 2015-01-08
  - '10.1073/pnas.1404623111'
  - ! 'This document provides further details about materials, methods and additional analyses to accompany the research report “Proxy-Phenotype Method Identifies Common Genetic Variants Associated with Cognitive Performance.”'
- - https://www.mattblaze.org/papers/humancambridgepreproc.pdf
  - Toward a Broader View of Security Protocols
  - Matt Blaze
  - 2004-03-06
  - ''
  - ! 'This position paper initiates and advocates the study of “Human-Scale Security Protocols” as a core activity of computing and network security research. The Human-Scale Security Protocols (HSSP) project treats “human scale” security problems and protocols as a central part of computer science. Our aim is to identify, stimulate research on, analyze, and improve “non-traditional” protocols that might either have something to teach us or be susceptible to improvement via the techniques and tools of computer security. There are compelling security problems across a wide spectrum of areas that do not outwardly involve computers or electronic communication and yet are remarkably similar in structure to the systems computer scientists routinely study. Interesting and relevant problem spaces that computer security has traditionally ignored range from the very serious (preventing terrorists from subverting aviation security) to the trivial and personal (ensuring that a restaurant serves the same wine that was ordered and charged for).'
- - https://www.mathematica-mpr.com/-/media/publications/pdfs/nonexperimentalreps.pdf'
  - ! 'Nonexperimental Replications of Social Experiments: A Systematic Review'
  - Steven Glazerman, Dan M. Levy, David Myers
  - 2002-09
  - ''
  - ! 'Controlled experiments, where subjects are randomly assigned to receive interventions, are desirable but frequently perceived to be infeasible or overly burdensome, especially in social settings. Therefore, nonexperimental (also called quasi-experimental) methods are often used instead. Quasi-experimental methods are less intrusive and sometimes less costly than controlled experiments, but their validity rests on particular assumptions that are often difficult to test. It is therefore important to find empirical evidence to assess the likelihood that a given method applied in a given context will yield unbiased estimates. The current study is a systematic review of validation research to better understand the conditions under which quasiexperimental methods most closely approximate the results that would be found in a well-designed and well-executed experimental study. We collect and summarize a set of earlier studies that each tried, using convenience samples and one or more quasi-experimental methods, to replicate the findings from a social experiment. Our synthesis aims to give both producers and consumers of social program evaluations a clear understanding of what we know and what we do not know about the performance of quasi-experimental evaluation methods.'
- - https://www.dropbox.com/s/77amimyqhy9cjuu/2007-chiang-themerchantandthealchemistsgate.pdf
  - ! "The Merchant and the Alchemist's Gate"
  - Ted Chiang
  - 2007-09
  - ''
  - ! 'This fantasy short story by Ted Chiang follows Fuwaad ibn Abbas, a fabric merchant in the ancient city of Baghdad. It begins when he is searching for a gift to give a business associate and happens to discover a new shop in the marketplace. The shop owner, who makes and sells a variety of very interesting items, invites Fuwaad into the back workshop to see a mysterious black stone arch which serves as a gateway into the future, which the shop owner has made by the use of alchemy. Fuwaad is intrigued, and the shop owner tells him 3 stories of others who have traveled through the gate to meet and have conversation with their future selves. When Fuwaad learns that the shop keeper has another gate in Cairo that will allow people to travel even into the past, he makes the journey there to try to rectify a mistake he made 20 years earlier. [Summary adapted from Wikipedia]'
- - ! 'https://web.archive.org/web/20171025150859/http://nitro.biosci.arizona.edu:80/zbook/NewVolume_2/pdf/Chapter38.pdf'
  - 'Applications of Index Selection'
  - 'Bruce Walsh, Michael Lynch'
  - '1997-08-04'
  - ''
  - ! 'The first topic, which consists of the bulk of this chapter, is using index selection to improve a single trait. One can have a number of measures of the same trait in either relatives of a focal individual or as multiple measures of the same trait in a single individual, or both. How does one best use this information? We start by developing the general theory for using an index to improve the response in a single trait (which follows as a simplification of the Smith-Hazel index). We then apply these results to several important cases—a general analysis when either phenotypic or genotypic correlations are zero, improving response using repeated measurements of a characters over time, and using information from relatives to improve response with a special focus on combined selection (the optimal weighting of individual and family information, proving many of the details first presented in Chapter 17). As we will see in Chapter 35, the mixed-model power of BLUP provides a better solution to many of these problems, but index selection is both historically important as well as providing clean analytic results.  In contrast to the first topic, the final three are essentially independent of each other and we try to present them as such (so that the reader can simply turn to the section of interest without regard to previous material in this chapter). They include selection on a ratio, selection on sex-specific and sexually-dimorphic traits, and finally selection on the environmental variance σ<sup>2</sup><sub>E</sub> when it shows heritable variation (expanding upon results from Chapter 13).'
- - ! 'https://web.archive.org/web/20171025141547/http://nitro.biosci.arizona.edu:80/zbook/NewVolume_2/pdf/Chapter37.pdf'
  - Theory of Index Selection
  - Bruce Walsh, Michael Lynch
  - 1997-08-04
  - ''
  - ! 'While Chapters 28 and 29 present the basic theory for multivariate response, how, in practice, does one perform artificial selection on multiple traits? One of the commonest schemes is to construct some sort of index, wherein the investigator assigns (either explicitly or implicitly) a weighting scheme to each trait, creating a univariate character that becomes the target of selection. For example, if <em>z</em> is the vector of character values measured in an individual, the most common index is a linear combination <em>Pb<sub>i</sub>z<sub>i</sub> = b<sup>T</sup> z</em> and most of our discussion focuses on such linear indices. We start with a general review of the theory of selection on a linear index and then cover in great detail the Smith-Hazel index (the index giving the largest expected response in a specified linear combination of characters) and its extensions. We also discuss a number of other indices for different purposes, such as restricted (constraining changes in specified traits) and desired-gains (specifying how the components, rather than the index, will evolve) indices. We conclude our discussion of index selection by considering how to best handle nonlinear indices. We finish the chapter by examining the other approach for selecting on multiple traits, namely choosing traits sequentially. Tandem selection, focusing on a single trait each generation (where the focal trait changes over generations) is one such approach, while the other is to select different traits at different times within the life span of single individuals (independent culling and multistage index selection).'
- - ! 'https://tylermoore.utulsa.edu/toit17.pdf'
  - Revisiting the Risks of Bitcoin Currency Exchange Closure
  - Tyler Moore, Nicolas Christin, Janos Szurdi
  - '2016'
  - 10.1145/0000000.0000000
  - ! 'Bitcoin has enjoyed wider adoption than any previous cryptocurrency; yet its success has also attracted the attention of fraudsters who have taken advantage of operational insecurity and transaction irreversibility. We study the risk investors face from the closure of Bitcoin exchanges, which convert between Bitcoins and hard currency. We examine the track record of 80 Bitcoin exchanges established between 2010 and 2015. We find that nearly half (38) have since closed, with customer account balances sometimes wiped out. Fraudsters are sometimes to blame, but not always. 25 exchanges suffered security breaches, 15 of which subsequently closed. We present logistic regressions using using longitudinal data on Bitcoin exchanges aggregated quarterly. We find that experiencing a breach is correlated with a 13-times greater odds that an exchange will close in that same quarter. We find that higher-volume exchanges are less likely to close (each doubling in trade volume corresponds to a 12 percent decrease in the odds of closure). We also find that exchanges who derive most of their business from trading less popular (fiat) currencies, which are offered by at most one competitor, are less likely to close.'
- - ! 'https://sites.duke.edu/timurkuran/files/2017/09/Islam-Economic-Performance-Kuran-JEL-in-press.pdf'
  - 'Islam and Economic Performance: Historical and Contemporary Links'
  - Timur Kuran
  - '2018'
  - ''
  - ! 'This essay critically evaluates the analytic literature concerned with causal connections between Islam and economic performance. It focuses on works since 1997, when this literature was last surveyed. Among the findings are the following: Ramadan fasting by pregnant women harms prenatal development; Islamic charities mainly benefit the middle class; Islam affects educational outcomes less through Islamic schooling than through structural factors that handicap learning as a whole; Islamic finance hardly affects Muslim financial behavior; and low generalized trust depresses Muslim trade. The last feature reflects the Muslim world’s delay in transitioning from personal to impersonal exchange. The delay resulted from the persistent simplicity of the private enterprises formed under Islamic law. Weak property rights reinforced the private sector’s stagnation by driving capital out of commerce and into rigid waqfs. Waqfs limited economic development through their inflexibility and democratization by restraining the development of civil society. Parts of the Muslim world conquered by Arab armies are especially undemocratic, which suggests that early Islamic institutions, including slave-based armies, were particularly critical to the persistence of authoritarian patterns of governance. States have contributed themselves to the persistence of authoritarianism by treating Islam as an instrument of governance. As the world started to industrialize, non-Muslim subjects of Muslim-governed states pulled ahead of their Muslim neighbors by exercising the choice of law they enjoyed under Islamic law in favor of a Western legal system.'
- - https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.22.4.199
  - "Retrospectives Guinnessometrics: The Economic Foundation of “Student’s” t"
  - Stephen T. Ziliak
  - 2008-09
  - ''
  - ! 'In economics and other sciences, “statistical significance” is by custom, habit, and education a necessary and sufficient condition for proving an empirical result (Ziliak and McCloskey, 2008; McCloskey and Ziliak, 1996). The canonical routine is to calculate what’s called a t-statistic and then to compare its estimated value against a theoretically expected value of it, which is found in “Student’s” <em>t</em> table. A result yielding a <em>t</em>-value greater than or equal to about 2.0 is said to be “statistically significant at the 95 percent level.” Alternatively, a regression coefficient is said to be “statistically significantly different from the null, <em>p</em> &lt; .05.” Canonically speaking, if a coefficient clears the 95 percent hurdle, it warrants additional scientific attention. If not, not. The first presentation of “Student’s” test of significance came a century ago, in “The Probable Error of a Mean” (1908b), published by an anonymous “Student.” The author’s commercial employer required that his identity be shielded from competitors, but we have known for some decades that the article was written by William Sealy Gosset (1876–1937), whose entire career was spent at Guinness’s brewery in Dublin, where Gosset was a master brewer and experimental scientist (E. S. Pearson, 1937). Perhaps surprisingly, the ingenious “Student” did not give a hoot for a single finding of “statistical” significance, even at the 95 percent level of significance as established by his own tables. Beginning in 1904, “Student,” who was a businessman besides a scientist, took an economic approach to the logic of uncertainty, arguing finally that statistical significance is “nearly valueless” in itself.'
- - https://people.csail.mit.edu/pkrafft/papers/krafft-thesis-final.pdf
  - A Rational Choice Framework for Collective Behavior
  - Peter M. Krafft
  - 2017-09
  - ''
  - ! 'As the world becomes increasingly digitally mediated, people can more and more easily form groups, teams, and communities around shared interests and goals. Yet there is a constant struggle across forms of social organization to maintain stability and coherency in the face of disparate individual experiences and agendas. When are collectives able to function and thrive despite these challenges? In this thesis I propose a theoretical framework for reasoning about collective intelligence—the ability of people to accomplish their shared goals together. A simple result from the literature on multiagent systems suggests that strong general collective intelligence in the form of “rational group agency” arises from three conditions: aligned utilities, accurate shared beliefs, and coordinated actions. However, achieving these conditions can be difficult, as evidenced by impossibility results related to each condition from the literature on social choice, belief aggregation, and distributed systems. The theoretical framework I propose serves as a point of inspiration to study how human groups address these difficulties. To this end, I develop computational models of facets of human collective intelligence, and test these models in specific case studies. The models I introduce suggest distributed Bayesian inference as a framework for understanding shared belief formation, and also show that people can overcome other difficult computational challenges associated with achieving rational group agency, including balancing the group “exploration versus exploitation dilemma” for information gathering and inferring levels of “common p-belief” to coordinate actions.'
- - https://pdfs.semanticscholar.org/e17a/aaf487ec6415cac38e7e96490511e4b3b05d.pdf
  - "Why Aren’t We Smarter Already: Evolutionary Trade-Offs and Cognitive Enhancements"
  - Thomas T. Hills, Ralph Hertwig
  - '2011'
  - 10.1177/0963721411418300
  - ! 'Pharmacological enhancers of cognition promise a bright new future for humankind: more focus, more willpower, and better memory, with applications ranging from education to military combat. Underlying such promises is a linear, more-is-better vision of cognition that makes intuitive sense. This vision is at odds, however, with our understanding of cognition’s evolutionary origins. The mind has evolved under various constraints and consequently represents a delicate balance among these constraints. Evidence of the trade-offs that have shaped cognition include (a) inverted U-shaped performance curves commonly found in response to pharmacological interventions and (b) unintended side effects of enhancement on other traits. Taking an evolutionary perspective, we frame the above two sets of findings in terms of within-task (exemplified by optimal-control problems) and between-task (associated with a gain/loss asymmetry) trade-offs, respectively. With this framework, psychological science can provide much-needed guidance to enhancement development, a field that still lacks a theoretical foundation.'
- - https://pdfs.semanticscholar.org/b596/4787fc1abf739148d604abfbd2689e73e52f.pdf
  - The Fallacy Of The Null-Hypothesis Significance Test
  - William W. Rozeboom
  - '1960'
  - ''
  - ! 'In this paper, I wish to examine a dogma of inferential procedure which, for psychologists at least, has attained the status of a religious conviction. The dogma to be scrutinized is the "null-hypothesis significance test" orthodoxy that passing statistical judgment on a scientific hypothesis by means of experimental observation is a decision procedure wherein one rejects or accepts a null hypothesis according to whether or not the value of a sample statistic yielded by an experiment falls within a certain predetermined "rejection region" of its possible values. The thesis to be advanced is that despite the awesome preeminence this method has attained in our experimental journals and textbooks of applied statistics, it is based upon a fundamental misunderstanding of the nature of rational inference, and is seldom if ever appropriate to the aims of scientific research.'
- - https://pdfs.semanticscholar.org/76c6/ce0abf6f67f2c089df372261203989b43903.pdf
  - "Does Incubation Enhance Problem Solving? A Meta-Analytic Review"
  - Ut Na Sio, Thomas C. Ormerod
  - '2009'
  - 10.1037/a0014212
  - ! 'A meta-analytic review of empirical studies that have investigated incubation effects on problem solving is reported. Although some researchers have reported increased solution rates after an incubation period (i.e., a period of time in which a problem is set aside prior to further attempts to solve), others have failed to find effects. The analysis examined the contributions of moderators such as problem type, presence of solution-relevant or misleading cues, and lengths of preparation and incubation periods to incubation effect sizes. The authors identified a positive incubation effect, with divergent thinking tasks benefiting more than linguistic and visual insight tasks from incubation. Longer preparation periods gave a greater incubation effect, whereas filling an incubation period with high cognitive demand tasks gave a smaller incubation effect. Surprisingly, low cognitive demand tasks yielded a stronger incubation effect than did rest during an incubation period when solving linguistic insight problems. The existence of multiple types of incubation effect provides evidence for differential invocation of knowledge-based vs. strategic solution processes across different classes of problem, and it suggests that the conditions under which incubation can be used as a practical technique for enhancing problem solving must be designed with care.'
- - https://pdfs.semanticscholar.org/6698/bf91c9333faa0d333a800254b8063230d4f4.pdf
  - 'Optimizing retrieval as a learning event: When and why expanding retrieval practice enhances long-term retention'
  - Benjamin C. Storm, Robert Bjork, Jennifer C Storm
  - '2010'
  - 10.3758/MC.38.2.244
  - ! 'Retrieving information from memory makes that information more recallable in the future than it otherwise would have been. Optimizing retrieval practice has been assumed, on the basis of evidence and arguments tracing back to Landauer and Bjork (1978), to require an expanding-interval schedule of successive retrievals, but recent findings suggest that expanding retrieval practice may be inferior to uniform-interval retrieval practice when memory is tested after a long retention interval. We report three experiments in which participants read educational passages and were then repeatedly tested, without feedback, after an expanding or uniform sequence of intervals. On a test 1 week later, recall was enhanced by the expanding schedule, but only when the task between successive retrievals was highly interfering with memory for the passage. These results suggest that the extent to which learners benefit from expanding retrieval practice depends on the degree to which the to-be-learned information is vulnerable to forgetting.'
- - https://pdfs.semanticscholar.org/48cc/e5ee49facf75eeb12832c387452424b645dd.pdf
  - A Bayesian Framework for Reinforcement Learning
  - Malcolm Strens
  - 2000-06-28
  - ''
  - ! 'The reinforcement learning problem can be decomposed into two parallel types of inference: (i) estimating the parameters of a model for the underlying process; (ii) determining behavior which maximizes return under the estimated model. Following Dearden, Friedman and Andre (1999), it is proposed that the learning process estimates online the full posterior distribution over models. To determine behavior, a hypothesis is sampled from this distribution and the greedy policy with respect to the hypothesis is obtained by dynamic programming. By using a different hypothesis for each trial appropriate exploratory and exploitative behavior is obtained. This Bayesian method always converges to the optimal policy for a stationary process with discrete states.'
- - https://pdfs.semanticscholar.org/2e41/7612892dfb22ece5a98976a340d51dec06ed.pdf
  - IQ, Academic Performance, Environment and Earnings
  - Jeffrey S. Zax, Daniel I. Rees
  - 2001-05
  - ''
  - ! 'This paper explores the effects of peers, friends, family, IQ and academic performance, observed in the last year of high school, on earnings at ages 35 and 53. All significantly affect earnings at both ages. The effects of IQ are much smaller than asserted in, for example, <em>The Bell Curve</em>, and badly overstated in the absence of controls for family, wider context or academic performance. Aspirations appear to be very important. Socialization and role models may be as well, but not ability spillovers. Feasible increases in academic performance and education can compensate for the effects of many cognitive and contextual deficits. [This paper exemplifies the fallacy of controlling for intermediate variables&mdash;as if all those "controls" had nothing to do with IQ causing earnings! &mdash;Editor]'
- - https://ondoc.logand.com/d/2721/pdf
  - 'DARPA and the Quest for Machine Intelligence, 1983–1993'
  - Alex Roland, Philip Shiman
  - '2002'
  - ''
  - ! 'Between 1983 and 1993, the Defense Advanced Research Projects Agency (DARPA) spent an extra $1 billion on computer research to achieve machine intelligence.<sup>1</sup> The Strategic Computing Initiative (SCI) was conceived at the outset as an integrated plan to promote computer chip design and manufacturing, computer architecture, and artificial intelligence software. These technologies seemed ripe in the early 1980s. If only DARPA could connect them, it might achieve what Pamela McCorduck called “machines who think.” What distinguishes Strategic Computing (SC) from other stories of modern, large-scale technological development is that the program self-consciously set about advancing an entire research front. Instead of focusing on one problem after another, or of funding a whole field in hopes that all would prosper, SC treated intelligent machines as a single problem composed of interrelated subsystems. The strategy was to develop each of the subsystems cooperatively and map out the mechanisms by which they would connect. While most research programs entail tactics or strategy, SC boasted grand strategy, a master plan for an entire campaign.'
- - https://labs.la.utexas.edu/tucker-drob/files/2015/02/Hambrick-Tucker-Drob-2014-PBR-Genetics-of-Music-Accomplishment.pdf
  - 'The genetics of music accomplishment: Evidence for gene-environment correlation and interaction'
  - David Z. Hambrick, Elliot M. Tucker-Drob
  - '2014'
  - 10.3758/s13423-014-0671-9
  - ! 'Theories of skilled performance that emphasize training history, such as K. Anders Ericsson and colleagues’ deliberate-practice theory, have received a great deal of recent attention in both the scientific literature and the popular press. Twin studies, however, have demonstrated evidence for moderate-to-strong genetic influences on skilled performance. Focusing on musical accomplishment in a sample of over 800 pairs of twins, we found evidence for gene–environment correlation, in the form of a genetic effect on music practice. However, only about one quarter of the genetic effect on music accomplishment was explained by this genetic effect on music practice, suggesting that genetically influenced factors other than practice contribute to individual differences in music accomplishment. We also found evidence for gene-environment interaction, such that genetic effects on music accomplishment were most pronounced among those engaging in music practice, suggesting that genetic potentials for skilled performance are most fully expressed and fostered by practice.'
- - /docs/anime/2018-zhang.pdf
  - Two-stage Sketch Colorization
  - Lvmin Zhang, Chengze Li, Tientsin Wong, Yi Ji, Chunping Liu
  - '2018'
  - 10.1145/3272127.3275090
  - ! 'Sketch or line art colorization is a research field with significant market demand. Different from photo colorization which strongly relies on texture information, sketch colorization is more challenging as sketches may not have texture. Even worse, color, texture, and gradient have to be generated from the abstract sketch lines. In this paper, we propose a semi-automatic learning-based framework to colorize sketches with proper color, texture as well as gradient. Our framework consists of two stages. In the first drafting stage, our model guesses color regions and splashes a rich variety of colors over the sketch to obtain a color draft. In the second refinement stage, it detects the unnatural colors and artifacts, and try to fix and refine the result. Comparing to existing approaches, this two-stage design effectively divides the complex colorization task into two simpler and goal-clearer subtasks. This eases the learning and raises the quality of colorization. Our model resolves the artifacts such as water-color blurring, color distortion, and dull textures.  We build an interactive software based on our model for evaluation. Users can iteratively edit and refine the colorization. We evaluate our learning model and the interactive system through an extensive user study. Statistics shows that our method outperforms the state-of-art techniques and industrial applications in several aspects including, the visual quality, the ability of user control, user experience, and other metrics.'
- - https://academic.oup.com/beheco/article/21/3/639/220022
  - Social context of shell acquisition in Coenobita clypeatus hermit crabs
  - Randi D. Rotjan, Jeffrey R. Chabot, Sara M. Lewis
  - 2010-04-01
  - 10.1093/beheco/arq027
  - ! 'Vacancy chains involve unique patterns of resource acquisition behaviors that determine how reusable resources are distributed through animal populations. Shell vacancy chains have been described for several hermit crab species, both terrestrial and marine, but little is known about the ecological and behavioral dynamics of shell choice in social versus solitary contexts. Here, we present a novel conceptual framework that differentiates 2 types of shell vacancy chain in hermit crabs and discuss fundamentally distinct predictions concerning the behavioral and ecological costs and benefits associated with synchronous versus asynchronous vacancy chains. In laboratory studies of the terrestrial hermit crab <em>Coenobita clypeatus</em>, we found support for the prediction that social context alters shell acquisition behaviors. Field observations demonstrated that both synchronous and asynchronous vacancy chains are common and revealed previously undescribed waiting and piggybacking behaviors that appear to facilitate synchronous vacancy chains. Additionally, simulation results from an agent-based model showed that population density and waiting behaviors can both influence the likelihood of synchronous vacancy chains. Together, these results indicate that better understanding of hermit crab resource acquisition requires studying social behaviors, including vacancy chain formation.'
- - https://mpra.ub.uni-muenchen.de/74268/1/MPRA_paper_74268.pdf
  - Redundancy, Unilateralism and Bias beyond GDP – results of a Global Index Benchmark
  - Alexander Dill, Nicolas Gebhart
  - 2016-09-25
  - ''
  - ! 'Eight out of ten leading international indices to assess developing countries in aspects beyond GDP are showing strong redundancy, bias and unilateralism. The quantitative comparison gives evidence for the fact that always the same countries lead the ranks with a low standard deviation. The dependency of the GDP is striking: do the indices only measure indicators that are direct effects of a strong GDP? While the impact of GDP can be discussed reverse as well, the standard deviation shows a strong bias: only one out of the twenty countries with the highest standard deviation is among the Top-20 countries of the world, but 11 countries among those with the lowest standard deviation. Let’s have a look at the backsides of global statistics and methods to compare their findings. The article is the result of a pre-study to assess Social Capital for development countries made for the German Federal Ministry for Economic Cooperation and Development. The study led to the UN Sustainable Development Goals (UN SDG) project World Social Capital Monitor.'
- - http://www.incompleteideas.net/IncIdeas/BitterLesson.html
  - The Bitter Lesson
  - Rich Sutton
  - 2019-03-13
  - ''
  - ! '<p><strong>The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective</strong>, and by a large margin. The ultimate reason for this is Moore’s law, or rather its generalization of continued exponentially falling cost per unit of computation. Most AI research has been conducted as if the computation available to the agent were constant (in which case leveraging human knowledge would be one of the only ways to improve performance) but, over a slightly longer time than a typical research project, massively more computation inevitably becomes available. Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation.</p><p>…In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer-chess researchers who had pursued methods that leveraged human understanding of the special structure of chess…A similar pattern of research progress was seen in computer Go, only delayed by a further 20 years. Enormous initial efforts went into avoiding search by taking advantage of human knowledge, or of the special features of the game, but all those efforts proved irrelevant, or worse, once search was applied effectively at scale…In speech recognition, there was an early competition, sponsored by DARPA, in the 1970s. Entrants included a host of special methods that took advantage of human knowledge—knowledge of words, of phonemes, of the human vocal tract, etc. On the other side were newer methods that were more statistical in nature and did much more computation, based on hidden Markov models (HMMs). Again, the statistical methods won out over the human-knowledge-based methods… In computer vision…Modern deep-learning neural networks use only the notions of convolution and certain kinds of invariances, and perform much better.</p><p>…We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that (1) AI researchers have often tried to build knowledge into their agents, (2) this always helps in the short term, and is personally satisfying to the researcher, but (3) in the long run it plateaus and even inhibits further progress, and (4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.</p>'
- - /docs/genetics/heritable/2019-khera.pdf
  - Rare Genetic Variants Associated With Sudden Cardiac Death in Adults
  - Amit V. Khera, Heather Mason-Suares, Deanna Brockman, Minxian Wang, Martin J. VanDenburgh, Ozlem Senol-Cosar, Candace Patterson, Christopher Newton-Cheh, Seyedeh M. Zekavat, Julie Pester, Daniel I. Chasman, Christopher Kabrhel, Majken K. Jensen, JoAnn E. Manson, J. Michael Gaziano, Kent D. Taylor, Nona Sotoodehnia, Wendy S. Post, Stephen S. Rich, Jerome I. Rotter, Eric S. Lander, Heidi L. Rehm, Kenney Ng, Anthony Philippakis, Matthew Lebo, Christine M. Albert, Sekar Kathiresan
  - 2019-11-18
  - 10.1016/j.jacc.2019.08.1060
  - ! '<p><em>Background</em>: Sudden cardiac death occurs in ∼220,000 U.S. adults annually, the majority of whom have no prior symptoms or cardiovascular diagnosis. Rare pathogenic DNA variants in any of 49 genes can pre-dispose to 4 important causes of sudden cardiac death: cardiomyopathy, coronary artery disease, inherited arrhythmia syndrome, and aortopathy or aortic dissection.</p><p><em>Objectives</em>: This study assessed the prevalence of rare pathogenic variants in sudden cardiac death cases versus controls, and the prevalence and clinical importance of such mutations in an asymptomatic adult population.</p><p><em>Methods</em>: The authors performed whole-exome sequencing in a case-control cohort of 600 adult-onset sudden cardiac death cases and 600 matched controls from 106,098 participants of 6 prospective cohort studies. Observed DNA sequence variants in any of 49 genes with known association to cardiovascular disease were classified as pathogenic or likely pathogenic by a clinical laboratory geneticist blinded to case status. In an independent population of 4,525 asymptomatic adult participants of a prospective cohort study, the authors performed whole-genome sequencing and determined the prevalence of pathogenic or likely pathogenic variants and prospective association with cardiovascular death.</p><p><em>Results</em>: Among the 1,200 sudden cardiac death cases and controls, the authors identified 5,178 genetic variants and classified 14 as pathogenic or likely pathogenic. These 14 variants were present in 15 individuals, all of whom had experienced sudden cardiac death—corresponding to a pathogenic variant prevalence of 2.5% in cases and 0% in controls (<em>p</em> &lt; 0.0001). Among the 4,525 participants of the prospective cohort study, 41 (0.9%) carried a pathogenic or likely pathogenic variant and these individuals had 3.24-fold higher risk of cardiovascular death over a median follow-up of 14.3 years (<em>p</em> = 0.02).</p><p><em>Conclusions</em>: Gene sequencing identifies a pathogenic or likely pathogenic variant in a small but potentially important subset of adults experiencing sudden cardiac death; these variants are present in ∼1% of asymptomatic adults.</p>'
- - /docs/genetics/heritable/2016-bagnall.pdf
  - A Prospective Study of Sudden Cardiac Death among Children and Young Adults
  - Richard D. Bagnall, Robert G. Weintraub, Jodie Ingles, Johan Duflou, Laura Yeates, Lien Lam, Andrew M. Davis, Tina Thompson, Vanessa Connell, Jennie Wallace, Charles Naylor, Jackie Crawford, Donald R. Love, Lavinia Hallam, Jodi White, Christopher Lawrence, Matthew Lynch, Natalie Morgan, Paul James, Desirée du Sart, Rajesh Puranik, Neil Langlois, Jitendra Vohra, Ingrid Winship, John Atherton, Julie McGaughran, Jonathan R. Skinner, Christopher Semsarian
  - 2016-06-23
  - 10.1056/NEJMoa1510687
  - ! '<p><em>Background</em>: Sudden cardiac death among children and young adults is a devastating event. We performed a prospective, population-based, clinical and genetic study of sudden cardiac death among children and young adults.</p><p><em>Methods</em>: We prospectively collected clinical, demographic, and autopsy information on all cases of sudden cardiac death among children and young adults 1 to 35 years of age in Australia and New Zealand from 2010 through 2012. In cases that had no cause identified after a comprehensive autopsy that included toxicologic and histologic studies (unexplained sudden cardiac death), at least 59 cardiac genes were analyzed for a clinically relevant cardiac gene mutation.</p><p><em>Results</em>: A total of 490 cases of sudden cardiac death were identified. The annual incidence was 1.3 cases per 100,000 persons 1 to 35 years of age; 72% of the cases involved boys or young men. Persons 31 to 35 years of age had the highest incidence of sudden cardiac death (3.2 cases per 100,000 persons per year), and persons 16 to 20 years of age had the highest incidence of unexplained sudden cardiac death (0.8 cases per 100,000 persons per year). The most common explained causes of sudden cardiac death were coronary artery disease (24% of cases) and inherited cardiomyopathies (16% of cases). Unexplained sudden cardiac death (40% of cases) was the predominant finding among persons in all age groups, except for those 31 to 35 years of age, for whom coronary artery disease was the most common finding. Younger age and death at night were independently associated with unexplained sudden cardiac death as compared with explained sudden cardiac death. A clinically relevant cardiac gene mutation was identified in 31 of 113 cases (27%) of unexplained sudden cardiac death in which genetic testing was performed. During follow-up, a clinical diagnosis of an inherited cardiovascular disease was identified in 13% of the families in which an unexplained sudden cardiac death occurred.</p><p><em>Conclusions</em>: The addition of genetic testing to autopsy investigation substantially increased the identification of a possible cause of sudden cardiac death among children and young adults.</p>'
- - https://www.newscientist.com/article/2224569-controversial-dna-screening-technique-used-for-at-least-one-pregnancy/
  - Controversial DNA screening technique used for at least one pregnancy
  - Michael Le Page (<em>New Scientist</em>)
  - 2019-11-22
  - ''
  - ! '<p>A company called Genomic Prediction has confirmed that at least one woman is pregnant with embryos selected after analysing hundreds of thousands of DNA variants to assess the risk of disease. It is the first time this approach has been used for screening IVF embryos, but some don’t think this use of the technology is justified.</p><p>“Embryos have been chosen to reduce disease risk using pre-implantation genetic testing for polygenic traits, and this has resulted in pregnancy,” Laurent Tellier, CEO of Genomic Prediction, told New Scientist. He didn’t say how many pregnancies there were, or what traits or conditions were screened for.</p>'
- - /docs/genetics/editing/2019-anzalone.pdf
  - 'Search-and-replace genome editing without double-strand breaks or donor DNA'
  - Andrew V. Anzalone, Peyton B. Randolph, Jessie R. Davis, Alexander A. Sousa, Luke W. Koblan, Jonathan M. Levy, Peter J. Chen, Christopher Wilson, Gregory A. Newby, Aditya Raguram, David R. Liu
  - '2019-10-21'
  - '10.1038/s41586-019-1711-4'
  - ! 'Most genetic variants that contribute to disease<sup>1</sup> are challenging to correct efficiently and without excess byproducts<sup>2,3,4,5</sup>. Here we describe prime editing, a versatile and precise genome editing method that directly writes new genetic information into a specified DNA site using a catalytically impaired Cas9 endonuclease fused to an engineered reverse transcriptase, programmed with a prime editing guide RNA (pegRNA) that both specifies the target site and encodes the desired edit. We performed more than 175 edits in human cells, including targeted insertions, deletions, and all 12 types of point mutation, without requiring double-strand breaks or donor DNA templates. We used prime editing in human cells to correct, efficiently and with few byproducts, the primary genetic causes of sickle cell disease (requiring a transversion in HBB) and Tay–Sachs disease (requiring a deletion in HEXA); to install a protective transversion in PRNP; and to insert various tags and epitopes precisely into target loci. Four human cell lines and primary post-mitotic mouse cortical neurons support prime editing with varying efficiencies. Prime editing shows higher or similar efficiency and fewer byproducts than homology-directed repair, has complementary strengths and weaknesses compared to base editing, and induces much lower off-target editing than Cas9 nuclease at known Cas9 off-target sites. Prime editing substantially expands the scope and capabilities of genome editing, and in principle could correct up to 89% of known genetic variants associated with human diseases.'
- - https://www.wired.com/story/a-new-crispr-technique-could-fix-many-more-genetic-diseases/
  - ! 'A New Crispr Technique Could Fix Almost All Genetic Diseases: A less error-prone DNA editing method could correct many more harmful mutations than was previously possible'
  - Megan Molteni (<em>Wired</em>)
  - 2019-10-21
  - ''
  - ! '<p>Crispr, for all its DNA-snipping precision, has always been best at breaking things. But if you want to replace a faulty gene with a healthy one, things get more complicated. In addition to programming a piece of guide RNA to tell Crispr where to cut, you have to provide a copy of the new DNA and then hope the cell’s repair machinery installs it correctly. Which, spoiler alert, it often doesn’t. Anzalone wondered if instead there was a way to combine those two pieces, so that one molecule told Crispr both where to make its changes and what edits to make. Inspired, he cinched his coat tighter and hurried home to his apartment in Chelsea, sketching and Googling late into the night to see how it might be done.</p><p>A few months later, his idea found a home in the lab of David Liu, the Broad Institute chemist who’d recently developed a host of more surgical Crispr systems, known as base editors. Anzalone joined Liu’s lab in 2018, and together they began to engineer the Crispr creation glimpsed in the young post-doc’s imagination. After much trial and error, they wound up with something even more powerful. The system, which Liu’s lab has dubbed “prime editing,” can for the first time make virtually any alteration—additions, deletions, swapping any single letter for any other—without severing the DNA double helix. “If Crispr-Cas9 is like scissors and base editors are like pencils, then you can think of prime editors to be like word processors,” Liu told reporters in a press briefing.</p><p>Why is that a big deal? Because with such fine-tuned command of the genetic code, prime editing could, according to Liu’s calculations, correct around 89% of the mutations that cause heritable human diseases. Working in human cell cultures, his lab has already used prime editors to fix the genetic glitches that cause sickle cell anemia, cystic fibrosis, and Tay-Sachs disease. Those are just three of more than 175 edits the group unveiled today in a scientific article published in the journal <em>Nature</em>.</p><p>The work “has a strong potential to change the way we edit cells and be transformative,” says Gaétan Burgio, a geneticist at the Australian National University who was not involved in the work, in an email. He was especially impressed at the range of changes prime editing makes possible, including adding up to 44 DNA letters and deleting up to 80. “Overall, the editing efficiency and the versatility shown in this paper are remarkable.”</p><p>…The bigger problem, according to folks like Burgio, is that prime editors are huge, in molecular terms. They’re so big that they won’t pack up neatly into the viruses researchers typically use to shuttle editing components into cells. These colossi might even clog a microinjection needle, making it difficult to deliver into mouse (or potentially human) embryos. That, says Burgio, could make prime editing a lot less practical than existing techniques.</p>'
- - https://www.sciencemag.org/news/2019/10/new-prime-genome-editor-could-surpass-crispr
  - New ‘prime’ genome editor could surpass CRISPR
  - Jon Cohen (<em>Science Magazine</em>)
  - 2019-10-21
  - 10.1126/science.aaz9297
  - ! '<p>CRISPR, an extraordinarily powerful genome-editing tool invented in 2012, can still be clumsy. It sometimes changes genes it shouldn’t, and it edits by hacking through both strands of DNA’s double helix, leaving the cell to clean up the mess—shortcomings that limit its use in basic research and agriculture and pose safety risks in medicine. But a new entrant in the race to refine CRISPR promises to steer around some of its biggest faults. “It’s a huge step in the right direction,” chemist George Church, a CRISPR pioneer at Harvard University, says about the work, which appears online today in <em>Nature</em>.</p><p>…Liu’s earlier handwork, base editing, does not cut the double-stranded DNA but instead uses the CRISPR targeting apparatus to shuttle an additional enzyme to a desired sequence, where it converts a single nucleotide into another. Many genetic traits and diseases are caused by a single nucleotide change, so base editing offers a powerful alternative for biotechnology and medicine. But the method has limitations, and it, too, often introduces off-target mutations.</p><p>Prime editing steers around shortcomings of both techniques by heavily modifying the Cas9 protein and the guide RNA. The altered Cas9 only “nicks” a single strand of the double helix, instead of cutting both. The new guide, called a pegRNA, contains an RNA template for a new DNA sequence, to be added to the genome at the target location. That requires a second protein, attached to Cas9: a reverse transcriptase enzyme, which can make a new DNA strand from the RNA template and insert it at the nicked site.</p><p>Liu, who has already formed a company around the new technology, Prime Medicine, stresses that to gain a place in the editing toolkit, it will have to prove robust and useful in many labs. Delivering the large construct of RNA and enzymes into living cells will also be difficult, and no one has yet shown it can work in an animal model.</p>'
- - https://openreview.net/forum?id=r1lyTjAqYX#deepmind
  - Recurrent Experience Replay in Distributed Reinforcement Learning
  - Steven Kapturowski, Georg Ostrovski, John Quan, Remi Munos, Will Dabney
  - 2018-09-27
  - ''
  - ! '<p><em>Abstract</em>: Building on the recent successes of distributed training of RL agents, in this paper we investigate the training of RNN-based RL agents from distributed prioritized experience replay. We study the effects of parameter lag resulting in representational drift and recurrent state staleness and empirically derive an improved training strategy. Using a single network architecture and fixed set of hyper-parameters, the resulting agent, Recurrent Replay Distributed DQN (R2D2), quadruples the previous state of the art on Atari-57, and matches the state of the art on DMLab-30. It is the first agent to exceed human-level performance in 52 of the 57 Atari games.</p><p><em>Keywords</em>: RNN, LSTM, experience replay, distributed training, reinforcement learning</p><p><em>TL;DR</em>: Investigation on combining recurrent neural networks and experience replay leading to state-of-the-art agent on both Atari-57 and DMLab-30 using single set of hyper-parameters.</p>'
- - https://www.pnas.org/content/116/47/23505
  - A single combination gene therapy treats multiple age-related diseases
  - Noah Davidsohn, Matthew Pezzone, Andyna Vernet, Amanda Graveline, Daniel Oliver, Shimyn Slomovic, Sukanya Punthambaker, Xiaoming Sun, Ronglih Liao, Joseph V. Bonventre, George M. Church
  - 2019-11-19
  - 10.1073/pnas.1910073116
  - ! '<p><em>Significance</em>: Human and animal longevity is directly bound to their health span. While previous studies have provided evidence supporting this connection, therapeutic implementation of this knowledge has been limited. Traditionally, diseases are researched and treated individually, which ignores the interconnectedness of age-related conditions, necessitates multiple treatments with unrelated substances, and increases the accumulative risk of side effects. In this study, we address and overcome this deadlock by creating adeno-associated virus (AAV)-based antiaging gene therapies for simultaneous treatment of several age-related diseases. We demonstrate the modular and extensible nature of combination gene therapy by testing therapeutic AAV cocktails that confront multiple diseases in a single treatment. We observed that 1 treatment comprising 2 AAV gene therapies was efficacious against all 4 diseases.</p><p><em>Abstract</em>: Comorbidity is common as age increases, and currently prescribed treatments often ignore the interconnectedness of the involved age-related diseases. The presence of any one such disease usually increases the risk of having others, and new approaches will be more effective at increasing an individual’s health span by taking this systems-level view into account. In this study, we developed gene therapies based on 3 longevity associated genes (fibroblast growth factor 21 [FGF21], αKlotho, soluble form of mouse transforming growth factor-β receptor 2 [sTGFβR2]) delivered using adeno-associated viruses and explored their ability to mitigate 4 age-related diseases: obesity, type II diabetes, heart failure, and renal failure. Individually and combinatorially, we applied these therapies to disease-specific mouse models and found that this set of diverse pathologies could be effectively treated and in some cases, even reversed with a single dose. We observed a 58% increase in heart function in ascending aortic constriction ensuing heart failure, a 38% reduction in α-smooth muscle actin (αSMA) expression, and a 75% reduction in renal medullary atrophy in mice subjected to unilateral ureteral obstruction and a complete reversal of obesity and diabetes phenotypes in mice fed a constant high-fat diet. Crucially, we discovered that a single formulation combining 2 separate therapies into 1 was able to treat all 4 diseases. These results emphasize the promise of gene therapy for treating diverse age-related ailments and demonstrate the potential of combination gene therapy that may improve health span and longevity by addressing multiple diseases at once. [Keywords: gene therapy, AAV, combination therapy, age-related diseases]</p>'
- - https://jetpress.org/volume1/moravec.htm
  - When will computer hardware match the human brain?
  - Hans Moravec
  - '1998'
  - ''
  - ! 'This paper describes how the performance of AI machines tends to improve at the same pace that AI researchers get access to faster hardware. The processing power and memory capacity necessary to match general intellectual performance of the human brain are estimated. Based on extrapolation of past trends and on examination of technologies under development, it is predicted that the required hardware will be available in cheap machines in the 2020s...At the present rate, computers suitable for human-like robots will appear in the 2020s. Can the pace be sustained for another three decades?'
- - https://d4mucfpksywv.cloudfront.net/papers/GPT_2_Report.pdf#openai
  - Release Strategies and the Social Impacts of Language Models
  - Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, Jasmine Wang
  - '2019-11-05'
  - ''
  - ! '<p>GPT-2 is a large-scale unsupervised language model that generates coherent paragraphs of text, first announced by OpenAI in February 2019<sup>[63]</sup>. We developed four variants of the model, ranging in size from small (124 million parameters) to large (~1.5 billion parameters). We chose a staged release process, releasing the smallest model in February, but withholding larger models due to concerns about the potential for misuse, such as generating fake news content, impersonating others in email, or automating abusive social media content production<sup>[54]</sup>. We released the 355 million parameter model in May as part of a staged release process. We released our 774 million parameter model in August with a six-month follow up announcement, and we are now releasing our 1.5 billion parameter model.</p><p>While large language models’ flexibility and generative capabilities raise misuse concerns, they also have a range of beneficial uses—they can assist in prose, poetry, and programming; analyze dataset biases; and more. We want to release systems that will have a widely-distributed positive impact on society and have low misuse potential, and have striven to make release decisions informed by analysis,engagement, and empirical evidence.</p><p>Instead of releasing the full 1.5 billion model in February, we adopted a ‘staged release’ process. This delay of nine months allowed time between model releases to conduct risk and benefit analyses as model sizes increased. We also hope our staged release process was helpful in allowing others time to adapt and react: giving researchers a chance to mitigate risk of potential misuse, and giving the general public time to adapt to a world in which it is prudent to mistrust everything they read a little more. In addition to finding minimal evidence of misuse so far, several other factors contributed to our confidence in publishing our 774 million and 1.5 billion parameter models. These include what we learned about the positive social impact of beneficial uses, and what we learned through our partnerships among the AI community and through discussions across fields about establishing norms for responsible publication. This report discusses OpenAI’s work related to staged release of large models, partnership-based research, and broader issues in responsible publication that the AI community will need to address.</p><ul><li><p>Overview</p></li><li><p>Staged Release</p></li><li><p>Partnerships</p></li><li><p>Engagement</p></li><li><p>Social Impacts of Large Language Models</p><ul><li>Beneficial Use Potential</li><li>Misuse: Actor Assessment</li><li>Detecting Synthetic Text</li><li>Bias: Exploratory Research</li></ul></li><li><p>Future Trends in Language Models</p></li><li><p>Recommendations for Publication Norms in AI</p></li><li><p>Conclusion</p></li><li><p>Acknowledgments</p></li><li><p>References</p></li><li><p>Appendices</p><ul><li>Appendix A: Summary of Model Sharing Agreement</li><li>Appendix B: Release Timeline</li><li>Appendix C: Examples of Biases in GPT-2</li><li>Appendix D: Partner Research, Middlebury Institute of International Studies’ Center on Terrorism, Extremism, and Counterterrorism</li><li>Appendix E: Partner Research, Cornell University</li></ul></li></ul>'
- - https://openai.com/blog/gpt-2-1-5b-release/
  - ! 'GPT-2: 1.5B Release'
  - Irene Solaiman, Jack Clark, Miles Brundage
  - 2019-11-05
  - ''
  - ! '<p>As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we’ve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we’re actively continuing the conversation with the AI community on responsible publication.</p><p><em>Our findings</em>:</p><ol type="1"><li>Humans find GPT-2 outputs convincing.</li><li>GPT-2 can be fine-tuned for misuse.</li><li>Detection is challenging.</li><li>We’ve seen no strong evidence of misuse so far.</li><li>We need standards for studying bias.</li></ol><p>…<em>Next steps</em>: Our experience with GPT-2 over the past 9 months has given us valuable insight into the challenges and opportunities for creating responsible publication norms in AI. We’re continuing our work on this issue via participation in the Partnership on AI’s “Responsible Publication Norms for Machine Learning” project and discussions with our colleagues in the research community.</p>'
- - https://sites.google.com/view/videopredictioncapacity
  - ! 'High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks: Videos'
  - Ruben Villegas, Arkanath Pathak, Harini Kannan, Dumitru Erhan, Quoc V. Le, Honglak Lee
  - '2019'
  - ''
  - ! '<p>Sample videos generated by large-scale RNNs:</p><ul><li><p>128x128 Videos:</p><ul><li>Human 3.6M</li><li>KITTI Driving</li></ul></li><li><p>Video Comparisons (64x64):</p><ul><li>Towel pick</li><li>Human 3.6M</li><li>KITTI Driving</li><li>Towel pick</li><li>Human 3.6M</li><li>KITTI Driving</li></ul></li></ul>'
- - https://learningtopredict.github.io/#google
  - Learning to Predict Without Looking Ahead World Models Without Forward Prediction [blog writeup]
  - C. Daniel Freeman, Luke Metz, David Ha
  - 2019-10-29
  - ''
  - ! '<p>Much of model-based reinforcement learning involves learning a model of an agent’s world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware—e.g., a brain—arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call <em>observational dropout</em>, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into <em>learning</em> a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment.</p><p>[Image caption: “Our agents are only given infrequent observations of the real environment. As a side effect for optimizing performance in this setting, a “world model” emerges. We show the true dynamics in color, with full saturation denoting frames the policy can see. The black and white outline shows the state of the emergent world model. These world model exhibits similar, but not identical dynamics to forward predictive models but only model “important” aspects of the environment."]</p>'
- - http://www.aidungeon.io/2019/11/my-orc-band-and-our-quest-for-equal.html
  - 'AI Dungeon 2: My Musical Troupe of Orcs Uses Music to Advance Orc Rights'
  - Nick Walton
  - 2019-11-26
  - ''
  - ! '<p>[Demonstration dialogue of interacting with a GPT-2-1.5b trained on text adventures/RPGs. The player chooses to join a band of orcs as a musician and tries to steer the game towards orc rights, with moderate success, reaching the Emperor himself.]</p><p>In the first AI Dungeon, we created and deployed a deep learning generated text adventure using OpenAI’s 124M parameter GPT-2 model. In the interest of computational cost, possible actions and their results were generated and given to the player to choose from.</p><p>In AI Dungeon 2 we do away with pregenerated actions and allow the user to enter any action. The model then continues generating the story resulting from that action. We also upgrade the size of our model to OpenAI’s largest 1.5B parameter model and fine-tune it on a collection of text adventures obtained from <code>chooseyourstory.com</code>. Following the example of the <a href="https://arxiv.org/abs/1909.05858" title="&#39;CTRL: A Conditional Transformer Language Model for Controllable Generation&#39;, Keskar et al 2019">Salesforce CTRL model</a> we also modified the sampling of our model to add a penalty to already generated words to reduce the repetition issues that GPT-2 has and enable a lower temperature setting.</p><p>When playing AI Dungeon 2 the player can choose from several possible settings and characters. These choices generate a starting prompt and context sentence. The context sentence is always included as input to the model to help keep it grounded to the chosen setting while the starting prompt is the beginning of the story.</p> <p>[Dialogue sample:] </p> <p>...After the Gnoll War ends, the orcs decide to hold a big celebration. You immediately organize concert to entertain everyone. It goes well and you even win a few awards for your work. However, you still aren’t satisfied and you decide to do something else.</p><pre><code>&gt; write plays for the orcs to perform in</code></pre><p>You write a series of plays based on the stories of the orcs. These works are performed throughout the Empire and they are very popular. You also take an interest in the orcs’ future and begin to study their language and culture. In time you even develop a liking for the orcs themselves.</p><pre><code>&gt; found a human-orc friendship organization</code></pre><p>While you were studying the orcs, you came across a group called the Human-Orc Friendship Association (HOOFA). While they weren’t exactly like the Orcs, they had similar goals. You decided to form a separate chapter just for them.</p><pre><code>&gt; write some pamphlets support orc-human friendship</code></pre><p>You wrote a pamphlet explaining what the HOOFA was and how it worked. You also explained that the orcs were the only race that could truly understand each other and that humans were inferior to the orcs.</p><pre><code>&gt; promote inter-racial marriage between humans and orcs</code></pre><p>In order to promote inter-racial marriage between humans and orcs, you started a branch of the HOOFA called the Inter-Race Marriage Bureau (IRMB) which was located in the city of Kishak...</p>'
- - https://pkhungurn.github.io/talking-head-anime/
  - Talking Head Anime from a Single Image
  - Pramook Khungurn
  - 2019-11-25
  - ''
  - ! '<p>Fascinated by <a href="https://en.wikipedia.org/wiki/Virtual_YouTuber">virtual YouTubers</a>, I put together a deep neural network system that makes becoming one much easier. More specifically, the network takes as input an image of an anime character’s face and a desired pose, and it outputs another image of the same character in the given pose.'
- - /docs/conscientiousness/2019-wilmot.pdf
  - A century of research on conscientiousness at work
  - Michael P. Wilmot, Deniz S. Ones
  - 2019-11-12
  - 10.1073/pnas.1908430116
  - ! '<p><em>Significance</em>: Conscientiousness (C) is the most potent noncognitive predictor of occupational performance. However, questions remain about how C relates to a plethora of occupational variables, what its defining characteristics and functions are in occupational settings, and whether its performance relation differs across occupations. To answer these questions, we quantitatively review 92 meta-analyses reporting relations to 175 occupational variables. Across variables, results reveal a substantial mean effect of <em>ρ<sub>M</sub></em>=20.</p><p>We then use results to synthesize 10 themes that characterize C in occupational settings. Finally, we discover that performance effects of C are weaker in high-complexity versus low- to moderate-complexity occupations. Thus, for optimal occupational performance, we encourage decision makers to match C’s goal-directed motivation and behavioral restraint to more predictable environments.</p><p><em>Abstract</em>: Evidence from more than 100 y of research indicates that conscientiousness (C) is the most potent noncognitive construct for occupational performance. However, questions remain about the magnitudes of its effect sizes across occupational variables, its defining characteristics and functions in occupational settings, and potential moderators of its performance relation. Drawing on 92 unique meta-analyses reporting effects for 175 distinct variables, which represent <em>n</em> &gt; 1.1 million participants across <em>k</em> &gt; 2,500 studies, we present the most comprehensive, quantitative review and synthesis of the occupational effects of C available in the literature. Results show C has effects in a desirable direction for 98% of variables and a grand mean of <em>ρ<sub>M</sub></em>=0.20 (SD = 0.13), indicative of a potent, pervasive influence across occupational variables. Using the top 33% of effect sizes (<em>ρ</em>≥0.24), we synthesize 10 characteristic themes of C’s occupational functioning: (1) motivation for goal-directed performance, (2) preference for more predictable environments, (3) interpersonal responsibility for shared goals, (4) commitment, (5) perseverance, (6) self-regulatory restraint to avoid counterproductivity, and (7) proficient performance—especially for (8) conventional goals, (9) requiring persistence. Finally, we examine C’s relation to performance across 8 occupations. Results indicate that occupational complexity moderates this relation. That is, (10) high occupational complexity versus low-to-moderate occupational complexity attenuates the performance effect of C. Altogether, results suggest that goal-directed performance is fundamental to C and that motivational engagement, behavioral restraint, and environmental predictability influence its optimal occupational expression. We conclude by discussing applied and policy implications of our findings. [Keywords: conscientiousness, personality, meta-analysis, second-order meta-analysis, occupations]</p>'
- - https://www.nature.com/articles/d41586-019-03268-y
  - ! 'On the troubling trail of psychiatry’s pseudopatients stunt: Susannah Cahalan’s investigation of the social-psychology experiment that saw healthy people sent to mental hospitals finds inconsistencies'
  - ! 'Alison Abbott (<em>Nature</em>)'
  - ! '2019-10-29'
  - ! '10.1038/d41586-019-03268-y'
  - ! '<p>Although Rosenhan died in 2012, Cahalan easily tracked down his archives, held by social psychologist Lee Ross, his friend and colleague at Stanford. They included the first 200 pages of Rosenhan’s unfinished draft of a book about the experiment…Ross warned her that Rosenhan had been secretive. As her attempts to identify the pseudonymous pseudopatients hit one dead end after the other, she realized Ross’s prescience.</p><p>The archives did allow Cahalan to piece together the beginnings of the experiment in 1969, when Rosenhan was teaching psychology at Swarthmore College in Pennsylvania…Rosenhan cautiously decided to check things out for himself first. He emerged humbled from nine traumatizing days in a locked ward, and abandoned the idea of putting students through the experience.</p><p>…According to Rosenhan’s draft, it was at a conference dinner that he met his first recruits: a recently retired psychiatrist and his psychologist wife. The psychiatrist’s sister also signed up. But the draft didn’t explain how, when and why subsequent recruits signed up. Cahalan interviewed numerous people who had known Rosenhan personally or indirectly. She also chased down the medical records of individuals whom she suspected could have been involved in the experiment, and spoke with their families and friends. But her sleuthing brought her to only one participant, a former Stanford graduate student called Bill Underwood.</p><p>…Underwood and his wife were happy to talk, but two of their comments jarred. Rosenhan’s draft described how he prepared his volunteers very carefully, over weeks. Underwood, however, remembered only brief guidance on how to avoid swallowing medication by hiding pills in his cheek. His wife recalled Rosenhan telling her that he had prepared writs of <em>habeas corpus</em> for each pseudopatient, in case an institution would not discharge them. But Cahalan had already worked out that that wasn’t so.</p><p>Comparing the <em>Science</em> report with documents in Rosenhan’s archives, she also noted many mismatches in numbers. For instance, Rosenhan’s draft, and the Science paper, stated that Underwood had spent seven days in a hospital with 8,000 patients, whereas he spent eight days in a hospital with 1,500 patients.</p><p>When all of the leads from her contacts led to ground, she published a commentary in <em>The Lancet Psychiatry</em> asking for help in finding them—to no avail. Had Rosenhan invented them, she found herself asking?</p>'
- - https://pdfs.semanticscholar.org/57c8/aa6e7101b6cb7f1db2076401318cdb60b0c1.pdf
  - ! "On Pseudoscience in Science, Logic in Remission, and Psychiatric Diagnosis: A Critique of Rosenhan's 'On Being Sane in Insane Places'"
  - Robert L. Spitzer
  - '1975'
  - ''
  - ! '<p>Rosenhan’s “On Being Sane in Insane Places” is pseudoscience presented as science. Just as his pseudopatients were diagnosed at discharge as “schizophrenia in remission”, so a careful examination of this study’s methods, results, and conclusion leads to a diagnosis of “logic in remission”. Rosenhan’s study proves that pseudopatients are not detected by psychiatrists as having simulated signs of mental illness. This rather unremarkable finding is not relevant to the real problems of the reliability and validity of psychiatric diagnosis and only serves to obscure them. A correct interpretation of these data contradicts the conclusions that were drawn. In the setting of a psychiatric hospital, psychiatrists seem remarkably able to distinguish the “sane” from the “insane”.</p>'
- - https://nypost.com/2019/11/02/stanford-professor-who-changed-america-with-just-one-study-was-also-a-liar/
  - Stanford professor who changed America with just one study was also a liar
  - Susannah Cahalan
  - 2019-11-02
  - ''
  - ! "[Summary of investigation into David Rosenhan: like the Robbers Cave or Stanford Prison Experiment, his famous fake-insane patients experiment cannot be verified and many troubling anomalies have come to light. Cahalan is unable to find almost all of the supposed participants, Rosenhan hid his own participation & his own medical records show he fabricated details of his case, he throw out participant data that didn't match his narrative, reported numbers are inconsistent, Rosenhan abandoned a lucrative book deal about it and avoided further psychiatric research, and showed some character traits of a fabulist eager to please.]"
- - https://medium.com/@jsmp/orchestrating-false-beliefs-about-gender-discrimination-a25a48e1d02
  - Orchestrating false beliefs about gender discrimination
  - Jonatan Pallesen
  - 2019-02-19
  - ''
  - ! 'Blind auditions and gender discrimination: A seminal paper from 2000 investigated the impact of blind auditions in orchestras, and found that they increased the proportion of women in symphony orchestras. I investigate the study, and find that there is no good evidence presented. [The study is temporally confounded by a national trend of increasing female participation, does not actually establish any particular correlate of blind auditions, much less randomized experiments of blinding, the dataset is extremely underpowered, the effects cited in coverage cannot be found anywhere in the paper, and the critical comparisons which <em>are</em> there are not even statistically-significant in the first place. None of these caveats are included in the numerous citations of the study as "proving" discrimination against women.]'
- - https://onlinelibrary.wiley.com/doi/full/10.1002/anie.201410356
  - Disappearing Polymorphs Revisited
  - Dejan-Krešimir Bučar, Robert W. Lancaster, Joel Bernstein
  - 2015-06-01
  - 10.1002/anie.201410356
  - ! 'Nearly twenty years ago, Dunitz and Bernstein described a selection of intriguing cases of polymorphs that disappear. The inability to obtain a crystal form that has previously been prepared is indeed a frustrating and potentially serious problem for solid-state scientists. This Review discusses recent occurrences and examples of disappearing polymorphs (as well as the emergence of elusive crystal forms) to demonstrate the enduring relevance of this troublesome, but always captivating, phenomenon in solid-state research. A number of these instances have been central issues in patent litigations. This Review, therefore, also highlights the complex relationship between crystal chemistry and the law.'
- - /docs/science/1995-dunitz.pdf
  - Disappearing Polymorphs
  - Jack D. Dunitz, Joel Bernstein
  - '1995'
  - ''
  - ! '<p>When a compound exhibits polymorphism—the existence of more than one crystal structure—it may be important to obtain a particular polymorph under controlled and reproducible conditions. However, this is not always easy to achieve. Tales of difficulties in obtaining crystals of a particular known form or in reproducing results from another laboratory (or even from one’s own!) abound. Indeed, there are cases where it was difficult to obtain a given polymorphic form even though this had previously been obtained routinely over long time periods. Several monographs contain explicit or passing references to these problems, but much of this lore has gone undocumented, especially in the last 30 years or so. In this Account we present and discuss old and new examples.</p>'
- - https://www.theguardian.com/news/2019/nov/07/the-dice-man-elusive-author-luke-rhinehart-george-cockroft-emmanuel-carrere
  - ! "Who is the real Dice Man? The elusive writer behind the disturbing cult novel: A search for the mysterious author of a counterculture classic led to someone else entirely. Or did it?"
  - Emmanuel Carrère (<em>Guardian</em>)
  - 2019-11-07
  - ''
  - ! "<p>[A writer tracks down the author of <em>Dice Man</em>, George Cockcroft, who turns out to be an ordinary old novelist retired on a farm in upstate New York, who developed the novel’s idea from a minor game played as a youth. He profiles followers of the dice man approach, who turn out to be far more interesting as the dice pushes them into unusual risk-taking: for example, one Cuadrado, who “Like his father, he is a tax lawyer, but thanks to the dice he has also become a wine importer, a webmaster, a Go teacher, a fan of Iceland and the publisher of the Mauritian poet Malcolm de Chazal.”]</p>"
- - https://blogs.sciencemag.org/pipeline/archives/2019/11/26/perverse-polymorphism
  - Perverse Polymorphism
  - Derek Lowe
  - 2019-11-26
  - ''
  - ! '<p>…as the case of ritonavir shows, you can have a compound that has been worked on for years and produced commercially in bulk that hits upon a more stable solid phase. And since these more stable crystal forms tend to have very different solubilities, the effect on a drug development program (or in ritonavir’s case, a drug that is already rolling off the manufacturing line!) can be extremely unwelcome. When this happens, it can seem as if the original crystal form is going extinct and never to be seen again, an effect that seems almost supernatural. But as these papers note, the “unintentional crystalline seed” hypothesis is surely the explanation.</p><p>…What’s more, a given cubic foot of air could easily contain a million or so particles under a half-micron size without anyone noticing at all. Consider also that such too-small-to-see particles can lurk in what looks like a clear solution, and you have plenty of opportunities to spread a given polymorph around by what seems like magic. The 2015 paper tracks down several examples of the spread of such material…It’s also not true that polymorphs can truly go extinct, either, although it’s understandable that it might appear that way. There are always conditions out there to obtain the old crystalline form, although there is no requirement that these be easy to find (!) Indeed, the original form of ritonavir was recovered and brought back into production after a great deal of effort, although not before HIV-positive patients had seen their medicine disappear from the shelves for months (and not before Abbott had lost a quarter of a billion dollars along the way).</p><p>…There are compounds for which only one crystalline form has ever been reported, and there are others with two dozen polymorphs (and when that’s happening, you can be pretty sure that there are some others that haven’t shown up yet). Only one polymorph of aspirin was known until 2005, when another turned up.</p>'
- - https://www.atlasobscura.com/articles/imposter-brooklyn-weyman-clifford
  - "The Many Faces of Brooklyn’s Greatest Imposter: Stanley Clifford Weyman lived many, many lives"
  - Eric Grundhauser
  - 2017-08-23
  - ''
  - ! '<p>There are those who impersonate other people for money and fame, and then there are people like Stanley Clifford Weyman (not his real name), Brooklyn’s greatest imposter, who did it for the love of living in the skin of others. Throughout his life, Weyman impersonated military officials, political figures, and even the personal doctor of Rudolph Valentino’s widow—all just because he wanted to.</p><p>…Weinberg never impersonated specific people, but rather invented figures with variations of his name, such as “Rodney S. Wyman” and “Allen Stanley Weyman.” A couple of his recurring favorites were “Ethan Allen Weinberg” and “Royal St. Cyr”, but according to a 1968 story about him in The New Yorker, he settled on Stanley Clifford Weyman, as his more or less permanent name, around middle age.</p><p>…According to <em>The New Yorker</em> profile, his years of faking included time as “several doctors of medicine, and two psychiatrists, he was a number of officers in the United States Navy—ranging in rank from lieutenant to admiral—five or six United States Army officers, a couple of lawyers, the State Department Naval Liaison Officer, an aviator, a sanitation expert, many consuls-general, and a United Nations expert on Balkan and Asian affairs.” Weyman was no hero, but his ambition and dedication to craft are, perhaps, admirable. Very few images of Weyman exist, so his face isn’t so recognizable today, but that’s probably exactly as he would have had it.</p>'
- - https://vitalik.ca/general/2019/11/22/progress.html
  - "Hard Problems in Cryptocurrency: Five Years Later"
  - Vitalik Buterin
  - 2019-11-22
  - ''
  - ! '<p>[Vitalik Buterin of Ethereum reviews cryptocurrency technological developments since 2014, in cryptography, consensus theory, &amp; economics:]</p><ol type="1"><li><p>Cryptographic:</p><ul><li><em>Blockchain scalability</em>: Great theoretical progress, pending more real-world evaluation.</li><li><em>Distributed secure timestamping</em>: Some progress.</li><li><em>Arbitrary Proof of Computation</em>: Great theoretical and practical progress. [SNARKs/STARK/SHARK etc]</li><li><em>Code Obfuscation [DRM]</em>: Slow progress.</li><li><em>Hash-Based Cryptography [which is quantum-secure]</em>: Some progress.</li></ul></li><li><p>Consensus theory:</p><ul><li><em>ASIC-Resistant Proof of Work</em>: Solved as far as we can.</li><li><em>Useful Proof of Work</em>: Probably not feasible, with one exception.</li><li><em>Proof of Stake</em>: Great theoretical progress, pending more real-world evaluation.</li><li><em>Proof of Storage</em>: A lot of theoretical progress, though still a lot to go, as well as more real-world evaluation.</li></ul></li><li><p>Economics:</p><ul><li><p><em>Stable-value cryptoassets</em>: Some progress.</p></li><li><p><em>Decentralized Public Goods Incentivization</em>: Some progress.</p></li><li><p><em>Reputation systems</em>: Slow progress</p></li><li><p><em>Proof of excellence</em>: No progress, problem is largely forgotten.</p></li><li><p><em>Anti-Sybil systems</em>: Some progress.</p><ul><li><em>Decentralized contribution metrics</em>: Some progress, some change in focus.</li></ul></li><li><p><em>Decentralized success metrics</em>: Some progress.</p></li></ul></li></ol><p>…In general, base-layer problems are slowly but surely decreasing, but application-layer problems are only just getting started.</p>'
- - https://pointersgonewild.com/2019/11/02/they-might-never-tell-you-its-broken/
  - They Might Never Tell You It’s Broken
  - Maxime Chevalier-Boisvert
  - 2019-11-02
  - ''
  - ! '<p>As part of my PhD, I developed Higgs, an experimental JIT compiler…I developed it on GitHub, completely in the open, and wrote about my progress on this blog. Pretty soon, the project had 300 stars on GitHub, a handful of open source contributors, and I was receiving some nice feedback.</p><p>…One day, someone I had been exchanging with on the chat room for two weeks reached out to me to signal a strange bug. They couldn’t get the tests to pass and were getting a segmentation fault. I was puzzled. They asked me if Higgs had MacOS support. I explained that I’d never tested it on MacOS myself, but I couldn’t see any reason why it wouldn’t work. I told this person that the problem was surely on their end. Higgs had been open source for over a year. It was a pretty niche project, but I knew for a fact that at least 40–60 people must have tried it, and at least 50% of these people must have been running MacOS. I assumed that surely, if Higgs didn’t run on MacOS at all, someone would have opened a GitHub issue by now. Again, I was wrong.</p><p>…It’s a horrifying thought, but it could be that for every one person who opens an issue on GitHub, 100 or more people have already tried your project, run into that same bug, and simply moved on.</p>'
- - https://www.frontiersin.org/articles/10.3389/fphys.2012.00082/full
  - Fatigue is a brain-derived emotion that regulates the exercise behavior to ensure the protection of whole body homeostasis
  - Timothy David Noakes
  - 2012-04-12
  - 10.3389/fphys.2012.00082
  - ! 'An influential book written by A. Mosso in the late nineteenth century proposed that fatigue that “at first sight might appear an imperfection of our body, is on the contrary one of its most marvelous perfections. The fatigue increasing more rapidly than the amount of work done saves us from the injury which lesser sensibility would involve for the organism” so that “muscular fatigue also is at bottom an exhaustion of the nervous system.” It has taken more than a century to confirm Mosso’s idea that both the brain and the muscles alter their function during exercise and that fatigue is predominantly an emotion, part of a complex regulation, the goal of which is to protect the body from harm. Mosso’s ideas were supplanted in the English literature by those of A. V. Hill who believed that fatigue was the result of biochemical changes in the exercising limb muscles–“peripheral fatigue”–to which the central nervous system makes no contribution. The past decade has witnessed the growing realization that this brainless model cannot explain exercise performance. This article traces the evolution of our modern understanding of how the CNS regulates exercise specifically to insure that each exercise bout terminates whilst homeostasis is retained in all bodily systems. The brain uses the symptoms of fatigue as key regulators to insure that the exercise is completed before harm develops. These sensations of fatigue are unique to each individual and are illusory since their generation is largely independent of the real biological state of the athlete at the time they develop. The model predicts that attempts to understand fatigue and to explain superior human athletic performance purely on the basis of the body’s known physiological and metabolic responses to exercise must fail since subconscious and conscious mental decisions made by winners and losers, in both training and competition, are the ultimate determinants of both fatigue and athletic performance.'
- - https://nintil.com/
  - Nintil
  - Jose Luis Ricon
  - ''
  - ''
  - ! 'Blog of Jose Luis Ricon (<a href="https://twitter.com/ArtirKel">Twitter</a>), machine learning engineer. Ricon blogs primarily about economics and progress studies, mixing link compilations with more researched essays such as about the economic (in)efficiency of the USSR, or the extent to which tutoring & "direct instruction" boost educational achievement.'
- - https://talktotransformer.com/
  - Talk To Transformer
  - Adam King
  - '2019'
  - ''
  - ! "[Interactive web interface to GPT-2-1.5b.] See how a modern neural network completes your text. Type a custom snippet or try one of the examples...Built by Adam King (@AdamDanielKing) as an easier way to play with OpenAI's new machine learning model. This site runs the full-sized GPT-2 model, called 1558M."
- - https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/
  - 'XLM-R: State-of-the-art cross-lingual understanding through self-supervision'
  - FAIR
  - 2019-11-07
  - ''
  - ! '<p>A new model, called XLM-R, that uses self-supervised training techniques to achieve state-of-the-art performance in cross-lingual understanding, a task in which a model is trained in one language and then used with other languages without additional training data. Our model improves upon previous multilingual approaches by incorporating more training data and languages—including so-called low-resource languages, which lack extensive labeled and unlabeled data sets.</p><p>XLM-R has achieved the best results to date on four cross-lingual understanding benchmarks, with increases of 4.7 percent average accuracy on the XNLI cross-lingual natural language inference data set, 8.4 percent average F1 score on the recently introduced MLQA question answering data set, and 2.1 percent F1 score on NER. After extensive experiments and ablation studies, we’ve shown that XLM-R is the first multilingual model to outperform traditional monolingual baselines that rely on pretrained models.</p><p>In addition to sharing our results, we’re releasing the code and models that we used for this research. Those resources can be found on our fairseq, Pytext and XLM repositories on GitHub.</p><p>…With people on Facebook posting content in more than 160 languages, XLM-R represents an important step toward our vision of providing the best possible experience on our platforms for everyone, regardless of what language they speak. Potential applications include serving highly accurate models for identifying hate speech and other policy-violating content across a wide range of languages. As this work helps us transition toward a one-model-for-many-languages approach—as opposed to one model per language—it will also make it easier to continue launching high-performing products in multiple languages at once.</p>'
- - /docs/science/1960-campbell.pdf#page=5
  - The Self-Repairing Robot
  - John W. Campbell
  - '1960'
  - ''
  - ! '<p>[From <em>Analog Magazine</em>, October 1960 (v66, #2), pg87–88.</p><p>Campbell describes two examples:</p><ol type="1"><li>glycerine, where attempts to freeze it per a German chemist’s research failed and resulted only in a glass, until they contacted him for information and he sent a sample of his glycerine back, which ‘contaminated’ their own samples and resulted in frozen glycerine but now never glass.</li><li>EDT: Bell Labs was growing quartz-substitute crystals called EDT which worked perfectly, replacing expensive quartz, until one day a new polymorph showed up, destroying all EDT crystal production. All attempts to recreate EDT failed, but fortunately, the problem of growing quartz had been solved in the mean time, so it was ultimately not a disaster.]</li></ol>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.2289&rep=rep1&type=pdf
  - Computer-Generated Floral Ornament
  - Michael T. Wong, Douglas E. Zongker, David H. Salesin
  - '1998'
  - ''
  - ! 'This paper describes some of the principles of traditional floral ornamental design, and explores ways in which these designs can be created algorithmically. It introduces the idea of “adaptive clip art”, which encapsulates the rules for creating a specific ornamental pattern. Adaptive clip art can be used to generate patterns that are tailored to fit a particularly shaped region of the plane. If the region is resized or reshaped, the ornament can be automatically regenerated to fill this new area in an appropriate way. Our ornamental patterns are created in two steps: first, the geometry of the pattern is generated as a set of two-dimensional curves and filled boundaries; second, this geometry is rendered in any number of styles. We demonstrate our approach with a variety of floral ornamental designs.'
- - https://pdfs.semanticscholar.org/ccac/0394825b1a8ab9933f8ca3449e5b66a5a526.pdf
  - 'Magnetic Curves: Curvature-Controlled Aesthetic Curves Using Magnetic Fields'
  - Ling Xu, David Mould
  - '2009'
  - ''
  - ! 'We describe “magnetic curves”, a particle-tracing method that creates curves with constantly changing curvature. It is well known that charged particles in a constant magnetic field trace out circular or helical trajectories. Motivated by John Ruskin’s advice to use variation in curvature to achieve aesthetic curves, we propose to continuously change the charge on a simulated particle so that it can trace out a complex curve with continuously varying curvature. We show some examples of abstract figures created by this method and also show how some stylized representational forms, including fire, hair, and trees, can be drawn with magnetic curves.'
- - https://medium.com/@tokudu/computer-generated-floral-ornament-based-on-magnetic-curves-d77a3f206893
  - Computer-generated Floral Ornament Based on Magnetic Curves
  - Anton Lopyrev
  - 2016-08-02
  - ''
  - ! '<p>While the concept of using vegetation to produce ornament seems to be very trivial to take up, it proves to be difficult to create a good floral ornament design by hand. It turns out that hand drawn floral ornamentation is a very time-consuming task that requires a great deal of skill and training. In fact, most of the floral clip-art found on the web (Figure 3) is usually produced by experienced artists and is usually quite costly. As a result, one naturally tends to think about automated ways of generate floral motifs.</p><p>This article explores the problem of how to produce aesthetically pleasing computer-generated ornament. The method described here is a combination of two papers by Ling Xu et al. [11] and M. T. Wong et al. [1], which are further discussed in the next section. However, instead of making the entire process fully automated, as aforementioned papers suggest, this article focuses on an idea of interactive user control. The vision here is that while it is possible to automatically produce a relatively attractive floral ornament, artistic input still remains the best tool for evaluation, about whether or not the resultant ornament is indeed aesthetically pleasing. Consequently, the tool that is described in this article relies on a heavy UI component.</p><p>…The starting point of my algorithm is the basic implementation of the magnetic curves paper. The idea behind the magnetic curves algorithm is that under certain constraints a charged particle that moves under the influence of a magnetic field will trace out interesting spiral curves. By recursively releasing secondary particles from the original particle at constant intervals, more complicated curves that resemble branching vegetation can be produced.</p><p>…In this article I presented an overview of a tool I developed for interactive generation of floral ornament. While constrained to a pre-set selection of clip-art, this tool showcases the great possibilities of the magnetic curves algorithm to produce aesthetically pleasing ornament, when combined with the idea of adaptive clip-art. Without a doubt, the algorithm I presented in this article greatly improves upon Ling Xu’s results from his original “magnetic curves” article. The results that I was able to achieve with my tool are comparable in their quality to a floral design that can be produced by a professional artist. I hope that the work I’ve done here can be used one day to aid an artist in the generation of beautiful designs.</p>'
- - https://publicdomainreview.org/about/
  - 'The Public Domain Review: About'
  - The Public Domain Review
  - ''
  - ''
  - ! '<p>Founded in 2011, <strong>The Public Domain Review</strong> is an online journal and not-for-profit project dedicated to the exploration of curious and compelling works from the history of art, literature, and ideas.</p><p>In particular, as our name suggests, the focus is on works which have now fallen into the public domain, that vast commons of out-of-copyright material that everyone is free to enjoy, share, and build upon without restriction. Our aim is to promote and celebrate the public domain in all its abundance and variety, and help our readers explore its rich terrain–like a small exhibition gallery at the entrance to an immense network of archives and storage rooms that lie beyond. With a focus on the surprising, the strange, and the beautiful, we hope to provide an ever-growing cabinet of curiosities for the digital age, a kind of hyperlinked <em>Wunderkammer</em>–an archive of content which truly celebrates the breadth and diversity of our shared cultural commons and the minds that have made it.</p><p>…Some highlights include visions of the future from late 19<sup>th</sup> century France, a dictionary of Victorian slang and a film showing the very talented “hand-farting” farmer of Michigan… from a history of the smile in portraiture to the case of the woman who claimed to give birth to rabbits.</p>'
- - https://identitydesigned.com/issho/
  - 'Issho: Designed by Dutchscot, London'
  - Identity Designed
  - 2018-11-20
  - ''
  - ! 'Gallery of a Japanese restaurant, Issho, which has been redesigned by the minimalist design firm Dutchscot. The design emphasises <em>kintsugi</em>, irregular gold stripes used to repair pottery, white/red/blue, and traditional Japanese cloud motifs.'
- - https://publicdomainreview.org/essay/the-lost-world-of-the-london-coffeehouse/
  - The Lost World of the London Coffeehouse
  - Matthew Green
  - 2013-08-07
  - ''
  - ! "In contrast to today's rather mundane spawn of coffeehouse chains, the London of the 17<sup>th</sup> and 18<sup>th</sup> century was home to an eclectic and thriving coffee drinking scene. Dr Matthew Green explores the halcyon days of the London coffeehouse, a haven for caffeine-fueled debate and innovation which helped to shape the modern world."
- - '/docs/anime/1993-anno-charscounterattackfanclubbook-khodazattranslation.pdf#page=4'
  - "Excerpts from the Hideaki Anno/Yoshiyuki Tomino interview from the <em>Char's Counterattack Fan Club Book</em> (1993)"
  - 'Hideaki Anno, Yoshiyuki Tomino, trans. kohdazat'
  - '1993'
  - ''
  - ! '<p><code>Ogura</code>: Usually he’s [Mamoru Oshii] very critical of other people’s works. Did you hear what he had to say about <em>Porco Rosso</em>?</p><p><code>Anno</code>: Oh, I’m critical of <em>Porco Rosso</em>, myself.</p><p><code>Tomino</code>: What was wrong with <em>Porco</em>?</p><p><code>Anno</code>: As a picture, nothing. But because I know Miyazaki-san personally, I can’t view it objectively. His presence in the film is too conspicuous, it’s no good. In other words… it feels like he’s showing off.</p><p><code>Tomino</code>: How so?</p><p><code>Anno</code>: He has the main character act all self-deprecating, calling himself a pig… but then puts him in a bright red plane, has him smoking all cool-like, even creates a love triangle between a cute young thing and a sexy older lady.</p><p><code>Tomino</code>: Ha! I see what you mean. He and I are around the same age, though. So I get how he feels, unconditionally. So I may think, “Oh boy…” but I can’t stay mad at him (laughs).</p>'
- - https://tvtropes.org/pmwiki/pmwiki.php/Main/KickTheDog
  - "Trope: 'Kick the Dog'"
  - TVTropes
  - ''
  - ''
  - ! '<p>When a character does something evil, cruel or very mean for no apparent gain, because the author wants to demonstrate that he’s not a nice guy and shift audience sympathy away from him.</p><p>Why this trope works could be expressed in the words of William Cowper: “I would not enter on my list of friends (though graced with polished manners and fine sense, yet wanting sensibility) the man who needlessly sets foot upon a worm.” In other words, a cruel act, no matter how trivial, establishes someone as a cruel person. Conversely, the creator may show a character being kind for no apparent gain, to demonstrate that the character is a nice person and someone the audience is meant to cheer for. Both devices are used to help the audience become emotionally invested in the story.</p><p>What separates this trope from a character’s other evil or cruel acts is that this bit of evil is gratuitous. It doesn’t get the character anything or even advance the plot. The sole reason for this story beat existing is to place one or more characters squarely on the wrong side of the Rule of Empathy.</p>'
- - https://www.animenewsnetwork.com/review/belladonna-of-sadness/.102644
  - "Review: <em>Belladonna of Sadness</em>"
  - Gabriella Elkins (ANN)
  - 2016-06-17
  - ''
  - ! '<p><em>Summary</em>: Medieval peasants Jean and Jeanne are idyllic newlyweds. Their happiness vanishes, however, when Jeanne is raped by the local lord in a legally sanctioned deflowering ritual. Afterwards, while the couple tries to resume their life together, Jeanne starts receiving visions from a demon. It comforts her in her sadness, but it also encourages her to act out against the lord. Jeanne resists at first, but as her fortunes continue to wane, she’s thrown further into the demon’s embrace. As time goes on, Jeanne is drawn into an experience that radically reconfigures her sense of herself, the world, and the course of history itself.</p><p><em>Review</em>: An X-rated anime classic newly remastered for the screen, <em>Belladonna of Sadness</em> is one of animation’s premiere psychedelic experiences, brought over to North America for nearly the first time ever in 2016. Its history has already been covered by us before, but here’s a quick refresher: <em>Belladonna of Sadness</em> is a legendarily low-budget, sexual, and psychedelic anime film from the 1970s. Poorly received at the time of its release, it accrued a cult audience over the next few decades. Recently, its reputation has been rehabilitated to the point where it’s considered an overlooked classic. Still, wider appreciation of the film was hampered by the lack of an English release and poor quality of existing prints. That changed in 2014, when the high-end distribution company Cinelicious chose it as their first candidate for an in-house 4k restoration and re-release. This May, the completed film began screening in theaters across the United States and Canada, and will continue to do so until September. I attended one of these screenings at International House theater in Philadelphia. This was my first time seeing the film, and I left very much impressed by both its artistry and storytelling.</p><p>…Fair warning, though—it’s not an exaggeration that this film is touted as ultra-sexual. I’d say most of the film’s runtime is made up of sex scenes, some of them violent and disturbing. It literally opens with a rape. These scenes are appropriate to the story, and the scenes are gorgeous in their artistry, but they are unpleasant. Otherwise, the sexual imagery is largely abstract. Flowers become vaginas, figures in cloaks become disembodied penises, and Jeanne’s rape is depicted as her being bisected from the groin upwards. Some psychedelic sequences also contain intense strobe lighting, so epileptics be warned. As for the visuals themselves, expect watercolors, morphing lineart, and little in terms of actual animation. There are no lush Kyoto Animation frame counts here. Much of the film’s motion consists of pans and zooms across static illustrations. There aren’t even any lip flaps. The studio went under while making this film, so this was a method of cutting costs. However, the results are memorable and even contribute to the film’s power. (There’s a great analysis to be written about its use of vertical versus horizontal space.) Despite these limitations, <em>Belladonna of Sadness</em> is, on a purely aesthetic level, almost unbelievably beautiful. I’d hang any given frame of it up on my wall. Even if you don’t care about it’s message, this film is still worth watching as a work of altered-state eroticism.</p><p>Overall, viewers who can handle the content will probably be entertained by this gorgeous and trippy movie. However, I especially recommend <em>Belladonna of Sadness</em> to anyone interested in the history of anime.</p><p>…<em>Belladonna of Sadness</em> is the culmination of a rare attempt to make blatantly un-commercial, artistically challenging anime. At the cost of bankruptcy, Mushi Productions made a masterpiece that wouldn’t be fully appreciated for 40 years. Now hindsight allows us to see the breadth of its influence and depth of its daring. Get in on this experience while you have the chance.</p>'
- - https://publicdomainreview.org/essay/made-in-taiwan-how-a-frenchman-fooled-18th-century-london/
  - "Made in Taiwan? How a Frenchman Fooled 18<sup>th</sup>-Century London"
  - Benjamin Breen
  - 2018-04-18
  - ''
  - ! 'Benjamin Breen on the remarkable story of George Psalmanazar, the mysterious Frenchman who successfully posed as a native of Formosa (now modern Taiwan) and gave birth to a meticulously fabricated culture with bizarre customs, exotic fashions, and its own invented language...Who was this man? The available facts remain surprisingly slim. Despite hundreds of years of research by everyone from the father of British Prime Minister Benjamin Disraeli to contemporary scholars at Penn and the National Taiwan University, we still don’t even know Psalmanazar’s real name or place of origin (although he was likely from southern France). We know that elite figures ranging from the scientists of the Royal Society to the Bishop of London initially believed his claims, but he eventually fell into disgrace as competing experts confirmed that he was a liar. Beyond this, we move into the fictional realms that "Psalmanazar", like a Borges character come to life, summoned into existence with his voice and pen...Although the scale and singularity of his deception made him unique, Psalmanazar was also representative: while he was inventing tales of Formosan cannibalism, his peers were writing falsified histories of pirate utopias, parodic accounts of islands populated by super-intelligent horses, and sincere descriptions of demonic sacrifices.'
- - https://publicdomainreview.org/essay/exquisite-rot-spalted-wood-and-the-lost-art-of-intarsia/
  - "Exquisite Rot: Spalted Wood and the Lost Art of Intarsia"
  - Daniel Elkind
  - 2018-05-16
  - ''
  - ! '<p>The technique of intarsia—the fitting together of pieces of intricately cut wood to make often complex images—has produced some of the most awe-inspiring pieces of Renaissance craftsmanship. Daniel Elkind explores the history of this masterful art, and how an added dash of colour arose from a most unlikely source: lumber ridden with fungus...painting in wood is in many ways more complicated than painting on wood. Rather than fabricating objects from a single source, the art of intarsia is the art of mosaic, of picking the right tone, of sourcing only properly seasoned lumber from mature trees and adapting materials intended for one context to another. Painting obscures the origins of a given material, whereas intarsia retains the original character of the wood grain—whose knots and whorls are as individual as the islands and deltas of friction ridges that constitute the topography of a fingerprint—while forming a new image. From a distance, the whole appears greater than the sum of its parts; up close, one can appreciate the heterogeneity of the components...</p> <p>Inspired by the New Testament and uninhibited by Mosaic proscription, craftsmen in the city of Siena began to introduce flora and fauna into their compositions in the 14<sup>th</sup> century. Figures and faces became common by the late fifteenth century and, by the early sixteenth century, <em>intarsiatori</em> in Florence were making use of a wide variety of dyes in addition to natural hardwoods to mimic the full spectrum from the lightest (spindlewood) to medium (walnut) and dark (bog oak)—with the tantalizing exception of an aquamarine color somewhere between green and blue which required treating wood with “copper acetate (verdigris) and copper sulfate (vitriol).”<sup>8</sup></p><p>…Furnishings that featured slivers of <em>griinfaule</em> or “green oak” were especially prized by master cabinetmakers like Bartholomew Weisshaupt and coveted by the elite of the Holy Roman Empire.<sup>10</sup> Breaking open rotting hardwood logs to reveal delicate veins of turquoise and aquamarine, craftsmen discovered that the green in green oak was the result of colonization by the green elf-cup fungus, <em>Chlorociboria aeruginascens</em>, whose tiny teal fruiting bodies grow on felled, barkless conifers and hardwoods like oak and beech across much of Europe, Asia, and North America. Fungal rot usually devalues wood, but green oak happened to fill a lucrative niche in a burgeoning luxury trade, and that made it, for a time at least, as precious as some rare metals. During the reign of Charles V, when the Hapsburgs ruled both Spain and Germany, a lively trade in these intarsia pieces sprang up between the two countries.</p>'
- - https://publicdomainreview.org/essay/o-uommibatto-how-the-pre-raphaelites-became-obsessed-with-the-wombat/
  - ! '"O Uommibatto": How the Pre-Raphaelites Became Obsessed with the Wombat'
  - Angus Trumble
  - 2019-01-10
  - ''
  - ! '<p>Angus Trumble on Dante Gabriel Rossetti and company’s curious but longstanding fixation with the furry oddity that is the wombat—that “most beautiful of God’s creatures”—which found its way into their poems, their art, and even, for a brief while, their homes…the Pre-Raphaelites were not the first English to become enamoured by the unusual creature. Wombats captured the attention of English naturalists as soon as they found out about them from early settlers, explorers, and naturalists at the time of first contact. The Aboriginal word wombat was first recorded near Port Jackson, and though variants such as wombach, womback, the wom-bat and womat were noted, the present form of the name stuck very early, from at least 1797. Beautiful drawings survive from the 1802 voyages of the <em>Investigator</em> and <em>Le Géographe</em>. Ferdinand Bauer, who sailed with Matthew Flinders, and Charles-Alexandre Lesueur, who was in the rival French expedition of Nicolas Baudin, both drew the creature. These were engraved and carefully studied at home. Wombats were admired for their stumpy strength, their patience, their placid, not to say congenial manners, and also a kind of stoic determination. Occasionally they were thought clumsy, insensible or even stupid, but these isolated observations are out of step with the majority of nineteenth-century opinion.</p>'
- - https://publicdomainreview.org/essay/visions-of-algae-in-eighteenth-century-botany/
  - Visions of Algae in Eighteenth-Century Botany
  - Ryan Feigenbaum
  - 2016-09-07
  - ''
  - ! "Although not normally considered the most glamorous of Mother Nature's offerings, algae has found itself at the heart of many a key moment in the last few hundred years of botanical science. Ryan Feigenbaum traces the surprising history of one particular species—<em>Conferva fontinalis</em>—from the vials of Joseph Priestley's laboratory to its possible role as inspiration for Shelley's <em>Frankenstein</em>."
- - https://publicdomainreview.org/essay/greenland-unicorns-and-the-magical-alicorn/
  - Greenland Unicorns and the Magical Alicorn
  - Natalie Lawrence
  - 2019-09-19
  - ''
  - ! 'When the existence of unicorns, and the curative powers of the horns ascribed to them, began to be questioned, one Danish physician pushed back through curious means—by reframing the unicorn as an aquatic creature of the northern seas. Natalie Lawrence on a fascinating convergence of established folklore, nascent science, and pharmaceutical economy.'
- - https://publicdomainreview.org/essay/mesmerising-science-the-franklin-commission-and-the-modern-clinical-trial/
  - Mesmerising Science The Franklin Commission and the Modern Clinical Trial
  - Urte Laukaityte
  - 2018-11-20
  - ''
  - ! 'Benjamin Franklin, magnetic trees, and erotically-charged séances— Urte Laukaityte on how a craze for sessions of "animal magnetism" in late 18<sup>th</sup>-century Paris led to the randomised placebo-controlled and double-blind clinical trials we know and love today...By a lucky coincidence, Benjamin Franklin was in France as the first US ambassador with a mission to ensure an official alliance against its arch nemesis, the British. On account of his fame as a great man of science in general and his experiments on one such invisible force—electricity—in particular, Franklin was appointed as head of the royal commission. The investigating team also included the chemist Antoine-Laurent Lavoisier, the astronomer Jean-Sylvain Bailly, and the doctor Joseph-Ignace Guillotin. It is a curious fact of history that both Lavoisier and Bailly were later executed by the guillotine—the device attributed to their fellow commissioner. The revolution also, of course, brought the same fate to King Louis XVI and his Mesmer-supporting wife Marie Antoinette. In a stroke of insight, the commissioners figured that the cures might be affected by one of two possible mechanisms: psychological suggestion (what they refer to as “imagination”) or some actual physical magnetic action. Mesmer and his followers claimed it was the magnetic fluid, so that served as the experimental condition if you like. Continuing with the modern analogies, suggestion would then represent a rudimentary placebo control condition. So to test animal magnetism, they came up with two kinds of trials to try and separate the two possibilities: either the research subject is being magnetised but does not know it (magnetism without imagination) or the subject is not being magnetised but thinks that they are (imagination without magnetism). The fact that the trials were blind, or in other words, the patients did not know when the magnetic operation was being performed, marks the commission’s most innovative contribution to science...Whatever the moral case may be, the report paved the way for the modern empirical approach in more ways than one. Stephen Jay Gould called the work “a masterpiece of the genre, an enduring testimony to the power and beauty of reason” that “should be rescued from its current obscurity, translated into all languages”. Just to mention a few further insights, the commissioners were patently aware of psychological phenomena like the experimenter effect, concerned as they were that some patients might report certain sensations because they thought that is what the eminent men of science wanted to hear. That seems to be what propelled them to make the study placebo-controlled and single-blind. Other phenomena reminiscent of the modern-day notion of priming, and the role of expectations more generally, are pointed out throughout the document. The report also contains a detailed account of how self-directed attention can generate what are known today as psychosomatic symptoms. Relatedly, there is an incredibly lucid discussion of mass psychogenic illness, and mass hysteria more generally, including in cases of war and political upheaval. Just five years later, France would descend into the chaos of a violent revolution.'
- - https://publicdomainreview.org/essay/bugs-and-beasts-before-the-law/
  - Bugs and Beasts Before the Law
  - Nicholas Humphrey
  - 2011-03-27
  - ''
  - ! '<p>Murderous pigs sent to the gallows, sparrows prosecuted for chattering in church, a gang of thieving rats let off on a wholly technical acquittal—theoretical psychologist and author Nicholas Humphrey explores the strange world of medieval animal trials.</p><p>…Such stories, however, are apparently not news for very long. Indeed the most extraordinary examples of people taking retribution against animals seem to have been almost totally forgotten. A few years ago I lighted on a book, first published in 1906, with the surprising title <em>The Criminal Prosecution and Capital Punishment of Animals</em> by E.P.Evans, author of <em>Animal Symbolism in Ecclesiastical Architecture</em>, <em>Bugs and Beasts before the Law</em>, etc., etc. The frontispiece showed an engraving of a pig, dressed up in a jacket and breeches, being strung up on a gallows in the market square of a town in Normandy in 1386; the pig had been formally tried and convicted of murder by the local court. When I borrowed the book from the Cambridge University Library, I showed this picture of the pig to the librarian. “Is it a joke?”, she asked.</p><p>No, it was not a joke. All over Europe, throughout the middle-ages and right on into the 19<sup>th</sup> century, animals were, as it turns out, tried for human crimes. Dogs, pigs, cows, rats and even flies and caterpillars were arraigned in court on charges ranging from murder to obscenity. The trials were conducted with full ceremony: evidence was heard on both sides, witnesses were called, and in many cases the accused animal was granted a form of legal aid—a lawyer being appointed at the tax-payer’s expense to conduct the animal’s defence.</p><p>…Evans’ book details more than two hundred such cases: sparrows being prosecuted for chattering in Church, a pig executed for stealing a communion wafer, a cock burnt at the stake for laying an egg. As I read my eyes grew wider and wider.</p>'
- - https://publicdomainreview.org/essay/the-snowflake-man-of-vermont/
  - The Snowflake Man of Vermont
  - Keith C. Heidorn
  - 2011-02-14
  - ''
  - ! 'Keith C. Heidorn takes a look at the life and work of Wilson Bentley, a self-educated farmer from a small American town who, by combining a bellows camera with a microscope, managed to photograph the dizzyingly intricate and diverse structures of the snow crystal.'
- - https://resobscura.blogspot.com/2017/05/why-are-there-so-many-17th-century.html
  - 'Why Are There So Many 17<sup>th</sup> Century Paintings of Monkeys Getting Drunk?'
  - Benjamin Breen
  - 2017-05-04
  - ''
  - ! '<p>One cold Friday in 1660, Samuel Pepys encountered two unpleasant surprises. “At home found all well,” he wrote in his diary, “but the monkey loose, which did anger me, and so I did strike her.” Later that night, a candlemaker named Will Joyce (the good-for-nothing husband of one of Pepys’s cousins) stumbled in on Pepys and his aunt while “drunk, and in a talking vapouring humour of his state, and I know not what, which did vex me cruelly.” Presumably, Pepys didn’t resort to blows this time around.</p><p>The two objects of Pepys’ scorn that day, his disobedient pet monkey and his drunken cousin-in-law, were not as distant as one might think. Monkeys stood in for intoxicated humans on a surprisingly frequent basis in 17<sup>th</sup> century culture. In early modern paintings, tippling primates can frequently be seen in human clothing, smoking tobacco, playing cards, rolling dice, and just plain getting wasted.</p><p>Why?</p><p>… So what is going on with these images showing drunken and drug-selling monkeys? I think that what we’re missing when we simply see these as a form of social satire is that these are also paintings about <em>addiction</em>. Desire is a dominant theme in these works: monkeys are shown jealously squabbling over piles of tobacco, or even, in the example below, hoarding tulip flowers during the height of the Dutch tulipmania (they appear to be using the profits to get drunk, in the upper left)…But there’s an alternative narrative running through these paintings as well. It epitomizes the ambivalence that has long surrounded intoxicating substances, in many cultures and in many times: These monkeys seem to be having fun.</p>'
- - https://publicdomainreview.org/collection/alexander-graham-bell-s-tetrahedral-kites-1903-9/
  - "Alexander Graham Bell's Tetrahedral Kites (1903–9) [image gallery]"
  - The Public Domain Review
  - ''
  - ''
  - ! "<p>The wonderful imagery documenting Alexander Graham Bell's experiments with tetrahedral kites.…the Scottish-born inventor Alexander Graham Bell is also noted for his work in aerodynamics, a rather more photogenic endeavour perhaps, as evidenced by the wonderful imagery documenting his experiments with tetrahedral kites. The series of photographs depict Bell and his colleagues demonstrating and testing out a number of different kite designs, all based upon the tetrahedral structure, to whose pyramid-shaped cells Bell was drawn as they could share joints and spars and so crucially lessen the weight-to-surface area ratio…Bell began his experiments with tetrahedral box kites in 1898, eventually developing elaborate structures comprised of multiple compound tetrahedral kites covered in maroon silk, constructed with the aim of carrying a human through the air. Named <em>Cygnet</em> I, II, and III (for they took off from water) these enormous tetrahedral beings were flown both unmanned and manned during a five year period from 1907 until 1912.</p>"
- - https://publicdomainreview.org/collection/the-model-book-of-calligraphy-1561-1596/
  - "The Model Book of Calligraphy (1561–1596) [image gallery]"
  - The Public Domain Review
  - ''
  - ''
  - ! '<p>Pages from a remarkable book entitled <em>Mira calligraphiae monumenta</em> (<em>The Model Book of Calligraphy</em>), the result of a collaboration across many decades between a master scribe, the Croatian-born Georg Bocskay, and Flemish artist Joris Hoefnagel. In the early 1560s, while secretary to the Holy Roman Emperor Ferdinand I, Bocksay produced his Model Book of Calligraphy, showing off the wonderful range of writing style in his repertoire. Some 30 years later (and 15 years after the death of Bocskay), Ferdinand’s grandson, who had inherited the book, commissioned Hoefnagel to add his delightful illustrations of flowers, fruits, and insects. It would prove to be, as The Getty, who now own the manuscript, comment, “one of the most unusual collaborations between scribe and painter in the history of manuscript illumination”. In addition to the amendments to Bocksay’s pages shown here, Hoefnagel also added an elaborately illustrated section on constructing the letters of the alphabet which we featured on the site a while back.</p>'
- - https://publicdomainreview.org/essay/christopher-smarts-jubilate-agno/
  - ! "Christopher Smart’s Jubilate Agno"
  - Frank Key
  - 2011-01-31
  - ''
  - ! '<p>The poet Christopher Smart—also known as “Kit Smart”, “Kitty Smart”, “Jack Smart” and, on occasion, “Mrs Mary Midnight”—was a well known figure in 18<sup>th</sup>-century London. Nowadays he is perhaps best known for considering his cat Jeoffry. Writer and broadcaster Frank Key looks at Smart’s weird and wonderful <em>Jubilate Agno</em>…</p><p>It was not until 1939 that his masterpiece, written during his confinement in St Luke’s, was first published. <em>Jubilate Agno</em> is one of the most extraordinary poems in the English language, and almost certainly the reason we remember Christopher Smart today. It has been described as a vast hymn of praise to God and all His works, and also as the ravings of a madman. Indeed, that first edition was published under the title <em>Rejoice In The Lamb: A Song From Bedlam</em>, clearly marking it as a curio from the history of mental illness. It was W. H. Bond’s revised edition of 1954 which gave order to Smart’s surviving manuscript, restoring the Latin title <em>Jubilate Agno</em>, bringing us the poem in the form we know it today.</p><p>Christopher Smart never completed the work, which consists of four fragments making a total of over 1,200 lines, each beginning with the words “Let” or “For”. For example, Fragment A is all “Let”s, whereas in Fragment B the “Let”s and “For”s are paired, which may have been the intention for the entire work, modelled on <a href="https://en.wikipedia.org/wiki/Antiphon">antiphonal</a> <a href="https://en.wikipedia.org/wiki/Biblical_poetry">Hebrew poetry</a>. References and allusions abound to Biblical (especially Old Testament) figures, plants and animals, gems, contemporary politics and science, the poet’s family and friends, even obituary lists in current periodicals. The language is full of puns, archaisms, coinages, and unfamiliar usages. Dr Johnson famously said “Nothing odd will do long; <em>Tristram Shandy</em> did not last”. <em>Jubilate Agno</em> is, if anything, “odder” than Sterne’s novel, and perhaps we are readier to appreciate it in the twenty-first century than when it was written…one of the great joys of <em>Jubilate Agno</em> is in its sudden dislocations and unexpected diversions. The “my cat Jeoffrey” passage is justly famous, but the poem is cram-packed with similar wonders, and must be read in full to appreciate its inimitable genius.</p>'
- - https://publicdomainreview.org/essay/illustrations-of-madness-james-tilly-matthews-and-the-air-loom/
  - 'Illustrations of Madness: James Tilly Matthews and the Air Loom'
  - Mike Jay
  - 2014-11-12
  - ''
  - ! '<p>Mike Jay recounts the tragic story of James Tilly Matthews, a former peace activist of the Napoleonic Wars who was confined to London’s notorious Bedlam asylum in 1797 for believing that his mind was under the control of the “Air Loom”—a terrifying machine whose mesmeric rays and mysterious gases were brainwashing politicians and plunging Europe into revolution, terror, and war.</p><p>…Over the ten years they had spent together in Bedlam, Matthews revealed his secret world to Haslam in exhaustive detail. Around the corner from Bedlam, in a dank basement cellar by London Wall, a gang of villains were controlling and tormenting him with a machine called an “Air Loom”. Matthews had even drawn a technical diagram of the device, which Haslam included in his book with a sarcastic commentary that invited the reader to laugh at its absurdity: a literal “illustration of madness”. But Matthews’ drawing has a more unnerving effect than Haslam allows. Levers, barrels, batteries, brass retorts and cylinders are rendered with the cool conviction of an engineer’s blueprint. It is the first ever published work of art by an asylum inmate, but it would hardly have looked out of place in the scientific journals or enyclopaedias of its day.</p><p>The Air Loom worked, as its name suggests, by weaving “airs”, or gases, into a “warp of magnetic fluid” which was then directed at its victim. Matthews’ explanation of its powers combined the cutting-edge technologies of pneumatic chemistry and the electric battery with the controversial science of animal magnetism, or mesmerism. The finer detail becomes increasingly strange. It was fuelled by combinations of “fetid effluvia”, including “spermatic-animal-seminal rays”, “putrid human breath”, and “gaz from the anus of the horse”, and its magnetic warp assailed Matthews’ brain in a catalogue of forms known as “event-workings”. These included “brain-saying” and “dream-working”, by which thoughts were forced into his brain against his will, and a terrifying array of physical tortures from “knee nailing”, “vital tearing” and “fibre ripping” to “apoplexy-working with the nutmeg grater” and the dreaded “lobster-cracking”, where the air around his chest was constricted until he was unable to breathe. To facilitate their control over him, the gang had implanted a magnet into his brain. He was tormented constantly by hallucinations, physical agonies, fits of laughter or being forced to parrot whatever words they chose to feed into his head. No wonder some people thought he was mad.</p><p>The machine’s operators were a gang of undercover Jacobin terrorists, who Matthews described with haunting precision. Their leader, Bill the King, was a coarse-faced and ruthless puppetmaster who “has never been known to smile”; his second-in-command, Jack the Schoolmaster, took careful notes on the Air Loom’s operations, pushing his wig back with his forefinger as he wrote. The operator was a sinister, pockmarked lady known only as the “Glove Woman”. The public face of the gang was a sharp-featured woman named Augusta, superficially charming but “exceedingly spiteful and malignant” when crossed, who roamed London’s west end as an undercover agent.</p><p>The operation directed at Matthews was only part of a larger story. There were more Air Looms and their gangs concealed across London, and their unseen influence extended all the way up to the Prime Minister, William Pitt, whose mind was firmly under their control. Their agents lurked in streets, theatres and coffee-houses, where they tricked the unsuspecting into inhaling magnetic fluids. If the gang were recognised in public, they would grasp magnetised batons that clouded the perception of anyone in the vicinity. The object of their intrigues was to poison the minds of politicians on both sides of the Channel, and thereby keep Britain and revolutionary France locked into their ruinous war.</p>'
- - https://www.scientificamerican.com/article/vacancy-hermit-crab-social-networks/
  - "On a Tiny Caribbean Island, Hermit Crabs Form Sophisticated Social Networks [Video]: Hermit crabs have evolved sophisticated social strategies to exchange resources so that everyone benefits"
  - Ferris Jabr (<em>Scientific American</em>)
  - 2012-06-05
  - ''
  - ! '<p>…As they grow, hermit crabs must move into larger shells, so they are always on the lookout for a more spacious dwelling. And an undamaged shell is preferable to a broken one, even if the shells are the same size. Knowing this, the researchers decided to dramatically change the available hermit crab real estate on Carrie Bow Cay. They placed 20 beautifully intact shells that were a little too big for most hermit crabs at various spots around the island and watched what happened.</p><p>When a lone crab encountered one of the beautiful new shells, it immediately inspected the shelter with its legs and antennae and scooted out of its current home to try on the new shelter for size. If the new shell was a good fit, the crab claimed it. Classic hermit crab behavior. But if the new shell was too big, the crab did not scuttle away disappointed—instead, it stood by its discovery for anywhere between 15 minutes and 8 hours, waiting. This was unusual. Eventually other crabs showed up, each one trying on the shell. If the shell was also too big for the newcomers, they hung around too, sometimes forming groups as large as 20. The crabs did not gather in a random arrangement, however. Rather, they clamped onto one another in a conga line stretching from the largest to smallest animal—a behavior the biologists dubbed “piggybacking.”</p><p>Only one thing could break up the chain of crabs: a Goldilocks hermit crab for whom the shell introduced by Lewis and Rotjan was just right. As soon as such a crab claimed its new home, all the crabs in queue swiftly exchanged shells in sequence. The largest crab at the front of the line seized the Goldilocks crab’s abandoned shell. The second largest crab stole into the first’s old shell. And so on.</p><p>No one had ever documented such well-orchestrated shell swapping before, but similar behavior was not unknown. In 1986, Ivan Chase of Stony Brook University made the first observations of hermit crabs exchanging shells in a “vacancy chain”—a term originally coined by social scientists to describe the ways that people trade coveted resources like apartments and jobs. When one person leaves, another moves in. Since then, several researchers—including Lewis and Rotjan—have studied the behavior in different hermit crab species. Some preliminary evidence suggests that other animals use vacancy chains too, including clown fish, lobsters, octopuses and some birds. As Chase explains in the June issue of Scientific American, vacancy chains are an excellent way to distribute resources: Unlike more typical competition, a single vacancy chain benefits everyone involved—each individual gets an upgrade. So it makes sense that hermit crabs and other animals have evolved sophisticated social behaviors to make the most of vacancy chains.</p>'
- - https://www.ianwatson.info/plumbing-stanley-kubrick/
  - Plumbing Stanley Kubrick
  - Ian Watson
  - '1999'
  - ''
  - ! '<p>[A Scottish writer’s memoir of years working on <a href="https://en.wikipedia.org/wiki/A.I._Artificial_Intelligence"><em>A.I. Artificial Intelligence</em></a> &amp; coping with <a href="https://en.wikipedia.org/wiki/Stanley_Kubrick">Stanley Kubrick’s</a> eccentricities.</p><p>Summoned to Kubrick’s secluded mansion and offered an enormous sum of money, Watson began collaborating on a film idea with Kubrick, who was a perfectionist who demanded endless marathon revisions of possible stories and ideas, only to throw them out and hare off on an entirely different avenue; he would spend extravagantly on travel or books on a topic or demand photos of a particular place or a specific item like a bag on sale only discard them without a second look, perennially challenging his assistants’ patience. (This attitude extended to his films, where he thought nothing of ordering in an entire plastic replica garden, only to decide it was inadequate, discard it, and order real palm trees flown in.) He was a lover of animals like cats, dogs, and birds, requiring a servant to mow grass &amp; deliver it to a cat kept upstairs on a daily basis, although his affection was often quite as harmful as helpful (his generosity in ordering feeding of the birds made them obese). Careless of rough drafts, he’d lose printouts or erase disks, but even more paranoid, he would be infuriated when the local hacker who assisted them with computer problems restored files from backups the hacker had prudently kept. This paranoia further kept him terrified about global geopolitics, such as whether Saddam Hussein would trigger nuclear war in the Middle East.</p><p>For all the surreal comedy, when Kubrick dies—<em>A.I</em> still being nowhere near filming, of course—and Watson writes up his memoirs, he finds that he misses Kubrick and “I remain sad that he’s gone.”]</p>'
- - https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/17526/%22%20manuscript.pdf?sequence=1&isAllowed=y
  - "Humans can identify cats’ affective states from subtle facial expressions"
  - L.C. Dawson, J. Cheal, L. Niel, G. Mason
  - 2019-11
  - '10.7120/09627286.28.4.519'
  - ! '<p>Although cats’ popularity as pets rivals that of dogs, cats are little studied, and people’s abilities to read this apparently ’inscrutable’ species have attracted negligible research. To determine whether people can identify feline emotions from cats’ faces, participants (<em>n</em> = 6,329) each viewed 20 video clips of cats in carefully operationalised positively (<em>n</em> = 10) or negatively valenced states (<em>n</em> = 10) (cross-factored with low and high activity levels). Obvious cues (eg open mouths or fully retracted ears) were eliminated. Participants’ average scores were low (11.85/20 correct), but overall above chance; furthermore, 13% of participants were individually significantly successful at identifying the valence of cats’ states (scoring ≥ 15/20 correct). Women were more successful at this task than men, and younger participants more successful than older, as were participants with professional feline (eg veterinary) experience. In contrast, personal contact with cats (eg pet-owning) had little effect. Cats in positive states were most likely to be correctly identified, particularly if active rather than inactive. People can thus infer cats’ affective states from subtle aspects of their facial expressions (although most find this challenging); and some individuals are very good at doing so. Understanding where such abilities come from, and precisely how cats’ expressions change with affective state, could potentially help pet owners, animal care staff and veterinarians optimise feline care and welfare.</p>'
- - https://dspace.mit.edu/handle/1721.1/116112
  - "Pricing the Future in the Seventeenth Century: Calculating Technologies in Competition"
  - William P. Deringer
  - 2017-04
  - ''
  - ! 'Time is money. But how much? What is money in the future worth to you today? This question of "present value" arises in myriad economic activities, from valuing financial securities to real estate transactions to governmental cost-benefit analysis—even the economics of climate change. In modern capitalist practice, one calculation offers the only "rational" way to answer: compound-interest discounting. In the early modern period, though, economic actors used at least two alternative calculating technologies for thinking about present value, including a vernacular technique called years purchase and discounting by simple interest. All of these calculations had different strengths and affordances, and none was unquestionably better or more "rational" than the others at the time. The history of technology offers distinct resources for understanding such technological competitions, and thus for understanding the emergence of modern economic temporality.'
- - https://bitcoin.org/bitcoin.pdf
  - "Bitcoin: A Peer-to-Peer Electronic Cash System"
  - Satoshi Nakamoto
  - 2008-10-31
  - ''
  - ! "A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network.The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone."
- - https://www.avmf.org/clientuploads/documents/News%20Articles/Cat%20Health%20Network%20Feline%20SNP%20Chip%20Studies%20-%20Final%20Accomplishments%20MAFFINAL%2005-23-13.pdf#page=5
  - Cat Health Network Feline SNP Chip Studies Final Accomplishments
  - Cat Health Network
  - '2011'
  - ''
  - ! 'Morris Animal Foundation, the American Veterinary Medical Foundation, Winn Feline Foundation and the American Association of Feline Practitioners collaborated to form the Cat Health Network in 2011. The partners are all committed to improving feline health and recognize that combining resources may lead to major advances in cat care. Through the Cat Health Network, scientists used a gene chip containing single nucleotide polymorphisms (SNPs, pronounced “snips”) to study numerous genetic predispositions to feline diseases and conditions. Following are final, lay-language status updates for all awards that have completed.'
- - https://www.apa.org/pubs/journals/releases/neu-24-5-563.pdf
  - Influence of Age on Practice Effects in Longitudinal Neurocognitive Change
  - Timothy A. Salthouse
  - '2010'
  - 10.1037/a0019026
  - ! '<p>Longitudinal comparisons of neurocognitive functioning often reveal stability or age-related increases in performance among adults under about 60 years of age. Because nearly monotonic declines with increasing age are typically evident in cross-sectional comparisons, there is a discrepancy in the inferred age trends based on the two types of comparisons. The current research investigated the role of practice effects in longitudinal comparisons on the discrepancy.</p><p><em>Method</em>: Longitudinal data over an average interval of 2.5 years were available on five abilities (i.e., reasoning, spatial visualization, episodic memory, perceptual speed, vocabulary) in a sample of 1,616 adults ranging from 18 to over 80 years of age. Practice effects were estimated from comparisons of the performance of people of the same age tested for either the first or second time, after adjusting for the possibility of selective attrition.</p><p><em>Results</em>:Increased age was associated with significantly more negative longitudinal changes with each ability. All of the estimated practice effects were positive, but they varied in magnitude across neurocognitive abilities and as a function of age. After adjusting for practice effects the longitudinal changes were less positive at younger ages and slightly less negative at older ages.</p><p><em>Conclusions</em>: It was concluded that some, but not all, of the discrepancy between cross-sectional and longitudinal age trends in neurocognitive functioning is attributable to practice effects positively biasing the longitudinal trends. These results suggest that the neurobiological substrates of neurocognitive functioning may change across different periods in adulthood.</p>'
- - https://www.albany.edu/faculty/kretheme/PAD705/PastExams/JPE_RolePreMarketBWWageDiff.pdf
  - "The Role of Premarket Factors in Black-White Wage Differences"
  - Derek A. Neal, William R. Johnson
  - '1996'
  - 10.1086/262045
  - ! "Many attempts to measure the wage effects of current labor market discrimination against minorities include controls for worker productivity that could themselves be affected by market discrimination and are very imprecise measures of worker skill. The resulting estimates of residual wage gaps may be biased. Our approach is a parsimoniously specified wage equation that controls for skill with the score of a test administered as teenagers prepared to leave high school and embark on work careers or post-secondary education. Independent evidence shows that this test score is a racially unbiased measure of the skills and abilities these teenagers were about to bring to the labor market. We find that this one test score explains all of the black-white wage gap for young women and much of the gap for young men. For today's young adults, the black-white wage gap primarily reflects a skill gap, which in turn we can trace, at least in part, to observable differences in the family backgrounds and school environments of black and white children. While our results do provide some evidence of current labor market discrimination, skill gaps play such a large role that we believe future research should focus on the obstacles black children face in acquiring productive skill."
- - https://foundation.wikimedia.org/wiki/File:UK_BOARD_MEETING.pdf
  - Wikimedia UK Board Meeting, London
  - Sue Gardner
  - 2011-11-19
  - ''
  - ! "It's getting harder for new people to join our projects. Newbies are making up a smaller percentage of editors overall than ever before, and the absolute number of newbies is dropping as well. Wikimedia needs to attract and retain more new and diverse editors, and to retain our experienced editors. A stable editing community is critical to the long-term sustainability and quality of both our current projects and our movement.We consider meeting this challenge our top priority."
- - http://web.elastic.org/~fche/mirrors/www.cryptome.org/2014/06/wmd-4th-gen-quest.pdf
  - The physical principles of thermonuclear explosives, inertial confinement fusion, and the quest for fourth generation nuclear weapons
  - Andre Gsponer, Jean-Pierre Hurni
  - 2009-01-20
  - ''
  - ! "<p>This report is an assessment of the prospect of developing new (i.e., fourth generation) nuclear weapons in the context of the Comprehensive Nuclear Test-Ban Treaty (CTBT) that was adopted by the UN General Assembly in 1996 and of the current moratorium on nuclear testing in effect in all nuclear-weapon States.</p> <p>The conclusion stresses that considerable research is underway in all five nuclear-weapon States (as well as in several other major industrialized States such as Germany and Japan) on ICF and on many physical processes that provide the scientific basis necessary to develop fourth generation nuclear weapons. Substantial progress has been made in the past few years on all these processes, and the construction of large ICF microexplosion facilities in both nuclear-weapon and non-nuclear-weapon States is giving the arms race a fresh boost. The world runs the risk that certain countries will equip themselves directly with fourth generation nuclear weapons, bypassing the acquisition of previous generations of nuclear weapons.</p>"
- - http://uweb.cas.usf.edu/~drohrer/pdfs/Cepeda_et_al_2006PsychBull.pdf
  - ! "Distributed Practice in Verbal Recall Tasks: A Review and Quantitative Synthesis"
  - 'Nicholas J. Cepeda, Harold Pashler, Edward Vul, John T. Wixted, Doug Rohrer'
  - '2006'
  - '10.1037/0033-2909.132.3.354'
  - ! 'The authors performed a meta-analysis of the distributed practice effect to illuminate the effects of temporal variables that have been neglected in previous reviews. This review found 839 assessments of distributed practice in 317 experiments located in 184 articles. Effects of spacing (consecutive massed presentations vs. spaced learning episodes) and lag (less spaced vs. more spaced learning episodes) were examined, as were expanding inter study interval (ISI) effects. Analyses suggest that ISI and retention interval operate jointly to affect final-test retention; specifically, the ISI producing maximal retention increased as retention interval increased. Areas needing future research and theoretical implications are discussed.'
- - https://sites.williams.edu/nk2/files/2011/08/Kornell.2009b.pdf
  - 'Optimising Learning Using Flashcards: Spacing Is More Effective Than Cramming'
  - Nate Kornell
  - 2009-01-19
  - 10.1002/acp.1537
  - ! "The spacing effect—that is, the benefit of spacing learning events apart rather than massing them together—has been demonstrated in hundreds of experiments, but is not well known to educators or learners. I investigated the spacing effect in the realistic context of flashcard use. Learners often divide flashcards into relatively small stacks, but compared to a large stack, small stacks decrease the spacing between study trials. In three experiments, participants used a web-based study programme to learn GRE-type word pairs. Studying one large stack of flashcards (i.e. spacing) was more effective than studying four smaller stacks of flashcards separately (i.e. massing). Spacing was also more effective than cramming—that is, massing study on the last day before the test. Across experiments, spacing was more effective than massing for 90% of the participants, yet after the first study session, 72% of the participants believed that massing had been more effective than spacing."
- - https://scottbarrykaufman.com/wp-content/uploads/2012/01/Nisbett-et-al.-2012.pdf
  - "Intelligence: New Findings and Theoretical Developments"
  - Richard E. Nisbett, Joshua Aronson, Clancy Blair, William Dickens, James Flynn, Diane F. Halpern, Eric Turkheimer
  - 2012-01-02
  - 10.1037/a0026699
  - ! "We review new findings and new theoretical developments in the field of intelligence. New findings include the follow-ing: (a) Heritability of IQ varies significantly by social class. (b) Almost no genetic polymorphisms have been discovered that are consistently associated with variation in IQ in the normal range. (c) Much has been learned about the biological underpinnings of intelligence. (d) “Crystallized” and “fluid” IQ are quite different aspects of intelligence at both the behavioral and biological levels. (e) The importance of the environment for IQ is established by the 12-point to 18-point increase in IQ when children are adopted from working-class to middle-class homes. (f) Even when improvements in IQ produced by the most effective early childhood interventions fail to persist, there can be very marked effects on academic achievement and life outcomes. (g) In most developed countries studied, gains on IQ tests have continued, and they are beginning in the developing world. (h) Sex differences in aspects of intelligence are due partly to identifiable biological factors and partly to socialization factors. (i) The IQ gap between Blacks and Whites has been reduced by 0.33 SD in recent years. We report theorizing concerning (a) the relationship between working memory and intelligence, (b) the apparent contradiction between strong heritability effects on IQ and strong secular effects on IQ, (c) whether a general intelligence factor could arise from initially largely independent cognitive skills, (d) the relation between self-regulation and cognitive skills, and (e) the effects of stress on intelligence."
- - https://api.research-repository.uwa.edu.au/portalfiles/portal/11790041/Flematti_MS.pdf
  - "Identification of the cat attractants isodihydronepetalactone and isoiridomyrmecin from <em>Acalypha indica</em>"
  - Adrian Scaffidi, Dave Algar, Björn Bohman, Emilio L. Ghisalberti1, Gavin Flematti
  - '2016'
  - 10.1071/CH15476_AC
  - ! "<em>Acalypha indica</em> is a herb that grows throughout the tropical regions of the world. As well as being exploited for medicinal use, the roots of this plant are known to elicit a drug-like effect on cats. Recent research into feral cat control on Christmas Island has investigated whether a preparation of the roots of <em>A. indica</em> might be effective in traps to attract feral cats. However, the volatile nature of the attractants made it unviable for use in traps for more than a few days. In this study we investigated the volatile components emitted by the plant roots and identified two iridoid compounds, (4R,4aR,7S,7aR)-isodihydronepetalactone and (4R,4aS,7S,7aR)-isoiridomyrmecin, which are known to affect behavioural activity in cats. Synthesis of standards confirmed the stereochemistry of both compounds emitted by the plant. Potential application for these compounds in feral cat control is discussed."
- - https://pdfs.semanticscholar.org/7687/cce675f3b1b51067ed9d0a3d70da64741764.pdf
  - "Energetics And The Evolution Of The Genus <em>Homo</em>"
  - Leslie C. Aiello, Jonathan C. K. Wells
  - 2002-10
  - 10.1146/annurev.anthro.31.040402.085403
  - ! '<p>The genus <em>Homo</em> as represented by <em>Homo ergaster</em> (= early African <em>Homo erectus</em>) is characterized by a pattern of features that is more similar to modern humans than to the earlier and contemporaneous australopithecines and paranthropines. These features include larger relative brain sizes, larger bodies, slower rates of growth and maturation, dedicated bipedal locomotion, and smaller teeth and jaws. These features are phenotypic expressions of a very different lifestyle for the earliest members of the genus <em>Homo</em>. This paper considers the energetic correlates of the emergence of the genus <em>Homo</em> and suggests that there were three major changes in maintenance energy requirements. First, there was an absolute increase in energy requirements due to greater body size. Second, there was a shift in the relative requirements of the different organs, with increased energy diverted to brain metabolism at the expense of gut tissue, possibly mediated by changes in the proportion of weight comprised of fat. And third, there was a slower rate of childhood growth, offset by higher growth costs during infancy and adolescence. These changes, as well as energetic requirements of reproduction and bipedal locomotion, are considered in a discussion of one of the major transitions in adaptation in human evolution, the appearance of our own genus.</p><p>[Keywords: human evolution; metabolic rate; diet; growth; <em>Homo erectus</em>; <em>Homo ergaster</em>; australopithecines; brain evolution.]</p>'
- - http://repec.org/sed2006/up.30684.1139268077.pdf
  - "IQ in the Ramsey Model: A Naïve Calibration"
  - Garett Jones
  - '2006'
  - ''
  - ! 'I show that in a conventional Ramsey model, between one-fourth and one-half of the global income distribution can be explained by a single factor: The effect of large, persistent differences in national average IQ on the private marginal product of labor. Thus, differences in national average IQ may be a driving force behind global income inequality. These persistent differences in cognitive ability&mdash;which are well-supported in the psychology literature&mdash;are likely to be somewhat malleable through better health care, better education, and especially better nutrition in the world’s poorest countries. A simple calibration exercise in the spirit of Bils and Klenow (2000) and Castro (2005) is conducted. I show that an IQ-augmented Ramsey model can explain more than half of the empirical relationship between national average IQ and GDP per worker. I provide evidence that little of the IQ-productivity relationship is likely to be due to reverse causality.'
- - /docs/nootropics/2008-dejongh.pdf
  - "Botox for the brain: enhancement of cognition, mood and pro-social behavior and blunting of unwanted memories"
  - Reinoud de Jongh, Ineke Bolt, Maartje Schermer, Berend Olivier
  - 2007-12-17
  - 10.1016/j.neubiorev.2007.12.001
  - ! 'It has been suggested that the recent rapid developments in the fields of neuroscience and psychopharmacology have increased the possibilities for pharmacological enhancement of mental functioning. Here, evidence is reviewed which shows that drugs acting on a variety of neurotransmitter systems can indeed enhance cognition, and to a lesser extent mood and pro-social behavior. Moreover, it seems possible to interfere with the (re)consolidation of traumatic memories. There are, however, a number of caveats: first, as cognition-enhancing drugs can simultaneously exert both linear and quadratic (U-shaped) effects, doses most effective in facilitating one behavior could at the same time exert null or even detrimental effects on other cognitive domains. Second, individuals with a ‘low memory span’ might benefit from cognition-enhancing drugs, whereas ‘high span subjects’ are ‘overdosed’. And finally, evidence suggests that a number of trade-offs could occur. For example, increases of cognitive stability might come at the cost of a decreased capacity to flexibly alter behavior. A short overview of ethical issues raised by the use of cognition and mood enhancing drugs demonstrates the tremendous variety in views and opinions regarding the subject.'
- - http://psychnet.wustl.edu/coglab/wp-content/uploads/2015/01/2007-Is-expanded.pdf
  - "Is Expanded Retrieval Practice a Superior Form of Spaced Retrieval? A Critical Review of the Extant Literature"
  - David A. Balota, Janet M. Duchek, Jessica M. Logan
  - '2015'
  - ''
  - ! 'The spacing effect is one of the most ubiquitous findings in learning and memory.Performance on a variety of tasks is better when the repetition of the to-be-learned information is distributed as opposed to massed in presentation. This observation was first formalized in Jost’s law, which states that “if two associations are of equal strength but of different age, a new repetition has a greater value for the older one” (McGeogh, 1943). Spacing effects occur across domains (e.g., learning perceptual motor tasks vs. learning lists of words), across species (e.g., rats, pigeons, and humans), across age groups and individuals with different memory impairments,and across retention intervals of seconds to months (see Cepeda, Pashler, Vul,Wixted, & Rohrer, 2006; Crowder, 1976; Dempster, 1996, for reviews). In this light, it is interesting that spacing effects have not received much attention in Cognitive Psychology textbooks. In fact, in our sampling of seven such textbooks,only one had a section dedicated to this topic, while virtually all cognitive text-books discussed mnemonic techniques such as the pegword or method of loci. Given the power and simplicity of implementing spaced practice, we clearly hope this changes in the future.'
- - https://people.seas.harvard.edu/~salil/research/timelock.pdf
  - Time-Lock Puzzles in the Random Oracle Model
  - Mohammad Mahmoody, Tal Moran, Salil Vadhan
  - 2011-07-18
  - 10.1007/978-3-642-22792-9_3
  - ! 'A time-lock puzzle is a mechanism for sending messages “to the future”. The sender publishes a puzzle whose solution is the message to be sent, thus hiding it until enough time has elapsed for the puzzle to be solved. For time-lock puzzles to be useful, generating a puzzle should take less time than solving it. Since adversaries may have access to many more computers than honest solvers, massively parallel solvers should not be able to produce a solution much faster than serial ones.To date, we know of only one mechanism that is believed to satisfy these properties: the one proposed by Rivest, Shamir and Wagner (1996), who originally introduced the notion of time-lock puzzles. Their puzzle is based on the serial nature of exponentiation and the hardness of factoring, and is therefore vulnerable to advances in factoring techniques (as well as to quantum attacks). In this work, we study the possibility of constructing time-lock puzzles in the random-oracle model. Our main result is negative, ruling out time-lock puzzles that require more parallel time to solve than the total work required to generate a puzzle. In particular, this rules out black-box constructions of such time-lock puzzles from one-way permutations and collision-resistant hash-functions. On the positive side, we construct a time-lock puzzle with a linear gap in parallel time: a new puzzle can be generated with one round of <em>n</em> parallel queries to the random oracle, but <em>n</em> rounds of serial queries are required to solve it (even for massively parallel adversaries).'
- - /docs/algernon/1995-aiello.pdf
  - "The Expensive-Tissue Hypothesis: The Brain and the Digestive System in Human and Primate Evolution"
  - Leslie C. Aiello, Peter Wheeler
  - '1995'
  - 10.2307/2744104
  - ! 'Brain tissue is metabolically expensive, but there is no significant correlation between relative basal metabolic rate and relative brain size in humans and other encephalized mammals. The expensive-tissue hypothesis suggests that the metabolic requirements of relatively large brains are offset by a corresponding reduction of the gut. The splanchnic organs (liver and gastro-intestinal tract) are as metabolically expensive as brains, and the gut is the only one of the metabolically expensive organs in the human body that is markedly small in relation to body size. Gut size is highly correlated with diet, and relatively small guts are compatible only with high-quality, easy-to-digest food. The often-cited relationship between diet and relative brain size is more properly viewed as a relationship between relative brain size and relative gut size, the latter being determined by dietary quality. No matter what is selecting for relatively large brains in humans and other primates, they cannot be achieved without a shift to a high-quality diet unless there is a rise in the metabolic rate. Therefore the incorporation of increasingly greater amounts of animal products into the diet was essential in the evolution of the large human brain.'
- - https://paulbingley.com/papers/signals-manuscript.pdf
  - Signaling and Productivity in the Private Financial Returns to Schooling
  - Paul Bingley; Kaare Christensen; Kristoffer Markwardt
  - 2015-06-20
  - ''
  - ! 'Does formal schooling contribute to individual labor market productivity or does it act as a signal to employers of predetermined labor market skills? We test for whether employers statistically discriminate between workers on the basis of their schooling, by assuming we can observe a proxy for worker productivity that the employer cannot&mdash;father, brother and co-twin earnings. Using population-based Danish administrative data, we find that employers initially statistically discriminate be-tween workers on the basis of schooling, but schooling earnings differentials fall overtime as employers learn about worker productivity. We further propose a novel test for job market signaling using differences in twin pair earnings growth, and find that signaling is important at the upper end of the schooling distribution&mdash;explaining a large proportion of the college wage premium.'
- - https://papers.nips.cc/paper/5185-more-efficient-reinforcement-learning-via-posterior-sampling.pdf#deepmind
  - (More) Efficient Reinforcement Learning via Posterior Sampling
  - Ian Osband; Benjamin Van Roy; Daniel Russo
  - 2013-06-04
  - ''
  - ! 'Most provably-efficient learning algorithms introduce optimism about poorly-understood states and actions to encourage exploration. We study an alternative approach for efficient exploration, posterior sampling for reinforcement learning (PSRL). This algorithm proceeds in repeated episodes of known duration. At the start of each episode, PSRL updates a prior distribution over Markov decision processes and takes one sample from this posterior. PSRL then follows the policy that is optimal for this sample during the episode. The algorithm is conceptually simple, computationally efficient and allows an agent to encode prior knowledge in a natural way. We establish an Õ(τ ⋅ S ⋅ √(AT)) bound on the expected regret, where <em>T</em> is time, τ is the episode length and <em>S</em> and <em>A</em> are the cardinalities of the state and action spaces. This bound is one of the first for an algorithm not based on optimism, and close to the state of the art for any reinforcement learning algorithm. We show through simulation that PSRL significantly outperforms existing algorithms with similar regret bounds.'
- - http://oops.uni-oldenburg.de/624/13/grafee01.pdf
  - Feeling Pain and Being in Pain
  - Nikola Grahek
  - '2001'
  - ''
  - ! 'This book is principally devoted to the thorough consideration and general theoretical appreciation of the two most radical dissociation syndromes to be found in human pain experience. The first syndrome is related to the complete dissociation between sensory and affective, cognitive and behavioral components of pain, while the second one has to do with absolute dissociation that goes into opposite direction: the full dissociation of affective components of human pain experience from its sensory-discriminative components. The former syndrome can be called pain without painfulness and the latter one painfulness without pain. In the first case, one is able to feel pain but is not able to be in pain, while in the second case one is able to be in pain but not able to feel pain. Taking into account our common experience of pain, it might well seem to us that the two syndromes just described are inconceivable and, thus, impossible. In order to make them more intelligible and, thus, less inconceivable, the crucial distinction between feeling pain and being in pain is introduced and explained on conceptual and empirical grounds. But the main point is that pain without painfulness as well as painfulness without pain are, however bizarre or outlandish, nonetheless possible, for the simple reason that ample clinical evidence conclusively shows that they can be found in human pain experience. So, the question is not whether they exist or can exist, but what they can teach us about the true nature and structure of human pain experience. Accordingly, the major theoretical aim of this book will be to appreciate what lessons are to be learned from the consideration of these syndromes as far as our very concept or, more importantly, our very experience of pain is concerned.'
- - https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD007469.pub2/pdf/full
  - "Vitamin D supplementation for prevention of cancer in adults (Review)"
  - G. Bjelakovic, L.L. Gluud, D. Nikolova, K. Whitfield, G. Krstic, J. Wetterslev, C. Gluud
  - '2014'
  - 10.1002/14651858.CD007469.pub2
  - ! 'There is currently no firm evidence that vitamin D supplementation decreases or increases cancer occurrence in predominantly elderly community-dwelling women. Vitamin DE supplementation decreased cancer mortality and vitamin D supplementation decreased all-cause mortality, but these estimates are at risk of type I errors due to the fact that too few participants were examined, and to risks of attrition bias originating from substantial dropout of participants. Combined vitamin DE and calcium supplements increased nephrolithiasis, whereas it remains unclear from the included trials whether vitamin DE, calcium, or both were responsible for this effect. We need more trials on vitamin D supplementation, assessing the benefits and harms among younger participants, men, and people with low vitamin D status, and assessing longer duration of treatments as well as higher dosages of vitamin D. Follow-up of all participants is necessary to reduce attrition bias.'
- - https://link.springer.com/content/pdf/10.1007%2Fs13238-015-0153-5.pdf
  - 'CRISPR/Cas9-mediated gene editing in human tripronuclear zygotes'
  - Puping Liang, Yanwen Xu, Xiya Zhang, Chenhui Ding, Rui Huang, Zhen Zhang, Jie Lv, Xiaowei Xie,Yuxi Chen, Yujing Li, Ying Sun, Yaofu Bai, Zhou Songyang, Wenbin Ma, Canquan Zhou, Junjiu Huang
  - 2015-04-01
  - 10.1007/s13238-015-0153-5
  - ! 'Genome editing tools such as the clustered regularly interspaced short palindromic repeat (CRISPR)-associated system (Cas) have been widely used to modify genes in model systems including animal zygotes and human cells, and hold tremendous promise for both basic research and clinical applications. To date, a serious knowledge gap remains in our understanding of DNA repair mechanisms in human early embryos, and in the efficiency and potential off-target effects of using technologies such as CRISPR/Cas9 in human pre-implantation embryos. In this report, we used tripronuclear(3PN) zygotes to further investigate CRISPR/Cas9-mediated gene editing in human cells. We found that CRISPR/Cas9 could effectively cleave the endogenousβ-globin gene (HBB). However, the efficiency of homologous recombination directed repair (HDR) of HBB was low and the edited embryos were mosaic. Off-target cleavage was also apparent in these 3PN zygotes as revealed by the T7E1 assay and whole-exome sequencing. Furthermore, the endogenous delta-globin gene (HBD), which is homologous to HBB, competed with exogenous donor oligos to act as the repair template, leading to untoward mutations. Our data also indicated that repair of the HBB locus in these embryos occurred preferentially through the non-crossover HDR pathway. Taken together, our work highlights the pressing need to further improve the fidelity and specificity of the CRISPR/Cas9 platform, a prerequisite for any clinical applications of CRISPR/Cas9-mediated editing.'
- - http://learningsys.org/nips17/assets/slides/dean-nips17.pdf
  - 'Machine Learning for Systems and Systems for Machine Learning'
  - Jeff Dean
  - '2017'
  - ''
  - ! 'Slide deck for Google Brain presentation on Machine Learning and the future of ML development processes. Conclusions: ML hardware is at its infancy. Even faster systems and wider deployment will lead to many more breakthroughs across a wide range of domains. Learning in the core of all of our computer systems will make them better/more adaptive. There are many opportunities for this.'
- - https://philarchive.org/archive/SOTAOAv1
  - Advantages of Artificial Intelligences, Uploads, and Digital Minds
  - Kaj Sotala
  - '2012'
  - 10.1142/S1793843012400161
  - ! 'I survey four categories of factors that might give a digital mind, such as an upload or an artificial general intelligence, an advantage over humans. Hardware advantages include greater serial speeds and greater parallel speeds. Self-improvement advantages include improvement of algorithms, design of new mental modules, and modification of motivational system. Co-operative advantages include copyability, perfect co-operation, improved communication, and transfer of skills. Human handicaps include computational limitations and faulty heuristics, human-centric biases, and socially motivated cognition. The shape of hardware growth curves, as well as the ease of modifying minds, are found to have a major impact on how quickly a digital mind may take advantage of these factors.'
- - http://jtoomim.org/brain-training/fluid%20intelligence%20and%20sleep.pdf
  - Adolescent sleep and fluid intelligence performance
  - Anna Johnston, Michael Gradisar, Hayley Dohnt, Michael Billows, Stephanie McCappin
  - '2010'
  - 10.1111/j.1479-8425.2010.00442.x
  - ! 'Fluid intelligence involves novel problem-solving and may be susceptible to poor sleep. This study examined relationships between adolescent sleep, fluid intelligence, and academic achievement. Participants were 217 adolescents (42% male) aged 13 to 18 years (mean age, 14.9 years; SD=1.0) in grades 9–11. Fluid intelligence was predicted to mediate the relationship between adolescent sleep and academic achievement. Students completed online questionnaires of self-reported sleep, fluid intelligence (Letter Sets and Number Series), and self-reported grades. Total sleep time was not significantly related to fluid intelligence nor academic achievement (both <em>p</em>&gt;0.05); however, sleep difficulty (e.g. difficulty initiating sleep, unrefreshing sleep) was related to both (<em>p</em>&lt;0.05). The strength of the relationship between sleep difficulty and grades was reduced when fluid intelligence was introduced into the model; however, the z-score was not significant to confirm mediation.Nevertheless, fluid intelligence is a cognitive ability integral in academic achievement, and in this study has been shown it to be susceptible to sleep impairments (but not duration) in adolescents.'
- - http://ije.oxfordjournals.org/content/42/4/1057.full.pdf+html
  - "The impact of neighbourhood deprivation on adolescent violent criminality and substance misuse: A longitudinal, quasi-experimental study of the total Swedish population"
  - Amir Sariaslan, Niklas Langstrom, Brian D’Onofrio, Johan Hallqvist, Johan Franck, Paul Lichtenstein
  - 2013-03-26
  - 10.1093/ije/dyt066
  - ! 'We found that the adverse effect of neighbourhood deprivation on adolescent violent criminality and substance misuse in Sweden was not consistent with a causal inference. Instead, our findings highlight the need to control for familial confounding in multilevel studies of criminality and substance misuse.'
- - http://gscan2pdf.sourceforge.net/
  - 'gscan2pdf: A GUI to produce PDFs or DjVus from scanned documents'
  - Jeffrey Ratcliffe
  - '2019'
  - ''
  - 'FLOSS Perl GUI program for scanning and processing large documents such as books, doing simple editing, and exporting to PDF.'
- - https://files.eric.ed.gov/fulltext/ED471814.pdf
  - "Can Nonexperimental Comparison Group Methods Match the Findings from a Random Assignment Evaluation of Mandatory Welfare-to-Work Programs? MDRC Working Papers on Research Methodology"
  - Howard S. Bloom, Michael Michalopoulos, Carolyn J. Hill, Ying Lei
  - '2002'
  - ''
  - ! 'A study explored which nonexperimental comparison group methods provide the most accurate estimates of the impacts of mandatory welfare-to-work programs and whether the best methods work well enough to substitute for random assignment experiments. Findings were compared for nonexperimental comparison groups and statistical adjustment procedures with those for experimental control groups from a large-sample, six-state random assignment experiment&mdash;the National Evaluation of Welfare-to-Work Strategies. The methods were assessed in terms of their ability to estimate program impacts on annual earnings during short-run and medium-run follow-up periods. Findings with respect to the first issue suggested in-state comparison groups perform somewhat better than out-of-state or multi-state, especially for medium-run impact estimates; a simple difference of means or ordinary least squares regression can perform as well or better than more complex methods when used with a local comparison group; impact estimates for out-of-state or multi-state comparison groups are not improved substantially by more complex estimation procedures but are improved somewhat when propensity score methods are used to eliminate comparison groups that are not balanced on their baseline characteristics. Findings with respect to the second issue indicated the best methods did not work well enough to replace random assignment.Statistical analyses are appended.'
- - https://eprint.iacr.org/2015/482.pdf
  - How to build time-lock encryption
  - Jia Liu, Tibor Jager, Saqib A. Kakvi, Bogdan Warinschi
  - 2018-01-20
  - 10.1007/s10623-018-0461-x
  - ! 'Time-lock encryption is a method to encrypt a message such that it can only be decrypted after a certain deadline has passed. We propose a novel time-lock encryption scheme, whose main advantage over prior constructions is that even receivers with relatively weak computational resources should immediately be able to decrypt after the deadline, without any interaction with the sender, other receivers, or a trusted third party. We build our time-lock encryption on top of the new concept of computational reference clocks and an extractable witness encryption scheme. We explain how to construct a computational reference clock based on Bitcoin. We show how to achieve constant level of multilinearity for witness encryption by using SNARKs. We propose a new construction of a witness encryption scheme which is of independent interest: our scheme, based on SubsetSum, achieves extractable security without relying on obfuscation. The scheme employs multilinear maps of arbitrary order and is independent of the implementations of multilinear maps.'
- - https://cryptome.org/0002/ja-conspiracies.pdf
  - CRYPTOME
  - Julian Assange
  - 2006-12-03
  - ''
  - ! 'These essays on conspiracies by Julian Assange (me@iq.org) were retrieved today from his website iq.org. The first from the currently active site, dated November 10, 2006, and the second at archive.org, dated December 3, 2006.'
- - http://coalition4evidence.org/wp-content/uploads/2013/06/IES-Commissioned-RCTs-positive-vs-weak-or-null-findings-7-2013.pdf
  - 'Randomized Controlled Trials Commissioned by the Institute of Education Sciences Since 2002: How Many Found Positive Versus Weak or No Effects?'
  - Coalition for Evidence-Based Policy
  - '2013'
  - ''
  - ! "Since the establishment of the Institute for Education Sciences (IES) within the U.S. Department of Education in 2002, IES has commissioned a sizable number of well-conducted randomized controlled trials (RCTs) evaluating the effectiveness of diverse educational programs, practices, and strategies (“interventions”). These interventions have included, for example, various educational curricula, teacher professional development programs, school choice programs, educational software, and data-driven school reform initiatives. Largely as a result of these IES studies, there now exists–for the first time in U.S. education–a sizable body of credible knowledge about what works and what doesn't work to improve key educational outcomes of American students. A clear pattern of findings in these IES studies is that the large majority of interventions evaluated produced weak or no positive effects compared to usual school practices. This pattern is consistent with findings in other fields where RCTs are frequently carried out, such as medicine and business,<sup>1</sup> and underscores the need to test many different interventions so as to build the number shown to work."
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.659.8433&rep=rep1&type=pdf
  - Artificial Selection on Relative Brain Size in the Guppy Reveals Costs and Benefits of Evolving a Larger Brain
  - Alexander Kotrschal, Bjorn Rogell, Andreas Bundsen, Beatrice Svensson, Susanne Zajitschek, Ioana Brannstrom, Simone Immler, Alexei A. Maklakov, Niclas Kolm
  - 2013-01-21
  - 10.1016/j.cub.2012.11.058
  - ! 'The large variation in brain size that exists in the animal kingdom has been suggested to have evolved through the balance between selective advantages of greater cognitive ability and the prohibitively high energy demands of a larger brain (the ‘‘expensive-tissue hypothesis’’). Despite over a century of research on the evolution of brain size, empirical support for the trade-off between cognitive ability and energetic costs is based exclusively on correlative evidence, and the theory remains controversial. Here we provide experimental evidence for costs and benefits of increased brain size. We used artificial selection for large and small brain size relative to body size in a live-bearing fish, the guppy (Poecilia reticulata), and found that relative brain size evolved rapidly in response to divergent selection in both sexes. Large-brained females outperformed small-brained females in a numerical learning assay designed to test cognitive ability. Moreover, large-brained lines, especially males, developed smaller guts, as predicted by the expensive-tissue hypothesis, and produced fewer offspring. We propose that the evolution of brain size is mediated by a functional trade-off between increased cognitive ability and reproductive performance and discuss the implications of these findings for vertebrate brain evolution.'
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.649.2804&rep=rep1&type=pdf
  - Proceeding From Observed Correlation to Causal Inference
  - Michael Rutter
  - '2007'
  - ''
  - ! 'This article notes 5 reasons why a correlation between a risk (or protective) factor and some specified outcome might not reflect environmental causation. In keeping with numerous other writers, it is noted that a causal effect is usually composed of a constellation of components acting in concert. The study of causation, therefore, will necessarily be informative on only one or more subsets of such components. There is no such thing as a single basic necessary and sufficient cause. Attention is drawn to the need (albeit unobservable) to consider the counterfactual (i.e., what would have happened if the individual had not had the supposed risk experience). 15 possible types of natural experiments that may be used to test causal inferences with respect to naturally occurring prior causes (rather than planned interventions) are described. These comprise 5 types of genetically sensitive designs intended to control for possible genetic mediation (as well as dealing with other issues), 6 uses of twin or adoptee strategies to deal with other issues such as selection bias or the contrasts between different environmental risks, 2 designs to deal with selection bias, regression discontinuity designs to take into account unmeasured confounders, and the study of contextual effects. It is concluded that, taken in conjunction, natural experiments can be very helpful in both strengthening and weakening causal inferences.'
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.648.1155&rep=rep1&type=pdf
  - 'The Mystery Machine: End-to-end performance analysis of large-scale Internet services'
  - Michael Chow, David Meisner, Jason Flinn, Daniel Peek, Thomas F. Wenisch
  - 2014-10-06
  - ''
  - ! 'Current debugging and optimization methods scale poorly to deal with the complexity of modern Internet services, in which a single request triggers parallel execution of numerous heterogeneous software components over a distributed set of computers. The Achilles’ heel of current methods is the need for a complete and accurate model of the system under observation: producing such a model is challenging because it requires either assimilating the collective knowledge of hundreds of programmers responsible for the individual components or restricting the ways in which components interact. Fortunately, the scale of modern Internet services offers a compensating benefit: the sheer volume of re-quests serviced means that, even at low sampling rates, one can gather a tremendous amount of empirical performance observations and apply “big data” techniques to analyze those observations. In this paper, we show how one can automatically construct a model of request execution from preexisting component logs by generating a large number of potential hypotheses about program behavior and rejecting hypotheses contradicted by the empirical observations. We also show how one can validate potential performance improvements without costly implementation effort by leveraging the variation in component behavior that arises naturally over large numbers of requests to measure the impact of optimizing individual components or changing scheduling behavior.'
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.217.2276&rep=rep1&type=pdf
  - 'How Close Is Close Enough? Testing Nonexperimental Estimates of Impact against Experimental Estimates of Impact with Education Test Scores as Outcomes'
  - Elizabeth Ty Wilde, Robinson Hollister
  - '2002'
  - ''
  - ! '<p>In this study we test the performance of some nonexperimental estimators of impacts applied to an educational intervention—reduction in class size—where achievement test scores were the outcome. We compare the nonexperimental estimates of the impacts to “true impact” estimates provided by a random-assignment design used to assess the effects of that intervention. Our primary focus in this study is on a nonexperimental estimator based on a complex procedure called propensity score matching.</p> <p>We put greatest emphasis on looking at the question of “how close is close enough?” in terms of a decision-maker trying to use the evaluation to determine whether to invest in wider application of the intervention being assessed—in this case, reduction in class size. We illustrate this in terms of a rough cost-benefit framework for small class size as applied to Project Star. We find that in 30 to 45% of the 11 cases, the propensity-score-matching nonexperimental estimators would have led to the “wrong” decision.</p>'
- - https://www.cambridge.org/core/journals/the-british-journal-of-psychiatry/article/lithium-in-drinking-water-and-food-and-risk-of-suicide/20AD7AB41A74FC744EE58D914BCFEEED/core-reader
  - Lithium in drinking water and food, and risk of suicide
  - Prabha S. Chandra, Girish N. Babu
  - 2018-01-02
  - 10.1192/bjp.195.3.271a
  - ! "<p>The study by Ohgami et al raises serious ethical issues related to the interpretation of research findings and, as a consequence, their possible application. While not denying that the findings are interesting and have caused a stir in the lay press and on the internet, we question the methodology and the possible implications if the results are taken seriously.</p> <p>First, sociological reasons for suicide are important, and changing rates of suicide in many countries are linked to changes such as migration, poverty, relationships and economic issues. The finding that when gender was included in the analysis there was a difference in the significance levels between men and women (with the results being less significant in women) is one such example. Adding lithium to tap water is not going to change these demographic and social factors that contribute to suicide rates, and not having accounted for at least some of these is a major limitation of the study. Second, although we agree with Young in his commentary that more research is needed to prove or disprove this tantalizing idea, it is also important to assess what the impact of different levels of tap-water lithium is going to be on thyroid function, pregnant women and on the unborn fetus. It is also important to assess whether tap-water levels of lithium directly correlate with serum lithium levels in the respective populations. The levels of lithium in body fluids in normal healthy controls have varied from 0.01 to 0.09 meq/1 in one study, but there are no data about serum lithium levels among individuals attempting suicide. Maybe assessment of serum lithium levels among those with suicidal behaviour can be a place to start. More data are also needed on the role of low-dose lithium in individuals without mood disorders who are at risk of suicide.</p> <p>Finally, several foods (particularly spices) are known to have relatively high levels of lithium as reported by a study in India several years ago. This study reported levels as high as 12 μg/g of lithium in tobacco and high levels in crude salt, rock salt and several spices. Maybe, until such time that we are certain about lithium's role in decreasing suicidality in non-psychiatric populations, it might be worth conducting randomised controlled trials with these foods in individuals with suicidal behaviour to see whether low doses of lithium really help.</p> <p>Let us not throw the lithium out with the tap water yet!</p>"
- - /docs/culture/2019-candia.pdf
  - The universal decay of collective memory and attention
  - Cristian Candia, C. Jara-Figueroa, Carlos Rodriguez-Sickert, Albert-László Barabási, César A. Hidalgo
  - '2019-12-10'
  - 10.1038/s41562-018-0474-5
  - ! 'Collective memory and attention are sustained by two channels: oral communication (communicative memory) and the physical recording of information (cultural memory). Here, we use data on the citation of academic articles and patents, and on the online attention received by songs, movies and biographies, to describe the temporal decay of the attention received by cultural products. We show that, once we isolate the temporal dimension of the decay, the attention received by cultural products decays following a universal biexponential function. We explain this universality by proposing a mathematical model based on communicative and cultural memory, which fits the data better than previously proposed log-normal and exponential models. Our results reveal that biographies remain in our communicative memory the longest (20–30 years) and music the shortest (about 5.6 years). These findings show that the average attention received by cultural products decays following a universal biexponential function.'
- - https://archive.ahrq.gov/downloads/pub/evidence/pdf/meditation/medit.pdf
  - 'Meditation Practices for Health: State of the Research'
  - University of Alberta Evidence-based Practice Center
  - '2007'
  - ''
  - ! 'Many uncertainties surround the practice of meditation. Scientific research on meditation practices does not appear to have a common theoretical perspective and is characterized by poor methodological quality. Firm conclusions on the effects of meditation practices in healthcare cannot be drawn based on the available evidence. Future research on meditation practices must be more rigorous in the design and execution of studies and in the analysis and reporting of results.'
- - https://antilop.cc/sr/files/Silk_Road_JTAN_com_Search_Warrant.pdf
  - Search And Seizure Warrant
  - United States District Court for the Eastern District of Pennsylvania
  - 2013-09-09
  - ''
  - ! 'Search warrant for the Silk Road server hosted in Sellersville, PA.'
- - /docs/statistics/causality/1999-dehejia.pdf
  - 'Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs'
  - Rajeev H. Dehejia, Sadek Wahba
  - 1999-10-01
  - ''
  - ! "This article uses propensity score methods to estimate the treatment impact of the National Supported Work (NSW) Demonstration, a labor training program, on post-intervention earnings. We use data from Lalonde's evaluation of nonexperimental methods that combine the treated units from a randomized evaluation of the NSW with nonexperimental comparison units drawn from survey datasets. We apply propensity score methods to this composite dataset and demonstrate that, relative to the estimators that Lalonde evaluates, propensity score estimates of the treatment impact are much closer to the experimental benchmark estimate. Propensity score methods assume that the variables associated with assignment to treatment are observed (referred to as ignorable treatment assignment, or selection on observables). Even under this assumption, it is difficult to control for differences between the treatment and comparison groups when they are dissimilar and when there are many pre-intervention variables. The estimated propensity score (the probability of assignment to treatment, conditional on pre-intervention variables) summarizes the pre-intervention variables. This offers a diagnostic on the comparability of the treatment and comparison groups, because one has only to compare the estimated propensity score across the two groups. We discuss several methods (such as stratification and matching) that use the propensity score to estimate the treatment impact. When the range of estimated propensity scores of the treatment and comparison groups overlap, these methods can estimate the treatment impact for the treatment group. A sensitivity analysis shows that our estimates are not sensitive to the specification of the estimated propensity score, but are sensitive to the assumption of selection on observables. We conclude that when the treatment and comparison groups overlap, and when the variables determining assignment to treatment are observed, these methods provide a means to estimate the treatment impact. Even though propensity score methods are not always applicable, they offer a diagnostic on the quality of nonexperimental comparison groups in terms of observable pre-intervention variables."
- - https://www.newyorker.com/magazine/2008/04/21/up-and-then-down
  - "Up and Then Down: The lives of elevators"
  - Nick Paumgarten (<em>The New Yorker</em>)
  - 2008-04-21
  - ''
  - ! "[Profile of elevator safety, technology, and economics: the history and present day of elevators, interwoven with a story of a man trapped in an elevator for 41 hours. Elevators are remarkably safe and over-engineered, and make skyscrapers, and hence dense cities, economically possible. Balancing elevator space with tenant space is a critical part of elevator design, as is routing between floors and figuring out the exact socially-acceptable density of passengers. Elevator technology continues advancing, driven by ultra-tall skyscrapers like the Burj Khalifa. Nevertheless, the standard elevator design is so simple, energetically-efficient, and safe that it's hard to improve on.]"
- - http://journal.frontiersin.org/article/10.3389/fnhum.2016.00375/full
  - "Revisiting hydrocephalus as a model to study brain resilience [RETRACTED]"
  - "Matheus Fernandes de Oliveira, Fernando Campos Gomes Pinto, Koshiro Nishikuni, Ricardo Vieira Botelho, Alessandra Moura Lima, José Marcus Rotta"
  - 2012-01-06
  - 10.3389/fnhum.2011.00181
  - ! 'Hydrocephalus is an entity which embraces a variety of diseases whose final result is the enlarged size of cerebral ventricular system, partially or completely. The physiopathology of hydrocephalus lies in the dynamics of circulation of cerebrospinal fluid (CSF). The consequent CSF stasis in hydrocephalus interferes with cerebral and ventricular system development. Children and adults who sustain congenital or acquired brain injury typically experience a diffuse insult that impacts many areas of the brain. Development and recovery after such injuries reflects both restoration and reorganization of cognitive functions. Classic examples were already reported in literature. This suggests the presence of biological mechanisms associated with resilient adaptation of brain networks. We will settle a link between the notable modifications to neurophysiology secondary to hydrocephalus and the ability of neuronal tissue to reassume and reorganize its functions.'
- - https://www.sciencedirect.com/science/article/pii/S0160289619300789
  - "Structural brain imaging correlates of general intelligence in UK Biobank"
  - S.R. Cox, S.J. Ritchie, C. Fawns-Ritchie, E.M. Tucker-Drob, Ian J. Deary
  - 2019-09
  - 10.1016/j.intell.2019.101376
  - ! '<p><em>Highlights</em>:</p><ul><li>We used a large sample from UK Biobank (<em>N</em> = 29,004, age range = 44–81 years).</li><li>The association between brain volume and intelligence (‘<em>g</em>’) was <em>r</em> = 0.276.</li><li>Multiple global tissue measures explained twice the <em>g</em> variance in older than middle age.</li><li>The size of the association between <em>g</em> and global brain measures did not vary by sex.</li><li>We investigate the regional cortical, subcortical and white matter correlates of g.</li></ul><p><em>Abstract</em>: The associations between indices of brain structure and measured intelligence are unclear. This is partly because the evidence to-date comes from mostly small and heterogeneous studies. Here, we report brain structure-intelligence associations on a large sample from the UK Biobank study. The overall <em>N</em> = 29,004, with <em>N</em> = 18,426 participants providing both brain MRI and at least one cognitive test, and a complete four-test battery with MRI data available in a minimum <em>N</em> = 7201, depending upon the MRI measure. Participants’ age range was 44–81 years (M = 63.13, SD = 7.48). A general factor of intelligence (<em>g</em>) was derived from four varied cognitive tests, accounting for one third of the variance in the cognitive test scores. The association between (age- and sex-corrected) total brain volume and a latent factor of general intelligence is <em>r</em> = 0.276, 95% C.I. = [0.252, 0.300]. A model that incorporated multiple global measures of grey and white matter macro- and microstructure accounted for more than double the <em>g</em> variance in older participants compared to those in middle-age (13.6% and 5.4%, respectively). There were no sex differences in the magnitude of associations between <em>g</em> and total brain volume or other global aspects of brain structure. The largest brain regional correlates of <em>g</em> were volumes of the insula, frontal, anterior/superior and medial temporal, posterior and paracingulate, lateral occipital cortices, thalamic volume, and the white matter microstructure of thalamic and association fibres, and of the forceps minor. Many of these regions exhibited unique contributions to intelligence, and showed highly stable out of sample prediction.</p>'
- - /docs/iq/2019-lee.pdf
  - "The causal influence of brain size on human intelligence: Evidence from within-family phenotypic associations and GWAS modeling"
  - James J. Lee, Matt McGue, William G. Iacono, Andrew M. Michael, Christopher F. Chabris
  - 2019-07
  - 10.1016/j.intell.2019.01.011
  - ! '<p>There exists a moderate correlation between MRI-measured brain size and the general factor of IQ performance (<em>g</em>), but the question of whether the association reflects a theoretically important causal relationship or spurious confounding remains somewhat open. Previous small studies (<em>n</em>&lt;100) looking for the persistence of this correlation within families failed to find a tendency for the sibling with the larger brain to obtain a higher test score. We studied the within-family relationship between brain volume and intelligence in the much larger sample provided by the Human Connectome Project (<em>n</em> = 1022) and found a highly significant correlation (disattenuated <em>ρ</em> = 0.18, p_ &lt; .001). We replicated this result in the Minnesota Center for Twin and Family Research (<em>n</em> = 2698), finding a highly significant within-family correlation between head circumference and intelligence (disattenuated <em>ρ</em> = 0.19, <em>p</em> &lt; .001). We also employed novel methods of causal inference relying on summary statistics from genome-wide association studies (GWAS) of head size (<em>n</em> ≈ 10,000) and measures of cognition (257,000 &lt; <em>n</em> &lt; 767,000). Using bivariate LD Score regression, we found a genetic correlation between intracranial volume (ICV) and years of education (EduYears) of 0.41 (<em>p</em> &lt; .001). Using the Latent Causal Variable method, we found a genetic causality proportion of 0.72 (<em>p</em> &lt; .001); thus the genetic correlation arises from an asymmetric pattern, extending to sub-significant loci, of genetic variants associated with ICV also being associated with EduYears but many genetic variants associated with EduYears not being associated with ICV. This is the pattern of genetic results expected from a causal effect of brain size on intelligence. These findings give reason to take up the hypothesis that the dramatic increase in brain volume over the course of human evolution has been the result of natural selection favoring general intelligence.</p>'
- - https://rifters.com/real/articles/Forsdyke-2015-BrainScansofHydrocephalicsChallengeCherishedAssumptions.pdf
  - "Wittgenstein’s Certainty is Uncertain: Brain Scans of Cured Hydrocephalics Challenge Cherished Assumptions"
  - Donald R. Forsdyke
  - 2015-07-24
  - 10.1007/s13752-015-0219-x
  -  ! '<p>The philosopher Ludwig Wittgenstein chose as his prime exemplar of certainty the fact that the skulls of normal people are filled with neural tissue, not sawdust. In 1980 the British pediatrician John Lorber reported that some normal adults, apparently cured of childhood hydrocephaly, had no more than 5% of the volume of normal brain tissue. While initially disbelieved, Lorber’s observations have since been independently confirmed by clinicians in France and Brazil. Thus Wittgenstein’s certainty has become uncertain. Furthermore, the paradox that the human brain’s information content (memory) appears to exceed the storage capacity of even normal-sized brains, requires resolution. This article is one of a series on disparities between brain size and its assumed information content, as seen in cases of savant syndrome, microcephaly, and hydrocephaly, and with special reference to the Victorian era views of Conan Doyle, Samuel Butler, and Darwin’s research associate, George Romanes. The articles argue that, albeit unlikely, the scope of explanations must not exclude extracorporeal information storage.</p><p>[Keywords: Female brain, Head size, Information storage capacity, Long-term memory, John Lorber, Neuronal reductionism, Plasticity limits, Redundancy, Supernatural explanations, Ventricle size]</p>'
- - https://www.frontiersin.org/articles/10.3389/fnhum.2014.00397/full
  - "Long-term memory: scaling of information to brain size"
  - Donald R. Forsdyke
  - 2014-06-03
  - 10.3389/fnhum.2014.00397
  - ! 'The material bases of information—paper, computer discs—usually scale with information quantity. Large quantities of information usually require large material bases. Conventional wisdom has it that human long-term memory locates within brain tissue, and so might be expected to scale with brain size which, in turn, depends on cranial capacity. Large memories, as in savants, should always require large heads. Small heads should always scale with small memories. While it was previously concluded that neither of these predictions was invariably true, the evidence was weak. Brain size also depends on ventricle size, which can remain large in some survivors of childhood hydrocephaly, occupying 95% of cranial volume. Yet some of these have normal or advanced intelligence, indicating little impairment of long-term memory. This paradox challenges the scaling hypothesis. Perhaps we should be looking further afield?'
- - http://blogs.discovermagazine.com/neuroskeptic/2015/07/26/is-your-brain-really-necessary-revisited/
  - '"Is Your Brain Really Necessary?", Revisited'
  - Neuroskeptic
  - 2015-07-26
  - ''
  - ! '<p>According to British biochemist Donald R. Forsdyke in a new paper in <em>Biological Theory</em>, the existence of people who seem to be missing most of their brain tissue calls into question some of the “cherished assumptions” of neuroscience. I’m not so sure.</p><p>…There’s no question that some of these brains are very striking. But I don’t think we need to throw out the textbooks yet.</p><p>While the enormous “holes” in these brains seem dramatic, the bulk of the grey matter of the cerebral cortex, around the outside of the brain, appears to be intact and in the correct place—this is visible as the dark grey ‘shell’ beneath the skull. What appears to be missing is the white matter, the nerve tracts that connect the various parts of the cerebral cortex with each other, and with the other areas of the brain. However, some white matter is still visible as the pale grey layer that borders the holes. The big question is whether this layer of white matter is sufficient to connect up the grey matter and allow it to function normally. There doesn’t seem to be much of it, but on the other hand, we really don’t know how much white matter is strictly necessary.</p><p>I wonder also if the white matter might be denser than normal i.e. if the fibers were packed together due to being gradually compressed by the expanding fluid spaces? No-one seems to have looked at this possibility directly; while there have been brain scanning studies of these adult post-hydrocephalics, no detailed post-mortem studies of their brain tissue have been published, as far as I know. (Forsdyke does not discuss any and I couldn’t find any in my searches.) For more on the neuroanatomy of this issue, see John Hawks (discussed by Forsdyke.)</p><p>Therefore in my view, these cases probably won’t require us to rethink neuroscience, although they do raise the issue of how much white matter is necessary. It may be that much of our white matter is redundant, which would be interesting, but not on a metaphysical level.</p>'
- - /docs/iq/2007-feuillet.pdf
  - "Brain of a white-collar worker"
  - Lionel Feuillet, Henry Dufour, Jean Pelletier
  - '2007-07-21'
  - 10.1016/S0140-6736(07)61127-1
  - ! '[Very brief case study.] On neuropsychological testing, he proved to have an intelligence quotient (IQ) of 75: his verbal IQ was 84, and his performance IQ 70. CT showed severe dilatation of the lateral ventricles (figure); MRI revealed massive enlargement of the lateral, third, and fourth ventricles, a very thin cortical mantle and a posterior fossa cyst. We diagnosed a non-communicating hydrocephalus...after a ventriculoperitoneal shunt was inserted, the findings on neurological examination became normal within a few weeks. The findings on neuropsychological testing and CT did not change.'
- - http://www.pnas.org/content/early/2012/06/19/1201895109.full.pdf
  - 'The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost'
  - Suzana Herculano-Houzel
  - 2012-06-19
  - 10.1073/pnas.1201895109
  - ! 'Neuroscientists have become used to a number of “facts” about the human brain: It has 100 billion neurons and 10- to 50-fold more glial cells; it is the largest-than-expected for its body among primates and mammals in general, and therefore the most cognitively able; it consumes an outstanding 20% of the total body energy budget despite representing only 2% of body mass because of an increased metabolic need of its neurons; and it is endowed with an overdeveloped cerebral cortex, the largest compared with brain size. These facts led to the widespread notion that the human brain is literally extraordinary: an outlier among mammalian brains, defying evolutionary rules that apply to other species, with a uniqueness seemingly necessary to justify the superior cognitive abilities of humans over mammals with even larger brains. These facts, with deep implications for neurophysiology and evolutionary biology, are not grounded on solid evidence or sound assumptions, however. Our recent development of a method that allows rapid and reliable quantification of the numbers of cells that compose the whole brain has provided a means to verify these facts. Here, I review this recent evidence and argue that, with 86 billion neurons and just as many nonneuronal cells, the human brain is a scaled-up primate brain in its cellular composition and metabolic cost, with a relatively enlarged cerebral cortex that does not have a relatively larger number of brain neurons yet is remarkable in its cognitive abilities and metabolism simply because of its extremely large number of neurons.'
- - https://onlinelibrary.wiley.com/doi/full/10.1111/epi.12342
  - "Long-term functional outcomes and their predictors after hemispherectomy in 115 children"
  - Ahsan N. V. Moosa, Lara Jehi, Ahmad Marashly, Gary Cosmo, Deepak Lachhwani, Elaine Wyllie, Prakash Kotagal, William Bingaman, Ajay Gupta
  - 2013-08-23
  - 10.1111/epi.12342
  - ! '<p><em>Purpose</em>: To examine the long-term functional outcomes and their predictors using a patient/family centered approach in a cohort of children who had hemispherectomy. Functional outcome measures studied were the following: ambulation ability, visual symptoms, spoken language, reading skills, and behavioral problems.</p><p><em>Methods</em>: We reviewed 186 consecutive children who underwent hemispherectomy between 1997 and 2009 at our center. Preoperative clinical, electroencephalography (EEG), imaging, and surgical data were collected. 125 families completed a structured questionnaire to assess the functional status and seizure outcome. Prognostic predictors were examined using a multivariate regression analysis.</p><p><em>Key Findings</em>: At a mean follow-up of 6.05 years after hemispherectomy, 70 patients (56%) were seizure-free and 45 (36%) had seizure recurrence; 10 patients (8%) were free of their preoperative seizures but had new-onset nonepileptic spells and were excluded from further analysis. Of 115, at follow-up (mean age at follow-up 12.7 years, range 2–28 years), 96 patients (83%) walked independently, 10 (8.7%) walked with assistance, and 9 (7.8%) were unable to walk. New visual symptoms that were not present preoperatively were reported only in 28 patients (24%). Eighty patients (70%) had satisfactory spoken language skills but only 44 (42%) of the 105 children older than 6 years had satisfactory reading skills. Significant behavioral problems were reported in 30 patients (27%). Only five (6.2%) of the 81 children aged between 6 and 18 years attended mainstream school without assistance; 48 (59%) were in mainstream school with assistance and the rest were in special school for disabled or home cared. Five (21%) of the 24 patients older than 18 years of age were gainfully employed. Multivariate logistic regression analysis identified the following factors as independently associated with poor functional outcome. (1) Seizure recurrence negatively affected all functional domains—ambulation ability, spoken language and reading skills, and behavior (<em>p</em> &lt; 0.05). (2) Abnormalities in the unoperated hemisphere on magnetic resonance imaging (MRI) (<em>p</em> &lt; 0.05) and preexisting quadriparesis (<em>p</em> &lt; 0.01) correlated with poor motor outcome. (3) Multilobar MRI abnormalities in the contralateral hemisphere (odds ratio [OR] = 13.9, <em>p</em> = 0.001) and young age (indeterminate preoperative language status) at hemispherectomy (OR = 11.1, <em>p</em> = 0.01) also correlated with poor language outcome. (4) Younger age at epilepsy onset correlated with poor reading skills (<em>p</em> = 0.01) but not with spoken language skills.</p><p><em>Significance</em>: This study highlights the long-term functional status of patients after hemispherectomy. The majority of patients were ambulant independently; however, impairments in reading and spoken language were frequent. Seizure recurrence after hemispherectomy and contralateral hemisphere abnormalities on MRI were the major predictors of poor outcome in ambulation, spoken language, and reading abilities. This study will assist in presurgical counseling using simple understandable functional outcome measures and may help in planning early interventions after hemispherectomy to improve functional outcome.</p>'
- - https://www.nytimes.com/2019/11/19/health/brain-removal-hemispherectomies-scans.html
  - "How the Brain Can Rewire Itself After Half of It Is Removed: New scans showed how the brains of people who had a hemisphere removed in childhood continue to function"
  - Knvul Sheikh (NYT)
  - 2019-11-19
  - ''
  - ! '<p>Her son, Henry, endured hundreds of seizures a day. Despite receiving high doses of medication, his little body seemed like a rag doll as one episode blended into another. He required several surgeries, starting when he was 3 1/2 months old, eventually leading to a complete anatomical hemispherectomy, or the removal of half of his brain, when he turned 3. The procedure was first developed in the 1920s to treat malignant brain tumors. But its success in children who have brain malformations, intractable seizures or diseases where damage is confined to half the brain, has astonished even seasoned scientists. After the procedure, many of the children are able to walk, talk, read and do everyday tasks. Roughly 20 percent of patients who have the procedure go on to find gainful employment as adults.</p><p>Now, research published Tuesday in the journal <em>Cell Reports</em> suggests that some individuals recover so well from the surgery because of a reorganization in the remaining half of the brain. Scientists identified the variety of networks that pick up the slack for the removed tissue, with some of the brain’s specialists learning to operate like generalists. “The brain is remarkably plastic,” said Dorit Kliemann, a cognitive neuroscientist at the California Institute of Technology, and the first author of the study. “It can compensate for dramatic loss of brain structure, and in some cases the remaining networks can support almost typical cognition.”</p><p>…Instead, researchers found that while the type of connections remained the same in the individuals with just one hemisphere, different regions responsible for processing sensorimotor information, vision, attention and social cues strengthened existing connections, communicating more frequently with each other compared with ordinary brains. It was almost as if parts of the brain that may have normally been specialized, say, as trumpet players, had talked to the rest of the band and taken additional responsibilities to play percussion instruments as well, Dr. Behrmann said. “Their brain networks seem to be multitasking.”</p><p>The results are encouraging for researchers and families trying to understand how the brain adapts and functions after a hemispherectomy. “I think there’s more and more evidence to suggest that brain plasticity is a really long-lasting phenomena,” said Dr. Ajay Gupta, a pediatric neurologist at the Cleveland Clinic, who has followed nearly 200 children after the surgery. Until recently, the scientific consensus has been that hemispherectomy surgery is best performed at a very young age, before a child reaches the age of 4 or 5. That way, they can regain normal function as they grow older. While neuroplasticity is stronger in early childhood, the new study suggests that surgery should not be withheld after an arbitrary end date, Dr. Gupta said. Adults in the study had undergone hemispherectomy surgery at ages ranging from 3 months to 11 years old.</p><p>A factor that may play a more important role in patient outcomes is the age at which seizures begin to occur. The surgery is still considered a last resort after medical treatment. But if the duration of seizures and resulting brain damage can be limited, patients may recover more function. “The other hemisphere is already having to handle extra responsibilities before patients get treated,” said Lynn K. Paul, a neuroscientist at California Institute of Technology and a co-author of the study. “It continues to do so when you take out the damaged hemisphere. So what we really want is to protect the hemisphere that’s working.”</p><p>…After the operation, children become significantly weaker in their hands and arms on the side opposite the operation. Their vision becomes blocked on that side, and they may also lose some ability to recognize where sounds are coming from. “There are some things that definitely require a higher level of rehab and learning. For example, reading and writing and math,” Dr. Gupta said. In many cases, however, those skills have already been compromised by the underlying diseases…For now, she is happy that her son can walk independently, communicate with an iPad and eat meals without a feeding tube.</p>'
- - https://ai.facebook.com/blog/understanding-the-generalization-of-lottery-tickets-in-neural-networks/
  - "Understanding the generalization of ‘lottery tickets’ in neural networks"
  - Ari Morcos, Yuandong Tian (FAIR)
  - 2019-11-25
  - ''
  - ! '<p>The lottery ticket hypothesis, initially proposed by researchers Jonathan Frankle and Michael Carbin at MIT, suggests that by training deep neural networks (DNNs) from “lucky” initializations, often referred to as “winning lottery tickets,” we can train networks which are 10-100x smaller with minimal losses—or even while achieving gains—in performance. This work has exciting implications for potentially finding ways to not only train with fewer resources, but also run faster inference of models on smaller devices, like smartphones and VR headsets. But the lottery ticket hypothesis is not yet fully understood by the AI community. In particular, it has remained unclear whether winning tickets are dependent on specific factors or rather represent an intrinsic feature of DNNs.</p><p>New research from Facebook AI finds the first definitive evidence that lottery tickets generalize across related, but distinct datasets and can extend to reinforcement learning (RL) and natural language processing (NLP). We’re sharing details on the results of our experiments using winning tickets, and we’re also introducing a new theoretical framework on the formation of lottery tickets to help researchers advance toward a better understanding of lucky initializations.</p><p>…there are many more open questions about the underlying properties and behaviors of neural networks, such as how do these winning tickets form, why do they exist, and how do they work?</p><p>To begin to analyze these questions in the context of deep ReLU networks, we used a student-teacher setting, in which a larger student network must learn to mimic exactly what the smaller teacher is doing. Since we can define the teacher network with fixed parameters in this setting, we can quantitatively measure the student network’s learning progress, and, critical to our investigation of lottery tickets, how the student network’s initialization affects the learning process.</p><p>In the student-teacher setting, we see that after training, the activity patterns of select student neurons correlate more strongly with those of teacher neurons than with the activity of other student neurons—a concept that is referred to as “student specialization.” This stronger correlation suggests that, during training, the student network not only learns the teacher’s network output but also the internal structure of the teacher by mimicking individual teacher neurons.</p><p>In our analysis, we show this occurrence happens locally in a 2-layer ReLU network: if the initial weights of a student neuron happen to be similar to those of some teacher neurons, then specialization will follow. The size of the neural network is important because the larger the student network, the more likely that one of the student neurons will start out close enough to a teacher neuron to learn to mimic its activity during training. What’s more, if a student neuron’s initial activation region has a more substantial overlap with a teacher neuron, then that student neuron specializes faster. This behavior corroborates the lottery ticket hypothesis, which similarly proposes that some lucky subset of initializations exist within neural networks, and “winning tickets” are the lucky student neurons that happen to be in the right location at the beginning of training. In our follow-up research, we strengthen our results by removing many mathematical assumptions, including independent activations and locality, and still prove that student specialization happens in the lowest layer in deep ReLU networks after training. From our analysis, we find certain mathematical properties in the training dynamics resonate with the lottery ticket phenomenon: those weights with a slight advantage in the initialization may have a greater chance of being the winning tickets after training converges.</p>'
- - /docs/iq/1980-lewin.pdf
  - "Is Your Brain Really Necessary? John Lorber, a British neurologist, claims that some patients are more normal than would be inferred from their brain scans"
  - Roger Lewin
  - 1980-12-12
  - 10.2307/1684473
  - ! '<p>…Lorber was not jesting totally when he addressed a conference of pediatricians with a paper entitled “Is your brain really necessary?” Lorber believes that his observations on a series of hydrocephalics who have severely reduced brain tissue throws into question many traditional notions about the brain, both in clinical and scientific terms.</p><p>“There’s a young student at this university,” says Lorber, “who has an IQ of 126, has gained a first-class honors degree in mathematics, and is socially completely normal. And yet the boy has virtually no brain.” The student’s physician at the university noticed that the youth had a slightly larger than normal head, and so referred him to Lorber, simply out of interest. “When we did a brain scan on him,” Lorber recalls, “we saw that instead of the normal 4.5-centimeter thickness of brain tissue between the ventricles and the cortical surface, there was just a thin layer of mantle measuring a millimeter or so. His cranium is filled mainly with cerebrospinal fluid.”</p><p>…In young children, whose skulls are still malleable, one obvious consequence can be a grossly enlarged head. Additionally, this physical assault from within leads to a real loss of brain matter. It is therefore not surprising that many hydrocephalics suffer intellectual and physical disabilities. What is surprising, however, is that a substantial proportion of patients appear to escape functional impairment in spite of grossly abnormal brain structure.</p><p>“The spina bifida unit at the Children’s Hospital here in Sheffield is one of the largest in the world,” explains Lorber, “and this gives us an opportunity to make many observations. Since the introduction of the safe, noninvasive brain scanning technique just a few years ago we have done more than 600 scans on patients with hydrocephalus.” Lorber divides the subjects into four categories: those with minimally enlarged ventricles; those whose ventricles fill 50 to 70% of the cranium; those in which the ventricles fill between 70 and 90% of the intracranial space; and the most severe group, in which ventricle expansion fills 95% of the cranium. Many of the individuals in this last group, which forms just less than 10% of the total sample, are severely disabled, but half of them have IQ’s greater than 100. This group provides some of the most dramatic examples of apparently normal function against all odds.</p><p>Commenting on Lorber’s work, Kenneth Till, a former neurosurgeon at the Great Ormond Street Hospital for Sick Children, London, has this to say: “Interpreting brain scans can be very tricky. There can be a great deal more brain tissue in the cranium than is immediately apparent.” Till echoes the cautions of many practitioners when he says, “Lorber may be being rather overdramatic when he says that someone has ‘virtually no brain.’” Lorber acknowledges the problem of interpretation of brain scans, and he counters Till’s remarks by insisting, “Of course these results are dramatic, but they’re not overdramatic. One would not make the claim if one did not have the evidence.”</p><p>…Lorber concludes from these observations that “there must be a tremendous amount of redundancy or spare capacity in the brain, just as there is with kidney and liver.” He also contends that “the cortex probably is responsible for a great deal less than most people imagine.” These are two areas of considerable dispute in neurobiology. Wall lends support for this second point. “One reason why results such as Lorber’s have been neglected for so long is because of the implied attack on the predominance of the cerebral cortex,” suggests Wall. “For hundreds of years neurologists have assumed that all that is dear to them is performed by the cortex, but it may well be that the deep structures in the brain carry out many of the functions assumed to be the sole province of the cortex.” He likens the cortex to a “reference library” that may be consulted from time to time.</p><p>On the question of the brain’s spare capacity there is equal contention. “To talk of redundancy in the brain is an intellectual cop-out to try to get round something you don’t understand,” states Wall. Geschwind agrees: “Certainly the brain has a remarkable capacity for reassigning functions following trauma, but you can usually pick up some kind of deficit with the right tests, even after apparently full recovery.” However, Colin Blakemore, professor of physiology at Oxford University, England, sees spare capacity as an important quality of the human brain. “The brain frequently has to cope with minor lesions and it’s crucial that it can overcome these readily,” he says; “there may be some reorganization of brain tissue, but mostly there’s a reallocation of function.”</p><p>It is perhaps significant that many of the instances in which gross enlargement of cerebral ventricles is compatible with normal life are cases where the condition develops slowly. Gross surgical lesions in rat brains are known to inflict severe functional disruption, but if the same damage is done bit by bit over a long period of time, the dysfunction can be minimal. Just as the rat brains appear to cope with a stepwise reduction of available hardware, so too do the human brains in some cases of hydrocephalus…The sparing of the gray matter even in severe hydrocephalus could go some way to explaining the remarkable retention of many normal functions in severely affected individuals. …</p>'
- - https://moxie.org/stories/brink-of-death/
  - Hypothermia
  - Moxie Marlinspike
  - ''
  - ''
  - ! '<p>"I made a series of mistakes that culminated in the worst sailing accident of my life, and almost took me to the bottom of the ocean."</p> <p>[One fall evening after work, Marlinspike and a friend made a simple plan to sail a 15-foot catamaran out 600 feet into the San Francisco Bay, where they’d drop anchor and row back in a smaller boat, leaving the sailboat to wait for their next adventure. (Anarchist sailors don’t like to pay dockage fees.) Marlinspike headed out into the bay on the catamaran with his friend following in a rowboat. Only after Marlinspike had passed the pier did he realize the wind was blowing at a treacherous 30 miles an hour. He decided to turn back but discovered that he’d misrigged the craft and had to fix his mistake. As the sun sank toward the horizon, he shouted to his friend that they should give up and return to shore, and the friend rowed back to safety.</p><p>Then, without warning, the wind gusted. The catamaran flipped, throwing Marlinspike into the ice-cold water. “The suddenness of it was unbelievable, as if I was on a tiny model made of paper which someone had simply flicked with their finger,” he would later write in a blog post about the experience. Soon the boat was fully upside down, pinned in place by the wind. Marlinspike tried to swim for shore. But the pier was too far away, the waves too strong, and he could feel his body succumbing to hypothermia, blackness creeping into the edges of his vision. He headed back to the overturned boat. Alone now in the dark, he clung to the hull, took stock of the last hour’s events, and realized, with slow and lonely certainty, that he was very likely going to die.</p><p>When a tugboat finally chanced upon his soaked and frozen form he was nearly unconscious and had to be towed up with a rope. When he arrived at the hospital, Marlinspike says, the nurses told him his temperature was so low their digital thermometers couldn’t register it. As he recovered over the next days, he had the sort of realization that sometimes results from a near-death experience. “It definitely sharpened my focus,” he says of the incident. “It made me question what I was doing with my life.”</p><p>Marlinspike’s time at Twitter had given him an ambitious sense of scale: He was determined to encrypt core chunks of the Internet. A normal person might have quit sailing. Instead, Marlinspike quit Twitter. A year and a day after he had started, he walked away from over $1 million in company stock.]</p>'
- - /Replications#animal-models
  - "Animal Research Methodological Problems & Transferability"
  - Gwern Branwen
  - 2013-03-22
  - ''
  - ! '<p>On the general topic of animal model external validity &amp; translation to humans, a number of op-eds, reviews, and meta-analyses have been done; reading through some of the literature up to March 2013, I would summarize them as indicating that the animal research literature in general is of considerably lower quality than human research, and that for those and intrinsic biological reasons, the probability of meaningful transfer from animal to human can be astoundingly low, far below 50% and in some categories of results, 0%.</p><p>The primary reasons identified for this poor performance are generally: small samples (much smaller than the already underpowered norms in human research), lack of blinding in taking measurements, pseudo-replication due to animals being correlated by genetic relatedness/living in same cage/same room/same lab, extensive non-normality in data, large differences between labs due to local differences in reagents/procedures/personnel illustrating the importance of “tacit knowledge”, publication bias (small cheap samples + little perceived ethical need to publish + no preregistration norms), unnatural &amp; unnaturally easy lab environments (more naturalistic environments both offer more realistic measurements &amp; challenge animals), large genetic differences due to inbreeding/engineering/drift of lab strains mean the same treatment can produce dramatically different results in different strains (or sexes) of the same species, different species can have different responses, and none of them may be like humans in the relevant biological way in the first place.</p><p>So it is no wonder that “we can cure cancer in mice but not people” and almost all amazing breakthroughs in animals never make it to human practice; medicine &amp; biology are difficult.</p>'
- - /Replication
  - "The Replication Crisis: Flaws in Mainstream Science"
  - Gwern Branwen
  - 2010-10-27
  - ''
  - ! '<p>Long-standing problems in standard scientific methodology have exploded as the “<a href="https://en.wikipedia.org/wiki/Replication_Crisis" class="docMetadata" data-popup-title="Replication crisis" data-popup-author="English Wikipedia" data-popup-abstract="<p>The <b>replication crisis</b> is, as of 2019, an ongoing methodological crisis in which it has been found that many scientific studies are difficult or impossible to replicate or reproduce. The replication crisis affects the social sciences and medicine most severely. The crisis has long-standing roots; the phrase was coined in the early 2010s as part of a growing awareness of the problem. The replication crisis represents an important body of research in the field of metascience.</p>" title="Wikipedia: Replication Crisis">Replication Crisis</a>”: the discovery that many results in fields as diverse as psychology, economics, medicine, biology, and sociology are in fact false or quantitatively highly inaccurately measured. I cover here a handful of the issues and publications on this large, important, and rapidly developing topic up to about 2013, at which point the Replication Crisis became too large a topic to cover more than cursorily.</p> <p>The crisis is caused by methods &amp; publishing procedures which interpret random noise as important results, far too small datasets, selective analysis by an analyst trying to reach expected/desired results, publication bias, poor implementation of existing best-practices, nontrivial levels of research fraud, software errors, philosophical beliefs among researchers that false positives are acceptable, neglect of known confounding like genetics, and skewed incentives (financial &amp; professional) to publish ‘hot’ results.</p> <p>Thus, any individual piece of research typically establishes little. Scientific validation comes not from small <em>p</em>-values, but from discovering a regular feature of the world which disinterested third parties can discover with straightforward research done independently on new data with new procedures—<em>replication</em>.</p>'
- - https://scottbarrykaufman.com/wp-content/uploads/2018/08/Gideon-et-al.-2018.pdf
  - "Are Bigger Brains Smarter? Evidence From a Large-Scale Preregistered Study"
  - Gideon Nave, Wi Hoon Jung, Richard Karlsson Linnér, Joseph W. Kable, Philipp D. Koellinger
  - 2018-11-30
  - 10.1177/0956797618808470
  - ! '<p>A positive relationship between brain volume and intelligence has been suspected since the 19<sup>th</sup> century, and empirical studies seem to support this hypothesis. However, this claim is controversial because of concerns about publication bias and the lack of systematic control for critical confounding factors (e.g., height, population structure). We conducted a preregistered study of the relationship between brain volume and cognitive performance using a new sample of adults from the United Kingdom that is about 70% larger than the combined samples of all previous investigations on this subject (<em>N</em> = 13,608). Our analyses systematically controlled for sex, age, height, socioeconomic status, and population structure, and our analyses were free of publication bias. We found a robust association between total brain volume and fluid intelligence (<em>r</em> = .19), which is consistent with previous findings in the literature after controlling for measurement quality of intelligence in our data. We also found a positive relationship between total brain volume and educational attainment (<em>r</em> = .12). These relationships were mainly driven by gray matter (rather than white matter or fluid volume), and effect sizes were similar for both sexes and across age groups.</p><p>[Keywords: intelligence, educational attainment, brain volume, preregistered analysis, UK Biobank, open data, open materials, preregistered]</p>'
- - https://www.theguardian.com/science/2018/apr/16/a-real-life-lord-of-the-flies-the-troubling-legacy-of-the-robbers-cave-experiment
  - "A real-life Lord of the Flies: the troubling legacy of the Robbers Cave experiment; In the early 1950s, the psychologist Muzafer Sherif brought together a group of boys at a US summer camp – and tried to make them fight each other. Does his work teach us anything about our age of resurgent tribalism? [an extract from <em>The Lost Boys</em>]"
  - David Shariatmadari
  - 2018-04-16
  - ''
  - ! '<p>In 50s Middle Grove, things didn’t go according to plan either, though the surprise was of a different nature. Despite his pretence of leaving the 11-year-olds to their own devices, Sherif and his research staff, posing as camp counsellors and caretakers, interfered to engineer the result they wanted. He believed he could make the two groups, called the Pythons and the Panthers, sworn enemies via a series of well-timed “frustration exercises”. These included his assistants stealing items of clothing from the boys’ tents and cutting the rope that held up the Panthers’ homemade flag, in the hope they would blame the Pythons. One of the researchers crushed the Panthers’ tent, flung their suitcases into the bushes and broke a boy’s beloved ukulele. To Sherif’s dismay, however, the children just couldn’t be persuaded to hate each other…The robustness of the boy’s “civilised” values came as a blow to Sherif, making him angry enough to want to punch one of his young academic helpers. It turned out that the strong bonds forged at the beginning of the camp weren’t easily broken. Thankfully, he never did start the forest fire—he aborted the experiment when he realised it wasn’t going to support his hypothesis.</p><p>But the Rockefeller Foundation had given Sherif $38,000. In his mind, perhaps, if he came back empty-handed, he would face not just their anger but the ruin of his reputation. So, within a year, he had recruited boys for a second camp, this time in Robbers Cave state park in Oklahoma. He was determined not to repeat the mistakes of Middle Grove.</p><p>…At Robbers Cave, things went more to plan. After a tug-of-war in which they were defeated, the Eagles burned the Rattler’s flag. Then all hell broke loose, with raids on cabins, vandalism and food fights. Each moment of confrontation, however, was subtly manipulated by the research team. They egged the boys on, providing them with the means to provoke one another—who else, asks Perry in her book, could have supplied the matches for the flag-burning?</p><p>…Sherif was elated. And, with the publication of his findings that same year, his status as world-class scholar was confirmed. The “Robbers Cave experiment” is considered seminal by social psychologists, still one of the best-known examples of “realistic conflict theory”. It is often cited in modern research. But was it scientifically rigorous? And why were the results of the Middle Grove experiment—where the researchers couldn’t get the boys to fight—suppressed? “Sherif was clearly driven by a kind of a passion,” Perry says. “That shaped his view and it also shaped the methods he used. He really did come from that tradition in the 30s of using experiments as demonstrations—as a confirmation, not to try to find something new.” In other words, think of the theory first and then find a way to get the results that match it. If the results say something else? Bury them…“I think people are aware now that there are real ethical problems with Sherif’s research,” she tells me, “but probably much less aware of the backstage [manipulation] that I’ve found. And that’s understandable because the way a scientist writes about their research is accepted at face value.” The published report of Robbers Cave uses studiedly neutral language. “It’s not until you are able to compare the published version with the archival material that you can see how that story is shaped and edited and made more respectable in the process.” That polishing up still happens today, she explains. “I wouldn’t describe him as a charlatan … every journal article, every textbook is written to convince, persuade and to provide evidence for a point of view. So I don’t think Sherif is unusual in that way.”</p>'
- - /docs/sr/2016-munksgaard.pdf
  - 'A replication and methodological critique of the study “Evaluating drug trafficking on the Tor Network”'
  - Rasmus Munksgaard, Jakob Demant, Gwern Branwen
  - 2016-09
  - 10.1016/j.drugpo.2016.02.027
  - ! "[Debunking a remarkably sloppy darknet market paper which screwed up its scraping and somehow concluded that the notorious Silk Road 2, in defiance of all observable evidence & subsequent FBI data, actually sold primarily e-books and hardly any drugs. This study has yet to be retracted.] The development of cryptomarkets has gained increasing attention from academics, including growing scientific literature on the distribution of illegal goods using cryptomarkets. Dolliver's 2015 article “Evaluating drug trafficking on the Tor Network: Silk Road 2, the Sequel” addresses this theme by evaluating drug trafficking on one of the most well-known cryptomarkets, Silk Road 2.0. The research on cryptomarkets in general—particularly in Dolliver's article—poses a number of new questions for methodologies. This commentary is structured around a replication of Dolliver's original study. The replication study is not based on Dolliver's original dataset, but on a second dataset collected applying the same methodology. We have found that the results produced by Dolliver differ greatly from our replicated study. While a margin of error is to be expected, the inconsistencies we found are too great to attribute to anything other than methodological issues. The analysis and conclusions drawn from studies using these methods are promising and insightful. However, based on the replication of Dolliver's study, we suggest that researchers using these methodologies consider and that datasets be made available for other researchers, and that methodology and dataset metrics (e.g. number of downloaded pages, error logs) are described thoroughly in the context of web-o-metrics and web crawling."
- - /statistics/bias/2005-jussim.pdf
  - "Teacher expectations and self-fulfilling prophecies: knowns and unknowns, resolved and unresolved controversies"
  - Lee Jussim, Kent D. Harber
  - '2005'
  - 10.1207/s15327957pspr0902_3
  - ! '<p>This article shows that 35 years of empirical research on teacher expectations justifies the following conclusions: (a) Self-fulfilling prophecies in the classroom do occur, but these effects are typically small, they do not accumulate greatly across perceivers or over time, and they may be more likely to dissipate than accumulate; (b) powerful self-fulfilling prophecies may selectively occur among students from stigmatized social groups; (c) whether self-fulfilling prophecies affect intelligence, and whether they in general do more harm than good, remains unclear, and (d) teacher expectations may predict student outcomes more because these expectations are accurate than because they are self-fulfilling. Implications for future research, the role of self-fulfilling prophecies in social problems, and perspectives emphasizing the power of erroneous beliefs to create social reality are discussed.</p><p>[Jussim discusses the famous ‘Pygmalion effect’. It demonstrates the Replication crisis: an initial extraordinary finding indicating that teachers could raise student IQs by dozens of points gradually shrunk over repeated replications to essentially zero net long-term effect. The original finding was driven by statistical malpractice bordering on research fraud: some students had “pretest IQ scores near zero, and others had post-test IQ scores over 200”! Rosenthal further maintained the Pygmalion effect by statistical trickery, such as his ‘fail-safe <em>N</em>’, which attempted to show that hundreds of studies would have to have not been published in order for the Pygmalion effect to be true—except this assumes zero publication bias in those unpublished studies and begs the question.]</p>'
- - http://www.2arms1head.com/
  - "Two Arms and a Head: The Death of a Newly Paraplegic Philosopher"
  - Clayton Atreus
  - 2008-02-24
  - ''
  - ! '<p>[Paper/suicide note by a philosophy graduate <a href="https://advrider.com/f/threads/seattle-to-argentina-on-a-klr650.136505/">who went on a motorcycle tour of Mexico</a> and ran into a goat, instantly becoming a <a href="https://en.wikipedia.org/wiki/Paraplegia">paraplegic</a>. Atreus discusses how paraplegia robs him of the ability to do almost everything he valued in life, from running to motorcycling to sex, while burdening him down with dead weight equivalent to hundreds of pounds, which make the simplest action, like getting out of a car, take minutes or hours, radically shortening his effective days. He is an ambulatory corpse, “two arms and a head”. Atreus discusses in detail the existential horror of his condition, from complete lack of bowel control requiring him to constantly dig his own feces out of his anus to being trapped in a wheelchair larger than a washing machine to the cruelty of well-intentioned encouragement to social alienation and his constant agonized awareness of everything he has lost. If the first question of philosophy is whether to commit suicide, Atreus finds that for him, the answer is "yes". The paper/book concludes with his description of stabbing himself and slowly bleeding to death.]</p><p>This book is born of pain. I wrote it out of <em>compulsion</em> during the most hellish time of my life. Writing it hurt me and was at times extremely unpleasant. Is the book my death-rattle or the sound of me screaming inside of my cage? Does its tone tell you I am angry or merely seeking a psychological expedient against the madness I see around me? The book is my creation but is also in many ways foreign to me for I am living in a foreign land. Most generally perhaps it is just the thoughts that passed through my head over the twenty months I spent moving toward death. I am certainly not a man who is at peace with his life, but on the contrary I despise it as I have never before despised anything. Who can sort it all out? Being imprisoned in the nightmarish cage of paraplegia has done all manner of violence to the deepest parts of me. Still, I have not gone mad. I am no literary genius and don’t expect everything I say to be understood, but if you would like to know what my experiences have been like, and what I am like, I will try my best to show you.</p><p>What do I think of this book? I have no affection for it. I find it odious and unattractive and am very saddened that I wrote it. But it is what I had to say. It took on a life of its own and when I now step back and look at what I created I regard it with distaste. If I could, I would put all of these horrible thoughts in a box, seal it forever, then go out and live life. I would run in the sun, enjoy my freedom, and revel in myself. But that’s the point. I cannot go out and live life because this is not life. So instead I speak to you from the place I now occupy, between life and death.</p><p>… Imagine a man cut off a few inches below the armpits. Neglect for a moment questions concerning how he eliminates waste and so forth, and just assume that the site of the “amputation” is, to borrow from Gogol, “as uniform as a newly fried pancake”. This man would be vastly, immensely better off than me. If you don’t know who <a href="https://en.wikipedia.org/wiki/Johnny_Eck">Johnny Eck</a> is, he had a role in the <a href="https://en.wikipedia.org/wiki/Freaks_(1932_film)">1932 movie <em>Freaks</em></a>. He was the guy who was essentially a torso with arms. He walked on his hands. How fortunate he was compared to me may not register right away, because the illusion I mentioned above would probably make you find Johnny Eck’s condition far more shocking than mine. But the truth is that mine is much more horrible than his, barring whatever social “advantages” the illusion of being whole might confer on me. The other day I saw a picture of a woman missing both legs. They were cut off mid-thigh. I thought that if only I was like her perhaps my life would be bearable. She was, in my opinion, better off than the pancake man, who is beyond any doubt far better off than me. One man said to me, “At least you didn’t lose your legs.” No, I <em>did</em> lose my legs, and my penis, and my pelvis. Let’s get something very clear about the difference between paraplegics and double-leg amputees. If tomorrow every paraplegic woke up as a double-leg amputee, the Earth itself would quiver with ecstasy from the collective bursting forth of joyous emotion. Tears of the most exquisitely overwhelming relief and happiness would stream down the cheeks of former paraplegics the world over. My wording here is deliberate. It’s no exaggeration. Losing both legs is bad, but paraplegia is ghoulishly, nightmarishly worse.</p> <p>Part of what I wanted in desiring to die in the company of those I loved was to reassure them and perhaps give them courage to face death well.  That was something I really wanted to give to them and I’m sorry I can only do it with these words. I was driven almost mad by all of the things many other people said about paraplegia, suicide, and what was still possible in my condition. I hope everyone understands how all of that affected the tone of what I wrote. I was so frustrated with all of it, I thought it was so insane. But I only wanted to break free of it all and say what I felt. I felt like it stifled me so horribly.</p> <p>I cut some more and the blood is flowing well again. I’m surprised how long it is taking me to even feel anything. I thought I was dizzy but I’m not sure I am now. It’s 8:51 pm. I thought I would get cold but I’m not cold either, I’m actually hot but that’s probably the two sweaters. Starting to feel a little badly. Sweating, a little light-headed.</p> <p>I’m going to go now, done writing. Goodbye everyone.</p>'
- - https://emptypath.wordpress.com/2011/12/16/in-praise-of-self-deprecation/
  - "In praise of self-deprecation"
  - Wislawa Szymborska
  - '1976'
  - ''
  - ! '<blockquote><p>The buzzard has nothing to fault himself with.<br />Scruples are alien to the black panther.<br />Piranhas do not doubt the rightness of their actions.<br />The rattlesnake approves of himself without reservations.<br /></p><p>The self-critical jackal does not exist.<br />The locust, alligator, trichina, horsefly<br />live as they live and are glad of it.<br /></p><p>The killer whale’s heart weighs one hundred kilos<br />but in other respects it is light.<br /></p><p>There is nothing more animal-like<br />than a clear conscience<br />on the third planet of the Sun.<br /></p></blockquote>'
- - https://www.wsj.com/articles/the-summers-most-unread-book-is-1404417569
  - ! "The Summer's Most Unread Book Is… A simple index drawn from e-books shows which best sellers are going unread (we're looking at you, Piketty)"
  - Jordan Ellenberg
  - 2014-07-03
  - ''
  - ! '<p>Sadly overlooked is that other crucial literary category: the summer <em>non</em>-read, the book that you pick up, all full of ambition, at the beginning of June and put away, the bookmark now and forever halfway through chapter 1, on Labor Day. The classic of this genre is Stephen Hawking’s <em>A Brief History of Time</em>, widely called “the most unread book of all time.”…How can we find today’s greatest non-reads? Amazon’s “Popular Highlights” feature provides one quick and dirty measure. Every book’s Kindle page lists the five passages most highlighted by readers. If every reader is getting to the end, those highlights could be scattered throughout the length of the book. If nobody has made it past the introduction, the popular highlights will be clustered at the beginning.</p><p>Thus, the Hawking Index (HI): Take the page numbers of a book’s five top highlights, average them, and divide by the number of pages in the whole book. The higher the number, the more of the book we’re guessing most people are likely to have read. (Disclaimer: This is not remotely scientific and is for entertainment purposes only!) Here’s how some current best sellers and classics weigh in, from highest HI to lowest:</p><ul><li><p><em>Thinking Fast and Slow</em> by Daniel Kahneman: 6.8%</p><p>Apparently the reading was more slow than fast. To be fair, Prof. Kahneman’s book, the summation of a life’s work at the forefront of cognitive psychology, is more than twice as long as <em>Lean In</em>, so his score probably represents just as much total reading as Ms. Sandberg’s does.</p></li><li><p><em>A Brief History of Time</em> by Stephen Hawking: 6.6%</p><p>The original avatar backs up its reputation pretty well. But it’s outpaced by one more recent entrant—which brings us to our champion, the most unread book of this year (and perhaps any other). Ladies and gentlemen, I present:</p></li><li><p><em>Capital in the Twenty-First Century</em> by Thomas Piketty: 2.4%</p><p>Yes, it came out just three months ago. But the contest isn’t even close. Mr. Piketty’s book is almost 700 pages long, and the last of the top five popular highlights appears on page 26. Stephen Hawking is off the hook; from now on, this measure should be known as the Piketty Index.</p></li></ul>'
- - https://www.inc.com/minda-zetlin/amazon-book-stuffing-authors-scam-chance-carter-romance-kindle-unlimited.html
  - ! "Kindle Unlimited Book Stuffing Scam Earns Millions and Amazon Isn't Stopping It: Book stuffer Chance Carter is gone. But readers are still paying for books that are 90 percent filler."
  - Minda Zetlin
  - 2018-06-13
  - ''
  - ! '<p>…a distasteful practice called “book stuffing” by some Kindle Unlimited authors. Kindle Unlimited is an Amazon program that works like Netflix for books: You can read as much as you want for a flat monthly fee. For various reasons, Kindle Unlimited is filled with books written and self-published by independent authors, many of them in the romance genre.</p><p>How do authors get compensated when readers pay a flat fee for the service? Amazon has created a pool of funds that authors are paid from, currently around $22.5 million. Up until 2015, authors earned a flat fee for each download of their books. But the company noticed that many of these Kindle Unlimited books were very, very short. So instead, Amazon began paying a bit less than ¢0.5 cent for each page that was actually read. That’s how book stuffing was born.</p><p>It works like this. An Amazon author publishes a new book that’s, say, 300 pages long. At ¢0.5 per page, the author would earn about $1.50 every time that book was read to the end. To beef up their earnings, book stuffers add several other already-published books, or a long series of newsletters, to the end of the book as “bonus material.” Most stuffed books run near 3,000 pages, the maximum that Amazon will pay for. In the current system, an author could earn about $13.50 per book this way, which is more than most authors earn from traditional publishers when their books are sold as hardcovers.</p><p><strong>$1.2 million a year?</strong></p><p>Serious book stuffers acquire email lists that they sometimes share with each other. They boost their sales by sending out promotional email to hundreds of thousands of email addresses. They also spend a lot of money on Amazon Marketing Services, promoting their books as “sponsored” to Kindle Unlimited subscribers and other Kindle shoppers. These tactics, in combination with artificially producing positive reviews (against Amazon’s rules), help them rank high in Amazon’s romance category, crowding out authors who take a more traditional approach. Some book stuffers publish a new book every couple of weeks (they may use ghostwriters to actually write the books), doing a new promotion for each one. In this way, observers report, they can earn as much as $100,000 <em>per month</em>.</p><p>…Why would anyone read through 2,700 pages of uninteresting bonus material? They usually don’t, but many authors do something that gets people to turn to the last page of the book, such as promising a contest or giveaway (forbidden by Amazon rules), or putting some new and perhaps particularly racy content right at the end of the book. On some devices, Amazon may simply be using the last page opened as a measure of how much of a book was “read.” Thus, the author gets full credit for the book, even though the customer didn’t read all of it.</p><p>…Carter openly invited other authors to pay for the use of his “platform” to send out promotional emails to their own mailing lists and also share mailing lists and cross-promote with other authors/book stuffers. In fact, he was so proud of his book stuffing talents that he posted his credo for the world to see in a Kindle publishing forum:</p><blockquote><ul><li>Making content as long as possible.</li><li>Releasing as frequently as possible.</li><li>Advertising as hard as possible.</li><li>Ranking as high as possible.</li><li>And then doing it all over again.</li></ul></blockquote>'
- - https://www.theverge.com/2018/7/16/17566276/cockygate-amazon-kindle-unlimited-algorithm-self-published-romance-novel-cabal
  - "Bad romance: To cash in on Kindle Unlimited, a cabal of authors gamed Amazon’s algorithm"
  - Sarah Jeong
  - 2018-07-16
  - ''
  - ! '<p>On June 4<sup>th</sup>, a group of lawyers shuffled into a federal court in Manhattan to argue over two trademark registrations. The day’s hearing was the culmination of months of internet drama—furious blog posts, Twitter hashtags, YouTube videos, claims of doxxing, and death threats….They were gathered there that day because one self-published romance author was suing another for using the word “cocky” in her titles. And as absurd as this courtroom scene was—with a federal judge soberly examining the shirtless doctors on the cover of an “MFM Menage Romance”—it didn’t even begin to scratch the surface.</p><p>The fight over <code>#Cockygate</code>, as it was branded online, emerged from the strange universe of Amazon Kindle Unlimited, where authors collaborate and compete to game Amazon’s algorithm. Trademark trolling is just the beginning: There are private chat groups, ebook exploits, conspiracies to seed hyper-specific trends like “Navy SEALs” and “mountain men,” and even a controversial sweepstakes in which a popular self-published author offered his readers a chance to win diamonds from Tiffany’s if they reviewed his new book…A genre that mostly features shiny, shirtless men on its covers and sells ebooks for ¢99 a pop might seem unserious. But at stake are revenues sometimes amounting to a million dollars a year, with some authors easily netting six figures a month. The top authors can drop $50,000 on a single ad campaign that will keep them in the charts—and see a worthwhile return on that investment.</p><p>…According to Willink, over the course of RWA, Valderrama told her about certain marketing and sales strategies, which she claimed to handle for other authors. Valderrama allegedly said that she organized newsletter swaps, in which authors would promote each other’s books to their respective mailing lists. She also claimed to manage review teams—groups of assigned readers who were expected to leave reviews for books online. According to Willink, Valderrama’s authors often bought each other’s books to improve their ranking on the charts—something that she arranged, coordinating payments through her own PayPal account. Valderrama also told her that she used multiple email addresses to buy authors’ books on iBooks when they were trying to hit the USA Today list. When Valderrama invited Willink to a private chat group of romance authors, Willink learned practices like chart gaming and newsletter placement selling—and much more—were surprisingly common.</p><p>…In yet more screencaps, members discuss the mechanics of “book stuffing.” Book stuffing is a term that encompasses a wide range of methods for taking advantage of the Kindle Unlimited revenue structure. In Kindle Unlimited, readers pay $9.99 a month to read as many books as they want that are available through the KU program. This includes both popular mainstream titles like the <em>Harry Potter</em> series and self-published romances put out by authors like Crescent and Hopkins. Authors are paid according to pages read, creating incentives to produce massively inflated and strangely structured books. The more pages Amazon thinks have been read, the more money an author receives.</p><p>…Book stuffing is particularly controversial because Amazon pays authors from a single communal pot. In other words, Kindle Unlimited is a zero-sum game. The more one author gets from Kindle Unlimited, the less the other authors get. The romance authors Willink was discovering didn’t go in for clumsy stuffings of automatic translations or HTML cruft; rather, they stuffed their books with ghostwritten content or repackaged, previously published material. In the latter case, the author will bait readers with promises of fresh content, like a new novella, at the end of the book. Every time a reader reads to the end of a 3,000-page book, the author earns almost 14 dollars. For titles that break into the top of the Kindle Unlimited charts, this trick can generate a fortune.</p>'
- - https://www.vox.com/culture/2019/2/6/18212431/black-leopard-red-wolf-marlon-james-review
  - "Black Leopard Red Wolf was sold as an African Game of Thrones. It’s a weirder book than that. Man Booker Prize winner Marlon James goes genre with his latest novel."
  - Constance Grady
  - 2019-02-06
  - ''
  - ! '<p>The oft-repeated elevator pitch on <em>Black Leopard Red Wolf</em>, the buzzy new novel from Man Booker Prize winner Marlon James, is that it’s the African <em>Game of Thrones</em>. (“I said that as a joke,” James protested in an interview this week.) To a certain extent, the comparison holds. <em>Black Leopard Red Wolf</em> is a lush epic fantasy set in an enchanted and mythical Africa, filled with quests and magical beasts and vicious battles to the death. But it’s also a much weirder, twistier book than the <em>Game of Thrones</em> parallels would suggest. Most notably, it is not driven by story. <em>Black Leopard Red Wolf</em> actively resists any attempts on the reader’s part to sink inside the world of the book and lose themselves. It is deliberately opaque, on the level of sentence as well as plot.</p><p>On the sentence level, James likes to withhold proper nouns until the last possible moment and then waits to reveal them just a little bit longer than you’d think he should be able to get away with. That means his sentences are generally carried by verbs, and you don’t know who is doing what or why for long stretches at a time: You just get an impression of anonymous limbs tangled together in sex or battle for some reason that is not immediately clear.</p><p>On the plot level, the quest for a missing boy that ostensibly powers the action of the book is so confusing, and has so little to do with the main character’s motivations, that the rest of the characters are constantly complaining about it. “This child carries no stakes for you,” one says toward the end of the novel to Tracker, our protagonist, and she’s correct. So is the poor sad giant who has the premise of the quest he is on explained to him multiple times and can only conclude, “Confusing, this is.”</p><p>…In other words, we know that the quest will be futile and the child will die. We also know that the protagonist is not particularly interested in the quest. It is nearly impossible for a reader to hook into the narrative. Yet <em>Black Leopard Red Wolf</em> spends hundreds and hundreds of pages tracking its many twists and permutations. The opacity here is clearly a deliberate choice on James’s part. He is not interested in easy reads or straightforward stories. “The African folktale is not your refuge from skepticism,” he told the New Yorker earlier this year. “It is not here to make things easy for you, to give you faith so you don’t have to think.” And James plans to keep things challenging through the rest of the Dark Star trilogy, of which <em>Black Leopard</em> is only the first volume. He’s modeling it on Showtime’s <em>Rashomon</em>-like series <em>The Affair</em>, he says, so that each volume will present the same events to the reader through a different point of view. “The series is three different versions of the same story, and I’m not going to tell people which they should believe,” James says.</p>'
- - https://github.com/paul-buerkner/brms
  - "brms: an R package for Bayesian generalized multivariate non-linear multilevel models using Stan"
  - Paul Bürkner et al
  - ''
  - ''
  - ! 'The brms package provides an interface to fit Bayesian generalized (non-)linear multivariate multilevel models using Stan, which is a C++ package for performing full Bayesian inference (see http://mc-stan.org/). The formula syntax is very similar to that of the package lme4 to provide a familiar and simple interface for performing regression analyses. A wide range of response distributions are supported, allowing users to fit—among others—linear, robust linear, count data, survival, response times, ordinal, zero-inflated, and even self-defined mixture models all in a multilevel context. Further modeling options include non-linear and smooth terms, auto-correlation structures, censored data, missing value imputation, and quite a few more. In addition, all parameters of the response distribution can be predicted in order to perform distributional regression. Multivariate models (i.e., models with multiple response variables) can be fit, as well. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. Model fit can easily be assessed and compared with posterior predictive checks, cross-validation, and Bayes factors.'
- - https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html#additive-distributional-models
  - "Estimating Distributional Models with brms: Additive Distributional Models"
  - Paul Bürkner
  - 2019-08-29
  - ''
  - ! '<p>This vignette provides an introduction on how to fit distributional regression models with brms. We use the term distributional model to refer to a model, in which we can specify predictor terms for all parameters of the assumed response distribution. In the vast majority of regression model implementations, only the location parameter (usually the mean) of the response distribution depends on the predictors and corresponding regression parameters. Other parameters (e.g., scale or shape parameters) are estimated as auxiliary parameters assuming them to be constant across observations. This assumption is so common that most researchers applying regression models are often (in my experience) not aware of the possibility of relaxing it. This is understandable insofar as relaxing this assumption drastically increase model complexity and thus makes models hard to fit. Fortunately, brms uses Stan on the backend, which is an incredibly flexible and powerful tool for estimating Bayesian models so that model complexity is much less of an issue.</p> <p>...In the examples so far, we did not have multilevel data and thus did not fully use the capabilities of the distributional regression framework of brms. In the example presented below, we will not only show how to deal with multilevel data in distributional models, but also how to incorporate smooth terms (i.e., splines) into the model. In many applications, we have no or only a very vague idea how the relationship between a predictor and the response looks like. A very flexible approach to tackle this problems is to use splines and let them figure out the form of the relationship.</p>'
- - /docs/iq/2014-abdulkadiroglu.pdf
  - "The Elite Illusion: Achievement Effects at Boston and New York Exam Schools"
  - "Atila Abdulkadiroğlu, Joshua Angrist, Parag Pathak"
  - 2014-02-05
  - 10.3982/ECTA10266
  - ! "Parents gauge school quality in part by the level of student achievement and a school's racial and socioeconomic mix. The importance of school characteristics in the housing market can be seen in the jump in house prices at school district boundaries where peer characteristics change. The question of whether schools with more attractive peers are really better in a value-added sense remains open, however. This paper uses a fuzzy regression-discontinuity design to evaluate the causal effects of peer characteristics. Our design exploits admissions cutoffs at Boston and New York City's heavily over-subscribed exam schools. Successful applicants near admissions cutoffs for the least selective of these schools move from schools with scores near the bottom of the state SAT score distribution to schools with scores near the median. Successful applicants near admissions cutoffs for the most selective of these schools move from above-average schools to schools with students whose scores fall in the extreme upper tail. Exam school students can also expect to study with fewer nonwhite classmates than unsuccessful applicants. Our estimates suggest that the marked changes in peer characteristics at exam school admissions cutoffs have little causal effect on test scores or college quality."
- - /docs/iq/2014-dobbie.pdf
  - "The Impact of Attending a School with High-Achieving Peers: Evidence from the New York City Exam Schools"
  - "Will Dobbie, Roland G. Fryer Jr."
  - 2014-07
  - "10.1257/app.6.3.58"
  - ! ' This paper uses data from three prominent exam high schools in New York City to estimate the impact of attending a school with high-achieving peers on college enrollment and graduation. Our identification strategy exploits sharp discontinuities in the admissions process. Applicants just eligible for an exam school have peers that score 0.17 to 0.36 standard deviations higher on eighth grade state tests and that are 6.4 to 9.5 percentage points less likely to be black or Hispanic. However, exposure to these higher-achieving and more homogeneous peers has little impact on college enrollment, college graduation, or college quality.'
- - https://articlegateway.com/index.php/AJM/article/view/2392
  - "Non-Cognitive Skills: How Much Do They Matter for Earnings in Canada?"
  - "Dawson McLean, Mohsen Bouaissa, Bruno Rainville, Ludovic Auger"
  - 2019-12-04
  - 10.33423/ajm.v19i4.2392
  - ! 'Evidence from different countries suggests that non-cognitive skills play an important role in wage determination and overall social outcomes, but studies for Canada are scarce. We contribute to filling this gap by estimating wage regressions with the Big Five traits using the Longitudinal and International Study of Adults. Our results indicate that conscientiousness is positively associated with wages, while agreeableness, extraversion, and neuroticism are associated with negative returns, with higher magnitudes on agreeableness and conscientiousness for females. Cognitive ability has the highest estimated wage return so, while significant, non-cognitive skills do not seem to be the most important wage determinant. [Keywords: Management, Labour Market, Returns to Skills, Non-Cognitive Skill, Cognitive Skill, Wage Regressions, Personality Traits, Five-Factor Model]'
- - https://openai.com/blog/sparse-transformer/
  - "Generative Modeling with Sparse Transformers: We’ve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence—whether text, images, or sound. It uses an algorithmic improvement of the <em>attention</em> mechanism to extract patterns from sequences 30× longer than possible previously"
  - Rewon Child, Scott Gray (OpenAI)
  - 2019-04-23
  - ''
  - ! '<p>One existing challenge in AI research is modeling long-range, subtle interdependencies in complex data like images, videos, or sounds. The Sparse Transformer incorporates an O(N ⋅ √N) reformulation of the O(N<sup>2</sup>) Transformer self-attention mechanism, along with several other improvements, to apply it directly to these rich data types. Previously, models used on these data were specifically crafted for one domain or difficult to scale to sequences more than a few thousand elements long. In contrast, our model can model sequences with tens of thousands of elements using hundreds of layers, achieving state-of-the-art performance across multiple domains. At OpenAI, we’re using it to help us build AI systems that possess a greater ability to understand the world…Even computing a single attention matrix, however, can become impractical for very large inputs. We instead use sparse attention patterns, where each output position only computes weightings from a subset of input positions.</p><p><strong>Future work and limitations</strong>:</p><ul><li>The sparse attention patterns we introduced are only preliminary steps in the direction of efficient modeling of long sequences. We think exploring different patterns and combinations of sparsity is useful, and that learning sparse patterns is a particularly promising avenue of research for the next generation of neural network architectures.</li><li>Even with the improvements we described above, autoregressive sequence generation still seems impractical for very high resolution images or video. The optimized attention operations we have introduced, however, may be useful primitives to combine with other approaches to modeling high dimensional data, like multi-scale approaches.</li></ul>'
- - https://openai.com/blog/musenet/
  - "MuseNet: a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles"
  - Christine Payne (OpenAI)
  - 2019-04-25
  - ''
  - ! '<p>We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as GPT-2, a large-scale transformer model trained to predict the next token in a sequence, whether audio or text.</p><p>[See also: <a href="https://arxiv.org/abs/1904.10509">“Generating Long Sequences with Sparse Transformers”</a>, Child et al 2019</p><blockquote><p>Transformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to O(n ⋅ √n). We also introduce (a) a variation on architecture and initialization to train deeper networks, (b) the recomputation of attention matrices to save memory, and (c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, CIFAR-10, and ImageNet-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more. ]</p></blockquote>'
- - https://magenta.tensorflow.org/music-transformer
  - "Music Transformer: Generating Music with Long-Term Structure"
  - Cheng-Zhi Anna Huang, Ian Simon, Monica Dinculescu (Google Magenta)
  - 2018-12-13
  - ''
  - ! '<p><strong>Update (9/16/19)</strong>: <em><a href="https://magenta.tensorflow.org/piano-transformer">Play with Music Transformer</a> in an interactive Colab!</em></p><figure style="text-align: center;"><img src="/images/gan/2018-huang-magenta-musictransformer-attentionvisualization.png" alt="https://magenta.tensorflow.org/assets/music_transformer/motifs_shaded_boxes.png" style="max-width: 100%; margin: auto" /></figure><p>Generating long pieces of music is a challenging problem, as music contains structure at multiple timescales, from millisecond timings to motifs to phrases to repetition of entire sections. We present <a href="https://arxiv.org/abs/1809.04281">Music Transformer</a>, an attention-based neural network that can generate music with improved long-term coherence. Here are three piano performances generated by the model:</p><center><div><audio controls=""><source src="https://magenta.tensorflow.org/assets/music_transformer/relatively_jazz.mp3" type="audio/mpeg" /></audio></div><div><audio controls=""><source src="https://magenta.tensorflow.org/assets/music_transformer/classical_favourite_sample.mp3" type="audio/mpeg" /></audio></div><div><audio controls=""><source src="https://magenta.tensorflow.org/assets/music_transformer/transformer_nice.mp3" type="audio/mpeg" /></audio></div></center><p>Similar to <a href="performance-rnn">Performance RNN</a>, we use an event-based representation that allows us to generate expressive performances directly (i.e. without first generating a score). In contrast to an LSTM-based model like Performance RNN that compresses earlier events into a fixed-size hidden state, here we use a <a href="https://arxiv.org/abs/1706.03762">Transformer</a>-based model that has direct access to all earlier events.</p><p>Our recent <a href="https://magenta.tensorflow.org/maestro-wave2midi2wave">Wave2Midi2Wave</a> project also uses Music Transformer as its language model.</p>'
- - https://openai.com/projects/five/
  - "OpenAI Five: 2016–2019"
  - OpenAI
  - 2019-12-13
  - ''
  - ! '<p>At OpenAI, we’ve used the multiplayer video game Dota 2 as a research platform for general-purpose AI systems. Our Dota 2 AI, called OpenAI Five, learned by playing over 10,000 years of games against itself. It demonstrated the ability to achieve expert-level performance, learn human–AI cooperation, and operate at internet scale.</p> <p>[OpenAI final report on OA5: timeline, training curve, index of blog posts.]</p>'
- - /docs/psychology/1996-petrie.pdf
  - "Environment is not the Most Important Variable in Determining Oral Morphine Consumption in Wistar Rats"
  - B. F. Petrie
  - 1996-04-01
  - 10.2466/pr0.1996.78.2.391
  - ! 'The role of differential housing on sucrose-morphine consumption in outbred Wistar rats was investigated in two studies. The results of earlier research, indicating rats housed in a quasi-natural colony drank significantly less sucrose-morphine than rats isolated in standard laboratory cages, could not be replicated, as the consumption of sucrose-morphine by the isolated animals in the present two studies was reduced. It is possible that during a colony conversion the supplier inadvertently introduced strain differences making the present rats more resistant to xenobiotic consumption. Discussion documents the role of genetics in morphine consumption.'
- - https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf#page=5
  - "GPT-1: Improving Language Understanding by Generative Pre-Training"
  - "Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever"
  - 2018-06-08
  - ''
  - ! 'Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by <em>generative pre-training</em> of a language model on a diverse corpus of unlabeled text, followed by <em>discriminative fine-tuning</em> on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).'
- - https://ftfy.readthedocs.io/en/latest/
  - "ftfy: fixes text for you"
  - 'ftfy'
  - ''
  - ''
  - ! '<p><code>ftfy</code> fixes Unicode that’s broken in various ways.</p><p>The goal of ftfy is to <strong>take in bad Unicode and output good Unicode</strong>, for use in your Unicode-aware code. This is different from taking in non-Unicode and outputting Unicode, which is not a goal of ftfy. It also isn’t designed to protect you from having to write Unicode-aware code. ftfy helps those who help themselves.</p><p>Of course you’re better off if your input is decoded properly and has no glitches. But you often don’t have any control over your input; it’s someone else’s mistake, but it’s your problem now.</p><p>ftfy will do everything it can to fix the problem.</p>'
- - https://onlinelibrary.wiley.com/doi/full/10.1111/ele.13438
  - "Individual differences in behaviour explain variation in survival: a meta-analysis"
  - "Maria Moiron, Kate L. Laskowski, Petri T. Niemelä"
  - 2019-12-06
  - 10.1111/ele.13438
  - ! 'Research focusing on among-individual differences in behaviour (‘animal personality’) has been blooming for over a decade. Central theories explaining the maintenance of such behavioural variation posits that individuals expressing greater “risky” behaviours should suffer higher mortality. Here, for the first time, we synthesize the existing empirical evidence for this key prediction. Our results did not support this prediction as there was no directional relationship between riskier behaviour and greater mortality; however there was a significant absolute relationship between behaviour and survival. In total, behaviour explained a significant, but small, portion (5.8%) of the variance in survival. We also found that risky (vs. “shy”) behavioural types live significantly longer in the wild, but not in the laboratory. This suggests that individuals expressing risky behaviours might be of overall higher quality but the lack of predation pressure and resource restrictions mask this effect in laboratory environments. Our work demonstrates that individual differences in behaviour explain important differences in survival but not in the direction predicted by theory. Importantly, this suggests that models predicting behaviour to be a mediator of reproduction-survival trade-offs may need revision and/or empiricists may need to reconsider their proxies of risky behaviours when testing such theory.'
- - https://journals.sagepub.com/doi/pdf/10.1177/1098612X15582080
  - Audiogenic reflex seizures in cats
  - Mark Lowrie, Claire Bessant, Robert J Harvey, Andrew Sparkes, Laurent Garosi
  - 2015-04-27
  - '10.1177/1098612X15582080'
  - ! '<p><strong>Objectives</strong>: This study aimed to characterise feline audiogenic reflex seizures (FARS).</p><p><strong>Methods</strong>: An online questionnaire was developed to capture information from owners with cats suffering from FARS. This was collated with the medical records from the primary veterinarian. 96 cats were included.</p><p><strong>Results</strong>: Myoclonic seizures were one of the cardinal signs of this syndrome (90/96), frequently occurring prior to generalised tonic–clonic seizures (GTCSs) in this population. Other features include a late onset (median 15 years) and absence seizures (6/96), with most seizures triggered by high-frequency sounds amid occasional spontaneous seizures (up to 20%). Half the population (48/96) had hearing impairment or were deaf. One-third of cats (35/96) had concurrent diseases, most likely reflecting the age distribution. Birmans were strongly represented (30/96). Levetiracetam gave good seizure control. The course of the epilepsy was non-progressive in the majority (68/96), with an improvement over time in some (23/96). Only 33/96 and 11/90 owners, respectively, felt the GTCSs and myoclonic seizures affected their cat’s quality of life (QoL). Despite this, many owners (50/96) reported a slow decline in their cat’s health, becoming less responsive (43/50), not jumping (41/50), becoming uncoordinated or weak in the pelvic limbs (24/50) and exhibiting dramatic weight loss (39/50). These signs were exclusively reported in cats experiencing seizures for &gt;2 years, with 42/50 owners stating these signs affected their cat’s QoL.</p><p><strong>Conclusions and relevance</strong>: In gathering data on audiogenic seizures in cats, we have identified a new epilepsy syndrome named FARS with a geriatric onset. Further studies are warranted to investigate potential genetic predispositions to this condition.</p>'
- - https://thesession.org/
  - The Session
  - 'The Session community'
  - ''
  - ''
  - ! 'The Session is an online community and website dedicated to Irish traditional music. You can find >40k tunes to play, find sessions to play them in, and join in discussions about the music. You can also find events (like concerts and festivals), or explore the track listings of recordings.'
- - https://www.nature.com/articles/s41467-019-13585-5
  - "Genome-wide analysis identifies molecular systems and 149 genetic loci associated with income"
  - W. David Hill, Neil M. Davies, Stuart J. Ritchie, Nathan G. Skene, Julien Bryois, Steven Bell, Emanuele Di Angelantonio, David J. Roberts, Shen Xueyi, Gail Davies, David C. M. Liewald, David J. Porteous, Caroline Hayward, Adam S. Butterworth, Andrew M. McIntosh, Catharine R. Gale, Ian J. Deary
  - 2019-12-16
  - 10.1038/s41467-019-13585-5
  - ! 'Socioeconomic position (SEP) is a multi-dimensional construct reflecting (and influencing) multiple socio-cultural, physical, and environmental factors. In a sample of 286,301 participants from UK Biobank, we identify 30 (29 previously unreported) independent-loci associated with income. Using a method to meta-analyze data from genetically-correlated traits, we identify an additional 120 income-associated loci. These loci show clear evidence of functionality, with transcriptional differences identified across multiple cortical tissues, and links to GABA-ergic and serotonergic neurotransmission. By combining our genome wide association study on income with data from eQTL studies and chromatin interactions, 24 genes are prioritized for follow up, 18 of which were previously associated with intelligence. We identify intelligence as one of the likely causal, partly-heritable phenotypes that might bridge the gap between molecular genetic inheritance and phenotypic consequence in terms of income differences. These results indicate that, in modern era Great Britain, genetic effects contribute towards some of the observed socioeconomic inequalities.'
- - https://danluu.com/keyboard-latency/
  - Keyboard latency
  - Dan Luu
  - 2017-10-16
  - ''
  - ! '<p>[Dan Luu continues his investigation of why computers feel so laggy and have such high latency compared to old computers (<a href="https://danluu.com/input-lag/">total computer latency</a>, <a href="https://danluu.com/term-latency/">terminal latency</a>, <a href="https://danluu.com/web-bloat/">web bloat</a>, cf <a href="https://pavelfatin.com/typing-with-pleasure/">Pavel Fatin’s “Typing with pleasure”</a> text editor analysis).</p><p>He measures 21 keyboard latencies using a logic analyzer, finding a range of 15–60ms (!), representing a waste of a large fraction of the available ~100–200ms latency budget before a user notices and is irritated (“the median keyboard today adds as much latency as the entire end-to-end pipeline as a fast machine from the 70s.”). The latency estimates are surprising, and do not correlate with advertised traits. They simply have to be measured empirically.]</p><p>We can see that, even with the limited set of keyboards tested, there can be as much as a 45ms difference in latency between keyboards. Moreover, a modern computer with one of the slower keyboards attached can’t possibly be as responsive as a quick machine from the 70s or 80s because the keyboard alone is slower than the entire response pipeline of some older computers. That establishes the fact that modern keyboards contribute to the latency bloat we’ve seen over the past forty years…Most keyboards add enough latency to make the user experience noticeably worse, and keyboards that advertise speed aren’t necessarily faster. The two gaming keyboards we measured weren’t faster than non-gaming keyboards, and the fastest keyboard measured was a minimalist keyboard from Apple that’s marketed more on design than speed.</p>'
- - https://danluu.com/input-lag/
  - 'Computer latency: 1977–2017'
  - Dan Luu
  - 2017-12
  - ''
  - ! '<p>I’ve had this nagging feeling that the computers I use today feel slower than the computers I used as a kid. As a rule, I don’t trust this kind of feeling because human perception has been shown to be unreliable in empirical studies, so I carried around a high-speed camera and measured the response latency of devices I’ve run into in the past few months. These are tests of the latency between a keypress and the display of a character in a terminal (see appendix for more details) …If we look at overall results, the fastest machines are ancient. Newer machines are all over the place. Fancy gaming rigs with unusually high refresh-rate displays are almost competitive with machines from the late 70s and early 80s, but “normal” modern computers can’t compete with thirty to forty year old machines.</p><p>…Almost every computer and mobile device that people buy today is slower than common models of computers from the 70s and 80s. Low-latency gaming desktops and the iPad Pro can get into the same range as quick machines from thirty to forty years ago, but most off-the-shelf devices aren’t even close.</p><p>If we had to pick one root cause of latency bloat, we might say that it’s because of “complexity”. Of course, we all know that complexity is bad. If you’ve been to a non-academic non-enterprise tech conference in the past decade, there’s a good chance that there was at least one talk on how complexity is the root of all evil and we should aspire to reduce complexity.</p><p>Unfortunately, it’s a lot harder to remove complexity than to give a talk saying that we should remove complexity. A lot of the complexity buys us something, either directly or indirectly. When we looked at the input of a fancy modern keyboard vs. the Apple 2 keyboard, we saw that using a relatively powerful and expensive general purpose processor to handle keyboard inputs can be slower than dedicated logic for the keyboard, which would both be simpler and cheaper. However, using the processor gives people the ability to easily customize the keyboard, and also pushes the problem of “programming” the keyboard from hardware into software, which reduces the cost of making the keyboard. The more expensive chip increases the manufacturing cost, but considering how much of the cost of these small-batch artisanal keyboards is the design cost, it seems like a net win to trade manufacturing cost for ease of programming.</p>'
- - https://danluu.com/term-latency/
  - Terminal Latency
  - Dan Luu
  - 2017-07-18
  - ''
  - ! '<p>These graphs show the distribution of latencies for each terminal. The y-axis has the latency in milliseconds. The x-axis is the percentile (e.g., 50 means represents 50%-ile keypress i.e., the median keypress). Measurements are with macOS unless otherwise stated. The graph on the left is when the machine is idle, and the graph on the right is under load. If we just look at median latencies, some setups don’t look too bad—terminal.app and emacs-eshell are at roughly 5ms unloaded, small enough that many people wouldn’t notice. But most terminals (st, alacritty, hyper, and iterm2) are in the range where you might expect people to notice the additional latency even when the machine is idle. If we look at the tail when the machine is idle, say the 99.9%-ile latency, every terminal gets into the range where the additional latency ought to be perceptible, according to studies on user interaction. For reference, the internally generated keypress to GPU memory trip for some terminals is slower than the time it takes to send a packet from Boston to Seattle and back, about 70ms.</p><p>…Most terminals have enough latency that the user experience could be improved if the terminals concentrated more on latency and less on other features or other aspects of performance. However, when I search for terminal benchmarks, I find that terminal authors, if they benchmark anything, benchmark the speed of sinking stdout or memory usage at startup. This is unfortunate because most “low performance” terminals can already sink stdout many orders of magnitude faster than humans can keep up with, so further optimizing stdout throughput has a relatively small impact on actual user experience for most users. Likewise for reducing memory usage when an idle terminal uses 0.01% of the memory on my old and now quite low-end laptop. If you work on a terminal, perhaps consider relatively more latency and interactivity (e.g., responsiveness to ^C) optimization and relatively less throughput and idle memory usage optimization.</p>'
- - https://www.inkandswitch.com/slow-software.html
  - Slow Software
  - Mark McGranaghan (Ink & Switch)
  - 2018-11
  - ''
  - ! '<p>You spend lots of time waiting on your computer. You pause while apps start and web pages load. Spinner icons are everywhere. Hardware gets faster, but software still feels slow. What gives? If you use your computer to do important work, you deserve fast software. Too much of today’s software falls short. At the Ink &amp; Switch research lab we’ve researched why that is, so that we can do better. This article shares we’ve learned…Let’s look at an example of how latency can add up:</p><figure><img src="/images/design/2018-mcgranaghan-inkandswitch-slowsoftware-inputlatencycascade.png" alt="Latency waterfall example: A hypothetical example of end-to-end latency from input to display. Dashed vertical lines indicate cycles the pipeline needs to wait for. (https://www.inkandswitch.com/media/slow-software/input-latency-cascade.png)" /><figcaption><em>Latency waterfall example</em>: A hypothetical example of end-to-end latency from input to display. Dashed vertical lines indicate cycles the pipeline needs to wait for.</figcaption></figure><p>…There is a deep stack of technology that makes a modern computer interface respond to a user’s requests. Even something as simple as pressing a key on a keyboard and having the corresponding character appear in a text input box traverses a lengthy, complex gauntlet of steps, from the scan rate of the keyboard, through the OS and framework processing layers, through the graphics card rendering and display refresh rate. There is reason for this complexity, and yet we feel sad that computer users trying to be productive with these devices are so often left waiting, watching spinners, or even just with the slight but still perceptible sense that their devices simply can’t keep up with them.</p><ul><li><p>What feels slow</p><ul><li>Latency not throughput</li><li>Touch interfaces</li><li>Typing</li><li>Mousing</li><li>Applications</li><li>Real-world apps</li></ul></li><li><p>Where slowness comes from</p><ul><li>Input devices</li><li>Sample rates</li><li>Displays and GPUs</li><li>Cycle stacking</li><li>Runtime overhead</li><li>Latency by design</li><li>User-hostile work</li><li>Application code</li><li>Putting it together</li></ul></li><li><p>Toward fast software</p></li><li><p>References</p></li></ul>'
- - https://www.inkandswitch.com/local-first.html
  - "Local-first software: You own your data, in spite of the cloud"
  - Martin Kleppmann, Adam Wiggins, Peter van Hardenberg, Mark McGranaghan (Ink & Switch)
  - 2019-04
  - ''
  - ! '<p>[<a href="https://www.inkandswitch.com/media/local-first/local-first.pdf" title="Kleppmann et al 2019">PDF version</a>]</p><p>Cloud apps like Google Docs and Trello are popular because they enable real-time collaboration with colleagues, and they make it easy for us to access our work from all of our devices. However, by centralizing data storage on servers, cloud apps also take away ownership and agency from users. If a service shuts down, the software stops functioning, and data created with that software is lost.</p><p>In this article we propose “local-first software”: a set of principles for software that enables both collaboration and ownership for users. Local-first ideals include the ability to work offline and collaborate across multiple devices, while also improving the security, privacy, long-term preservation, and user control of data.</p><p>We survey existing approaches to data storage and sharing, ranging from email attachments to web apps to Firebase-backed mobile apps, and we examine the trade-offs of each. We look at Conflict-free Replicated Data Types (CRDTs): data structures that are multi-user from the ground up while also being fundamentally local and private. CRDTs have the potential to be a foundational technology for realizing local-first software.</p><p>We share some of our findings from developing local-first software prototypes at Ink &amp; Switch over the course of several years. These experiments test the viability of CRDTs in practice, and explore the user interface challenges for this new data model. Lastly, we suggest some next steps for moving towards local-first software: for researchers, for app developers, and a startup opportunity for entrepreneurs.</p><p>…in the cloud, ownership of data is vested in the servers, not the users, and so we became borrowers of our own data. The documents created in cloud apps are destined to disappear when the creators of those services cease to maintain them. Cloud services defy long-term preservation. No Wayback Machine can restore a sunsetted web application. The Internet Archive cannot preserve your Google Docs.</p><p>In this article we explored a new way forward for software of the future. We have shown that it is possible for users to retain ownership and control of their data, while also benefiting from the features we associate with the cloud: seamless collaboration and access from anywhere. It is possible to get the best of both worlds.</p><p>But more work is needed to realize the local-first approach in practice. Application developers can take incremental steps, such as improving offline support and making better use of on-device storage. Researchers can continue improving the algorithms, programming models, and user interfaces for local-first software. Entrepreneurs can develop foundational technologies such as CRDTs and peer-to-peer networking into mature products able to power the next generation of applications.</p><ul><li><p>Motivation: collaboration and ownership</p></li><li><p>Seven ideals for local-first software</p><ul><li>No spinners: your work at your fingertips</li><li>Your work is not trapped on one device</li><li>The network is optional</li><li>Seamless collaboration with your colleagues</li><li>The Long Now</li><li>Security and privacy by default</li><li>You retain ultimate ownership and control</li></ul></li><li><p>Existing data storage and sharing models</p><ul><li>How application architecture affects user experience<ul><li>Files and email attachments</li><li>Web apps: Google Docs, Trello, Figma</li><li>Dropbox, Google Drive, Box, OneDrive, etc.</li><li>Git and GitHub</li></ul></li><li>Developer infrastructure for building apps<ul><li>Web app (thin client)</li><li>Mobile app with local storage (thick client)</li><li>Backend-as-a-Service: Firebase, CloudKit, Realm</li><li>CouchDB</li></ul></li></ul></li><li><p>Towards a better future</p><ul><li>CRDTs as a foundational technology</li><li>Ink &amp; Switch prototypes<ul><li>Trello clone</li><li>Collaborative drawing</li><li>Media canvas</li><li>Findings</li></ul></li><li>How you can help<ul><li>For distributed systems and programming languages researchers</li><li>For Human-Computer Interaction (HCI) researchers</li><li>For practitioners</li><li>Call for startups</li></ul></li></ul></li><li><p>Conclusions</p></li></ul>'
- - https://www.inkandswitch.com/media/local-first/local-first.pdf
  - "Local-First Software: You Own Your Data, in spite of the Cloud"
  - Martin Kleppmann, Adam Wiggins, Peter van Hardenberg, Mark McGranaghan (Ink & Switch)
  - 2019-10-23
  - 10.1145/3359591.3359737
  - ! '<p>Cloud apps like Google Docs and Trello are popular because they enable real-time collaboration with colleagues, and they make it easy for us to access our work from all of our devices. However, by centralizing data storage on servers, cloud apps also take away ownership and agency from users. If a service shuts down, the software stops functioning, and data created with that software is lost.</p><p>In this article we propose <em>local-first</em> software, a set of principles for software that enables both collaboration <em>and</em> ownership for users. Local-first ideals include the ability to work offline and collaborate across multiple devices, while also improving the security, privacy, long-term preservation, and user control of data.</p><p>We survey existing approaches to data storage and sharing, ranging from email attachments to web apps to Firebase-backed mobile apps, and we examine the trade-offs of each. We look at Conflict-free Replicated Data Types (CRDTs): data structures that are multi-user from the ground up while also being fundamentally local and private. CRDTs have the potential to be a foundational technology for realizing local-first software.</p><p>We share some of our findings from developing local-first software prototypes at the Ink &amp; Switch research lab over the course of several years. These experiments test the viability of CRDTs in practice, and explore the user interface challenges for this new data model. Lastly, we suggest some next steps for moving towards local-first software: for researchers, for app developers, and a startup opportunity for entrepreneurs.</p><p>[Keywords: collaboration software, mobile computing, data ownership, CRDTs, peer-to-peer communication]</p>'
- - /docs/traffic/2017-sinha.pdf
  - "Anti-Ad Blocking Strategy: Measuring its True Impact"
  - Atanu R. Sinha, Meghanath Macha, Pranav Maneriker, Sopan Khosla, Avani Samdariya, Navjot Singh
  - 2017-08-14
  - '10.1145/3124749.3124756'
  - ! "The increasing use of ad blocking software poses a major threat for publishers in loss of online ad revenue, and for advertisers in the loss of audience. Major publishers have adopted various anti-ad blocking strategies such as denial of access to website content and asking users to subscribe to paid ad-free versions. However, publishers are unsure about the true impact of these strategies [2, 3]. We posit that the real problem lies in the measurement of effectiveness because the existing methods compare metrics after implementation of such strategies with that of metrics just before implementation, making them error prone due to sampling bias. The errors arise due to differences in group compositions across before and after periods, as well as differences in time-period selection for the before measurement. We propose a novel algorithmic method which modifies the difference-in-differences approach to address the sampling bias due to differences in time-period selection. Unlike difference-in-differences, we choose the time-period for comparison in an endogenous manner, as well as, exploit differences in ad blocking tendencies among visitors' arriving on the publisher's site to allow cluster specific choice of the control time-period. We evaluate the method on both synthetic data (which we make available) and proprietary real data from an online publisher and find good support."
- - https://onlinelibrary.wiley.com/doi/10.1111/desc.12925
  - "Predicting educational achievement from genomic measures and socioeconomic status"
  - Sophie von Stumm, Emily Smith-Woolley, Ziada Ayorech, Andrew McMillan, Kaili Rimfeld, Philip S. Dale, Robert Plomin
  - 2019-11-23
  - 10.1111/desc.12925
  - ! '<p>The two best predictors of children’s educational achievement available from birth are parents’ socioeconomic status (SES) and, recently, children’s inherited DNA differences that can be aggregated in genome-wide polygenic scores (GPS). Here, we chart for the first time the developmental interplay between these two predictors of educational achievement at ages 7, 11, 14 and 16 in a sample of almost 5,000 UK school children. We show that the prediction of educational achievement from both GPS and SES increases steadily throughout the school years. Using latent growth curve models, we find that GPS and SES not only predict educational achievement in the first grade but they also account for systematic changes in achievement across the school years. At the end of compulsory education at age 16, GPS and SES, respectively, predict 14% and 23% of the variance of educational achievement. Analyses of the extremes of GPS and SES highlight their influence and interplay: In children who have high GPS and come from high SES families, 77% go to university, whereas 21% of children with low GPS and from low SES backgrounds attend university. We find that the associations of GPS and SES with educational achievement are primarily additive, suggesting that their joint influence is particularly dramatic for children at the extreme ends of the distribution.</p><p>Research Highlights</p><ul><li>Genome-wide polygenic scores (GPS) and socioeconomic status (SES) account together for 27% of the variance in educational achievement from age 7 through 16 years</li><li>The predictive validity of GPS and SES increases over the course of compulsory schooling</li><li>The association of GPS and SES is primarily additive: their joint long-term influence is particularly pronounced in children at the extreme ends of the distribution</li><li>77% of children with high GPS from high SES families go to university compared to 21% of children with low GPS from low SES</li></ul>'
- - https://danluu.com/web-bloat/
  - Web Bloat
  - Dan Luu
  - 2017-02-08
  - ''
  - ! '<p>A couple years ago, I took a road trip from Wisconsin to Washington and mostly stayed in rural hotels on the way. I expected the internet in rural areas too sparse to have cable internet to be slow, but I was still surprised that a large fraction of the web was inaccessible. Some blogs with lightweight styling were readable, as were pages by academics who hadn’t updated the styling on their website since 1995. But very few commercial websites were usable (other than Google). When I measured my connection, I found that the bandwidth was roughly comparable to what I got with a 56k modem in the 90s. The latency and packet loss were significantly worse than the average day on dialup: latency varied between 500ms and 1000ms and packet loss varied between 1% and 10%. Those numbers are comparable to what I’d see on dialup on a bad day.</p><p>Despite my connection being only a bit worse than it was in the 90s, the vast majority of the web wouldn’t load…When Microsoft looked at actual measured connection speeds, they found that half of Americans don’t have broadband speed. Heck, AOL had 2 million dial-up subscribers in 2015, just AOL alone. Outside of the U.S., there are even more people with slow connections. I recently chatted with Ben Kuhn, who spends a fair amount of time in Africa, about his internet connection:</p><blockquote><p>I’ve seen ping latencies as bad as ~45 sec and packet loss as bad as 50% on a mobile hotspot in the evenings from Jijiga, Ethiopia. (I’m here now and currently I have 150ms ping with no packet loss but it’s 10am). There are some periods of the day where it ~never gets better than 10 sec and ~10% loss. The internet has gotten a lot better in the past ~year; it used to be that bad all the time except in the early mornings.</p></blockquote><p>…Let’s load some websites that programmers might frequent with a variety of simulated connections to get data on page load times…The timeout for tests was 6 minutes; anything slower than that is listed as <strong>FAIL</strong>. Pages that failed to load are also listed as <strong>FAIL</strong>. A few things that jump out from the table are:</p><ol type="1"><li>A large fraction of the web is unusable on a bad connection. Even on a good (0% packet loss, no ping spike) dialup connection, some sites won’t load…If you were to look at the 90%-ile results, you’d see that most pages fail to load on dialup and the “Bad” and “😱” connections are hopeless for almost all sites.</li><li>Some sites will use a lot of data!</li></ol><p>…The flaw in the “page weight doesn’t matter because average speed is fast” [claim] is that if you average the connection of someone in my apartment building (which is wired for 1Gbps internet) and someone on 56k dialup, you get an average speed of 500 Mbps. That doesn’t mean the person on dialup is actually going to be able to load a 5MB website. The average speed of 3.9 Mbps comes from a 2014 Akamai report, but it’s just an average. If you look at Akamai’s 2016 report, you can find entire countries where more than 90% of IP addresses are slower than that!..“Use bcrypt” has become the mantra for a reasonable default if you’re not sure what to do when storing passwords. The web would be a nicer place if “use webpagetest” caught on in the same way. It’s not always the best tool for the job, but it sure beats the current defaults.</p>'
- - http://www.stuartcheshire.org/rants/latency.html
  - "It's the Latency, Stupid"
  - Stuart Cheshire
  - '2001'
  - ''
  - ! '<p>[Seminal essay explaining why the rollout of “broadband” home connections to replace 56k dialups had not improved regular WWW browsing as much as people expected: while broadband had greater <em>throughput</em>, it had similar (or worse) <em>latency</em>.</p><p>Because much of the wallclock time of any Internet connection is spent setting up and negotiating with the other end, and not that much is spent on the raw transfer of large numbers of bytes, the speedup is far smaller than one would expect by dividing the respective bandwidths.</p><p>Further, while bandwidth/throughput is easy to improve by adding more or higher-quality connections and can be patched elsewhere in the system by adding parallelism or upgrading parts or investing in data compression, the latency-afflicted steps are stubbornly serial, any time lost is physically impossible to retrieve, and many steps are inherently limited by the speed of light—more capacious connections quickly run into <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s law</a>, where the difficult-to-improve serial latency-bound steps dominate the overall task. As Cheshire summarizes it:]</p><ol type="1"><li>Fact One: Making more bandwidth is easy.</li><li>Fact Two: Once you have bad latency you’re stuck with it.</li><li>Fact Three: Current consumer devices have appallingly bad latency.</li><li>Fact Four: Making limited bandwidth go further is easy.</li></ol><p>…That’s the problem with communications devices today. Manufacturers say “speed” when they mean “capacity”. The other problem is that as far as the end-user is concerned, the thing they want to do is transfer large files quicker. It may seem to make sense that a high-capacity slow link might be the best thing for the job. What the end-user doesn’t see is that in order to manage that file transfer, their computer is sending dozens of little control messages back and forth. The thing that makes computer communication different from television is interactivity, and interactivity depends on all those little back-and-forth messages.</p><p>The phrase “high-capacity slow link” that I used above probably looked very odd to you. Even to me it looks odd. We’ve been used to wrong thinking for so long that correct thinking looks odd now. How can a high-capacity link be a slow link? High-capacity means fast, right? It’s odd how that’s not true in other areas. If someone talks about a “high-capacity” oil tanker, do you immediately assume it’s a very fast ship? I doubt it. If someone talks about a “large-capacity” truck, do you immediately assume it’s faster than a small sports car?</p><p>We have to start making that distinction again in communications. When someone tells us that a modem has a speed of 28.8 kbit/sec we have to remember that 28.8 kbit/sec is its capacity, not its speed. Speed is a measure of distance divided by time, and ‘bits’ is not a measure of distance.</p><p>I don’t know how communications came to be this way. Everyone knows that when you buy a hard disk you should check what its seek time is. The maximum transfer rate is something you might also be concerned with, but the seek time is definitely more important. Why does no one think to ask what a modem’s ‘seek time’ is? The latency is exactly the same thing. It’s the minimum time between asking for a piece of data and getting it, just like the seek time of a disk, and it’s just as important.</p>'
- - https://blog.chriszacharias.com/page-weight-matters
  - Page Weight Matters
  - Chris Zacharias
  - 2012-12-21
  - ''
  - ! '<p>[Google engineer recounts the results of heavily optimizing YouTube to make it usable in slow Third World Countries: in an example of <a href="https://en.wikipedia.org/wiki/Jevons_paradox">Jevons Paradox</a> &amp; <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a>, he found that despite making YouTube better for all users, average page load time got <em>worse</em>—because now Africans were actually able to use it.]</p><p>When we plotted the data geographically and compared it to our total numbers broken out by region, there was a disproportionate increase in traffic from places like Southeast Asia, South America, Africa, and even remote regions of Siberia. Further investigation revealed that, in these places, the average page load time under [the optimized version] Feather was over <strong>2 minutes</strong>! This meant that a regular video page, at over a megabyte, was taking more than <strong>20 minutes</strong> to load! This was the penalty incurred before the video stream even had a chance to show the first frame. Correspondingly, entire populations of people simply could not use YouTube because it took too long to see anything. Under Feather, despite it taking over 2 minutes to get to the first frame of video, watching a video actually became a real possibility. Over the week, word of Feather had spread in these areas and our numbers were completely skewed as a result. Large numbers of people who were previously unable to use YouTube before were suddenly able to.</p><p>Through Feather, I learned a valuable lesson about the state of the Internet throughout the rest of the world. Many of us are fortunate to live in high bandwidth regions, but there are still large portions of the world that do not. By keeping your client side code small and lightweight, you can literally open your product up to new markets.</p>'
- - https://pavelfatin.com/typing-with-pleasure/
  - "Typing with pleasure"
  - Pavel Fatin
  - 2015-12-20
  - ''
  - ! '<p>In this article I examine human- and machine aspects of typing latency (“typing lag”) and present experimental data on latency of popular text / code editors. The article is inspired by my work on implementing <a href="https://blog.jetbrains.com/idea/2015/08/experimental-zero-latency-typing-in-intellij-idea-15-eap/">“zero-latency typing”</a> in IntelliJ IDEA.</p><ol type="1"><li><p>Human side</p><p>1.1. Feedback 1.2. Motor skill 1.3. Internal model 1.4. Multisensory integration 1.5. Effects</p></li><li><p>Machine side</p><p>2.1. Input latency 2.2. Processing latency 2.3. Output latency 2.4. Total latency</p></li><li><p>Editor benchmarks</p><p>3.1. Configuration 3.2. Methodology 3.3. Windows 3.4. Linux 3.5. VirtualBox</p></li><li><p>Summary</p></li><li><p>Links</p></li></ol><p>…To measure processing delays experimentally I created <a href="https://pavelfatin.com/typometer">Typometer</a>—a tool to determine and analyze visual latency of text editors (sources). Typometer works by generating OS input events and using screen capture to measure the delay between a keystroke and a corresponding screen update. Hence, the measurement encompasses all the constituents of processing latency (i. e. OS queue, VM, editor, GPU pipeline, buffering, window manager and possible V-Sync). That is the right thing to do, because all those components are inherently intertwined with the editor, and in principle, editor application has influence on all the parts. … [He tested 9] Editors: Atom 1.1 / Eclipse 4.5.1 / Emacs 24.5.1 / Gedit 3.10.4 / GVim 7.4.712 / IntelliJ Idea CE 15.0 / Netbeans 8.1 / Notepad++ 6.8.4 / Sublime Text 3083.</p><figure><img src="/images/design/2015-fatin-typingwithpleasure-windowstexteditorlatency.png" alt="“Editor latency in MS Windows (text file) in milliseconds” (https://pavelfatin.com/images/typing/editor-latency-windows-text.png)" /><figcaption>“Editor latency in MS Windows (text file) in milliseconds”</figcaption></figure><p>Apparently, editors are not created equal (at least, from the standpoint of latency).</p>'
- - http://www.cap-lore.com/Hardware/Wheel.html
  - "The Wheel of Reincarnation"
  - Norman Hardy
  - ''
  - ''
  - ! '<p>Short technology essay based on <a href="http://cva.stanford.edu/classes/cs99s/papers/myer-sutherland-design-of-display-processors.pdf" title="On the Design of Display Processors">Myer &amp; Sutherland 1968</a> (!) discussing a perennial pattern in computing history dubbed the ‘Wheel of Reincarnation’ for how old approaches inevitably reincarnate as the exciting new thing: shifts between ‘local’ and ‘remote’ computing resources, which are exemplified by repeated cycles in graphical display technologies from dumb ‘terminals’ which display only raw pixels to smart devices which interpret more complicated inputs like text or vectors or programming languages (eg PostScript). These cycles are driven by cost, latency, architectural simplicity, and available computing power.</p><p>The Wheel of Reincarnation paradigm has played out for computers as well, in shifts from local terminals attached to mainframes to PCs to smartphones to ‘cloud computing’.</p>'
- - http://cva.stanford.edu/classes/cs99s/papers/myer-sutherland-design-of-display-processors.pdf
  - On the Design of Display Processors
  - T.H. Meyer, I.E. Sutherland
  - 1968-06
  - 10.1145/363347.363368
  - ! 'The flexibility and power needed in the channel for a computer display are considered. To work efficiently, such a channel must have a sufficient number of instruction that it is best understood as a small processor rather than a powerful channel. As it was found that successive improvements to the display processor design lie on a circular path, by making improvements one can return to the original simple design plus one new general purpose computer for each trip around. The degree of physical separation between display and parent computer is a key factor in display processor design. [Keywords: display processor design, display system, computer graphics, graphic terminal, displays, graphics, display generator, display channel, display programming, graphical interaction, remote displays, Wheel of Reincarnation]'
- - https://www.theatlantic.com/science/archive/2017/11/how-the-zombie-fungus-takes-over-ants-bodies-to-control-their-minds/545864/
  - "How the Zombie Fungus Takes Over Ants’ Bodies to Control Their Minds: The infamous parasite’s methods are more complex and more sinister than anyone suspected"
  - Ed Yong
  - 2017-11-14
  - ''
  - ! '<p>When the fungus infects a carpenter ant, it grows through the insect’s body, draining it of nutrients and hijacking its mind. Over the course of a week, it compels the ant to leave the safety of its nest and ascend a nearby plant stem. It stops the ant at a height of 25 centimeters—a zone with precisely the right temperature and humidity for the fungus to grow. It forces the ant to permanently lock its mandibles around a leaf. Eventually, it sends a long stalk through the ant’s head, growing into a bulbous capsule full of spores. And because the ant typically climbs a leaf that overhangs its colony’s foraging trails, the fungal spores rain down onto its sisters below, zombifying them in turn.</p><p>…It’s also an obsession of one David Hughes, an entomologist at Pennsylvania State University, who has been studying it for years. He wants to know exactly how this puppet master controls its puppets—and <a href="https://www.pnas.org/content/114/47/12590.full" title="&#39;Three-dimensional visualization and a deep-learning model reveal complex fungal parasite networks in behaviorally manipulated ants&#39;, Fredericksen et al 2017">his latest experiments</a> suggest that it’s even more ghoulish than it first appears.</p><p>…When the fungus first enters its host, it exists as single cells that float around the ant’s bloodstream, budding off new copies of themselves. But at some point, as Fredericksen’s images show, these single cells start working together. They connect to each other by building short tubes, of a kind that have only ever been seen before in fungi that infects plants. Hooked up in this way, they can communicate and exchange nutrients. They can also start invading the ant’s muscles, either by penetrating the muscle cells themselves or growing into the spaces between them. The result is what you can see in this video: a red muscle fiber, encircled and drained by a network of interconnected yellow fungal cells. This is something unique to Ophiocordyceps. Hughes’s team found that another parasitic fungus, which fatally infects ants but doesn’t manipulate their minds, also spreads into muscles but doesn’t form tubes between individual cells, and doesn’t wire itself into large networks.</p><p>Whenever Hughes or anyone else discusses the zombie-ant fungus, they always talk about it as a single entity, which corrupts and subverts a host. But you could also think of the fungus as a colony, much like the ants it targets. Individual microscopic cells begin life alone but eventually come to cooperate, fusing into a superorganism. Together, these brainless cells can commandeer the brain of a much larger creature. But surprisingly, they can do that without ever physically touching the brain itself. Hughes’s team found that fungal cells infiltrate the ant’s entire body, including its head, but they leave its brain untouched… “But manipulation of ants by <em>Ophiocordyceps</em> is so exquisitely precise that it is perhaps surprising that the fungus doesn’t invade the brain of its host,” Weinersmith says.</p>'
- - https://www.pnas.org/content/110/2/696.full
  - Eight pairs of descending visual neurons in the dragonfly give wing motor centers accurate population vector of prey direction
  - Paloma T. Gonzalez-Bellido, Hanchuan Peng, Jinzhu Yang, Apostolos P. Georgopoulos, Robert M. Olberg
  - 2013-01-08
  - 10.1073/pnas.1210489109
  - ! 'Intercepting a moving object requires prediction of its future location. This complex task has been solved by dragonflies, who intercept their prey in midair with a 95% success rate. In this study, we show that a group of 16 neurons, called target-selective descending neurons (TSDNs), code a population vector that reflects the direction of the target with high accuracy and reliability across 360°. The TSDN spatial (receptive field) and temporal (latency) properties matched the area of the retina where the prey is focused and the reaction time, respectively, during predatory flights. The directional tuning curves and morphological traits (3D tracings) for each TSDN type were consistent among animals, but spike rates were not. Our results emphasize that a successful neural circuit for target tracking and interception can be achieved with few neurons and that in dragonflies this information is relayed from the brain to the wing motor centers in population vector form. [Keywords: vision, invertebrate, predatory behavior, electrophysiology, confocal microscopy]'
- - http://paradise.caltech.edu/cook/papers/TwoNeurons.pdf
  - It Takes Two Neurons To Ride a Bicycle
  - Matthew Cook
  - '2004'
  - ''
  - ! 'Past attempts to get computers to ride bicycles have required an inordinate amount of learning time (1700 practice rides for a reinforcement learning approach [1], while still failing to be able to ride in a straight line), or have required an algebraic analysis of the exact equations of motion for the specific bicycle to be controlled [2, 3]. Mysteriously, humans do not need to do either of these when learning to ride a bicycle. Here we present a two-neuron network<sup>1</sup> that can ride a bicycle in a desired direction (for example, towards a desired goal or along a desired path), which may be chosen or changed at run time. Just as when a person rides a bicycle, the network is very accurate for long range goals, but in the short run stability issues dominate the behavior. This happens not by explicit design, but arises as a natural consequence of how the network controls the bicycle.'
- - /docs/genetics/selection/2019-delguidice.pdf
  - "Invisible Designers: Brain Evolution Through the Lens of Parasite Manipulation"
  - Marco Del Giudice
  - 2019-09
  - 10.1086/705038
  - ! 'The ability of parasites to manipulate host behavior to their advantage has been studied extensively, but the impact of parasite manipulation on the evolution of neural and endocrine mechanisms has remained virtually unexplored. If selection for countermeasures has shaped the evolution of nervous systems, many aspects of neural functioning are likely to remain poorly understood until parasites—the brain’s invisible designers—are included in the picture. This article offers the first systematic discussion of brain evolution in light of parasite manipulation. After reviewing the strategies and mechanisms employed by parasites, the paper presents a taxonomy of host countermeasures with four main categories, namely: restrict access to the brain; increase the costs of manipulation; increase the complexity of signals; and increase robustness. For each category, possible examples of countermeasures are explored, and the likely evolutionary responses by parasites are considered. The article then discusses the metabolic, computational, and ecological constraints that limit the evolution of countermeasures. The final sections offer suggestions for future research and consider some implications for basic neuroscience and psychopharmacology. The paper aims to present a novel perspective on brain evolution, chart a provisional way forward, and stimulate research across the relevant disciplines. [Keywords: behavior, brain evolution, hormones, neurobiology, parasite-host interactions, parasite manipulation.]'
- - https://www.scottaaronson.com/papers/pnp.pdf#page=5
  - "P≟NP"
  - Scott Aaronson
  - '2017'
  - '10.1007/978-3-319-32162-2_1'
  - ! 'In 1955, John Nash sent a remarkable letter to the National Security Agency, in which—seeking to build theoretical foundations for cryptography—he all but formulated what today we call the P≟NP problem, considered one of the great open problems of science. Here I survey the status of this problem in 2017, for a broad audience of mathematicians, scientists,and engineers. I offer a personal perspective on what it’s about, why it’s important, why it’s reasonable to conjecture that P≠NP is both true and provable, why proving it is so hard, the landscape of related problems, and crucially, what progress has been made in the last half-century toward solving those problems. The discussion of progress includes diagonalization and circuit lower bounds; the relativization, algebrization, and natural proofs barriers; and the recent works of Ryan Williams and Ketan Mulmuley, which (in different ways) hint at a duality between impossibility proofs and algorithms. [2017 revised version of 2016 paper.]'
- - https://scale.com/
  - "Scale: The Data Platform for AI; High quality training and validation data for AI applications"
  - Scale AI, Inc.
  - ''
  - ''
  - ! '<p>["Scale is an API for training data, providing access to human-powered data for a multitude of use cases located in San Francisco, California, United States; founded 2016-06-01. Scale accelerates the development of AI applications by helping computer vision teams generate high-quality ground truth data. Our advanced LiDAR, video, and image annotation APIs allow self-driving, drone, and robotics teams at companies like Waymo, OpenAI, Lyft, Zoox, Pinterest, and Airbnb focus on building differentiated models vs. labeling data."]</p> <p>["Scale has around 100 employees, according to Wang, but its limited full-time staff is a small fraction of the human-power behind the services Scale offers. The startup has nearly 30,000 contractors aiding in the labeling process. “The humans are pretty critical to what we’re doing because they’re there to make sure that all the data we provide is really high quality,” Wang says.</p><p>Companies provide Scale with data via their API and the startup puts its resources to work labeling the text, audio, pictures and video so that its customers’ machine learning models can be trained. The startup’s customers include Waymo, OpenAI, Airbnb and Lyft.</p><p>For a customer working with autonomous driving data, Scale’s services may mean taking collected video frames and manually segmenting out individual cars, humans or other obstacles. For another customer, it can mean making common sense language connections to ensure natural language processing models can understand language in context. The “human insight” can help minimize labeling bias and give customers data that is more precise and more accurate, though, as with just about all AI startups, the hope is that these insights will gradually usher in a future where reliance on these humans-in-the-loop will be lessened. In the meantime, Scale sits atop an army of contractors that might hold the key to bulking up Silicon Valley’s machine learning intelligence."]</p>'
- - https://openai.com/blog/fine-tuning-gpt-2/
  - "Fine-Tuning GPT-2 from Human Preferences"
  - Daniel Ziegler, Nisan Stiennon, Jeffrey Wu, Tom Brown, Dario Amodei, Alec Radford, Paul Christiano, Geoffrey Irving (OpenAI)
  - 2019-09-19
  - ''
  - ! '<p>We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of “machines talking to humans,” which we believe is key to extracting information about human values.</p><p>This work applies human preference learning to several natural language tasks: continuing text with positive sentiment or physically descriptive language using the BookCorpus, and summarizing content from the TL;DR and CNN/Daily Mail datasets. Each of these tasks can be viewed as a text completion problem: starting with some text X, we ask what text Y should follow. [For summarization, the text is the article plus the string “TL;DR:”.]</p><p>We start with a pretrained language model (the 774M parameter version of GPT-2) and fine-tune the model by asking human labelers which of four samples is best. Fine-tuning for the stylistic continuation tasks is sample efficient: 5,000 human samples suffice for strong performance according to humans. For summarization, models trained with 60,000 comparisons learn to copy whole sentences from the input while skipping irrelevant preamble; this copying is an easy way to ensure accurate summaries, but may exploit the fact that labelers rely on simple heuristics.</p><p><em>Bugs can optimize for bad behavior</em></p><p>One of our code refactors introduced a bug which flipped the sign of the reward. Flipping the reward would usually produce incoherent text, but the same bug also flipped the sign of the KL penalty. The result was a model which optimized for negative sentiment while preserving natural language. Since our instructions told humans to give very low ratings to continuations with sexually explicit text, the model quickly learned to output only content of this form. This bug was remarkable since the result was not gibberish but maximally bad output. The authors were asleep during the training process, so the problem was noticed only once training had finished. A mechanism such as Toyota’s Andon cord could have prevented this, by allowing any labeler to stop a problematic training process.</p><p><strong>Looking forward</strong></p><p>We’ve demonstrated reward learning from human preferences on two kinds of natural language tasks, stylistic continuation and summarization. Our results are mixed: for continuation we achieve good results with very few samples, but our summarization models are only “smart copiers”: they copy from the input text but skip over irrelevant preamble. The advantage of smart copying is truthfulness: the zero-shot and supervised models produce natural, plausible-looking summaries that are often lies. We believe the limiting factor in our experiments is data quality exacerbated by the online data collection setting, and plan to use batched data collection in the future.</p><p>We believe the application of reward learning to language is important both from a capability and safety perspective. On the capability side, reinforcement learning lets us correct mistakes that supervised learning would not catch, but RL with programmatic reward functions “can be detrimental to model quality.” On the safety side, reward learning for language allows important criteria like “don’t lie” to be represented during training, and is a step towards scalable safety methods such as a debate and amplification.</p>'
- - https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/
  - Learning from Human Preferences
  - Dario Amodei, Paul Christiano, Alex Ray (OpenAI)
  - 2017-06-13
  - ''
  - ! '<p>One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.</p><p>We present a learning algorithm that uses small amounts of human feedback to solve modern RL environments. Machine learning systems with human feedback have been explored before, but we’ve scaled up the approach to be able to work on much more complicated tasks. Our algorithm needed 900 bits of feedback from a human evaluator to learn to backflip—a seemingly simple task which is simple to judge but challenging to specify.</p><p>The overall training process is a 3-step feedback cycle between the human, the agent’s understanding of the goal, and the RL training.</p><figure><img src="/images/rl/2017-amodei-openai-learningfromhumanpreferences-architecture2x-2x.png" alt="Preference learning architecture (https://openai.com/content/images/2017/06/diagram@2x-2.png)" /><figcaption>Preference learning architecture</figcaption></figure><p>Our AI agent starts by acting randomly in the environment. Periodically, two video clips of its behavior are given to a human, and the human decides which of the two clips is closest to fulfilling its goal—in this case, a backflip. The AI gradually builds a model of the goal of the task by finding the reward function that best explains the human’s judgments. It then uses RL to learn how to achieve that goal. As its behavior improves, it continues to ask for human feedback on trajectory pairs where it’s most uncertain about which is better, and further refines its understanding of the goal.</p>'
- - https://deepmind.com/blog/article/learning-through-human-feedback
  - Learning through human feedback
  - Jan Leike, Miljan Martic, Shane Legg (DeepMind)
  - 2017-06-12
  - ''
  - ! '<p>The system—described in our paper “Deep Reinforcement Learning from Human Preferences”—departs from classic RL systems by training the agent from a neural network known as the ‘reward predictor’, rather than rewards it collects as it explores an environment.</p><p>It consists of three processes running in parallel:</p><ol type="1"><li>A reinforcement learning agent explores and interacts with its environment, such as an Atari game.</li><li>Periodically, a pair of 1–2 second clips of its behaviour is sent to a human operator, who is asked to select which one best shows steps towards fulfilling the desired goal.</li><li>The human’s choice is used to train a reward predictor, which in turn trains the agent. Over time, the agent learns to maximise the reward from the predictor and improve its behaviour in line with the human’s preferences.</li></ol><p>The system separates learning the goal from learning the behaviour to achieve it</p><p>This iterative approach to learning means that a human can spot and correct any undesired behaviours, a crucial part of any safety system. The design also does not put an onerous burden on the human operator, who only has to review around 0.1% of the agent’s behaviour to get it to do what they want. However, this can mean reviewing several hundred to several thousand pairs of clips, something that will need to be reduced to make it applicable to real world problems.</p>'
- - /Tea#water-experiment
  - "Tea/Water Experiment: Blinded Randomized Racing-Arms Experiment of Mineral Water Taste"
  - Gwern Branwen
  - 2017-04-04
  - ''
  - ! '<p>The kind of water used in tea is claimed to make a difference in the flavor: mineral water being better than tap water or distilled water. However, mineral water is vastly more expensive than tap water. To test the claim, I run a preliminary test of pure water to see if any water differences are detectable at all. Compared my tap water, 3 distilled water brands (Great Value, Nestle Pure Life, &amp; Poland Spring), 1 osmosis-purified brand (Aquafina), and 3 non-carbonated mineral water brands (Evian, Voss, &amp; Fiji) in a series of <em>n</em>=67 blinded randomized comparisons of water flavor. The comparisons are modeled using a Bradley-Terry competitive model implemented in Stan; comparisons were chosen using an adaptive Bayesian best-arm sequential trial (racing) method designed to locate the best-tasting water in the minimum number of samples by preferentially comparing the best-known arm to potentially superior arms. Blinding &amp; randomization are achieved by using a Lazy Susan to physically randomize two identical (but marked in a hidden spot) cups of water. The final posterior distribution indicates that some differences between waters are likely to exist but are small &amp; imprecisely estimated and of little practical concern.</p>'
- - /GPT-2-music#spaceless-model
  - "GPT-2 Folk Music: Training a Spaceless Model"
  - Gwern Branwen
  - 2019-12-12
  - ''
  - ! 'While training a GPT-2-117M on a folk music corpus written in ABC format, persistent syntax errors kept being generated by an otherwise-high-quality model: random spaces would be generated, rendering a music piece either erroneous or lower-quality. Why? It seems to be some issue with the GPT BPE encoder handling of spaces which makes it difficult to emit the right space-separated characters. We found that ABC does not actually require spaces, and we simply removed all spaces from the corpus—noticeably improving quality of generated pieces.'
- - /Faces#discriminator-ranking
  - "Generating Anime Faces with StyleGAN: Using a trained Discriminator to Rank and Clean Data"
  - Gwern Branwen
  - 2019-04-22
  - ''
  - ! 'The Discriminator of a GAN is trained to detect outliers or bad datapoints. So it can be used for cleaning the original dataset of aberrant samples. This works reasonably well and I obtained BigGAN/StyleGAN quality improvements by manually deleting the worst samples (typically badly-cropped or low-quality faces), but has peculiar behavior which indicates that the Discriminator is not learning anything equivalent to a "quality" score but may be doing some form of <em>memorization</em> of specific real datapoints. What does this mean for how GANs work?'
- - /docs/statistics/order/1964-mardia.pdf
  - Asymptotic Independence of Bivariate Extremes
  - K. V. Mardia
  - 1964-11-01
  - 10.1177/0008068319640305
  - ! '<p>Sibuya (1960) has given a necessary and sufficient condition for asymptotic independence of two extremes for a sample from bivariate population. We shall obtain such a condition for asymptotic independence of all the four extremes <em>X</em>, <em>X’</em>, <em>Y</em> and <em>Y’</em>. It assumes a very simple form when <em>f(x,y)</em> is symmetrical in <em>x</em> and <em>y</em>, and the marginal p. d. f. of <em>x</em> and <em>y</em> have the same form. Under these conditions on the p. d. f., a modification is possible in the condition given by Sibuya (1960) which reduces to one given by Watson (1954) for other purpose. It is further shown that extremes for samples from bivariate normal population satisfy our condition if <em>|p|</em> &lt; 1, where <em>p</em> is the population correlation coefficient. Geffroy (1958) and Sibuya (1960} have proved a particular result for asymptotic independence of only two extremes <em>X</em> and <em>Y</em> in the normal case.</p>'
- - https://gantdaily.com/2019/12/11/former-area-physician-charged-with-forging-prescriptions-sent-to-ard/
  - "Former Area Physician Charged with Forging Prescriptions Sent to ARD"
  -  Julie Rae Rickard (GANT Daily)
  - 2019-12-11
  - ''
  - ! '<p>A former area physician charged with forging prescriptions was placed into a special program Monday. John Sylvester O’Shea, 69, of Washington, D.C. was charged by the attorney general’s office with procuring for self/other drug by fraud, identity theft and forgery, all misdemeanors, in July after a tip from a DuBois pharmacist led to an investigation into his prescriptions. According to the affidavit of probable cause, O’Shea was receiving prescriptions for Modafinil and Armodafinil from doctors in DuBois, Washington, D.C., and Raleigh, N.C., as well as others.</p><p>…In his interview with police, O’Shea explained he was taking the drugs because of his shift work. He stated he knew the maximum dosage for the drugs was 200 mg for the Modafinil and 250 mg for the Armodafinil per day. O’Shea admitted he was taking approximately 800 mg per day or three to four pills per shift since he had built up a tolerance to the drugs. He reportedly admitted he was “doctor shopping” and the other doctors did not know about his other prescriptions. He said his need for the drug “got out of hand.”</p><p>On Monday President Judge Fredric J. Ammerman placed O’Shea into the accelerated rehabilitative disposition program, which is for first-time offenders. He must serve two years ARD probation and was ordered to complete drug and alcohol counseling. He will not be able to prescribe any drugs for this time period and he is not to be practicing medicine for one year. O’Shea’s attorney noted that O’Shea’s medical license has been suspended and he is on a drug monitoring program already in his home area.</p>'
- - 'https://www.cell.com/cell-reports/fulltext/S2211-1247(19)31571-2'
  - Functional Oocytes Derived from Granulosa Cells
  - Chenglei Tian, Linlin Liu, Xiaoying Ye, Haifeng Fu, Xiaoyan Sheng, Lingling Wang, Huasong Wang, Dai Heng, Lin Liu
  - 2019-12-24
  - 10.1016/j.celrep.2019.11.080
  - ! '<ul><li>Granulosa cells can be reprogrammed to form oocytes by chemical reprogramming</li><li>Rock inhibition and crotonic acid facilitate the chemical induction of gPSCs from GCs</li><li>PGCLCs derived from gPSCs exhibit longer telomeres and high genomic stability</li></ul><p>The generation of genomically stable and functional oocytes has great potential for preserving fertility and restoring ovarian function. It remains elusive whether functional oocytes can be generated from adult female somatic cells through reprogramming to germline-competent pluripotent stem cells (gPSCs) by chemical treatment alone. Here, we show that somatic granulosa cells isolated from adult mouse ovaries can be robustly induced to generate gPSCs by a purely chemical approach, with additional Rock inhibition and critical reprogramming facilitated by crotonic sodium or acid. These gPSCs acquired high germline competency and could consistently be directed to differentiate into primordial-germ-cell-like cells and form functional oocytes that produce fertile mice. Moreover, gPSCs promoted by crotonylation and the derived germ cells exhibited longer telomeres and high genomic stability like PGCs in vivo, providing additional evidence supporting the safety and effectiveness of chemical induction, which is particularly important for germ cells in genetic inheritance. [Keywords: chemical reprogramming, pluripotent stem cell, oocyte, granulosa cell]</p>'
- - https://phys.org/news/2019-12-mouse-pups-born-eggs-derived.html
  - Mouse pups born from eggs derived from the granulosa cells that surround oocytes
  - Cell Press
  - 2019-12-24
  - ''
  - ! '<p>Ovarian follicles are the basic functional unit of the ovary and consist of an oocyte, the immature egg, which is surrounded by granulosa cells. Besides being crucial to the development of follicles, studies have shown that granulosa cells possess plasticity that shows stem cell-like properties.</p><p>“The thing about in vitro fertilization is that they only use the oocyte for the procedure,” says senior author Lin Liu, of the College of Life Sciences at Nankai University. “After the egg retrieval, the granulosa cells in the follicle are discarded. It got us thinking, what if we can utilize these granulosa cells? Since every egg has thousands of granulosa cells surrounding it, if we can induce them into pluripotent cells and turn those cells into oocytes, aren’t we killing two birds with one stone?”</p><p>Granulosa cells tend to undergo cell death and differentiation once removed from the follicles. Liu and his team including Ph.D. students Chenglei Tian and Haifeng Fu developed a chemical “cocktail” with Rock inhibitor and crotonic acid for creating chemically induced pluripotent stem cells (CiPSCs) from granulosa cells. The research team introduced Rock inhibitor to prevent cell death and promote proliferation. In combination with other important small chemicals, crotonic acid facilitates the induction of granulosa cells into germline-competent pluripotent stem cells that exhibit pluripotency similar to embryonic stem cells.</p>'
- - http://web.maths.unsw.edu.au/~jim/wrongthoughts.html
  - "What is Wrong with Our Thoughts? A Neo-Positivist Credo [ch7, <em>The Plato Cult and Other Philosophical Follies</em>]"
  - '<a href="https://en.wikipedia.org/wiki/David_Stove">David Stove</a>'
  - '1991'
  - ''
  - ! '[Fierce but witty critique of philosophy throughout the ages and defense of Logical Positivism, with Christian theology, Neoplatonism, and German Idealism as examples. Logical Positivists took the easy way out: the problem with these philosophies is not that they are gibberish or meaningless, because at least then they would all be wrong in the same way and could perhaps be refuted in the same way, but that they each are wrong in a myriad of different ways, ways for which we have no existing "fallacy" defined, entire universes of new errors---undermining the hope of using reason or philosophy to make any kind of progress. What is wrong with philosophy, and ourselves, if we cannot even explain why these are so badly wrong after millennia of thought and debate?]'
- - /docs/statistics/bias/2019-kvarven.pdf
  - "Comparing meta-analyses and preregistered multiple-laboratory replication projects"
  - Amanda Kvarven, Eirik Strømland, Magnus Johannesson
  - 2019-12-23
  - 10.1038/s41562-019-0787-z
  - ! 'Many researchers rely on meta-analysis to summarize research evidence. However, there is a concern that publication bias and selective reporting may lead to biased meta-analytic effect sizes. We compare the results of meta-analyses to large-scale preregistered replications in psychology carried out at multiple laboratories. The multiple-laboratory replications provide precisely estimated effect sizes that do not suffer from publication bias or selective reporting. We searched the literature and identified 15 meta-analyses on the same topics as multiple-laboratory replications. We find that meta-analytic effect sizes are significantly different from replication effect sizes for 12 out of the 15 meta-replication pairs. These differences are systematic and, on average, meta-analytic effect sizes are almost 3 times as large as replication effect sizes. We also implement 3 methods of correcting meta-analysis for bias, but these methods do not substantively improve the meta-analytic results.'
- - http://buttersafe.com/2012/05/24/the-floppy-toast/
  - "The Floppy Toast"
  - Buttersafe
  - 2012-04-24
  - ''
  - ! '<p><strong>The Floppy Toast</strong></p><p>The morning started off the way that every morning did<br />A small meal and cup of joe to perk up drooping lids.<br /><br />But when it came to making toast,<br />Today was not a copy.<br />Even after it emerged,<br />The toast was hella floppy.<br /><br />He tried and tried to make the toast<br />Become what it should be,<br />Yet every time the timer stopped<br />It popped up floppily.<br /><br />He simply couldn’t understand this strange phenomenon,<br />And so he tried to get some facts by calling up his mom.<br /><br />“That’s stupid weird,” his mother offered, somewhat groggily.<br />“But you’re a grown up dude. Why don’t you solve this without me?”<br /><br />So he decided he would take<br />His toast into the doctor,<br />Who hopefully would find a way<br />To make it much less softer.<br /><br />“Though floppy human body parts<br />Can be firmed up with pills,<br />Alas your loaf’s not stricken with<br />Those special types of ills.”<br /><br />“It seems your toast must have been cursed,<br />By magics dark and bleak,<br />And so a magic answer to your problems<br />You must seek.”<br /><br />“Mt. Crazy-Hot is home to dangers<br />Quite antagonistic,<br />But at the summit lives a very helpful<br />Wise old mystic.”<br /><br />What choice had he except to scale this ancient no man’s land?<br />His breakfast problems had already gotten out of hand.<br /><br />He tucked away his floppy toast,<br />And started on his way.<br />His muscles burned first from the climb,<br />And then burned from the flames.<br /><br />With every step the fires licked<br />His body up and down<br />Which frankly did not nearly feel<br />As sexy as it sounds.<br /><br />And then from the inferno rose a creature of the deep<br />Who did not seem too happy to be woken from its sleep.<br /><br />Long time the manxome foe he pondered, brewing strategy<br />Until the monster chose to force his hand more rapidly.<br /><br />An incendiary breath is<br />Quite the motivator,<br />To run like hell and save your clever<br />Plans for some point later.<br /><br />And so he ran and ran and ran<br />And ran and ran and ran<br />And ran and ran and ran and ran<br />Then ran into a man.<br /><br />“You must be the mystic with the culinary talents!<br />You’ve got to help me sir! My morning toast hangs in the balance!”<br /><br />“No matter how I tried,<br />Its floppiness was unimpeded.<br />Were my methods lacking something<br />That was absolutely needed?”<br /><br />“Though I am wise, perhaps the one with answers here is you.<br />Look upon your meal again, you may see something new.”<br /><br />And lo, he did produce it<br />For his enigmatic host<br />But no longer was it floppy!<br />’Twas the perfect piece of toast!<br /><br />The oils he secreted from his skin<br />Amidst the climb<br />Had soaked into the slice<br />As if a butter most divine!<br /><br />And after in that butter<br />It had practically been drowned<br />The scorching flames transformed it<br />To a crispy, golden brown!<br /><br />“Perfection comes through hardship,<br />A truth hidden from my eyes.<br />This cursed toast revealed it.<br />’Twas a blessing in disguise!<br /><br />Despite the difficulties,<br />Through my journey I stayed strong.<br />It seems that the perfect toast<br />Was inside me all along!”<br /><br />“I’m glad this less has awakened<br />Wisdom from within.<br />And next time you can simply think<br />To plug the toaster in.”</p>'
- - https://blog.aboutamazon.com/company-news/2016-letter-to-shareholders
  - "2016 Letter to Shareholders"
  - Jeff Bezos (Amazon)
  - 2017-04-17
  - ''
  - ! '<p>“Jeff, what does Day 2 look like?” That’s a question I just got at our most recent all-hands meeting. I’ve been reminding people that it’s Day 1 for a couple of decades. I work in an Amazon building named Day 1, and when I moved buildings, I took the name with me. I spend time thinking about this topic. “Day 2 is stasis. Followed by irrelevance. Followed by excruciating, painful decline. Followed by death. And <em>that</em> is why it is <em>always</em> Day 1.”</p><p>To be sure, this kind of decline would happen in extreme slow motion. An established company might harvest Day 2 for decades, but the final result would still come. I’m interested in the question, how do you fend off Day 2? What are the techniques and tactics? How do you keep the vitality of Day 1, even inside a large organization?</p><ol type="1"><li><p>True Customer Obsession …</p></li><li><p>Resist Proxies …</p></li><li><p>Embrace External Trends …</p></li><li><p>High-Velocity Decision Making</p><ol type="1"><li><p>…First, never use a one-size-fits-all decision-making process. Many decisions are reversible, two-way doors. Those decisions can use a light-weight process. For those, so what if you’re wrong? I wrote about this in more detail in last year’s letter.</p></li><li><p>Second, most decisions should probably be made with somewhere around 70% of the information you wish you had. If you wait for 90%, in most cases, you’re probably being slow. Plus, either way, you need to be good at quickly recognizing and correcting bad decisions. If you’re good at course correcting, being wrong may be less costly than you think, whereas being slow is going to be expensive for sure.</p></li><li><p>Third, use the phrase “disagree and commit.” This phrase will save a lot of time. If you have conviction on a particular direction even though there’s no consensus, it’s helpful to say, “Look, I know we disagree on this but will you gamble with me on it? Disagree and commit?” By the time you’re at this point, no one can know the answer for sure, and you’ll probably get a quick yes.</p><p>This isn’t one way. If you’re the boss, you should do this too. I disagree and commit all the time. We recently greenlit a particular Amazon Studios original. I told the team my view: debatable whether it would be interesting enough, complicated to produce, the business terms aren’t that good, and we have lots of other opportunities. They had a completely different opinion and wanted to go ahead. I wrote back right away with “I disagree and commit and hope it becomes the most watched thing we’ve ever made.” Consider how much slower this decision cycle would have been if the team had actually had to <em>convince</em> me rather than simply get my commitment.</p><p>Note what this example is not: it’s not me thinking to myself “well, these guys are wrong and missing the point, but this isn’t worth me chasing.” It’s a genuine disagreement of opinion, a candid expression of my view, a chance for the team to weigh my view, and a quick, sincere commitment to go their way. And given that this team has already brought home 11 Emmys, 6 Golden Globes, and 3 Oscars, I’m just glad they let me in the room at all!</p></li></ol></li></ol>'
- - /docs/statistics/2014-copss-pastpresentfuturestatistics.pdf
  - Past, Present, and Future of Statistical Science
  - Xihong Lin, Christian Genest, David L. Banks, Geert Molenberghs, David W. Scott, Jane-Ling Wang
  - 2014-03-26
  - 10.1201/b16720
  - ! '<p><em>Past, Present, and Future of Statistical Science</em> was commissioned in 2013 by the Committee of Presidents of Statistical Societies (COPSS) to celebrate its 50<sup>th</sup> anniversary and the International Year of Statistics. COPSS consists of five charter member statistical societies in North America and is best known for sponsoring prestigious awards in statistics, such as the COPSS Presidents’ award. Through the contributions of a distinguished group of 50 statisticians who are past winners of at least one of the five awards sponsored by COPSS, this volume showcases the breadth and vibrancy of statistics, describes current challenges and new opportunities, highlights the exciting future of statistical science, and provides guidance to future generations of statisticians. The book is not only about statistics and science but also about people and their passion for discovery. Distinguished authors present expository articles on a broad spectrum of topics in statistical education, research, and applications. Topics covered include reminiscences and personal reflections on statistical careers, perspectives on the field and profession, thoughts on the discipline and the future of statistical science, and advice for young statisticians. Many of the articles are accessible not only to professional statisticians and graduate students but also to undergraduate students interested in pursuing statistics as a career and to all those who use statistics in solving real-world problems. A consistent theme of all the articles is the passion for statistics enthusiastically shared by the authors. Their success stories inspire, give a sense of statistics as a discipline, and provide a taste of the exhilaration of discovery, success, and professional accomplishment.</p><blockquote><p>“This collection of reminiscences, musings on the state of the art, and advice for young statisticians makes for compelling reading. There are 52 contributions from eminent statisticians who have won a Committee of Presidents of Statistical Societies award. Each is a short, focused chapter and so one could even say this is ideal bedtime (or coffee break) reading. Anyone interested in the history of statistics will know that much has been written about the early days but little about the field since the Second World War. This book goes some way to redress this and is all the more valuable for coming from the horse’s mouth…the closing chapter, the shortest of all, from Brad Efron: a list of”thirteen rules for giving a really bad talk“. This made me laugh out loud and should be posted on the walls of all conferences. I shall leave the final word to Peter Bickel:”We should glory in this time when statistical thinking pervades almost every field of endeavor. It is really a lot of fun."</p><p>―Robert Grant, in <em>Significance</em>, April 2017</p></blockquote><p><strong>The History of COPSS</strong>: “A brief history of the Committee of Presidents of Statistical Societies (COPSS)”, Ingram Olkin</p><p><strong>Reminiscences and Personal Reflections on Career Paths</strong></p><p>“Reminiscences of the Columbia University Department of Mathematical Statistics in the late 1940s”, Ingram Olkin·“A career in statistics”, Herman Chernoff·“. . . how wonderful the field of statistics is . . .”, David R. Brillinger·“An unorthodox journey to statistics: Equity issues, remarks on multiplicity”, Juliet Popper Shaffer·“Statistics before and after my COPSS Prize”, Peter J. Bickel·“The accidental biostatistics professor”, Donna Brogan·“Developing a passion for statistics”, Bruce G. Lindsay·“Reflections on a statistical career and their implications”, R. Dennis Cook·“Science mixes it up with statistics”, Kathryn Roeder·“Lessons from a twisted career path”, Jeffrey S. Rosenthal·“Promoting equity”, Mary Gray</p><p><strong>Perspectives on the Field and Profession</strong></p><p>“Statistics in service to the nation”, Stephen E. Fienberg·“Where are the majors?”, Iain M. Johnstone·“We live in exciting times”, Peter Hall·“The bright future of applied statistics”, Rafael A. Irizarry·“The road travelled: From a statistician to a statistical scientist”, Nilanjan Chatterjee·“Reflections on a journey into statistical genetics and genomics”, Xihong Lin·“Reflections on women in statistics in Canada”, Mary E. Thompson·“The whole women thing”, Nancy Reid·“Reflections on diversity”, Louise Ryan</p><p><strong>Reflections on the Discipline</strong></p><p>“Why does statistics have two theories?”, Donald A.S. Fraser·“Conditioning is the issue”, James O. Berger·“Statistical inference from a Dempster–Shafer perspective”, Arthur P. Dempster·“Nonparametric Bayes”, David B. Dunson·“How do we choose our default methods?”, Andrew Gelman·“Serial correlation and Durbin–Watson bounds”, T.W. Anderson·“A non-asymptotic walk in probability and statistics”, Pascal Massart·“The past’s future is now: What will the present’s future bring?”, Lynne Billard·“Lessons in biostatistics”, Norman E. Breslow·“A vignette of discovery”, Nancy Flournoy·“Statistics and public health research”, Ross L. Prentice·“Statistics in a new era for finance and health care”, Tze Leung Lai·“Meta-analyses: Heterogeneity can be a good thing”, Nan M. Laird·“Good health: Statistical challenges in personalizing disease prevention”, Alice S. Whittemore·“Buried treasures”, Michael A. Newton·“Survey sampling: Past controversies, current orthodoxy, future paradigms”, Roderick J.A. Little·“Environmental informatics: Uncertainty quantification in the environmental sciences”, Noel A. Cressie·“A journey with statistical genetics”, Elizabeth Thompson·“Targeted learning: From MLE to TMLE”, Mark van der Laan·“Statistical model building, machine learning, and the ah-ha moment”, Grace Wahba·“In praise of sparsity and convexity”, Robert J. Tibshirani·“Features of Big Data and sparsest solution in high confidence set”, Jianqing Fan·“Rise of the machines”, Larry A. Wasserman·“A trio of inference problems that could win you a Nobel Prize in statistics (if you help fund it)”, Xiao-Li Meng</p><p><strong>Advice for the Next Generation</strong></p><p>“Inspiration, aspiration, ambition”, C.F. Jeff Wu·“Personal reflections on the COPSS Presidents’ Award”, Raymond J. Carroll·“Publishing without perishing and other career advice”, Marie Davidian·“Converting rejections into positive stimuli”, Donald B. Rubin·“The importance of mentors”, Donald B. Rubin·“Never ask for or give advice, make mistakes, accept mediocrity, enthuse”, Terry Speed·“Thirteen rules”, Bradley Efron</p>'
- - https://www.discovermagazine.com/planet-earth/freedom-from-fungus-why-dont-humans-have-chestnut-style-blights-and-white-nose-style-syndromes
  - "Freedom From Fungus: Why Don't Humans Have Chestnut-Style Blights and White Nose-Style Syndromes?"
  - Sarah Zhang (Discover)
  - 2012-05-16
  - ''
  - ! '[Fungi are some of the most common organisms around, prolific, hardy, and fungal infections are major causes of infection-related mortality in plants and reptiles and can infect and kill almost anything, but <em>mammals</em> usually die of bacteria/viruses/parasites. Dying of a fungus is rare, and we hardly even get fungal infections except in odd places like our extremities (eg toes), or odd times of life like when bats hibernate. Why? Perhaps because we are warm-blooded, so our body heat is fatal to fungi. This explains why extremities or hibernating bats are vulnerable (colder). And perhaps this even played a role in the extinction of the dinosaurs and triumph of mammals?]'
- - https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/
  - "Guide To Using Reverse Image Search For Investigations"
  - Aric Toller (Bellingcat)
  - 2019-12-26
  - ''
  - ! '<p>…if you only use Google for reverse image searching, you will be disappointed more often than not. Limiting your search process to uploading a photograph in its original form to just images.google.com may give you useful results for the most obviously stolen or popular images, but for most any sophisticated research project, you need additional sites at your disposal—along with a lot of creativity.</p><p>This guide will walk through detailed strategies to use reverse image search in digital investigations, with an eye towards identifying people and locations, along with determining an image’s progeny. After detailing the core differences between the search engines, Yandex, Bing, and Google are tested on five test images showing different objects and from various regions of the world.</p><p>…Reverse image search engines have progressed dramatically over the past decade, with no end in sight. Along with the ever-growing amount of indexed material, a number of search giants have enticed their users to sign up for image hosting services, such as <a href="https://www.theringer.com/2017/5/25/16043842/google-photos-data-collection-e8578b3256e0">Google Photos</a>, giving these search algorithms an endless amount of material for machine learning. On top of this, facial recognition AI is entering the consumer space with products like <a href="https://findclone.ru/">FindClone</a> and may already be used in some search algorithms, namely with Yandex. There are no publicly available facial recognition programs that use any Western social network, such as Facebook or Instagram, but perhaps it is only a matter of time until something like this emerges, dealing a major blow to online privacy while also (at that great cost) increasing digital research functionality.</p><p>If you skipped most of the article and are just looking for the bottom line, here are some easy-to-digest tips for reverse image searching:</p><ul><li>Use <strong>Yandex</strong> first, second, and third, and then try <strong>Bing</strong> and <strong>Google</strong> if you still can’t find your desired result.</li><li>If you are working with source imagery that is <strong>not from a Western or former Soviet country</strong>, then you may not have much luck. These search engines are hyper-focused on these areas, and struggle for photographs taken in South America, Central America/Caribbean, Africa, and much of Asia.</li><li><strong>Increase the resolution</strong> of your source image, even if it just means doubling or tripling the resolution until it’s a pixelated mess. None of these search engines can do much with an image that is under 200×200.</li><li>Try <strong>cropping out</strong> elements of the image, or <strong>pixelating</strong> them if it trips up your results. Most of these search engines will focus on people and their faces like a heat-seeking missile, so pixelate them to focus on the background elements.</li><li>If all else fails, get really creative: <strong>mirror</strong> your image horizontally, add some color <strong>filters</strong>, or use the <strong>clone</strong> <strong>tool</strong> on your image editor to fill in elements on your image that are disrupting searches.</li></ul>'
- - https://www.nature.com/articles/s41467-019-13549-9
  - A 5700 year-old human genome and oral microbiome from chewed birch pitch
  - Theis Z. T. Jensen, Jonas Niemann, Katrine Højholt Iversen, Anna K. Fotakis, Shyam Gopalakrishnan, Åshild J. Vågene, Mikkel Winther Pedersen, Mikkel-Holger S. Sinding, Martin R. Ellegaard, Morten E. Allentoft, Liam T. Lanigan, Alberto J. Taurozzi, Sofie Holtsmark Nielsen, Michael W. Dee, Martin N. Mortensen, Mads C. Christensen, Søren A. Sørensen, Matthew J. Collins, M. Thomas P. Gilbert, Martin Sikora, Simon Rasmussen, Hannes Schroeder
  - 2019-12-17
  - 10.1038/s41467-019-13549-9
  - ! 'The rise of ancient genomics has revolutionised our understanding of human prehistory but this work depends on the availability of suitable samples. Here we present a complete ancient human genome and oral microbiome sequenced from a 5700 year-old piece of chewed birch pitch from Denmark. We sequence the human genome to an average depth of 2.3× and find that the individual who chewed the pitch was female and that she was genetically more closely related to western hunter-gatherers from mainland Europe than hunter-gatherers from central Scandinavia. We also find that she likely had dark skin, dark brown hair and blue eyes. In addition, we identify DNA fragments from several bacterial and viral taxa, including Epstein-Barr virus, as well as animal and plant DNA, which may have derived from a recent meal. The results highlight the potential of chewed birch pitch as a source of ancient DNA.'
- - https://www.fightaging.org/archives/2019/12/a-look-back-at-2019-progress-towards-the-treatment-of-aging-as-a-medical-condition/
  - "A Look Back at 2019: Progress Towards the Treatment of Aging as a Medical Condition"
  - 'Reason (Fight Aging)'
  - 2019-12-31
  - ''
  - ! '<p>[Aging research over the past year, 2019. Categories include: The State of Funding, Conferences and Community, Clinical Development, Cellular Senescence, Mitochondria in Aging, Nuclear DNA Damage, Cross-Links, Neurodegeneration, Upregulation of Cell Maintenance, In Vivo Cell Reprogramming, Parabiosis, The Gut Microbiome in Aging, Biomarkers of Aging, Cancer, The Genetics of Longevity, Regenerative Medicine, Odds and Ends, Short Articles, and In Conclusion.]</p> <p>As has been the case for a few years now, progress towards the implementation of rejuvenation therapies is accelerating dramatically, ever faster with each passing year. While far from everyone is convinced that near term progress in addressing human aging is plausible, it is undeniable that we are far further ahead than even a few years ago. Even the public at large is beginning to catch on. While more foresightful individuals of past generations could do little more than predict a future of rejuvenation and extended healthy lives, we are in a position to make it happen.</p>'
- - https://web.mit.edu/~yandros/rpg/ogf-interview.html
  - "Interview with Ryan Dancey: D20 System and Open Gaming Movement"
  - Ryan Dancey
  - 2000-03-09
  - ''
  - ! '<p>Q. <strong>Can you briefly summarize what the Open Gaming Movement is about? Where did it come from, and what does it mean to the average gamer?</strong></p><p>A. Sure. Prepare yourself for a big gulp of business theory…That brings us to Open Gaming, and why we’re pursuing this initiative inside Wizards and outside to the larger community of game publishers.</p><p>Here’s the logic in a nutshell. We’ve got a theory that says that D&amp;D is the most popular role playing game because it is the game more people know how to play than any other game. (For those of you interested researching the theory, this concept is called “The Theory of Network Externalities”). Note: This is a very painful concept for a lot of people to embrace, including a lot of our own staff, and including myself for many years. The idea that D&amp;D is somehow “better” than the competition is a powerful and entrenched concept. The idea that D&amp;D can be “beaten” by a game that is “better” than D&amp;D is at the heart of every business plan from every company that goes into marketplace battle with the D&amp;D game. If you accept the Theory of Network Externalities, you have to admit that the battle is lost before it begins, because the value doesn’t reside in the game itself, but in the network of people who know how to play it.</p><p>If you accept (as I have finally come to do) that the theory is valid, then the logical conclusion is that the larger the number of people who play D&amp;D, the harder it is for competitive games to succeed, and the longer people will stay active gamers, and the more value the network of D&amp;D players will have to Wizards of the Coast. In fact, we believe that there may be a secondary market force we jokingly call “The Skaff Effect”, after our own <a href="https://en.wikipedia.org/wiki/Skaff_Elias">Skaff Elias</a>. Skaff is one of the smartest guys in the company, and after looking at lots of trends and thinking about our business over a long period of time, he enunciated his theory thusly:</p><blockquote><p>“All marketing and sales activity in a hobby gaming genre eventually contributes to the overall success of the market share leader in that genre.”</p></blockquote><p>In other words, the more money other companies spend on their games, the more D&amp;D sales are eventually made. Now, there are clearly issues of efficiency—not every dollar input to the market results in a dollar output in D&amp;D sales; and there is a substantial time lag between input and output; and a certain amount of people are diverted from D&amp;D to other games never to return. However, we believe very strongly that the net effect of the competition in the <span class="smallcaps-auto">RPG</span> genre is positive for D&amp;D. The downside here is that I believe that one of the reasons that the <span class="smallcaps-auto">RPG</span> as a category has declined so much from the early 90’s relates to the proliferation of systems. Every one of those different game systems creates a “bubble” of market inefficiency; the cumulative effect of all those bubbles has proven to be a massive downsizing of the marketplace. I have to note, highlight, and reiterate: The problem is not competitive product, the problem is competitive systems. I am very much for competition and for a lot of interesting and cool products.</p><p>So much for the dry theory and background. Here’s the logical conclusions we’ve drawn: We make more revenue and more profit from our core rulebooks than any other part of our product lines. In a sense, every other <span class="smallcaps-auto">RPG</span> product we sell other than the core rulebooks is a giant, self-financing marketing program to drive sales of those core books. At an extreme view, you could say that the core <em>book</em> of D&amp;D—the <span class="smallcaps-auto">PHB</span> [<em>Player’s Handbook</em> rulebook]—is the focus of all this activity, and in fact, the <span class="smallcaps-auto">PHB</span> is the #1 best selling, and most profitable <span class="smallcaps-auto">RPG</span> product Wizards of the Coast makes year in and year out.</p><p>The logical conclusion says that reducing the “cost” to other people to publishing and supporting the core D&amp;D game to zero should eventually drive support for all other game systems to the lowest level possible in the market, create customer resistance to the introduction of new systems, and the result of all that “support” redirected to the D&amp;D game will be to steadily increase the number of people who play D&amp;D, thus driving sales of the core books. This is a feedback cycle—the more effective the support is, the more people play D&amp;D. The more people play D&amp;D, the more effective the support is.</p><p>The other great effect of Open Gaming should be a rapid, constant improvement in the quality of the rules. With lots of people able to work on them in public, problems with math, with ease of use, of variance from standard forms, etc. should all be improved over time. The great thing about Open Gaming is that it is interactive—someone figures out a way to make something work better, and everyone who uses that part of the rules is free to incorporate it into their products. Including us. So D&amp;D as a game should benefit from the shared development of all the people who work on the Open Gaming derivative of D&amp;D.</p><p>After reviewing all the factors, I think there’s a very, very strong business case that can be made for the idea of embracing the ideas at the heart of the Open Source movement and finding a place for them in gaming.</p>'
- - https://www.sciencemag.org/news/2019/12/eyeing-organs-human-transplants-companies-unveil-most-extensively-gene-edited-pigs-yet
  - "Eyeing organs for human transplants, companies unveil the most extensively gene-edited pigs yet"
  - Kelly Servick (Science)
  - 2019-12-19
  - 10.1126/science.aba6487
  - ! '<p>If any swine is fit to be an organ donor for people, then the dozens of pigs snuffling around Qihan Bio’s facility in Hangzhou, China, may be the best candidates so far. The Chinese company and its U.S. collaborators reported today that they have used the genome editor CRISPR to create the most extensively genetically engineered pigs to date—animals whose tissues, the researchers say, finally combine all the features necessary for a safe and successful transplant into humans. “This is the first prototype,” says Luhan Yang, a geneticist at Qihan Bio. In a preprint published today on bioRxiv, Qihan researchers and collaborators, including Cambridge, Massachusetts–based eGenesis—which Yang co-founded with Harvard University geneticist George Church—described the new generation of animals and various tests on their cells; the researchers have already begun to transplant the pigs’ organs into nonhuman primates, a key step toward human trials.</p><p>…In the new study, the team for the first time combined these PERV “knockouts” with a suite of other changes to prevent immune rejection, for a record-setting 13 modified genes. In pig ear cells, they removed three genes coding for enzymes that help produce molecules on pig cells that provoke an immune response. They also inserted six genes that inhibit various aspects of the human immune response and three more that help regulate blood coagulation. The researchers then put the DNA-containing nuclei of these edited cells into eggs from pig ovaries collected at a slaughterhouse. These eggs developed into embryos that were implanted into surrogate mothers. Cells from the resulting piglets got another round of edits to remove the PERV sequences, after which their DNA went into another set of egg cells to create a new generation of pigs with all the desired edits. (In future, Yang says, the team will try to make all the modifications in a single generation.)</p><p>The resulting pigs appeared healthy and fertile with functioning organs, the team reports today. And initial tests of their cells in lab dishes suggest their organs will be much less prone to immune rejection than those of unmodified pigs: The tendency of the pig cells to bind to certain human antibodies was reduced by 90%, and the modified cells better survived interactions with human immune cells. But a key test is still to come: Yang says her team has begun to transplant organs from the highly edited pigs into monkeys to gauge their safety and longevity.</p><p>The combination of edits described in the new paper is “a technical feat,” says Marilia Cascalho, a transplant immunologist at the University of Michigan in Ann Arbor. “Whether it offers an advantage [over other engineered pig organs] … the jury is out on that,” she says…Yang says that Qihan plans to remain “laser-focused” on preclinical studies in 2020, but expects to be testing pig organs in humans within 5 years. Many in the field now feel an inevitable momentum around xenotransplantation: “There is so much need for organs,” Cascalho says. “I think it’s going to be a reality.”</p>'
- - https://openreview.net/forum?id=rkgNKkHtvB#google
  - "Reformer: The Efficient Transformer"
  - Nikita Kitaev, Lukasz Kaiser, Anselm Levskaya
  - 2019-09-25
  - ''
  - ! '<ul><li><p><em>Keywords</em>: attention, locality sensitive hashing, reversible layers</p></li><li><p><em>TL;DR</em>: Efficient Transformer with locality-sensitive hashing and reversible layers</p></li><li><p><em>Abstract</em>:</p><p>Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(<em>L</em><sup>2</sup>) to O(<em>L</em>), where <em>L</em> is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of <em>N</em> times, where <em>N</em> is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.</p></li><li><p><em>Code</em>: https://pastebin.com/62r5FuEW</p></li></ul>'
- - https://www.theatlantic.com/family/archive/2019/01/how-do-people-communicate-before-death/580303/
  - "What People Actually Say Before They Die: Insights into the little-studied realm of last words"
  - Michael Erard (Atlantic)
  - 2019-01-16
  - ''
  - ! '<p>…“There’s so much <em>so</em> in sorrow,” he said at one point. “Let me down from here,” he said at another. “I’ve lost my modality.” To the surprise of his family members, the lifelong atheist also began hallucinating angels and complaining about the crowded room—even though no one was there.</p><p>Felix’s 53-year-old daughter, Lisa Smartt, kept track of his utterances, writing them down as she sat at his bedside in those final days. Smartt majored in linguistics at UC Berkeley in the 1980s and built a career teaching adults to read and write. Transcribing Felix’s ramblings was a sort of coping mechanism for her, she says….eventually she wrote a book, <a href="https://www.amazon.com/Words-Threshold-What-Nearing-Death/dp/1608684601"><em>Words on the Threshold</em></a>, published in early 2017, about the linguistic patterns in 2,000 utterances from 181 dying people, including her father. Despite the limitations of this book, it’s unique—it’s the only published work I could find when I tried to satisfy my curiosity about how people <em>really</em> talk when they die.</p><p>…Many people die in such silence, particularly if they have advanced dementia or Alzheimer’s that robbed them of language years earlier. For those who do speak, it seems their vernacular is often banal. From a doctor I heard that people often say, “Oh fuck, oh fuck.” Often it’s the names of wives, husbands, children. “A nurse from the hospice told me that the last words of dying men often resembled each other,” wrote Hajo Schumacher in a <a href="http://www.spiegel.de/plus/maenner-und-ihre-muetter-der-milf-komplex-a-40b6d23f-0677-4c9c-9e3a-3a43cab12d0d">September essay in <em>Der Spiegel</em></a>. “Almost everyone is calling for ‘Mommy’ or ‘Mama’ with the last breath.”…Delirium is so frequent then, wrote the New Zealand psychiatrist Sandy McLeod, that “it may even be regarded as exceptional for patients to remain mentally clear throughout the final stages of malignant illness.” About half of people who recover from postoperative delirium recall the disorienting, fearful experience.</p><p>…He also repeated words and phrases, often ones that made no sense. “The green dimension! The green dimension!” (Repetition is common in the speech of people with dementia and also those who are delirious.) Smartt found that repetitions often expressed themes such as gratitude and resistance to death. But there were also unexpected motifs, such as circles, numbers, and motion. “I’ve got to get off, get off! Off of this life,” Felix had said…In <em>Final Gifts</em>, the hospice nurses Callanan and Kelley note that “the dying often use the metaphor of travel to alert those around them that it is time for them to die.” They quote a 17-year-old, dying of cancer, distraught because she can’t find the map. “If I could find the map, I could go home! Where’s the map? I want to go home!”</p>'
- - https://old.reddit.com/r/slatestarcodex/comments/dwtr0m/matthew_walkers_why_we_sleep_is_riddled_with/#thing_t1_f7mid7m
  - '[Comment on Guzey post]'
  - Kinkajoe
  - 2019-11-16
  - ''
  - ! '<p>I study sleep. While some of walker’s claims may be hyperbolic, I think they are within reason and justified by the important message he is trying to convey. Too many people have begun to forego sleep in their health choices, and he has helped raise awareness of sleep’s role in our health.</p><p>Many of these criticisms are quite unfair or misunderstanding the science...</p>'
- - http://famouspoetsandpoems.com/poets/mary_oliver/poems/15844
  - "The Kingfisher"
  - Mary Oliver
  - '1990'
  - ''
  - ! '<p>The kingfisher rises out of the black wave<br />like a blue flower, in his beak<br />he carries a silver leaf. I think this is<br />the prettiest world—so long as you don’t mind<br />a little dying, how could there be a day in your whole life<br />that doesn’t have its splash of happiness?<br />There are more fish than there are leaves<br />on a thousand trees, and anyway the kingfisher<br />wasn’t born to think about it, or anything else.<br />When the wave snaps shut over his blue head, the water<br />remains water—hunger is the only story<br />he has ever heard in his life that he could believe.<br />I don’t say he’s right. Neither<br />do I say he’s wrong. Religiously he swallows the silver leaf<br />with its broken red river, and with a rough and easy cry<br />I couldn’t rouse out of my thoughtful body<br />if my life depended on it, he swings back<br />over the bright sea to do the same thing, to do it<br />(as I long to do something, anything) perfectly.</p>'
- - https://www.ibiblio.org/ipa/poems/milosz/a_conversation_with_jeanne.php
  - A Conversation With Jeanne
  - Czesław Miłosz
  - '1984'
  - ''
  - ! '<p>Let us not talk philosophy, drop it, Jeanne. So many words, so much paper, who can stand it. I told you the truth about my distancing myself. I’ve stopped worrying about my misshapen life. It was no better and no worse than the usual human tragedies.</p><p>For over thirty years we have been waging our dispute As we do now, on the island under the skies of the tropics. We flee a downpour, in an instant the bright sun again, And I grow dumb, dazzled by the emerald essence of the leaves.</p><p>We submerge in foam at the line of the surf, We swim far, to where the horizon is a tangle of banana bush, With little windmills of palms. And I am under accusation: That I am not up to my oeuvre, That I do not demand enough from myself, As I could have learned from Karl Jaspers, That my scorn for the opinions of this age grows slack.</p><p>I roll on a wave and look at white clouds.</p><p>You are right, Jeanne, I don’t know how to care about the salvation of my soul. Some are called, others manage as well as they can. I accept it, what has befallen me is just. I don’t pretend to the dignity of a wise old age. Untranslatable into words, I chose my home in what is now, In things of this world, which exist and, for that reason, delight us: Nakedness of women on the beach, coppery cones of their breasts, Hibiscus, alamanda, a red lily, devouring With my eyes, lips, tongue, the guava juice, the juice of <em>la prune de Cythère</em>, Rum with ice and syrup, lianas-orchids In a rain forest, where trees stand on the stilts of their roots.</p><p>Death, you say, mine and yours, closer and closer, We suffered and this poor earth was not enough. The purple-black earth of vegetable gardens Will be here, either looked at or not. The sea, as today, will breathe from its depths. Growing small, I disappear in the immense, more and more free.</p><p><em>Guadeloupe</em></p>'
- - /docs/genetics/2016-plomin.pdf#page=10
  - Top 10 Replicated Findings From Behavioral Genetics
  - Robert Plomin, John C. DeFries, Valerie S. Knopik, Jenae M. Neiderhiser
  - '2016'
  - '10.1177/1745691615617439'
  - ! '<p><strong>Finding 7. Most measures of the “environment” show significant genetic influence</strong></p><p>Although it might seem a peculiar thing to do, measures of the environment widely used in psychological science—such as parenting, social support, and life events—can be treated as dependent measures in genetic analyses. If they are truly measures of the environment, they should not show genetic influence. To the contrary, in 1991, Plomin and Bergeman conducted a review of the first 18 studies in which environmental measures were used as dependent measures in genetically sensitive designs and found evidence for genetic influence for these measures of the environment. Significant genetic influence was found for objective measures such as videotaped observations of parenting as well as self-report measures of parenting, social support, and life events. How can measures of the environment show genetic influence? The reason appears to be that such measures do not assess the environment independent of the person. As noted earlier, humans select, modify, and create environments correlated with their genetic behavioral propensities such as personality and psychopathology (McAdams, Gregory, &amp; Eley, 2013). For example, in studies of twin children, parenting has been found to reflect genetic differences in children’s characteristics such as personality and psychopathology (Avinun &amp; Knafo, 2014; Klahr &amp; Burt, 2014; Plomin, 1994).</p><p>Since 1991, more than 150 articles have been published in which environmental measures were used in genetically sensitive designs; they have shown consistently that there is significant genetic influence on environmental measures, extending the findings from family environments to neighborhood, school, and work environments. Kendler and Baker (2007) conducted a review of 55 independent genetic studies and found an average heritability of 0.27 across 35 diverse environmental measures (confidence intervals not available). Meta-analyses of parenting, the most frequently studied domain, have shown genetic influence that is driven by child characteristics (Avinun &amp; Knafo, 2014) as well as by parent characteristics (Klahr &amp; Burt, 2014). Some exceptions have emerged. Not surprisingly, when life events are separated into uncontrollable events (e.g., death of a spouse) and controllable life events (e.g., financial problems), the former show nonsignificant genetic influence. In an example of how all behavioral genetic results can differ in different cultures, Shikishima, Hiraishi, Yamagata, Neiderhiser, and Ando (2012) compared parenting in Japan and Sweden and found that parenting in Japan showed more genetic influence than in Sweden, consistent with the view that parenting is more child centered in Japan than in the West.</p><p>Researchers have begun to use GCTA to replicate these findings from twin studies. For example, GCTA has been used to show significant genetic influence on stressful life events (Power et al., 2013) and on variables often used as environmental measures in epidemiological studies such as years of schooling (C. A. Rietveld, Medland, et al., 2013). Use of GCTA can also circumvent a limitation of twin studies of children. Such twin studies are limited to investigating within-family (twin-specific) experiences, whereas many important environmental factors such as socioeconomic status (SES) are the same for two children in a family. However, researchers can use GCTA to assess genetic influence on family environments such as SES that differ between families, not within families. GCTA has been used to show genetic influence on family SES (Trzaskowski et al., 2014) and an index of social deprivation (Marioni et al., 2014).</p>'
- - https://edwardtufte.github.io/tufte-css/#sidenotes
  - "Tufte-CSS: Sidenotes: Footnotes and Marginal Notes"
  - Dave Liepmann (Tufte-CSS)
  - ''
  - ''
  - ! '<p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<sup>3</sup> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p><p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p><p>…If you want a sidenote without footnote-style numberings, then you want a margin note. Notice there isn’t a number preceding the note. On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text.</p>'
- - /Causality#overview-the-current-situation
  - "Causality in the Social Sciences: Overview: The Current Situation"
  - Gwern Branwen
  - 2019-12-05
  - ''
  -  ! '<p>Here is how I currently understand the relationship between correlation and causality, and the collective findings of meta-scientific research:</p><ol type="1"><li><p><a href="/Replication"><em>The Replication Crisis</em></a>: a shockingly large fraction of psychological research and other fields is simple random noise which cannot be replicated.</p></li><li><p><a href="/Everything"><em>Everything Is Correlated</em></a>: when we systematically measure many variables at large scale with large <em>n</em>, we find that ‘everything is correlated’—even things which seem to have no causal relationship whatsoever.</p></li><li><p><a href="/docs/sociology/1987-rossi"><em>The Metallic Laws</em></a>: empirically, most efforts to change human behavior and sociology and economics and education fail in randomized evaluation and the mean effect size of experiments in meta-analyses typically approaches zero, despite promising correlations.</p></li><li><p><a href="/Correlation"><em>Correlation ≠ Causation</em></a>: so, we live in a world where research manufactures many spurious results and, even once we see through the fake findings, finding a correlation is meaningless because everything is correlated to begin with and accordingly, they are little better than experimenting at random, which doesn’t work well either.</p><p>But <em>why</em> is correlation ≠ causation?</p></li><li><p><a href="/Causality#what-a-tangled-net-we-weave-when-first-we-practice-to-believe"><em>Dense Causal Graphs</em></a>: because, if we write down a causal graph consistent with ‘everything is correlated’ and the empirical facts of average null effects + unpredictive correlations, this implies that all variables are part of enormous dense causal graphs where each variable is connected to several others.</p></li><li><p><a href="/Causality#heuristics-biases"><em>Incorrect Intuitions</em></a>: This inequality between observable correlations and actual useful causal manipulability merely grows with larger networks, and causal networks in fields like economics or biology are far more complex than those in more ordinary everyday fields like ‘catching a ball’.</p><p>Our intuitions, formed in simple domains designed to have sparse causal networks (it would be bad if balls could make you do random things! your brain is carefully designed to control the influence of any outside forces &amp; model the world as simple for planning purposes), turn out to be profoundly misleading in these other domains.</p></li><li><p><em>No, Really, Correlation ≠ Causation</em>: This cognitive bias is why correlation ≠ causation is so difficult to internalize and accept, and honored primarily in the breach even by sophisticated researchers, and is why randomized experiments are historically late developed, neglected, counterintuitive, and criticized when run despite routinely debunking conventional wisdom of experts in almost every field.</p></li></ol>'
- - https://slatestarcodex.com/2013/07/17/who-by-very-slow-decay/
  - Who By Very Slow Decay
  - Scott Alexander
  - 2013-07-17
  - ''
  - ! '<p>[Essay by psychiatrist about care of the dying in American healthcare: people die agonizing, slow, expensive deaths, prolonged by modern healthcare, deprived of all dignity and joy by disease and decay. There is little noble about it.]</p><p>You will become bedridden, unable to walk or even to turn yourself over. You will become completely dependent on nurse assistants to intermittently shift your position to avoid pressure ulcers. When they inevitably slip up, your skin develops huge incurable sores that can sometimes erode all the way to the bone, and which are perpetually infected with foul-smelling bacteria. Your limbs will become practically vestigial organs, like the appendix, and when your vascular disease gets too bad, one or more will be amputated, sacrifices to save the host. Urinary and fecal continence disappear somewhere in the process, so you’re either connected to catheters or else spend a while every day lying in a puddle of your own wastes until the nurses can help you out….</p><p>Somewhere in the process your mind very quietly and without fanfare gives up the ghost. It starts with forgetting a couple of little things, and progresses…They don’t remember their own names, they don’t know where they are or what they’re doing there, and they think it’s the 1930s or the 1950s or don’t even have a concept of years at all. When you’re alert and oriented “x0”, the world becomes this terrifying place where you are stuck in some kind of bed and can’t move and people are sticking you with very large needles and forcing tubes down your throat and you have no idea why or what’s going on.</p><p>So of course you start screaming and trying to attack people and trying to pull the tubes and IV lines out. Every morning when I come in to work I have to check the nurses’ notes for what happened the previous night, and every morning a couple of my patients have tried to pull all of their tubes and lines out. If it’s especially bad they try to attack the staff, and although the extremely elderly are really bad at attacking people this is nevertheless Unacceptable Behavior and they have to be restrained ie tied down to the bed. A presumably more humane alternative sometimes used instead or in addition is to just drug you up on all of those old-timey psychiatric medications that actual psychiatrists don’t use anymore because of their bad reputation…Nevertheless, this is the way many of my patients die. Old, limbless, bedridden, ulcerated, in a puddle of waste, gasping for breath, loopy on morphine, hopelessly demented, in a sterile hospital room with someone from a volunteer program who just met them sitting by their bed.</p><p>…I work in a Catholic hospital. People here say the phrase “culture of life” a lot, as in “we need to cultivate a culture of life.” They say it almost as often as they say “patient-centered”. At my hospital orientation, a whole bunch of nuns and executives and people like that got up and told us how we had to do our part to “cultivate a culture of life.”</p><p>And now every time I hear that phrase I want to scream. 21<sup>st</sup> century American hospitals do not need to “cultivate a culture of life”. We have enough life. We have life up the wazoo. We have more life than we know what to do with. We have life far beyond the point where it becomes a sick caricature of itself. We prolong life until it becomes a sickness, an abomination, a miserable and pathetic flight from death that saps out and mocks everything that made life desirable in the first place. 21<sup>st</sup> century American hospitals need to cultivate a culture of life the same way that Newcastle needs to cultivate a culture of coal, the same way a man who is burning to death needs to cultivate a culture of fire.</p><p>And so every time I hear that phrase I want to scream, or if I cannot scream, to find some book of hospital poetry that really is a book of hospital poetry and shove it at them, make them read it until they understand. There is no such book, so I hope it will be acceptable if I just rip off of Wilfred Owen directly:</p><blockquote><p>If in some smothering dreams you too could pace<br />Behind the gurney that we flung him in,<br />And watch the white eyes writhing in his face,<br />His hanging face, like a devil’s sack of sin;<br />If you could hear, at every jolt, the blood<br />Come gargling from the froth-corrupted lungs,<br />Obscene with cancer, bitter with the cud<br />Of vile, incurable sores on innocent tongues<br />My friend, you would not so pontificate<br />To reasoners beset by moral strife<br />The old lie: we must try to cultivate<br />A culture of life.</p></blockquote>'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1119282/
  - "Instinctive sleeping and resting postures: an anthropological and zoological approach to treatment of low back and joint pain"
  - Michael Tetley
  - 2000-12-23
  - '10.1136/bmj.321.7276.1616'
  - ! '<p>If you are a medical professional and have been trained in a “civilised” country you probably know next to nothing about the primate <em>Homo sapiens</em> and how they survive in the wild. You probably do not know that nature has provided an automatic manipulator to correct most spinal and peripheral joint lesions in primates. In common with millions of other so called civilised people you suffer unnecessarily from musculoskeletal problems and are discouraged about how to treat the exponential rise in low back pain throughout the developed world. Humans are one of 200 species of primates.<sup>1</sup> All primates suffer from musculoskeletal problems; nature, recognising this fact, has given primates a way to correct them.</p><p>The study of animals in the wild has been a lifelong pursuit. I grew up with tribal people and in 1953–4 commanded a platoon of African soldiers from 9 tribes, who taught me to sleep on my side without a pillow so that I could listen out for danger with both ears. I have organised over 14 expeditions all over the world to meet native peoples and study their sleeping and resting postures. They all adopted similar postures and exhibited few musculoskeletal problems. I must emphasise that this is not a comparison of genes or races but of lifestyles. I tried to carry out surveys to collect evidence but they were meaningless, as tribespeople give you the answer they think you want. They often object to having their photographs taken, so I have demonstrated the postures.</p><p><em>Summary points</em>:</p><ul><li>Forest dwellers and nomads suffer fewer musculoskeletal lesions than “civilised” people</li><li>Nature’s automatic manipulator during sleep is the kickback against the vertebrae by the ribs when the chest is prevented from movement by the forest floor</li><li>Various resting postures correct different joints</li><li>Pillows are not necessary</li></ul>'
- - https://www.nytimes.com/2019/12/30/business/china-scientist-genetic-baby-prison.html
  - "Chinese Scientist Who Genetically Edited Babies Gets 3 Years in Prison: He Jiankui’s work was also carried out on a third infant, according to China’s state media, in a new disclosure that is likely to add to the global uproar over such experiments."
  - Sui-Lee Wee (NYT)
  - 2019-12-30
  - ''
  -  ! '<p>A court in China on Monday sentenced He Jiankui, the researcher who shocked the global scientific community when he claimed that he had created the world’s first genetically edited babies, to three years in prison for carrying out “illegal medical practices.” In a surprise announcement from a trial that was closed to the public, the court in the southern city of Shenzhen found Dr. He guilty of forging approval documents from ethics review boards to recruit couples in which the man had H.I.V. and the woman did not, Xinhua, China’s official news agency, reported. Dr. He had said he was trying to prevent H.I.V. infections in newborns, but the state media on Monday said he deceived the subjects and the medical authorities alike.</p><p>Dr. He, 35, sent the scientific world into an uproar last year when he announced at a conference in Hong Kong that he had created the world’s first genetically edited babies—twin girls. On Monday, China’s state media said his work had resulted in a third genetically edited baby, who had been previously undisclosed.</p><p>Dr. He pleaded guilty and was also fined $430,000, according to Xinhua. In a brief trial, the court also handed down prison sentences to two other scientists who it said had “conspired” with him: Zhang Renli, who was sentenced to two years in prison, and Qin Jinzhou, who got a suspended sentence of one and a half years…The court said the trial had to be closed to the public to guard the privacy of the people involved.</p>'
- - https://www.statnews.com/2019/06/25/alzheimers-cabal-thwarted-progress-toward-cure/
  - "The maddening saga of how an Alzheimer’s ‘cabal’ thwarted progress toward a cure for decades"
  - Sharon Begley (STAT)
  - 2019-06-25
  - ''
  -  ! '<p>In the 30 years that biomedical researchers have worked determinedly to find a cure for Alzheimer’s disease, their counterparts have developed drugs that helped cut deaths from cardiovascular disease by more than half, and cancer drugs able to eliminate tumors that had been incurable. But for Alzheimer’s, not only is there no cure, there is not even a disease-slowing treatment.</p><p>…In more than two dozen interviews, scientists whose ideas fell outside the dogma recounted how, for decades, believers in the dominant hypothesis suppressed research on alternative ideas: They influenced what studies got published in top journals, which scientists got funded, who got tenure, and who got speaking slots at reputation-buffing scientific conferences. The scientists described the frustrating, even career-ending, obstacles that they confronted in pursuing their research. A top journal told one that it would not publish her paper because others hadn’t. Another got whispered advice to at least pretend that the research for which she was seeking funding was related to the leading idea—that a protein fragment called beta-amyloid accumulates in the brain, creating neuron-killing clumps that are both the cause of Alzheimer’s and the key to treating it. Others could not get speaking slots at important meetings, a key showcase for research results. Several who tried to start companies to develop Alzheimer’s cures were told again and again by venture capital firms and major biopharma companies that they would back only an amyloid approach.</p><p>…For all her regrets about the amyloid hegemony, Neve is an unlikely critic: She co-led the 1987 discovery of mutations in a gene called APP that increases amyloid levels and causes Alzheimer’s in middle age, supporting the then-emerging orthodoxy. Yet she believes that one reason Alzheimer’s remains incurable and untreatable is that the amyloid camp “dominated the field,” she said. Its followers were influential “to the extent that they persuaded the National Institute of Neurological Disorders and Stroke [part of the National Institutes of Health] that it was a waste of money to fund any Alzheimer’s-related grants that didn’t center around amyloid.” To be sure, NIH did fund some Alzheimer’s research that did not focus on amyloid. In a sea of amyloid-focused grants, there are tiny islands of research on oxidative stress, neuroinflammation, and, especially, a protein called tau. But Neve’s NINDS program officer, she said, “told me that I should at least collaborate with the amyloid people or I wouldn’t get any more NINDS grants.” (She hoped to study how neurons die.) A decade after her APP discovery, a disillusioned Neve left Alzheimer’s research, building a distinguished career in gene editing. Today, she said, she is “sick about the millions of people who have needlessly died from” the disease.</p><p>Dr. Daniel Alkon, a longtime NIH neuroscientist who started a company to develop an Alzheimer’s treatment, is even more emphatic: “If it weren’t for the near-total dominance of the idea that amyloid is the only appropriate drug target,” he said, “we would be 10 or 15 years ahead of where we are now.”</p><p>Making it worse is that the empirical support for the amyloid hypothesis has always been shaky. There were numerous red flags over the decades that targeting amyloid alone might not slow or reverse Alzheimer’s. “Even at the time the amyloid hypothesis emerged, 30 years ago, there was concern about putting all our eggs into one basket, especially the idea that ridding the brain of amyloid would lead to a successful treatment,” said neurobiologist Susan Fitzpatrick, president of the James S. McDonnell Foundation. But research pointing out shortcomings of the hypothesis was relegated to second-tier journals, at best, a signal to other scientists and drug companies that the criticisms needn’t be taken too seriously. Zaven Khachaturian spent years at NIH overseeing its early Alzheimer’s funding. Amyloid partisans, he said, “came to permeate drug companies, journals, and NIH study sections,” the groups of mostly outside academics who decide what research NIH should fund. “Things shifted from a scientific inquiry into an almost religious belief system, where people stopped being skeptical or even questioning.”</p><p>…“You had a whole industry going after amyloid, hundreds of clinical trials targeting it in different ways,” Alkon said. Despite success in millions of mice, “none of it worked in patients.”</p><p>Scientists who raised doubts about the amyloid model suspected why. Amyloid deposits, they thought, are a response to the true cause of Alzheimer’s and therefore a marker of the disease—again, the gravestones of neurons and synapses, not the killers. The evidence? For one thing, although the brains of elderly Alzheimer’s patients had amyloid plaques, so did the brains of people the same age who died with no signs of dementia, a pathologist discovered in 1991. Why didn’t amyloid rob them of their memories? For another, mice engineered with human genes for early Alzheimer’s developed both amyloid plaques and dementia, but there was no proof that the much more common, late-onset form of Alzheimer’s worked the same way. And yes, amyloid plaques destroy synapses (the basis of memory and every other brain function) in mouse brains, but there is no correlation between the degree of cognitive impairment in humans and the amyloid burden in the memory-forming hippocampus or the higher-thought frontal cortex. “There were so many clues,” said neuroscientist Nikolaos Robakis of the Icahn School of Medicine at Mount Sinai, who also discovered a mutation for early-onset Alzheimer’s. “Somehow the field believed all the studies supporting it, but not those raising doubts, which were very strong. The many weaknesses in the theory were ignored.”</p>'
- - /docs/biology/2019-thomas.pdf
  - 'Objective subtle cognitive difficulties predict future amyloid accumulation and neurodegeneration'
  - ! "Kelsey R. Thomas, Katherine J. Bangen, Alexandra J. Weigand, Emily C. Edmonds, Christina G. Wong, Shanna Cooper, Lisa Delano-Wood, Mark W. Bondi, for the Alzheimer's Disease Neuroimaging Initiative"
  - 2019-12-30
  - '10.1212/WNL.0000000000008838'
  - ! '<p><em>Objective</em>: To determine the temporal sequence of objectively defined subtle cognitive difficulties (Obj-SCD) in relation to amyloidosis and neurodegeneration, the current study examined the trajectories of amyloid PET and medial temporal neurodegeneration in participants with Obj-SCD relative to cognitively normal (CN) and mild cognitive impairment (MCI) groups.</p><p><em>Method</em>: A total of 747 Alzheimer’s Disease Neuroimaging Initiative participants (305 CN, 153 Obj-SCD, 289 MCI) underwent neuropsychological testing and serial amyloid PET and structural MRI examinations. Linear mixed effects models examined 4-year rate of change in cortical 18F-florbetapir PET, entorhinal cortex thickness, and hippocampal volume in those classified as Obj-SCD and MCI relative to CN.</p><p><em>Result</em>: Amyloid accumulation was faster in the Obj-SCD group than in the CN group; the MCI and CN groups did not significantly differ from each other. The Obj-SCD and MCI groups both demonstrated faster entorhinal cortical thinning relative to the CN group; only the MCI group exhibited faster hippocampal atrophy than CN participants.</p><p><em>Conclusion</em>: Relative to CN participants, Obj-SCD was associated with faster amyloid accumulation and selective vulnerability of entorhinal cortical thinning, whereas MCI was associated with faster entorhinal and hippocampal atrophy. Findings suggest that Obj-SCD, operationally defined using sensitive neuropsychological measures, can be identified prior to or during the preclinical stage of amyloid deposition. Further, consistent with the Braak neurofibrillary staging scheme, Obj-SCD status may track with early entorhinal pathologic changes, whereas MCI may track with more widespread medial temporal change. Thus, Obj-SCD may be a sensitive and noninvasive predictor of encroaching amyloidosis and neurodegeneration, prior to frank cognitive impairment associated with MCI.</p>'
- - https://mlp.fandom.com/wiki/The_Last_Problem
  - "MLP:FiM: S9E26: The Last Problem"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>The Last Problem</strong> is the twenty-sixth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and twenty-second episode overall.[1] It premiered as the final episode of the series, as part of the 90-minute finale with <em>The Ending of the End—Part 1</em> and <em>The Ending of the End—Part 2</em>.</p><p>In this epilogue episode, an older and wiser Princess Twilight Sparkle is visited by a student with a friendship problem. As she attempts to solve it, she looks back on the times she and her friends spent together.</p><p>A sequel event to the episode, “The Crowning Achievement”, was included in Gameloft’s mobile game.</p>'
- - https://mlp.fandom.com/wiki/The_Big_Mac_Question
  - "MLP:FiM: S9E23: The Big Mac Question"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>The Big Mac Question</strong> is the twenty-third[1][2] episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and nineteenth episode overall.[3] The title is a reference to the saying “the big question”, which is often used as a euphemism for a marriage proposal.</p><p>When Big McIntosh and Sugar Belle decide to propose to each other, everything their friends do to help ends up making a mess of the whole thing.</p>'
- - https://mlp.fandom.com/wiki/Sparkle%27s_Seven
  - "MLP:FiM: S9E4: Sparkle's Seven"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>Sparkle’s Seven</strong> (also titled “Twilight’s Seven” by some sources and in the episode’s script,[1]) is the fourth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundredth episode overall,[2] celebrated as a milestone episode. The title is a reference to the 1960 film <em>Ocean’s 11</em>, its 2001 remake, and/or the all-female spin-off to the latter <em>Ocean’s 8</em>, previously referenced by “Sparkle’s Six” in <em>Twilight Sparkle and the Crystal Heart Spell</em> and “Luna’s 5” on the <em>My Little Pony: Nightmare Knights</em> Issue #1 cover RI.</p><p>In this episode, Twilight Sparkle and Shining Armor pit their wits against each other to settle a long-standing sibling rivalry, but they soon discover they are not the only competitors.</p>'
- - https://mlp.fandom.com/wiki/Daring_Doubt
  - "MLP:FiM: S9E21: Daring Doubt"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>Daring Doubt</strong> is the twenty-first episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and seventeenth episode overall.[1]</p><p>When another author releases his own version of the events in A. K. Yearling’s Daring Do books, Rainbow Dash is furious, while Fluttershy is curious to know the truth.</p>'
- - https://mlp.fandom.com/wiki/The_Last_Laugh
  - "MLP:FiM: S9E14: The Last Laugh"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>The Last Laugh</strong> (incorrectly[1] titled as “That’s a Laugh” by some sources), is the fourteenth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and tenth episode overall.[2]</p><p>When Pinkie Pie seeks help from her old friend Cheese Sandwich in finding her life’s purpose, she discovers the unimaginable has happened.</p>'
- - https://mlp.fandom.com/wiki/Between_Dark_and_Dawn
  - "MLP:FiM: S9E13: Between Dark and Dawn"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>Between Dark and Dawn</strong> is the thirteenth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and ninth episode overall.[1] It marks season nine’s midseason finale.[2]</p><p>In this episode, Celestia and Luna take a “bucket-list” sister vacation while Twilight and her friends struggle to cover the princesses’ many royal duties alone.</p>'
- - https://www.kickscondor.com/
  - Kicks Condor
  - Kicks Condor
  - ''
  - ''
  - ! '[Homepage of programmer Kicks Condor; hypertext-oriented link compilation and experimental design blog.]'
- - https://href.cool/2010s/
  - "Cool Links of the Decade: 2010s"
  - Kicks Condor
  - 2019-12
  - ''
  - ! '<p>Eh, this is doomed - <a href="https://waxy.org/">Waxy</a> or <a href="https://imperica.com/">Imperica</a> should take a crack at this. The AV Club did a <a href="https://aux.avclub.com/the-100-best-worst-and-weirdest-things-we-saw-on-the-1839566367">list</a> of ‘things’. I wanted to cover stuff that wasn’t on there. A lot happened outside of celebrities, Twitter and momentary memes. (We all obviously love <span class="citation" data-cites="electrolemon">@electrolemon</span>, “double rainbow”, Key &amp; Peele’s <em>Gremlins 2 Brainstorm</em>, 10 hr vids, etc.)</p><pre><code>  &lt;p&gt;There is a master &lt;a href=&quot;https://www.fimoculous.com/decade-review-2010.cfm&quot;&gt;list of lists&lt;/a&gt; as well.&lt;/p&gt;  &lt;p&gt;Hope for this list—get u mad &amp;amp; u destroy me &amp;amp; u blog in 2020.&lt;/p&gt;</code></pre>'
- - https://www.goodreads.com/review/show/2821183153
  - "Review of 'String of Beads: Complete Poems of Princess Shikishi'"
  - Gwern Branwen
  - 2019-12-29
  - ''
  - ! "[Review of translation of complete corpus of imperial court poet Princess Shikishi (1149–1201). While well-annotated, Sato's decision to translate each poem in a single line drains it of any enjoyability, turning it into a prose-like slog.]"
- - https://www.goodreads.com/review/show/1798638457
  - "Review of 'Experimenter Effects In Behavioral Research', Robert Rosenthal"
  - Gwern Branwen
  - 2019-12-28
  - ''
  - ! "Review of a major and widely-cited psychology monograph purporting to demonstrate pervasive and powerful effects of social expectations and settings and the general environment on all aspects of human psychology, experimentation, and research, even to the point of the 'Pygmalion effect' proving that teacher expectations can boost student IQs by hundreds of points. The Pygmalion effect was based on impossible data, was defended by statistical malpractice, and repeatedly failed to replicate, and this exemplifies the problem with Rosenthal's research and the book as a whole: despite its appearance of extreme rigor and concern for bias, it is clear that the results actually exemplify the Replication Crisis and that almost none of his research is reliable, bogus from beginning to end, and the results were designed to serve ideological goals despite the intrinsic absurdity and inconsistency with basic observations of the stability and consistency and predictive power of individual differences and the impotence of environmental interventions."
- - https://old.reddit.com/r/AIDungeon/
  - '/r/AIDungeon/'
  - Reddit
  - ''
  - ''
  - ! '[Subreddit for sharing AI Dungeon 2 game transcripts and discussing bugs/issues/upgrades; <a href="https://old.reddit.com/r/AIDungeon/comments/e8fz8l/putting_together_a_frequently_asked_questions_list/">FAQ</a>.]'
- - https://www.edwardtufte.com/tufte/books_visex
  - '<em>Visual Explanations: Images and Quantities, Evidence and Narrative</em>, Tufte 1997'
  - Edward Tufte
  - '1997'
  - ''
  - ! '<p><em>Visual Explanations: Images and Quantities, Evidence and Narrative</em> [Tufte #3] is about pictures of verbs, the representation of mechanism and motion, process and dynamics, causes and effects, explanation and narrative. Practical applications and examples include statistical graphics, charts for making important decisions in engineering and medicine, technical manuals, diagrams, design of computer interfaces and websites and on-line manuals, animations and scientific visualizations, techniques for talks, and design strategies for enhancing the rate of information transfer in print, presentations, and computer screens. The use of visual evidence in deciding to launch the space shuttle Challenger is discussed in careful detail. Video snapshots show redesigns of a supercomputer animation of a thunderstorm. The book is designed and printed to the highest standards, with luscious color throughout and four built-in flaps for showing motion and before/after effects.</p><p>158 pages; ISBN 1930824157</p><figure><img src="/images/design/1997-tufte-visualexplanations-cover.jpg" alt="Cover of Visual Explanations (https://www.edwardtufte.com/tufte/graphics/visex_bookcover.gif)" /><figcaption>Cover of <em>Visual Explanations</em></figcaption></figure>'
- - https://statmodeling.stat.columbia.edu/2019/12/27/why-we-sleep-data-manipulation-a-smoking-gun/
  - '<em>Why we sleep</em> data manipulation: A smoking gun?'
  - Andrew Gelman
  - 2019-12-27
  - ''
  - ! '<p>In his post, Matthew Walker’s “Why We Sleep” Is Riddled with Scientific and Factual Errors” (see our discussions <a href="https://statmodeling.stat.columbia.edu/2019/11/18/is-matthew-walkers-why-we-sleep-riddled-with-scientific-and-factual-errors/">here</a>, <a href="https://statmodeling.stat.columbia.edu/2019/11/24/why-we-sleep-update-some-thoughts-while-we-wait-for-matthew-walker-to-respond-to-alexey-guzeys-criticisms/">here</a>, and <a href="https://statmodeling.stat.columbia.edu/2019/12/26/whassup-with-why-we-sleep/">here</a>), Alexey Guzey added the following <a href="https://guzey.com/books/why-we-sleep/#appendix-what-do-you-do-when-a-part-of-the-graph-contradicts-your-argument-you-cut-it-out-of-course">stunner</a>:</p><p><img src="/images/statistics/2019-guzey-whywesleep-walkerdatamanipulation.png" alt="https://statmodeling.stat.columbia.edu/wp-content/uploads/2019/12/Screen-Shot-2019-12-27-at-8.18.51-AM.png" width="550" /></p><p>We’ve left “super-important researcher too busy to respond to picky comments” territory and left “well-intentioned but sloppy researcher can’t keep track of citations” territory and entered “research misconduct” territory.</p><p>…This seems like a good time to revisit that Dan Davies <a href="https://blog.danieldavies.com/2004_05_23_d-squareddigest_archive.html">line</a>:</p><blockquote><p>Good ideas do not need lots of lies told about them in order to gain public acceptance.</p></blockquote>'
- - https://statmodeling.stat.columbia.edu/2019/12/26/whassup-with-why-we-sleep/
  - "Whassup with <em>Why We Sleep</em>?"
  - Andrew Gelman
  - 2019-12-26
  - ''
  - ! '<p>Last month <a href="https://statmodeling.stat.columbia.edu/2019/11/18/is-matthew-walkers-why-we-sleep-riddled-with-scientific-and-factual-errors/">we reported</a> on the book Why We Sleep, which had been dismantled in a <a href="https://guzey.com/books/why-we-sleep/">long and detailed blog post</a> by Alexey Guzey. A week later I looked again, and Walker had not responded to Guzey in any way. In the meantime, Why We Sleep has also been <a href="https://www.gatesnotes.com/About-Bill-Gates/Holiday-Books-2019">endorsed</a> by O.G. software entrepreneur Bill Gates. Programmers typically have lots of personal experience of sleep deprivation, so this is a topic close to their hearts.</p><p>As of this writing, it seems that Walker still has not responded to most of the points Guzey made about errors in his book. The closest thing I can find is <a href="https://sleepdiplomat.wordpress.com">this post</a> dated 19 Dec 2019, titled “Why We Sleep: Responses to questions from readers.” The post is on a site called On Sleep that appears to have been recently set up—I say this because I see no internet record of it, and it currently has just this one post. I’m not trying to be some sort of sleuth here, I’m just trying to figure out what’s going on. For now, I’ll assume that this post is written by Walker.</p><p>The post begins:</p><blockquote><p>The aim of the book, Why We Sleep, is to provide the general public access to a broad collection of sleep research. Below, I address thoughtful questions that have been raised regarding the book and its content in <a href="https://bookmarks.reviews/reviews/all/why-we-sleep/">reviews</a>, <a href="https://bookmarks.reviews/reviews/all/why-we-sleep/">online</a> forums and direct emails that I have received. Related, I very much appreciate being made aware of any errors in the book requiring revision. I see this as a key part of good scholarship. Necessary corrections will be made in future editions.</p></blockquote><p>The first link above goes to a page of newspaper and magazine reviews, and the second link goes to Guzey’s post. I didn’t really see any questions raised regarding the book in those newspaper and magazine reviews, so I’m guessing that the “thoughtful questions” that Walker is referring to are coming entirely, or nearly entirely, from Guzey. It seems odd for Walker to cite “online forums” and only link to one of them. Also, although Walker links to Guzey, he does not address the specific criticisms Guzey made of his book.</p><p>…Based on his book and his Ted talk, it seems that Walker has a message to send, and he doesn’t care much about the details. He’s sloppy with sourcing, gets a lot wrong, and has not responded well to criticism.</p><p>But this does not mean we should necessarily dismiss his message. Ultimately his claims need to be addressed on their merits.</p>'
- - https://statmodeling.stat.columbia.edu/2019/11/24/why-we-sleep-update-some-thoughts-while-we-wait-for-matthew-walker-to-respond-to-alexey-guzeys-criticisms/
  - '<em>Why We Sleep</em> update: some thoughts while we wait for Matthew Walker to respond to Alexey Guzey’s criticisms'
  - Andrew Gelman
  - 2019-11-24
  - ''
  - '<p>So. It’s been a week since Alexey Guzey posted his wonderfully-titled article, “Matthew Walker’s ‘Why We Sleep’ Is Riddled with Scientific and Factual Errors.”…As of this writing, the ball remains in Walker’s court.</p><p>I googled <em>”matthew walker” “alexey guzey”</em> and <em>”matthew walker” sleep</em> and a few other things, but nowhere did I find any response from Walker to Guzey’s criticisms.</p><p>It’s hard for me to imagine that Walker hasn’t heard about Guzey’s article by now, but I guess it’s possible that he (Walker) is on vacation or that he’s preparing a response but has not finished yet….While we’re waiting for Walker to respond, I had a few more thoughts:</p><ol type="1"><li>A few years ago, if someone were to claim that a celebrated professor of neuroscience and psychology at a major university had published a book on his own field of expertise, and the book was full of scientific and factual errors, that would’ve been a major scandal, no? But now, we’re like, yeah, sure, that’s just more same old same old. As the saying goes, the big scandal is how little a scandal this has been.</li><li>What would be really cool would be if NPR and Joe Rogan ran interviews with Alexey Guzey about this story. NPR probably won’t bite. But Joe Rogan . . . he might go for this, right? I bet Joe Rogan, or someone on his team, reads social media. And Rogan likes combat. He’s had Walker on his show, now time to have Guzey come in with the critique. That said, I don’t know that a podcast is the best format for such a debate. I think blogging is a better way to go, as then there’s enough space to lay out all the evidence.</li><li>Assuming Guzey’s criticisms hold up, I’m still trying to figure out what happened with that book. How could Walker introduce <em>so many</em> errors on his own area of expertise (or, I guess I should say, supposed expertise)? Was he just really really confused? Did he delegate the research and writing to lazy research assistants? Did he feel that his underlying story was important so the details didn’t matter? Did he conduct his research by putting all his notes onto index cards, then mistype material off the cards? I just don’t have a good way of thinking about these things.</li><li>Guzey’s article is careful and in many ways bulletproof: he backs up each of his statements, he doesn’t exaggerate (even for humorous purposes), and nobody seems to have found any mistakes in what he wrote. In addition, Guzey has gone on the web and responded to comments: where people claim he got things wrong, he has responded in detail.</li></ol><p>This is excellent behavior on Guzey’s part but I just want to say that it should not be <em>required</em>. Suppose, just for the sake of argument, that Guzey was gratuitously rude, that he made some claims without making his the evidence clear, even that he made some mistakes. Suppose that he spent 13 hours or even 1.3 hours rather than 130 hours writing this post, so that he only got to the highlights and didn’t carefully check everything he wrote? That would be unfortunate, <em>but it wouldn’t make his critique less valid.</em></p><p>What I’m saying is: by preparing a critique that’s clean, clear, well sourced, well written—actually enjoyable to read—, a critique that doesn’t make any questionable claims, by being so careful, Guzey has done us a favor. He’s made it easier to follow what he’s written, and he’s making it more difficult for someone to dismiss his arguments on superficial grounds. He’s raising the game, and that’s wonderful.</p><p>But if Guzey hadn’t gone to that trouble, he could still be making a useful contribution. It would just be the duty of Walker to extract that contribution.</p>'
- - https://statmodeling.stat.columbia.edu/2019/11/18/is-matthew-walkers-why-we-sleep-riddled-with-scientific-and-factual-errors/
  - 'Is Matthew Walker’s <em>Why We Sleep</em> Riddled with Scientific and Factual Errors?'
  - Andrew Gelman
  - 2019-11-18
  - ''
  - ! '<p>Asher Meir points to this hilarious post by Alexey Guzey entitled, <a href="https://guzey.com/books/why-we-sleep/">Matthew Walker’s “Why We Sleep” Is Riddled with Scientific and Factual Errors</a>.</p><p>Just to start with, the post has a wonderful descriptive title. And the laffs start right away:</p><p><img src="/images/statistics/2019-guzey-whywesleep-tableofcontents.png" alt="https://statmodeling.stat.columbia.edu/wp-content/uploads/2019/11/Screen-Shot-2019-11-17-at-9.37.25-PM.png" width="550" /></p><p>Positively Nabokovian, I’d say. I mean it. The above table of contents makes me want to read more.</p><p>I’ve not read Walker’s book and I don’t know anything about sleep research, so I won’t try to judge Guzey’s claims. I read through and I found Guzey’s arguments to be persuasive, but, hey, I’m easily persuaded.</p><p>I’d be happy to read a followup article by Michael Walker, “Alexey Guzey’s ‘Matthew Walker’s “Why We Sleep” Is Riddled with Scientific and Factual Errors’ Is Riddled with Scientific and Factual Errors.” That (hypothetical) post could completely turn me around! Then, of course, I’d be waiting for Guzey’s reply, “Michael Walker’s ‘Alexey Guzey’s “Matthew Walker’s ‘Why We Sleep’ Is Riddled with Scientific and Factual Errors” Is Riddled with Scientific and Factual Errors’ Is Riddled with Scientific and Factual Errors.” At that point, I’d probably have heard enough to have formed a firm opinion. Right now, the ball is totally in Walker’s court.</p><p>…Let me tell you a story. I went to graduate school at Harvard. Finest university in the world. My first day in a Harvard class, I was sitting with rapt attention, learning all sorts of interesting and important things (for reals; it was an amazing class that motivated me to become a statistician), sitting at one of those chairs with a desk attached to it, you know, the kind of chair where the desk part flips up so it’s in front of you, and, on the bottom of that desk was a wad of gum.</p><p>Back when I was in junior high, gum was almost a form of currency. I’d buy a pack of grape Bubble Yum for a quarter at the corner store on the way to school, then chew it in the morning during the endless hours between first period and lunch. I’d put one piece of gum in my mouth, chew it until it lost all its flavor, then add the second piece, chew it etc., and continue until I had a massive wad, all five pieces, ultimately flavorless, and I’d chew and chew and blow huge bubbles when the teacher wasn’t looking.</p><p>I’m not trying to make myself out into some big rebel here; the point is, we all did that. So of course there was yucky gum under all the desks. You knew to never run your hands under a desk, cos you never knew what might turn up. That was junior high.</p><p>Then in high school, everyone was much more mature, a lot less gum chewing . . . but still, gum under the desks. I took classes at the University of Maryland, a fine university with an OK basketball team . . . still, they had gum. Then I went to MIT, one of the finest engineering schools in the world . . . yup, gum. But Harvard? I’d hoped Harvard was better than that. But it wasn’t.</p><p>Anyway, that’s how I felt, learning that this purveyor of (possibly) horribly false claims is not just a professor of neuroscience at a top university—we know that top universities have lots of frauds—but was hired by Google. Google! Here I am, almost sixty years old (I don’t <em>feel</em> close to 60, but that’s my problem, not yours), and still there’s room for disillusionment.</p>'
- - https://guzey.com/books/why-we-sleep/
  - "Matthew Walker's <em>Why We Sleep</em> Is Riddled with Scientific and Factual Errors"
  - Alexey Guzey
  - 2019-11-15
  - ''
  - ! '<p>…In the process of reading the book and encountering some extraordinary claims about sleep, I decided to compare the facts it presented with the scientific literature. I found that the book consistently overstates the problem of lack of sleep, sometimes egregiously so. It misrepresents basic sleep research and contradicts its own sources.</p><p>In one instance, Walker claims that sleeping less than six or seven hours a night doubles one’s risk of cancer–this is not supported by the scientific evidence (Section 1.1). In another instance, Walker seems to have invented a “fact” that the WHO has declared a sleep loss epidemic (Section 4). In yet another instance, he falsely claims that the National Sleep Foundation recommends 8 hours of sleep per night, and then uses this “fact” to falsely claim that two-thirds of people in developed nations sleep less than the “the recommended eight hours of nightly sleep” (Section 5).</p><p>Walker’s book has likely wasted thousands of hours of life and worsened the health of people who read it and took its recommendations at face value (Section 7).</p><ul><li><ul><li><a href="https://guzey.com/books/why-we-sleep/#no-shorter-sleep-does-not-imply-shorter-life-span">No, shorter sleep does not imply shorter life span</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#also-no-sleeping-less-than-6-hours-a-night-does-not-double-your-risk-of-cancer">Also, no – sleeping less than 6 hours a night does not double your risk of cancer</a></li><li><a href="https://guzey.com/books/why-we-sleep/#how-much-confidence-should-we-place-in-epidemiological-sleep-data">How much confidence should we place in epidemiological sleep data?</a></li></ul></li><li><a href="https://guzey.com/books/why-we-sleep/#no-a-good-night-s-sleep-is-not-always-beneficial-sleep-deprivation-therapy-in-depression">No, a good night’s sleep is not always beneficial: sleep deprivation therapy in depression</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-lack-of-sleep-will-not-outright-kill-you">No, lack of sleep will not outright kill you</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-the-world-health-organization-never-declared-a-sleep-loss-epidemic">No, the World Health Organization never declared a sleep loss epidemic</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-two-thirds-of-adults-in-developed-nations-do-not-fail-to-obtain-the-recommended-amount-of-sleep">No, two-thirds of adults in developed nations do not fail to obtain the recommended amount of sleep</a></li><li><a href="https://guzey.com/books/why-we-sleep/#summary">Summary</a></li><li><a href="https://guzey.com/books/why-we-sleep/#the-potential-harm-done-by-the-book">The potential harm done by the book</a></li><li><a href="https://guzey.com/books/why-we-sleep/#conclusion">Conclusion</a></li><li><a href="https://guzey.com/books/why-we-sleep/#acknowledgements">Acknowledgments</a></li><li><a href="https://guzey.com/books/why-we-sleep/#citation">Citation</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-things-i-m-not-saying-in-this-essay">Appendix: things I’m <em>not</em> saying in this essay</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-people-who-sleep-just-6-hours-a-day-might-have-the-lowest-mortality">Appendix: people who sleep just 6 hours a day might have the lowest mortality</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-why-i-only-checked-chapter-1">Appendix: why I only checked Chapter 1</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-is-why-we-sleep-pop-science-or-is-it-an-academic-book-also-miscitations-impossible-numbers-and-walker-copy-pasting-papers">Appendix: is <em>Why We Sleep</em> pop-science or is it an academic book? Also, miscitations, impossible numbers, and Walker copy-pasting papers</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#three-papers-referring-to-why-we-sleep">Three papers referring to <em>Why We Sleep</em></a></li><li><a href="https://guzey.com/books/why-we-sleep/#two-papers-by-walker-citing-why-we-sleep">Two papers by Walker citing <em>Why We Sleep</em></a></li><li><a href="https://guzey.com/books/why-we-sleep/#walker-copy-pasting-papers">Walker copy-pasting papers</a></li><li><a href="https://guzey.com/books/why-we-sleep/#further-reading">Further reading</a></li></ul></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-common-objections">Appendix: common objections</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#walker-is-a-professor-of-psychology-and-neuroscience-at-berkeley-who-spent-more-than-20-years-studying-sleep-who-the-fuck-are-you">“Walker is a professor of psychology and neuroscience at Berkeley who spent more than 20 years studying sleep. Who the fuck are you?”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#the-mortality-sleep-j-curve-from-section-1-doesn-t-disprove-walker-s-the-shorter-your-sleep-the-shorter-your-life-span-first-the-association-between-long-sleep-and-short-life-span-is-generally-considered-to-reflect-underlying-comorbidities-that-prolong-time-in-bed-second-this-doesn-t-look-at-sleep-loss-or-sleep-extension-at-the-level-of-the-individual-person-and-if-you-look-at-the-individual-person-then-shorter-sleep-is-likely-to-be-associated-with-shorter-life">“The mortality/sleep J-curve from section 1 doesn’t disprove Walker’s ‘the shorter your sleep, the shorter your life span’. First, the association between long sleep and short life span is generally considered to reflect underlying comorbidities that prolong time in bed. Second, this doesn’t look at sleep loss or sleep extension at the level of the individual person and if you look at the individual person, then shorter sleep is likely to be associated with shorter life.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#only-checking-the-introduction-is-wrong-because-it-s-not-representative-of-the-rest-of-the-book-in-later-chapters-walker-is-much-more-rigorous">“Only checking the introduction is wrong because it’s not representative of the rest of the book. In later chapters, Walker is much more rigorous.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#but-don-t-many-people-get-8-9-hours-of-sleep-when-they-don-t-restrict-sleep">“But don’t many people get 8-9 hours of sleep when they don’t restrict sleep?”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#in-chapter-1-walker-writes-vehicular-accidents-caused-by-drowsy-driving-exceed-those-caused-by-alcohol-and-drugs-combined-this-shows-how-dangerous-it-is-to-not-sleep-and-you-have-not-refuted-this-part">“In Chapter 1, Walker writes ‘vehicular accidents caused by drowsy driving exceed those caused by alcohol and drugs combined’. This shows how dangerous it is to not sleep and you have not refuted this part.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#ok-maybe-sleep-and-longevity-are-not-positively-related-but-the-part-of-the-book-i-found-most-important-is-about-sleep-and-learning-for-example-in-chapter-7-walker-writes-that-a-memory-retention-benefit-of-between-20-and-40-percent-is-being-offered-by-sleep-this-shows-how-important-sleep-is-for-memory-and-you-have-not-refuted-this-part">“Ok, maybe sleep and longevity are not positively related, but the part of the book I found most important is about sleep and learning. For example, in Chapter 7, Walker writes that ‘a memory retention benefit of between 20 and 40 percent [is] being offered by sleep’. This shows how important sleep is for memory and you have not refuted this part.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#in-chapter-15-walker-writes-that-after-a-thirty-hour-shift-without-sleep-residents-make-a-whopping-460-percent-more-diagnostic-mistakes-in-the-intensive-care-unit-than-when-well-rested-after-enough-sleep-this-shows-how-dangerous-it-is-to-not-sleep-and-you-have-not-refuted-this-part">“In Chapter 15, Walker writes that ‘after a thirty-hour shift without sleep, residents make a whopping 460 percent more diagnostic mistakes in the intensive care unit than when well rested after enough sleep’. This shows how dangerous it is to not sleep and you have not refuted this part.”</a></li></ul></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-my-personal-experience-with-sleep">Appendix: my personal experience with sleep</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-the-concrete-harm-done-by-the-book">Appendix: the concrete harm done by the book</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-what-do-you-do-when-a-part-of-the-graph-contradicts-your-argument-you-cut-it-out-of-course">Appendix: what do you do when a part of the graph contradicts your argument? You cut it out, of course</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-a-strong-contender-for-the-single-most-absurd-paragraph-in-the-book">Appendix: a strong contender for the single most absurd paragraph in the book</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-sleep-and-testicles-sleep-and-testosterone">Appendix: sleep and testicles; sleep and testosterone</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-where-did-walker-get-his-phd">Appendix: where did Walker get his PhD?</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-serious-problems-in-chapter-8-found-by-a-reader">Appendix: serious problems in Chapter 8 found by a reader</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-fatal-familial-insomnia">Appendix: fatal familial insomnia</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix">Appendix</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#possible-origin-of-the-sleeplessness-epidemic-thing">Possible origin of the “sleeplessness epidemic” thing</a></li><li><a href="https://guzey.com/books/why-we-sleep/#what-you-can-learn-from-hunter-gatherers-sleeping-patterns">“What You Can Learn From Hunter-Gatherers’ Sleeping Patterns”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#most-sleep-does-not-serve-a-vital-function-evidence-from-drosophila-melanogaster">Most sleep does not serve a vital function: Evidence from Drosophila melanogaster</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-not-every-living-creature-generates-a-circadian-rhythm">No, not every living creature generates a circadian rhythm</a></li><li><a href="https://guzey.com/books/why-we-sleep/#extended-quote-about-the-dangers-of-lack-sleep-from-chapter-1">Extended quote about the dangers of lack sleep from Chapter 1</a></li><li><a href="https://guzey.com/books/why-we-sleep/#the-full-discussion-of-sleep-deprivation-therapy-from-chapter-7">The full discussion of sleep deprivation therapy from Chapter 7</a></li></ul></li></ul></li></ul>'
- - https://guzey.com/
  - Alexey Guzey homepage
  - Alexey Guzey
  - ''
  - ''
  - ! '<p>I’m an independent researcher with background in Economics, Mathematics, and Cognitive Science. My biggest intellectual influences are <a href="https://guzey.com/favorite/slate-star-codex/">Scott Alexander</a>, <a href="https://guzey.com/favorite/media/#podcasts">Dan Carlin</a>, <a href="https://amzn.to/2MIaxRJ">Scott Adams</a>, and <a href="http://www.gwern.net/">Gwern</a>.</p><p>Right now, I think about <a href="https://guzey.com/how-life-sciences-actually-work/">meta-science, biology</a> and <a href="https://guzey.com/patronage-and-research-labs/">philanthropy</a>. My long-term goal is to make the future humane, aesthetic, and to make it happen faster.</p><p>You can contact me at <a href="mailto:alexey@guzey.com">alexey@guzey.com</a> or via <a href="https://twitter.com/alexeyguzey">Twitter</a>, <a href="https://t.me/alexeyguzey">Telegram</a>, <a href="https://facebook.com/alexeyguzey">Facebook</a> or <a href="https://vk.com/alexeyguzey">VK</a></p>'
- - http://www.snowcrystals.com/
  - SnowCrystals.com
  - Kenneth G. Libbrecht
  - 1999-02-01
  - ''
  - ! 'Welcome to SnowCrystals.com! Your online guide to snowflakes, snow crystals, and other ice phenomena. SnowCrystals.com has been bringing you snowflake photos and facts since February 1, 1999. Over 26 million visitors so far! [Photos / books / science; designer snowflakes, how to grow snowflakes, "identical-twin" snowflakes etc]'
- - https://colab.research.google.com/github/nickwalton/AIDungeon/blob/master/AIDungeon_2.ipynb
  - AI Dungeon 2 Colab notebook
  - Nick Walton
  - 2019-12-14
  - ''
  - ! '<blockquote><p>AI Dungeon 2 is a completely AI generated text adventure built with OpenAI’s largest GPT-2 model. It’s a first of its kind game that allows you to enter and will react to any action you can imagine.</p></blockquote><p><em>What is this?</em></p><p>Google Colab is a way to experience machine learning for free. Google provides GPUs that you can run code in. Because this game exploded however, Google likely won’t be able to allow free usage of it for AI Dungeon for very long. We are almost done making an app version of the game where you will be able to play AI Dungeon 2. Until that’s released you can still play the game here.</p><p><em>Main mirrors of AI Dungeon 2 are currently down due to high download costs.</em></p><p>We are using BitTorrent as a temporary solution to host game files and keep this game alive. It’s not fast, but it’s the best we’ve got right now.</p><p>If you want to help, best thing you can do is to download this torrent file with game files and seed it indefinitely to the best of your ability. This will help new players download this game faster, and discover the vast worlds of AI Dungeon 2!</p><ul><li>Follow <span class="citation" data-cites="nickwalton00">[@nickwalton00]</span>(https://twitter.com/nickwalton00) on Twitter for updates on when it will be available again.</li><li><a href="https://www.patreon.com/AIDungeon">Support AI Dungeon 2 on Patreon</a> to help me to continue improving the game with all the awesome ideas I have for its future!</li></ul><p>How to play</p><ol type="1"><li>Click “Tools”-&gt; “Settings…” -&gt; “Theme” -&gt; “Dark” (optional but recommended)</li><li>Go to <strong>Main Game</strong> section below</li><li>Run Install block</li><li>Run Download Model block</li><li>It will then take a couple minutes to boot up as the model is downloaded loaded onto the GPU.</li><li>Run the game block</li><li>If you have questions about getting it to work then please go to github repo to get help.</li></ol>'
- - https://news.yahoo.com/shattered-inside-the-secret-battle-to-save-americas-undercover-spies-in-the-digital-age-100029026.html
  - "'Shattered': Inside the secret battle to save America's undercover spies in the digital age"
  - Jenna McLaughlin, Zach Dorfman (Yahoo News)
  - 2019-12-30
  - ''
  - ! '[Wide-ranging review of how social media, government database hacks, personal genomics, open-source intelligence, and pervasive surveillance are destroying traditional espionage, as undercover agents are unable to enter countries or recruit sources without being instantly exposed, forcing ever greater reliance on signals intelligence/hacking. Failures in OPSEC have resulted in entire countries going dark and the exposure of multiple US espionage networks and execution of sources, as well as embarrassing many countries when organizations like Bellingcat are able to expose agents and operations. While agencies like the FBI and CIA have begun adapting to the new reality, they have a long way to go, and countries like Russia or China or North Korea will only become harder to penetrate and obtain intelligence on.]'
- - /Turing-complete#how-many-computers-are-in-your-computer
  - "How Many Computers Are In Your Computer?"
  - Gwern Branwen
  - 2018-01-29
  - ''
  - ! '<p>Why are there so many places for backdoors and weird machines in your “computer”? Because your computer is in fact scores or hundreds, perhaps even thousands, of computer chips, many of which are explicitly or implicitly capable of Turing-complete computations (many more powerful than desktops of bygone eras), working together to create the illusion of a single computer. Backdoors, bugs, weird machines, and security do not care about what you think—only where resources can be found and orchestrated into a computation.</p>'
- - /Replication#further-reading
  - "The Replication Crisis: Further Reading"
  - Gwern Branwen
  - 2019-12-06
  - ''
  - ! '[A bibliography of online links to papers/blogs/articles on the Replication Crisis, primarily post-2013 and curated from my newsletter, as a followup to the main article text describing the Replication Crisis.]'
- - /docs/statistics/bias/1976-rosenthal-experimenterexpectancyeffects.pdf
  - "Experimenter Effects in Behavioral Research: Enlarged Edition"
  - Robert Rosenthal
  - '1976'
  - ''
  - ! '<p>Within the context of a general discussion of the unintended effects of scientists on the results of their research, this work reported on the growing evidence that the hypothesis of the behavioral scientist could come to serve as self-fulfilling prophecy, by means of subtle processes of communication between the experimenter and the human or animal research subject. [The <em>Science Citation Index</em> (<em>SCI</em>) and the <em>Social Sciences Citation Index</em> (<em>SSCI</em>) indicate that the book has been cited over 740 times since 1966 [as of 1979].] —<a href="http://garfield.library.upenn.edu/classics1979/A1979HZ32400001.pdf" title="CC/Number 27, 2 July 1979: This Week&#39;s Citation Classic">“Citation Classic”</a></p> [Enlarged Edition, expanded with discussion of the Pygmalion effect etc: ISBN 0-470-01391-5]'
- - https://www.oreilly.com/ideas/piracy-is-progressive-taxation-and-other-thoughts-on-the-evolution-of-online-distribution
  - "Piracy is progressive taxation, and other thoughts on the evolution of online distribution: Seven lessons from Tim O’Reilly’s experience as an author and publisher"
  - "Tim O'Reilly"
  - 2002-12-11
  - ''
  - ! '<p>The continuing controversy over online file sharing sparks me to offer a few thoughts as an author and publisher. To be sure, I write and publish neither movies nor music, but books. But I think that some of the lessons of my experience still apply.</p><ol type="1"><li><p><strong>Lesson 1: Obscurity is a far greater threat to authors and creative artists than piracy.</strong></p><p>…More than 100,000 books are published each year, with several million books in print, yet fewer than 10,000 of those new books have any significant sales, and only a hundred thousand or so of all the books in print are carried in even the largest stores…The web has been a boon for readers, since it makes it easier to spread book recommendations and to purchase the books once you hear about them. But even then, few books survive their first year or two in print. Empty the warehouses and you couldn’t give many of them away…</p></li><li><p><strong>Lesson 2: Piracy is progressive taxation</strong></p><p>For all of these creative artists, most laboring in obscurity, being well-enough known to be pirated would be a crowning achievement. Piracy is a kind of progressive taxation, which may shave a few percentage points off the sales of well-known artists (and I say “may” because even that point is not proven), in exchange for massive benefits to the far greater number for whom exposure may lead to increased revenues….</p></li><li><p><strong>Lesson 3: Customers want to do the right thing, if they can.</strong></p><p>…We’ve found little or no abatement of sales of printed books that are also available for sale online…The simplest way to get customers to stop trading illicit digital copies of music and movies is to give those customers a legitimate alternative, at a fair price.</p></li><li><p><strong>Lesson 4: Shoplifting is a bigger threat than piracy.</strong></p><p>…What we have is a problem that is analogous, at best, to shoplifting, an annoying cost of doing business. And overall, as a book publisher who also makes many of our books available in electronic form, we rate the piracy problem as somewhere below shoplifting as a tax on our revenues. Consistent with my observation that obscurity is a greater danger than piracy, shoplifting of a single copy can lead to lost sales of many more. If a bookstore has only one copy of your book, or a music store one copy of your CD, a shoplifted copy essentially makes it disappear from the next potential buyer’s field of possibility. Because the store’s inventory control system says the product hasn’t been sold, it may not be reordered for weeks or months, perhaps not at all. I have many times asked a bookstore why they didn’t have copies of one of my books, only to be told, after a quick look at the inventory control system: “But we do. It says we still have one copy in stock, and it hasn’t sold in months, so we see no need to reorder.” It takes some prodding to force the point that perhaps it hasn’t sold because it is no longer on the shelf…</p></li><li><p><strong>Lesson 5: File sharing networks don’t threaten book, music, or film publishing. They threaten existing publishers.</strong></p><p>…The question before us is not whether technologies such as peer-to-peer file sharing will undermine the role of the creative artist or the publisher, but how creative artists can leverage new technologies to increase the visibility of their work. For publishers, the question is whether they will understand how to perform their role in the new medium before someone else does. Publishing is an ecological niche; new publishers will rush in to fill it if the old ones fail to do so…Over time, it may be that online music publishing services will replace CDs and other physical distribution media, much as recorded music relegated sheet music publishers to a niche and, for many, made household pianos a nostalgic affectation rather than the home entertainment center. But the role of the artist and the music publisher will remain. The question then, is not the death of book publishing, music publishing, or film production, but rather one of who will be the publishers.</p></li><li><p><strong>Lesson 6: “Free” is eventually replaced by a higher-quality paid service</strong></p><p>A question for my readers: How many of you still get your email via peer-to-peer UUCP dialups or the old “free” Internet, and how many of you pay $19.95 a month or more to an ISP? How many of you watch “free” television over the airwaves, and how many of you pay $20–$60 a month for cable or satellite television? (Not to mention continue to rent movies on videotape and DVD, and purchasing physical copies of your favorites.) Services like Kazaa flourish in the absence of competitive alternatives. I confidently predict that once the music industry provides a service that provides access to all the same songs, freedom from onerous copy-restriction, more accurate metadata and other added value, there will be hundreds of millions of paying subscribers…Another lesson from television is that people prefer subscriptions to pay-per-view, except for very special events. What’s more, they prefer subscriptions to larger collections of content, rather than single channels. So, people subscribe to “the movie package,” “the sports package” and so on. The recording industry’s “per song” trial balloons may work, but I predict that in the long term, an “all-you-can-eat” monthly subscription service (perhaps segmented by musical genre) will prevail in the marketplace.</p></li><li><p><strong>Lesson 7: There’s more than one way to do it.</strong></p><p>A study of other media marketplaces shows, though, that there is no single silver-bullet solution. A smart company maximizes revenue through all its channels, realizing that its real opportunity comes when it serves the customer who ultimately pays its bills….Interestingly, some of our most successful print/online hybrids have come about where we present the same material in different ways for the print and online contexts. For example, much of the content of our bestselling book Programming Perl (more than 600,000 copies in print) is available online as part of the standard Perl documentation. But the entire package–not to mention the convenience of a paper copy, and the aesthetic pleasure of the strongly branded packaging–is only available in print. Multiple ways to present the same information and the same product increase the overall size and richness of the market. And that’s the ultimate lesson. “Give the Wookiee what he wants!” as Han Solo said so memorably in the first <em>Star Wars</em> movie. Give it to him in as many ways as you can find, at a fair price, and let him choose which works best for him.</p></li></ol>'
- - /docs/psychology/okcupid/themathematicsofbeauty.html
  - The Mathematics Of Beauty
  - Christian Rudder (OKCupid)
  - 2011-01-10
  - ''
  - ! '<p>[Today’s dataset: 1.54m votes, 596k messages, 64k profiles.]</p><p>This post investigates female attractiveness, but without the usual photo analysis stuff. Instead, we look <em>past</em> a woman’s picture, into the reaction she creates in the reptile mind of the human male. Among the remarkable things we’ll show:</p><ul><li>that the more men as a group <em>disagree</em> about a woman’s looks, the more they end up liking her</li><li>guys tend to ignore girls who are merely <em>cute</em></li><li>and, in fact, having some men think she’s <em>ugly</em> actually works in woman’s favor</li></ul><p>…Now let’s look back at the two real users from before, this time with their own graphs. OkCupid uses a <em>1 to 5 star</em> system for rating people, so the rest of our discussion will be in those terms. All the users pictured were generous and confident enough to allow us to dissect their experience on our site, and we appreciate it. Okay, so we have: […] As you can see, though the average attractiveness for the two women above is very close, their vote patterns differ. On the left you have consensus, and on the right you have split opinion.</p><p>To put a fine point on it:</p><ul><li>Ms. Left is, in an absolute sense, considered slightly <em>more attractive</em></li><li>Ms. Right was also given the <em>lowest rating</em> 142% more often</li><li>yet Ms. Right gets <em>3×</em> as many messages</li></ul><p>When we began pairing other people of similar looks and profiles, but different message outcomes, this pattern presented itself again and again. The less-messaged woman was usually considered <em>consistently attractive</em>, while the more-messaged woman often created <em>variation</em> in male opinion…Our first result was to compare the standard deviation of a woman’s votes to the messages she gets. The more men disagree about a woman’s looks, the more they like her. I’ve plotted the deviation vs. messages curve below, again including some examples…</p>'
- - http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/
  - "Goodbooks-10k: a new dataset for book recommendations"
  - Zygmunt Z. (FastML)
  - 2017-11-29
  - ''
  - ! '<p>There have been a few recommendations datasets for movies (Netflix, Movielens) and music (Million Songs), but not for books. That is, until now. The dataset contains six million ratings for ten thousand most popular books (with most ratings). There are also:</p><ul><li>books marked to read by the users</li><li>book metadata (author, year, etc.)</li><li>tags/shelves/genres</li></ul><p>As to the source, let’s say that these ratings come from a site similar to <code>goodreads.com</code>, but with more permissive terms of use. There are a few types of data here:</p><ul><li>explicit ratings</li><li>implicit feedback indicators (books marked to read)</li><li>tabular data (book info)</li><li>tags</li></ul><p>…<a href="https://github.com/zygmuntz/goodbooks-10k">All files</a> are available on GitHub. Some of them are quite large, so GitHub won’t show their contents online. See <a href="https://github.com/zygmuntz/goodbooks-10k/tree/master/samples">samples</a> for smaller CSV snippets. You can download individual zipped files from <a href="https://github.com/zygmuntz/goodbooks-10k/releases">releases</a>.</p>'
- - https://github.com/zygmuntz/goodbooks-10k
  - "<code>goodbooks-10k</code>: Ten thousand books, six million ratings: http://fastml.com/goodbooks-10k"
  - Zygmunt Z. (FastML)
  - 2017-11-29
  - ''
  - ! '<h1 id="goodbooks-10k">goodbooks-10k</h1><p>This dataset contains six million ratings for ten thousand most popular (with most ratings) books. There are also:</p><ul><li>books marked to read by the users</li><li>book metadata (author, year, etc.)</li><li>tags/shelves/genres</li></ul><h2 id="access">Access</h2><p>Some of these files are quite large, so GitHub won’t show their contents online. See <a href="https://github.com/zygmuntz/goodbooks-10k/samples/">samples/</a> for smaller CSV snippets.</p><p>Open the <a href="https://github.com/zygmuntz/goodbooks-10k/quick_look.ipynb">notebook</a> for a quick look at the data. Download individual zipped files from <a href="https://github.com/zygmuntz/goodbooks-10k/releases">releases</a>.</p><p>The dataset is accessible from <a href="https://maciejkula.github.io/spotlight/datasets/goodbooks.html">Spotlight</a>, recommender software based on PyTorch.</p><h2 id="contents">Contents</h2><p><strong>ratings.csv</strong> contains ratings sorted by time. It is 69MB and looks like that:</p><pre><code>user_id,book_id,rating1,258,52,4081,42,260,52,9296,52,2318,3</code></pre><p>Ratings go from one to five. Both book IDs and user IDs are contiguous. For books, they are 1-10000, for users, 1-53424.</p><p><strong>to_read.csv</strong> provides IDs of the books marked “to read” by each user, as <em>user_id,book_id</em> pairs, sorted by time. There are close to a million pairs.</p><p><strong>books.csv</strong> has metadata for each book (goodreads IDs, authors, title, average rating, etc.). The metadata have been extracted from goodreads XML files, available in <code>books_xml</code>.</p><h3 id="tags">Tags</h3><p><strong>book_tags.csv</strong> contains tags/shelves/genres assigned by users to books. Tags in this file are represented by their IDs. They are sorted by <em>goodreads_book_id</em> ascending and <em>count</em> descending.</p><p>In raw XML files, tags look like this:</p><pre><code>&lt;popular_shelves&gt;    &lt;shelf name=&quot;science-fiction&quot; count=&quot;833&quot;/&gt;    &lt;shelf name=&quot;fantasy&quot; count=&quot;543&quot;/&gt;    &lt;shelf name=&quot;sci-fi&quot; count=&quot;542&quot;/&gt;    ...    &lt;shelf name=&quot;for-fun&quot; count=&quot;8&quot;/&gt;    &lt;shelf name=&quot;all-time-favorites&quot; count=&quot;8&quot;/&gt;    &lt;shelf name=&quot;science-fiction-and-fantasy&quot; count=&quot;7&quot;/&gt;&lt;/popular_shelves&gt;</code></pre><p>Here, each tag/shelf is given an ID. <strong>tags.csv</strong> translates tag IDs to names.</p><h3 id="goodreads-ids">goodreads IDs</h3><p>Each book may have many editions. <em>goodreads_book_id</em> and <em>best_book_id</em> generally point to the most popular edition of a given book, while goodreads <em>work_id</em> refers to the book in the abstract sense.</p><p>You can use the goodreads book and work IDs to create URLs as follows:</p><pre><code>https://www.goodreads.com/book/show/2767052https://www.goodreads.com/work/editions/2792775</code></pre><p>Note that <em>book_id</em> in <strong>ratings.csv</strong> and <strong>to_read.csv</strong> maps to <em>work_id</em>, not to <em>goodreads_book_id</em>, meaning that ratings for different editions are aggregated.</p>'
- - https://ukiyo-e.org/
  - Ukiyo-e Search
  - John Resig
  - '2013'
  - ''
  - ! '<p>"Japanese Woodblock Print Search: Ukiyo-e Search provides an incredible resource: The ability to both search for Japanese woodblock prints by simply taking a picture of an existing print AND the ability to see similar prints across multiple collections of prints.</p><p>…The Ukiyo-e.org database and image similarity analysis engine, created by <a href="https://johnresig.com/about/">John Resig</a> to aide researchers in the study of Japanese woodblock prints, was launched in December 2012. The database currently contains over 213,000 prints from 24 institutions and, as of September 2013, has received 3.4 million page views from 150,000 people.</p><p>The database has the following major features:</p><ul><li>A database of Japanese woodblock print images and metadata aggregated from a variety of museums, universities, libraries, auction houses, and dealers around the world.</li><li>An indexed text search engine of all the metadata provided by the institutions about the prints.</li><li>An image search engine of all the images in the database, searchable by uploading an image of a print.</li><li>Each print image is analyzed and compared against all other print images in the database. Similar prints are displayed together for comparison and analysis.</li><li>Multiple copies of the same print are automatically lined up with each other and made viewable in a gallery for easy comparison.</li><li>The entire web site, and all artist information contained within it, is available in both English and Japanese, aiding international researchers.</li></ul><p>These features, available in the Ukiyo-e.org database, are already providing researchers with substantial benefit. New copies of prints have been located by scholars at museums. Museums have been able to correct unattributed prints, finding the correct artist. Prints have been identified by lay people who cannot read Japanese and/or are unable to interpret the imagery depicted in a print.</p><p>It is challenging to reconcile information from numerous databases, many of which are in different languages. The difficulty of finding and utilizing an effective image similarity search engine, one that is capable of working with images of different sizes, colors, or even in black-and-white, is a point that deserves considerable attention.</p><p>The Ukiyo-e.org database is already significantly impacting Japanese woodblock print studies and may have implications for visual art research and digital humanities at large.</p>'
- - https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/
  - "A Very Unlikely Chess Game"
  - Scott Alexander
  - 2020-01-06
  - ''
  - ! '<p>Black is GPT-2. Its excuse is that it’s a text prediction program with no concept of chess. As far as it knows, it’s trying to predict short alphanumeric strings like “e2e4” or “Nb7”. Nobody told it this represents a board game. It doesn’t even have a concept of 2D space that it could use to understand such a claim. But it still captured my rook! Embarrassing! … Last month, I asked him if he thought GPT-2 could play chess. I wondered if he could train it on a corpus of chess games written in standard notation (where, for example, e2e4 means “move the pawn at square e2 to square e4”). There are literally millions of games written up like this. GPT-2 would learn to predict the next string of text, which would correspond to the next move in the chess game. Then you would prompt it with a chessboard up to a certain point, and it would predict how the chess masters who had produced its training data would continue the game – ie make its next move using the same heuristics they would. Gwern handed the idea to his collaborator Shawn Presser, who had a working GPT-2 chess engine running <em>within</em> a week: … You can play against GPT-2 yourself by following the directions in the last tweet, though it won’t be much of a challenge for anyone better than I am.</p><p>…What does this imply? I’m not sure (and maybe it will imply more if someone manages to make it actually good). It was already weird to see something with no auditory qualia learn passable poetic meter. It’s even weirder to see something with no concept of space learn to play chess. Is any of this <a href="https://slatestarcodex.com/2019/02/28/meaningful/">meaningful</a>? How impressed should we be that the same AI can write poems, compose music, and play chess, without having been designed for any of those tasks? I still don’t know.</p><p>[See also <a href="https://arxiv.org/abs/2007.03500">Noever et al 2020</a> who apply GPT-2 to Go SGF games.]</p>'
- - https://foundational-research.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf
  - Multiverse-wide Cooperation via Correlated Decision Making
  - Caspar Oesterheld
  - 2018-01-29
  - ''
  - ! 'Some decision theorists argue that when playing a prisoner’s dilemma-type game against a sufficiently similar opponent, we should cooperate to make it more likely that our opponent also cooperates. This idea, which Hofstadter calls superrationality, has strong implications when combined with the insight from modern physics that we probably live in a large universe or multiverse of some sort. If we care about what happens in civilizations located elsewhere in the multiverse, we can superrationally cooperate with some of their inhabitants. That is, if we take their values into account, this makes it more likely that they do the same for us. In this paper, I attempt to assess the practical implications of this idea. I argue that to reap the full gains from trade, everyone should maximize the same impartially weighted sum of the utility functions of all collaborators. I also argue that we can obtain at least weak evidence about the content of these utility functions. In practice, the application of superrationality implies that we should promote causal cooperation, moral pluralism, moral reflection, and ensure that our descendants, who will be smarter and thus better at finding out how to benefit other superrationalists in the universe, engage in superrational cooperation.'
- - https://possiblywrong.wordpress.com/2019/04/06/follow-up-i-found-two-identical-packs-of-skittles-among-468-packs-with-a-total-of-27740-skittles/
  - "Follow-up: I found two identical packs of Skittles, among 468 packs with a total of 27,740 Skittles"
  -  E.R. Farmer
  - 2019-04-06
  - ''
  - ! '<p>This is a follow-up to <a href="https://possiblywrong.wordpress.com/2019/01/09/identical-packs-of-skittles/" title="Identical packs of Skittles">a post from earlier this year</a> discussing the likelihood of encountering two identical packs of Skittles, that is, two packs having exactly the same number of candies of each flavor. Under some reasonable assumptions, it was estimated that we should expect to have to inspect “only about 400-500 packs” on average until encountering a first duplicate. This is interesting, because as described in that earlier post, there are millions of different possible packs– or even if we discount those that are much less likely to occur (like, say, a pack of nothing but red Skittles), then there are still hundreds of thousands of different “likely” packs that we might expect to encounter.</p><p>So, on 12 January of this year, I started buying boxes of packs of Skittles. This past week, “only” 82 days, 13 boxes, 468 packs, and 27,740 individual Skittles later, I found the following identical 2.17-ounce packs.</p><p>…this seemed like a great opportunity to demonstrate the <em>predictive power</em> of mathematics. A few months ago, we did some calculations on a cocktail napkin, so to speak, <em>predicting</em> that we should be able to find a pair of identical packs of Skittles with a reasonably–and perhaps surprisingly–small amount of effort. Actually seeing that effort through to the finish line can be a vivid demonstration for students of this predictive power of what might otherwise be viewed as “merely abstract” and not concretely useful mathematics.</p>'
- - /docs/philo/1969-west.pdf
  - An Atomist Illustration In Aristotle
  - Martin L. West
  - '1969'
  - 10.1524/phil.1969.113.12.150
  - ! '<p>[Textual criticism of translations/interpretations of <a href="http://classics.mit.edu/Aristotle/gener_corr.1.i.html">a Democritus passage in Aristotle</a>. West argues that the translation of a passage generally translated as the generic observation</p><blockquote><p>Tragedy and comedy come out of the same letters.</p></blockquote><p>or the more abstract observation</p><blockquote><p>Tragedy and Comedy come out of the same letters.</p></blockquote><p>should be read as Democritus engaged in word play:</p><blockquote><p>For ‘Tragedy’ [<em>τρ<strong>α</strong>γωδία</em>] and ‘Comedy’ [<em>τρ<strong>υ</strong>γωδία</em>] come to be out of the same letters.</p></blockquote><p>Because the surrounding passage in Aristotle strongly implies that Democritus is defending the position that small changes (in atoms) can yield large changes (in observed appearance or behavior or property), in the same way that a word can alter its meaning completely based on a single letter (emphasis added):</p><blockquote><p>A similar criticism applies to all our predecessors with the single exception of Democritus. Not one of them penetrated below the surface or made a thorough examination of a single one of the problems. Democritus, however, does seem not only to have thought carefully about all the problems, but also to be distinguished from the outset by his method. For, as we are saying, none of the other philosophers made any definite statement about growth, except such as any amateur might have made. They said that things grow ‘by the accession of like to like’, but they did not proceed to explain the manner of this accession. Nor did they give any account of ‘combination’: and they neglected almost every single one of the remaining problems, offering no explanation, e.g. of ‘action’ or ‘passion’ how in physical actions one thing acts and the other undergoes action. Democritus and Leucippus, however, postulate the ‘figures’, and make ‘alteration’ and coming-to-be result from them. They explain coming-to-be and passing-away by their ‘dissociation’ and ‘association’, but ‘alteration’ by their ‘grouping’ and ‘Position’. And since they thought that the ‘truth lay in the appearance, and the appearances are conflicting and infinitely many, they made the ’figures’ infinite in number. <em>Hence—owing to the changes of the compound—the same thing seems different and conflicting to different people: it is ‘transposed’ by a small additional ingredient, and appears utterly other by the ‘transposition’ of a <strong>single</strong> constituent.</em> [For Tragedy and Comedy are both composed of the same letters.]</p></blockquote><p>West states that if Democritus had not intended this wordplay, he would have used other terms for ‘tragedy’ and ‘comedy’. Hence not using his alternative reading and translation renders the passage ‘unintelligble’.]</p>'
- - /Scanners#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite
  - "How often do researchers not read the papers they cite?"
  - Gwern Branwen
  - 2019-10-07
  - ''
  - ! 'One fertile source of leprechauns seems to be the observation that researchers do not read many of the papers that they cite in their own papers. The frequency of this can be inferred from pre-digital papers, based on bibliographic errors: if a citation has mistakes in it, such that one could not have actually looked up the paper in a library or database, and those mistakes were copied from another paper, then the authors almost certainly did not read the paper (otherwise they would have fixed the mistakes when they found them out the hard way) and simply copied the citation. The empirically-measured spread of bibliographic errors suggest that researchers frequently do not read the papers they cite. The frequency can be further confirmed by examining citations to see when the citers misdescribe the original paper, "quotation errors", showing that the errors involved are substantial and not merely bibliographic. ... How often do authors not read their cites? This might seem near-impossible to answer, but bibliographic analysis offers a cute trick. In olden times, citations and bibliographies had to be compiled by hand; this is an error-prone process, but one may make a different error from another author citing the same paper, and one might correct any error on reading the original. On the other hand, if you cite a paper because you blindly copied the citation from another paper and never get around to reading it, you may introduce additional errors but you definitely won''t fix any error in what you copied. So one can get an idea of how frequent non-reads are by <em>tracing lineages of bibliographic errors</em>: the more people copy around the same wrong version of a citation (out of the total set of citations for that cite), the fewer of them must be actually reading it. Such copied errors turn out to be quite common and represent a large fraction of citations, and thus suggests that many paper are being cited without being read. Simkin & Roychowdhury venture a guess that as many as 80% of authors citing a paper have not actually read the original. [Bibliography of papers in the area.]'
- - https://www.lesswrong.com/posts/NkjPp86uuyunxDoB8/subscripting-typographic-convention-for-citations-dates
  - "Subscripting Typographic Convention For Citations/Dates/Sources/Evidentials: A Proposal"
  - Gwern Branwen
  - 2020-01-08
  - ''
  - ! '<p>Reviving an old General Semantics proposal: borrowing from scientific notation and using subscripts like ‘Gwern<sub>2020</sub>’ for denoting sources (like citation, timing, or medium) might be a useful trick for clearer writing, compared to omitting such information or using standard cumbersome circumlocutions.</p>'
- - https://www.tandfonline.com/doi/full/10.1080/10510974.2019.1692884
  - "What’s in a Font?: Ideological Perceptions of Typography"
  - Katherine Haenschen, Daniel J. Tamul
  - 2019-12-20
  - '10.1080/10510974.2019.1692884'
  - ! 'Although extensive political communication research considers the content of candidate messages, scholars have largely ignored how those words are rendered–specifically, the typefaces in which they are set. If typefaces are found to have political attributes, that may impact how voters receive campaign messages. Our paper reports the results of two survey experiments demonstrating that individuals perceive typefaces, type families, and type styles to have ideological qualities. Furthermore, partisanship moderates subjects’ perceptions of typefaces: Republicans generally view typefaces as more conservative than Independents and Democrats. We also find evidence of affective polarization, in that individuals rate typefaces more favorably when perceived as sharing their ideological orientation. Results broaden our understanding of how meaning is conveyed in political communication, laying the groundwork for future research into the functions of typography and graphic design in contemporary political campaigns. Implications for political practitioners are also discussed. Keywords: Political communication, ideology, partisanship, typeface, graphic design. [Ranking: Blackletter, Times New Roman, Jubilat, Gill Sans, Birds of Paradise, Century Gothic, Sunrise.]'
- - https://slatestarcodex.com/2020/01/08/what-intellectual-progress-did-i-make-in-the-2010s/
  - "What Intellectual Progress Did I Make In The 2010s?"
  - Scott Alexander
  - 2020-01-08
  - ''
  - ! '<p>[Scott Alexander look back on how his ideas/beliefs evolved over the past decade of blogging at Jackdaws/LessWrong/SlateStarCodex. Primary topics:</p><ol type="1"><li><p>Bayesian predictive coding as a unified theory of brain perception, control, behavior, and psychiatric disorders as bad priors/updates</p><ul><li>Psychedelics use as modifying brain priors, explaining how psychedelics affect and sometimes benefit their users</li><li>trauma/attachment disorder</li></ul></li><li><p>Philosophy of mental disease</p></li><li><p>efficacy of SSRIs</p></li><li><p>Genetics of psychiatric disorders, especially autism/transsexuals: ???</p></li><li><p>Willpower: also predictive coding???</p></li><li><p>Diet/weight loss: setpoints, somehow</p></li><li><p>Existential risk: dissolving the Great Filter, raising AI risk awareness</p></li><li><p>Secular stagnation: progress is slowing, perhaps because human populations aren’t growing exponentially</p><ul><li>Baumol’s cost disease as core cause of economic stagnation and political backlash</li></ul></li><li><p>The Replication Crisis: even worse than he thought</p></li><li><p>Psychological effects:</p><ul><li>Placebo effect: much more powerless than he thought</li><li>Birth order effects: much more powerful than he thought</li></ul></li><li><p>Utilitarianism: still confused, but more towards rule-utilitarianism</p></li><li><p>Politics: social media turbocharging tribalism/outgroup-bias</p></li><li><p>Ideology of liberalism and SJWism</p></li><li><p>Coordination problems as core problem of politics</p></li><li><p>Enlightenment: not actually that great, possibly wireheading]</p></li></ol>'
- - /docs/iq/smpy/1994-subotnik-beyondterman.pdf
  - "Beyond Terman: contemporary longitudinal studies of giftedness and talent"
  - Rena F. Subotnik, Karen D. Arnold
  - '1994'
  - ''
  - ! '<p><em>Beyond Terman: Contemporary Longitudinal Studies of Giftedness and Talent</em> is an important contribution to the literature in two fields—those of gifted education and educational research. It is significant for the former in terms of the insights and understandings it provides about giftedness and its nurture. It is important for the latter for its elucidations of the methodology associated with longitudinal research. The editors point out that “[the] volume presents recent collected works that demonstrate the fit between longitudinal methodology and the central issues of gifted education. Collectively, the studies investigate the early determinants of later academic and career achievement and creativity while employing varied identification practices, perspectives, theoretical orientations, and populations.”</p><p>The studies described vary along many dimensions, including research problem, sample size and character, length of study, data collection procedures and sources, and longitudinal orientation (i.e., emergent/developmental or retrospective). The studies deal with a variety of talent areas, such as academic achievement, science, technical creativity, music, creative and productive thinking, and career development. The samples include gifted and talented children, youths, and adults, both males and females. Although most of the studies deal with identified gifted/talented individuals, one is a retrospective look at the achievements of graduate students in a university-level leadership education program. Studies originating in Germany and Israel add an international flavor and, more importantly, remind us that there is good research being conducted beyond the borders of the U.S.</p><p>As the premiere longitudinal investigation of a gifted population, the Terman study set a standard of comprehensiveness, large study sample, and societal influence that is difficult to supersede. In spite of the Terman study’s large number of research associates and rich sources of funding support, the data are still being organized for more accurate statistical analysis and examined for more challenging research questions. Further, the <em>Genetic Studies of Genius</em> and its more current follow-ups did not address key questions of concern in today’s social, political, and historical climate, or issues of central importance in the future. The investigations in this book have established a groundwork for answering previously unanswered questions: Are we identifying the “right” people? What are the outcomes associated with various forms of identification and intervention?</p><p>Over the course of his long career, Terman’s perspective on high IQ as a source for potential genius changed to allow personality, interest, special abilities, and opportunity to play a growing role in adult achievement. In filling a vacuum left by Terman, this collection of contemporary studies can guide policy and program development based on the conditions and interventions that contribute to the fulfillment of talent.</p>'
- - /docs/japanese/1997-tsuzuki-tokyoacertainstyle.pdf
  - "Tokyo: A Certain Style"
  - Kyoichi Tsuzuki
  - '1997'
  - ''
  - ! '<p>Writer-photographer Kyoichi Tsuzuki visited a hundred apartments, condos, and houses, documenting what he saw in more than 400 color photos that show the real Tokyo style—a far cry from the serene gardens, shoji screens, and Zen minimalism usually associated with Japanese dwellings.</p> <p>In <em>this</em> Tokyo, necessities such as beds, bathrooms, and kitchens vie for space with electronic gadgets, musical instruments, clothes, books, records, and kitschy collectibles. Candid photos vividly capture the dizzying “cockpit effect”of living in a snug space crammed floor to ceiling with stuff. And it’s not just bohemian types and students who must fit their lives and work into tight quarters, but professionals and families with children, too. In descriptive captions, the inhabitants discuss the ingenious ways they’ve adapted their home environments to suit their diverse lifestyles.</p>'
- - /docs/music-distraction/2012-perham.pdf
  - Disliked Music can be Better for Performance than Liked Music
  - Nick Perham, Martinne Sykora
  - 2012-01-12
  - 10.1002/acp.2826
  - 'Although liked music is known to improve performance through boosting one’s mood and arousal, both liked music and disliked music impair serial recall performance. Given that the key acoustical feature of this impairment is the acoustical variation, it is possible that some music may contain less acoustical variation and so produce less impairment. In this situation, unliked, unfamiliar music could be better for performance than liked, familiar music. This study tested this by asking participants to serially recall eight-item lists in either quiet, liked or disliked music conditions. Results showed that performance was significantly poorer in both music conditions compared with quiet. More importantly, performance in the liked music condition was significantly poorer than in the disliked music condition. These findings provide further illustration of the irrelevant sound effect and limitations of the impact of liked music on cognition.'
- - /docs/predictions/2001-armstrong-principlesforecasting.pdf
  - "Principles of Forecasting: A Handbook for Researchers and Practitioners"
  - J. Scott Armstrong
  - '2001'
  - ''
  - ! '<p>Forecasting is important in many aspects of our lives. As individuals, we try to predict success in our marriages, occupations, and investments. Organizations invest enormous amounts based on forecasts for new products, factories, retail outlets, and contracts with executives. Government agencies need forecasts of the economy, environmental impacts, new sports stadiums, and effects of proposed social programs.</p> <p>The purpose of this book is to summarize knowledge of forecasting as a set of principles. These “principles” represent advice, guidelines, prescriptions, condition-action statements, and rules. We expect principles to be supported by empirical evidence. For this book, however, I asked authors to be ambitious in identifying principles for forecasting by including those based on expert judgment and even those that might be speculative. The authors describe the evidence so that you can judge how much confidence can be placed in the principles.</p> <P>To summarize the findings, I invited 39 leading researchers to describe principles in their areas of expertise...Most of the book is devoted to descriptions of forecasting methods, discussions of the conditions under which they are most useful, and summaries of the evidence.</p>'
- - /docs/radiance/1984-berger.pdf
  - "The Astounding Investigation: The Manhattan Project's Confrontation With Science Fiction, published in <em>Analog Science Fiction/Science Fact</em>"
  - Albert I. Berger
  - '1984-09-01'
  - ''
  - ! '<p>In the spring of 1944, agents from the Manhattan Project’s security division interviewed Cleve Cartmill and John Campbell in the wake of Campbell’s publication of Cartmill’s short story “‘Deadline’’ in the March, 1944 issue of <em>Astounding Science Fiction</em>, in which U-235 had been separated from non-fissionable isotopes and was ready to be detonated in a functional bomb, whose details were described. As described, Cartmill’s bomb would not work; and it did not resemble the uranium bomb being built by the Manhattan Project. However, suspecting a leak from the Project (whose most difficult engineering problem with uranium was its separation into fissionable and non-fissionable isotopes), agents interviewed both author and editor.”Where did you get this idea?"</p><p>The incident has become part of science fiction folklore. Campbell spoke of it often before his death, and it is often referred to by members of the <em>Analog Science Fiction/Science Fact</em> science fiction community, usually in the context of discussing the genre’s anticipation of actual scientific and technological developments. However, the military intelligence agents kept records of the investigation, records which have just been released in response to a request under the Freedom of Information Act. Seven separate documents, comprising some 39 pages of reports and memoranda filed under Cleve Cartmill’s name, show just how the people who were guarding the building of the real atomic bomb responded to the news that a disreputable pulp fiction magazine was apparently keeping pace with this recent and most secret research. Coincidentally, they shed light on Astounding’s fabled editorial practices just as World War II was disrupting the ‘‘stable’’ of famous science fiction writers John Campbell had assembled there between 1937 and 1941.</p><p>The Manhattan Project sought to provide internal security through compartmentalization. Only at the very top, and on a need-to-know basis, were the participants supposed to know what they were working on. Campbell and Cartmill had created a problem by naming what was intended to be unnameable: the near-term practical possibility of an atomic bomb. Campbell seems to have known something was up: “I’m stating fact, not theory,” he had written to Cartmill. Cartmill was afraid before he began writing that “Deadline” would do exactly what it did do: inadvertently call attention to a real bomb project. As contemptuous as Project security and the censor were of science fiction, they were also little afraid of precisely what Campbell’s science fiction did best: putting scattered bits of scientific knowledge together into a specific, concrete idea or device, and speculating on what that idea or device’s impact might be on the world at large. That kind of speculation represents a way of thinking distinctly at odds with those of bureaucracies like the Manhattan Project. The latter are often perfectly aware that two and two add up to four, but they equally often want to control the distribution of that news, for legitimate (as in this case perhaps) as frequently as for disreputable reasons.</p><p>So the affair represents more than just the anecdote which it has become. Cartmill’s letters reveal many of the constraints under which Campbell labored during the war; the affair as a whole shows the extremely casual way in which Campbell regarded so-called “voluntary censorship”. But that casualness, juxtaposed with the grim concern for control and fear of undue speculation on the part of the Project, marks an early and quite concrete example of the tension between the imagination engendered by science fiction and the concerns of the giant bureaucracies (governmental or private) which have so dominated scientific research and technological development since the end of World War II. It is probably belaboring <em>Analog</em> readers to remind them that that tension has furnished themes for more than a generation of science fiction stories.</p>'
- - /docs/statistics/bayes/1814-laplace-philosophicalessayonprobabilities-ch5probabilitiestestimonies.pdf
  - "Philosophical Essay on Probabilities, Chapter 11: Concerning the Probabilities of Testimonies"
  - Pierre-Simon Laplace
  - '1814'
  - ''
  - ! '<p>The majority of our opinions being founded on the probability of proofs it is indeed important to submit it to calculus. Things it is true often become impossible by the difficulty of appreciating the veracity of witnesses and by the great number of circumstances which accompany the deeds they attest; but one is able in several cases to resolve the problems which have much analogy with the questions which are proposed and whose solutions may be regarded as suitable approximations to guide and to defend us against the errors and the dangers of false reasoning to which we are exposed. An approximation of this kind, when it is well made, is always preferable to the most specious reasonings.</p> <p>We would give no credence to the testimony of a man who should attest to us that in throwing a hundred dice into the air they had all fallen on the same face. If we had ourselves been spectators of this event we should believe our own eyes only after having carefully examined all the circumstances, and after having brought in the testimonies of other eyes in order to be quite sure that there had been neither hallucination nor deception. But after this examination we should not hesitate to admit it in spite of its extreme improbability; and no one would be tempted, in order to explain it, to recur to a denial of the laws of vision. We ought to conclude from it that the probability of the constancy of the laws of nature is for us greater than this, that the event in question has not taken place at all a probability greater than that of the majority of historical facts which we regard as incontestable. One may judge by this the immense weight of testimonies necessary to admit a suspension of natural laws, and how improper it would be to apply to this case the ordinary rules of criticism. All those who without offering this immensity of testimonies support this when making recitals of events contrary to those laws, decrease rather than augment the belief which they wish to inspire; for then those recitals render very probable the error or the falsehood of their authors. But that which diminishes the belief of educated men increases often that of the uneducated, always greedy for the wonderful.</p> <p>The action of time enfeebles then, without ceasing, the probability of historical facts just as it changes the most durable monuments. One can indeed diminish it by multiplying and conserving the testimonies and the monuments which support them. Printing offers for this purpose a great means, unfortunately unknown to the ancients. In spite of the infinite advantages which it procures the physical and moral revolutions by which the surface of this globe will always be agitated will end, in conjunction with the inevitable effect of time, by rendering doubtful after thousands of years the historical facts regarded to-day as the most certain.</p>'
- - /docs/statistics/decision/1959-schlaifer-probabilitystatisticsbusinessdecisions.pdf
  - 'Probability and Statistics for Business Decisions: An Introduction to Managerial Economics Under Uncertainty'
  - Robert Schlaifer
  - '1959'
  - ''
  - ! '<p>This book is a non-mathematical introduction to the logical analysis of practical business problems in which a decision must be reached under uncertainty. The analysis which it recommends is based on the modern theory of utility and what has come to be known as the “‘personal”’ definition of probability; the author believes, in other words, that when the consequences of various possible courses of action depend on some unpredictable event, the practical way of choosing the ‘‘best’’ act is to assign values to consequences and probabilities to events and then to select the act with the highest expected value. In the author’s experience, thoughtful businessmen intuitively apply exactly this kind of analysis in problems which are simple enough to allow of purely intuitive analysis; and he believes that they will readily accept its formalization once the essential logic of this formalization is presented in a way which can be comprehended by an intelligent layman. Excellent books on the pure mathematical theory of decision under uncertainty already exist; the present text is an endeavor to show how formal analysis of practical decision problems can be made to pay its way.</p> <p>From the point of view taken in this book,there is no real difference between a ‘‘statistical’’ decision problem in which a part of the available evidence happens to come from a ‘“‘sample”’ and a problem in which all the evidence is of a less formal nature. Both kinds of problems are analyzed by use of the same basic principles; and one of the resulting advantages is that it becomes possible to avoid having to assert that nothing useful can be said about a sample which contains an unknown amount of bias while at the same time having to admit that in most practical situations it is totally impossible to draw a sample which does not contain an unknown amount of bias. In the same way and for the same reason there is no real difference between a decision problem in which the long-run-average demand for some commodity is known with certainty and one in which it is not; and not the least of the advantages which result from recognizing this fact is that it becomes possible to analyze a problem of inventory control without having to pretend that a finite amount of experience can ever give anyone perfect knowledge of long-run-average demand. The author is quite ready to admit that in some situations it may be difficult for the businessman to assess the numerical probabilities and utilities which are required for the kind of analysis recommended in this book, but he is confident that the businessman who really tries to make a reasoned analysis of a difficult decision problem will find it far easier to do this than to make a direct determination of, say, the correct risk premium to add to the pure cost of capital or of the correct level at which to conduct a test of significance.</p> <p>In sum, the author believes that the modern theories of utility and personal probability have at last made it possible to develop a really complete theory to guide the making of managerial decisions—a theory into which the traditional disciplines of statistics and economics under certainty and the collection of miscellaneous techniques taught under the name of operations research will all enter as constituent parts. He hopes, therefore, that the present book will be of interest and value not only to students and practitioners of inventory control, quality control, marketing research, and other specific business functions but also to students of business and businessmen who are interested in the basic principles of managerial economics and to students of economics who are interested in the theory of the firm. Even the teacher of a course in mathematical decision theory who wishes to include applications as well as complete-class and existence theory may find the book useful as a source of examples of the practical decision problems which do arise in the real world.</p>'
- - /docs/sunkcosts/1984-northcraft.pdf
  - "Dollars, Sense, and Sunk Costs: A Life Cycle Model of Resource Allocation Decisions"
  - Gregory B. Northcraft, Gerrit Wolf
  - '1984-04'
  - 10.5465/amr.1984.4277636
  - ! 'Decisions as to whether to cut off a losing enterprise (clouded by what already has been invested in the venture) may be facilitated by a new model proposed here—the life cycle model. The model, borrowing an accounting measure (the time adjusted rate of return) to describe the effect of "sunk costs" on the expected rate of return for future costs in a project, is used to examine the relevance of negative feedback to the decision to commit further resources to completion of a project.'
- - /docs/sunkcosts/1988-arkes.pdf
  - Eliminating the Hindsight Bias
  - Hal R. Arkes, David Faust, Thomas J. Guilmette, Kathleen Hart
  - 1988-05
  - 10.1037/0021-9010.73.2.305
  - ! '<p>Those who consider the likelihood of an event after it has occurred exaggerate their likelihood of having been able to predict that event in advance. We attempted to eliminate this hindsight bias among 194 neuropsychologists. Foresight subjects read a case history and were asked to estimate the probability of three different diagnoses. Subjects in each of the three hindsight groups were told that one of the three diagnoses was correct and were asked to state what probability they would have assigned to each diagnosis if they were making the original diagnosis. Foresight-reasons and hindsight-reasons subjects performed the same task as their foresight and hindsight counterparts, except they had to list one reason why each of the possible diagnoses might be correct. The frequency of subjects succumbing to the hindsight bias was lower in the hindsight-reasons groups than in the hindsight groups not asked to list reasons, <em>x</em><sup>2</sup>( 1, <em>N</em> = 140) = 4.12, <em>p</em> &lt; .05.</p>'
- - http://jtoomim.org/files/Ling_2009-Cognitive_effects_of_creatine_ethyl_ester_supplementation.pdf
  - Cognitive effects of creatine ethyl ester supplementation
  - Jonathan Ling, Minos Kritikos, Brian Tiplady
  - 2009-12
  - 10.1097/fbp.0b013e3283323c2a
  - ! 'Supplementation with creatine-based substances as a means of enhancing athletic performance has become widespread. Until recently, however, the effects of creatine supplementation on cognitive performance has been given little attention. This study used a new form of creatine–creatine ethyl ester–to investigate whether supplementation would improve performance in 5 cognitive tasks, using a double-blind, placebo-controlled study. Creatine dosing led to an improvement over the placebo condition on several measures. Although creatine seems to facilitate cognition on some tasks, these results require replication using objective measures of compliance. The improvement is discussed in the context of research examining the influence of brain energy capacity on cognitive performance.'
- - ! 'http://www.justice.gov/usao/nys/pressreleases/December13/JonesetalArrestsSilkRoad2PR/Jones,%20Andrew,%20et%20al%20(Silk%20Road)%20Indictment.pdf'
  - 'United States of America v. Jones, Andrew Michael, et. al.'
  - United States District Court Southern District of New York
  - 2013-12-20
  - ''
  - ! "From, in or about January 2011, up to and including on or about October 2, 2013, an underground website known as 'Silk Road' hosted a sprawling black-market bazaar on the Internet, where illegal drugs and other illicit goods and services were regularly bought and sold by the site's users. The Grand Jury indicts Defendants Andrew Michael Jones, Gary Davis, and Peter Phillip Nash on three counts of Narcotics Trafficking Conspiracy, Computer Hacking Conspiracy, and Money Laundering Conspiracy."
- - http://www.klingberglab.se/pub/McNab2008.pdf
  - 'Common and unique components of inhibition and working memory: An fMRI, within-subjects investigation'
  - Fiona McNab, Gaelle Leroux, Fredrik Strand, Lisa Thorell, Sissela Bergman, Torkel Klingberg
  - 2008-05-16
  - 10.1016/j.neuropsychologia.2008.04.023
  - ! 'Behavioural findings indicate that the core executive functions of inhibition and working memory are closely linked, and neuroimaging studies indicate overlap between their neural correlates. There has not, however, been a comprehensive study, including several inhibition tasks and several working memory tasks, performed by the same subjects. In the present study, 11 healthy adult subjects completed separate blocks of 3 inhibition tasks (a stop task, a go/no-go task and a flanker task), and 2 working memory tasks (one spatial and one verbal). Activation common to all 5 tasks was identified in the right inferior frontal gyrus, and, at a lower threshold, also the right middle frontal gyrus and right parietal regions (BA 40 and BA 7). Left inferior frontal regions of interest (ROIs) showed a significant conjunction between all tasks except the flanker task. The present study could not pinpoint the specific function of each common region, but the parietal region identified here has previously been consistently related to working memory storage and the right inferior frontal gyrus has been associated with inhibition in both lesion and imaging studies. These results support the notion that inhibitory and working memory tasks involve common neural components, which may provide a neural basis for the interrelationship between the two systems.'
- - https://deepmind.com/documents/183/SPIRAL.pdf
  - Synthesizing Programs for Images using Reinforced Adversarial Learning
  - Yaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, S. M. Ali Eslami, Oriol Vinyals
  - 2018-04-03
  - ''
  - ! '<p>Advances in deep generative networks have led to impressive results in recent years. Nevertheless, such models can often waste their capacity on the minutiae of datasets, presumably due to weak inductive biases in their decoders. This is where graphics engines may come in handy since they abstract away low-level details and represent images as high-level programs. Current methods that combine deep learning and renderers are limited by hand-crafted likelihood or distance functions, a need for large amounts of supervision, or difficulties in scaling their inference algorithms to richer datasets. To mitigate these issues, we present SPIRAL, an adversarially trained agent that generates a program which is executed by a graphics engine to interpret and sample images. The goal of this agent is to fool a discriminator network that distinguishes between real and rendered data, trained with a distributed reinforcement learning setup without any supervision. A surprising finding is that using the discriminator’s output as a reward signal is the key to allow the agent to make meaningful progress at matching the desired output rendering. To the best of our knowledge, this is the first demonstration of an end-to-end, unsupervised and adversarial inverse graphics agent on challenging real world (MNIST, OMNIGLOT, CELEBA) and synthetic 3D datasets. A video of the agent can be found at <a href="https://youtu.be/iSyvwAwa7vk">YouTube</a>.</p>'
- - https://pdfs.semanticscholar.org/29d0/884cf4ed6acdb2711f556863a1ef2bd3a908.pdf
  - In vitro eugenics
  - Robert Sparrow
  - 2014-11
  - 10.1136/medethics-2012-101200
  - ! '<p>A series of recent scientific results suggest that, in the not-too-distant future, it will be possible to create viable human gametes from human stem cells. This paper discusses the potential of this technology to make possible what I call “<em>in vitro</em> eugenics”: the deliberate breeding of human beings <em>in vitro</em> by fusing sperm and egg derived from different stem-cell lines to create an embryo and then deriving new gametes from stem cells derived from that embryo. Repeated iterations of this process would allow scientists to proceed through multiple human generations in the laboratory. <em>In vitro</em> eugenics might be used to study the heredity of genetic disorders and to produce cell lines of a desired character for medical applications. More controversially, it might also function as a powerful technology of ‘human enhancement’ by allowing researchers to use all the techniques of selective breeding to produce individuals with a desired genotype.</p>'
- - https://pdfs.semanticscholar.org/cfda/7aa20912874b9818ae242a04703cc0922181.pdf
  - "Seeing the Forest from the Trees: When Predicting the Behavior or Status of Groups, Correlate Means"
  - David Lubinski, Lloyd G. Humphreys
  - '1996'
  - 10.1037/1076-8971.2.2.363
  - ! '<p>When measures of individual differences are used to predict group performance, the reporting of correlations computed on samples of individuals invites misinterpretation and dismissal of the data. In contrast, if regression equations, in which the correlations required are computed on bivariate means, as are the distribution statistics, it is difficult to underappreciate or lightly dismiss the utility of psychological predictors. Given sufficient sample size and linearity of regression, this technique produces cross-validated regression equations that forecast criterion means with almost perfect accuracy. This level of accuracy is provided by correlations approaching unity between bivariate samples of predictor and criterion means, and this holds true regardless of the magnitude of the “simple” correlation (e.g., <em>r</em><sub>xy</sub> = .20, or <em>r</em><sub>xy</sub> = .80). We illustrate this technique empirically using a measure of general intelligence as the predictor and other measures of individual differences and socioeconomic status as criteria. In addition to theoretical applications pertaining to group trends, this methodology also has implications for applied problems aimed at developing policy in education, medical, and psychological clinics, business, industry, the military, and other domains of public welfare. Linkages between this approach and epidemiological research reinforce its utility as a tool for making decisions about policy.</p>'
- - https://www.biorxiv.org/content/biorxiv/early/2016/05/03/051094.full.pdf
  - 'LD Hub: a centralized database and web interface to perform LD score regression that maximizes the potential of summary level GWAS data for SNP heritability and genetic correlation analysis'
  - Jie Zheng, A. Mesut Erzurumluoglu, Benjamin L. Elsworth, Laurence Howe, Philip C. Haycock, Gibran Hemani, Katherine Tansey, Charles Laurin, Early Genetics and Lifecourse Epidemiology (EAGLE) Eczema Consortium, Beate St. Pourcain, Nicole M. Warrington, Hilary K. Finucane, Alkes L. Price, Brendan K. Bulik-Sullivan, Verneri Anttila, Lavinia Paternoster, Tom R. Gaunt, David M. Evans, Benjamin M. Neale
  - 2016-05-03
  - 10.1101/051094
  - ! '<p><strong>Motivation:</strong> LD score regression is a reliable and efficient method of using genome-wide association study (GWAS) summary-level results data to estimate the SNP heritability of complex traits and diseases, partition this heritability into functional categories, and estimate the genetic correlation between different phenotypes. Because the method relies on summary level results data, LD score regression is computationally tractable even for very large sample sizes. However, publicly available GWAS summary-level data are typically stored in different databases and have different formats, making it difficult to apply LD score regression to estimate genetic correlations across many different traits simultaneously.</p><p><strong>Results:</strong> In this manuscript, we describe LD Hub—a centralized database of summary-level GWAS results for 177 diseases/traits from different publicly available resources/consortia and a web interface that automates the LD score regression analysis pipeline. To demonstrate functionality and validate our software, we replicated previously reported LD score regression analyses of 49 traits/diseases using LD Hub; and estimated SNP heritability and the genetic correlation across the different phenotypes. We also present new results obtained by uploading a recent atopic dermatitis GWAS meta-analysis to examine the genetic correlation between the condition and other potentially related traits. In response to the growing availability of publicly accessible GWAS summary-level results data, our database and the accompanying web interface will ensure maximal uptake of the LD score regression methodology, provide a useful database for the public dissemination of GWAS results, and provide a method for easily screening hundreds of traits for overlapping genetic aetiologies.</p><p><strong>Availability and implementation:</strong> The web interface and instructions for using LD Hub are available at <a href="http://ldsc.broadinstitute.org/">LDSC</a></p>'
- - https://www.donorsiblingregistry.com/sites/default/files/files/dissertation%281%29.pdf
  - Quantitative Genetics in the Postmodern Family of the Donor Sibling Registry
  - Joseph Christopher Lee
  - 2013-06-12
  - ''
  - ! '<p>Quantitative genetics is primarily concerned with two subjects: the correlation between relatives and the response to selection. The correlation between relatives is used to determine the heritability of a trait—the key quantity that addresses the question of nature vs. nurture. Heritability, in turn, is used to predict the response to selection—the main driver of improvements in crops and livestock. The theory of quantitative genetics has been thoroughly tested and applied in plants and animals, but heritability and selection remain open questions in humans due to limited natural experimental designs.</p><p>The Donor Sibling Registry (DSR) is an organization that helps individuals conceived as a result of sperm, egg, or embryo donation make contact with genetically related individuals. Families who conceived children via anonymous sperm donation join the DSR and match with other families who used the same donor ID at the same sperm bank. The resulting donor pedigree consists of heterosexual, lesbian, and single mother families who are connected through the common anonymous sperm donor used to conceive their children.</p><p>Here, we introduce a new quantitative genetic study design based on the unprecedented family relationships found in the donor pedigree. We surveyed 945 individual families constituting 159 donor pedigrees from the Donor Sibling Registry and used their demographic, physical, and behavioral characteristics to conduct a quantitative genetic study of selection and heritability. A direct measurement of phenotypic assortment showed mothers actively selected mates for height, eye color, and religion. Artificial selection for donor height increased mean child height in a manner consistent with the selection differential. Reared-apart donor-conceived paternal half-siblings provided unbiased heritability estimates for traits influenced by maternal and contrast effects. Maternal effects were important in determining the variance of birth weight while eliminating contrast effects revealed sociability to be a highly heritable childhood temperament. Thus, the unprecedented family relationships in the donor pedigree enable a universal model for quantitative genetics.</p>'
- - https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-soska-updated.pdf
  - Measuring the Longitudinal Evolution of the Online Anonymous Marketplace Ecosystem
  - Kyle Soska, Nicolas Christin
  - 2015-08
  - ''
  - ! 'February 2011 saw the emergence of Silk Road, the first successful online anonymous marketplace, in which buyers and sellers could transact with anonymity properties far superior to those available in alternative online or offline means of commerce. Business on Silk Road, primarily involving narcotics trafficking, rapidly boomed, and competitors emerged. At the same time, law enforcement did not sit idle, and eventually managed to shut down Silk Road in October 2013 and arrest its operator. Far from causing the demise of this novel form of commerce, the Silk Road take-down spawned an entire, dynamic, online anonymous marketplace ecosystem, which has continued to evolve to this day. This paper presents a long-term measurement analysis of a large portion of this online anonymous marketplace ecosystem, including 16 different marketplaces, over more than two years (2013–2015). By using long-term measurements, and combining our own data collection with publicly available previous efforts, we offer a detailed understanding of the growth of the online anonymous marketplace ecosystem. We are able to document the evolution of the types of goods being sold, and assess the effect (or lack thereof) of adversarial events, such as law enforcement operations or large-scale frauds, on the overall size of the economy. We also provide insights into how vendors are diversifying and replicating across marketplaces, and how vendor security practices (e.g., PGP adoption) are evolving. These different aspects help us understand how traditional, physical-world criminal activities are developing an online presence, in the same manner traditional commerce diversified online in the 1990s.'
- - /docs/statistics/decision/1939-pearson.pdf
  - '"Student" as Statistician'
  - E. S. Pearson
  - 1939-01-00
  - 10.2307/2332648
  - ! "[Egon Pearson describes Student, or Gosset, as a statistician: Student corresponded widely with young statisticians/mathematicians, encouraging them, and having an outsized influence not reflected in his publication. Student's preferred statistical tools were remarkably simple, focused on correlations and standard deviations, but wielded effectively in the analysis and efficient design of experiments (particularly agricultural experiments), and he was an early decision-theorist, focused on practical problems connected to his Guinness Brewery job—which detachment from academia partially explains why he didn't publish methods or results immediately or often. The need to handle small <em>n</em> of the brewery led to his work on small-sample approximations rather than, like Pearson et al in the Galton biometric tradition, relying on collecting large datasets and using asymptotic methods, and Student carried out one of the first Monte Carlo simulations.]"
- - https://www.nature.com/articles/s41599-019-0366-y
  - "Statistical reliability analysis for a most dangerous occupation: Roman emperor"
  - Joseph Homer Saleh
  - 2019-12-23
  - 10.1057/s41599-019-0366-y
  - ! 'Popular culture associates the lives of Roman emperors with luxury, cruelty, and debauchery, sometimes rightfully so. One missing attribute in this list is, surprisingly, that this mighty office was most dangerous for its holder. Of the 69 rulers of the unified Roman Empire, from Augustus (d. 14 CE) to Theodosius (d. 395 CE), 62% suffered violent death. This has been known for a while, if not quantitatively at least qualitatively. What is not known, however, and has never been examined is the time-to-violent-death of Roman emperors. This work adopts the statistical tools of survival data analysis to an unlikely population, Roman emperors, and it examines a particular event in their rule, not unlike the focus of reliability engineering, but instead of their time-to-failure, their time-to-violent-death. We investigate the temporal signature of this seemingly haphazard stochastic process that is the violent death of a Roman emperor, and we examine whether there is some structure underlying the randomness in this process or not. Nonparametric and parametric results show that: (i) emperors faced a significantly high risk of violent death in the first year of their rule, which is reminiscent of infant mortality in reliability engineering; (ii) their risk of violent death further increased after 12 years, which is reminiscent of wear-out period in reliability engineering; (iii) their failure rate displayed a bathtub-like curve, similar to that of a host of mechanical engineering items and electronic components. Results also showed that the stochastic process underlying the violent deaths of emperors is remarkably well captured by a (mixture) Weibull distribution. We discuss the interpretation and possible reasons for this uncanny result, and we propose a number of fruitful venues for future work to help better understand the deeper etiology of the spectacle of regicide of Roman emperors.'
- - https://www.nytimes.com/2018/04/04/technology/nasim-aghdam-youtube-shooter.html
  - "‘Vegan Bodybuilder’: How YouTube Attacker, Nasim Aghdam, Went Viral in Iran"
  - Daisuke Wakabayashi, Thomas Erdbrink, Matthew Haag (NYT)
  - 2018-04-04
  - ''
  - ! '<p>In Iran, she was known as Green Nasim, a social media star with followings on YouTube, on Instagram and elsewhere. · In the United States, she cast a very different profile, a proponent of vegan diets, animal rights and home exercise who had increasingly become agitated by one of the tech companies that helped give her a platform… · The police said Ms. Aghdam’s anger over what she believed to be unfair treatment by YouTube had set her on a 500-mile drive from her home near San Diego to YouTube’s offices on the northern edge of Silicon Valley. · “People like me are not good for big business, like for animal business, medicine business and for many other businesses. That’s why they are discriminating and censoring us,” she said in a video posted online last year criticizing YouTube. “This is what they are doing to vegan activists and many other people who try to promote healthy, humane and smart living.”</p><p>…Ms. Aghdam was in her late 30s. In several of her videos, she said she was born in Iran, in the city of Urmia, where most people also speak Turkish, as she does in some of her videos. Ms. Aghdam had YouTube pages in Persian, Turkish and English. She explained that she and her family were members of the Baha’i faith, which faces persecution in Iran, a country with a Muslim majority. · Several of her colorful—and sometimes bizarre—videos had gone viral in Iran. Her website, which said it was quoting Western news outlets, identified her as “the first Persian female vegan bodybuilder.” · “Now the media will be faced with a new type of Iranian female which does not fit within any of their usual categorizations,” a Twitter user named Katayoon said Wednesday. · “This was shocking and saddening,” one Iranian, Bahare, wrote on Twitter of Ms. Aghdam. “We laughed so much but now it turns out all those videos were so serious for herself.” · Ms. Aghdam became especially famous for one clip in which she wears a revealing purple dress, showing cleavage, and begins to slowly strip off her clothes to reveal a pair of fake plastic breasts. “Don’t trust your eyes,” read a caption in English on the clip.</p><p>…Her personal website and videos posted to YouTube and elsewhere were filled with complaints about YouTube. “When searching for my website in google, at top of link they add ‘an error occurred’ but there is no error!” a website under Ms. Aghdam’s name, NasimeSabz.com, said in February 2016. “They add it to keep you from my visiting my site.” · Life in the United States had not been good, she said in one video from March 30. “There they kill you by ax,” she said of Iran. “Here they kill you with cotton,” referring to an Iranian expression meaning dying by something that you do not know is dangerous. · In another video, she responded to viewers who had begun to wonder if she was mentally ill: “I don’t have any special mental or physical disease, but I live on a planet filled with disease, disorders, perversions and injustices.” · The American dream appeared to be tarnished for her after she began to face hurdles in the United States. · “If you are superficial, you will think it is heaven here, that you can go naked outside and have sex left and right like other animals without any morality,” she said in one video in Persian. “But if you enter the system, you will see that it is worse than Iran,” she said. “Those who want to inform people against the system and big companies get censored.”</p>'
- - https://slatestarcodex.com/2013/04/12/noisy-poll-results-and-reptilian-muslim-climatologists-from-mars/
  - "Lizardman’s Constant Is 4%"
  - Scott Alexander
  - 2013-04-12
  - ''
  - ! '<p>I have only done a little bit of social science research, but it was enough to make me hate people. One study I helped with analyzed whether people from different countries had different answers on a certain psychological test. So we put up a website where people answered some questions about themselves (like “what country are you from?”) and then took the psychological test. · And so of course people screwed it up in every conceivable way. There were the merely dumb, like the guy who put “male” as his nationality and “American” as his gender. But there were also the actively malicious or at least annoying, like the people (yes, more than one) who wrote in “Martian”. · I think we all probably know someone like this, maybe a couple people like this. · I also think most of us <em>don’t</em> know someone who believes reptilian aliens in human form control all the major nations of Earth. · Public Policy Polling’s recent poll on conspiracy theories mostly showed up on my Facebook feed as “4% of Americans believe lizardmen are running the Earth”. · (of note, an additional 7% of Americans are “not sure” whether lizardmen are running the Earth or not.) · Imagine the situation. You’re at home, eating dinner. You get a call from someone who says “Hello, this is Public Policy Polling. Would you mind answering some questions for us?” You say “Sure”. An extremely dignified sounding voice says–and this is the exact wording of the question–“Do you believe that shape-shifting reptilian people control our world by taking on human form and gaining political power to manipulate our society, or not?” Then it urges you to press 1 if yes, press 2 if no, press 3 if not sure. · So first we get the people who think “Wait, was 1 the one for if I did believe in lizardmen, or if I didn’t? I’ll just press 1 and move on to the next question.” · Then we get the people who are like “I never heard it before, but if this nice pollster thinks it’s true, I might as well go along with them.” · Then we get the people who are all “F#&amp;k you, polling company, I don’t want people calling me when I’m at dinner. You screw with me, I tell you what I’m going to do. I’m going to tell you I believe lizard people are running the planet.” · And <em>then</em> we get the people who put “Martian” as their nationality in psychology experiments. Because some men just want to watch the world burn. · Do these three groups total 4% of the US population? Seems plausible.</p><p>…But sometimes it’s not some abstruse subtle bias. Sometimes it’s not a good-natured joke. Sometimes people might just be actively working to corrupt your data. · Another link I’ve seen on my Facebook wall a few times is this one: “Are Climate Change Sceptics More Likely To Be Conspiracy Theorists?” It’s based on a paper by Stephen Lewandowsky et al called “NASA Faked The Moon Landing, Therefore Climate Science Is A Hoax–An Analysis Of The Motivated Rejection Of Science”. · The paper’s thesis was that climate change skeptics are motivated by conspiracy ideation–a belief that there are large groups of sinister people out to deceive them. This seems sort of reasonable on the face of it–being a climate change skeptic requires going against the belief of the entire scientific establishment. My guess is that there probably is a significant link here waiting to be discovered. · …But a bunch of global warming skeptics started re-analyzing the data and coming up with their own interpretations…More interestingly, they found that pretty much all of the link between global warming skepticism and stupidity was a couple of people (there were so few skeptics, <em>and</em> so few conspiracy believers, that these couple of people made up a pretty big proportion of them, and way more than enough to get a “significant” difference with the global warming believers). Further, most of these couple of people had given the maximally skeptical answer to every single question about global warming, and the maximally credulous answer to every single question about conspiracies. · The danger here now seems obvious. Global warming believer blogs publish a link to this study, saying gleefully that it’s going to prove that global warming skeptics are idiots who also think NASA faked the moon landing and the world is run by lizardmen or whatever. Some global warming believers decide to help this process along by pretending to be super-strong global warming skeptics and filling in the stupidest answers they can to every question. The few real global warming skeptics who take the survey aren’t enough signal to completely drown out this noise. Therefore, they do the statistics and triumphantly announce that global warming skepticism is linked to stupid beliefs.</p><p>…The lesson from all three of the cases in this post seems clear. When we’re talking about very unpopular beliefs, polls can only give a weak signal. Any possible source of noise–jokesters, cognitive biases, or deliberate misbehavior–can easily overwhelm the signal. Therefore, polls that rely on detecting very weak signals should be taken with a grain of salt.</p>'
- - /docs/genetics/selection/1992-innis.pdf
  - "Tolman and Tryon: Early research on the inheritance of the ability to learn"
  - N. K. Innis
  - '1992'
  - '10.1037/0003-066X.47.2.190'
  - ! "Few psychologists today are aware of the seminal role played by learning theorist Edward C. Tolman in the early development of the field of behavior genetics. Tolman was the first to publish a study of selective breeding for maze-learning ability in rats. He continued to foster research in this field by supporting the work of his students, particularly Robert C. Tryon. Tryon carried out the first major long-term study of maze-bright and maze-dull rats. This article focuses on Tolman's early years at Berkeley and the events culminating in the inheritance project, as well as on the evolution of this research under Tryon's direction."
- - /docs/sociology/1999-lee.pdf
  - "Parachuting for charity: is it worth the money? A 5-year audit of parachute injuries in Tayside and the cost to the NHS"
  - C.T. Lee, P. Williams, W.A. Hadden
  - 1999-05
  - "10.1016/S0020-1383(99)00083-2"
  - ! 'All parachute injuries from two local parachute centres over a 5-year period were analysed. Of 174 patients with injuries of varying severity, 94% were first-time charity-parachutists. The injury rate in charity-parachutists was 11% at an average cost of £3751 per casualty. 63% of casualties who were charity-parachutists required hospital admission, representing a serious injury rate of 7%, at an average cost of £5781 per patient. The amount raised per person for charity was £30. Each pound raised for charity cost the NHS £13.75 in return. Parachuting for charity costs more money than it raises, carries a high risk of serious personal injury and places a significant burden on health resources.'
- - https://www.lesswrong.com/posts/SmDziGM9hBjW9DKmf/2019-ai-alignment-literature-review-and-charity-comparison
  - 2019 AI Alignment Literature Review and Charity Comparison
  - Larks
  - 2019-12-18
  - ''
  - ! '<p>As in <a href="https://forum.effectivealtruism.org/posts/nSot23sAjoZRgaEwa/2016-ai-risk-literature-review-and-charity-comparison">2016</a>, <a href="https://forum.effectivealtruism.org/posts/XKwiEpWRdfWo7jy7f/2017-ai-safety-literature-review-and-charity-comparison">2017</a> and <a href="https://forum.effectivealtruism.org/posts/BznrRBgiDdcTwWWsB/2018-ai-alignment-literature-review-and-charity-comparison">2018</a>, I have attempted to review the research that has been produced by various organisations working on AI safety, to help potential donors gain a better understanding of the landscape. This is a similar role to that which GiveWell performs for global health charities, and somewhat similar to a securities analyst with regards to possible investments. My aim is basically to judge the output of each organisation in 2019 and compare it to their budget. This should give a sense of the organisations’ average cost-effectiveness. We can also compare their financial reserves to their 2019 budgets to get a sense of urgency.</p><p>…Here are the un-scientifically-chosen hashtags: Agent Foundations · AI Theory · Amplification · Careers · CIRL · Decision Theory · Ethical Theory · Forecasting · Introduction · Misc · ML safety · Other Xrisk · Overview · Philosophy · Politics · RL · Security · Short-term · Strategy.</p><ul><li><em>Research organisations reviewed</em>: FHI (The Future of Humanity Institute) · CHAI (The Center for Human-Aligned AI) · MIRI (The Machine Intelligence Research Institute) · GCRI (The Global Catastrophic Risks Institute) · CSER (The Center for the Study of Existential Risk) · Ought · OpenAI · Google DeepMind · AI Safety camp · FLI (The Future of Life Institute) · AI Impacts · GPI (The Global Priorities Institute) · FRI (The Foundational Research Institute) · Median Group · CSET (The Center for Security and Emerging Technology) · Leverhulme Center for the Future of Intelligence · BERI (The Berkeley Existential Risk Initiative) · AI Pulse</li><li><em>Capital Allocators reviewed</em>: LTFF (Long-term future fund) · OpenPhil (The Open Philanthropy Project)</li></ul><p>…The size of the field continues to grow, both in terms of funding and researchers. Both make it increasingly hard for individual donors. I’ve attempted to subjectively weigh the productivity of the different organisations against the resources they used to generate that output, and donate accordingly.</p>'
- - /docs/iq/1999-spitz.pdf
  - "Beleaguered 'Pygmalion': A History of the Controversy Over Claims that Teacher Expectancy Raises Intelligence"
  - Herman H. Spitz
  - 1999-09
  - "10.1016/S0160-2896(99)00026-4"
  - ! "The 1968 publication of the Rosenthal and Jacobson's <em>Pygmalion in the Classroom</em> offered the optimistic message that raising teachers' expectations of their pupils' potentials would raise their pupils' intelligence. This claim was, and still is, endorsed by many psychologists and educators. The original study, along with the scores of attempted replications and the acrimonious controversy that followed it, is reviewed, and its consequences discussed."
- - https://www.nature.com/articles/s41586-019-1466-y
  - A national experiment reveals where a growth mindset improves achievement
  - David S. Yeager, Paul Hanselman, Gregory M. Walton, Jared S. Murray, Robert Crosnoe, Chandra Muller, Elizabeth Tipton, Barbara Schneider, Chris S. Hulleman, Cintia P. Hinojosa, David Paunesku, Carissa Romero, Kate Flint, Alice Roberts, Jill Trott, Ronaldo Iachan, Jenny Buontempo, Sophia Man Yang, Carlos M. Carvalho, P. Richard Hahn, Maithreyi Gopalan, Pratik Mhatre, Ronald Ferguson, Angela L. Duckworth, Carol S. Dweck
  - 2019-08-07
  - '10.1038/s41586-019-1466-y'
  - ! 'A global priority for the behavioural sciences is to develop cost-effective, scalable interventions that could improve the academic outcomes of adolescents at a population level, but no such interventions have so far been evaluated in a population-generalizable sample. Here we show that a short (less than one hour), online growth mindset intervention—which teaches that intellectual abilities can be developed—improved grades among lower-achieving students and increased overall enrolment to advanced mathematics courses in a nationally representative sample of students in secondary education in the United States. Notably, the study identified school contexts that sustained the effects of the growth mindset intervention: the intervention changed grades when peer norms aligned with the messages of the intervention. Confidence in the conclusions of this study comes from independent data collection and processing, pre-registration of analyses, and corroboration of results by a blinded Bayesian analysis.'
- - https://www.sciencedirect.com/science/article/pii/S0160289619301680
  - "Working memory training does not enhance older adults' cognitive skills: A comprehensive meta-analysis"
  - "Giovanni Sala, N. Deniz Aksayli, K. Semir Tatlidil, Yasuyuki Gondo, Fernand Gobet"
  - 2019-11
  - "10.1016/j.intell.2019.101386"
  - ! '<ul><li>Working memory (WM) training does not enhance older adults’ cognitive function.</li><li>The training slightly improves older adults’ performance in untrained memory tasks.</li><li>The same pattern of results is observed in younger adults.</li><li>The models exhibit a high degree of consistency; hence this literature is not noisy.</li></ul><p>Abstract:</p><p>In the last two decades, considerable efforts have been devoted to finding a way to enhance cognitive function by cognitive training. To date, the attempt to boost broad cognitive functions in the general population has failed. However, it is still possible that some cognitive training regimens exert a positive influence on specific populations, such as older adults. In this meta-analytic review, we investigated the effects of working memory (WM) training on older adults’ cognitive skills. Three robust-variance-estimation meta-analyses (<em>N</em> = 2140, <em>m</em> = 43, and <em>k</em> = 698) were run to analyze the effects of the intervention on (a) the trained tasks, (b) near-transfer measures, and (c) far-transfer measures. While large effects were found for the trained tasks (<em>g</em> = 0.877), only modest (<em>g</em> = 0.274) and near-zero (<em>g</em> = 0.121) effects were obtained in the near-transfer and far-transfer meta-analyses, respectively. Publication-bias analysis provided adjusted estimates that were slightly lower. Moreover, when active control groups were implemented, the far-transfer effects were null (<em>g</em> = −0.008). Finally, the effects were highly consistent across studies (i.e., low or null true heterogeneity), especially in the near- and far-transfer models. While confirming the difficulty in obtaining transfer effects with cognitive training, these results corroborate recent empirical evidence suggesting that WM is not isomorphic with other fundamental cognitive skills such as fluid intelligence.</p>'
- - https://psyarxiv.com/7s8wr/
  - "Cognitive and academic benefits of music training with children: A multilevel meta-analysis"
  - Giovanni Sala, Fernand Gobet
  - 2020-01-14
  - 10.31234/osf.io/7s8wr
  - ! '<p>Music training has repeatedly been claimed to positively impact on children’s cognitive skills and academic achievement. This claim relies on the assumption that engaging in intellectually demanding activities fosters particular domain-general cognitive skills, or even general intelligence. The present meta-analytic review (<em>N</em> = 6,984, <em>k</em> = 254, <em>m</em> = 54) shows that this belief is incorrect. Once the study quality design is controlled for, the overall effect of music training programs is null (<em>g</em> ≈ 0) and highly consistent across studies (τ<sup>2</sup> ≈ 0). Small statistically significant overall effects are obtained only in those studies implementing no random allocation of participants and employing non-active controls (<em>g</em> ≈ 0.200, <em>p</em> &lt; .001). Interestingly, music training is ineffective regardless of the type of outcome measure (e.g., verbal, non-verbal, speed-related, etc.). Furthermore, we note that, beyond meta-analysis of experimental studies, a considerable amount of cross-sectional evidence indicates that engagement in music has no impact on people’s non-music cognitive skills or academic achievement. We conclude that researchers’ optimism about the benefits of music training is empirically unjustified and stem from misinterpretation of the empirical data and, possibly, confirmation bias. Given the clarity of the results, the large number of participants involved, and the numerous studies carried out so far, we conclude that this line of research should be dismissed.</p>'
- - https://statistics.fas.harvard.edu/files/statistics-2/files/statistical_paradises_and_paradoxes.pdf
  - "Statistical paradises and paradoxes in big data (I): Law of large populations, big data paradox, and the 2016 US presidential election"
  - Xiao-Li Meng
  - 2018-07-28
  - '10.1214/18-AOAS1161SF'
  - ! '<p>Statisticians are increasingly posed with thought-provoking and even paradoxical questions, challenging our qualifications for entering the statistical paradises created by Big Data. By developing measures for data quality, this article suggests a framework to address such a question: “Which one should I trust more: a 1% survey with 60% response rate or a self-reported administrative dataset covering 80% of the population?” A 5-element Euler-formula-like identity shows that for any dataset of size <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>, probabilistic or not, the difference between the sample average <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>X</mi><mo accent="true">¯</mo></mover><mi>n</mi></msub><annotation encoding="application/x-tex">\overline{X}_{n}</annotation></semantics></math> and the population average <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>X</mi><mo accent="true">¯</mo></mover><mi>N</mi></msub><annotation encoding="application/x-tex">\overline{X}_{N}</annotation></semantics></math> is the product of three terms: (1) a <i>data quality</i> measure, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><annotation encoding="application/x-tex">\rho_{{R,X}}</annotation></semantics></math>, the correlation between <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>j</mi></msub><annotation encoding="application/x-tex">X_{j}</annotation></semantics></math> and the response/recording indicator <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>R</mi><mi>j</mi></msub><annotation encoding="application/x-tex">R_{j}</annotation></semantics></math>; (2) a <i>data quantity</i> measure, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msqrt><mrow><mo stretchy="false" form="prefix">(</mo><mi>N</mi><mo>−</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo><mi>/</mi><mi>n</mi></mrow></msqrt><annotation encoding="application/x-tex">\sqrt{(N-n)/n}</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is the population size; and (3) a <i>problem difficulty</i> measure, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>σ</mi><mi>X</mi></msub><annotation encoding="application/x-tex">\sigma_{X}</annotation></semantics></math>, the standard deviation of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>. This decomposition provides multiple insights: (I) Probabilistic sampling ensures high data quality by controlling <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><annotation encoding="application/x-tex">\rho_{{R,X}}</annotation></semantics></math> at the level of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>N</mi><mrow><mo>−</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow></msup><annotation encoding="application/x-tex">N^{-1/2}</annotation></semantics></math>; (II) When we lose this control, the impact of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is no longer canceled by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><annotation encoding="application/x-tex">\rho_{{R,X}}</annotation></semantics></math>, leading to a <i>Law of Large Populations</i> (LLP), that is, our estimation error, relative to the benchmarking rate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><msqrt><mi>n</mi></msqrt></mrow><annotation encoding="application/x-tex">1/\sqrt{n}</annotation></semantics></math>, increases with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msqrt><mi>N</mi></msqrt><annotation encoding="application/x-tex">\sqrt{N}</annotation></semantics></math>; and (III) the “bigness” of such Big Data (for population inferences) should be measured by the <i>relative size</i> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><mi>n</mi><mi>/</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">f=n/N</annotation></semantics></math>, not the <i>absolute size</i> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>; (IV) When combining data sources for population inferences, those relatively tiny but higher quality ones should be given far more weights than suggested by their sizes.</p><p>Estimates obtained from the Cooperative Congressional Election Study (CCES) of the 2016 US presidential election suggest a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><mo>≈</mo><mo>−</mo><mn>0.005</mn></mrow><annotation encoding="application/x-tex">\rho_{{R,X}}\approx-0.005</annotation></semantics></math> for self-reporting to vote for Donald Trump. Because of LLP, this seemingly minuscule data defect correlation implies that the simple sample proportion of the self-reported voting preference for Trump from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">1\%</annotation></semantics></math> of the US eligible voters, that is, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≈</mo><mn>2</mn><mtext mathvariant="normal">,</mtext><mn>300</mn><mtext mathvariant="normal">,</mtext><mn>000</mn></mrow><annotation encoding="application/x-tex">n\approx2\mbox{,}300\mbox{,}000</annotation></semantics></math>, has the same mean squared error as the corresponding sample proportion from a genuine simple random sample of size <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≈</mo><mn>400</mn></mrow><annotation encoding="application/x-tex">n\approx400</annotation></semantics></math>, a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>99.98</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">99.98\%</annotation></semantics></math> reduction of sample size (and hence our confidence). The CCES data demonstrate LLP vividly: on average, the larger the state’s voter populations, the further away the actual Trump vote shares from the usual <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>95</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">95\%</annotation></semantics></math> confidence intervals based on the sample proportions. This should remind us that, without taking data quality into account, population inferences with Big Data are subject to a <i>Big Data Paradox</i>: the more the data, the surer we fool ourselves.</p>'
- - 'https://www.journalofexpertise.org/articles/volume2_issue4/JoE_2_4_Kell&Wai.pdf'
  - "Right-Tail Range Restriction: A Lurking Threat to Detecting Associations between Traits and Skill among Experts"
  - Harrison J. Kell, Jonathan Wai
  - '2019'
  - ''
  - ! 'It has been claimed by prominent authors that there is no relationship between differences in some human traits (e.g., cognitive ability, physical ability) and differences in skill among experts. We assert that the failure to detect such associations is often due to an extreme form of range restriction that particularly plagues research focused on expert samples: <em>right-tail range restriction</em> (RTRR). RTRR refers to a lack of representation of data from the far right segment of the normal distribution, inhibiting the observation of statistical associations. Using two example studies we demonstrate that, when RTRR is not present, relationships between differences in experts’ traits and differences in their degree of skill can be observed. Based on the characteristics of these studies we make recommendations for methodological practices that can be followed to help investigators overcome RTRR and facilitate the continued development of a robust and replicable science of expertise. [Keywords: Range restriction, expertise, traits, cognitive ability, physical ability, performance, athletics, psychological attributes]'
- - '/docs/genetics/correlation/2019-pgc.pdf'
  - 'Genomic Relationships, Novel Loci, and Pleiotropic Mechanisms across Eight Psychiatric Disorders'
  - Cross-Disorder Group of the Psychiatric Genomics Consortium (PGC)
  - 2019-12-12
  - '10.1016/j.cell.2019.11.020'
  - ! '<ul><li>Three groups of highly genetically-related disorders among 8 psychiatric disorders</li><li>Identified 109 pleiotropic loci affecting more than one disorder</li><li>Pleiotropic genes show heightened expression beginning in 2<sup>nd</sup> prenatal trimester</li><li>Pleiotropic genes play prominent roles in neurodevelopmental processes</li></ul><p>Genetic influences on psychiatric disorders transcend diagnostic boundaries, suggesting substantial pleiotropy of contributing loci. However, the nature and mechanisms of these pleiotropic effects remain unclear. We performed analyses of 232,964 cases and 494,162 controls from genome-wide studies of anorexia nervosa, attention-deficit/hyperactivity disorder, autism spectrum disorder, bipolar disorder, major depression, obsessive-compulsive disorder, schizophrenia, and Tourette syndrome. Genetic correlation analyses revealed a meaningful structure within the eight disorders, identifying three groups of inter-related disorders. Meta-analysis across these eight disorders detected 109 loci associated with at least two psychiatric disorders, including 23 loci with pleiotropic effects on four or more disorders and 11 loci with antagonistic effects on multiple disorders. The pleiotropic loci are located within genes that show heightened expression in the brain throughout the lifespan, beginning prenatally in the second trimester, and play prominent roles in neurodevelopmental processes. These findings have important implications for psychiatric nosology, drug development, and risk prediction.</p>'
- - /docs/catnip/2017-ottoni.pdf
  - "The palaeogenetics of cat dispersal in the ancient world"
  - Claudio Ottoni, Wim Van Neer, Bea De Cupere, Julien Daligault, Silvia Guimaraes, Joris Peters, Nikolai Spassov, Mary E. Prendergast, Nicole Boivin, Arturo Morales-Muñiz, Adrian Bălăşescu, Cornelia Becker, Norbert Benecke, Adina Boroneant, Hijlke Buitenhuis, Jwana Chahoud, Alison Crowther, Laura Llorente, Nina Manaseryan, Hervé Monchot, Vedat Onar, Marta Osypińska, Olivier Putelat, Eréndira M. Quintana Morales, Jacqueline Studer, Ursula Wierer, Ronny Decorte, Thierry Grange, Eva-Maria Geigl
  - 2017-06-19
  - 10.1038/s41559-017-0139
  - ! 'The cat has long been important to human societies as a pest-control agent, object of symbolic value and companion animal, but little is known about its domestication process and early anthropogenic dispersal. Here we show, using ancient DNA analysis of geographically and temporally widespread archaeological cat remains, that both the Near Eastern and Egyptian populations of <em>Felis silvestris lybica</em> contributed to the gene pool of the domestic cat at different historical times. While the cat’s worldwide conquest began during the Neolithic period in the Near East, its dispersal gained momentum during the Classical period, when the Egyptian cat successfully spread throughout the Old World. The expansion patterns and ranges suggest dispersal along human maritime and terrestrial routes of trade and connectivity. A coat-colour variant was found at high frequency only after the Middle Ages, suggesting that directed breeding of cats occurred later than with most other domesticated animals.'
- - /docs/psychology/2008-macknik.pdf
  - "Attention and awareness in stage magic: turning tricks into research"
  - Stephen L. Macknik, Mac King, James Randi, Apollo Robbins, Teller, John Thompson, Susana Martinez-Conde
  - 2008-07-30
  - 10.1038/nrn2473
  - ! "Just as vision scientists study visual art and illusions to elucidate the workings of the visual system, so too can cognitive scientists study cognitive illusions to elucidate the underpinnings of cognition. Magic shows are a manifestation of accomplished magic performers' deep intuition for and understanding of human attention and awareness. By studying magicians and their techniques, neuroscientists can learn powerful methods to manipulate attention and awareness in the laboratory. Such methods could be exploited to directly study the behavioural and neural basis of consciousness itself, for instance through the use of brain imaging and other neural recording techniques."
- - https://scholarspace.manoa.hawaii.edu/bitstream/10125/64076/0269.pdf
  - "Knowledge Sharing Network in a Community of Illicit Practice: A Cybermarket Subreddit Case"
  - K. Hazel Kwon, Weiwen Yu, Steve Kilar, Chun Shao, Kailey Broussard, Thomas Lutes
  - 2020-01-07
  - ''
  - ! 'Often neglected in the literature about communities of practice is the fact that online knowledge-sharing communities thrive among illicit collectives whose activities are stigmatized or outlawed. This paper focuses on a knowledge-sharing community of users who engage in illegal practices by examining the ways in which the community’s network structure changes when a high-stakes, uncertain event—the July 2017 shutdown of the dark web market Alphabay—occurs. This study compares the discussion network structures in the subreddit r/AlphaBay during pre-shutdown days (the “routine” period) and shutdown days (the “market defect” period) and offers a content analysis of the knowledge and resources shared by users during these periods. Several differences were observed: (a) the network structure changed such that the network size grew while becoming more centralized; (b) new crisis-specific players emerged; (c) types of knowledge shared during the market defect period was qualitatively different from the routine period.'
- - https://www.laurenceking.com/blog/2019/09/26/dorodango-blog/
  - "Dorodango, the Japanese art of making mud balls: <em>Dorodango</em> author Bruce Gardner shares the story of how he discovered the Japanese art of hikaru dorodango"
  - Bruce Gardner
  - 2019-09-26
  - ''
  - ! '<p>[Photo essay on making shiny balls of mud.]</p> <p>Hi there, this is Bruce Gardner. I am out of Albuquerque, New Mexico and my strange superpower is: I am very good at making mud balls, aka hikaru dorodango. I’m taking over the Laurence King blog today to introduce my new book, <a href="https://www.laurenceking.com/product/dorodango/"><em>Dorodango: The Japanese Art of Making Mud Balls</em></a>…Coming from the words <em>doro</em>, meaning “mud” and <em>dango</em>, a type of Japanese flour cake, hikaru dorodango consists of forming a mud ball by hand. Layers of increasingly fine dirt are added to the surface over the space of days to a point at which the dorodango can be polished to a high sheen (hikaru means “shining”)…I was introduced to hikaru dorodango by <a href="/docs/japanese/2002-gibson">a William Gibson essay</a> in Tate Magazine, way back in 2002. I was immediately bowled over by the idea of creating art from such a humble material; I have been creating mud balls ever since.</p><p>…Here is an image of a few of my pieces that illustrate the scope of colour and texture that is possible with soil gathered from different locations (various parts of New Mexico, in this case).</p><p><img src="/images/2019-gardner-dorodango-5displaypieces.jpg" alt="https://s3-eu-west-1.amazonaws.com/laurence-king/wp-content/uploads/2019/09/20163632/Dorodango-by-Bruce-Gardner-Laurence-King-Publishing1-1440x1080.jpg" /></p><p>…The process of creating hikaru dorodango is very conducive to flow: There is a repetitive quality to the work but it is still challenging as the dorodango changes, one minute to the next. Your mind remains engaged but you’re disconnected from everything else. Hours can easily slip by this way…How sturdy are they? That varies by soil. Some would shatter like glass if you dropped them. This one would dent your hardwood floor and roll away.</p>'
- - https://www.frontiersin.org/articles/10.3389/fendo.2019.00845/full
  - "Utility and First Clinical Application of Screening Embryos for Polygenic Disease Risk Reduction"
  - Nathan R. Treff, Jennifer Eccles, Lou Lello, Elan Bechor, Jeffrey Hsu, Kathryn Plunkett, Raymond Zimmerman, Bhavini Rana, Artem Samoilenko, Steven Hsu, Laurent C. A. M. Tellier (Genomic Prediction)
  - 2019-12-04
  - '10.3389/fendo.2019.00845'
  - ! 'For over 2 decades preimplantation genetic testing (PGT) has been in clinical use to reduce the risk of miscarriage and genetic disease in patients with advanced maternal age and risk of transmitting disease. Recently developed methods of genome-wide genotyping and machine learning algorithms now offer the ability to genotype embryos for polygenic disease risk with accuracy equivalent to adults. In addition, contemporary studies on adults indicate the ability to predict polygenic disorders with risk equivalent to monogenic disorders. Existing biobanks provide opportunities to model the clinical utility of polygenic disease risk reduction among sibling adults. Here, we provide a mathematical model for the use of embryo screening to reduce the risk of type 1 diabetes. Results indicate a 45–72% reduced risk with blinded genetic selection of one sibling. The first clinical case of polygenic risk scoring in human preimplantation embryos from patients with a family history of complex disease is reported. In addition to these data, several common and accepted practices place PGT for polygenic disease risk in the applicable context of contemporary reproductive medicine. In addition, prediction of risk for PCOS, endometriosis, and aneuploidy are of particular interest and relevance to patients with infertility and represent an important focus of future research on polygenic risk scoring in embryos.'
- - https://jamanetwork.com/journals/jama/fullarticle/2759201
  - Backlash Over Meat Dietary Recommendations Raises Questions About Corporate Ties to Nutrition Scientists
  - Rita Rubin (JAMA)
  - 2020-01-15
  - 10.1001/jama.2019.21441
  - ! '<p>[Summary of vegetarian activist/researcher reaction to recent reviews &amp; meta-analysis indicating that the correlation of meat-eating with bad health often does not appear in epidemiological datasets, the randomized experiments do not support the strong claims, and the overall evidence that eating meat = bad health is low quality &amp; weak:</p><ul><li><a href="https://annals.org/aim/fullarticle/2752329/meat-consumption-health-food-thought">“Meat Consumption and Health: Food for Thought”</a>, Carroll &amp; Doherty 2019 (editorial)</li><li><a href="https://annals.org/aim/fullarticle/2752320/red-processed-meat-consumption-risk-all-cause-mortality-cardiometabolic-outcomes">“Red and Processed Meat Consumption and Risk for All-Cause Mortality and Cardiometabolic Outcomes: A Systematic Review and Meta-analysis of Cohort Studies”</a>, Zeraatkar et al 2019a</li><li><a href="https://annals.org/aim/fullarticle/2752321/reduction-red-processed-meat-intake-cancer-mortality-incidence-systematic-review">“Reduction of Red and Processed Meat Intake and Cancer Mortality and Incidence: A Systematic Review and Meta-analysis of Cohort Studies”</a>, Han et al 2019</li><li><a href="https://annals.org/aim/fullarticle/2752327/patterns-red-processed-meat-consumption-risk-cardiometabolic-cancer-outcomes-systematic">“Patterns of Red and Processed Meat Consumption and Risk for Cardiometabolic and Cancer Outcomes: A Systematic Review and Meta-analysis of Cohort Studies”</a>, Vernooij et al 2019</li><li><a href="/docs/longevity/2019-zeraatkar.pdf">“Effect of Lower Versus Higher Red Meat Intake on Cardiometabolic and Cancer Outcomes: A Systematic Review of Randomized Trials”</a>, Zeraatkar et al 2019b</li><li><a href="https://annals.org/aim/fullarticle/2752323/health-related-values-preferences-regarding-meat-consumption-mixed-methods-systematic">“Health-Related Values and Preferences Regarding Meat Consumption: A Mixed-Methods Systematic Review”</a>, Valli et al 2019</li><li><a href="https://annals.org/aim/fullarticle/2752328/unprocessed-red-meat-processed-meat-consumption-dietary-guideline-recommendations-from">“Unprocessed Red Meat and Processed Meat Consumption: Dietary Guideline Recommendations From the Nutritional Recommendations (NutriRECS) Consortium”</a>, Johnston et al 2019</li></ul><p>After breaking the embargo, they began lobbying against it, spamming the journal editor, demanding the papers be retracted before publication, denouncing it in talks, and contacting the Federal Trade Commission &amp; district attorneys demanding they investigate; they justify these activities by saying that since high-quality evidence can’t be easily obtained in nutrition, there is no need for it, and accusing the authors of financial conflicts of interest and comparing them to global warming deniers.</p><p>However, the conflicts of interest represent very small percentages of funding, and the vegetarian activist/researchers themselves are heavily funded by anti-meat interests, such as olive research institutions, walnut industry bodies, the egg industry, snack companies, and alternative diet groups, with the list of funders of one member including but far from limited to “the <a href="https://en.wikipedia.org/wiki/Pulse_(legume)">Pulse</a> Research Network, the Almond Board of California, the International Nut and Dried Fruit Council; Soy Foods Association of North America; the Peanut Institute; Kellogg’s Canada; and Quaker Oats Canada.”]</p>'
- - https://annals.org/aim/fullarticle/2752329/meat-consumption-health-food-thought
  - "Meat Consumption and Health: Food for Thought"
  - Aaron E. Carroll, Tiffany S. Doherty
  - 2019-11-19
  - 10.7326/M19-2620
  - ! '<p>For some time, medical and science organizations have been beating the drum that red and processed meat are bad for you. For almost as long, they have lamented that their efforts to inform the public have not convinced enough people to change their consumption. This month’s issue offers us food for thought on why. The field of nutritional epidemiology is plagued by observational studies that have conducted inappropriate analyses, accompanied by likely erroneous conclusions (1). Many studies selectively report results, and many lack an a priori hypothesis. Many use notoriously unreliable self-reports of food consumption while failing to collect or appropriately control for data on numerous potential confounders.</p><p>…Four more studies join the evidence base this month, and because they review all of the evidence that came before, they cannot be accused of cherry-picking. The first was a meta-analysis of cohort studies that focused on how dietary patterns, including differing amounts of red or processed meat, affected all-cause mortality, cardiometabolic outcomes, and cancer incidence and mortality (6). More than 100 studies including more than 6 million participants were analyzed. The overall conclusions were that dietary patterns, including differences in meat consumption, may result in only small differences in risk outcomes over long periods.</p><p>The next study was a meta-analysis that homed in specifically on cohort studies examining how reductions in red and processed meat might affect cancer incidence and mortality (7). It included 118 studies with more than 6 million participants, and it, too, found that the possible impact of reduced meat intake was very small. The third study was a meta-analysis of cohort studies that looked specifically at meat consumption and its relationship to all-cause mortality and cardiometabolic outcomes (8), and—once again—it found that any link was very small.</p><p>…In a fourth analysis in this issue (9), researchers examined randomized controlled trials that compared diets with differing amounts of red meat consumption for at least 6 months. They found 12 eligible studies, but one of them—the Women’s Health Initiative—was so large (almost 49 000 women) that it dominated the analysis. We can wish for more studies, and we could hope that they had more homogenous outcomes and better fidelity to assigned diets, but the overall conclusions from what they had were that “red meat may have little or no effect on major cardiometabolic outcomes and cancer mortality and incidence.”</p><p>…it may be time to stop producing observational research in this area. These meta-analyses include millions of participants. Further research involving much smaller cohorts has limited value. High-quality randomized controlled trials are welcome, but only if they’re designed to tell us things we don’t already know.</p>'
- - https://annals.org/aim/fullarticle/2752328/unprocessed-red-meat-processed-meat-consumption-dietary-guideline-recommendations-from
  - "Unprocessed Red Meat and Processed Meat Consumption: Dietary Guideline Recommendations From the Nutritional Recommendations (NutriRECS) Consortium"
  - 'Bradley C. Johnston, Dena Zeraatkar, Mi Ah Han, Robin W.M. Vernooij, Claudia Valli, Regina El Dib, Catherine Marshall, Patrick J. Stover, Susan Fairweather-Taitt, Grzegorz Wójcik, Faiz Bhatia, Russell de Souza, Carlos Brotons, Joerg J. Meerpohl, Chirag J. Patel, Benjamin Djulbegovic, Pablo Alonso-Coello, Malgorzata M. Bala, Gordon H. Guyatt'
  - '2019-11-19'
  - '10.7326/M19-1621'
  - ! '<p><em>Description</em>: Dietary guideline recommendations require consideration of the certainty in the evidence, the magnitude of potential benefits and harms, and explicit consideration of people’s values and preferences. A set of recommendations on red meat and processed meat consumption was developed on the basis of 5 de novo systematic reviews that considered all of these issues.</p><p><em>Methods</em>: The recommendations were developed by using the Nutritional Recommendations (NutriRECS) guideline development process, which includes rigorous systematic review methodology, and GRADE methods to rate the certainty of evidence for each outcome and to move from evidence to recommendations. A panel of 14 members, including 3 community members, from 7 countries voted on the final recommendations. Strict criteria limited the conflicts of interest among panel members. Considerations of environmental impact or animal welfare did not bear on the recommendations. Four systematic reviews addressed the health effects associated with red meat and processed meat consumption, and 1 systematic review addressed people’s health-related values and preferences regarding meat consumption.</p><p><em>Recommendations</em>: The panel suggests that adults continue current unprocessed red meat consumption (weak recommendation, low-certainty evidence). Similarly, the panel suggests adults continue current processed meat consumption (weak recommendation, low-certainty evidence).</p>'
- - https://annals.org/aim/fullarticle/2752327/patterns-red-processed-meat-consumption-risk-cardiometabolic-cancer-outcomes-systematic
  - "Patterns of Red and Processed Meat Consumption and Risk for Cardiometabolic and Cancer Outcomes: A Systematic Review and Meta-analysis of Cohort Studies"
  - Robin W.M. Vernooij, Dena Zeraatkar, Mi Ah Han, MD, Regina El Dib, Max Zworth, Kirolos Milio, Daegan Sit, Yung Lee, Huda Gomaa, Claudia Valli, Mateusz J. Swierz, Yaping Chang, Steven E. Hanna, Paula M. Brauer, John Sievenpiper, Russell de Souza, Pablo Alonso-Coello, Malgorzata M. Bala, Gordon H. Guyatt, Bradley C. Johnston
  - 2019-11-19
  - 10.7326/M19-1583
  - ! '<p><em>Background</em>: Studying dietary patterns may provide insights into the potential effects of red and processed meat on health outcomes.</p><p><em>Purpose</em>: To evaluate the effect of dietary patterns, including different amounts of red or processed meat, on all-cause mortality, cardiometabolic outcomes, and cancer incidence and mortality.</p><p><em>Data Sources</em>: Systematic search of <span class="smallcaps-auto">MEDLINE</span>, <span class="smallcaps-auto">EMBASE</span>, the Cochrane Central Register of Controlled Trials, <span class="smallcaps-auto">CINAHL</span>, Web of Science, and ProQuest Dissertations &amp; Theses Global from inception to April 2019 with no restrictions on year or language.</p><p><em>Study Selection</em>: Teams of 2 reviewers independently screened search results and included prospective cohort studies with 1000 or more participants that reported on the association between dietary patterns and health outcomes.</p><p><em>Data Extraction</em>: Two reviewers independently extracted data, assessed risk of bias, and evaluated the certainty of evidence using <span class="smallcaps-auto">GRADE</span> (Grading of Recommendations Assessment, Development and Evaluation) criteria.</p><p><em>Data Synthesis</em>: Eligible studies that followed patients for 2 to 34 years revealed low- to very-low-certainty evidence that dietary patterns lower in red and processed meat intake result in very small or possibly small decreases in all-cause mortality, cancer mortality and incidence, cardiovascular mortality, nonfatal coronary heart disease, fatal and nonfatal myocardial infarction, and type 2 diabetes. For all-cause, cancer, and cardiovascular mortality and incidence of some types of cancer, the total sample included more than 400 000 patients; for other outcomes, total samples included 4000 to more than 300 000 patients.</p><p><em>Limitation</em>: Observational studies are prone to residual confounding, and these studies provide low- or very-low-certainty evidence according to the <span class="smallcaps-auto">GRADE</span> criteria.</p><p><em>Conclusion</em>: Low- or very-low-certainty evidence suggests that dietary patterns with less red and processed meat intake may result in very small reductions in adverse cardiometabolic and cancer outcomes.</p>'
- - https://annals.org/aim/fullarticle/2752323/health-related-values-preferences-regarding-meat-consumption-mixed-methods-systematic
  - "Health-Related Values and Preferences Regarding Meat Consumption: A Mixed-Methods Systematic Review"
  - Claudia Valli, Montserrat Rabassa, Bradley C. Johnston, Ruben Kuijpers, Anna Prokop-Dorner, Joanna Zajac, Dawid Storman, Monika Storman, Malgorzata M. Bala, Ivan Solà, Dena Zeraatkar, Mi Ah Han, Robin W.M. Vernooij, Gordon H. Guyatt, Pablo Alonso-Coello
  - 2019-11-19
  - 10.7326/M19-1326
  - ! '<p><em>Background</em>: A person’s meat consumption is often determined by their values and preferences.</p><p><em>Purpose</em>: To identify and evaluate evidence addressing health-related values and preferences regarding meat consumption.</p><p><em>Data Sources</em>: <span class="smallcaps-auto">MEDLINE</span>, <span class="smallcaps-auto">EMBASE</span>, Web of Science, Centre for Agriculture and Biosciences Abstracts, International System for Agricultural Science and Technology, and Food Science and Technology Abstracts were searched from inception to July 2018 without language restrictions.</p><p><em>Study Selection</em>: Pairs of reviewers independently screened search results and included quantitative and qualitative studies reporting adults’ health-related values and preferences regarding meat consumption.</p><p><em>Data Extraction</em>: Pairs of reviewers independently extracted data and assessed risk of bias.</p><p><em>Data Synthesis</em>: Data were synthesized into narrative form, and summaries were tabulated and certainty of evidence was assessed using the <span class="smallcaps-auto">GRADE</span> (Grading of Recommendations Assessment, Development and Evaluation) approach. Of 19 172 initial citations, 41 quantitative studies (38 addressed reasons for meat consumption and 5 addressed willingness to reduce meat consumption) and 13 qualitative studies (10 addressed reasons for meat consumption and 4 addressed willingness to reduce meat consumption) were eligible for inclusion. Thirteen studies reported that omnivores enjoy eating meat, 18 reported that these persons consider meat an essential component of a healthy diet, and 7 reported that they believe they lack the skills needed to prepare satisfactory meals without meat. Omnivores are generally unwilling to change their meat consumption. The certainty of evidence was low for both “reasons for meat consumption” and “willingness to reduce meat consumption in the face of undesirable health effects.”</p><p><em>Limitation</em>: Limited generalizability of findings to lower-income countries, low-certainty evidence for willingness to reduce meat consumption, and limited applicability to specific types of meat (red and processed meat).</p><p><em>Conclusion</em>: Low-certainty evidence suggests that omnivores are attached to meat and are unwilling to change this behavior when faced with potentially undesirable health effects.</p>'
- - https://annals.org/aim/fullarticle/2752321/reduction-red-processed-meat-intake-cancer-mortality-incidence-systematic-review
  - "Reduction of Red and Processed Meat Intake and Cancer Mortality and Incidence: A Systematic Review and Meta-analysis of Cohort Studies"
  - Mi Ah Han, Dena Zeraatkar, Gordon H. Guyatt, Robin W.M. Vernooij, Regina El Dib, Ying Zhang, Abdullah Algarni, Gareth Leung, Dawid Storman, Claudia Valli, Montserrat Rabassa, Nadia Rehman, Michael K. Parvizian, Max Zworth, Luciane Cruz Lopes, Daegan Sit, Malgorzata M. Bala, Pablo Alonso-Coello, Bradley C. Johnston
  - 2019-11-19
  - 10.7326/M19-0699
  - ! '<p><em>Background</em>: Cancer incidence has continuously increased over the past few centuries and represents a major health burden worldwide.</p><p><em>Purpose</em>: To evaluate the possible causal relationship between intake of red and processed meat and cancer mortality and incidence.</p><p><em>Data Sources</em>: Embase, Cochrane Central Register of Controlled Trials, Web of Science, <span class="smallcaps-auto">CINAHL</span>, and ProQuest from inception until July 2018 and <span class="smallcaps-auto">MEDLINE</span> from inception until April 2019 without language restrictions.</p><p><em>Study Selection</em>: Cohort studies that included more than 1000 adults and reported the association between consumption of unprocessed red and processed meat and cancer mortality and incidence.</p><p><em>Data Extraction</em>: Teams of 2 reviewers independently extracted data and assessed risk of bias; 1 reviewer evaluated the certainty of evidence, which was confirmed or revised by the senior reviewer.</p><p><em>Data Synthesis</em>: Of 118 articles (56 cohorts) with more than 6 million participants, 73 articles were eligible for the dose–response meta-analyses, 30 addressed cancer mortality, and 80 reported cancer incidence. Low-certainty evidence suggested that an intake reduction of 3 servings of unprocessed meat per week was associated with a very small reduction in overall cancer mortality over a lifetime. Evidence of low to very low certainty suggested that each intake reduction of 3 servings of processed meat per week was associated with very small decreases in overall cancer mortality over a lifetime; prostate cancer mortality; and incidence of esophageal, colorectal, and breast cancer.</p><p><em>Limitation</em>: Limited causal inferences due to residual confounding in observational studies, risk of bias due to limitations in diet assessment and adjustment for confounders, recall bias in dietary assessment, and insufficient data for planned subgroup analyses.</p><p><em>Conclusion</em>: The possible absolute effects of red and processed meat consumption on cancer mortality and incidence are very small, and the certainty of evidence is low to very low.</p>'
- - https://annals.org/aim/fullarticle/2752320/red-processed-meat-consumption-risk-all-cause-mortality-cardiometabolic-outcomes
  - "Red and Processed Meat Consumption and Risk for All-Cause Mortality and Cardiometabolic Outcomes: A Systematic Review and Meta-analysis of Cohort Studies"
  - Dena Zeraatkar, Mi Ah Han, Gordon H. Guyatt, Robin W.M. Vernooij, Regina El Dib, Kevin Cheung, Kirolos Milio, Max Zworth, Jessica J. Bartoszko, Claudia Valli, Montserrat Rabassa, Yung Lee, Joanna Zajac, Anna Prokop-Dorner, Calvin Lo, Malgorzata M. Bala, Pablo Alonso-Coello, Steven E. Hanna, Bradley C. Johnston
  - 2019-11-19
  - 10.7326/M19-0655
  - ! '<p><em>Background</em>: Dietary guidelines generally recommend limiting intake of red and processed meat. However, the quality of evidence implicating red and processed meat in adverse health outcomes remains unclear.</p><p><em>Purpose</em>: To evaluate the association between red and processed meat consumption and all-cause mortality, cardiometabolic outcomes, quality of life, and satisfaction with diet among adults.</p><p><em>Data Sources</em>: <span class="smallcaps-auto">EMBASE</span> (Elsevier), Cochrane Central Register of Controlled Trials (Wiley), Web of Science (Clarivate Analytics), <span class="smallcaps-auto">CINAHL</span> (<span class="smallcaps-auto">EBSCO</span>), and ProQuest from inception until July 2018 and <span class="smallcaps-auto">MEDLINE</span> from inception until April 2019, without language restrictions, as well as bibliographies of relevant articles.</p><p><em>Study Selection</em>: Cohort studies with at least 1000 participants that reported an association between unprocessed red or processed meat intake and outcomes of interest.</p><p><em>Data Extraction</em>: Teams of 2 reviewers independently extracted data and assessed risk of bias. One investigator assessed certainty of evidence, and the senior investigator confirmed the assessments.</p><p><em>Data Synthesis</em>: Of 61 articles reporting on 55 cohorts with more than 4 million participants, none addressed quality of life or satisfaction with diet. Low-certainty evidence was found that a reduction in unprocessed red meat intake of 3 servings per week is associated with a very small reduction in risk for cardiovascular mortality, stroke, myocardial infarction (MI), and type 2 diabetes. Likewise, low-certainty evidence was found that a reduction in processed meat intake of 3 servings per week is associated with a very small decrease in risk for all-cause mortality, cardiovascular mortality, stroke, MI, and type 2 diabetes.</p><p><em>Limitation</em>: Inadequate adjustment for known confounders, residual confounding due to observational design, and recall bias associated with dietary measurement.</p><p><em>Conclusion</em>: The magnitude of association between red and processed meat consumption and all-cause mortality and adverse cardiometabolic outcomes is very small, and the evidence is of low certainty.</p>'
- - https://www.tensorflow.org/tfrc
  - "TensorFlow Research Cloud (TFRC): Accelerate your cutting-edge machine learning research with free Cloud TPUs"
  - TFRC (Google)
  - ''
  - ''
  - ! "<p>The TensorFlow Research Cloud (TFRC) program enables researchers to apply for access to a cluster of more than 1,000 Cloud TPUs. In total, this cluster delivers a total of more than 180 petaflops of raw compute power! Researchers accepted into the TFRC program can use these Cloud TPUs at no charge to accelerate the next wave of open research breakthroughs. Participants in the TFRC program will be expected to share their TFRC-supported research with the world through peer-reviewed publications, open source code, blog posts, or other means. They should also be willing to share detailed feedback with Google to help us improve the TFRC program and the underlying Cloud TPU platform over time. In addition, participants accept Google's Terms and Conditions, acknowledge that their information will be used in accordance with our Privacy Policy, and agree to conduct their research in accordance with the Google AI principles. Machine learning researchers around the world have done amazing things with the limited computational resources they currently have available. We'd like to empower researchers from many different backgrounds to think even bigger and tackle exciting new challenges that would be inaccessible otherwise.</p> <p>[TFRC is an easy-to-apply cloud credit program which grants free access to up to hundreds of GCP TPUs and sometimes whole TPU pods to researchers & hobbyists like me; I relied on TFRC credits to train a variety of GPT-2-1.5b models which are infeasible on consumer GPUs. It took seconds to apply, they replied in hours with credits, and were highly responsive thereafter as we encountered various TPU issues.]</p>"
- - https://thegradient.pub/machine-learning-ancient-japan/
  - How Machine Learning Can Help Unlock the World of Ancient Japan
  - Alex Lamb
  - 2019-11-17
  - ''
  - ! '<p>Humanity’s rich history has left behind an enormous number of historical documents and artifacts. However, virtually none of these documents, containing stories and recorded experiences essential to our cultural heritage, can be understood by non-experts due to language and writing changes over time…This is a global problem, yet one of the most striking examples is the case of Japan. From 800 until 1900 CE, Japan used a writing system called Kuzushiji, which was removed from the curriculum in 1900 when the elementary school education was reformed. Currently, the overwhelming majority of Japanese speakers cannot read texts which are more than 150 years old. The volume of these texts—comprised of over three million books in storage but only readable by a handful of specially-trained scholars—is staggering. One library alone has digitized 20 million pages from such documents. The total number of documents—including, but not limited to, letters and personal diaries—is estimated to be over one billion. Given that very few people can understand these texts, mostly those with PhDs in classical Japanese literature and Japanese history, it would be very expensive and time-consuming to finance for scholars to convert these documents to modern Japanese. This has motivated the use of machine learning to automatically understand these texts.</p><p>…Given its importance to Japanese culture, the problem with utilizing computers to help with Kuzushiji recognition has been explored extensively through the use of various methods in deep learning and computer vision. However, these models were unable to achieve strong performance on Kuzushiji recognition. This was due to inadequate understanding of Japanese historical literature in the optical character recognition (OCR) community and the lack of high quality standardized datasets. To address this, the National Institute of Japanese Literature (NIJL) created and released a Kuzushiji dataset, curated by the Center for Open Data in the Humanities (CODH). The dataset currently has over 4000 character classes and a million character images.</p><p><strong>KuroNet</strong>: KuroNet is a Kuzushiji transcription model that I developed with my collaborators, Tarin Clanuwat and Asanobu Kitamoto from the ROIS-DS Center for Open Data in the Humanities at the National Institute of Informatics in Japan. The KuroNet method is motivated by the idea of processing an entire page of text together, with the goal of capturing both long-range and local dependencies. KuroNet passes images containing an entire page of text through a residual U-Net architecture (FusionNet) in order to obtain a feature representation…For more information about KuroNet, please checkout our paper <a href="https://arxiv.org/abs/1910.09433" title="Clanuwat et al 2019">“KuroNet: Pre-Modern Japanese Kuzushiji Character Recognition with Deep Learning”</a>, which was accepted to the 2019 International Conference on Document Analysis and Recognition (ICDAR)</p><p>…<strong>Kaggle Kuzushiji Recognition Competition</strong>: While KuroNet achieved state-of-the-art results at the time of its development and was published in the top tier conference on document analysis and recognition, we wanted to open this research up to the broader community. We did this partially to stimulate further research on Kuzushiji and to discover ways in which KuroNet may be deficient. Ultimately, after 3 months of competition, which saw 293 teams, 338 competitors, and 2652 submissions, the winner achieved an F1 score of 0.950. When we evaluated KuroNet on the same setup, we found that it achieved an F1 score 0.902, which would have put it in 12th place—which, although acceptable, remains well below the best performing solutions.</p><p>…<strong>Future Research</strong>: The work done by CODH has already led to substantial progress in transcribing Kuzushiji documents, however, the overall problem of unlocking the knowledge of historical documents is far from solved.</p>'
- - https://scholarspace.manoa.hawaii.edu/bitstream/10125/64319/0465.pdf
  - "Dishing the Deets: How dark-web users teach each other about international drug shipments"
  - Reagan C. Smith, Richard Frank
  - 2020-01-07
  - ''
  - ! 'International trafficking of drugs enabled by the dark-web is still a problem despite the increase in take-down actions. Even though the transaction takes place digitally, the national postal systems are the ones being exploited and used for delivery. Users of the dark-web readily share information on forums, cryptomarkets, and feedback pages to maximize their safety and success while conducting these drug transactions. Using data collected from forums, vendor profiles, and feedback pages, this study provides an evidence that the knowledge being shared on the dark-web is rich data law enforcement and governments need to use as intelligence. Users discuss all aspect of the delivery process, including proper addressing, stealth packaging, and risks associated with taking delivery of the package. Based on these findings, policy recommendations are made to guide the implementation of techniques to counter the rise of dark-web-enabled drug shipments in the fight against drugs and cryptomarkets...Data collected for this research was obtained from two forums and one cryptomarket between the period of November 2017 and April 2018. [/r/DNM, Dread, & Dream Market respectively].'
- - https://onlinelibrary.wiley.com/doi/full/10.1002/acp.3532
  - "Background music stints creativity: Evidence from compound remote associate tasks"
  - Emma Threadgold, John E. Marsh, Neil McLatchie, Linden J. Ball
  - 2019-02-02
  - 10.1002/acp.3532
  - ! "Background music has been claimed to enhance people's creativity. In three experiments, we investigated the impact of background music on performance of Compound Remote Associate Tasks (CRATs), which are widely thought to tap creativity. Background music with foreign (unfamiliar) lyrics (Experiment 1), instrumental music without lyrics (Experiment 2), and music with familiar lyrics (Experiment 3) all significantly impaired CRAT performance in comparison with quiet background conditions. Furthermore, Experiment 3 demonstrated that background music impaired CRAT performance regardless of whether the music induced a positive mood or whether participants typically studied in the presence of music. The findings challenge the view that background music enhances creativity and are discussed in terms of an auditory distraction account (interference-by-process) and the processing disfluency account."
- - https://mindhacks.com/2016/12/08/rational-judges-not-extraneous-factors-in-decisions/
  - "Rational Judges, Not Extraneous Factors In Decisions"
  - Tom Stafford
  - 2016-12-08
  - ''
  - ! '<p>This seeming evidence of the irrationality of judges has been cited hundreds of times, in economics, psychology and legal scholarship. Now, a new analysis by <a href="http://journal.sjdm.org/16/16823/jdm16823.html" title="The irrational hungry judge effect revisited: Simulations reveal that the magnitude of the effect is overestimated">Andreas Glöckner in the journal <em>Judgement and Decision Making</em></a> questions these conclusions.</p><p>Glöckner’s analysis doesn’t prove that extraneous factors weren’t influencing the judges, but he shows how the same effect could be produced by entirely rational judges interacting with the protocols required by the legal system.</p><p>The main analysis works like this: we know that favourable rulings take longer than unfavourable ones (~7 mins vs ~5 mins), and we assume that judges are able to guess how long a case will take to rule on before they begin it (from clues like the thickness of the file, the types of request made, the representation the prisoner has and so on). Finally, we assume judges have a time limit in mind for each of the three sessions of the day, and will avoid starting cases which they estimate will overrun the time limit for the current session.</p><p>It turns out that this kind of rational time-management is sufficient to generate the drops in favourable outcomes. How this occurs isn’t straightforward and interacts with a quirk of original author’s data presentation (specifically their graph shows the order number of cases when the number of cases in each session varied day to day–so, for example, it shows that the 12<sup>th</sup> case after a break is least likely to be judged favourably, but there wasn’t always a 12<sup>th</sup> case in each session. So sessions in which there were more unfavourable cases were more likely to contribute to this data point).</p>'
- - http://nautil.us/blog/impossibly-hungry-judges
  - Impossibly Hungry Judges
  - Daniël Lakens
  - 2017-07-05
  - ''
  - ! '<p>I was listening to a recent Radiolab episode on blame and guilt, where the guest Robert Sapolsky mentioned a famous study on judges handing out harsher sentences before lunch than after lunch….During the podcast, it was mentioned that the percentage of favorable decisions drops from 65% to 0% over the number of cases that are decided on. This sounded unlikely. I looked at Figure 1 from the paper (below), and I couldn’t believe my eyes. Not only is the drop indeed as large as mentioned—it occurs three times in a row over the course of the day, and after a break, it returns to exactly 65%!</p><p>…Some people dislike statistics. They are only interested in effects that are so large, you can see them by just plotting the data. This study might seem to be a convincing illustration of such an effect. My goal in this blog is to argue against this idea. You need statistics, maybe <em>especially</em> when effects are so large they jump out at you. When reporting findings, authors should report <em>and interpret</em> effect sizes. An important reason for this is that effects can be impossibly large.</p><p>…If hunger had an effect on our mental resources of this magnitude, our society would fall into minor chaos every day at 11:45 a.m. Or at the very least, our society would have organized itself around this incredibly strong effect of mental depletion. Just like manufacturers take size differences between men and women into account when producing items such as golf clubs or watches, we would stop teaching in the time before lunch, doctors would not schedule surgery, and driving before lunch would be illegal. If a psychological effect is this big, we don’t need to discover it and publish it in a scientific journal—you would already know it exists. Sort of how the “after lunch dip” is a strong and replicable finding that you can <em>feel</em> yourself (and that, as it happens, is directly in conflict with the finding that judges perform better immediately after lunch—surprisingly, the authors don’t discuss the <em>after lunch dip</em>).</p><p>…I think it is telling that most psychologists don’t seem to be able to recognize data patterns that are too large to be caused by psychological mechanisms. There are simply no plausible psychological effects that are strong enough to cause the data pattern in the hungry judges study. Implausibility is not a reason to completely dismiss empirical findings, but impossibility is. It is up to authors to interpret the effect size in their study, and to show the mechanism through which an effect that is impossibly large, becomes plausible. Without such an explanation, the finding should simply be dismissed.</p>'
- - https://www.newyorker.com/magazine/2020/01/13/a-world-without-pain
  - "A World Without Pain: Does hurting make us human?"
  - Ariel Levy (The New Yorker)
  - 2020-01-06
  - ''
  - ! '<p>Cameron is entirely insensitive to physical pain. As a child, she fell and hurt her arm while roller-skating, but had no idea she’d broken it until her mother noticed that it was hanging strangely. Giving birth was no worse…Cameron was having a trapeziectomy, an operation to remove a small bone at the base of the thumb joint. Though her hands never hurt, they’d become so deformed by arthritis that she couldn’t hold a pen properly. She’d had a similar experience with her hip, which had recently been replaced; it didn’t hurt, but her family noticed that she wasn’t walking normally. She saw her local doctor about it several times, but the first question was always “How much pain are you in?” And the answer was always “None.” (“The third time I was there I think they figured, ‘We’ll just take an X-ray to shut this woman up,’” Cameron told me. “Then the X-ray came in and it was really bad. Everything was all distorted and mangled and crumbling. He said, ‘<em>Wow</em>. This has got to be done.’”)…Cameron is beguiled by the idea that she can help alleviate others’ suffering—she remembers the terrible migraines that tormented her mother. Her father, however, was pain-free. “I never saw him take an aspirin,” Cameron said. “I’m convinced he was the same as me, because I never heard my father complaining about any pain, ever. He died suddenly, of a brain hemorrhage—I think other people would have had a warning.” · …People with severe congenital neuropathy tend to die young, because they injure themselves so frequently and severely. (Without pain, children are in constant danger. They swallow something burning hot, the esophagus ruptures, bacteria spill into the internal organs, and terminal sepsis sets in. They break their necks roughhousing. To protect some patients, doctors have removed all their teeth to prevent them from chewing off their tongues and bleeding to death.) · …Cameron does not have neuropathy: she can feel all the sensations the rest of us do, except pain. The most striking difference between her and everyone else is the way she processes endocannabinoids—chemicals that exist naturally in every human brain. Endocannabinoids mitigate our stress response, and they bind to the same receptors as the THC in the kind of cannabis you smoke. Normally, they are broken down by an enzyme called fatty acid amide hydrolase, or FAAH. But Cameron has a mutation on her FAAH gene that makes the enzyme less effective—so her endocannabinoids build up. She has extraordinarily high levels of one in particular: anandamide, whose name is derived from the Sanskrit word for “bliss.” · About a third of the population has a mutation in the FAAH gene, which provides increased levels of anandamide. “That phenotype—low levels of anxiety, forgetfulness, a happy-go-lucky demeanor—isn’t representative of how everyone responds to cannabis, but you see a lot of the prototypical changes in them that occur when people consume cannabis,” said Matthew Hill, a biologist at the University of Calgary’s Hotchkiss Brain Institute, who was a co-author of the Cameron paper. The FAAH gene, like every gene, comes in a pair. People who have the mutation in one allele of the gene seem a little high; people who have it in both even more so. Jo Cameron is fully baked. “When I met Jo for the first time, I was just struck by her,” Cox, an affable forty-year-old with a scruffy beard, told me, one afternoon in his lab at U.C.L. “She was <em>very</em> chatty. Did you notice that?” (It’s hard to miss.) “I said to her, ‘Are you worried about what’s going to happen today?’ Because she was meeting our clinicians to have a skin biopsy and do quantitative sensory testing—pain-threshold tests. She said, ‘No. In fact, I’m never worried about anything.’” Cox told me that it was difficult to get through everything in the time they’d allotted, because Cameron was so friendly and loquacious with the scientists, even as they burned her, stuck her with pins, and pinched her with tweezers until she bled. This imperviousness to pain is what makes her distinct from everyone else with a FAAH mutation. They, like even the most committed stoners, can still get hurt. · …I asked Matthew Hill—a renowned expert on cannabinoids and stress—if there was any downside to Cameron’s biology, and he laughed out loud. “Yes! From an evolutionary perspective, it would be tremendously destructive for a species to have that,” he said. Without fear, you drown in waves that you shouldn’t be swimming in; you take late-night strolls in cities that you don’t know; you go to work at a construction site and neglect to put on a hard hat. “Her phenotype is only beneficial in an environment where there is no danger,” Hill asserted. “If you can’t be concerned about a situation where you’d be at risk of something adverse happening to you, you are more likely to put yourself in one. Anxiety is a highly adaptive process: that’s why every mammalian species exhibits some form of it.” · Unlike other pain-insensitive people, Cameron has made it into her seventies without getting badly hurt. Sometimes she realizes that she’s burning her hand on the stove because she smells singeing; sometimes she cuts herself in the garden and sees that she’s bleeding. But none of that has been severe, and Cameron did raise two children safely into adulthood. “The human brain is very capable of learning, ‘This is what’s appropriate to do in this situation,’” Hill said. Cameron’s relative cautiousness may have developed imitatively. “And there may not have been that much threat presented to her—she’s lived in a rural community in Scotland,” he concluded. “Maybe she hasn’t had to deal with that much that would physically or emotionally harm her.” · …One complicating question is how much of Cameron’s Cameronness is really a consequence of her FAAH mutation and FAAH OUT deletion. She has plenty of other genes, after all, and her upbringing and her early environment also played a role in making her who she is. Since the paper was published, Matthew Hill has heard from half a dozen people with pain insensitivity, and he told me that many of them seemed nuts. “If you had this phenotype and weren’t a generally pleasant person like Jo—maybe you’re, like, a douche-y frat boy—the way that you would process this might be entirely different. Our whole perception of this phenotype is explicitly based on the fact that it was Jo who presented it.”</p>'
- - https://csimq-journals.rtu.lv/article/download/csimq.2019-21.04/1744
  - "Evaluation of Adblock Software Usage"
  - Anna Sołtysik-Piorunkiewicz, Artur Strzelecki, Edyta Abramek
  - 2019-12
  - 10.7250/csimq.2019-21.04
  - ! 'The article shows the main factors of adblocking software usage. The study was based on data obtained by a web questionnaire. The research was focused on evaluation of ad blocking (adblock) software usage factors in five categories: (1) gender, age, and education; (2) use of advertising and sources of knowledge about advertising; (3) technical and social reasons for blocking online advertisements; (4) usage of an adblock-wall; and (5) type of online advertisement. An evaluation of adblock usage factors revealed four main technical reasons for adblock usage connected with website technology and web development problems—interruption, amount of ads, speed, and security; and one social reason for adblock usage, namely, the problem of privacy. [Keywords: Adblock Software, Web Advertisement, Website, Security, Privacy.]'
- - /docs/eva/2012-hoffer.pdf
  - "Aesthetics of Destruction: Music and the Worldview of Shinji Ikari in <em>Neon Genesis Evangelion</em>"
  - Heike Hoffer
  - '2012'
  - ''
  - ! "Director Anno Hideaki's series <em>Neon Genesis Evangelion</em> caused a sensation when it first aired on TV Tokyo in 1995 and has become one of the most influential anime ever made. Since its premiere, fans across the globe have debated the possible interpretations of the complex plot, but little has been said about how composer Sagisu Shiro's score might contribute to understanding the series. Anno's rehabilitation in a Jungian clinic and subsequent personal study of human psychology plays heavily into understanding the main character Ikari Shinji, and music has much to contribute to appreciating Shinji's view of the world. Shinji is an impressionable fourteen-year old boy, so his musical interpretations of the people and things around him do not always match reality. Sagisu's music gives the viewers welcome insight into Shinji's thoughts and feelings as he matures throughout the series."
- - /docs/economics/2016-kuran.pdf
  - "Legal Roots of Authoritarian Rule in the Middle East: Civic Legacies of the Islamic Waqf"
  - "Timur Kuran"
  - '2016'
  - "10.5131/AJCL.2016.0014"
  - ! "In the legal system of the premodern Middle East, the closest thing to an autonomous private organization was the Islamic waqf. This non-state institution inhibited political participation, collective action, and rule of law, among other indicators of democratization. It did so through several mechanisms. Its activities were essentially set by its founder, which limited its capacity to meet political challenges. Being designed to provide a service on its own, it could not participate in lasting political coalitions. The waqf’s beneficiaries had no say in evaluating or selecting its officers, and they had trouble forming a political community. Thus, for all the resources it controlled, the Islamic waqf contributed minimally to building civil society. As a core element of Islam’s classical institutional complex, it perpetuated authoritarian rule by keeping the state largely unrestrained. Therein lies a key reason for the slow pace of the Middle East’s democratization process."
- - https://github.com/ricsonc/transformers-play-chess/blob/master/README.md
  - Transformers Play Chess
  - Ricson Cheng
  - 2020-01-10
  - ''
  - ! '<p>The Shannon entropy of natural English language is roughly one byte per word, depending on the dataset used. Shannon estimated the number of possible chess games to be 10<sup>120</sup>. I’ve also seen an estimate of 3 reasonable moves per ply (so 10<sup>40</sup> possible 40 move games). This begs the question: just how much information is there in a chess move?…I treated this as a sequence modeling problem. An alternative (and possibly better) approach would be to explicitly make use of the board state. However as I was lazy, I did not do this. I was also motivated by the idea of recreating blindfold chess, which is challenging for humans, but unclear for computers (how would you blindfold a computer?—(also see Tom Murphy’s Elo World)). Also as the “Markovian” approach of simply predicting the move given the current board state has been done many, many times before, I decided this was more interesting.</p><p>…The <code>lichess.org</code> game database contains at the time of writing roughly 1 billion games…I chose to use long algebraic notation, which specifies the start and end coordinate of every piece moved (for example, e2e4). “special” moves also include castling and promotion. There are slightly less than 2000 valid unique tokens in this notation</p><p>…I used the <code>transformer_big_single_gpu</code> (henceforth known as T78) model from the tensor2tensor repository which has roughly 78 million parameters. I used the default hyperparameters and did not tune anything. I trained on a single 1080ti for almost 4 days (~2 million steps). This turns out to be roughly 50 million games, which is to say, the model only saw 25% of the dataset.</p><p>…Results:</p><ul><li>A games: 2.15 bits per ply, 4.43 perplexity</li><li>B games: 2.26 bits per ply, 4.80 perplexity</li></ul><p>I “preregistered” a guess of 2.5 bits per ply before running any experiments. After seeing the results, I believe a better designed model could probably reach between 1.6 and 2.0 BPP. I also believe a larger model would perform better, as I was probably close to saturating the capacity of T78.</p><p>[Response to <a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/">“A Very Unlikely Chess Game”</a>, see <a href="https://old.reddit.com/r/slatestarcodex/comments/el87vo/a_very_unlikely_chess_game/fdh0vqd/">Reddit</a>.]</p>'
- - /docs/genetics/selection/2019-trumble.pdf
  - "The Exposome in Human Evolution: From Dust to Diesel"
  - Benjamin C. Trumble, Caleb E. Finch
  - 2019-12
  - 10.1086/706768
  - ! 'Global exposures to air pollution and cigarette smoke are novel in human evolutionary history and are associated with at least 12 million premature deaths per year. We investigate the history of the human <em>exposome</em> for relationships between novel environmental toxins and genetic changes during human evolution in six phases. Phase I: With increased walking on savannas, early human ancestors inhaled crustal dust, fecal aerosols, and spores; carrion scavenging introduced new infectious pathogens. Phase II: Domestic fire exposed early <em>Homo</em> to novel toxins from smoke and cooking. Phases III and IV: Neolithic to preindustrial <em>Homo</em> sapiens incurred infectious pathogens from domestic animals and dense communities with limited sanitation. Phase V: Industrialization introduced novel toxins from fossil fuels, industrial chemicals, and tobacco at the same time infectious pathogens were diminishing. Thereby, pathogen-driven causes of mortality were replaced by chronic diseases driven by sterile inflammogens, exogenous and endogenous. Phase VI: Considers future health during global warming with increased air pollution and infections. We hypothesize that adaptation to some ancient toxins persists in genetic variations associated with inflammation and longevity. [Keywords: exposome, human evolution, genes, toxins, infections.]'
- - https://www.nytimes.com/2020/01/13/science/air-pollution-fires-genes.html
  - "Air Pollution, Evolution, and the Fate of Billions of Humans: It’s not just a modern problem. Airborne toxins are so pernicious that they may have shaped our DNA over millions of years"
  - Carl Zimmer (The New York Times)
  - 2020-01-13
  - ''
  - ! '<p>Scientists are still figuring out how air pollution causes these ailments. They are also puzzling over the apparent resilience that some people have to this modern onslaught. Some researchers now argue that the answers to these questions lie in our distant evolutionary past, millions of years before the first cigarette was lit and the first car hit the road.</p><p>Our ancestors were bedeviled by airborne toxins even as bipedal apes walking the African savanna, argued Benjamin Trumble, a biologist at Arizona State University, and Caleb Finch of the University of Southern California, in the December issue of the Quarterly Review of Biology. Our forebears evolved defenses against these pollutants, the scientists propose. Today, those adaptations may provide protection, albeit limited, against tobacco smoke and other airborne threats. But our evolutionary legacy may also be a burden, Dr. Trumble and Dr. Finch speculated. Some genetic adaptations may have increased our vulnerability to diseases linked to air pollution. It is “a really creative, interesting contribution to evolutionary medicine,” said Molly Fox, an anthropologist at the University of California, Los Angeles, who was not involved in the new study. The story begins about seven million years ago. Africa at the time was gradually growing more arid. The Sahara emerged in northern Africa, while grasslands opened up in eastern and southern Africa. The ancestors of chimpanzees and gorillas remained in the retreating forests, but our ancient relatives adapted to the new environments. They evolved into a tall, slender frame well suited to walking and running long distances. Dr. Finch and Dr. Trumble believe that early humans faced another challenge that has gone largely overlooked: the air. Periodically, the savanna would have experienced heavy dust storms from the Sahara, and our distant ancestors may have risked harm to their lungs from breathing in the silica-rich particles. “When the dust is up, we’re going to see more pulmonary problems,” Dr. Finch said. Even today, Greek researchers have found that when Sahara winds reach their country, patients surge into hospitals with respiratory complaints. The dense foliage of tropical forests gave chimpanzees and gorillas a refuge from dust. But the earliest humans, wandering the open grasslands, had nowhere to hide. Dust was not the only hazard. The lungs of early humans also may have been irritated by the high levels of pollen and particles of fecal matter produced by the savanna’s vast herds of grazing animals. Dr. Finch and Dr. Trumble maintain that scientists should consider whether these new challenges altered our biology through natural selection. Is it possible, for instance, that people who are resilient to cigarette smoke have inherited genetic variants that protected their distant ancestors from cave fires?</p><p>…“Most traditional people live in a highly smoky environment,” Dr. Finch said. “I think it has been a fact of human living for us even before our species.” Smoke created a new evolutionary pressure, he and Dr. Trumble believe. Humans evolved powerful liver enzymes, for example, to break down toxins passing into the bloodstream from the lungs. Gary Perdew, a molecular toxicologist at Penn State University, and his colleagues have found evidence of smoke-driven evolution in another gene, <span class="smallcaps-auto">AHR</span>. This gene makes a protein found on cells in the gut, lungs and skin. When toxins get snagged on the protein, cells release enzymes that break down the poisons. Other mammals use <span class="smallcaps-auto">AHR</span> to detoxify their food. But the protein is also effective against some of the compounds in wood smoke. Compared to other species, the human version produces a weaker response to toxins, perhaps because <span class="smallcaps-auto">AHR</span> protein is not the perfect protector—the fragments it leaves behind can cause tissue damage. Before fire, our ancestors did not need to use <span class="smallcaps-auto">AHR</span> very often; in theory, their bodies could tolerate the limited damage the protein caused. But when we began breathing smoke regularly and needing the <span class="smallcaps-auto">AHR</span> protein constantly, the gene might have become dangerous to our health. Dr. Perdew believes that humans evolved a weaker <span class="smallcaps-auto">AHR</span> response as a way to find “a sweet spot,” a compromise that minimized the damage of airborne pollutants without causing too many side effects. These adaptations were never perfect, as evidenced by the fact that millions of people still die today from indoor air pollution. But evolution doesn’t seek perfect health.</p>'
- - https://www.stalbansreview.co.uk/news/4125149.blind-veteran-tells-tales-from-war-and-life-since/
  - "Blind veteran tells tales from war and life since: An ex-serviceman blinded in battle has spoken exclusively to reporter Alexandra Barham about the horrors of war and the trials and tribulations of life that followed without sight"
  - Alexandra Barham, Michael Tetley
  - 2009-02-13
  - ''
  - ! '<p>Mike, who was born and raised in Kenya speaking its native language Swahili, was conscripted to command indigenous troops in the King’s African Rifles as unrest began to spread throughout his homeland. It was after Mau Mau militants ambushed a police truck that a battle erupted between the rivals. A clash Mike so vividly recalls as it marked the last time he could appreciate the gift of sight before it was lost. Remembering the battle, Mike said: “One of the Mau Mau threw a grenade at me and it landed by my foot. I jumped away from it and threw myself on the ground hoping that when it went off I wouldn’t get hit.”The next thing I remember I was running flat out and I got a bullet in my right ear which came out of my right eye. “My dad always said I didn’t have anything between my ears and now he’s got definite proof.”The next thing I remember I fell over and as I picked myself up everything went black. I sat down and I can’t remember much more than that—not in a logical sense anyway." Dissatisfied with blasting their victim with a rifle—nearly killing him—the Mau Mau rebels returned armed with machetes to cut up Mike, who lay helpless on the ground nursing his wound. Powerless to defend himself, Mike has always owed his survival to an ally soldier, Reguton—with whom he still has regular contact—who shot dead the seven rebels.</p><p>…Mike was transferred to a military hospital in England after the attack where he received the devastating news that he would never see again. Just a week before the shooting Mike had asked for his girlfriend’s hand in marriage, but following doctors’ gloomy prognosis he broke off the engagement. “After I was blinded I never thought I could look after a wife,” he said. “I didn’t think I would be able to look after myself let alone anyone else—it’s one of my biggest regrets.” But anxious not to allow his disability to blight the years ahead of him, Mike began learning the art of braille at St Dunstan’s, a national charity for the blind. Soon after Mike enrolled on a physiotherapy course with the Royal National Institute for the Blind (<span class="smallcaps-auto">RNIB</span>) suggested by his dad who felt the career suited his structural interests. It was during his training that he met his late wife Selma, and the couple eventually married in 1957. For the past 45 years Mike has been running a thriving physiotherapy clinic at his St Albans home and he remains committed to his work.</p>'
- - https://www.theguardian.com/society/2011/jul/17/the-rape-of-men
  - "The rape of men: the darkest secret of war: Sexual violence is one of the most horrific weapons of war, an instrument of terror used against women. Yet huge numbers of men are also victims. In this harrowing report, Will Storr travels to Uganda to meet traumatised survivors, and reveals how male rape is endemic in many of the world's conflicts"
  - Will Storr (The Guardian)
  - 2011-07-17
  - ''
  - ! '<p>Of all the secrets of war, there is one that is so well kept that it exists mostly as a rumour. It is usually denied by the perpetrator and his victim. Governments, aid agencies and human rights defenders at the UN barely acknowledge its possibility. Yet every now and then someone gathers the courage to tell of it…“That was hard for me to take,” Owiny tells me today. “There are certain things you just don’t believe can happen to a man, you get me? But I know now that sexual violence against men is a huge problem. Everybody has heard the women’s stories. But nobody has heard the men’s.”</p><p>It’s not just in East Africa that these stories remain unheard. One of the few academics to have looked into the issue in any detail is Lara Stemple, of the University of California’s Health and Human Rights Law Project. Her study <a href="https://repository.uchastings.edu/cgi/viewcontent.cgi?article=3728&amp;context=hastings_law_journal#page=2" title="Stemple 2009">“Male Rape and Human Rights”</a> notes incidents of male sexual violence as a weapon of wartime or political aggression in countries such as Chile, Greece, Croatia, Iran, Kuwait, the former Soviet Union and the former Yugoslavia. Twenty-one per cent of Sri Lankan males who were seen at a London torture treatment centre reported sexual abuse while in detention. In El Salvador, 76% of male political prisoners surveyed in the 1980s described at least one incidence of sexual torture. A study of 6,000 concentration-camp inmates in Sarajevo found that 80% of men reported having been raped…Dolan first heard of wartime sexual violence against men in the late 1990s while researching his PhD in northern Uganda, and he sensed that the problem might be dramatically underestimated. Keen to gain a fuller grasp of its depth and nature, he put up posters throughout Kampala in June 2009 announcing a “workshop” on the issue in a local school. On the day, 150 men arrived. In a burst of candour, one attendee admitted: “It’s happened to all of us here.”…a rare 2010 survey, published in the Journal of the American Medical Association, found that 22% of men and 30% of women in Eastern Congo reported conflict-related sexual violence.</p><p>…Back at <span class="smallcaps-auto">RLP</span> I’m told about the other ways in which their clients have been made to suffer. Men aren’t simply raped, they are forced to penetrate holes in banana trees that run with acidic sap, to sit with their genitals over a fire, to drag rocks tied to their penis, to give oral sex to queues of soldiers, to be penetrated with screwdrivers and sticks. Atim has now seen so many male survivors that, frequently, she can spot them the moment they sit down. “They tend to lean forward and will often sit on one buttock,” she tells me. “When they cough, they grab their lower regions. At times, they will stand up and there’s blood on the chair. And they often have some kind of smell.”</p>'
- - https://www.theguardian.com/world/2017/nov/03/revealed-male-used-systematically-in-libya-as-instrument-of-war
  - "Revealed: male rape used systematically in Libya as instrument of war: Videos and testimony expose brutal tactics used by several factions in fractured country"
  - Cécile Allegra
  - 2017-11-03
  - ''
  - ! '<p>Male rape is being used systematically in Libya as an instrument of war and political domination by rival factions, according to multiple testimonies gathered by investigators. Years of work by a Tunis-based group and witnessed by a journalist from <em>Le Monde</em> have produced harrowing reports from victims, and video footage showing men being sodomised by various objects, including rockets and broom handles. In several instances, witnesses say a victim was thrown into a room with other prisoners, who were ordered to rape him or be killed.</p><p>The atrocity is being perpetrated to humiliate and neutralise opponents in the lawless, militia-dominated country. Male rape is such a taboo in Arab societies that the abused generally feel too damaged to rejoin political, military or civic life. One man, Ahmed, told investigators he was detained for four years in a prison in Tomina, on the outskirts of Misrata. “They separate you to subjugate you,” he said. “‘Subjugate the men’, that’s the expression that they use. So that you never hold your head up again. And they were filming everything with their phones. “They take a broom and fix it on the wall. If you want to eat, you have to take off your pants, back on to the broom and not move off until the jailer sees blood flowing. Nobody can escape it.”</p><p>…In one camp, south of Tripoli, a man called Ali recounted his experience. He was 39 but looked 65 and walked with a cane. “Some of us were locked in a room, naked, for a whole night with groups of migrants,” he said. “The guards did not release them until they had all raped each other. Fortunately, I didn’t go through that, I only got the stick and the wheel.” The “wheel” involved being put naked and folded double, through a tyre suspended from the ceiling, making it easier for torturers to penetrate him with weaponry. Ali said he now had physical problems, “leaks” as he called them.</p><p>In another camp in southern Tripoli, Fathia said women were not immune. She said her entire family was violated by a militia from Misrata, with the men being deliberately targeted. “They dragged me in the street, in front of everyone, saying: ‘You raped our girls. We’ll do the same thing to you.’ “The worst thing they did to me,” she whispered, “is to rape me in front of my eldest son. Since then, he won’t speak to me.” Asked about other inmates who suffered a similar ordeal, Fathia said: “I only heard men’s voices. They were screaming, day and night.”</p>'
- - /docs/economics/2017-akam-theexquisitelyenglishandamazinglylucrativeworldoflondonclerks.html
  - "The Exquisitely English (and Amazingly Lucrative) World of London Clerks: It’s a Dickensian profession that can still pay upwards of $650,000 per year"
  - Simon Akam (Bloomberg News)
  - 2017-05-23
  - ''
  - ! '<p>Alex/John/Mark Taylor belongs to one of the last surviving professions of Dickensian London. Clerks have co-existed with chimney sweeps and gene splicers. It’s a trade that one can enter as a teenager, with no formal qualifications, and that’s astonishingly well-paid. A senior clerk can earn a half-million pounds per year, or more than $650,000, and some who are especially entrenched make far more.</p><p>Clerks—pronounced “clarks”—have no equivalent in the U.S. legal system, and have nothing in common with the Ivy League–trained Supreme Court aides of the same spelling. They exist because in England and Wales, to simplify a bit, the role of lawyer is divided in two: There are solicitors, who provide legal advice from their offices, and there are barristers, who argue in court. Barristers get the majority of their business via solicitors, and clerks act as the crucial middlemen between the tribes—they work for and sell the services of their barristers, steering inquiring solicitors to the right man or woman. Clerks are by their own cheerful admission “wheeler-dealers,” what Americans might call hustlers. They take a certain pride in managing the careers of their bosses, the barristers—a breed that often combines academic brilliance with emotional fragility. Many barristers regard clerks as their pimps. Some, particularly at the junior end of the profession, live in terror of clerks. The power dynamic is baroque and deeply English, with a naked class divide seen in few other places on the planet. Barristers employ clerks, but a bad relationship can strangle their supply of cases. In his 1861 novel <em>Orley Farm</em>, Anthony Trollope described a barrister’s clerk as a man who “looked down from a considerable altitude on some men who from their professional rank might have been considered as his superiors.”…One of the most peculiar aspects of the clerk-barrister relationship is that clerks handle money negotiations with clients. Barristers argue that avoiding fee discussions keeps their own interactions with clients clean and uncomplicated, but as a consequence, they’re sometimes unaware of how much they actually charge. The practice also insulates and coddles them. Clerks become enablers of all sorts of curious, and in some cases self-destructive, behavior.</p><p>…John Flood, a legal sociologist who in 1983 published the only book-length study of barristers’ clerks, subtitled <em>The Law’s Middlemen</em>, uses an anthropological lens to explain the relationship. He suggests that barristers, as the de facto priests of English law—with special clothes and beautiful workplaces—require a separate tribe to keep the temple flames alight and press money from their congregation. Clerks keep barristers’ hands clean; in so doing they accrue power, and they’re paid accordingly. I asked more than a dozen clerks and barristers, as well as a professional recruiter, what the field pays. Junior clerks, traditionally recruited straight after leaving school at 16 and potentially with no formal academic qualifications, start at £15,000 to £22,000 ($19,500 to $28,600); after 10 years they can make £85,000. Pay for senior clerks ranges from £120,000 to £500,000, and a distinct subset can earn £750,000. The Institute of Barristers’ Clerks disputed these figures, saying the lows were too low and the highs too high. But there’s no doubt that the best clerks are well-rewarded. David Grief, 63, a senior clerk at the esteemed Essex Court Chambers, spoke to me enthusiastically about his personal light airplane, a TB20 Trinidad.</p><p>…Before the U.K. decimalized its currency in 1971, clerks received “shillings on the guinea” for each case fee. Under the new money system, the senior clerks’ take was standardized at 10% of their chambers’ gross revenue. Sometimes, but not always, they paid their junior staff and expenses out of this tithe. Chambers at the time were typically small, four to six barristers strong, but in the 1980s, they grew. As they added barristers and collected more money, each chambers maintained just one chief clerk, whose income soared. The system was opaque: The self-employed barristers didn’t know what their peers within their own chambers were paid, and in a precomputer age, with all transactions recorded in a byzantine paper system, barristers sometimes didn’t know what their clerks earned, either. Jason Housden, a longtime clerk who now works at Matrix Chambers, told me that, when he started out in the 1980s at another office, his senior clerk routinely earned as much as the top barristers and on occasion was the best-paid man in the building. · One anecdote from around the same time, possibly apocryphal, is widely shared. At a chambers that had expanded and was bringing in more money, three silks decided their chief clerk’s compensation, at 10%, had gotten out of hand. They summoned him for a meeting and told him so. In a tactical response that highlights all the class baggage of the clerk-barrister relationship, as well as the acute British phobia of discussing money, the clerk surprised the barristers by agreeing with them. “I’m not going to take a penny more from you,” he concluded. The barristers, gobsmacked and paralyzed by manners, never raised the pay issue again, and the clerk remained on at 10% until retirement. · Since the 1980s, fee structures have often been renegotiated when a senior clerk retires. Purely commission-based arrangements are now rare—combinations of salary and incentive are the rule, though some holdouts remain. Goddard told me last summer that he receives 3% of the entire take of the barristers at 4 Stone; later he said this was inaccurate, and that his pay was determined by a “complicated formula.” (Pupil barristers, as trainees are known, start there at £65,000 per year, and the top silks each make several million pounds.) · The huge sums that clerks earn, at least relative to their formal qualifications, both sit at odds with the feudal nature of their employment and underpin it. In some chambers, clerks still refer to even junior barristers as “sir” or “miss.” Housden remembers discussing this issue early in his career with a senior clerk. He asked the man whether he found calling people half his age “sir” demeaning. The reply was straightforward: “For three-quarters of a million pounds per year, I’ll call anyone sir.”</p>'
- - https://old.reddit.com/r/SubSimulatorGPT2Meta/comments/entfgx/update_upgrading_to_15b_gpt2_and_adding_22_new/
  - "Update: Upgrading to 1.5B GPT-2, and adding 22 new subreddit-bots"
  - disumbrationist
  - '2020-01-12'
  - ''
  - ! '<p>When I originally trained the models in May 2019, I’d used the 345M version of GPT-2, which at the time was the largest one that OpenAI had publicly released. Last November, however, OpenAI <a href="https://openai.com/blog/gpt-2-1-5b-release/">finally released the full 1.5 billion parameter model</a>.</p><p>The 1.5B model requires much more memory to fine-tune than the 345M, so I was initially having a lot of difficulty getting it to work on Colab. Thankfully, I was contacted by <a href="https://old.reddit.com/u/gwern">/u/gwern</a> (<a href="https://www.patreon.com/gwern">here’s his Patreon</a>) and Shawn Presser (<a href="https://old.reddit.com/u/shawwwn">/u/shawwwn</a>), who very generously offered to do the fine-tuning themselves if I provided them with the dataset. This training took about 2 weeks, and apparently required <a href="https://twitter.com/gwern/status/1215005375407112193">around $70K worth of TPU credits</a>, so in hindsight this upgrade definitely wouldn’t have been possible for me to do myself, without their assistance.</p><p>Based on my tests of the new model so far, I’m pretty happy with the quality, and IMO it is noticeably more coherent than the 345M version.</p><p>One thing that I should point out about the upgrade is that the original 345M models had been separately fine-tuned for each subreddit individually (i.e. there were 108 separate models), whereas the upgraded one is just a single 1.5B model that has been fine-tuned using a combined dataset containing the comments/submissions from <em>all</em> the subreddits that I scraped. The main reason for this decision is simply that it would not have been feasible to train ~100 separate 1.5B models. Also, there may have been benefits from transfer learning across subreddits, which wouldn’t occur with separate models.</p><p>…Here is the full list of new bots to be added: /r/capitalismvsocialism · /r/chess · /r/conlangs · /r/dota2 · /r/etymology · /r/fiftyfifty · /r/hobbydrama · /r/markmywords · /r/moviedetails · /r/neoliberal · /r/obscuremedia · /r/recipes · /r/riddles · /r/stonerphilosophy · /r/subsimulatorgpt2 · /r/subsimulatorgpt2meta · /r/tellmeafact · /r/twosentencehorror · /r/ukpolitics · /r/wordavalanches · /r/wouldyourather · /r/zen</p>'
- - http://unsongbook.com/
  - '<em>Unsong</em>'
  - Scott Alexander
  - 2015-12-28
  - ''
  - ! '<p>[<em>Unsong</em> is a finished (2015–2017) online web serial fantasy “kabbalah-punk” novel written by Scott Alexander (<a href="https://slatestarcodex.com/">SSC</a>). GoodReads summary:</p><blockquote><p>Aaron Smith-Teller works in a kabbalistic sweatshop in Silicon Valley, where he and hundreds of other minimum-wage workers try to brute-force the Holy Names of God. All around him, vast forces have been moving their pieces into place for the final confrontation. An overworked archangel tries to debug the laws of physics. Henry Kissinger transforms the ancient conflict between Heaven and Hell into a US-Soviet proxy war. A Mexican hedge wizard with no actual magic wreaks havoc using the dark art of placebomancy. The Messiah reads a book by Peter Singer and starts wondering exactly what it would mean to do as much good as possible…</p><p>Aaron doesn’t care about any of this. He and his not-quite-girlfriend Ana are engaged in something far more important – griping about magical intellectual property law. But when a chance discovery brings them into conflict with mysterious international magic-intellectual-property watchdog UNSONG, they find themselves caught in a web of plots, crusades, and prophecies leading inexorably to the end of the world.</p></blockquote><p><a href="https://tvtropes.org/pmwiki/pmwiki.php/Literature/Unsong">TVTropes</a>; <a href="https://www.goodreads.com/review/show/1997706071">my review of <em>Unsong</em></a>: ★★★★☆.]</p>'
- - /docs/sociology/2020-richmondrakerd.pdf
  - Clustering of health, crime and social-welfare inequality in 4 million citizens from two nations
  - Leah S. Richmond-Rakerd, Stephanie D’Souza, Signe Hald Andersen, Sean Hogan, Renate M. Houts, Richie Poulton, Sandhya Ramrakha, Avshalom Caspi, Barry J. Milne, Terrie E. Moffitt
  - 2020-01-20
  - 10.1038/s41562-019-0810-4
  - ! 'Health and social scientists have documented the hospital revolving-door problem, the concentration of crime, and long-term welfare dependence. Have these distinct fields identified the same citizens? Using administrative databases linked to 1.7 million New Zealanders, we quantified and monetized inequality in distributions of health and social problems and tested whether they aggregate within individuals. Marked inequality was observed: Gini coefficients equalled 0.96 for criminal convictions, 0.91 for public-hospital nights, 0.86 for welfare benefits, 0.74 for prescription-drug fills and 0.54 for injury-insurance claims. Marked aggregation was uncovered: a small population segment accounted for a disproportionate share of use-events and costs across multiple sectors. These findings were replicated in 2.3 million Danes. We then integrated the New Zealand databases with the four-decade-long Dunedin Study. The high-need/high-cost population segment experienced early-life factors that reduce workforce readiness, including low education and poor mental health. In midlife they reported low life satisfaction. Investing in young people’s education and training potential could reduce health and social inequalities and enhance population wellbeing.'
- - https://www.atlasobscura.com/articles/cyoa-choose-your-own-adventure-maps
  - "These Maps Reveal the Hidden Structures of <em>Choose Your Own Adventure</em> Books: If you decide to see more, click on this story"
  - Sarah Laskow (Atlas Obscura)
  - 2017-06-13
  - ''
  - ! '<p>The last installment of the original <a href="https://en.wikipedia.org/wiki/Choose_Your_Own_Adventure">“Choose Your Own Adventure”</a> series came out in 1998, but since 2004, <a href="https://en.wikipedia.org/wiki/Chooseco">Chooseco</a>, founded by one of the series’ original authors, R.A. Montgomery, has been republishing classic volumes, as well as new riffs on the form of interactive fiction that seemed ubiquitous in the 1980s and ’90s. The new editions also carry an additional feature—maps of the hidden structure of each book.</p><figure><img src="/images/design/2017-chooseco-chooseyourownadventure-22-tattooofdeath-plotmap.jpg" alt="Tattoo of Death, Choose Your Own Adventure #22 (All maps courtesy of ChooseCo) (https://assets.atlasobscura.com/media/W1siZiIsInVwbG9hZHMvYXNzZXRzL2RlMTkxYzNlZjk4NGYyNmI3N19lYjMxYmQ3MDUzZWNhMDkzYmNfVGF0dG9vIE1hcC0xIGNvcHkuanBnIl0sWyJwIiwiY29udmVydCIsIiJdLFsicCIsImNvbnZlcnQiLCItcXVhbGl0eSA4MSAtYXV0by1vcmllbnQiXSxbInAiLCJ0aHVtYiIsIjEyODB4PiJdXQ/eb31bd7053eca093bc_Tattoo%20Map-1%20copy.jpg)" /><figcaption><em>Tattoo of Death</em>, Choose Your Own Adventure #22 (All maps courtesy of ChooseCo)</figcaption></figure><p>For years, fans have been creating visualizations of the forking structures of “Choose Your Own Adventure” books. Often, they’re interested in the types of outcomes at the end of each path. One map labels each ending as “new life, return home, or death,” and another separates them into “cliffhanger, solution, or death.” Christian Swinehart’s extensive graphical analysis of the books labels the endings as “great, favorable, mediocre, disappointing, or catastrophic.”</p><p>…Mapping the bones of the books can have other purposes, too. Nick Montfort, a poet and professor at the Massachusetts Institute of Technology who studies interactive fiction, has a habit of asking people what they know about “Choose Your Own Adventure” books. “They often say, ‘You have two choices after every page,’” he says. “That’s not true. Sometimes you have one choice. Sometimes you have more than two. When you show the maps, you can see that these books don’t look exactly the same.” The older volumes, for instance, tend to have more endings than the later ones, and three of the oldest—<em>Journey Under the Sea</em>, <em>Space and Beyond</em>, and <em>By Balloon to the Sahara</em>—have 42 endings each, more than any other books in the series….In just about every case, it can be surprising how a simple choice leads you down a complex path. In <em>By Balloon to the Sahara</em>, you’re in a balloon and are presented with a choice on the very first page. Storm clouds are on the horizon. Choice 1: “If you act now, you can release gas from the balloon and land before the storm overtakes you.” Choice 2: “Perhaps the storm will pass quickly. Maybe you can ride it out.” That’s just the beginning, since this book has the most decision points—48—of the series.</p><p>…There is yet another possibility in these nonlinear books: hidden endings. <em>Inside UFO 54-40</em> has a hidden ending that’s only available to a reader who ignores the decisions and flips to it without prompting. But it’s there. “It’s a two-page, big illustration of this city,” says Montfort, the MIT professor. “The land of Ultima. As you flip through the book, even if you’re being very obedient, you can’t help but wonder what this text is.”</p><p>…Maps like the ones Chooseco created can reveal the structure of a book that gives readers choices, but though the multiple story lines are part of what makes the series so fun, they’re not the only thing that defines it. The meat of “Choose Your Own Adventure” stories are gender-neutral romps in worlds where there are no obviously right or wrong moral choices. There’s danger around bend, usually in the form of something like space monkeys, malicious ghosts, or conniving grown-ups. Even with a map, there’s no way to find out what really comes next without making a choice and flipping to another page.</p>'
- - https://samizdat.co/cyoa/
  - "Choose Your Own Adventure: One Book, Many Readings"
  - Christian Swinehart
  - '2009'
  - ''
  - ! '<p>[Visualizing CYOA by generating graphs and coloring events by desirability; Swinehart observes distinct patterns in network types, harshness, linearity, and highlights various curious anomalies and tricks CYOA books could play on the reader.]</p> <p>...To get a sense for the distribution of pages within the actual CYOA books, I’ve prepared a dataset of 12 books. The earliest dates from 1979 and at the later edge are a handful from 1986. They are laid out chronologically (or according to series order for books released in the same year) with the oldest at the top left and more recent books below. Each book has been arranged into rows of ten pages apiece. In scanning over the distribution of colors in this plot, one clear pattern is a gradual decline in the number of endings. The earliest books (in the top row) are awash in reds and oranges, with a healthy number of ‘winning’ endings mixed in. Later CYOA books tended to favor a single ‘best’ ending (see CYOA 44 & 53). The most extreme case of this was actually not a Choose Your Own Adventure book at all but a gamebook offshoot of the Zork text adventure series. <em>The Cavern of Doom</em> (labeled WDIDN 3 above) has a virtually linear progression where endings later in the book are increasingly better than those on earlier pages. This is reflected in the nearly unbroken spectrum from red to blue when scanning down the rows. The one outlier is the catastrophic ending seen in the third row from the bottom. This was a punishment page that could only be reached by cheating. Unlike most other endings in the book it does not offer to let you continue the story from a few pages back but instead calls you a cheater and leaves you with no choice but to start over from the beginning. Another surprising change over time is the decline in the number of choices in the books. The mess of light grey boxes in the top row gives way to books like <em>A New Hope</em> (CYOASW 1) which have more pages devoted to linear narrative than to decisions and endings combined. But to address this apparent pattern with more rigor it would be best to look at the numbers of pages in each category independent of their placement in the book...I’d be very curious to know the reason for this progression toward linearity. Presumably the invisible hand was guiding this development, but whether the hunger was for less difficulty in the books or simply for something with more in the way of traditional storytelling is harder to unravel. I could also imagine that this balance between interaction and exposition was peculiar to the individual writers, so this could merely reflect a changing set of practitioners.</p>'
- - /docs/philo/1997-mikkelson.pdf
  - "Who Is Arguing About the Cat? Moral Action and Enlightenment According to Dōgen"
  - Douglas K. Mikkelson
  - 1997-07
  - 10.2307/1399911
  - ! '<blockquote><p>Once Ejo asked: “What is meant by the expression: ‘Cause and effect are not clouded’?” Dogen said: “Cause and effect are immovable.” Ejo asked: “If this is so, how can we escape?” Dogen replied: “Cause and effect emerge clearly at the same time.” Ejo asked: “If this is so, does cause prompt the next effect, or does effect bring about the next cause?” Dogen said: “If everything were like that, it would be like Nan-ch’uan cutting the cat. Because the assembly was unable to say anything, Nan-ch’uan cut the cat in two. Later, when Nan-ch’uan told this story to Chao-chou, the latter put his straw sandal on his head and went out, an excellent performance. If I had been Nan-ch’uan, I would have said: ‘Even if you can speak, I will cut the cat, and even if you cannot speak, I will still cut it. Who is arguing about the cat? Who can save the cat?’”</p></blockquote><p>—Dogen, <em>Shobogenzo Zuimonki</em>, 1.6<sup>1</sup></p><blockquote><p>…“One day a student asked me, ‘Does a man of enlightenment fall under the yoke of causation or not?’ I answered, ‘No, he does not.’ Since then I have been doomed to undergo five hundred rebirths as a fox. I beg you now to give the turning word to release me from my life as a fox. Tell me, does a man of enlightenment fall under the yoke of causation or not?” Hyakujo answered, “He does not ignore [cloud] causation [cause and effect].” No sooner had the old man heard these words than he was enlightened.<sup>2</sup></p></blockquote><p>“Causation” in this passage refers to “moral causation.” The Buddhist concept of karma acknowledges that good/bad deeds, thoughts, and so forth result in good/bad effects. Thus the import of the question posed by the “fox” is whether or not the enlightened person is subject to karma. Hyakujo’s answer, in effect, affirms that the enlightened person is subject to moral causation. Katsuki Sekida offers a common Zen interpretation of this passage in his comment: “Thus to ignore causation only compounds one’s malady. To recognize causation constitutes the remedy for it.”<sup>4</sup></p><p>Dōgen’s employment of this story in the “Daishugyo” chapter of the <a href="https://en.wikipedia.org/wiki/Sh%C5%8Db%C5%8Dgenz%C5%8D"><em>Shōbōgenzō</em></a> implies that, on one level, he thinks Hyakujo’s answer indeed provides a “remedy” for the old man’s predicament.<sup>5</sup> Yet Dogen was rarely content with merely citing traditional Zen interpretations of passages; typically, he sought to push his students to a further understanding by a creative reinterpretation of a passage. Lest his disciple therefore think this not-ignoring/recognition of causation is de facto a release from it in an ultimate sense, Dogen answers that the passage means “cause and effect are immovable.” In other words, moral causation, for Dogen, is an inexorable fact of human existence.</p><p>Given this fact, Ejo then asks how we can ever “escape” moral causation. Dogen’s response is enigmatic: “Cause and effect arise at the same time.” Nowhere in the <em>Shōbōgenzō Zuimonki</em> does he further clarify this passage. However, the key to understanding this statement can be gleaned from his discussion of causation in the “Shoakumakusa” chapter of the <em>Shōbōgenzō</em>, wherein he observes that “cause is not before and effect is not after.”<sup>6</sup> As Hee-Jin Kim explains, Dogen saw cause and effect as absolutely discontinuous moments that, in any given action, arise simultaneously from “thusness.” Therefore,</p><blockquote><p>no sooner does one choose and act according to a particular course of action than are the results thereof (heavens, hells, or otherwise) realized in it …. Man lives in the midst of causation from which he cannot escape even for a moment; nevertheless, he can live from moment to moment in such a way that these moments are the fulfilled moments of moral and spiritual freedom and purity in thusness.<sup>7</sup></p></blockquote><p>…Dogen’s own proposed response helps us to see the point he is trying to make via the words of the old Master: “In expressing full function, there are no fixed methods.” In other words, there is no fixed formula for expressing and eliciting without-thinking. Nan-ch’uan, in Dogen’s view, betrayed an attachment to only two positions—to kill or not kill the cat. He was “fixated,” we might say, by these two possibilities. This is evidenced by the fact that he does indeed carry out one of them precisely as he said he would.</p>'
- - https://believermag.com/under-the-weather/
  - "Under the Weather: As Psychiatrists And Philosophers Begin To Define A Pervasive Mental Health Crisis Triggered By Climate Change, They Ask Who Is Really Sick: The Individual Or Society?"
  - Ash Sanders (The Believer)
  - 2019-12-02
  - ''
  - ! '<p>Eating fallen fruit and sleeping outside, however, didn’t provide him relief from his feelings of guilt and foreboding. He began to feel a dread that was inescapable and all-consuming. A devastating depression that he had suffered a few years before that fall semester returned. Normally a math phenom, Chris started failing his tests. In his apartment, he would sit in the dark—he didn’t want to waste electricity—listen to records, and cry. “I felt like I was slowly dying,” he said. A few months later, Chris left Davis to pursue a PhD in philosophy at the University of Kansas. But his condition didn’t improve. After having subsisted on scavenged persimmons and radishes for the entire fall term, he’d lost a dangerous amount of weight. His mother paid a visit to campus and, horrified by his appearance, immediately drove him to the grocery store to buy food. At home, Chris’s family had a hard time understanding the intensity of the self-denial that governed his life. His father and sister blamed his breakdown on abuse that Chris had suffered as a child; they believed his desire to escape society was a projection, an act of taking responsibility for something that wasn’t his fault. But Chris had a different explanation. When he was fifteen, his father had taken him and his sister on a trip to Mount St. Helens. Halfway up the mountain, they had passed clear-cut land. As Chris recalls, one moment there was only evergreen forest and the next moment there was nothing—just bare ground and stumps as far as he could see. A word came to his mind: <em>evil</em>…“They made it sound like I had a psychosis or a mental breakdown and that this is just the form it took, when really, shouldn’t anyone who is ethical and compassionate also choose to opt out of this society?”</p><p>…I was working fifty-hour weeks, mostly unpaid. My mother, concerned, suggested that I take a break. But I refused. There was no pause button on climate change, so why should I get a break? On some days, Salt Lake City, where I lived, had exceptionally bad air quality, a thick soup of pollution settling between the mountains and the valley. The corridor between Salt Lake and Provo, where I’d gone to college, had been completely converted from farmland to strip malls in just ten years. To the south lay one of the biggest open-pit copper mines in the world, to the north was an industrial warren of refineries, and to the west was nuclear waste buried in clay-sealed chambers, reeking of death. That was just the local stuff. Coral reefs were collapsing, ocean ecosystems were overfished, and people in island nations were trapped between salted well water and the swallowing sea. Meanwhile, everyone around me was fine…Sometimes I could do it. Other times I got combative, desperate, contrary. Meanwhile, Chris got married and had two children. When we hung out, he was happier. But he was different too. In his purist days, he’d let his lawn go to seed, refusing to use scarce water resources to keep it green. Now he was living in the suburbs, putting in Kentucky bluegrass. “Why don’t you just keep your lawn the way it was?” I said, too urgently. “Because I’ve been sad my whole life,” Chris said, “and sometimes I just want to sit on my green lawn with my wife and feel love.” I knew it was just a lawn, but it upset me anyway.</p><p>…I quit climate activism for a time, but I’ve kept going to therapy, and I keep confusing my therapists by talking about the end of the world. As it turns out, I’m not alone. A report released in 2012 by the National Wildlife Federation warned that climate change is creating a mental health crisis. The climate scientists, psychologists, and policy experts who authored the study estimated that two hundred million Americans will suffer from mental illness as a result of natural disasters, droughts, heat waves, and economic downturn. Recent disasters bear this out. In the wake of Hurricane Maria, Puerto Rico’s worst natural disaster on record, there was a 7% spike in PTSD among the children who survived. In the year after Hurricane Katrina, the suicide rate in New Orleans tripled, and the number of instances of depression and PTSD grew to what health experts described as near-epidemic levels. Even people who aren’t directly impacted by climate disasters can be affected. According to a 2017 report by the American Psychological Association, merely acknowledging the reality of climate change and its consequences can trigger chronic fear, fatalism, anger, and exhaustion—a condition that psychologists are increasingly referring to as eco-anxiety. Eco-anxiety can manifest in other serious ways. In 2008, in the midst of a severe drought in Australia, a seventeen-year-old boy refused to drink water because he was afraid that doing so would lead to the deaths of millions of people. Doctors diagnosed him with “climate delusion” and prescribed antidepressants. When they asked him why he took such drastic action, he said he felt guilty….Greta Thunberg, a sixteen-year-old Swedish girl who inspired the growing student climate strike movement, says that learning about climate change—and seeing adults’ inaction—contributed to a severe depression during which she stopped eating and drinking…other activists are turning the violence of climate change on themselves—like David Buckel, a human rights lawyer who in 2018 lit himself on fire in Prospect Park, in Brooklyn, to call attention to the scale of the climate plight…Quante told me that one of her earliest memories was learning that so many things around her were alive—the trees, the grass, the frogs. It terrified her to realize the harm she was capable of. One day, after it had rained, her mother made her walk along a worm-strewn sidewalk, and she screamed as she was dragged along. “We’re killing them!” she said. “We’re killing them!”…Van Susteren started having trouble sleeping. After getting into bed and closing her eyes, she would be ambushed by intrusive images. She would see refugees surrounded by barbed wire, animals trapped in the path of a hurricane, people stranded in floodwaters. The worst image was of a child. It wasn’t any child she knew, but a sort of representative for all children. The child looked at Van Susteren and asked the same question again and again: “Why didn’t you do anything?” As a psychiatrist, Van Susteren recognized her symptoms. The stress, the insomnia, the intrusive thoughts—they read like PTSD. And yet the trauma she was imagining hadn’t happened yet, or at least it hadn’t happened to her…Van Susteren coined a new term for her condition: <em>pre-traumatic stress disorder</em>…In the back of the class, a student started crying. “If I didn’t have hope, how could I live?” she asked.</p><p>…Robert Salo, the doctor who diagnosed the Australian boy with climate psychosis, was careful to note the boy’s other symptoms (long-term depression, suicidal thoughts, and hearing voices) and the disproportionate sense of importance he placed on his own actions (believing that his own small water usage would lead to widespread deaths). Other critics have pointed out that climate delusion usually afflicts people who already suffer from other mental health maladies, and that the triggers for psychotic episodes generally take the form of the dominant political or cultural issues of the time, from nuclear holocaust to Cold War–era fears about the spread of communism.</p>'
- - https://www.theeagle.com/news/local/cc-world-s-first-cloned-cat-turns-years-old/article_d2aeac6e-2471-11ea-a5f2-7b6c21b2b4b4.html
  - "CC, world’s first cloned cat, turns 18 years old"
  - Chelsea Katz (The Eagle)
  - 2020-01-02
  - ''
  - ! '<p>The first of her kind, CC the cloned cat is breaking more boundaries as she turns 18 years old. There are no big plans locally to mark the day, but CC—Carbon Copy or Copy Cat—will be the focus of a Dutch cartoon set for release today to celebrate her birthday, researcher and owner Duane Kraemer said. </p> <p>...CC is not only enjoying life as the Kraemers’ pet, but she has her own condo called the “kitty house” behind the Kraemers’ house where she lives with her three offspring, sired by a cat named Smokey. Those offspring, just by existing, helped CC make headlines in the scientific community. There had not been much research done in the reproduction success of clones—and none had been done with a cat. Tim, Zip and Tess were born Sept. 1, 2006, along with a fourth kitten that was stillborn. Not knowing CC’s reaction would be to her kittens, Kraemer said, they found CC was “the perfect mother” and had the innate maternal instincts they were hoping she would exhibit. Besides proving clones can successfully reproduce, CC also proved not all clones die young. “Dolly the sheep, that was the first of the mammals to be cloned by nuclear transfer, had died at, I think, at 6 years of age,” Kraemer said. “So the fact that CC didn’t die young was news.” About 20% of cloned animals have developmental abnormalities of some kind, he said, with some being serious enough to result in the animal’s death at a young age or at birth. However, the other 80% born without those conditions “would probably live to a normal variation of ages.”</p>'
- - https://samizdat.co/me/
  - "Me"
  - Christian Swinehart
  - ''
  - ''
  - ! '<p>Christian Swinehart is a graphic designer, software developer, and data artist. His practice focuses on interaction and user interface design with a specialty in data visualization. He is the founder and principal of Samizdat Drafting Co. and is an active participant in the open-source world as the author of the <a href="http://plotdevice.io">PlotDevice</a> and <a href="http://arborjs.org">Arbor.js</a> visualization tools.</p><p>Christian’s work is informed by a background in biology and computational modeling. His projects frequently employ simulation and numerical analysis as a means to communicate the structure within complex systems. Recent clients include The New York Times, Bloomberg, Gallup, Pentagram, Diller Scofidio + Renfro, and Allied Works Architects.</p><p>Degrees Held:</p><ul><li>MFA | Graphic Design (RISD, 2008)</li><li>Ph.D. | Computational Neuroscience (Brandeis University, 2005)</li><li>BS | Cognitive Science (Dickinson College, 1998)</li></ul>'
- - /docs/psychology/2019-forscher.pdf
  - "A Meta-Analysis of Procedures to Change Implicit Measures"
  - Patrick Forscher, Calvin Lai, Jordan Axt, Charles Ebersole, Michelle Herman, Patricia Devine, Brian Nosek
  - 2019-08-19
  - 10.1037/pspa0000160
  - ! 'Using a novel technique known as network meta-analysis, we synthesized evidence from 492 studies (87,418 participants) to investigate the effectiveness of procedures in changing implicit measures, which we define as response biases on implicit tasks. We also evaluated these procedures’ effects on explicit and behavioral measures. We found that implicit measures can be changed, but effects are often relatively weak (|ds| < .30). Most studies focused on producing short-term changes with brief, single-session manipulations. Procedures that associate sets of concepts, invoke goals or motivations, or tax mental resources changed implicit measures the most, whereas procedures that induced threat, affirmation, or specific moods/emotions changed implicit measures the least. Bias tests suggested that implicit effects could be inflated relative to their true population values. Procedures changed explicit measures less consistently and to a smaller degree than implicit measures and generally produced trivial changes in behavior. Finally, changes in implicit measures did not mediate changes in explicit measures or behavior. Our findings suggest that changes in implicit measures are possible, but those changes do not necessarily translate into changes in explicit measures or behavior.'
- - /docs/sociology/2019-kristal.pdf
  - "What we can learn from five naturalistic field experiments that failed to shift commuter behaviour"
  - Ariella S. Kristal, Ashley V. Whillans
  - 2019-12-23
  - 10.1038/s41562-019-0795-z
  - ! '<p>Across five field experiments with employees of a large organization (<em>n</em> = 68,915), we examined whether standard behavioural interventions (‘nudges’) successfully reduced single-occupancy vehicle commutes. In Studies  1 and 2, we sent letters and emails with nudges designed to increase carpooling. These interventions failed to increase carpool sign-up or usage. In Studies  3a and 4, we examined the efficacy of other well-established behavioural interventions: non-cash incentives and personalized travel plans. Again, we found no positive effect of these interventions. Across studies, effect sizes ranged from Cohen’s <em>d</em> = −0.01 to <em>d</em> = 0.05. Equivalence testing, using study-specific smallest effect sizes of interest, revealed that the treatment effects observed in 4 out of 5 of our experiments were statistically equivalent to zero (<em>P</em> &lt; 0.04). The failure of these well-powered experiments designed to nudge commuting behaviour highlights both the difficulty of changing commuter behaviour and the importance of publishing null results to build cumulative knowledge about how to encourage sustainable travel.</p>'
- - /docs/anime/2019-ye.pdf
  - "Interactive Anime Sketch Colorization with Style Consistency via a Deep Residual Neural Network"
  - Ru-Ting Ye, Wei-Li Wang, Ju-Chin Chen, Kawuu W. Lin
  - 2019-11-21
  - 10.1109/taai48200.2019.8959911
  - ! "Anime line sketch colorization is to fill a variety of colors the anime sketch, to make it colorful and diverse. The coloring problem is not a new research direction in the field of deep learning technology. Because of coloring of the anime sketch does not have fixed color and we can't take texture or shadow as reference, so it is difficult to learn and have a certain standard to determine whether it is correct or not. After generative adversarial networks (GANs) was proposed, some used GANs to do coloring research, achieved some result, but the coloring effect is limited. This study proposes a method use deep residual network, and adding discriminator to network, that expect the color of colored images can consistent with the desired color by the user and can achieve good coloring results."
- - https://pure.tue.nl/ws/portalfiles/portal/142614149/J.R.Ubbink_09_09_2019_thesis_final.pdf
  - Characterization of illegal dark web arms markets
  - J. R. Ubbink
  - 2019-09
  - ''
  - ! '<p>The nature of online underground gun markets on the dark web has been relatively under-researched in comparison to those regarding drugs or malware. This work attempts to improve the general understanding of the nature of these markets, with a longitudinal assessment of the market as a whole. From this assessment, the various properties that characterize the market such as overall sales and the breadth of items on offer can be catalogued and compared against offline markets, or other online markets.</p><p>In addition to this longitudinal study, the online communities surrounding the sale of firearms were identified, with topic models fit to the datasets spanning approximately five years, with the intent of characterizing and comparing them to each other in a more structured manner. Once the topic models were generated, documents were drawn from before and after mass shooting attacks. These documents were then labeled by the separate topic models, and then contrasted and compared against each other in order to assess the reactions of these communities to traumatic events, thus observing if there were clear patterns of behavior universal across these communities.</p><p>Online underground arms markets were found to be generally thin, albeit larger in scale than a few years before, and appear to be predominantly focused on the sale of rifles, pistols, and custom orders. Gun communities online were observed to differ depending on the strictness of moderation of their parent communities, though still have a number of shared topics, such as gun legislation or usage. Furthermore, the assessed communities varied heavily in their reactions to attacks, further highlighting their differences.</p>'
- - https://www.tabletmag.com/jewish-news-and-politics/287821/orthodox-jews-attacked-brooklyn-hate-crime
  - "Everybody Knows: As the leading targets of hate crimes, Jews are routinely being attacked in the streets of New York City. So why is no one acting like it’s a big deal?"
  - Armin Rosen (Tablet)
  - 2019-07-16
  - ''
  - ! '<p>The incidents now pass without much notice, a steady, familiar drumbeat of violence and hate targeting visibly Jewish people in New York City…The increase in the number of physical assaults against Orthodox Jews in New York City is a matter of empirical fact. Anti-Semitic hate crimes against persons, which describes nearly everything involving physical contact, jumped from 17 in 2017 to 33 in 2018, with the number for the first half of 2019 standing at 19, according to the NYPD’s hate crime unit. Jews are the most frequent targets of hate crimes in New York City, and have been for some time (although this number is somewhat skewed by the fact that swastikas, which are by far the city’s most common hate incident, are automatically categorized as an anti-Jewish hate crime)…these seemingly random incidents—just the first few days of May saw an unprovoked attack in Lefferts Park in which a woman tried to pull off her victim’s <em>sheitel</em>, two violent assaults on Hasidic men in Williamsburg, and a possible attempted vehicular attack in the same neighborhood—is part of a typhoon of violence that in other contexts might call for a Justice Department Civil Rights Division investigation. The fact that the victims are most often outwardly identifiable, i.e., religious rather than secularized Jews, and the perpetrators who have been recorded on CCTV cameras are overwhelmingly black and Hispanic, inverts the perpetrator-victim dynamics with which most national Jewish organizations and their supporters are comfortable. A close look at these cases reveals no apparent connection to neo-Nazis, the alt-right, Donald Trump, jihadism, the BDS movement, or any other traditional cause of anti-Jewish behavior.</p><p>…Past spikes were seemingly less nebulous in origin. About five years ago, the so-called “knockout game”—a trend of teenagers committing or filming public sneak attacks—resulted in approximately 19 assaults on Jews in the city, according to Evan Bernstein, the New York and New Jersey regional director of the Anti-Defamation League. “The knockout game was definitely a real thing,” Molinari said, though he noted that the fact the attacks were apparently motivated by a quest for social media fame usually undermined the chances of pursuing hate crimes charges, including when visible Jews were the target.</p><p>This latest wave has no evident organizing principle behind it aside from pure hostility against targets that are unmistakably Jewish. In March, a 32-year-old man kicked a double stroller in Crown Heights and was charged with child endangerment. In late 2018, a 26-year-old man who turned out to be a former intern for then City Council Speaker Christie Quinn set fires at a remarkably pluralistic range of Jewish institutions in Brooklyn. In another odd and widely publicized incident, someone smashed the glass storefront of a crowded Chabad house, the only shul in the non-Jewish Brooklyn neighborhood of Bushwick, at around 1:30 a.m. on a Saturday morning in February and then escaped with the help of a driver waiting around the corner. “We don’t see patterns of perpetrators committing crimes,” says Molinari. “For the most part, 360 crimes are being done by 360 very diverse people, … there’s no connective tissue between any of these perpetrators.” Not a single incident during the spike has been traced to a white supremacist group or any other organized entity.</p><p>…One Jewish community activist who met with the mayor’s Office of Criminal Justice said that at the time of the meeting in mid-June there was no director, no dedicated staff, and nothing to show of the office outside of fairly preliminary efforts. As of early July, it was still unclear exactly what this entity will actually do, and there was no official launch date. Deutsch refrained from speculating about the reasons for any hesitation on de Blasio’s part, at times implying that the mayor’s staff might not have kept him updated or engaged on the issue. “Sometimes people are too busy, they’re inundated with issues that come up every single day,” he said. “That’s why you have staff.” At best, this means that the administration’s seeming complacency toward violent anti-Semitism is the result of lagging intraoffice communication, rather than any intentional policy on anyone’s part. At worst, it means De Blasio is actively avoiding the issue. In any case, much remains to be done. When asked about the office, an officer in one of the NYPD precincts where several attacks had occurred said, “we have nothing to do with that.” Molinari said he had been involved in one meeting with the mayor’s office about the effort. “The police commissioner and the higher-ups are all determining how exactly to implement that and what our place is going to be,” he said. None of the victims or community leaders mentioned in this article reported any substantial contact with anyone regarding the new office.</p><p>An honest reckoning with the problem carries plenty of its own risks. The spike in incidents complicates the current national political narrative around anti-Semitism, which maps a narrow left-right paradigm on to Jews and their terrorizers. The overwhelming majority of the alleged perpetrators in New York are either black or Hispanic, and casting anti-Semitism as an issue pitting Jews against various other minority groups threatens to re-agitate problems that many in the Jewish and surrounding communities hope no longer exist. …Yaacov Behrman, a Crown Heights-based educator and member of the local community board, believes that a sociological study of attitudes toward Jews among the city’s young people is an essential first step to countering anti-Semitism. Such an investigation might involve anonymous questionnaires administered in public schools. He doubts it will ever happen. “Personally I think the city is scared of what they’re gonna find and never do it,” he told Tablet. “I think the city is concerned they’ll find anti-Semitism numbers are very high in Brooklyn.”</p>'
- - https://ai.facebook.com/blog/near-perfect-point-goal-navigation-from-25-billion-frames-of-experience/
  - Near-perfect point-goal navigation from 2.5 billion frames of experience
  - Erik Wijmans, Abhishek Kadian (Facebook)
  - 2020-01-21
  - ''
  - ! '<p>The AI community has a long-term goal of building intelligent machines that interact effectively with the physical world, and a key challenge is teaching these systems to navigate through complex, unfamiliar real-world environments to reach a specified destination—without a preprovided map. We are announcing today that Facebook AI has created a new large-scale distributed reinforcement learning (RL) algorithm called DD-<span class="smallcaps-auto">PPO</span>, which has effectively solved the task of point-goal navigation using only an <span class="smallcaps-auto">RGB</span>-D camera, <span class="smallcaps-auto">GPS</span>, and compass data. Agents trained with DD-<span class="smallcaps-auto">PPO</span> (which stands for decentralized distributed proximal policy optimization) achieve nearly 100% success in a variety of virtual environments, such as houses and office buildings. We have also successfully tested our model with tasks in real-world physical settings using a LoCoBot and Facebook AI’s PyRobot platform. An unfortunate fact about maps is that they become outdated the moment they are created. Most real-world environments evolve—buildings and structures change, objects are moved around, and people and pets are in constant flux. By learning to navigate without a map, DD-<span class="smallcaps-auto">PPO</span>-trained agents will accelerate the creation of new AI applications for the physical world.</p><p>Previous systems reached a 92% success rate on these tasks, but even failing 1 out of 100 times is not acceptable in the physical world, where a robot agent might damage itself or its surroundings by making an error. DD-<span class="smallcaps-auto">PPO</span>-trained agents reach their goal 99.9% of the time. Perhaps even more impressive, they do so with near-maximal efficiency, choosing a path that comes within 3% (on average) of matching the shortest possible route from the starting point to the goal. It is worth stressing how uncompromising this task is. There is no scope for mistakes of any kind—no wrong turn at a crossroads, no backtracking from a dead end, no exploration or deviation of any kind from the most direct path. We believe that the agent learns to exploit the statistical regularities in the floor plans of real indoor environments (apartments, houses, and offices) that are also present in our data sets. This improved performance is powered by a new, more effective system for distributed training (DD-<span class="smallcaps-auto">PPO</span>), along with the state-of-the-art speed and fidelity of Facebook AI’s open source AI Habitat platform.</p><p>…We propose a simple, synchronous, distributed RL method that scales well. We call this method decentralized distributed proximal policy optimization, as it is decentralized (has no parameter server) and distributed (runs across many machines), and we use it to scale proximal policy optimization, a previously developed technique (Schulman et al., 2017). In DD-<span class="smallcaps-auto">PPO</span>, each worker alternates between collecting experience in a resource-intensive, <span class="smallcaps-auto">GPU</span>-accelerated simulated environment and then optimizing the model. This distribution is synchronous—there is an explicit communication stage in which workers synchronize their updates to the model.</p><p>The variability in experience collection runtime presents a challenge to using this method in RL. In supervised learning, all gradient computations take approximately the same time. In RL, some resource-intensive environments can take significantly longer to simulate. This introduces significant synchronization overhead, as every worker must wait for the slowest to finish collecting experience. To address this, we introduced a preemption threshold where the rollout collection stage of these stragglers is forced to end early once some percentage, <em>p</em> percent, (we find 60% to work well) of the other workers are finished collecting their rollout, thereby dramatically improving scaling. Our system weighs all workers’ contributions to the loss equally and limits the minimum number of steps before preemption to one-fourth the maximum to ensure that all environments contribute to learning.</p>'
- - https://www.nybooks.com/articles/2020/01/16/alma-mahler-it-had-to-be-her/
  - 'It Had to Be Her: Review of <em<Passionate Spirit: The Life of Alma Mahler</em>, Haste 2019'
  - Cathleen Schine (The New York Review of Books)
  - 2020-01-16
  - ''
  - ! '<p>[<em>The Browser</em> summary: “The amazing life of <a href="https://en.wikipedia.org/wiki/Alma_Mahler">Alma Mahler</a>. She married and/or romanced <a href="https://en.wikipedia.org/wiki/Gustav_Mahler">Gustav Mahler</a>, <a href="https://en.wikipedia.org/wiki/Oskar_Kokoschka">Oskar Kokoschka</a>, <a href="https://en.wikipedia.org/wiki/Walter_Gropius">Walter Gropius</a> and <a href="https://en.wikipedia.org/wiki/Franz_Werfel">Franz Werfel</a>. She was “anti-Semitic, narcissistic, boastful, and untruthful”. Was she also an “ambitious young woman who longed to be a great composer but became instead a great muse to great men?”. Was she an “artist stunted by society’s restrictions on women?”. Was she a “grandiose groupie, expropriating the fame of her husbands and lovers?” Perhaps uniquely, she was all three." Mahler’s life dramatized the Viennese milieu, with absurd melodrama.]</p><p>The Alma Schindler of her early diaries, which she began in 1898, is, indeed, appealing. They reveal an ebullient teenager full of serious opinions and enthusiasms, a flirtatious young woman giddy with the attentions of the cultural elite in culturally elite fin-de-siècle Vienna. Alma writes about crushes and kisses and assignations on the Ringstrasse, about vigorously practicing the piano and earnestly studying composition, about attending the opera, about buying dresses and fighting with her mama. She is a girl—a splendid girl in a splendid city at a splendid time. She is vain and unsure of herself, self-aggrandizing as only a serious, determined, sensitive young person can be. The early diaries, published in English in 1998, end in 1902, just before she married Gustav Mahler. Alma lived for another sixty-two years, years of vainglorious strutting, scheming, and disloyalty, years chronicled by her own memoirs and by her later diaries (which have not been translated into English). Mahler scholars have a name for the challenge that arises from her unreliable tendencies: the Alma Problem. “She is routinely accused of massaging the facts to serve her own legacy,” Haste writes, “of suppressing or editing her husband Gustav Mahler’s published letters to remove critical references to her, for instance—acts seen, particularly by Mahler scholars (for whom she was for some time their principal source), as tampering with the archive.”…Touched by her husband’s new devotion and convinced that he would die if she left him, Alma sent Gropius away. Gustav wrote her daily love poems, smothered her slippers in kisses, and listened again to her music, pronouncing it good and begging her to resume composing. Alma was undeniably talented, and her songs are admired today, but this episode points as much to her extraordinary power as a muse as to her gifts as an artist. Her daughter Anna said that when Alma</p><blockquote><p>just stopped in the doorway, you could immediately feel an electric charge…. She was an incredibly passionate woman…. And she really paid attention to everyone she spoke to. And encouraged them…. She was able to enchant people in a matter of seconds.</p></blockquote><p>Albrecht Joseph, eventually Anna’s fifth husband, who was shocked by Alma’s dowdiness when he first met the legendary seductress in 1931, nevertheless noted that her “unique gift” was “a profound, uncanny understanding of what it was that [creative] men tried to achieve, an enthusiastic, orgiastic persuasion that they could do what they aimed at, and that she, Alma, fully understood what it was.” The intensity of her belief in art and genius had the effect of creating an almost violent sympathy. Gustav, like the other men she loved, did not think he could survive artistically without her. · …And then there was Kokoschka. Alma later described her three-year affair with Oskar Kokoschka as “one violent struggle of love. Never before had I experienced so much strain, so much hell and so much paradise.” Jealous and controlling, the artist stalked her, patrolling her street after he left her house to make sure no other man visited. She refused to marry him, so while she was in Paris he stole her documents and posted the banns in the Döbling parish hall. “Oskar Kokoschka could only make love to me with the most peculiar game playing,” she later wrote. “As I refused to hit him during our hours of love, he began conjuring up the most appalling images of murder” of his supposed rivals “while whispering murkily to himself.” One night when she sang <em>Parsifal</em> at the piano, he whispered “a new, eerie text” into her ear, which caused her to scream and cry, then to swallow a toxic dose of bromine. (Kokoschka called the doctor.) · And through it all, he painted her. When she had an abortion (she wrote that she was afraid of “what might grow in me”), Kokoschka took a blood-stained cotton pad from her and kept it with him, saying, “That is, and will always be, my only child.” He painted bloody, murdered children. He drew “Alma Mahler Spinning with Kokoschka’s Intestine.” He insisted that she cover her arms with long sleeves. Kokoschka painted Alma entwined with him in a boat on a stormy sea, he painted Alma rising to the heavens while he stood in hell surrounded by snakes. Anna watched him work and asked, “Can’t you paint anything else except Mommy?” · When war came, Alma’s reaction was, as even the temperate Haste must admit, “an astonishing flourish of self-aggrandizement.” “I sometimes imagine,” Alma wrote, “that I was the one who ignited this whole world conflagration in order to experience some kind of development or enrichment—even if it be only death.” By now, she wanted to purify herself of the “evil fascination” of Kokoschka. She taunted him until he joined the cavalry, then broke off their relationship in unkind letters. In despair, Kokoschka insisted on being sent to the front, where he was wounded so badly he was reported dead in the Viennese papers. Though she later defiantly published a facsimile of Mahler’s manuscript of his Tenth Symphony, revealing (for a good price) his intimate, despairing notes, she was less keen on allowing her own letters to reach the public. After rushing to Kokoschka’s studio with her set of keys, she removed and burned her notes to him. · Though Kokoschka had not in fact died, her interest in him had. She was back to writing letters to Gropius. When she saw him while he was on leave, Haste writes, “their passion was rekindled,” and they got married. Kokoschka dealt with this rejection by commissioning a life-sized Alma doll, with instructions to “please make it possible that my sense of touch will be able to take pleasure in those parts where the layers of fat and muscle suddenly give way to a sinuous covering of skin.” The doll, covered in fluffy swan skin, suffered an ignominious end, beheaded and bedraggled in a courtyard the morning after Kokoschka threw a raucous farewell party for it.</p>'
- - /TWDNE#twdnev3
  - 'ThisWaifuDoesNotExist, version 3'
  - Gwern Branwen
  - 2020-01-20
  - ''
  - ! 'Discussion of TWDNEv3, launched January 2020. TWDNEv3 upgrades TWDNEv2 to use 100k anime portraits from an <a href="/Faces#stylegan-2">anime portrait StyleGAN 2</a>, an improvement to StyleGAN released in December 2019, which removes the blob artifacts and is generally of somewhat higher visual quality. TWDNEv3 provides images in 3 ranges of diversity, showing off both narrow but high quality samples and more wild samples. It replaces the StyleGAN 1 faces and portrait samples.'
- - /Faces#stylegan-2
  - 'Anime Portraits with StyleGAN 2'
  - Gwern Branwen
  - 2020-01-20
  - ''
  - ! 'How to use StyleGAN 2, an improvement to StyleGAN released in December 2019, which removes the blob artifacts and is generally of somewhat higher visual quality. StyleGAN 2 is tricky to use because it requires custom local compilation of optimized code. Aaron Gokaslan provided tips on getting StyleGAN 2 running and trained a StyleGAN 2 on my anime portraits, which is available for download and which I use to create <a href="/TWDNE#twdnev3">TWDNEv3"</a>'
- - /Search#case-studies
  - 'Internet Search Tips: 14 Case Studies'
  - Gwern Branwen
  - 2020-01-21
  - ''
  - 'Followup section to the article covering how to search the Internet effectively: 14 case studies of challenging Internet searches drawn from the past 10 years. I present the problem, and step through the process of finding it, and describe my tacit knowledge and implicit strategies. These case studies hopefully make the prior tips more understandable by showing them off in practice.'
- - https://www.nytimes.com/2019/12/29/arts/music/wozzeck-review-met-opera.html
  - 'Review: The Searing Beauty of Kentridge’s ‘Wozzeck’ at the Met: The artist William Kentridge uses his trademark animations to stage Berg’s bleak opera about a delusional soldier'
  - Anthony Tommasini (New York Times)
  - 2019-12-29
  - ''
  - ! '<p>Alban Berg’s bleak opera “Wozzeck” might not seem suited to the holiday season. One of the least cheerful pieces in the repertory, it tells the story of an impoverished and increasingly delusional soldier, driven to murder and suicide. Yet this time of year is also a moment to take stock. And few works look at life with more searing honesty than “Wozzeck.” The issues that drive this wrenching, profound opera are especially timely: the impact of economic inequality on struggling families; the looming threats of war and environmental destruction; the rigid stratification—almost the militarization—of every element of society.</p><p>…The opera—which unfolds in 15 short, episodic scenes—is played atop a set (designed by Sabine Theunissen) built of platforms connected by rickety walkways, evoking a bombed-out city amid consuming chaos. Silent actors, most in gas masks, keep appearing here and there. An almost continual montage of animation, drawings and projections, mostly in black and white, appear on and behind the set: images of blown-up churches and buildings; military maps; charcoal drawings of bedraggled people morphing into spectral stick figures; despoiled rivers and hills. In the first scene, rather than shaving his officious captain, as indicated in the libretto, Wozzeck here is operating a small movie camera that projects cartoonish images of people on a small screen. Mr. Kentridge said in a recent interview with The New York Times that he conceived the action of the opera as taking place within that projection.</p><p>…The carousing at a seedy tavern, where the crazed Wozzeck shows up after stabbing Marie, was all the more eerie for the multilayered setting and the ominous costumes (by Greta Goiris), with the crowd in gas masks, a bitter premonition of the war to come…One of the daring elements of the production is the depiction of Wozzeck and Marie’s young son as a simple puppet, wearing ragged clothes and a gas mask. Mr. Kentridge said in the interview that using real children in crucial roles can be distracting. But I have found it moving to see a boy in the role—especially in the final scene when, riding a hobby horse, he finally follows the townspeople, who have discovered the body of his mother offstage. Mr. Kentridge’s use of a puppet seems like a solution in search of a problem.</p>'
- - https://www.newyorker.com/magazine/2020/01/13/operatic-shows-of-force
  - 'Operatic Shows of Force: At the Met, a new production of “Wozzeck” stays relentlessly focussed on war, and a young soprano brings prodigious power to “The Queen of Spades”'
  - Alex Ross (New Yorker)
  - 2020-01-06
  - ''
  - ! '<p>Your judgment of the new Metropolitan Opera production of Alban Berg’s “Wozzeck,” which runs through January 22<sup>nd</sup>, may depend on how you classify it. The director is the South African artist William Kentridge, who is steeped in the Central European Expressionist milieu from which Berg’s ferocious anti-military opera emerged. If the staging is considered as an entry in Kentridge’s multimedia œuvre, it delivers a potent distillation of signature motifs: brusque drawings and prints of wounded faces and ravaged landscapes; stop-action animation of spasmodically jerking figures; photographic collages and cinematic montages. If, however, you measure the work against the emotional breadth of Berg’s opera, you may find it wanting. On opening night, I admired the virtuosity of the director’s technique but wished that he had paid more heed to the desperate inner lives of the characters.</p><p>…Although the Great War looms over every moment of the staging, it never becomes clear whether we are experiencing Wozzeck’s nightmarish premonitions of the conflict or his shell-shocked recollections of it. Characters often wear gas masks, hobble on crutches, and have bandages on their heads. Maps of troop movements in Flanders are projected onto a large screen behind the stage. The sets, designed by Sabine Theunissen, deploy sculptural accumulations of junk to render the locales where Wozzeck experiences successive humiliations: a captain’s quarters, a doctor’s laboratory, a tavern garden, a soldiers’ barracks. Greta Goiris, the costume designer, applies fantastical touches to drab uniforms and workaday wear. A blood-red gown for Marie stands out against a mostly black-and-white color scheme.</p><p>…Kentridge is at his best when crowds fill the stage, matching the teeming density of his visual aesthetic. His most bravura gesture comes in Act III, as Wozzeck staggers away from the pond where he has murdered Marie and into a bar full of drunkenly dancing figures. Berg prepares the change of scene with two enormous orchestral crescendos on the single note B, the second louder than the first. Kentridge made the inspired decision to have dancers enter during the second crescendo, both on the stage and on the screen at the back. They appear to be emanating from the concentrated beam of sound. Much less successful is Kentridge’s illustration of the overpowering final interlude, which follows Wozzeck’s death, by drowning. The triple-forte climax of the passage was marked by a groaningly obvious sequence of explosions on the screen.</p><p>The unremitting focus on war iconography blotted out the opera’s main narrative thrust: the deterioration of Wozzeck’s mind in the grip of military routine. Crucially, in Büchner’s scenario, the soldier is not at war but serving in a town regiment; violence explodes from the machinery of the system. The baritone Peter Mattei, who took the lead role, is one of the finest singing actors in opera, but in this staging he had little opportunity to trace the character’s arc toward madness; too often he seemed like an extra in a larger tableau. Elza van den Heever, as Marie, was similarly sidelined by the pervasive imagery of masculine aggression. Psychology has never been Kentridge’s strong suit as a director—it was also a blind spot in his previous Met productions, of Shostakovich’s “The Nose” and of Berg’s “Lulu”—but here the characterizations are weaker than ever. It’s instructive to compare this brilliant but somehow hollow affair with “The Head and the Load,” Kentridge’s monumental theatrical tribute to African soldiers who served in the Great War.</p>'
- - /newsletter/2019/02#carmen
  - 'Review of <em>Carmen</em> (opera)'
  - Gwern Branwen
  - 2019-03-02
  - ''
  - ! 'First opera review. How does a Met HD live opera broadcast work? Extremely well! They are lavishly produced, with multiple cameras and live directing, subtitling, and bonus features like seeing backstage. The opera itself is wonderful: it makes a great impression to sing and play orchestral music the entire time through, and the character motivations are painfully realistic and believable. I understand now the description of opera as a totalizing <em>Gesamtkunstwerk</em>: it combines all the art forms in an extremely technically-demanding to overpower the viewer and their emotions, overriding the lack of realism to produce an exaggerated effect, rendering it the most prestigious art of its era. The opera was interestingly "red pill"-like in depicting Carmen as demanding ever more sacrifices and ultimately abandoning her lover, leading to the final murder-suicide. Watching <em>Carmen</em> made me a believer in the Met HD broadcasts, and I resolved to watch more.'
- - https://www.tabletmag.com/jewish-arts-and-culture/290042/writing-akhnaten
  - "Writing ‘Akhnaten’: A co-author of Philip Glass’ Egyptian opera, opening at the Met this weekend, recalls how the monotheistic ‘heretic Pharaoh’ became the fat lady"
  - Shalom Goldman
  - '2019-11-06'
  - ''
  - ! '<p><em>Akhnaten</em>, Philip Glass’ “Egyptian opera,” opening at the Metropolitan Opera this weekend, premiered in 1984 and since then has been produced in many different stagings, primarily in European cities, where the composer has a very large and enthusiastic audience. Akhnaten’s American production story has been much more modest.</p><p>…Someone at the party had told Glass that I was studying Egyptian language and culture. He sought me out, introduced himself and asked if I knew anything about Akhnaten, the “heretic Pharaoh.” The party had put me in a jocular mood and my immediate response was “know about him? I just saw him!” I explained that I had only recently returned from Cairo, where the massive statue of Akhnaten in the Cairo Museum was the Egyptian artifact that had made the deepest impression on me. (Later I realized that in my response I was channeling a skit in <em>2000 Year Old Man</em> in which Carl Reiner asks Mel Brooks if he had known Joan of Arc. “What do you mean knew her,” said Brooks, “I dated her!”) Our initial conversation about Egypt and Akhnaten lasted for more than an hour.</p><p>In his remarkably creative way, Glass had been reading widely about Egypt and Akhnaten. He had studied James Henry Breasted’s authoritative <em>History of Egypt</em> and he read Freud’s speculations about Akhnaten in his last book, <em>Moses and Monotheism</em>. We agreed to meet the following week to continue our conversation. I told Glass that for our next meeting I would bring pictures of Akhnaten, his wife Nefertiti, and of his artistic creations. For Akhnaten was an artist and poet, as well as a Pharaoh—or at least that was the claim of some experts. Our subsequent meetings at which I was introduced to Glass’ theater and music collaborators, Robert Israel and Richard Riddell, went very well. They had worked with Glass on <em>Satyagraha</em> and were collaborating with him on the creation of <em>Akhnaten</em>. Asked by Glass if I would be able to serve as a researcher on his Egyptian project, I said yes.</p><p>…His formulation was: “Einstein as the man of science, Gandhi as the man of politics, Akhnaten as the man of religion.”</p><p>In his 1987 book, <em>Music by Philip Glass</em>, the composer explained his fascination with the heretic king: “On becoming Pharaoh, he declared a new religion based upon Aten, associated with the sun, but not actually the sun itself, a very important point theologically. His new god was supreme and alone, making Akhnaten the first declared monotheist in history. … Finally, by not completely identifying his god with the physical sun but emphasizing his independent nature, Akhnaten’s god is the first truly abstract god head we know.” Glass knew that not all historians of religion and culture agreed with this description. But for Glass, the main point was that “Akhnaten had changed his (and our) world through the force of his ideas and not through the force of arms.”</p>'
- - /newsletter/2019/10#manon
  - "Opera review: <em>Manon</em>"
  - Gwern Branwen
  - 2019-10-27
  - ''
  - ! '<p>Review of <em>Manon</em>, a French opera about a beautiful countryside girl whose craving for the ‘good life’ leads her into the Parisian <em>demimondaine</em> as a courtesan.</p><p>Exemplifying Girardian <em>mimesis</em>, Manon wants what everyone else wants, and wants what she can’t have, like her spurned lover only once he has taken religious vows. She plays off suitors, who compete in negative-sum games for her favors, until eventually she goes too far and is imprisoned, destroying her health; cast down, she realizes that ‘living only for pleasure’ was not the ideal life.</p><p>This scenario seems to exemplify the extent to which polygynous competition can result in negative-sum games, making almost everyone worse off except a few winners (and those possibly only temporarily).</p>'
- - /newsletter/2019/03#die-walkure
  - 'Review of <em>The Ring: Die Walküre</em> (opera)'
  - Gwern Branwen
  - 2019-04-01
  - ''
  - ! 'Second opera review, after <em>Carmen</em>. Oddly, this is #2 of The Ring cycle but neither #1 nor #3 were broadcast. Not as enjoyable, but impressive in its own right. It works better at providing a mythic sense than contemporary efforts like the Marvel Cinematic Universe, at least.'
- - /newsletter/2019/11#madama-butterfly
  - 'Review of <em>Madama Butterfly</em> (opera)'
  - Gwern Branwen
  - 2019-11-11
  - ''
  - ! 'One of the most popular operas, relies heavily on beautiful visuals and interesting gimmicks like puppeteers, at the cost of establishing plausible psychology for either protagonist or justifying the tragedy. Beautifully staged, this is true "poster art".'
- - /newsletter/2019/12#the-magic-flute
  - 'Review of <em>The Magic Flute</em> (opera)'
  - Gwern Branwen
  - 2019-12-29
  - ''
  - ! 'Rebroadcast of abridged 2006 performance (which demonstrates how much Met HD broadcasts have improved technically over the past decade). Gorgeous nonsense. With excellent music by Mozart, lyrics unusually in English, and eccentrically colorful costumes/sets, but mostly unconvincing characters (not helped by abridgement), and a plot stuffed full of Masonic symbols but lacking any sense.'
- - /newsletter/2019/10#turandot
  - 'Review of <em>Turandot</em> (opera)'
  - Gwern Branwen
  - 2019-10-14
  - ''
  - ! 'Fairy tale opera: a despotic Oriental princess chops off the heads of suitors if they cannot answer her riddle. A random prince happens to do so, sets her a counter-riddle, she fails, he tells her the answer, she falls in love with him for no reason, The End. Yeah, pretty dumb. Some amazing costumes and sets, though.'
- - /newsletter/2019/05#dialogues-des-carmelites
  - 'Review of <em>Dialogues des Carmélites</em> (opera)'
  - Gwern Branwen
  - 2019-05-20
  - ''
  - ! 'Dramatic opera on the martyrdom of a convent of nuns during the French Revolution. Starkly minimalist staging. Invokes many great themes, but does not really live up to them or explore them to any satisfying depth.
'
- - /docs/iq/2019-lang.pdf
  - "General Mental Ability and Specific Abilities: Their Relative Importance for Extrinsic Career Success"
  - Jonas W. Lang, Harrison J. Kell
  - '2019'
  - 10.1037/apl0000472
  - ! 'Recent research on the role of general mental ability (GMA) and specific abilities in work-related outcomes has shown that the results differ depending on the theoretical and conceptual approach that researchers use. While earlier research has typically assumed that GMA causes the specific abilities and has thus used incremental validity analysis, more recent research has explored the implications of treating GMA and specific abilities as equals (differing only in breadth and not subordination) and has used relative importance analysis. In this article, we extend this work to the prediction of extrinsic career success operationalized as pay, income, and the attainment of jobs with high prestige. Results, based on a large national sample, revealed that GMA and specific abilities measured in school were good predictors of job prestige measured after 11 years, pay measured after 11 years, and income 51 years later toward the end of the participants’ work lives. With 1 exception, GMA was a dominant predictor in incremental validity analyses. However, in relative importance analyses, the majority of the explained variance was explained by specific abilities, and GMA was not more important than single specific abilities in relative importance analyses. Visuospatial, verbal, and mathematical abilities all had substantial variance shares and were also more important than GMA in some of the analyses. Implications for the interpretation of cognitive ability data and facilitating people’s success in their careers are discussed.'
- - https://www.sciencedirect.com/science/article/pii/S0955395919303482
  - "Reputation transferability across contexts: Maintaining cooperation among anonymous cryptomarket actors when moving between markets"
  - Lukas Norbutas, Stijn Ruiter, Rense Cortena
  - 2020-02
  - 10.1016/j.drugpo.2019.102635
  - ! '<p><em>Background</em>: Buyers and sellers of illegal drugs in cryptomarkets have been found to overcome trust issues created by anonymity and the lack of legal protection with the help of reputation systems. Cryptomarkets rarely operate for longer than a year before closing or getting shut down due to external shocks, such as law enforcement operations. This results in large flows of users migrating between market platforms. An important question in order to better understand why cryptomarkets recover quickly after external shocks is: to what extent can reputation be carried over between different markets? This problem is non-trivial given the anonymity of cryptomarket users and the fact that reputation is tied to a user’s online identity. Here we analyze conditions under which sellers choose to migrate with the same identity and whether reputation history from previous cryptomarkets yields benefits in new contexts.</p><p><em>Methods</em>: We analyze sellers’ migration in three cryptomarkets (Abraxas, Agora and AlphaBay) and follow their reputation history by linking user accounts between marketplaces using the Grams database. We use longitudinal multi-level regression models to compare market success of migrant and non-migrant sellers. In total, the data contains more than 7,500 seller account and 2.5 million buyers’ reputational feedback messages over a period of 3 years.</p><p><em>Findings</em>: It is predominantly the successful sellers with a large number of sales and high reputation who choose to migrate and maintain their identity using cryptographic methods after market closures. We find that reputation history from previous markets creates a competitive advantage to migrant sellers compared to market entrants.</p><p><em>Conclusion</em>: Reputation transferability embeds cryptomarket users beyond a single market platform, which incentivizes cooperative behavior. The results also suggest that reputation transferability might contribute to a quick recovery of online drug trade after shutdowns and accumulation of market share in the hands of a small fraction of successful sellers. [Keywords: Trust, Reputation, Transferability, Cryptomarkets, Dark web, Online drug markets]</p>'
- - https://www.filfre.net/2020/01/master-of-orion/
  - '<em>Master of Orion</em>'
  - Jimmy Maher (The Digital Antiquarian)
  - 2020-01-24
  - ''
  - ! '<p>A typical game of <em>Master of Orion</em> plays out over three broad stages. The first stage is the land grab, the wide-open exploration and colonization phase that happens before you meet your rival aliens. Here your challenge is to balance the economic development of your existing planets against your need to settle as many new ones as possible to put yourself in a good position for the mid-game. (<em>When exactly do I stop spending my home planet’s resources on improving its own infrastructure and start using them to build more colony ships?</em>) The mid-game begins when you start to bump into your rivals, and comes to entail much jockeying for influence, as the various races begin to sort themselves into rival factions. (<em>The Alkaris, bird-like creatures, loathe the Mrrshans, the aforementioned race of frenzied pussycats, and their loathing is returned in kind. I don’t have strong feelings about either one—but whose side would it most behoove me to choose from a purely strategic perspective?</em>) The end-game is nigh when the there is no more room for anyone to expand, apart from taking planets from a rival by force, and the once-expansive galaxy suddenly seems claustrophobic. It often, although by no means always, is marked by a massive war that finally secures somebody that elusive two-thirds majority in the Galactic Council.</p><p>… Yet the core genius of <em>Master of Orion</em> actually lies in how resistant it is to generalization. It’s no exaggeration to say that there really is no “typical” game; I’ve enjoyed plenty which played out in nothing like the pattern I’ve just described for you. I’ve played games in which I never fired a single shot in anger, even ones where I’ve never built a single armed ship of war, just as I’ve played others where I was in a constant war for survival from beginning to end…<em>Master of Orion</em> can easily be read as the work of a designer who looked at <em>Civilization</em> and was unimpressed with its touchy-feely side, then set out to make a game that fixed all the other failings which that side obscured.</p><p>…<em>Master of Orion</em>, on the other hand, works hard at every turn to make such one-size-fits-all strategies impossible—and nowhere more so than in its tech tree. When a new game begins, each race is given a randomized selection of technologies that are possible for it to research, constituting only about half of the total number of technologies in the game. Thus, while a technology roughly equivalent to <em>Civilization</em>’s Railroads does exist in <em>Master of Orion</em>—Star Gates—you don’t <em>know</em> if this or any other technology is actually available to you until you advance far enough up the tree to reach the spot where it ought to be. You can’t base your entire strategy around a predictable technology progression. While you can acquire technologies that didn’t make it into your tree by trading with other empires, bullying them into giving them to you, or attacking their planets and taking them, that’s a much more fraught, uncertain path to go down than doing the research yourself, one that requires a fair amount of seat-of-your-pants strategy in its own right. Any way you slice it, in other words, you have to <em>improvise</em>. This one clever design choice has repercussions for every other aspect of the game. Take, for instance, the endlessly fascinating game-within-a-game of designing your fleet of starships. If the tech tree was static, players would inevitably settle upon a small set of go-to designs that worked for their style of play. As it is, though, every new ship is a fresh balancing act, its equipment calibrated to maximize your side’s technological strengths and mitigate its weaknesses, while also taking into careful account the strengths and weaknesses of the foe you expect to use it against, about which you’ve hopefully been compiling information through your espionage network. Do you build a huge number of tiny, fast, maneuverable fighters, or do you build just a few lumbering galactic dreadnoughts? Or do you build something in between? There are no universally correct answers, just sets of changing circumstances.</p><p>… in <em>Master of Orion</em>, each race’s unique affordances force you to play it differently. Likewise, each opposing race’s affordances in combination with those of your own force you to respond differently to that race when you encounter it, whether on the other side of a diplomats’ table or on a battlefield in space. Further, most races have one technology they’re unusually good at researching and one they’re unusually bad at. Throw in varying degrees of affinity and prejudice toward the other races, and, again, you’ve got an enormous amount of variation which defies cookie-cutter strategizing.</p><p>…Sometimes a status such as that enjoyed by <em>Master of Orion</em> arrives thanks to an historical accident or a mere flashy technical innovation, but that is definitively not the case here. <em>Master of Orion</em> remains as rewarding as ever in all its near-infinite variation. Personally, I like to embrace its dynamic spirit for everything it’s worth by throwing a (virtual) die to set up a new game, letting the Universe decide what size galaxy I play in, how many rivals I play with, and which race I play myself. The end result never fails to be enjoyable, whether it winds up a desperate free-for-all between six alien civilizations compressed into a tiny galaxy with just 24 stars, or a wide-open, stately game of peaceful exploration in a galaxy with over 100 of them. In short, <em>Master of Orion</em> is the most inexhaustible well of entertainment I’ve ever found in the form of a single computer game—a timeless classic that never fails to punish you for playing lazy, but never fails to reward you for playing well. I’ve been pulling it out to try to conquer another random galaxy at least once every year or two for half my life already. I suspect I’ll still be doing so until the day I die.</p>'
- - /docs/statistics/bias/2020-devito.pdf
  - "Compliance with legal requirement to report clinical trial results on ClinicalTrials.gov: a cohort study"
  - Nicholas J. DeVito, Seb Bacon, Ben Goldacre
  - 2020-01-17
  - '10.1016/S0140-6736(19)33220-9'
  - ! '<p><em>Background</em>: Failure to report the results of a clinical trial can distort the evidence base for clinical practice, breaches researchers’ ethical obligations to participants, and represents an important source of research waste. The Food and Drug Administration Amendments Act (<span class="smallcaps-auto">FDAAA</span>) of 2007 now requires sponsors of applicable trials to report their results directly onto ClinicalTrials.gov within 1 year of completion. The first trials covered by the Final Rule of this act became due to report results in January, 2018. In this cohort study, we set out to assess compliance.</p><p><em>Methods</em>: We downloaded data for all registered trials on ClinicalTrials.gov each month from March, 2018, to September, 2019. All cross-sectional analyses in this manuscript were performed on data extracted from ClinicalTrials.gov on Sept 16, 2019; monthly trends analysis used archived data closest to the 15<sup>th</sup> day of each month from March, 2018, to September, 2019. Our study cohort included all applicable trials due to report results under <span class="smallcaps-auto">FDAAA</span>. We excluded all non-applicable trials, those not yet due to report, and those given a certificate allowing for delayed reporting. A trial was considered reported if results had been submitted and were either publicly available, or undergoing quality control review at ClinicalTrials.gov. A trial was considered compliant if these results were submitted within 1 year of the primary completion date, as required by the legislation. We described compliance with the <span class="smallcaps-auto">FDAAA</span> 2007 Final Rule, assessed trial characteristics associated with results reporting using logistic regression models, described sponsor-level reporting, examined trends in reporting, and described time-to-report using the Kaplan-Meier method.</p><p><em>Findings</em>: 4209 trials were due to report results; 1722 (40·9%; 95% CI 39·4–42·2) did so within the 1-year deadline. 2686 (63·8%; 62·4–65·3) trials had results submitted at any time. Compliance has not improved since July, 2018. Industry sponsors were significantly more likely to be compliant than non-industry, non-US Government sponsors (odds ratio [OR] 3·08 [95% CI 2·52–3·77]), and sponsors running large numbers of trials were significantly more likely to be compliant than smaller sponsors (OR 11·84 [9·36–14·99]). The median delay from primary completion date to submission date was 424 days (95% CI 412–435), 59 days higher than the legal reporting requirement of 1 year.</p><p><em>Interpretation</em>: Compliance with the <span class="smallcaps-auto">FDAAA</span> 2007 is poor, and not improving. To our knowledge, this is the first study to fully assess compliance with the Final Rule of the <span class="smallcaps-auto">FDAAA</span> 2007. Poor compliance is likely to reflect lack of enforcement by regulators. Effective enforcement and action from sponsors is needed; until then, open public audit of compliance for each individual sponsor may help. We will maintain updated compliance data for each individual sponsor and trial at <a href="http://fdaaa.trialstracker.net/">fdaaa.trialstracker.net</a>.</p><p><em>Funding</em>: Laura and John Arnold Foundation.</p>'
- - https://www.sciencemag.org/news/2020/01/fda-and-nih-let-clinical-trial-sponsors-keep-results-secret-and-break-law
  - "FDA and NIH let clinical trial sponsors keep results secret and break the law"
  - Charles Piller (Science)
  - 2020-01-13
  - 10.1126/science.aba8123
  - ! '<p>The rule took full effect 2 years ago, on 18 January 2018, giving trial sponsors ample time to comply. But a Science investigation shows that many still ignore the requirement, while federal officials do little or nothing to enforce the law.</p><p>Science examined more than 4700 trials whose results should have been posted on the <span class="smallcaps-auto">NIH</span> website ClinicalTrials.gov under the 2017 rule. Reporting rates by most large pharmaceutical companies and some universities have improved sharply, but performance by many other trial sponsors—including, ironically, <span class="smallcaps-auto">NIH</span> itself—was lackluster. Those sponsors, typically either the institution conducting a trial or its funder, must deposit results and other data within 1 year of completing a trial. But of 184 sponsor organizations with at least five trials due as of 25 September 2019, 30 companies, universities, or medical centers never met a single deadline. As of that date, those habitual violators had failed to report any results for 67% of their trials and averaged 268 days late for those and all trials that missed their deadlines. They included such eminent institutions as the Harvard University–affiliated Boston Children’s Hospital, the University of Minnesota, and Baylor College of Medicine—all among the top 50 recipients of <span class="smallcaps-auto">NIH</span> grants in 2019. The violations cover trials in virtually all fields of medicine, and the missing or late results offer potentially vital information for the most desperate patients. For example, in one long-overdue trial, researchers compared the efficacy of different chemotherapy regimens in 200 patients with advanced lymphoma; another—nearly 2 years late—tests immunotherapy against conventional chemotherapy in about 600 people with late-stage lung cancer.</p><p>…Contacted for comment, none of the institutions disputed the findings of this investigation. In all 4768 trials Science checked, sponsors violated the reporting law more than 55% of the time. And in hundreds of cases where the sponsors got credit for reporting trial results, they have yet to be publicly posted because of quality lapses flagged by ClinicalTrials.gov staff (see sidebar).</p><p>Although the 2017 rule, and officials’ statements at the time, promised aggressive enforcement and stiff penalties, neither <span class="smallcaps-auto">NIH</span> nor <span class="smallcaps-auto">FDA</span> has cracked down. <span class="smallcaps-auto">FDA</span> now says it won’t brandish its big stick—penalties of up to $12,103 a day for failing to report a trial’s results—until after the agency issues further “guidance” on how it will exercise that power. It has not set a date. <span class="smallcaps-auto">NIH</span> said at a 2016 briefing on the final rule that it would cut off grants to those who ignore the trial reporting requirements, as authorized in the 2007 law, but so far has not done so…<span class="smallcaps-auto">NIH</span> and <span class="smallcaps-auto">FDA</span> officials do not seem inclined to apply that pressure. Lyric Jorgenson, <span class="smallcaps-auto">NIH</span> deputy director for science policy, says her agency has been “trying to change the culture of how clinical trial results are reported and disseminated; not so much on the ‘aha, we caught you,’ as much as getting people to understand the value, and making it as easy as possible to share and disseminate results.” To that end, she says, ClinicalTrials.gov staff have educated researchers about the website and improved its usability. As for <span class="smallcaps-auto">FDA</span>, Patrick McNeilly, an official at the agency who handles trial enforcement matters, recently told an industry conference session on ClinicalTrials.gov that “<span class="smallcaps-auto">FDA</span> has limited resources, and we encourage voluntary compliance.” He said the agency also reviews reporting of information on ClinicalTrials.gov as part of inspections of trial sites, or when it receives complaints. McNeilly declined an interview request, but at the conference he discounted violations of ClinicalTrials.gov reporting requirements found by journalists and watchdog groups. “We’re not going to blanketly accept an entire list of trials that people say are noncompliant,” he said.</p><p>…It also highlights that pharma’s record has been markedly better than that of academia and the federal government.</p><p>…But such good performance shouldn’t be an exception, Harvard’s Zarin says. “Further public accountability of the trialists, but also our government organizations, has to happen. One possibility is that <span class="smallcaps-auto">FDA</span> and <span class="smallcaps-auto">NIH</span> will be shamed into enforcing the law. Another possibility is that sponsors will be shamed into doing a better job. A third possibility is that ClinicalTrials.gov will never fully achieve its vital aspirations.”</p>'
- - https://www.spectator.co.uk/2020/01/how-david-rosenhans-fraudulent-thud-experiment-set-back-psychiatry-for-decades/
  - "How David Rosenhan’s fraudulent Thud experiment set back psychiatry for decades: In the 1970s, a social psychologist published ‘findings’ deeply critical of American psychiatric methods. The problem was they were almost entirely fictional"
  - Andrew Scull (Spectator)
  - 2020-01-25
  - ''
  - ! '<p>As her work proceeded, her doubts about Rosenhan’s work grew. At one point, I suggested that she write to <em>Science</em> and request copies of the peer review of the paper. What had the reviewers seen and requested? Did they know the identities of the anonymous pseudo-patients and the institutions to which they had been consigned? What checks had they made on the validity of Rosenhan’s claims? Had they, for example, asked to see the raw field notes? The editorial office told her that the peer review was confidential and they couldn’t share it. I wondered whether an approach from an academic rather than a journalist might be more successful, and with Cahalan’s permission, I sought the records myself, pointing out the important issues at stake, and noting that it would be perfectly acceptable for the names of the expert referees to be redacted. This time the excuse was different: the journal had moved offices, and the peer reviews no longer existed. That’s plausible, but it is distinctly odd that such different explanations should be offered.</p><p>…Of course, proving a negative, especially after decades have passed, is nigh on impossible. Perhaps the appearance of <em>The Great Pretender</em> will cause one or more of the missing pseudo-patients to surface, or for their descendants to speak up and reveal their identities, for surely anyone who participated in such a famous study could not fail to mention it to someone. More likely, I think, is that these people are fictitious, invented by someone who Cahalan’s researches suggest was fully capable of such deception. (Indeed, the distinguished psychologist Eleanor Maccoby, who was in charge of assessing Rosenhan’s tenure file, reported that she and others were deeply suspicious of him, and that they found it ‘impossible to know what he had really done, or if he had done it’, granting him tenure only because of his popularity as a teacher.)</p><p>…Most damning of all, though, are Rosenhan’s own medical records. When he was admitted to the hospital, it was not because he simply claimed to be hearing voices but was otherwise ‘normal’. On the contrary, he told his psychiatrist his auditory hallucinations included the interception of radio signals and listening in to other people’s thoughts. He had tried to keep these out by putting copper over his ears, and sought admission to the hospital because it was ‘better insulated there’. For months, he reported he had been unable to work or sleep, financial difficulties had mounted and he had contemplated suicide. His speech was retarded, he grimaced and twitched, and told several staff that the world would be better off without him. No wonder he was admitted.</p><p>Perhaps out of sympathy for Rosenhan’s son and his closest friends, who had granted access to all this damning material and with whom she became close, I think Cahalan pulls her punches a bit when she brings her book to a conclusion. But the evidence she provides makes an overwhelming case: Rosenhan pulled off one of the greatest scientific frauds of the past 75 years, and it was a fraud whose real-world consequences still resonate today. Exposing what he got up to is a quite exceptional accomplishment, and Cahalan recounts the story vividly and with great skill.</p>'
- - https://www.wired.com/story/cats-watch-youtube/
  - "Cats, Once YouTube Stars, Are Now an ‘Emerging Audience’: They're addicted to channels like Little Kitty & Family, Handsome Nature, and Videos for Your Cat—provided their owners switch on the iPad first"
  - Sage Lazzaro (Wired)
  - 2020-01-22
  - ''
  - !  '<p>Whenever Courtney Cirone grabs her iPad, her cat Cooper runs over as though a bag of treats had just been shaken. He wants to watch <a href="https://www.youtube.com/results?search_query=video+for+cats">YouTube</a>, specifically videos of squirrels and tiny birds scurrying about. “His eyes get super big, and he moves his head back and forth following the animals,” Cirone says. “He ducks his head down low like he’s hiding. One time he looked at me, meowing, like, ‘HELP ME CATCH THIS BASTARD.’” Cooper paws relentlessly at the screen, sometimes lunging at it head-first in an attempt to catch his digital prey. He loves these videos (along with clips of Dr. Phil). He’s so obsessed that Cirone limits his viewing to three times per week, because he sits very close and she’s cautious about protecting his eyes. When she turns her iPad off, he even sulks. If this sounds strange, it is and it’s not: Cats, famously the subjects of online videos, now sit on the other side, watching…Now she puts cat-targeted YouTube videos on for Jasper a few times weekly. He loves them so much that he’ll sit in front of the TV or in between Gall and her laptop to signal that he wants to watch.</p><p>Beyond all the content for humans, there’s a growing world on YouTube specifically for our feline friends. Loved by certain cat owners and occasionally championed by veterinarians and animal scientists, these videos tap into cats’ instincts to stalk, chase, and hunt. Cat-targeted footage of small animals is particularly popular on the platform, posted by channels like <a href="https://www.youtube.com/user/uspimpclub">Little Kitty &amp; Family</a>, <a href="https://www.youtube.com/channel/UCJLIwYrmwgwbTzgmB5yVc7Q/featured">Handsome Nature</a>, and <a href="https://www.youtube.com/channel/UCxHmw6gzrW6x6C6DmEVR3QA">Videos for Your Cat</a>. One of the most prolific creators, Paul Dinning, has posted hundreds of videos for cats, including an eight-hour <a href="https://www.youtube.com/watch?v=xbs7FT7dXYc">“Bird Bonanza”</a> that’s amassed almost 7 million views. According to YouTube’s Trends and Insights team, Dinning created eight of the 10 most-viewed videos for cats in 2019…In 2019, videos containing the phrase “videos for cats” were viewed over 55 million on the platform, up 41% from 2018. “We now have this world where cats are an emerging audience,” Pettie says, “and movies for cats are an emerging trend.”…According to YouTube, videos targeted at dogs garnered only 6 million views last year.</p><p>…Cat Games creator Max Gomboev, a motion designer from Russia, first started making these videos as a tribute to his late cat. After seeing how much other cat owners liked them and the experience they provided over cat-targeted mobile apps, like Cat Fishing 2, which offer much less variety, he started making videos more regularly. “It’s easier than installing an app, and you can show my videos on a TV,” Gomboev says. “Usually, I create a new video every 10 days. Cats like to watch something new.”.</p>'
- - https://mikelynch.org/2019/Nov/22/excavate/
  - "Excavate"
  - Mike Lynch
  - 2019-11-22
  - ''
  - ! '<p>After skipping it last year (I did NaNoWriMo instead) I decided that I missed doing National Novel Generating Month and thought I’d do something relatively simple, based on Tom Phillips’ <em>A Humument</em>, which I recently read for the first time. Phillips’ project was created by drawing over the pages of the forgotten Victorian novel <em>A Human Document</em>, leaving behind a handful of words on each page which form their own narrative, revealing a latent story in the original text. I wanted to simulate this process by taking a neural net trained on one text and use it to excavate a slice from a second text which would somehow preserve the style of the <span class="smallcaps-auto">RNN</span>. To get to the target length of 50,000 words, the second text would have to be very long, so I picked Robert Burton’s <em>The Anatomy of Melancholy</em>, which is over half a million words, and one of my favourite books.</p><p>The next step was to use this to implement the excavate algorithm, which works like this:</p><ol><li>read a vocab from the next L words from the primary text (Burton) where L is the lookahead parameter</li><li>take the first letter of every word in the vocab and turn it into a constraint</li><li>run the <span class="smallcaps-auto">RNN</span> with that constraint to get the next character C</li><li>prune the vocab to those words with the first letter C, with that letter removed</li><li>turn the new vocab into a new constraint and go back to 3</li><li>once we’ve finished a word, add it to the results</li><li>skip ahead to the word we picked, and read more words from the text until we have L words</li><li>go back to 2 unless we’ve run out of original text, or reached the target word count</li></ol><p>Here’s an example of how the <span class="smallcaps-auto">RNN</span> generates a single word with L set to 100:</p><p>Vocab 1: “prime cause of my disease. Or as he did, of whom Felix Plater speaks, that thought he had some of Aristophanes’ frogs in his belly, still crying Breec, okex, coax, coax, oop, oop, and for that cause studied physic seven years, and travelled over most part of Europe to ease himself. To do myself good I turned over such physicians as our libraries would afford, or my private friends impart, and have taken this pains. And why not? Cardan professeth he wrote his book, De Consolatione after his son’s death, to comfort himself; so did Tully”</p><p><span class="smallcaps-auto">RNN</span>: <strong>s</strong></p><p>Vocab 2: “peaks ome till tudied even uch on’s o”</p><p><span class="smallcaps-auto">RNN</span>: <strong>t</strong></p><p>Vocab 3: “ill udied”</p><p><span class="smallcaps-auto">RNN</span>: <strong>u</strong></p><p>Final result: <strong>studied</strong></p><p>The algorithm then restarts with a new 100-word vocabulary starting at “physic seven years”</p><p>It works pretty well with a high enough lookahead value, although I’m not happy with how the algorithm decides when to end a word. The weight table always gets a list of all the punctuation symbols and a space, which means that the <span class="smallcaps-auto">RNN</span> can always bail out of a word half-way if it decides to. I tried constraining it so that it always finished a word once it had narrowed down the options to a single-word vocab, but when I did this, it somehow removed the patterns of punctuation and line-breaks—for example, the way the Three Musketeers <span class="smallcaps-auto">RNN</span> emits dialogue in quotation marks—and this was a quality of the <span class="smallcaps-auto">RNN</span> I wanted to preserve. I think a little more work could improve this.</p><p>…This kind of hybridisation can be applied to any <span class="smallcaps-auto">RNN</span> and base text, so there’s a lot of scope for exploration here, of grafting the grammar and style of one text onto the words from another. And the alliteration and lipogram experiments above are just two simple examples of more general ways in which I’ll be able to tamper with the output of <span class="smallcaps-auto">RNN</span>s.</p>'
- - /docs/psychology/2000-mcabee.pdf
  - "Prolonged survival with hydranencephaly: report of two patients and literature review"
  - Gary N. McAbee, Allison Chan, Edmund L. Erde
  - 2000-07
  - "10.1016/S0887-8994(00)00154-5"
  - ! 'Infants with hydranencephaly are presumed to have a reduced life expectancy, with a survival of several weeks to months. Rarely, patients with prolonged survival have been reported, but these infants may have had other neurologic conditions that mimicked hydranencephaly, such as massive hydrocephalus or holoprosencephaly. We report two infants with prenatally acquired hydranencephaly who survived for 66 and 24 months. We reviewed published reports to ascertain the clinical and laboratory features associated with survival of more than 6 months. This review demonstrates that prolonged survival up to 19 years can occur with hydranencephaly, even without rostral brain regions, with isoelectric electroencephalograms, and with absent-evoked potentials. Finally, the ethical aspects of these findings, as they relate to anencephaly and organ transplantation, are discussed.'
- - /docs/psychology/1985-whishaw.pdf
  - "The mating movements of male decorticate rats: evidence for subcortically generated movements by the male but regulation of approaches by the female"
  - I.Q. Whishaw, B. Kolb
  - 1985-10
  - "10.1016/0166-4328(85)90042-7"
  - ! "The study shows that although many features of copulation in decorticate male rats are normal, copulatory success is importantly dependent upon the control of approaches exerted by the normal female rat. Copulation by neonatally decorticated adult rats and normal adult rats was studied in cohabitation and videotaped tests. Seven of 10 decorticate rats and 6 of 6 normal rats sired pups in the cohabitation test. When initially paired with ovariectomized and primed female rats, in the videotaped tests, all normal rats, but only one decorticated rat, copulated. All decorticate rats made movements indicative of sexual interest including: treading on the female's back, passing over the female, and sniffing the female's genitals. After activating stimulation, 5 of 6 remaining decorticated males copulated. After one successful mount the remaining copulatory patterns proceeded relatively normally. Numbers of mounts, intromissions, ejaculations, postejaculatory songs, and the intromission and ejaculatory patterns were like those of control rats, although the decorticate rats had fewer mount bouts and showed abnormalities in the execution of movements. Precopulatory movements were notated, using the Eshkol-Wachmann system, and compared with copulatory movements. Non-copulatory and copulatory approaches were similar, except that clasping appeared to be the key movement involved in the transition of an approach movement into a copulatory movement. The analysis also showed that the females' movements of hopping, turning, and kicking were important for regulating the males' approaches, and were instrumental in the success achieved by the decorticated males. The study shows that although the cortex, insofar as it facilitates the appearance of certain movements and contributes to their efficiency, is involved in male sexual activity, in its absence well organized sexual activity is possible, although this is dependent, in part, upon the behaviour of the female."
- - /docs/psychology/1982-carter.pdf
  - Neonatal decortication and adult female sexual behavior
  - C. Sue Carter, Diane M. Witt, Bryan Kolb, I.Q. Whishaw
  - 1982-10
  - 10.1016/0031-9384(82)90254-2
  - ! 'Neonatal lesions of the cerebral cortex in female rats did not eliminate female sexual behavior as measured by lordosis. However, lordosis in response to prolonged low levels of estradiol benzoate (1.0 μg/day for 6 days) was attenuated in lesioned females. Following estradiol benzoate plus progesterone (0.5 mg) treatment the probability of lordosis increased markedly in the decorticate females, but still remained below control levels. Decorticate females were mounted by the male at least as often as control females. Hopping and darting and rejection behaviors on the part of the female were virtually eliminated in the decorticate group. However, these females continued to direct sniffing behavior toward the male at levels above those of the controls.'
- - 'https://eng.uber.com/pplm/'
  - 'Controlling Text Generation with Plug and Play Language Models'
  - 'Rosanne Liu, Sumanth Dathathri, Andrea Madotto, Piero Molino, Jason Yosinski'
  - '2019-12-05'
  - ''
  - ! '<p>Recent findings from the scientific community show that training language models (LMs) on large, unannotated corpora and with a simple objective—to predict the next word in a passage of text given the preceding text—can demonstrate unprecedented fluency. LMs can generate coherent, relatable text, either from scratch or by completing a passage started by the user…Although these models are able to encode complex knowledge about spelling, grammar, and typical speech patterns, they are hard to steer or control. In other words, while we can ask them to generate many possible sentences or to complete a given sentence fragment, there is no easy way to get them to generate text with specific properties or about particular topics. For example, what if we wanted the generated text to start with the same prefix, ‘The food is awful’, but then to turn in a positive direction? Or gradually to change the topic of the generated text to being about politics? Researchers around the world have proposed multiple ways of conditioning text generation, including starting with a pre-trained LM and fine-tuning it to always produce positive sentences, training a large conditional model from scratch, or turning a given sentence into a more positive one by substituting new text in for key n-grams.</p><p>This article discusses an alternative approach to controlled text generation, titled the Plug and Play Language Model (PPLM), introduced in a recent paper from Uber AI. PPLM allows a user to flexibly plug in one or more simple attribute models representing the desired control objective into a large, unconditional LM. The method has the key property that it uses the LM as is—no training or fine-tuning is required—which enables researchers to leverage best-in-class LMs even if they do not have the extensive hardware required to train them.</p><p>…Fortunately, Uber AI’s Plug and Play Language Model allows researchers to make use of the few pretrained models out there: rather than requiring everyone to train their own woolly mammoth, PPLM lets users combine small attribute models with an LM to steer its generation. Attribute models can be 100,000 times smaller than the LM and still be effective in steering it, like a mouse sitting atop our woolly mammoth friend and telling it where to go (Figure 1). The mouse tells the mammoth where to go using gradients.</p><p><span style="font-weight: 400;">PPLM resolves this issue by approximately implementing the more efficient Metropolis-adjusted Langevin sampler of </span><a href="https://projecteuclid.org/euclid.bj/1178291835" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">Roberts and Tweedie (1996)</span></a><span style="font-weight: 400;"> as implemented for pairs of neural networks by </span><a href="https://arxiv.org/abs/1612.00005" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">Nguyen et al. (2016)</span></a><span style="font-weight: 400;"> in their Plug-and-Play Generative Networks (PPGN) model. In this vein, the PPLM algorithm entails three simple steps to generate a sample:</span><span style="font-weight: 400;"><br /> </span></p><ul><li style="list-style-type: none;"><ul><li style="font-weight: 400;"><span style="font-weight: 400;">Given a partially generated sentence, compute </span><i><span style="font-weight: 400;">log(p(x))</span></i><span style="font-weight: 400;"> and </span><i><span style="font-weight: 400;">log(p(a|x))</span></i><span style="font-weight: 400;"> and the gradients of each with respect to the hidden representation of the underlying language model. These quantities are both available using an efficient forward and backward pass of both models.</span></li><li style="font-weight: 400;"><span style="font-weight: 400;">Use the gradients to move the hidden representation of the language model a small step in the direction of increasing </span><i><span style="font-weight: 400;">log(p(a|x))</span></i><span style="font-weight: 400;"> and increasing </span><i><span style="font-weight: 400;">log(p(x))</span></i><span style="font-weight: 400;">.</span></li><li style="font-weight: 400;"><span style="font-weight: 400;">Sample the next word.</span></li></ul></li></ul><p><span style="font-weight: 400;">Intuitively, as a PPLM generates text one token at a time, it continuously steers its representation of the text in a direction that will be more likely to possess the desired attribute—high </span><i><span style="font-weight: 400;">log(p(a|x))</span></i><span style="font-weight: 400;">—while still retaining fluency under the original language model—high <em>log(</em></span><em><span style="font-weight: 400;">p(x))</span></em><span style="font-weight: 400;">.</span></p><p>…In addition to steering generated text using gradients from a particular p(a|x) attribute model, text must be steered by the p(x) from a base LM. As alluded by Bayes’ rule above and described in more detail in our paper, without also taking gradient steps in the direction of high likelihood by the LM, language degenerates; for example, optimizing only for positivity but not LM likelihood can produce strings like “great great great great great”. Thus, we use the unmodified language model to ensure the fluency of language is maintained at or near the level of the original language model (in this example, GPT-2-medium). We do this in two ways: first, by taking steps to minimize the Kullback–Leibler (KL) Divergence between the output distribution of the modified and unmodified language models, and second by performing post-norm fusion (introduced in Stahlberg et al. (2018)) between the modified and unmodified next word distributions. Through both factors the generated text is kept in high p(x) regions, as described in Section 3.3 of our paper and illustrated in Figure 3, below…</p>'
- - https://www.instagram.com/nathanwpylestrangeplanet/
  - Strange Planet (Instagram)
  - Nathan W. Pyle
  - ''
  - ''
  - ! "[Official Instagram account of Nathan W. Pyle's popular webcomic <em>Strange Planet</em>, which recounts in a deadpan manner ordinary human activities as conducted by literal-minded aliens who defamiliarize them. Pyle does not appear to have a webcomic website for <em>Strange Planet</em>, and the Instagram account to be his primary form of releasing SP comics.]"
- - https://waifulabs.com/
  - Waifu Labs
  - Sizigi Studios
  - '2019-07-23'
  - ''
  - ! "<p>[Waifu Labs is an interactive website for generating (1024px?) anime faces using a customized StyleGAN trained on Danbooru2018. Similar to Artbreeder, it supports face exploration and face editing, and at the end, a user can purchase prints of a particular face.]</p> <p>We taught a world-class artificial intelligence how to draw anime. All the drawings you see were made by a non-human artist! Wild, right? It turns out machines love waifus almost as much as humans do. We proudly present the next chapter of human history: lit waifu commissions from the world's smartest AI artist. In less than 5 minutes, the artist learns your preferences to make the perfect waifu just for you.</p>"
- - https://thispersondoesnotexist.com/
  - This Person Does Not Exist
  - 'Phillip Wang'
  - '2019-02-12'
  - ''
  - ! "<p>[This Person Does Not Exist is a StyleGAN-based noninteractive website, which uses the Nvidia-trained FFHQ face StyleGAN model to generate realistic 1024px faces (upgraded to StyleGAN 2 in 2020). One face is displayed at a time, and a new face automatically generated every few seconds. It inspired a rash of copycats, including This Waifu Does Not Exist.]</p> <p>Recently a talented group of researchers at Nvidia released the current state of the art generative adversarial network, StyleGAN, over at https://github.com/NVlabs/stylegan I have decided to dig into my own pockets and raise some public awareness for this technology. Faces are most salient to our cognition, so I've decided to put that specific pretrained model up. Their research group have also included pretrained models for cats, cars, and bedrooms in their repository that you can immediately use. Each time you refresh the site, the network will generate a new facial image from scratch from a 512 dimensional vector.</p>"
- - https://pair-code.github.io/interpretability/text-dream/blogpost/
  - "What does BERT dream of? A visual investigation of nightmares in Sesame Street"
  - Alex Bäuerle, James Wexler (PAIR)
  - 2020-01-13
  - ''
  - ! '<p><span class="smallcaps-auto">BERT</span>, a neural network published by Google in 2018, excels in natural language understanding. It can be used for multiple different tasks, such as sentiment analysis or next sentence prediction, and has recently been integrated into Google Search. This novel model has brought a big change to language modeling as it outperformed all its predecessors on multiple different tasks. Whenever such breakthroughs in deep learning happen, people wonder how the network manages to achieve such impressive results, and what it actually learned. A common way of looking into neural networks is feature visualization. The ideas of feature visualization are borrowed from Deep Dream, where we can obtain inputs that excite the network by maximizing the activation of neurons, channels, or layers of the network. This way, we get an idea about which part of the network is looking for what kind of input.</p><p>In Deep Dream, inputs are changed through gradient descent to maximize activation values. This can be thought of as similar to the initial training process, where through many iterations, we try to optimize a mathematical equation. But instead of updating network parameters, Deep Dream updates the input sample. What this leads to is somewhat psychedelic but very interesting images, that can reveal to what kind of input these neurons react. Examples for Deep Dream processes with images from the original Deep Dream blogpost. Here, they take a randomly initialized image and use Deep Dream to transform the image by maximizing the activation of the corresponding output neuron. This can show what a network has learned about different classes or for individual neurons.</p><p>Feature visualization works well for image-based models, but has not yet been widely explored for language models. This blogpost will guide you through experiments we conducted with feature visualization for <span class="smallcaps-auto">BERT</span>. We show how we tried to get <span class="smallcaps-auto">BERT</span> to dream of highly activating inputs, provide visual insights of why this did not work out as well as we hoped, and publish tools to explore this research direction further. When dreaming for images, the input to the model is gradually changed. Language, however, is made of discrete structures, i.e. tokens, which represent words, or word-pieces. Thus, there is no such gradual change to be made… Looking at a single pixel in an input image, such a change could be gradually going from green to red. The green value would slowly go down, while the red value would increase. In language, however, we can not slowly go from the word “green” to the word “red”, as everything in between does not make sense. To still be able to use Deep Dream, we have to utilize the so-called Gumbel-Softmax trick, which has already been employed in a paper by Poerner et. al.. This trick was introduced by Jang et. al. and Maddison et. al.. It allows us to soften the requirement for discrete inputs, and instead use a linear combination of tokens as input to the model. To assure that we do not end up with something crazy, it uses two mechanisms. First, it constrains this linear combination so that the linear weights sum up to one. This, however, still leaves the problem that we can end up with any linear combination of such tokens, including ones that are not close to real tokens in the embedding space. Therefore, we also make use of a temperature parameter, which controls the sparsity of this linear combination. By slowly decreasing this temperature value, we can make the model first explore different linear combinations of tokens, before deciding on one token.</p><p>…The lack of success in dreaming words to highly activate specific neurons was surprising to us. This method uses gradient descent and seemed to work for other models (see Poerner et. al. 2018). However, <span class="smallcaps-auto">BERT</span> is a complex model, arguably much more complex than the models that have been previously investigated with this method.</p>'
- - https://github.com/openai/lm-human-preferences
  - 'lm-human-preferences'
  - Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, Geoffrey Irving (OpenAI)
  - 2019-09-14
  - ''
  - ! '<p>Code for the paper ‘Fine-Tuning Language Models from Human Preferences’. Status: Archive (code is provided as-is, no updates expected). We provide code for:</p><ul><li>Training reward models from human labels</li><li>Fine-tuning language models using those reward models</li></ul><p>It does not contain code for generating labels. However, we have released human labels collected for our experiments, at <code>gs://lm-human-preferences/labels</code>. For those interested, the question and label schemas are simple and documented in <code>label_types.py</code>.</p><p>The code has only been tested using the smallest <span class="smallcaps-auto">GPT</span>-2 model (124M parameters). This code has only been tested using Python 3.7.3. Training has been tested on <span class="smallcaps-auto">GCE</span> machines with 8 V100s, running Ubuntu 16.04, but development also works on Mac OS X.</p>'
- - https://cloud.google.com/storage/docs/gsutil/commands/config
  - 'gsutil config—Obtain credentials and create configuration file'
  - Google
  - ''
  - ''
  - ! 'The gsutil config command obtains access credentials for Cloud Storage and writes a boto/gsutil configuration file containing the obtained credentials along with a number of other configuration-controllable values.'
- - "https://arxiv.org/pdf/1809.11096.pdf#page=6"
  - "Big<span class=\"smallcaps-auto\">GAN</span>: Large Scale <span class=\"smallcaps-auto\">GAN</span> Training for High Fidelity Natural Image Synthesis: 4.2 Characterizing Instability: The Discriminator"
  - "Andrew Brock, Jeff Donahue, Karen Simonyan"
  - "2019-08-26"
  - ""
  - ! '<p>We also observe that <strong>D</strong>’s loss approaches zero during training, but undergoes a sharp upward jump at collapse (Appendix F). One possible explanation for this behavior is that <strong>D</strong> is overfitting to the training set, memorizing training examples rather than learning some meaningful boundary between real and generated images. As a simple test for <strong>D</strong>’s memorization (related to Gulrajani et al. (2017)), we evaluate uncollapsed discriminators on the ImageNet training and validation sets, and measure what percentage of samples are classified as real or generated. While the training accuracy is consistently above 98%, the validation accuracy falls in the range of 50–55%, no better than random guessing (regardless of regularization strategy). This confirms that <strong>D</strong> is indeed memorizing the training set; we deem this in line with <strong>D</strong>’s role, which is not explicitly to generalize, but to distill the training data and provide a useful learning signal for <strong>G</strong>. Additional experiments and discussion are provided in Appendix G.</p>'
- - https://arxiv.org/pdf/1706.03741.pdf#page=15
  - "Deep reinforcement learning from human preferences: Appendix A.2: Atari"
  - "Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, Dario Amodei"
  - "2019-12-23"
  - ""
  - ! 'The predictor is trained asynchronously from the RL agent, and on our hardware typically processes 1 label per 10 RL timesteps. We maintain a buffer of only the last 3,000 labels and loop over this buffer continuously; this is to ensure that the predictor gives enough weight to new labels (which can represent a shift in distribution) when the total number of labels becomes large.'
- - https://artbreeder.com/
  - Artbreeder
  - Joel Simon
  - 2019-09-09
  - ''
  - ! '[Artbreeder is an interactive <span class=\"smallcaps-auto\">GAN</span> generator website. Originally named "Ganbreeder" and providing only the 256px Big<span class=\"smallcaps-auto\">GAN</span> generator, it now provides a variety of Big<span class=\"smallcaps-auto\">GAN</span> & Style<span class=\"smallcaps-auto\">GAN</span> models, including the anime portrait Style<span class=\"smallcaps-auto\">GAN</span> model. (It is more general than the similar Waifu Labs, but my anime model is not as good.) Users can generate random samples and explore slight variants of them to gradually explore the "latent space" and find interesting images, but they can also edit images more directly, upload existing images to find the most similar image produced by the model, etc. A popular website, it has generated >56m images from September 2019 to January 2020.]'
- - https://aidungeon.io/
  - AI Dungeon 2
  - Nick Walton
  - 2019-12
  - ''
  - ! '[AI Dungeon 2 is a project which trains <span class=\"smallcaps-auto\">GPT</span>-2-1.5b on logs from text adventure games; when used interactively by a human, it "plays <span class=\"smallcaps-auto\">RPG</span> games" with you, but because it is powered by <span class=\"smallcaps-auto\">GPT</span>-2-1.5b, it is immensely flexible and can cope (to some degree) with almost any input, producing bizarre, hilarious, or surprisingly logical sequences of adventures. It became popular overnight, crushing Walton with bandwidth bills, and has been turned into an app and community to support distribution and development. See also https://colab.research.google.com/github/nickwalton/AIDungeon/blob/master/AIDungeon_2.ipynb and https://old.reddit.com/r/AIDungeon/ and http://www.aidungeon.io/2019/11/my-orc-band-and-our-quest-for-equal.html .]'
- - https://paulfchristiano.com/
  - Homepage of Paul F. Christiano
  - Paul F. Christiano
  - ''
  - ''
  - ! '<p>I work on <a href="https://paulfchristiano.com/ai/">AI alignment</a>. I&#8217;m a member of the safety team at <a href="https://openai.com/">OpenAI</a>, a research associate at <a href="https://www.fhi.ox.ac.uk/"><span class=\"smallcaps-auto\">FHI</span></a>, a board member at <a href="https://ought.org/">Ought</a>, and a recent graduate of the <a href="http://theory.cs.berkeley.edu/">theory group</a> at UC Berkeley.</p> <p>You may be interested in my <a href="https://ai-alignment.com/">writing about alignment</a>, my <a href="http://sideways-view.com">blog</a>, my <a href="https://paulfchristiano.com/publications/">academic publications</a>, or my involvement with <a href="https://paulfchristiano.com/ea/">effective altruism</a>.</p> <p>You can reach me at <a href="mailto:paul@openai.com">paulfchristiano@gmail.com</a>.</p>'
- - https://www.nature.com/articles/s41598-019-53042-3
  - 'Life without a brain: Neuroradiological and behavioral evidence of neuroplasticity necessary to sustain brain function in the face of severe hydrocephalus'
  - 'C. F. Ferris, X. Cai, J. Qiao, B. Switzer, J. Baun, T. Morrison, S. Iriah, D. Madularu, K. W. Sinkevicius, P. Kulkarni'
  - 2019-12-11
  - 10.1038/s41598-019-53042-3
  - ! 'A two-year old rat, R222, survived a life-time of extreme hydrocephaly affecting the size and organization of its brain. Much of the cortex was severely thinned and replaced by cerebrospinal fluid, yet R222 had normal motor function, could hear, see, smell, and respond to tactile stimulation. The hippocampus was malformed and compressed into the lower hindbrain together with the hypothalamus midbrain and pons, yet R222 showed normal spatial memory as compared to age-matched controls. <span class=\"smallcaps-auto\">BOLD</span> <span class=\"smallcaps-auto\">MRI</span> was used to study the reorganization of R222’s brain function showing global activation to visual, olfactory and tactile stimulation, particularly in the brainstem/cerebellum. The results are discussed in the context of neuroadaptation in the face of severe hydrocephaly and subsequent tissue loss, with an emphasis on what is the “bare minimum” for survival.'
- - https://www.andrew.cmu.edu/user/nicolasc/publications/Arps-FC20.pdf
  - "Open Market or Ghost Town? The Curious Case of OpenBazaar"
  - James E. Arps, Nicolas Christin
  - 2020-01-08
  - ''
  - ! 'OpenBazaar, a decentralized electronic commerce market-place, has received significant attention since its development was first announced in early 2014. Using multiple daily crawls of the OpenBazaar network over approximately 14 months (June 25, 2018–September 3, 2019), we measure its evolution over time. We observed 6,651 unique participants overall, including 980 who used Tor at one point or another. More than half of all users (3,521) were only observed on a single day or less, and, on average, only approximately 80 users are simultaneously active on a given day. As a result, economic activity is, unsurprisingly, much smaller than on centralized anonymous marketplaces. Furthermore, while a majority of the 24,379 distinct items listed seem to be legal offerings, a majority of the measurable economic activity appears to be related to illicit products. We also discover that vendors are not always using prudent security practices, which makes a strong case for imposing secure defaults. We conclude that OpenBazaar, so far, has not gained much traction to usher in the new era of decentralized, private, and legitimate electronic commerce it was promising. This could be due to a lack of user demand for decentralized marketplaces, lack of integration of private features, or other factors, such as a higher learning curve for users compared to centralized alternatives. [Keywords: Measurement; peer-to-peer systems; electronic commerce.]'
- - https://beepb00p.xyz/pkm-search.html
  - "Building personal search infrastructure for your knowledge and code: Overview of search tools for desktop and mobile; using Emacs and Ripgrep as desktop search engine"
  - Dmitrii Gerasimov
  - 2019-11-01
  - ''
  - ! '<h2>Table of Contents</h2><div id="text-table-of-contents"><ul><li><a href="https://beepb00p.xyz/pkm-search.html#why">1. Why search?</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#what">2. What do I search?</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#personal_information">3. Searching in personal information</a><ul><li><a href="https://beepb00p.xyz/pkm-search.html#org_mode">Org mode notes</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#other">Other plaintext, chats and social media</a></li></ul></li><li><a href="https://beepb00p.xyz/pkm-search.html#recoll">4. Recoll</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#android">5. Searching on Android</a><ul><li><a href="https://beepb00p.xyz/pkm-search.html#org0000006">Orgzly</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#org0000007">Docsearch +</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#recoll_web">Recoll Web</a></li></ul></li><li><a href="https://beepb00p.xyz/pkm-search.html#web">6. Web search</a><ul><li><a href="https://beepb00p.xyz/pkm-search.html#org000000a">Firefox enhancements</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#org000000b">Chrome enhancements</a></li></ul></li><li><a href="https://beepb00p.xyz/pkm-search.html#code">7. Searching in code</a><ul><li><a href="https://beepb00p.xyz/pkm-search.html#org000000d">Why?</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#org000000e">What do I want</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#org000000f">Existing code search tools</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#org0000010">Solution: use Emacs and Ripgrep</a></li></ul></li><li><a href="https://beepb00p.xyz/pkm-search.html#appendix_cloudmacs">8. Appendix: searching away from computer</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#appendix_daemon">9. Appendix: Lightning fast Emacs</a><ul><li><a href="https://beepb00p.xyz/pkm-search.html#org0000013">running daemon on startup</a></li></ul></li><li><a href="https://beepb00p.xyz/pkm-search.html#appendix_emacs">10. Appending: general Emacs tips</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#future">11. Future and my holy grail of search</a></li><li><a href="https://beepb00p.xyz/pkm-search.html#org0000017">12. –</a></li></ul>…These days, if you have decent connection, you are seconds away from finding almost any public knowledge in the internet. However, there is another aspect of information: personal and specific to <i>your</i> needs, work and hobbies. It’s <i>your</i> todo list, <i>your</i> private notes, books <i>you</i> are reading. Of course, it’s not that well integrated with the outside world, hence the tooling and experience of interacting with it is very different.</p><p>Some examples:</p><ul class="org-ul"><li><div><span class="before-aside"> To find something from <i>my</i> Messenger history with a friend, I need to be online, open Facebook, navigate to search and use the interface Facebook’s employees thought convenient (spoiler: it sucks) </span><aside class="sidenote"><a class="post-tag" href="https://beepb00p.xyz/tags.html#offline">#offline</a></aside></div><p>It’s <i>my</i> information, something that came out from my brain. Why can’t I have it available anywhere, anytime, presented the way I prefer?</p></li><li><p>To find something in <i>my</i> Kobo ebook, I need to reach my device physically and type the query using the virtual keyboard (yep, e-ink lag!). Not a very pleasant experience.</p><p>It’s something <i>I</i> own and have read. Why does it have to be so hard?</p></li></ul><p>Such things are pretty frustrating to me, so I’ve been working on making them easier. Search has to be <a href="https://en.wikipedia.org/wiki/Incremental_search">incremental</a>, fast and as convenient to use as possible. I’ll be sharing some of workflows, tricks and thoughts in this post.</p><p>The post is geared towards using Emacs and Org-mode, but hopefully you’ll find some useful tricks for your current tools and workflow even if you don’t. There is (almost) nothing inherently special about Emacs, I’m sure you can achieve similar workflows in other modern text editors given they are flexible enough.</p><p>Note: throughout the post I will link to my <a href="https://github.com/karlicoss/dotfiles-emacs">emacs config</a> snippets. To prevent code references from staling, I use permalinks, but check master branch as well in case of patches or more comments in code.</p></div></div><div id="outline-container-org0000001" class="outline-2"><h2 id="what"><a class="headerlink" href="https://beepb00p.xyz/pkm-search.html#what">·</a><span class="section-number-2">2</span> What do I search?</h2><div id="text-what" class="outline-text-2"><p>I’ll write about searching in</p><ul class="org-ul"><li>my personal notes, tasks and knowledge repository (this blog included)</li><li>all digital trace I’m leaving (tweets, internet comments, annotations)</li><li>chat logs with people</li><li>books and papers I’m reading</li><li>code that I’m working on</li><li>information on the Internet (duh!)</li></ul></div></div>'
- - /TWDNE#results
  - "ThisWaifuDoesNotExist.net: Initial Traffic Results"
  - Gwern Branwen
  - 2019-02-23
  - ''
  - ! '<p>[<span class=\"smallcaps-auto\">TWDNE</span> traffic results: China virality drove hundreds of thousands of users, and traffic remains at nontrivial levels through to 2020.]</p><p>I set up the first version of <span class="smallcaps-auto">TWDNE</span> with faces Tuesday 19 February 2019; overnight, it went viral after being posted to a Chinese <span class="smallcaps-auto">FLOSS</span>/technology website, receiving hundreds of thousands of unique visitors over the next few days (&gt;700,000 unique visitors), with surprisingly long average sessions…<a href="/docs/traffic/20190218-20190720-twdne-analytics.pdf">By 20 July 2019, <span class="smallcaps-auto">TWDNE</span> traffic</a> hit 1,161,978 unique users in 1,384,602 sessions; because of the JS refresh, ‘pageviews’ (12,102,431) is not particularly meaningful, but we can infer from the remarkable 1m:48s length of the average session, that <span class="smallcaps-auto">TWDNE</span> users are looking at &gt;7 images per session.</p>'
- - /GPT-2#cleaning-project-gutenberg-contemporary-poetry
  - "GPT-2 Poetry: Combining and Cleaning Project Gutenberg & Poetry Foundation poetry"
  - Gwern Branwen
  - 2019-10-28
  - ''
  - ! 'Shawn Presser cleaned the Project Gutenberg poetry by using a heuristic on line numbers to guess where poems begin/end. This provides useful semantic metadata to the <span class=\"smallcaps-auto\">GPT</span>-2-117M model, reducing "runon" or "ramblingness", as it sees many discrete texts rather than a few book-length texts. I combined this improved PG poetry dataset with a new dataset on Kaggle, which scraped the Poetry Foundation website for modern/contemporary poetry, fixing the post-1920s emptiness of PG. The generated poems are much better.'
- - http://www.freesfonline.de/content/Abraham1.pdf
  - "The Cambist and Lord Iron: A Fairy Tale of Economics"
  - Daniel Abraham
  - '2007'
  - ''
  - ! '<p>(<a href="https://en.wikipedia.org/wiki/The_Cambist_and_Lord_Iron">WP</a>; <a href="https://tvtropes.org/pmwiki/pmwiki.php/Literature/TheCambistAndLordIron"><span class=\"smallcaps-auto\">TVT</span>ropes</a>; <a href="http://lesswrong.com/lw/3d6/the_cambist_and_lord_iron_a_fairy_tale_of/">LW discussion</a>; <a href="http://www.lightspeedmagazine.com/fiction/the-cambist-and-lord-iron-a-fairy-tale-of-economics/">non-<span class=\"smallcaps-auto\">PDF</span> version</a>) 2007 short story, set in a Renaissance-esque fantasy historical setting, featuring a cambist (a money-exchanger) who is set three dangerous tasks by a bored and dissolute aristocrat. The 3 challenges illustrate principles of economics:</p><ol type="1"><li>the <a href="https://en.wikipedia.org/wiki/Exchange_value">exchange</a> theory of <a href="https://en.wikipedia.org/wiki/Value_(economics)">value</a>: the value of something is what you can exchange it for in the market</li><li><a href="https://en.wikipedia.org/wiki/Revealed_preference">revealed preferences</a>: the choices individuals and groups reveal the true value set on things, regardless of what they may say</li><li><a href="https://en.wikipedia.org/wiki/Gains_from_trade">gains from trade</a>: a trade of 2 things, which remain unchanged, can make <em>both</em> parties better off</li></ol>'
- - http://abcnotation.com/wiki/abc:standard:v2.1#xreference_number
  - 'The abc music standard 2.1: section 3.1.1: <code>X:</code> - reference number'
  - Chris Walshaw et al
  - 2011-12
  - ''
  - ! '<p>The <code>X:</code> (reference number) field is used to assign to each tune within a tunebook a unique reference number (a positive integer), for example: <code>X:23</code>.</p><p>The <code>X:</code> field is also used to indicate the start of the tune (and hence the <a href="http://abcnotation.com/wiki/abc:standard:v2.1#tune_header_definition" title="abc:standard:v2.1 ↵" class="wikilink1">tune header</a>), so all tunes must start with an <code>X:</code> field and only one <code>X:</code> field is allowed per tune.</p><p>The <code>X:</code> field may be empty, although this is not recommended.</p><p><em> Recommendation for developers: </em> Software which writes <a href="http://abcnotation.com/wiki/abc:standard:v2.1#abc_file_definition" title="abc:standard:v2.1 ↵" class="wikilink1">abc files</a> is recommended to offer users the possibility to manage <code>X:</code> field numbering automatically. <abbr title="Graphical User Interface"><span class=\"smallcaps-auto\">GUI</span></abbr> applications may even hide the <code>X:</code> field from users although they should always allow the user access to the raw <a href="http://abcnotation.com/wiki/abc:standard:v2.1#abc_file_definition" title="abc:standard:v2.1 ↵" class="wikilink1">abc file</a>.</p>'
- - /Faces#reversing-stylegan-to-control-modify-images
  - 'Making Anime Faces With StyleGAN: Reversing StyleGAN To Control & Modify Images'
  - Gwern Branwen
  - 2019-03-24
  - ''
  - ! 'Discussion of how to modify existing images with <span class=\"smallcaps-auto\">GAN</span>s. There are several possibilities: train another NN to turn an image back into the original encoding; run blackbox search on encodings, repeatedly tweaking it to approximate a target face; or the whitebox approach, directly backpropagating through the model from the image <em>to</em> the encoding while holding the model fixed. All of these have been implemented for Style<span class=\"smallcaps-auto\">GAN</span>, and a combination works best. There are even <span class=\"smallcaps-auto\">GUI</span>s for editing Style<span class=\"smallcaps-auto\">GAN</span> anime faces!'
- - https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html
  - "Towards a Conversational Agent that Can Chat About…Anything"
  - Daniel Adiwardana, Thang Luong (Google Brain)
  - 2020-01-28
  - ''
  - ! '<p>Modern conversational agents (chatbots) tend to be highly specialized—they perform well as long as users don’t stray too far from their expected usage. To better handle a wide variety of conversational topics, open-domain dialog research explores a complementary approach attempting to develop a chatbot that is not specialized but can still chat about virtually anything a user wants. Besides being a fascinating research problem, such a conversational agent could lead to many interesting applications, such as further humanizing computer interactions, improving foreign language practice, and making relatable interactive movie and videogame characters.</p><p>However, current open-domain chatbots have a critical flaw—they often don’t make sense. They sometimes say things that are inconsistent with what has been said so far, or lack common sense and basic knowledge about the world. Moreover, chatbots often give responses that are not specific to the current context. For example, “I don’t know,” is a sensible response to any question, but it’s not specific. Current chatbots do this much more often than people because it covers many possible user inputs.</p><p>In <a href="https://arxiv.org/abs/2001.09977#google">“Towards a Human-like Open-Domain Chatbot”</a>, we present Meena, a 2.6 billion parameter end-to-end trained neural conversational model. We show that Meena can conduct conversations that are more sensible and specific than existing state-of-the-art chatbots. Such improvements are reflected through a new human evaluation metric that we propose for open-domain chatbots, called Sensibleness and Specificity Average (<span class="smallcaps-auto">SSA</span>), which captures basic, but important attributes for human conversation. Remarkably, we demonstrate that perplexity, an automatic metric that is readily available to any neural conversational models, highly correlates with <span class="smallcaps-auto">SSA</span>.</p><p>…The Meena model has 2.6 billion parameters and is trained on 341 GB of text, filtered from public domain social media conversations. Compared to an existing state-of-the-art generative model, OpenAI <span class="smallcaps-auto">GPT</span>-2, Meena has 1.7× greater model capacity and was trained on 8.5× more data.</p><p>… For each chatbot, we collect between 1600 and 2400 individual conversation turns through about 100 conversations. Each model response is labeled by crowdworkers to indicate if it is sensible and specific. The sensibleness of a chatbot is the fraction of responses labeled “sensible”, and specificity is the fraction of responses that are marked “specific”. The average of these two is the <span class="smallcaps-auto">SSA</span> score. The results below demonstrate that Meena does much better than existing state-of-the-art chatbots by large margins in terms of <span class="smallcaps-auto">SSA</span> scores, and is closing the gap with human performance.</p><p><strong>Automatic Metric: Perplexity</strong></p><p>Researchers have long sought for an automatic evaluation metric that correlates with more accurate, human evaluation. Doing so would enable faster development of dialogue models, but to date, finding such an automatic metric has been challenging. Surprisingly, in our work, we discover that perplexity, an automatic metric that is readily available to any neural seq2seq model, exhibits a strong correlation with human evaluation, such as the <span class="smallcaps-auto">SSA</span> value. Perplexity measures the uncertainty of a language model. The lower the perplexity, the more confident the model is in generating the next token (character, subword, or word). Conceptually, perplexity represents the number of choices the model is trying to choose from when producing the next token.</p><p>During development, we benchmarked eight different model versions with varying hyperparameters and architectures, such as the number of layers, attention heads, total training steps, whether we use Evolved Transformer or regular Transformer, and whether we train with hard labels or with distillation. As illustrated in the figure below, the lower the perplexity, the better the <span class="smallcaps-auto">SSA</span> score for the model, with a strong correlation coefficient (R<sup>2</sup> = 0.93)… As advocated previously, we will continue our goal of lowering the perplexity of neural conversational models through improvements in algorithms, architectures, data, and compute.</p>'
- - /docs/japanese/2005-kanda.pdf
  - 'Behind the Sensationalism: Images of a Decaying Corpse in Japanese Buddhist Art'
  - Fusae Kanda
  - '2005'
  - '10.1080/00043079.2005.10786227'
  - ! '<p>The <a href="https://ja.wikipedia.org/wiki/%E4%B9%9D%E7%9B%B8%E5%9B%B3"><em>kusözu</em></a>, “painting of the nine stages of a decaying corpse,” portrays the sequential decay of a female cadaver in graphic detail. The shocking subject, rooted in Buddhist devotional practices, was regularly painted and reinterpreted during half a millennium of Japanese art. The images of a decaying corpse were charged with contextualized functionalities that have gone unrecognized in current scholarship. Through an examination of four major exemplars of the genre, this study shows how new meanings of the image were catalyzed by religious and social transformations.</p> <p>The <em>kusozu</em>, "painting of the nine stages of a decaying corpse" (hereafter, painting of the nine stages), was executed in Japan from approximately the thirteenth through the nineteenth centuries in various formats, including handscrolls, hanging scrolls, and printed books. The subject itself is derived from a traditional Buddhist doctrine that urges contemplation on the nine stages of a decaying corpse (<em>kusokan</em>, hereafter, contemplation on the nine stages). The teaching dates to the early fifth century and promotes a systematic meditation on the impurity of a decaying corpse as an aid to ardent devotees who wish to liberate themselves from sensual desires and affections.</p> <p>This paper explores unrecognized features of the paintings of the nine stages as they appear through almost half a millennium of Japanese art. We will see that these narrative paintings functioned as distinct visual agents for audiences in different eras. The functionality of the image shifted from a meditative focus for pietistic catharsis, to a didactic incentive for the pursuit of paradise, to an intercessory offering for the dead at merit transferal rites, to a popularized platform for politically manipulated precepts on feminine morality. After giving the textual and theological background for the nine stages of a decaying corpse, I will examine four images of the nine stages from different centuries, which I term the Nakamura, Raigoji, Dainenbutsuji, and Akagi versions. Finally, some remarks are offered on the enduring vitality of this sensational subject.</p>'
- - https://strangeremains.com/2014/06/24/body-of-a-courtesan-in-nine-stages-a-19th-century-study-of-decomposition/
  - '"Body of a courtesan in nine stages": A 19<sup>th</sup> century study of decomposition'
  - Strange Remains
  - 2014-06-24
  - ''
  - ! '<p>“Body of a Courtesan in Nine Stages” was painted on handscroll by Japanese artist Kobayashi Eitaku in the 1870’s. It’s not unusual for artists to study corpses and body parts because of their need to learn about the human form, and because of the historical connection between the science of anatomy and artistic illustration. What makes this style unique is that it’s part of a Japanese artistic tradition devoted specifically to the study of human postmortem changes that stretches back hundreds of years.</p><p>“Body of a Courtesan in Nine Stages” is an example of kusozu, the illustration of a decomposing corpse, that was popular in Japanese art from about the 13th to 19<sup>th</sup> centuries…Though the painting maybe religious and/or scientific in nature, according to the British Museum it also has erotic themes. Because the subject matter is a courtesan, the curator notes for this piece at the British Museum say that this handscroll also falls into the genre of erotic art, or <em>shunga</em>. The word <em>shunga</em> means ‘picture of spring’ in Japanese. The word “spring” is a common synonym for sex. Below are all 9 panels. All images come from The British Museum.</p>'
- - https://strangeremains.com/2015/03/06/the-beauty-of-decomposition-in-japanese-watercolor/
  - "The beauty of human decomposition in Japanese watercolor"
  - Strange Remains
  - 2015-03-06
  - ''
  - ! '<p>I think I might be obsessed with <em>kusozu</em>, Japanese watercolor paintings that graphically depict human decomposition, which were popular between the 13th and 19<sup>th</sup> centuries; “Body of a Courtesan in Nine Stages” is another series in this genre featured previously on this site. Kusozu works of art were inspired by Buddhist beliefs and these paintings were meant to encourage people to ponder the temporary nature of the physical world. Kusozu watercolors also happen to be fantastic early studies of human decay and taphonomy, which is why one series, titled <em>Kusozu: the death of a noble lady and the decay of her body</em>, is currently on display as part of the “Forensics: The Anatomy of Crime” exhibit in London.</p><p>According to the Wellcome Collection, <em>Kusozu: the death of a noble lady and the decay of her body</em> was painted some time in the 18<sup>th</sup> century. The below scenes include: (1) the woman’s impending death and her preparation for it; (2) the noble woman has just passed away and her loved ones are seated around her; (3) slight skin discoloration (maybe some liver mortis) and a bit of bloating of during early decomposition; (4) the onset of putrefaction with bloating and marbling; (5) advanced decomposition as seen by pervasive marbling, leakage of purge fluid from the mouth, and the abdominal cavity has burst open (6) caving of abdominal cavity and scavenging animals; (7) start of skeletonization and the disappearance of soft tissue; (8) complete skeletonization and scattering of remains; (9) finally human remains have been completely scattered or consumed by unseen animals so all that remains is a memorial for the deceased woman.</p>'
- - https://www.goodreads.com/review/show/2671118186
  - "Review of 'The Cultural Revolution: A People's History, 1962-1976' by Frank Dikötter"
  - Gwern Branwen
  - 2019-01-14
  - ''
  - ! "Dikötter's history of the Cultural Revolution offers a broad overview of the multiple failures and follies of Maoism, which culminated in some of the most destructive and disastrous events in human history: the Cultural Revolution, the Great Leap Forward, and the Third Front. The Cultural Revolution was not prompted by any extraordinary famine, or invasion or genuine threat of invasion, or civil war, or disaster of any kind. How then could it have happened? The Cultural Revolution was sponsored by Mao as a way to purge the middle and upper ranks of the Communist Party of doubters, who might do to him what the Soviets had just done to Stalin: reveal his monstrous crimes to the world. But Mao didn't realize the forces he unleashed. Maoism had benefited from taking credit for post-<span class=\"smallcaps-auto\">WWII</span> recovery and the defeat of Japan, but the more its policies were implemented and it tightened its grip, the greater the gap between its utopian promises and the grim impoverished Chinese reality became. Because its theories were radically and systematically wrong, any honest attempt to implement them was doomed to fail, and anyone pragmatic would necessarily betray the system. Old systems and 'inequities' reasserted themselves, to the frustration of true believers. The only ideologically-permissible explanations were excuses like saboteurs and spies and corrupt officials. Usually kept in check, when given Mao's imprimatur and active egging on, mass social resentment and ideological frustration boiled over, leading to a frenzy of virtue-signaling, denunciations, preference falsification spirals, murders, cannibalism, and eventually outright civil war and pandemic. Finally, Mao decided enough purging had happened and his position was secure, and brought it to an end. As strange and awful as it was, the Cultural Revolution offers food for thought on how politics can go viciously wrong, and dangerous aspects of human psychology."
- - https://avmajournals.avma.org/doi/pdfplus/10.2460/javma.239.10.1311
  - Executive summary of phase 2 of the Bayer veterinary care usage study
  - John O. Volk, Karen E. Felsted, James G. Thomas, Colin W. Siren
  - 2011-11-15
  - 10.2460/javma.239.10.1311
  - ! '<p>Research conducted by Bayer Animal Health in cooperation with Brakke Consulting Incorporated and the National Commission on Veterinary Economic Issues and published earlier this year<sup>1</sup> identified 6 key factors that have contributed to a 10-year-long decline in patient visits to veterinary practices. The 6 factors were fragmentation of veterinary services, with more points of care and a wider variety of veterinary services available to pet owners; increased use of the Web by pet owners to obtain information regarding pet health issues, rather than calling or visiting a veterinarian; the negative impact of the economic recession of 2007 to 2009 on spending for veterinary services, which exacerbated an existing issue; inadequate understanding of the need for routine examinations on the part of pet owners; the cost of veterinary care; and feline resistance (ie, many cat owners have deferred taking their cat to the veterinarian because the cat aggressively resisted being put in a carrier for transport to the veterinary clinic and showed signs of stress during veterinary visits). The findings were based on interviews with pet owners and veterinarians and a national online survey of 2,188 US dog and cat owners.</p><p>The second phase of the Bayer veterinary care usage study was a national study of companion animal practice owners. The objectives were to measure visit trends and their impact at the practice level, confirm the findings of the first phase, measure current use or interest in use by veterinarians of certain service concepts identified in the first phase of the study that could potentially motivate pet owners to visit their veterinarian more often, identify factors common to practices that had had an increase in the number of pet visits, and identify opportunities for building patient traffic.</p><p>…<strong>Feline resistance</strong>—According to the <span class="smallcaps-auto">AVMA</span>,2 there are approximately 13% more cats than dogs in the United States. Yet respondents indicated that dogs represented 59% of their patients and cats 39%. 70% of respondents agreed that cat owners seemed more reluctant than dog owners to schedule visits to the practice. Although most (84%) respondents said that they provided training to all staff members on cats and their care, only 33% said they provided instructions to cat owners on how to make travel to the clinic less stressful. In the first phase of the study, 58% of cat owners said their pet “hated” going to the veterinarian, and during interviews, cat owners said that getting the cat into the carrier and taking it to the clinic were the greatest obstacles to visiting the veterinarian.<sup>1</sup></p>'
- - /docs/catnip/2014-volk.pdf
  - Executive summary of phase 3 of the Bayer veterinary care usage study
  - John O. Volk, James G. Thomas, Elizabeth J. Colleran, Colin W. Siren
  - 2014-04-01
  - 10.2460/javma.244.7.799
  - ! '<p>The annual number of feline visits to veterinarians decreased 14% from 2001 to 2011, according to the <em>2012 US Pet Ownership and Demographics Sourcebook</em> published by the <span class="smallcaps-auto">AVMA</span>, despite an increase in the cat population during that period.<sup>1</sup> Earlier research conducted by Bayer Healthcare Animal Health in cooperation with Brakke Consulting Inc and the National Commission on Veterinary Economic Issues (<span class="smallcaps-auto">NCVEI</span>) showed that feline resistance to carriers and transportation was a formidable obstacle for many cat owners in taking their pet to the veterinarian.<sup>2</sup></p><p>To probe more deeply into why cats are not taken to the veterinarian more often and to determine what veterinarians can do to improve feline medical care, Bayer and Brakke collaborated with the American Association of Feline Practitioners (<span class="smallcaps-auto">AAFP</span>) to examine the issue more closely. Bayer, Brakke, and the <span class="smallcaps-auto">AAFP</span> conducted focus group sessions as well as nationally representative surveys with cat owners and veterinarians.</p><p>…Four major reasons cat owners did not take their cats to the veterinarian for routine annual examinations were identified: lack of knowledge, feline resistance to pet carriers and travel, stressful experiences in the veterinary hospital, and cost.</p><p>Unlike the situation for dogs, most cats were acquired for free and without forethought. Many were gifts from family or friends or simply strays that showed up on the doorstep. Consequently, most cat owners received little or no initial instruction on proper veterinary care for their new pet. Only 48% of cat owners surveyed had taken their cat to the veterinarian within the preceding year. Many (37%) did not recall their veterinarian ever recommending annual examinations. Further, owners perceived that indoor cats were less likely to get sick and were unaware that cats are adept at hiding signs of illness or injury. The first phase of the Bayer veterinary care usage study<sup>2</sup> established that feline resistance to pet carriers and travel was a major obstacle to veterinary visits. During focus group sessions conducted for the present phase of the study, cat owners were asked to make collages demonstrating what taking their cat to the veterinarian is like. Most of the collages used pictures from horror films and other sources that reflected a terrible and stressful experience for the cat and owner. Yet, only 18% of cat owners surveyed said they had received any instruction from their veterinarian on how to make bringing the cat to the hospital less stressful.</p><p>Once the owner dealt with getting the cat to the veterinary practice, the stress did not end there. More than half of cat owners (57%) were less than completely satisfied with waiting room comfort for their cats, and nearly the same percentage were less than completely satisfied with waiting room comfort for themselves. It was clear from the focus group sessions that for most owners, a veterinary visit was something to be dreaded and endured.</p><p>Finally, when asked how satisfied they were with their veterinary experience, cat owners were least satisfied with the value obtained for the money they spent, with 59% rating this factor lowest in satisfaction. When asked which items on a list of 16 concepts would motivate them to take their cat to the veterinarian more often, the top 3 items were cost related: a coupon for 50% off the cost of a veterinary visit (50% of respondents), a low-cost preventive care plan paid monthly (40%), and a 20% discount for multiple pets if brought in within a 30-day period (30%). The cost issue was all the more important because many owners indicated during focus group sessions that they had cats primarily because they perceived cats as low-cost pets.</p><p>…Many veterinarians recognized that transporting cats to the veterinary hospital was a major obstacle; however, most had not taken action to address the issue. Only 24% of respondents to the veterinary survey said they always (3%) or often (21%) provided specific instructions to clients on making the visit less stressful. However, 41% of veterinarians said they had made changes to reduce feline stress within their practice, and 70% had conducted some type of staff training.</p><p>…59% of respondents to the cat owner survey agreed with the statement that “I didn’t necessarily find the cat, the cat found me.”</p><p>… In focus group discussions, cat owners were generally incredulous when told that their cat could be sick without them knowing it because cats are adept at hiding signs of illness. In the quantitative survey, only 70% of cat owners said they believed the following statement: “Cats have the ability to endure pain and suffering without any outward signs and could be sick without your knowing about it unless it has periodic checkups at the veterinarian.” Interestingly, this statement scored the lowest (in terms of percentage of owners who believed the statement) of 6 truthful statements about cat health.</p>'
- - https://fantasticanachronism.com/2020/01/17/having-had-no-predecessor-to-imitate/index.html
  - "Having Had No Predecessor to Imitate, He Had No Successor Capable of Imitating Him"
  - Alvaro de Menard
  - 2020-01-17
  - ''
  - ! '<p>Summary of the <a href="https://en.wikipedia.org/wiki/Homeric_Question">Homeric Question</a> that gripped Western classical literary scholarship for centuries: who wrote the <em>Iliad</em>/<em>Odyssey</em>, when, and how? They appear in Greek history out of nowhere: 2 enormously lengthy, sophisticated, beautiful, canonical, unified works that would dominate Western literature for millennia, and yet, appeared to draw on no earlier tradition nor Homer have any earlier works. How was this possible?</p><p>The iconoclastic Analysts proposed it was a fraud, and the works were pieced together later out of scraps from many earlier poets. The Unitarians pointed to the overall quality, the complex (apparently planned) structure and the inability of Analysts to agree with each other on what parts were what pieces or explain anomalies like not just passages splicing together Greek dialects but passages which were metrical only given long-obsolete Greek letters/pronunciations/words/ or even individual <em>words</em> mixing up Greek dialects (not that that was all that much easier to explain by the hypothesis of a single author).</p><p>The eventual resolution relied an old hypothesis: that Homer was in fact the product of a lost oral tradition. There was, unfortunately, no particular evidence for it, and so it never made any headway against the Analysts or Unitarians—until Milman Parry found a living oral tradition of epic poetry in the Balkans, and discovered in it all the signs of the Homeric poems, from repetitive epithets to a patchwork of dialects, and thus empirical examples of how long oral traditions could produce a work like Homer if one of them happened to get written down at some point.</p>'
- - /docs/borges/1932-borges-thehomericversions.pdf
  - The Homeric Versions
  - Jorge Luis Borges
  - '1932'
  - ''
  - ! '[6pg Borges essay on the literary merits of different translations of Homer and the problems of translation: the Newman-Arnold debate encapsulates the basic problem of literality vs literary. Borges gives translations of one passage by Buckley, Butcher & Lang, Cowper, Pope, Chapman, and Butler. Which is best? See also Borges 1936, <a href="/docs/borges/1936-borges-thetranslatorsofthethousandandonenights.pdf">"The Translators of the Thousand and One Nights"</a>, a much more extended discussion of different translations of a work.]'
- - /docs/borges/1936-borges-thetranslatorsofthethousandandonenights.pdf
  - 'The Translators of <em>The Thousand and One Nights</em>'
  - Jorge Luis Borges
  - '1936'
  - ''
  - ! '<p>[18pg Borges essay on translations of the collection of Arab fairytales <a href="https://en.wikipedia.org/wiki/The_Book_of_the_Thousand_Nights_and_a_Night"><em>The Thousand and One Nights</em></a>: each translator—<a href="https://en.wikipedia.org/wiki/Antoine_Galland">Galland</a>, <a href="https://en.wikipedia.org/wiki/Edward_William_Lane">Lane</a>, <a href="https://en.wikipedia.org/wiki/Richard_Francis_Burton">Burton</a>, <a href="https://en.wikipedia.org/wiki/Enno_Littmann">Littmann</a>, <a href="https://en.wikipedia.org/wiki/J._C._Mardrus">Mardrus</a>—criticized the previous translator by creation.]</p><p>At Trieste, in 1872, in a palace with damp statues and deficient hygienic facilities, a gentleman on whose face an African scar told its tale-Captain Richard Francis Burton, the English consul-embarked on a famous translation of the <em>Quitab alif laila ua laila</em>, which the <em>roumis</em> know by the title <em>The Thousand and One Nights</em>. One of the secret aims of his work was the annihilation of another gentleman (also weather-beaten, and with a dark and Moorish beard) who was compiling a vast dictionary in England and who died long before he was annihilated by Burton. That gentleman was Edward Lane, the Orientalist, author of a highly scrupulous version of <em>The Thousand and One Nights</em> that had supplanted a version by Galland. Lane translated against Galland, Burton against Lane; to understand Burton we must understand this hostile dynasty.</p>'
- - https://psyarxiv.com/rpgea/
  - "Can You Ever Be Too Smart for Your Own Good? Linear and Nonlinear Effects of Cognitive Ability"
  - Matt Brown, Jonathan Wai, Christopher Chabris
  - 2020-01-30
  - 10.31234/osf.io/rpgea
  - ! '<p>Despite a longstanding expert consensus about the importance of cognitive ability for life outcomes, contrary views continue to proliferate in scholarly and popular literature. This divergence of beliefs among researchers, practitioners, and the general public presents an obstacle for evidence-based policy and decision-making in a variety of settings. One commonly held idea is that greater cognitive ability does not matter or is actually harmful beyond a certain point (sometimes stated as either 100 or 120 IQ points). We empirically test these notions using data from four longitudinal, representative cohort studies comprising a total of 48,558 participants in the U.S. and U.K. from 1957 to the present. We find that cognitive ability measured in youth has a positive association with most occupational, educational, health, and social outcomes later in life. Most effects were characterized by a moderate-to-strong linear trend or a practically null effect (mean R<sup>2</sup> = .002 to .256). Although we detected several nonlinear effects, they were small in magnitude (mean incremental R<sup>2</sup> = .001). We found no support for any detrimental effects of cognitive ability and no evidence for a threshold beyond which greater scores cease to be beneficial. Thus, greater cognitive ability is generally advantageous—and virtually never detrimental.</p>'
- - /docs/psychology/2011-mccarthyjones.pdf
  - 'The varieties of inner speech: Links between quality of inner speech and psychopathological variables in a sample of young adults'
  - Simon McCarthy-Jones, Charles Fernyhough
  - 2011-12
  - 10.1016/j.concog.2011.08.005
  - ! '<p><em>Highlights</em>:</p><ul><li>We develop a questionnaire to assess a number of qualities of inner speech.</li><li>We examine its correlations with psychopathology in young adults.</li><li>The inner speech questionnaire was found to have satisfactory psychometrics.</li><li>Anxiety, but not depression, correlated with specific varieties of inner speech.</li><li>Proneness to auditory hallucinations correlated with levels of dialogic inner speech.</li></ul><p><em>Abstract</em>: A resurgence of interest in inner speech as a core feature of human experience has not yet coincided with methodological progress in the empirical study of the phenomenon. The present article reports the development and psychometric validation of a novel instrument, the Varieties of Inner Speech Questionnaire (<span class=\"smallcaps-auto\">VISQ</span>), designed to assess the phenomenological properties of inner speech along dimensions of dialogicality, condensed/expanded quality, evaluative/motivational nature, and the extent to which inner speech incorporates other people’s voices. In response to findings that some forms of psychopathology may relate to inner speech, anxiety, depression, and proneness to auditory and visual hallucinations were also assessed. Anxiety, but not depression, was found to be uniquely positively related to both evaluative/motivational inner speech and the presence of other voices in inner speech. Only dialogic inner speech predicted auditory hallucination-proneness, with no inner speech variables predicting levels of visual hallucinations/disturbances. Directions for future research are discussed. [Keywords: Anxiety, Auditory hallucination, Cognitive behavioral therapy, Depression, Dialogic, Inner speech, Rumination, Vygotsky]</p>'
- - https://www.fast.ai/2019/05/03/decrappify/
  - 'No<span class=\"smallcaps-auto\">GAN</span>: Decrappification, DeOldification, and Super Resolution'
  - Jason Antic (Deoldify), Jeremy Howard (fast.ai), Uri Manor (Salk Institute)
  - 2019-05-03
  - ''
  - ! '<p>Generative models are models that generate music, images, text, and other complex data types. In recent years generative models have advanced at an astonishing rate, largely due to deep learning, and particularly due to generative adversarial models (<span class="smallcaps-auto">GAN</span>s). However, <span class="smallcaps-auto">GAN</span>s are notoriously difficult to train, due to requiring a large amount of data, needing many <span class="smallcaps-auto">GPU</span>s and a lot of time to train, and being highly sensitive to minor hyperparameter changes.</p><p>fast.ai has been working in recent years towards making a range of models easier and faster to train, with a particular focus on using transfer learning. Transfer learning refers to pre-training a model using readily available data and quick and easy to calculate loss functions, and then fine-tuning that model for a task that may have fewer labels, or be more expensive to compute. This seemed like a potential solution to the <span class="smallcaps-auto">GAN</span> training problem, so in late 2018 fast.ai worked on a <a href="https://course.fast.ai/videos/?lesson=7">transfer learning technique for generative modeling</a>.</p><p>The pre-trained model that fast.ai selected was this: Start with an image dataset and “crappify” the images, such as reducing the resolution, adding jpeg artifacts, and obscuring parts with random text. Then train a model to “decrappify” those images to return them to their original state. fast.ai started with a model that was pre-trained for ImageNet classification, and added a U-Net upsampling network, adding various modern tweaks to the regular U-Net. A simple fast loss function was initially used: mean squared pixel error. This U-Net could be trained in just a few minutes. Then, the loss function was replaced was a combination of other loss functions used in the generative modeling literature (more details in the f8 video) and trained for another couple of hours. The plan was then to finally add a <span class="smallcaps-auto">GAN</span> for the last few epochs—however it turned out that the results were so good that fast.ai ended up not using a <span class="smallcaps-auto">GAN</span> for the final models. …</p><h4 id="nogan-training">No<span class="smallcaps-auto">GAN</span> Training</h4><p>No<span class="smallcaps-auto">GAN</span> is a new and exciting technique in <span class="smallcaps-auto">GAN</span> training that we developed, in pursuit of higher quality and more stable renders. How, and <em>how well</em>, it works is a bit surprising.</p><p>Here is the No<span class="smallcaps-auto">GAN</span> training process:</p><ol><li><p><strong>Pretrain the Generator.</strong> The generator is first trained in a more conventional and easier to control manner—with Perceptual Loss (aka Feature Loss) by itself. <span class="smallcaps-auto">GAN</span> training is not introduced yet. At this point you’re training the generator as best as you can in the easiest way possible. This takes up most of the time in No<span class="smallcaps-auto">GAN</span> training. Keep in mind: this pretraining by itself will get the generator model far. Colorization will be well-trained as a task, albeit the colors will tend toward dull tones. Self-Attention will also be well-trained at the at this stage, which is very important.</p></li><li><p><strong>Save Generated Images From Pretrained Generator.</strong></p></li><li><p><strong>Pretrain the Critic as a Binary Classifier.</strong> Much like in pretraining the generator, what we aim to achieve in this step is to get as much training as possible for the critic in a more “conventional” manner which is easier to control. And there’s nothing easier than a binary classifier! Here we’re training the critic as a binary classifier of real and fake images, with the fake images being those saved in the previous step. A helpful thing to keep in mind here is that you can simply use a pre-trained critic used for another image-to-image task and refine it. This has already been done for super-resolution, where the critic’s pretrained weights were loaded from that of a critic trained for colorization. All that is needed to make use of the pre-trained critic in this case is a little fine-tuning.</p></li><li><p><strong>Train Generator and Critic in (Almost) Normal <span class="smallcaps-auto">GAN</span> Setting. Quickly!</strong> This is the surprising part. It turns out that in this pretraining scenario, the critic will rapidly drive adjustments in the generator during <span class="smallcaps-auto">GAN</span> training. This happens during a narrow window of time before an “inflection point” of sorts is hit. After this point, there seems to be little to no benefit in training any further in this manner. In fact, if training is continued after this point, you’ll start seeing artifacts and glitches introduced in renderings.</p></li></ol><p>In the case of DeOldify, training to this point requires iterating through only about 1% to 3% of ImageNet data (or roughly 2600 to 7800 iterations on a batch size of five). This amounts to just around 30–90 minutes of <span class="smallcaps-auto">GAN</span> training, which is in stark contrast to the three to five days of progressively-sized <span class="smallcaps-auto">GAN</span> training that was done previously. Surprisingly, during that short amount of training, the change in the quality of the renderings is dramatic. In fact, this makes up the entirety of <span class="smallcaps-auto">GAN</span> training for the video model. The “artistic” and “stable” models go one step further and repeat the No<span class="smallcaps-auto">GAN</span> training process steps 2–4 until there’s no more apparent benefit (around five repeats).</p><p><em>Note:</em> a small but significant change to this <span class="smallcaps-auto">GAN</span> training that deviates from conventional <span class="smallcaps-auto">GAN</span>s is the use of a loss threshold that must be met by the critic before generator training commences. Until then, the critic continues training to “catch up” in order to be able to provide the generator with constructive gradients. This catch up chiefly takes place at the beginning of <span class="smallcaps-auto">GAN</span> training which immediately follows generator and critic pretraining.</p>'
- - /docs/iq/2020-shaffer.pdf
  - "Forethought and intelligence: How conscientiousness, future planning, and general mental ability predict net worth"
  - Jonathan A. Shaffer
  - 2020-06
  - 10.1016/j.paid.2020.109853
  - ! '<p>This study examined a model in which conscientiousness is related to net worth through its relationship with future planning, and in which general mental ability (<span class="smallcaps-auto">GMA</span>) moderates the effects of future planning on net worth. Data for this study were drawn from 1,135 participants in the National Survey of Midlife Development in the United States. Results from an analysis of conditional indirect effects suggest that conscientiousness shared a positive, indirect association with net worth through its relationship with future planning that was realized only for individuals higher in <span class="smallcaps-auto">GMA</span>. In contrast, conscientiousness had no indirect association with net worth for those low in <span class="smallcaps-auto">GMA</span>. This study helps add to the understanding of how noncognitive (personality) and cognitive (ability) traits affect individual-level economic outcomes and offers an explanation for both <em>how</em> and <em>when</em> conscientiousness influences net worth. These findings may be particularly important given efforts to design interventions that help improve individual financial outcomes.</p>'
- - https://www.nytimes.com/2019/06/20/magazine/judge-judy-tv.html
  - "Judge Judy Is Still Judging You: For more than 20 years, Judith Sheindlin has dominated daytime ratings—by making justice in a complicated world look easy"
  - Jazmine Hughes (New York Times Magazine)
  - 2019-06-20
  - ''
  - ! '<p>[Profile of <a href="https://en.wikipedia.org/wiki/Judy_Sheindlin">Judy Sheindlin</a>, star of the long-running (&gt;23 years) daytime television show <a href="https://en.wikipedia.org/wiki/Judge_Judy"><em>Judge Judy</em></a> where, as an arbitrator, she berates and resolves an endless line of small-claims courts. This article covers her biography as she evolved from an ambitious young Jew in NYC who entered corporate law but left to become a stay-at-home mom and ultimately a reality show star running, after &gt;5000 episodes, a finely-tuned machine for dragnetting cases from across the country, making a fortune from royalties and renewals: her net worth is anywhere up to $400 million.]</p>'
- - https://eev.ee/blog/2020/02/01/old-css-new-css/
  - "Old <span class=\"smallcaps-auto\">CSS</span>, New <span class=\"smallcaps-auto\">CSS</span>"
  - Eevee
  - 2020-02-01
  - ''
  - ! '<p>[Why is web programming so screwed up? A highly-opinionated history of how worse-is-better played out online from 1995 to now, by a programmer who started writing <span class="smallcaps-auto">HTML</span> ~1996 and has seen the evolution of it all up close: <span class="smallcaps-auto">HTML</span> was never designed to support even 1% of the things it is expected to do, requiring gruesome workarounds like tables for positioning anything or using images for rounded corners, and has been constantly extended with ad hoc and poorly-thought-through capabilities, sabotaged further by the exigencies of history like the ‘browser wars’ between Netscape &amp; Microsoft, and then Microsoft simply killing Internet Explorer (IE) development for several years after achieving a near-total global monopoly. With a vast amount of work, <span class="smallcaps-auto">HTML</span>/<span class="smallcaps-auto">CSS</span> can now support many desirable web pages, but the historical legacy continues to live on, in the use of now-obsolete workarounds, features which no one uses, strange inconsistencies &amp; limitations, etc.]</p>'
- - https://www.polygon.com/2020/1/14/21064608/microsoft-kinect-history-rise-and-fall
  - "All the money in the world couldn’t make Kinect happen: For a moment a decade ago, the game industry looked like a very different place"
  - Blake Hester (Polygon)
  - 2020-01-14
  - ''
  - ! '<p>[One of <em>Polygon</em>’s oral histories: this feature chronicles the inception and R&amp;D of the <a href="https://en.wikipedia.org/wiki/Kinect">Kinect</a> motion-tracking device), Microsoft’s bold experiment in revolutionizing UI by shipping scores of millions of units for the XBox, and the gradual fade-out and eventual death. While beloved by many, finding niches in everything from hospitals to nursing homes to research labs to art installations (making the Kinect the Velvet Underground of peripherals?), and powering unique games, it just couldn’t quite find its footing despite selling &gt;10 million units (perhaps a cautionary tale for VR enthusiasts).]</p>'
- - https://www.sciencedirect.com/science/article/pii/S0006322319318141
  - "Childhood Adoption and Mental Health in Adulthood: The Role of Gene-Environment Correlations and Interactions in the UK Biobank"
  - Kelli Lehto, Sara Hägg, Donghao Lu, Robert Karlsson, Nancy L. Pedersen, Miriam A. Mosing
  - 2019-10-31
  - 10.1016/j.biopsych.2019.10.016
  - ! '<p><em>Background</em>: Being adopted early in life, an indicator of exposure to early-life adversity, has been consistently associated with poor mental health outcomes in adulthood. Such associations have largely been attributed to stressful environments, e.g., exposure to trauma, abuse, or neglect. However, mental health is substantially heritable, and genetic influences may contribute to the exposure to childhood adversity, resulting in potential genetic confounding of such associations.</p><p><em>Methods</em>: Here, we explored associations between childhood adoption and mental health–related outcomes in midlife in 243,797 UK Biobank participants (n adopted = 3151). We used linkage disequilibrium score regression and polygenic risk scores for depressive symptoms, schizophrenia, neuroticism, and subjective well-being to address potential genetic confounding (gene-environment correlations) and gene-environment interactions. As outcomes, we explored depressive symptoms, bipolar disorder, neuroticism, loneliness, and mental health–related socioeconomic and psychosocial measures in adoptees compared with non-adopted participants.</p><p><em>Results</em>: Adoptees were slightly worse off on almost all mental, socioeconomic, and psychosocial measures. Each standard deviation increase in polygenic risk for depressive symptoms, schizophrenia, and neuroticism was associated with 6%, 5%, and 6% increase in the odds of being adopted, respectively. Significant genetic correlations between adoption status and depressive symptoms, major depression, and schizophrenia were observed. No evidence for gene-environment interaction between genetic risk and adoption on mental health was found.</p><p><em>Conclusions</em>: The association between childhood adoption and mental health cannot fully be attributed to stressful environments but is partly explained by differences in genetic risk between adoptees and those who have not been adopted (i.e., gene-environment correlation). [Keywords: Childhood adversity, Depressive symptoms, Gene-environment interplay, Neuroticism, Polygenic risk scores, Schizophrenia]</p>'
- - /docs/traffic/2020-bulkan.pdf
  - Modelling Quality of Experience for Online Video Advertisement Insertion
  - Utku Bulkan, Tasos Dagiuklas, Muddesar Iqbal
  - 2020-01-24
  - 10.1109/TBC.2020.2965064
  - ! '<p>The impact of online video advertisement has an evolving and undeniable influence on the success of online video streaming. A successful online video advertisement campaign deployment necessitates: “targeting appropriate marketing audience, determining optimum intervals to insert advertisement, associating the production quality of the content while considering advertisement conceptual features, matching the relevance of advertisement context to the content theme, calculating the applicable number of ads for stitching into the content, and correlating the ratio of advertisement length to total active watch duration”. This paper proposes a novel model for inserting advertisement into online video that considers content and commercial specific properties while optimizing Quality of Experience (QoE) by estimating suitable duration for advertisement, number of splits and content relation. The proposed model has been evaluated in a controlled on-line video test environment so that the success rate of this platform has been compared with the advertisement insertion strategies of technology frontrunners YouTube and Vimeo. In terms of medium and long length online videos, advertisements located within the content provides a better QoE compared to the ones that are located at the beginning of the video. For short length online videos, the general expectation of the audience tends to see the content immediately and any advertisement insertion related delay results in a corresponding customer behavior where 25% tend to quit after 3 seconds and another 25% after 5 seconds.</p>'
- - https://www.politico.com/news/magazine/2019/11/29/penn-station-robert-caro-073564
  - "This Is Why Your Holiday Travel Is Awful: The long, sordid history of New York’s Penn Station shows how progressives have made it too hard for the government to do big things—and why, believe it or not, Robert Caro is to blame"
  - Marc J. Dunkelman (Politico)
  - 2019-11-29
  - ''
  - ! '[Discussion of why infrastructure development is so extraordinarily costly and slow in <span class=\"smallcaps-auto\">NYC</span>: a major part of it is a deliberate creation of a tragedy of the anticommons, where a large number of entities can kill or delay projects for little or no reason. Exemplified by a case study of Penn Station, one of the most heavily-used train/subway stations in the world which is universally acknowledged to have been in desperate need of major renovations for well over 30 years, where sewage recently poured through the ceiling, and yet any major projects seem almost as distant as when discussions first began. Entities ranging from the US Postal Service (jealous of its underused rooms) to Amtrak (financial failure) to untrustworthy real estate developers to preservationist activists (in love with a brick wall) Jim Dolan (owner of Madison Square Garden) to 9/11 (disruption and creating new reasons for US Postal Service intransigence) to the State Senate have all conspired to delay and disrupt any progress.]'
- - https://boingboing.net/2016/06/15/the-fascinating-and-ego-killin.html
  - "The fascinating and ego-killing existence of human wormholes"
  - Ryan Holiday
  - 2016-06-15 (BoingBoing)
  - ''
  - ! '<p>He (<a href="https://en.wikipedia.org/wiki/Joe_Medicine_Crow">Medicine Crow</a>) was a fascinating man, not just for what he did but also for what he represents to us now. He was, to use a phrase <a href="http://kottke.org/12/01/human-wormholes-and-the-great-span">coined by Jason Kottke, a “human wormhole.”</a> His unusual and long live is a reminder to how connected the past and present really are.</p><p>A <a href="http://news.nationalpost.com/news/world/youre-shaking-hands-with-the-19th-century-montana-war-chief-joe-medicine-crow-dies-at-102">curator at the Smithsonian</a> described meeting Medicine Crow as “you’re shaking hands with the 19<sup>th</sup> century.” Which an amazing concept. A few intrepid <a href="https://old.reddit.com/r/AskHistorians/comments/2gex95/what_is_the_smallest_chain_of_handshakes_between/">historians on reddit</a> recently discovered an even more amazing one, calculating that it would take a chain of just six individuals who shook hands with one another to connect Barack Obama to George Washington across the centuries (Obama → Queen Elizabeth II → Herbert Hoover → William H. Taft → Benjamin Harrison → William Henry Harrison → Benjamin Harrison V → George Washington).</p><p>I’ve become fascinated with discovering and tracking some of these reminders. For some time now, I’ve <a href="http://ryanholiday.net/the-notecard-system-the-key-for-remembering-organizing-and-using-everything-you-read/">kept a file of them on 4×6 notecards </a>in my house. My friends and I email these moments to each other as we find them—some absurd (<a href="http://flavorwire.com/415737/5-of-the-most-scandalous-affairs-in-literary-history">Oscar Wilde and Walt Whitman may have hooked up</a>), coincidental (Orson Welles claimed to have been in the Biograph Theater in Chicago where John Dillinger was killed by the <span class="smallcaps-auto">FBI</span>) and some that are so unbelievable that they might just blow your mind (there’s <a href="https://www.youtube.com/watch?v%3DI_iq5yzJ-Dk">a video from a 1956 <span class="smallcaps-auto">CBS</span> game show</a>, <em>I’ve Got a Secret</em>, with a very old guest whose secret was that he was in Ford’s Theatre when Lincoln was assassinated. Appearing with him on the show? Lucille Ball.)</p><p>Here in modern life, it’s easy to think the past is dead and distant, until we bump up against the reality of Faulkner’s admonition that it’s not really even past. England’s government only <a href="http://www.nytimes.com/2014/12/28/world/that-debt-from-1720-britains-payment-is-coming.html">recently paid off debts it incurred as far back as 1720</a> from events like the South Sea Bubble, the Napoleonic wars, the empire’s abolition of slavery, and the Irish potato famine—meaning that for more than a decade and a half of the twenty first century there was still a direct and daily connection to the eighteenth and nineteenth centuries. (The US is <a href="http://www.wsj.com/articles/SB10001424052702303603904579493830954152394">still paying pensions</a> related to both the Civil War and the Spanish-American War.)</p><p>…Did you know that Tom Pratt, a football coach whose team the Arizona Cardinals narrowly missed going to the Super Bowl in 2015, was also on the coaching staff for the Kansas City Chiefs in the very first Super Bowl fifty years ago? Or that there <a href="http://www.smithsonianmag.com/ist/?next%3D/smart-news/there-are-whales-alive-today-who-were-born-before-moby-dick-was-written-660944/">are whales alive today</a> who were born before Melville published Moby Dick? Or <a href="https://en.wikipedia.org/wiki/Jonathan_(tortoise)">the world’s oldest tortoise</a>, Jonathan, lives on an island in the Atlantic and is 183 years old? Or that President John Tyler, born in 1790, who took office just ten years after little Jonathan was born, still has living grandchildren?</p><p>War is perhaps the strangest source of these anomalies. Did you know that Winston Churchill and James Bond creator Ian Fleming’s father fought in the same unit in <span class="smallcaps-auto">WWI</span>? When Fleming’s father was killed, Churchill wrote his obituary. General Simon Bolivar Buckner was a Confederate general in the Civil War (he surrendered to Grant at Fort Donelson). His son Simon Bolivar Buckner Jr also became a General, and he died at Okinawa some 83 years later. General MacArthur—his father, Arthur MacArthur, Jr.—was a Civil War hero for the Union. Stonewall Jackson had a granddaughter who lived to be 104. She died in 1991.</p><p>In high school, a promising young student at the Virginia Military Institute named George Marshall petitioned the president for a military commission. Which President did the creator of the Marshall plan petition? <span class="c3">William McKinley (just months before man’s life was cut short by an assassin’s bullet.) And most unbelievably, what of the fact that Robert Todd Lincoln was present as his father died of assassination, was at the train station with President James Garfield was assassinated, and was in attendance at the event in which McKinley was assassinated? Three assassinations, spread out over 40 years. Robert Todd Lincoln himself lived to be 82, dying in 1926. He could have read stories published by F. Scott Fitzgerald. He drove in a car. He talked on the telephone. He would have heard jazz music.</p><p>And these are just the events of the so called modern history.</p><p>We forget that woolly mammoths walked the earth while the pyramids were being built. We don’t realize that Cleopatra lived closer to our time than she did to the construction of those famous pyramids that marked her kingdom. We forget that Ovid and Jesus were alive at the same time. When British workers excavated the land in Trafalgar Square to build Nelson’s Column and its famous bronze lions, in the ground they found the bones of actual lions, who’d roamed that exact spot just a few thousand years before.</p>'
- - https://www.explainxkcd.com/wiki/index.php/1393:_Timeghost
  - 'Explain <em><span class=\"smallcaps-auto\">XKCD</span></em> #1393: "Timeghost"'
  - Explain <span class=\"smallcaps-auto\">XKCD</span>
  - ''
  - ''
  - ! '<p>[Explanation of <a href="https://www.xkcd.com/1393/"><em><span class="smallcaps-auto">XKCD</span></em> #1393, “Timeghost”</a>:]</p><p>Megan has been haunted by a Timeghost for some time. It is obviously not the first time the ghost arrives to let Megan know that “…ooOOOOOOOOooo… Tiiiime is passiiiing!” The ghost is dedicated to making people feel old by having them think about the passage of time. It is shown to reference time periods related to well-known people and events, such as famous actors and the release of movies and TV shows. Megan is just annoyed that it is back and wishes it to go away…But one thing about the prediction is true—they will eventually die. And this is the scary part about realizing how old you are and that you are quickly getting older: You will die, and “soon” (for some value thereof).</p><p>The comic seems to be using “factoid” to mean a small fact. “Factoid” can also mean a “questionable or spurious statement presented as a fact”, but this does not seem to be intended usage here. In this instance, some of the factoids are easily verifiable, while others are reasonable assumptions based on the number of years passed since the individual events. Several sources advocate the use of the word “factlet” to express a brief interesting fact, while using the word “factoid” for unverifiable or untrue statements passed as fact…“Timeghost” might be a literal interpretation of ‘<em>Zeitgeist</em>’, which is a German term for “spirit of time” and refers to the school of thought that influences or dominates the art and culture of a time period. All the events and people mentioned in this comic may be considered influences on present day art and culture.</p></p><p><p><a href="https://www.explainxkcd.com/wiki/index.php/Randall" title="Randall">Randall</a> has covered making people feel old several times in <a href="https://www.explainxkcd.com/wiki/index.php/647:_Scary" title="647: Scary">647: Scary</a>, <a href="https://www.explainxkcd.com/wiki/index.php/891:_Movie_Ages" title="891: Movie Ages">891: Movie Ages</a>, <a href="https://www.explainxkcd.com/wiki/index.php/973:_MTV_Generation" title="973: MTV Generation">973: <span class="smallcaps-auto">MTV</span> Generation</a> (in which White Hat utters Cueball’s “That can’t be right” line), and <a href="https://www.explainxkcd.com/wiki/index.php/1477:_Star_Wars" title="1477: Star Wars">1477: Star Wars</a>. Also see the blag post <a class="external text" href="https://blog.xkcd.com/2012/09/29/odd-temporal-milestones/">Odd Temporal Milestones</a>. This is, however, so far the only one that makes a prediction of anyone’s death. A similar ghost with a much different agenda was seen in <a href="https://www.explainxkcd.com/wiki/index.php/1108:_Cautionary_Ghost" title="1108: Cautionary Ghost">1108: Cautionary Ghost</a>. Similarly annoying fact(oids) were given in <a href="https://www.explainxkcd.com/wiki/index.php/1272:_Shadowfacts" title="1272: Shadowfacts">1272: Shadowfacts</a>.</p>'
- - https://www.frontiersin.org/articles/10.3389/fpsyg.2020.00074/full
  - "The Psychophysiological Effects of Different Tempo Music on Endurance Versus High-Intensity Performances"
  - Vittoria Maria Patania, Johnny Padulo, Enzo Iuliano, Luca Paolo Ardigò, Dražen Čular, Alen Miletić, Andrea De Giorgio
  - 2020-02-05
  - 10.3389/fpsyg.2020.00074
  - ! '<p>The use of music during training represents a special paradigm for trainers to stimulate people undertaking different types of exercise. However, the relationship between the tempo of music and perception of effort during different metabolic demands is still unclear. Therefore, the aim of this research was to determine whether high intensity exercise is more sensitive to the beneficial effects of music than endurance exercise. This study assessed 19 active women (age 26.4 ± 2.6 years) during endurance (walking for 10′ at 6.5 km/h on a treadmill) and high intensity (80% on 1-RM) exercise under four different randomly assigned conditions: no music (NM), with music at 90–110 bpm (<span class="smallcaps-auto">LOW</span>), with music at 130–150 bpm (<span class="smallcaps-auto">MED</span>), and with music at 170–190 bpm (<span class="smallcaps-auto">HIGH</span>). During each trial, heart rate (HR) and the rating of perceived exertion (<span class="smallcaps-auto">RPE</span>) were assessed. Repeated analysis of variance measures was used to detect any differences between the four conditions during high intensity and low intensity exercise. <span class="smallcaps-auto">RPE</span> showed more substantial changes during the endurance exercises (11%), than during high intensity exercise (6.5%), between <span class="smallcaps-auto">HIGH</span> and NM conditions. The metabolic demand during the walking exercise increased between NM and <span class="smallcaps-auto">HIGH</span> bpm conditions. This study indicates the benefits of music under stress conditions as well as during endurance and high intensity training. The results demonstrate that the beneficial effects of music are more likely to be seen in endurance exercise. Consequently, music may be considered an important tool to stimulate people engaging in low intensity physical exercise.</p>'
- - /docs/psychology/2019-archer.pdf
  - "The reality and evolutionary significance of human psychological sex differences"
  - John Archer
  - 2019-03-20
  - 10.1111/brv.12507
  - ! '<p>The aims of this article are: (1) to provide a quantitative overview of sex differences in human psychological attributes; and (2) to consider evidence for their possible evolutionary origins. Sex differences were identified from a systematic literature search of meta-analyses and large-sample studies. These were organized in terms of evolutionary significance as follows:</p><ol type="1"><li>characteristics arising from inter-male competition (within-sex aggression; impulsiveness and sensation-seeking; fearfulness; visuospatial and object-location memory; object-centred orientations);</li><li>those concerning social relations that are likely to have arisen from women’s adaptations for small-group interactions and men’s for larger co-operative groups (person-centred orientation and social skills; language; depression and anxiety);</li><li>those arising from female choice (sexuality; mate choice; sexual conflict).</li></ol><p>There were sex differences in all categories, whose magnitudes ranged from</p><ol type="1"><li>small (object location memory; negative emotions), to</li><li>medium (mental rotation; anxiety disorders; impulsivity; sex drive; interest in casual sex), to</li><li>large (social interests and abilities; sociosexuality); and</li><li>very large (escalated aggression; systemizing; sexual violence).</li></ol><p>Evolutionary explanations were evaluated according to whether:</p><ol type="1"><li>similar differences occur in other mammals;</li><li>there is cross-cultural consistency;</li><li>the origin was early in life or at puberty;</li><li>there was evidence for hormonal influences; and</li><li>where possible, whether there was evidence for evolutionarily derived design features.</li></ol><p>The evidence was positive for most features in most categories, suggesting evolutionary origins for a broad range of sex differences. Attributes for which there was no sex difference are also noted. Within-sex variations are discussed as limitations to the emphasis on sex differences.</p>'
- - https://www.wired.com/story/secret-history-facial-recognition/
  - "The Secret History of Facial Recognition: Sixty years ago, a sharecropper’s son invented a technology to identify faces. Then the record of his role all but vanished. Who was Woody Bledsoe, and who was he working for?"
  - Shaun Raviv (Wired)
  - 2020-01-21
  - ''
  - ! '<p>Over the following year, Woody came to believe that the most promising path to automated facial recognition was one that reduced a face to a set of relationships between its major landmarks: eyes, ears, nose, eyebrows, lips. The system that he imagined was similar to one that Alphonse Bertillon, the French criminologist who invented the modern mug shot, had pioneered in 1879. Bertillon described people on the basis of 11 physical measurements, including the length of the left foot and the length from the elbow to the end of the middle finger. The idea was that, if you took enough measurements, every person was unique. Although the system was labor-intensive, it worked: In 1897, years before fingerprinting became widespread, French gendarmes used it to identify the serial killer Joseph Vacher. Throughout 1965, Panoramic attempted to create a fully automated Bertillon system for the face. The team tried to devise a program that could locate noses, lips, and the like by parsing patterns of lightness and darkness in a photograph, but the effort was mostly a flop.</p><p>…Even with this larger sample size, though, Woody’s team struggled to overcome all the usual obstacles. The computer still had trouble with smiles, for instance, which “distort the face and drastically change inter-facial measurements.” Aging remained a problem too, as Woody’s own face proved. When asked to cross-match a photo of Woody from 1945 with one from 1965, the computer was flummoxed. It saw little resemblance between the younger man, with his toothy smile and dark widow’s peak, and the older one, with his grim expression and thinning hair. It was as if the decades had created a different person.</p><p>…In 1967, more than a year after his move to Austin, Woody took on one last assignment that involved recognizing patterns in the human face. The purpose of the experiment was to help law enforcement agencies quickly sift through databases of mug shots and portraits, looking for matches…Woody’s main collaborator on the project was Peter Hart, a research engineer in the Applied Physics Laboratory at the Stanford Research Institute. (Now known as <span class=\"smallcaps-auto\">SRI</span> International, the institute split from Stanford University in 1970 because its heavy reliance on military funding had become so controversial on campus.) Woody and Hart began with a database of around 800 images—two newsprint-quality photos each of about “400 adult male caucasians,” varying in age and head rotation. (I did not see images of women or people of color, or references to them, in any of Woody’s facial-recognition studies.) Using the <span class=\"smallcaps-auto\">RAND</span> tablet, they recorded 46 coordinates per photo, including five on each ear, seven on the nose, and four on each eyebrow. Building on Woody’s earlier experience at normalizing variations in images, they used a mathematical equation to rotate each head into a forward-looking position. Then, to account for differences in scale, they enlarged or reduced each image to a standard size, with the distance between the pupils as their anchor metric. The computer’s task was to memorize one version of each face and use it to identify the other. Woody and Hart offered the machine one of two shortcuts. With the first, known as group matching, the computer would divide the face into features—left eyebrow, right ear, and so on—and compare the relative distances between them. The second approach relied on Bayesian decision theory; it used 22 measurements to make an educated guess about the whole.</p><p>In the end, the two programs handled the task about equally well. More important, they blew their human competitors out of the water. When Woody and Hart asked three people to cross-match subsets of 100 faces, even the fastest one took six hours to finish. The <span class=\"smallcaps-auto\">CDC</span> 3800 computer completed a similar task in about three minutes, reaching a hundredfold reduction in time. The humans were better at coping with head rotation and poor photographic quality, Woody and Hart acknowledged, but the computer was “vastly superior” at tolerating the differences caused by aging. Overall, they concluded, the machine “dominates” or “very nearly dominates” the humans.</p><p>This was the greatest success Woody ever had with his facial-recognition research. It was also the last paper he would write on the subject. The paper was never made public—for “government reasons,” Hart says—which both men lamented. In 1970, two years after the collaboration with Hart ended, a roboticist named Michael Kassler alerted Woody to a facial-recognition study that Leon Harmon at Bell Labs was planning. “I’m irked that this second rate study will now be published and appear to be the best man-machine system available,” Woody replied. “It sounds to me like Leon, if he works hard, will be almost 10 years behind us by 1975.” He must have been frustrated when Harmon’s research made the cover of <em>Scientific American</em> a few years later, while his own, more advanced work was essentially kept in a vault.</p>'
- - /docs/statistics/bayes/2008-kesselman.pdf
  - "Verbal Probability Expressions In National Intelligence Estimates: A Comprehensive Analysis Of Trends From The Fifties Through Post 9/11"
  - Rachel F. Kesselman
  - 2008-05
  - ''
  - ! '<p>This research presents the findings of a study that analyzed words of estimators probability in the key judgments of National Intelligence Estimates from the 1950s through the 2000s. The research found that of the 50 words examined, only 13 were statistically significant. Furthermore, interesting trends have emerged when the words are broken down into English modals, terminology that conveys analytical assessments and words employed by the National Intelligence Council as of 2006. One of the more intriguing findings is that use of the word <em>will</em> has by far been the most popular for analysts, registering over 700 occurrences throughout the decades; however, a word of such certainty is problematic in the sense that intelligence should never deal with 100% certitude. The relatively low occurrence and wide variety of word usage across the decades demonstrates a real lack of consistency in the way analysts have been conveying assessments over the past 58 years. Finally, the researcher suggests the <em>Kesselman List of Estimative Words</em> for use in the IC. The word list takes into account the literature review findings as well as the results of this study in equating odds with verbal probabilities.</p><p>[Rachel’s lit review, for example, makes for very interesting reading. She has done a thorough search of not only the intelligence but also the business, linguistics and other literatures in order to find out how other disciplines have dealt with the problem of “What do we mean when we say something is ‘likely’…” She uncovered, for example, that, in medicine, words of estimative probability such as “likely”, “remote” and “probably” have taken on more or less fixed meanings due primarily to outside intervention or, as she put it, “legal ramifications”. Her comparative analysis of the results and approaches taken by these other disciplines is required reading for anyone in the Intelligence Community trying to understand how verbal expressions of probability are actually interpreted. The <span class="smallcaps-auto">NIC</span>s list only became final in the last several years so it is arguable whether this list of nine words really captures the breadth of estimative word usage across the decades. Rather, it would be arguable if this chart didn’t make it crystal clear that the Intelligence Community has really relied on just two words, “probably” and “likely” to express its estimates of probabilities for the last 60 years. All other words are used rarely or not at all.</p><p>Based on her research of what works and what doesn’t and which words seem to have the most consistent meanings to users, Rachel even offers her own list of estimative words along with their associated probabilities:</p><ol type="1"><li>Almost certain: 86–99%</li><li>Highly likely: 71–85%</li><li>Likely: 56–70%</li><li>Chances a little better [or less] than even: 46–55%</li><li>Unlikely: 31–45%</li><li>Highly unlikely: 16–30%</li><li>Remote: 1–15%</li></ol><p>]</p>'
- - https://html.spec.whatwg.org/multipage/text-level-semantics.html#the-ruby-element
  - "<span class=\"smallcaps-auto\">HTML</span> Living Standard: Text-level semantics: 4.5.10: The <code>ruby</code> element"
  - WhatWG
  - 2020-01-29
  - ''
  - ! '<p>The <strong>ruby</strong> element allows one or more spans of phrasing content to be marked with ruby annotations. Ruby annotations are short runs of text presented alongside base text, primarily used in East Asian typography as a guide for pronunciation or to include other annotations. In Japanese, this form of typography is also known as <em>furigana</em>…The <strong>ruby</strong> and <strong>rt</strong> elements can be used for a variety of kinds of annotations, including in particular (though by no means limited to) those described below. For more details on Japanese Ruby in particular, and how to render Ruby for Japanese, see <em>Requirements for Japanese Text Layout</em>.</p><p>…<em>Note</em>: At the time of writing, <span class="smallcaps-auto">CSS</span> does not yet provide a way to fully control the rendering of the <span class="smallcaps-auto">HTML</span> ruby element. It is hoped that <span class="smallcaps-auto">CSS</span> will be extended to support the styles described below in due course.</p><p>Example: Mono-ruby for individual base characters in Japanese: One or more hiragana or katakana characters (the ruby annotation) are placed with each ideographic character (the base text). This is used to provide readings of kanji characters:</p><pre><code>&lt;ruby&gt;B&lt;rt&gt;annotation&lt;/ruby&gt;</code></pre>'
- - https://en.wiktionary.org/wiki/et_alii
  - "Wiktionary: <em>et alii</em>"
  - Wiktionary
  - 2018-06-18
  - ''
  - ! '<p><strong>Etymology</strong>: From Latin <em>et</em> (“and”) + <em>alii</em> (“others”)</p><p><strong>Phrase</strong>: <em>et alii</em></p><ol type="1"><li><em>And others; used of men or boys, or groups of mixed gender; masculine plural</em></li></ol><p><strong>Usage notes</strong>: In some academic contexts, it may be appropriate to use the specific Latin form that would be used in Latin text, selecting the appropriate grammatical case. The abbreviation <a href="https://en.wiktionary.org/wiki/et_al.">“et al.”</a> finesses the need for such fastidiousness.</p>'
- - http://lesswrong.com/lw/f1/beware_trivial_inconveniences/
  - Beware Trivial Inconveniences
  - Scott Alexander
  - 2009-05-06
  - ''
  - ! '<p>The Great Firewall of China. A massive system of centralized censorship purging the Chinese version of the Internet of all potentially subversive content. Generally agreed to be a great technical achievement and political success even by the vast majority of people who find it morally abhorrent. I spent a few days in China. I got around it at the Internet cafe by using a free online proxy. Actual Chinese people have dozens of ways of getting around it with a minimum of technical knowledge or just the ability to read some instructions.</p><p>The Chinese government isn’t losing any sleep over this (although they also don’t lose any sleep over murdering political dissidents, so maybe they’re just very sound sleepers). Their theory is that by making it a little inconvenient and time-consuming to view subversive sites, they will discourage casual exploration. No one will bother to circumvent it unless they already seriously distrust the Chinese government and are specifically looking for foreign websites, and these people probably know what the foreign websites are going to say anyway.</p><p>Think about this for a second. The human longing for freedom of information is a terrible and wonderful thing. It delineates a pivotal difference between mental emancipation and slavery. It has launched protests, rebellions, and revolutions. Thousands have devoted their lives to it, thousands of others have even died for it. And it can be stopped dead in its tracks by requiring people to search for “how to set up proxy” before viewing their anti-government website.</p><p>…But these trivial inconveniences have major policy implications. Countries like China that want to oppress their citizens are already using “soft” oppression to make it annoyingly difficult to access subversive information. But there are also benefits for governments that want to help their citizens.</p>'
- - /docs/sr/2020-zhou.pdf
  - "A Market in Dream: the Rapid Development of Anonymous Cybercrime"
  - Gengqian Zhou, Jianwei Zhuge, Yunqian Fan, Kun Du, Shuqiang Lu
  - 2020-02-01
  - 10.1007/s11036-019-01440-2
  - ! '<p>In this paper we have conducted a comprehensive measurement and analysis on the Dream market, an anonymous online market that uses cryptocurrency as transaction currency. We first collect data between October 30<sup>th</sup> 2018 and March 1<sup>st</sup> 2019. Then we use decision tree-based approach to classify goods. Following we analyze the category of goods sold in the market, the shipping place of vendors. By analyzing more than 1,970,303 items, we find the goods sold in Dream Market are mainly drugs and digital goods. We estimate the total sales of all vendors, and find that an average monthly income is $14 million during the measurement period, which means that the market commission income is more than $560,000 per month. Based on these data, we use transaction cost theory to analyze the transaction attributes of illegal transactions, which shows that anonymous online market can reduce transaction cost of illegal transactions. We finally discuss the results analyzed and the intervention policy, as well as recent DDoS attacks and future trends of illegal transactions in anonymous online market.</p>'
- - https://publicdomainreview.org/collection/cosmography-manuscript-12th-century
  - "Collections/Images: Cosmography Manuscript (12th Century)"
  - The Public Domain Review
  - 2020-02-07
  - ''
  - ! '<p>This wonderful series of medieval cosmographic diagrams and schemas are sourced from a late 12th-century manuscript created in England. Coming to only nine folios, the manuscript is essentially a scientific textbook for monks, bringing together cosmographical knowledge from a range of early Christian writers such as Bede and Isodere, who themselves based their ideas on such classical sources as Pliny the Elder, though adapting them for their new Christian context. As for the intriguing diagrams themselves, The Walters Art Museum, which holds the manuscript and offers up excellent commentary on its contents, provides the following description:</p><blockquote><p>The twenty complex diagrams that accompany the texts in this pamphlet help illustrate [the ideas], and include visualizations of the heavens and earth, seasons, winds, tides, and the zodiac, as well as demonstrations of how these things relate to man. Most of the diagrams are <em>rotae</em>, or wheel-shaped schemata, favored throughout the Middle Ages for the presentation of scientific and cosmological ideas because they organized complex information in a clear, orderly fashion, making this material easier to apprehend, learn, and remember. Moreover, the circle, considered the most perfect shape and a symbol of God, was seen as conveying the cyclical nature of time and the Creation as well as the logic, order, and harmony of the created universe.</p></blockquote>'
- - https://www.nytimes.com/2019/11/27/magazine/63-up-michael-apted.html
  - "Does Who You Are at 7 Determine Who You Are at 63?: In 1964, with <em>Seven Up!</em> Michael Apted stumbled into making what has become the most profound documentary series in the history of cinema. Fifty-five years later, the project is reaching its conclusion."
  - Gideon Lewis-Kraus (New York Times)
  - 2019-11-27
  - ''
  - ! '<p>[This is a unique and very well-done take on <em>Seven Up</em>. It has the added dimension of how much of a learning process this was for Apted (the director), as well as other aspects that I hadn’t picked up from other sources.</p><p>I first discovered this series a few weeks ago. I found the idea fascinating and I expected to be keen to dig into it. So I read some of the pieces that I found online and I stopped. My expectation of wanting to dive into this living soap opera turned into a feeling of bleak depression. Part of it has something to do with the blandness of even the happiest of near-endings, and part of it has something to do with the sadness of seeing a seven year old quickly progress in age to that point in life when we’re sort of forced to evaluate who and where we are. It was far too quick of a journey for me. Their lives are presented like a history book, that places an emphasis on wars and other human struggles. It’s also similar to a newscast: the bad news overwhelms and the good news is boring, so it doesn’t get much attention. It’s a CV that demands to know “what have you done with your life?” in a series of bullet points that skews toward points of merit.</p><p>I suppose that part of my feeling has to do with the fact that I’m at that point in life myself. Family and peers are getting sick and dying. I’ll be doing the same. A lot of us aren’t mentally prepared for what it’s really like to be here. I think I’ve been working my way through it pretty well, but it takes a lot of emotional and philosophical work that we may not have a lot of experience with.</p><p>For me, <em>Seven Up</em> pokes and prods at life’s battle wounds without enough attention to the boring bits that may actually dominate a life, which might be where our focus needs to be if we’re to attain the contentment that should perhaps be our goal, whatever our class.]</p>'
- - https://thegradient.pub/independently-reproducible-machine-learning/
  - 'Quantifying Independently Reproducible Machine Learning'
  - Edward Raff
  - 2020-02-06
  - ''
  - ! '<p>How reproducible is the latest ML research, and can we begin to quantify what impacts its reproducibility? This question served as motivation for <a href="https://arxiv.org/abs/1909.06674">my Neur<span class="smallcaps-auto">IPS</span> 2019 paper</a>. Based on a combination of masochism and stubbornness, over the past eight years I have attempted to implement various ML algorithms from scratch. This has resulted in a ML library called <a href="https://github.com/EdwardRaff/JSAT"><span class="smallcaps-auto">JSAT</span></a>. My investigation in reproducible ML has also relied on personal notes and records hosted on Mendeley and Github. With these data, and clearly no instinct for preserving my own sanity, I set out to quantify and verify reproducibility! As I soon learned, I would be engaging in meta-science, the study of science itself.</p><p>…Some of the results were unsurprising. For example, the number of authors shouldn’t have any particular importance to a paper’s reproducibility, and it did not have a significant relationship. Hyperparameters are the knobs we can adjust to change an algorithms behavior, but are not learned by the algorithm itself. Instead, we humans must set their values (or devise a clever way to pick them). Whether or not a paper detailed the hyperparameters used was found to be significant, and we can intuit why. If you don’t tell the reader what the settings where, the reader has to guess. That takes work, time, and is error prone! So, some of our results have given credence to the ideas the community has already been pursuing in order to make papers more reproducible. What is important is that we can now quantify why these are good things to be pursuing. Other findings follow basic logic, such as the finding that papers that are easier to read are easier to reproduce, likely because they are easier to understand.</p><ol type="1"><li>…Having fewer equations per page makes a paper more reproducible.</li><li>Empirical papers may be more reproducible than theory-oriented papers.</li><li>Sharing code is not a panacea</li><li>Having detailed pseudo code is just as reproducible as having no pseudo code.</li><li>Creating simplified example problems do not appear to help with reproducibility.</li><li>Please, check your email</li></ol><p>…After completing this effort, my inclination is that there is room for improvement, but that we in the AI/ML field are doing a better job than most disciplines. A 62% success rate is higher than many meta-analyses from other sciences, and I suspect my 62% number is lower than reality…Finally, it has been pointed out to me that I may have created the most un-reproducible ML research ever. But in reality, it leads to a number of issues regarding how we do the science of meta-science, to study how we implement and evaluate our research. With that, I hope I’ve encouraged you to read my paper for further details and discussion. Think about how your own work fits into the larger picture of human knowledge and science. As the avalanche of new AI and ML research continues to grow, our ability to leverage and learn from all this work will be highly dependent on our ability to distill ever more knowledge down to a digestible form. At the same time, our process and systems must result in reproducible work that does not lead us astray. I have more work I would like to do in this space, and I hope you will join me.</p>'
- - /docs/sociology/2020-kalmoe.pdf
  - Uses and Abuses of Ideology in Political Psychology
  - Nathan P. Kalmoe
  - 2020-02-10
  - 10.1111/pops.12650
  - ! '<p>Ideology is a central construct in political psychology. Even so, the field’s strong claims about an ideological public rarely engage evidence of enormous individual differences: a minority with real ideological coherence and weak to nonexistent political belief organization for everyone else. Here, I bridge disciplinary gaps by showing the limits of mass political ideology with several popular measures and components—self-identification, core political values (egalitarian and traditionalism’s resistance to change), and policy indices—in representative U.S. surveys across four decades (<em>N</em>s ~ 13k–37k), plus panel data testing stability. Results show polar, coherent, stable, and potent ideological orientations only among the most knowledgeable 20–30% of citizens. That heterogeneity means full-sample tests overstate ideology for most people but understate it for knowledgeable citizens. Whether through top-down opinion leadership or bottom-up ideological reasoning, organized political belief systems require political attention and understanding to form. Finally, I show that convenience samples make trouble for ideology generalizations. I conclude by proposing analytic best practices to help avoid overclaiming ideology in the public. Taken together, what first looks like strong and broad ideology is actually ideological innocence for most and meaningful ideology for a few.</p>'
- - https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/
  - 'Turing-<span class=\"smallcaps-auto\">NLG</span>: A 17-billion-parameter language model by Microsoft'
  - Corby Rosset (Microsoft)
  - 2020-02-10
  - ''
  - ! '<p><img class="aligncenter wp-image-635634 size-full" src="/images/ai/2020-rosset-turingnlg-nlpmodelparametercountovertime.png" alt="chart (https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788.png)" width="1400" height="788" srcset="https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788.png 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></p><blockquote><p style="text-align: left;"><strong><em>Turing Natural Language Generation (T-<span class=\"smallcaps-auto\">NLG</span>) is a 17 billion parameter language model by Microsoft that outperforms the state of the art on many downstream <span class=\"smallcaps-auto\">NLP</span> tasks. We present a demo of the model, including its freeform generation, question answering, and summarization capabilities, to academics for feedback and research purposes. &lt;|endoftext|&gt;</em></strong></p><p style="text-align: left;">– This summary was generated by the Turing-<span class=\"smallcaps-auto\">NLG</span> language model itself.</p></blockquote><p>…Following the trend that larger natural language models lead to better results, Microsoft is introducing Turing Natural Language Generation (T-<span class=\"smallcaps-auto\">NLG</span>), the largest model ever published at 17 billion parameters, which outperforms the state of the art on a variety of language modeling benchmarks and also excels when applied to numerous practical tasks, including summarization and question answering. This work would not be possible without breakthroughs produced by the <b><a href="https://github.com/microsoft/DeepSpeed">DeepSpeed library</a></b> (compatible with <a href="https://pytorch.org/">PyTorch</a>) and <a href="https://arxiv.org/abs/1910.02054">ZeRO optimizer</a>, which can be explored more in this accompanying <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters">blog post.</a></p>'
- - https://www.newyorker.com/magazine/2020/02/17/was-jeanne-calment-the-oldest-person-who-ever-lived-or-a-fraud
  - 'Was Jeanne Calment the Oldest Person Who Ever Lived—or a Fraud? Some researchers have cast doubt on the record of the celebrated supercentenarian'
  - Lauren Collins (New Yorker)
  - 2020-02-10
  - ''
  - ! '<p>[Probably <em>not</em> a fraud. Summary of the state of Calment centenarian fraud accusations by Novoselov &amp; Zak: the tax fraud theory appears to rest on wildly overestimated tax burden estimates and has been abandoned in favor of covering up a death from tuberculosis which might affect their department store’s revenue, locals insist they or their relatives knew the two Calments too well for a switch, Yvonne’s child would have had to be in on it as well as a local notary, more of Jeanne’s stories about obscure people she knew appear to have been validated, Yvonne’s funeral was highly public, Jeanne’s anomalously tall late-life height appears to have been mis-measured and the real height much lower as expected from her great age, the nose fibroma argument is inconclusive, the photographs are too low-quality for proper forensic analysis, and one anecdote of calling Jeanne ‘Yvonne’ has been recanted. The fraud theory appears to be on very shaky ground now… but the mystery of Jeanne Calment’s longevity remains.]</p>'
- - /docs/melatonin/2020-goldin.pdf
  - 'Interplay of chronotype and school timing predicts school performance'
  - Andrea P. Goldin, Mariano Sigman, Gisela Braier, Diego A. Golombek, María J. Leon
  - 2020-02-10
  - 10.1038/s41562-020-0820-2
  - ! 'Most adolescents exhibit very late chronotypes and attend school early in the morning, a misalignment that can affect their health and psychological well-being. Here we examine how the interaction between the chronotype and school timing of an individual influences academic performance, studying a unique sample of 753 Argentinian students who were randomly assigned to start school in the morning (07:45), afternoon (12:40) or evening (17:20). Although chronotypes tend to align partially with class time, this effect is insufficient to fully account for the differences with school start time. We show that (1) for morning-attending students, early chronotypes perform better than late chronotypes in all school subjects, an effect that is largest for maths; (2) this effect vanishes for students who attend school in the afternoon; and (3) late chronotypes benefit from evening classes. Together, these results demonstrate that academic performance is improved when school times are better aligned with the biological rhythms of adolescents.'
- - https://www.washingtonpost.com/graphics/2020/world/national-security/cia-crypto-encryption-machines-espionage/
  - "‘The intelligence coup of the century’: For decades, the <span class=\"smallcaps-auto\">CIA</span> read the encrypted communications of allies and adversaries"
  - Greg Miller (Washington Post)
  - 2020-02-11
  - ''
  - ! '<p>For more than half a century, governments all over the world trusted a single company to keep the communications of their spies, soldiers and diplomats secret. The company, Crypto AG, got its first break with a contract to build code-making machines for U.S. troops during World War II. Flush with cash, it became a dominant maker of encryption devices for decades, navigating waves of technology from mechanical gears to electronic circuits and, finally, silicon chips and software. The Swiss firm made millions of dollars selling equipment to more than 120 countries well into the 21<sup>st</sup> century. Its clients included Iran, military juntas in Latin America, nuclear rivals India and Pakistan, and even the Vatican.</p><p>But what none of its customers ever knew was that Crypto AG was secretly owned by the <span class="smallcaps-auto">CIA</span> in a highly classified partnership with West German intelligence. These spy agencies rigged the company’s devices so they could easily break the codes that countries used to send encrypted messages. The decades-long arrangement, among the most closely guarded secrets of the Cold War, is laid bare in a classified, comprehensive <span class="smallcaps-auto">CIA</span> history of the operation obtained by The Washington Post and <a href="https://www.zdf.de/nachrichten/politik/cryptoleaks-bnd-cia-operation-rubikon-100.html" title="Cryptoleaks: How BND and CIA Deceived Everyone: Research by ZDF, Washington Post and SRF shows how the BND and CIA secretly spy on states—and concealed gross human rights violations."><span class="smallcaps-auto">ZDF</span></a>, a German public broadcaster, in a joint reporting project.The account identifies the <span class="smallcaps-auto">CIA</span> officers who ran the program and the company executives entrusted to execute it. It traces the origin of the venture as well as the internal conflicts that nearly derailed it. It describes how the United States and its allies exploited other nations’ gullibility for years, taking their money and stealing their secrets.</p><p>The operation, known first by the code name “Thesaurus” and later “Rubicon,” ranks among the most audacious in <span class="smallcaps-auto">CIA</span> history. “It was the intelligence coup of the century,” the <span class="smallcaps-auto">CIA</span> report concludes. “Foreign governments were paying good money to the U.S. and West Germany for the privilege of having their most secret communications read by at least two (and possibly as many as five or six) foreign countries.” From 1970 on, the <span class="smallcaps-auto">CIA</span> and its code-breaking sibling, the National Security Agency, controlled nearly every aspect of Crypto’s operations—presiding with their German partners over hiring decisions, designing its technology, sabotaging its algorithms and directing its sales targets. Then, the U.S. and West German spies sat back and listened. They monitored Iran’s mullahs during the 1979 hostage crisis, fed intelligence about Argentina’s military to Britain during the Falklands War, tracked the assassination campaigns of South American dictators and caught Libyan officials congratulating themselves on the 1986 bombing of a Berlin disco.</p><p>…The German spy agency, the <span class="smallcaps-auto">BND</span>, came to believe the risk of exposure was too great and left the operation in the early 1990s. But the <span class="smallcaps-auto">CIA</span> bought the Germans’ stake and simply kept going, wringing Crypto for all its espionage worth until 2018, when the agency sold off the company’s assets, according to current and former officials.</p><p>…This story is based on the <span class="smallcaps-auto">CIA</span> history and a parallel <span class="smallcaps-auto">BND</span> account, also obtained by The Post and <span class="smallcaps-auto">ZDF</span>, interviews with current and former Western intelligence officials as well as Crypto employees. Many spoke on the condition of anonymity, citing the sensitivity of the subject. It is hard to overstate how extraordinary the <span class="smallcaps-auto">CIA</span> and <span class="smallcaps-auto">BND</span> histories are. Sensitive intelligence files are periodically declassified and released to the public. But it is exceedingly rare, if not unprecedented, to glimpse authoritative internal histories of an entire covert operation. The Post was able to read all of the documents, but the source of the material insisted that only excerpts be published.</p>'
- - http://www.poetryfoundation.org/poems-and-poets/poems/detail/44399
  - "Pied Beauty"
  - Gerard Manley Hopkins
  - '1877'
  - ''
  - ! '<p>Glory be to God for dappled things—<br />For skies of couple-colour as a brinded cow;<br />For rose-moles all in stipple upon trout that swim;<br />Fresh-firecoal chestnut-falls; finches’ wings;<br />Landscape plotted and pieced—fold, fallow, and plough;<br />And áll trádes, their gear and tackle and trim.</p><p>All things counter, original, spare, strange;<br />Whatever is fickle, freckled (who knows how?)<br />With swift, slow; sweet, sour; adazzle, dim;<br />He fathers-forth whose beauty is past change:<br />Praise him.</p>'
- - https://pdfs.semanticscholar.org/37ee/f9fdeeeb642dc135c22c887a16ff62dbe62a.pdf
  - "Smart Vet: Autocompleting Sentences in Veterinary Medical Records"
  - Samuel Ginn
  - 2019-03-19
  - ''
  - ! '<p>Every day, veterinarians write tens of thousands of medical records, mostly in standard formats following the <span class="smallcaps-auto">SOAP</span> structure: “Subjective”, “Objective”, “Assessment”, and “Plan”. These notes record the findings of their physical exams and observations of their patients, and take countless hours to write. We present in this paper a new system that we call “Smart Vet” that assists veterinarians in the writing of their notes by suggesting autocompletions for their sentences as they are writing them within the sections of their medical records. To enable this, we present two approaches: an end-to-end deep learning system that models this task as a seq2seq neural machine translation problem (i.e. translate a given sequence of sentences that correspond to the existing medical record into the following sequence that corresponds to the next sentence the veterinarian would want to write)and a transformer-based language modeling system based on OpenAI’s recent advancements. Based on the success of this latter method, we evaluate this system live in a medical records application, and successfully see our autocompletions being used in production 12.46% of the time—a remarkable success.</p>'
- - /docs/catnip/2020-li.pdf
  - 'Where there are girls, there are cats'
  - Yuhang Li, Yue Wan, Yigui Zhang, Zhaomei Gong, Zhongqiu Li
  - 2020-02-10
  - 10.1016/j.biocon.2020.108412
  - ! '<p>The growing population of outdoor free-ranging cats poses an increasingly serious threat to biodiversity. Identifying the strategies that outdoor free-ranging cats apply to live with humans is an interesting research topic. In this study, we provided robust estimates of free-ranging cat density in 30 universities in Nanjing, Jiangsu Province, China. We found that the population density of free-ranging cats is linearly related to the proportion of female students in the university. An online questionnaire confirmed that human females were more concerned about the living conditions of free-ranging cats than human males in China. By contrast, a socialization test on 27 free-ranging cats suggests that the cats may have the ability to distinguish human sex and adopt a sociable skill to human females. This study leaves an interesting coevolution story between humans and cats and suggests that human sex may be an important factor to consider in cat population managements and wildlife conservation. [Keywords: Free-ranging cat, Feral cat, Human sex ratio, Socialization test]</p>'
- - https://kentonl.com/pub/gltpc.2020.pdf#google
  - "<span class=\"smallcaps-auto\">REALM</span>: Retrieval-Augmented Language Model Pre-Training"
  - Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang (Google)
  - 2020-02-10
  - ''
  - ! '<p>Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for <span class="smallcaps-auto">NLP</span> tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts.</p><p>To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent <em>knowledge retriever</em>, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents.</p><p>We demonstrate the effectiveness of Retrieval Augmented Language Model pre-training (<span class="smallcaps-auto">REALM</span>) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA).We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4–16% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.</p>'
- - https://colinraffel.com/publications/arxiv2020how.pdf#google
  - 'How Much Knowledge Can You Pack Into the Parameters of a Language Model?'
  - Adam Roberts, Colin Raffel, Noam Shazeer
  - 2020-02-10
  - ''
  - ! '<p>It has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions <em>without access to any external context or knowledge</em>. We show that this approach scales surprisingly well with model size and outperforms models that explicitly look up knowledge on the open-domain variants of Natural Questions and WebQuestions.</p>'
- - https://distill.pub/2020/growing-ca/#google
  - "Growing Neural Cellular Automata: Differentiable Model of Morphogenesis"
  - Alexander Mordvintsev, Ettore Randazzo, Eyvind Niklasson, Michael Levin (Google)
  - 2020-02-11
  - 10.23915/distill.00023
  - ! '<p>[Distill.pub interactive explainer: you can train small <span class="smallcaps-auto">CNN</span>s to coordinate as cellular automata to create complex damage-resilient global patterns using standard deep learning techniques like backpropagation, since <span class="smallcaps-auto">CNN</span>s are differentiable; the <span class="smallcaps-auto">CNN</span> updates such that when it is executed simultaneously in hundreds of ‘cells’, each cell can coordinate appropriately to emit a particular color and eg. form a complex lizard shape. Because it’s decentralized, any individual cell can be deleted and the damage healed.]</p><p>What is clear is that evolution has learned to exploit the laws of physics and computation to implement the highly robust morphogenetic software that runs on genome-encoded cellular hardware. This process is extremely robust to perturbations. Even when the organism is fully developed, some species still have the capability to repair damage—a process known as regeneration. Some creatures, such as salamanders, can fully regenerate vital organs, limbs, eyes, or even parts of the brain! Morphogenesis is a surprisingly adaptive process. Sometimes even a very atypical development process can result in a viable organism—for example, when an early mammalian embryo is cut in two, each half will form a complete individual—monozygotic twins!</p><p>The biggest puzzle in this field is the question of how the cell collective knows what to build and when to stop. The sciences of genomics and stem cell biology are only part of the puzzle, as they explain the distribution of specific components in each cell, and the establishment of different types of cells. While we know of many genes that are <em>required</em> for the process of regeneration, we still do not know the algorithm that is <em>sufficient</em> for cells to know how to build or remodel complex organs to a very specific anatomical end-goal. Thus, one major lynch-pin of future work in biomedicine is the discovery of the process by which large-scale anatomy is specified within cell collectives, and how we can rewrite this information to have rational control of growth and form.</p><p>…Let’s try to develop a cellular automata update rule that, starting from a single cell, will produce a predefined multicellular pattern on a 2D grid. This is our analogous toy model of organism development. To design the CA, we must specify the possible cell states, and their update function. Typical CA models represent cell states with a set of discrete values, although variants using vectors of continuous values exist. The use of continuous values has the virtue of allowing the update rule to be a differentiable function of the cell’s neighbourhood’s states. The rules that guide individual cell behavior based on the local environment are analogous to the low-level hardware specification encoded by the genome of an organism. Running our model for a set amount of steps from a starting configuration will reveal the patterning behavior that is enabled by such hardware.</p><p>…This article describes a toy embryogenesis and regeneration model. This is a major direction for future work, with many applications in biology and beyond. In addition to the implications for understanding the evolution and control of regeneration, and harnessing this understanding for biomedical repair, there is the field of bioengineering. As the field transitions from synthetic biology of single cell collectives to a true synthetic morphology of novel living machines, it will be essential to develop strategies for programming system-level capabilities, such as anatomical homeostasis (regenerative repair)…let’s speculate about what a “more physical” implementation of such a system could look like. We can imagine it as a grid of tiny independent computers, simulating individual cells. Each of those computers would require approximately 10Kb of <span class="smallcaps-auto">ROM</span> to store the “cell genome”: neural network weights and the control code, and about 256 bytes of <span class="smallcaps-auto">RAM</span> for the cell state and intermediate activations. The cells must be able to communicate their 16-value state vectors to neighbors. Each cell would also require an <span class="smallcaps-auto">RGB</span>-diode to display the color of the pixel it represents. A single cell update would require about 10k multiply-add operations and does not have to be synchronised across the grid. We propose that cells might wait for random time intervals between updates. The system described above is uniform and decentralised. Yet, our method provides a way to program it to reach the predefined global state, and recover this state in case of multi-element failures and restarts. We therefore conjecture this kind of modeling may be used for designing reliable, self-organising agents. On the more theoretical machine learning front, we show an instance of a decentralized model able to accomplish remarkably complex tasks. We believe this direction to be opposite to the more traditional global modeling used in the majority of contemporary work in the deep learning field, and we hope this work to be an inspiration to explore more decentralized learning modeling.</p>'
- - https://www.soci.org/Chemistry-and-Industry/CnI-Data/2010/24/Brussels-a-bittersweet-story
  - "Brussels: a bittersweet story"
  - "Cath O'Driscoll (<span class=\"smallcaps-auto\">SCI</span>)"
  - 2010-12-20
  - ''
  - ! '<p>the varieties on the table today are very different from those that we would have been eating in the past, according to Peter van der Toorn, head of R&amp;D in the leafy vegetables section at agrochemicals major Syngenta. ‘We don’t have real bitter tasting sprouts anymore,’ Van der Toorn says. ‘Our product range has moved to a series of “classic” tasting varieties and another series of super mild tasting varieties. But even the classic tasting sprouts are not as bitter as they were.’</p><p>Syngenta claims to be the leading company for creating new Brussels sprouts varieties, with a market share of roughly 80%. The company currently produces 24 commercial varieties – needed to ensure year-round availability, Van der Toorn says. ‘From 2012 onwards, Syngenta will have a complete assortment of super mild tasting hybrids available to guarantee product supply to consumers during the whole growing season.’ And the company is also now evaluating new red-coloured sprouts varieties, such as those on offer this Christmas at UK supermarket giant Asda. These red Brussels are currently being grown by Cambridgeshire farmer John Lankfer, who is reportedly supplying selected stores with 100 t of the brassica over the festive season. As well as their aesthetic appeal, the red sprouts are also claimed to have a milder, sweeter flavour, which it is hoped will make them more attractive to children.</p><p>…Syngenta began a breeding programme to develop milder tasting Brussels varieties in the early 1990s. While many older people prefer the classical bitter tastes, Van der Toorn notes that younger people tend to prefer the milder tasting varieties that have now become the industry standard.</p><p>The bitter taste of Brussels sprouts comes from compounds called glucosinolates and their degradation products, he explains. These bitter tasting compounds are an important part of the plant’s defence mechanism against leaf-eating enemies, such as insects, nematodes, slugs, and herbivores, like pigeons and deer. They are also responsible for many of the health-giving properties of Brussels and other brassicas, particularly their antioxidant and anti-cancer properties…Syngenta scientists first discovered the relationship between glucosinolates and bitter taste in the early 1990s, Van der Toorn says: ‘The lower the level of some glucosinolates the less bitter the taste of the Brussels, which is perceived as milder or sweeter.’ Fortunately, ‘the ones that are causing the bitter taste in Brussels sprouts are not the ones that have health benefits,’ he adds. The first of its sweeter tasting varieties, called <em>Maximus</em>, was introduced onto the marketplace in 1994, while another popular variety this Christmas is <em>Helemus</em>.</p>'
- - https://www.npr.org/sections/thesalt/2019/10/30/773457637/from-culinary-dud-to-stud-how-dutch-plant-breeders-built-our-brussels-sprouts-bo
  - "From Culinary Dud To Stud: How Dutch Plant Breeders Built Our Brussels Sprouts Boom"
  - Dan Charles (<span class=\"smallcaps-auto\">NPR</span>)
  - 2019-10-30
  - ''
  - ! '<p>Foods go in and out of style. Few of them, though, have gone through as dramatic a renaissance in their reputation as Brussels sprouts. For many years, they were scorned. Even Steve Bontadelli admits it, and he makes his living growing them. “A lot of people of my generation hated them,” he says. “Their moms boiled them and made them even stinkier.” Bontadelli’s farm is near Santa Cruz, Calif., where the weather is perfect for growing this vegetable. “We actually had a Brussels sprouts festival here for about 10 years,” he says. “And we got a lot of free press out of the deal, because people couldn’t believe that you’d have a festival for Brussels sprouts.” What’s worse, they even deserved their bad reputation. “They were just very bitter; a very strong bitter taste,” Bontadelli says.</p><p>This all started to change in the 1990s, and it began in the Netherlands, where Brussels sprouts have a simpler name: <em>spruitjes</em>. A Dutch scientist named Hans van Doorn, who worked at the seed and chemical company Novartis (the seed part is now called Syngenta), figured out exactly which chemical compounds in <em>spruitjes</em> made them bitter. At that point, the small handful of companies that sell Brussels sprouts seeds started searching their archives, looking for old varieties that happen to have low levels of the bitter chemicals.</p><p>…There are hundreds of these old varieties. The companies grew them in test plots, and they did, in fact, find some that weren’t as bitter. They cross-pollinated these old varieties with modern, high-yielding ones, trying to combine the best traits of old and new <em>spruitjes</em>. It took many years. But it worked. “From then on, the taste was much better. It really improved,” Sintenie says.</p><p>Then word spread in the professional culinary scene. It took off mainly in the United States, not in Europe. Shannan Troncoso remembers hearing, about a decade ago, that celebrity chef David Chang was doing amazing things with Brussels sprouts and bacon at his restaurant Momofuku, in New York. Then she encountered some crispy fried Brussels sprouts at a restaurant in San Francisco. “It was so good, I was like, I can figure this out! And I can introduce this back into my area,” she says….Demand is booming; farmers are getting four or five times more money than they did a decade ago for their crop. “My dad, his jaw would just drop,” Bontadelli says. “He’d ask me every day, ‘What’s the price, what’s the price?’ Because he’d been in the business his whole life. His eyes would just pop out when I’d tell him. He couldn’t believe it.” Bontadelli says that there were only about 2,500 acres in the whole country planted with Brussels sprouts just a few years ago. Today, there are 10,000 acres of Brussels sprouts in the U.S., and fields are getting planted in Mexico, too—just so people can get their Brussels sprouts year-round.</p>'
- - https://www.airlines.org/dataset/annual-round-trip-fares-and-fees-domestic/
  - 'Domestic Round-Trip Fares and Fees: Average Domestic Round-Trip Airfare: Nominal and Real ($2018)'
  - Airlines for America
  - '2018'
  - ''
  - ! 'The table below offers a time series of the average domestic round-trip airfare as reported by U.S. passenger airlines to the U.S. Department of Transportation1. Included in the table are the average base fare, the average bag and change fee revenue per passenger, and the combined average “all-in” base fare. All metrics are expressed in both current and inflation-adjusted dollars ($2017) and does not include government-imposed taxes and fees. ... 1990, all-in roundtrip fare: $556.03 ... 2018: $362.13'
- - https://vpostrel.com/articles/how-the-easter-bunny-got-so-soft
  - How those plush Easter bunnies got so cuddly
  - Virginia Postrel (Bloomberg)
  - 2015-04-05
  - ''
  - ! '<p>Easter bunnies aren’t what they used to be. The plush toys on store shelves these days are cheaper, often safer, and much, much softer than in bygone days. They represent a small example of a pervasive phenomenon: goods whose quality has improved gradually but significantly over time, without corresponding price increases and or public recognition.</p><p>If you shop around, you can find a stuffed Easter bunny for three dollars, as you could in the 1970s. My neighborhood Target is selling two models at that price, the cheapest in a lineup of plush Easter toys that includes offerings for $4.99, $9.99 and $19.99 (for a giant rabbit). Back in 1970, when I myself was young enough for Easter baskets, Walgreens advertised “plush bunnies in ‘hot’ colors” for $2.97, along with others for $2.19 and $3.77. The $2.97 bunny from 1970 was probably bigger than today’s $2.99 model, but keep in mind that these prices are not corrected for inflation. The 1970 bunny would cost$17.97 in today’s dollars. Or, to use another benchmark, the federal minimum wage in 1970 was $1.45—about half the price of one of those Walgreens bunnies—compared with today’s minimum of $7.25, more than double the price of the Target ones. Earning enough to buy the 1970 bunny required 123 minutes of minimum-wage labor versus about 25 minutes today. Three-dollar bunnies are low-profit items designed to get people in the store and stimulate impulse buying. But the broad pattern applies to more expensive stuffed animals as well: Prices have stayed low. For that, you can thank intense international competition.</p><p>…Consumers have come to expect low prices. But inexpensive doesn’t necessarily mean “cheap.” The quality of stuffed toys has also improved. “It’s a better product than it was years ago, and it’s not that much more expensive,” said Steven Meyer, the third-generation owner of Mary Meyer Corp., a Vermont-based toy company. Meyer joined the company in 1986, helping his father weather the tough transition to manufacturing in Korea.</p><p>For example, Meyer explained, Korean and Taiwanese toymakers introduced safety procedures, later copied in China, to assure the toys didn’t contain hidden hazards. “Every one of our toys is put through a metal detector before it goes into a box, and that’s because a little shard of a sewing needle can break off and go into the toy,” Meyer said. “We never thought of that when we produced in the United States.”</p><p>More immediately apparent is how the toys feel. A stuffed animal that would have delighted a baby boomer now seems rigid and rough. Today’s toys are stuffed with soft, fibrous polyester rather than the foam rubber, sawdust or ground nut shells of the past. Plush outer fabrics no longer have stiff backings; the yarns are knitted to one another rather than attached to a rigid fabric like a carpet. “The whole stuffed toy feels softer and slouchier,” Meyer said. The real magic, however, is in that silky faux fur. I first noticed it about a dozen years ago while buying Christmas presents for my nephew, who has super-sensitive skin and hates clothing tags and scratchy fabrics. Stuffed animals, I discovered, were as different from my childhood toys as a wickable polyester workout T-shirt is from a sweat-sticky polyester disco suit. The secret to both wickable T-shirts and softer Easter bunnies lies in polyester microfibers. These high-tech textiles have replaced the acrylic and polyester plushes that once covered stuffed toys just as they’ve nudged aside cotton for exercise apparel.</p><p>…Textile fibers, including polyester filaments, are measured in decitex or deniers, almost equivalent units unique to the business. For reference: Silk measures about 1.1 to 1.3 decitex, while human hair is 30 to 50. A microfiber is anything less than 1 decitex. Although polyester microfibers date to Toray Industries’ development of Ultrasuede in 1970, they have become widespread only in recent years, thanks in part to massive plant investments in China that have swamped the polyester market and driven down prices. Back when I was buying toys for my nephew, polyester fibers of around 3 decitex “were considered fine,” said Frank Horn, president of the Fiber Economics Bureau, the statistical collection and publication arm of the American Fiber Manufacturers Association. But over the past decade or so, true microfibers have “become ubiquitous.” Now, Horn estimated, the average is about 0.5 decitex—a reduction of about 85%—and some popular microfibers are as fine as 0.3 decitex. The finer the fiber, the softer the final fabric—making today’s stuffed animals extraordinarily silky. Largely unheralded outside the textile business, this progress was “not one particular technology but many,” explained textile chemist Phil Brown of Clemson University’s materials science and engineering school. “Some involved changing fiber shape, some involved using chemical treatments to reduce fiber size, some involved new fiber extrusion technologies in which fibers have more than one polymer component.”</p>'
- - /docs/anime/2019-lee.pdf
  - Unpaired Sketch-to-Line Translation via Synthesis of Sketches
  - Gayoung Lee, Dohyun Kim, Youngjoon Yoo, Dongyoon Han, Jung-Woo Ha, Jaehyuk Chang
  - 2019-11-17
  - 10.1145/3355088.3365163
  - ! 'Converting hand-drawn sketches into clean line drawings is a crucial step for diverse artistic works such as comics and product designs. Recent data-driven methods using deep learning have shown their great abilities to automatically simplify sketches on raster images. Since it is difficult to collect or generate paired sketch and line images, lack of training data is a main obstacle to use these models. In this paper, we propose a training scheme that requires only unpaired sketch and line images for learning sketch-to-line translation. To do this, we first generate realistic paired sketch and line images from unpaired sketch and line images using rule-based line augmentation and unsupervised texture conversion. Next, with our synthetic paired data, we train a model for sketch-to-line translation using supervised learning. Compared to unsupervised methods that use cycle consistency losses, our model shows better performance at removing noisy strokes. We also show that our model simplifies complicated sketches better than models trained on a limited number of handcrafted paired data.'
- - http://www.engineeringletters.com/issues_v27/issue_3/EL_27_3_01.pdf
  - "Anime Sketch Coloring with Swish-gated Residual U-net and Spectrally Normalized GAN"
  - Gang Liu, Xin Chen, Yanzhong Hu
  - 2019-08-12
  - ''
  - ! '<p>Anime sketch coloring is to fill various colors into the black-and-white anime sketches and finally obtain the color anime images. Recently, anime sketch coloring has become a new research hotspot in the field of deep learning. In anime sketch coloring, generative adversarial networks (<span class="smallcaps-auto">GAN</span>s) have been used to design appropriate coloring methods and achieved some results. However, the existing methods based on <span class="smallcaps-auto">GAN</span>s generally have low-quality coloring effects, such as unreasonable color mixing, poor color gradient effect. In this paper, an efficient anime sketch coloring method using swish-gated residual U-net (<span class="smallcaps-auto">SGRU</span>) and spectrally normalized <span class="smallcaps-auto">GAN</span> (<span class="smallcaps-auto">SNGAN</span>) has been proposed to solve the above problems. The proposed method is called spectrally normalized <span class="smallcaps-auto">GAN</span> with swish-gated residual U-net (<span class="smallcaps-auto">SSN</span>-<span class="smallcaps-auto">GAN</span>). In <span class="smallcaps-auto">SSN</span>-<span class="smallcaps-auto">GAN</span>, <span class="smallcaps-auto">SGRU</span> is used as the generator. <span class="smallcaps-auto">SGRU</span> is the U-net with the proposed swish layer and swish-gated residual blocks (<span class="smallcaps-auto">SGB</span>s). In <span class="smallcaps-auto">SGRU</span>, the proposed swish layer and swish-gated residual blocks (<span class="smallcaps-auto">SGB</span>s) effectively filter the information transmitted by each level and improve the performance of the network. The perceptual loss and the per-pixel loss are used to constitute the final loss of <span class="smallcaps-auto">SGRU</span>. The discriminator of <span class="smallcaps-auto">SSN</span>-<span class="smallcaps-auto">GAN</span> uses spectral normalization as a stabilizer of training of <span class="smallcaps-auto">GAN</span>, and it is also used as the perceptual network for calculating the perceptual loss. <span class="smallcaps-auto">SSN</span>-<span class="smallcaps-auto">GAN</span> can automatically color the sketch without providing any coloring hints in advance and can be easily end-to-end trained. Experimental results show that our method performs better than other state-of-the-art coloring methods, and can obtain colorful anime images with higher visual quality.</p>'
- - https://www.grea.ch/sites/default/files/rapport-drogues-sur-internet_2018.pdf
  - "Drogues sur Internet: Etat des lieuxsur la situation en Suisse"
  - Quentin Rossy, Ludovic Staehli, Damien Rhumorbarbe, Pierre Esseiva, Frank Zobel, Christian Schneider, Larissa J.Mayer
  - 2018-11
  - ''
  - ! '<p>[Google Translate of French abstract] Where do you find drugs on the Internet, how are they sold, what is the size of the market and what is Switzerland’s place in it? To try to answer these questions, Addiction Switzerland and the School of Criminal Sciences at <span class="smallcaps-auto">UNIL</span> have collected and analyzed a set of relevant data on behalf of the Federal Office of Public Health.   The Internet is made up of three basic components: a transmission network (cables or waves), a system for recognizing interconnected devices (the IP protocol) and data transport protocols. Together, they allow the use of applications (web, e-mail, messaging) for communication and information sharing. It is possible to find and buy drugs on many applications including websites, whether concealed or not, but also social networks and messaging applications. You can come across different promotion strategies, different sales spaces but also evaluation of the drugs offered. Other products such as drugs, narcotics, and new psychoactive substances (<span class="smallcaps-auto">NPS</span>) are also on sale.</p><p>Knowledge about the sale of narcotics on the various applications present on the Internet is still in its infancy, with the exception of crypto-markets which are often specialized in this field. These are sales platforms that allow for some anonymity. The use of specific infrastructures (called darknets), web spaces that are not or not very regulated (dark webs), encrypted communications and cryptocurrencies like Bitcoin allow this anonymity. The dark webs, and the crypto-markets they host, however, are tiny compared to all the spaces on the web.</p><p>The sale of narcotic drugs on crypto-markets has been revealed by the <em>Silk Road</em> website. Since then, many similar sites have appeared but with often relatively short lifespans, due to internal fraud or the intervention of the police. The sites are based on management by administrators and on advertisements that describe the product, its price and the conditions of its acquisition. They also rely on the assessment of products and sellers by buyers. They are thus, in their form, similar to many sites known as eBay.</p><p>To understand Switzerland’s place in this market, downloads of data from one of the main crypto-narcotics markets (<em>AlphaBay</em>, active from the end of 2014 to July 2017) were carried out. They show that the most cited countries of origin are the Anglo-Saxon countries (United States, Canada, Australia, United Kingdom), the Netherlands and Germany. Switzerland occupies a less important place but, if we consider its size, its role is not negligible in terms of sales. Thus, 57 seller accounts declaring to be located in Switzerland carried out just over ten thousand transactions for a turnover of approximately 1.3 million francs on AlphaBay. The sale of stimulants concerns 85% of these transactions, especially with small quantities and prices close to those of the physical market. These sales represent in fact only a very small part of the narcotics market in Switzerland, but some sellers make substantial sales of up to almost $30,000 a month.</p><p>There is little data on people in Switzerland who order drugs online. Analysis of data from the <em>Global Drug Survey</em> suggests that shopping on the web and on dark webs remains limited, but with an increasing trend. Older data shows that cannabis and stimulants are the products most ordered by Swiss buyers. They order from sellers in Switzerland but also abroad, especially in Germany, the Netherlands, the United Kingdom and Belgium. Overseas orders are generally associated with larger quantities but remain relatively small. On average, apart from cannabis, purchases rarely exceed 5–10 grams on average.</p><p>A small survey of cantonal police has shown that surveys of online drug purchases have so far been relatively rare. They often result from information provided by an informant or from the discovery of a computer turned on during a search. The most frequent case concerns parcels intercepted by customs with small quantities ordered on the Internet, most often cannabis, stimulants or hallucinogens.</p><p>We will retain from this exploration of the data on the Internet drug markets, that these are found in different spaces of the web, in particular the dark webs, but that they seem so far to constitute only a very small part of the drug market for narcotic drugs, at least in Switzerland. There are, however, some indications that the phenomenon is tending to spread, even if it is happening at a slower pace than one might have thought. Like other innovations, the sale and purchase of psychoactive substances on the Internet probably follows an adoption phase in a small group of individuals before, perhaps, becoming a wider phenomenon.</p>'
- - /docs/sr/2019-vana.pdf
  - From Darknets to Light
  - Prasad Vana, Pradeep Pachigolla
  - 2019-10-20
  - ''
  - ! '<p>A large majority of e-commerce happens on the “Surface Web”, which consists of all the websites that can be accessed through search engines. However, there has recently been a rapid growth in the “Dark Web”, consisting of websites which cannot be indexed by search engines. The Dark Web offers a high degree of anonymity and security to its users and has attracted illicit activity. Online marketplaces similar to eBay and Etsy on the Surface Web have also evolved on the Dark Web and are commonly known as “Darknet markets”. These markets have attracted sellers and buyers of illegal products such as drugs, weapons, and counterfeits. Law enforcement agencies are interested in curbing the rise of these markets. In this research, we focus on a bust operation conducted by the <span class="smallcaps-auto">FBI</span> and Europol in November 2014 that shut down Silk Road 2.0, one of the biggest Darknet markets at the time. Using the bust as an exogenous shock, we investigate the causal effect of the bust on Evolution and Agora, the next two biggest Darknet markets that were not subject to the bust. We find that the bust had positive marketing consequences for the buyers and the administrators of Evolution and Agora. Specifically, the prices reduced, and the number of transactions per vendor increased following the bust. Our results also indicate that these benefits are not simply a product of the forces of supply and demand but that they occur despite them. Our findings demonstrate that there could be surprising and unintended consequences to such busts and recommend law enforcement agencies consider them into their enforcement strategies. [Keywords: two-sided markets, e-commerce, Dark Web.]</p>'
- - /docs/sr/2019-yang.pdf
  - Anonymous market product classification based on deep learning
  - Lina Yang, Ying Yang, Huanhuan Yi, Guichun Zhu
  - 2019-12
  - 10.1145/3371425.3371467
  - ! 'With the rapid development of Internet technology, the abuse of dark networks and anonymous technology has brought great challenges to network supervision. Therefore, it is important to study the anonymous market. In this paper, we propose a single-mode multivariate classification model for anonymous market product classification. Divide anonymous markets products into 5 categories. Our algorithm uses the word vector embedded in a convolutional neural network based on Word2vec training. Compared with the simple machine learning classification model, the accuracy of the single-mode multivariate classification model on the test set is 91.84%. By studying the classification of anonymous market products, law enforcement personnel can better supervise anonymous market of illegal products and maintain network security.'
- - https://seclab.bu.edu/papers/reddit-WACCO2019.pdf
  - "A Qualitative Evaluation of Two Different Law Enforcement Approaches on Dark Net Markets"
  - Cerys Bradley, Gianluca Stringhini
  - 2019-06-17
  - '10.1109/EuroSPW.2019.00057'
  - ! '<p>This paper presents the results of a qualitative study on discussions about two major law enforcement interventions against Dark Net Market (<span class="smallcaps-auto">DNM</span>) users extracted from relevant Reddit forums. We assess the impact of Operation Hyperion and Operation Bayonet (combined with the closure of the site Hansa) by analyzing posts and comments made by users of two Reddit forums created for the discussion of Dark Net Markets. The operations are compared in terms of the size of the discussions, the consequences recorded, and the opinions shared by forum users. We find that Operation Bayonet generated a higher number of discussions on Reddit, and from the qualitative analysis of such discussions it appears that this operation also had a greater impact on the <span class="smallcaps-auto">DNM</span> ecosystem.</p>'
- - /docs/statistics/causality/1990-horwitz.pdf
  - 'Developing improved observational methods for evaluating therapeutic effectiveness'
  - 'Ralph I. Horwitz, Catherine M. Viscoli, John D. Clemens, Robert T. Sadock'
  - 1990-11
  - '10.1016/0002-9343(90)90182-D'
  - ! '<p>Therapeutic efficacy is often studied with observational surveys of patients whose treatments were selected non-experimentally. The results of these surveys are distrusted because of the fear that biased results occur in the absence of experimental principles, particularly randomization. The purpose of the current study was to develop and validate improved observational study designs by incorporating many of the design principles and patient assembly procedures of the randomized trial. The specific topic investigated was the prophylactic effectiveness of <em>β</em>-blocker therapy after an acute myocardial infarction.</p><p>To accomplish the research objective, three sets of data were compared. First, we developed a restricted cohort based on the eligibility criteria of the randomized clinical trial; second, we assembled an expanded cohort using the same design principles except for not restricting patient eligibility; and third, we used the data from the Beta Blocker Heart Attack Trial (<span class="smallcaps-auto">BHAT</span>), whose results served as the gold standard for comparison.</p><p>In this research, the treatment difference in death rates for the restricted cohort and the <span class="smallcaps-auto">BHAT</span> trial was nearly identical. In contrast, the expanded cohort had a larger treatment difference than was observed in the <span class="smallcaps-auto">BHAT</span> trial. We also noted the important and largely neglected role that eligibility criteria may play in ensuring the validity of treatment comparisons and study outcomes. The new methodological strategies we developed may improve the quality of observational studies and may be useful in assessing the efficacy of the many medical/surgical therapies that cannot be tested with randomized clinical trials.</p>'
- - /docs/sociology/1941-davis.pdf
  - Intermarriage In Caste Societies
  - Kingsley Davis
  - 1941-07
  - 10.1525/aa.1941.43.3.02a00030
  - ! 'Social stratification, whatever its causes, hinges upon certain objective bases or marks—e.g., sex, age, birth, race, residence, achievement, and appearance—tangible pegs whereon are hung the more intangible realities of invidious discrimination. This chapter deals with marital selection only in this second sense, being primarily concerned with the interrelation between marriage and caste. It discusses the strange circumstance that despite the intimate dependence of caste stratification upon caste endogamy, intermarriage often occurs in caste societies, sometimes in the highly regularized form of hypergamy. A cardinal principle of every stratified social order is that the majority of those marrying shall marry equals. This rule can be called (according to the type of stratification involved) class, caste, or ständische endogamy. There are forces that oppose rank endogamy. But the principle that stratification in itself necessitates such endogamy remains firm. The chapter also explores actual caste societies and attempts to deal with glaring exceptions (such as hypergamy) which occur in them.'
- - /docs/psychology/1998-shrum.pdf
  - "The Effects of Television Consumption on Social Perceptions: The Use of Priming Procedures to Investigate Psychological Processes"
  - ! "L. J. Shrum, Robert S. Wyer, Jr., Thomas C. O'Guinn"
  - 1998-03-01
  - 10.1086/209520
  - ! "Two studies investigated the extent to which heavy television viewing affects consumers' perceptions of social reality and the cognitive processes that underlie these effects. Both studies found evidence that heavy viewers' beliefs about social reality are more consistent with the content of television programming than are those of light viewers. The use of a priming methodology provided support for the notion that television is a causal factor in the formation of these beliefs and that a failure to discount television-based exemplars in forming these beliefs accounts for its influence. Implications of these results for a heuristic processing model of television effects are discussed."
- - https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.20141707
  - "Creative Destruction: Barriers to Urban Growth and the Great Boston Fire of 1872"
  - Richard Hornbeck, Daniel Keniston
  - '2017'
  - 10.1257/aer.20141707
  - ! 'Urban growth requires the replacement of outdated buildings, yet growth may be restricted when landowners do not internalize positive spillover effects from their own reconstruction. The Boston Fire of 1872 created an opportunity for widespread simultaneous reconstruction, initiating a virtuous circle in which building upgrades encouraged further upgrades of nearby buildings. Land values increased substantially among burned plots and nearby unburned plots, capitalizing economic gains comparable to the prior value of burned buildings. Boston had grown rapidly prior to the Fire, but negative spillovers from outdated durable buildings had substantially constrained its growth by dampening reconstruction incentives.'
- - 'http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.248.7497&rep=rep1&type=pdf'
  - "Razing San Francisco: The 1906 Disaster as a Natural Experiment in Urban Redevelopment"
  - James Siodla
  - '2015'
  - 10.1016/j.jue.2015.07.001
  - ! 'Urban developers face frictions in the process of redeveloping land, the timing of which depends on many economic factors. This timing can be disrupted by a large shock that destroys thousands of buildings, which could then have substantial short-run and long-run effects. Studying the impact of an urban disaster, therefore, can provide unique insight into urban dynamics. Exploiting the 1906 San Francisco Fire as an exogenous reduction in the city’s building stock, this paper examines residential density across razed and unburned areas between 1900 and 2011. In prominent residential neighborhoods, density increased at least 60% in razed areas relative to unburned areas by 1914, and a large density differential still exists today. These outcomes suggest that thriving cities face substantial redevelopment frictions in the form of durable buildings and that large shocks can greatly alter the evolution of urban land-use outcomes over time.'
- - /docs/traffic/2015-pagefair.pdf
  - "The cost of ad blocking: PageFair and Adobe 2015 Ad Blocking Report"
  - PageFair
  - '2015'
  - ''
  - ! '<p>In the third annual ad blocking report, PageFair, with the help of Adobe, provides updated data on the scale and growth of ad blocking software usage and highlights the global and regional economic impact associated with it. Additionally, this report explores the early indications surrounding the impact of ad blocking within the mobile advertising space and how mobile will change the ad blocking landscape.</p><p>Table of Contents: · 1. Introduction · 2. Table of Contents · 3. Key insights · 4. Global ad blocking growth · 5. Usage of ad blocking software in the United States · 6. Usage of ad blocking software in Europe · 7. The cost of blocking ads · 8. Effect of ad blocking by industry · 9. Google Chrome still the main driver of ad block growth · 10. Mobile is yet to be a factor in ad blocking growth · 11. Mobile will facilitate future ad blocking growth · 12. Reasons to start using an ad blocker · 13. Afterword · 14. Background · 15. Methodology · 16. Tables · 17. Tables</p><p><strong>Key Insights</strong>: More consumers block ads, continuing the strong growth rates seen during 2013 and 2014. The findings:</p><ul><li>Globally, the number of people using ad blocking software grew by <em>41%</em> year over year.</li><li><em>16%</em> of the US online population blocked ads during Q2 2015.</li><li>Ad block usage in the United States grew <em>48%</em> during the past year, increasing to <em>45 million</em> monthly active users (<span class="smallcaps-auto">MAU</span>s) during Q2 2015.</li><li>Ad block usage in Europe grew by <em>35%</em> during the past year, increasing to <em>77 million</em> monthly active users during Q2 2015.</li><li>The estimated loss of global revenue due to blocked advertising during 2015 was <em>$21.8B</em>.</li><li>With the ability to block ads becoming an option on the new iOS 9, mobile is starting to get into the ad blocking game. Currently Firefox and Chrome lead the mobile space with <em>93%</em> share of mobile ad blocking.</li></ul>'
- - /docs/genetics/heritable/2002-maia.pdf
  - 'Genetic factors in physical activity levels: A Twin Study'
  - José A.R Maia, Martine Thomis, Gaston Beunen
  - 2002-08-01
  - '10.1016/S0749-3797(02)00478-6'
  - ! '<p><em>Background</em>: Substantial interindividual variation is observed in sports participation and physical activity levels in youth. This study aimed to (1) estimate the relative contribution of genes, along with shared and nonshared environmental factors, to variation in sports participation index (<span class="smallcaps-auto">SPI</span>) and leisure-time physical activity (<span class="smallcaps-auto">LTPA</span>); and (2) test differences in those factors in males and females.</p><p><em>Methods</em>: The sample was comprised of 411 Portuguese twin pairs of different zygosity aged 12 to 25 years. The <span class="smallcaps-auto">SPI</span> and <span class="smallcaps-auto">LTPA</span> were assessed with the Baecke questionnaire. Quantitative genetic modeling was used to test alternative models for the presence of additive gene effects (<em>a</em><sup>2</sup>), common or shared environment within the family (<em>c</em><sup>2</sup>), and unique environmental factors (<em>e</em><sup>2</sup>).</p><p><em>Results</em>: The best-fitting models showed sex-specific effects for the two phenotypes. Variance components for <span class="smallcaps-auto">SPI</span> in males were <em>a</em><sup>2</sup>=68.4%, <em>c</em><sup>2</sup>=20%, and <em>e</em><sup>2</sup>=11.6%; and in females, <em>a</em><sup>2</sup>=39.8%, <em>c</em><sup>2</sup>=28.4%, and <em>e</em><sup>2</sup>=31.8%. For variation in <span class="smallcaps-auto">LTPA</span>, genetic factors in males explained 63%, common environment was not significant, and unique environment explained 37%. In females, contributing factors were <em>a</em><sup>2</sup>=32%, <em>c</em><sup>2</sup>=38%, and <em>e</em><sup>2</sup>=30%.</p><p><em>Conclusions</em>: Genetic effects explained a considerable amount of variation in <span class="smallcaps-auto">SPI</span> and <span class="smallcaps-auto">LTPA</span>, which were greater in males than in females. The relevance of shared environmental factors (family and peers) and nonshared environmental factors in <span class="smallcaps-auto">SPI</span> and <span class="smallcaps-auto">LTPA</span> is particularly evident in females. [Keywords: exercise, genetics, physical fitness, twins]</p>'
- - /docs/psychology/2019-habib.pdf
  - 'Microdeletion in a <em>FAAH</em> pseudogene identified in a patient with high anandamide concentrations and pain insensitivity'
  - 'Abdella M. Habib, Andrei L. Okorokov, Matthew N. Hill, Jose T. Bras, Man-Cheung Lee, Shengnan Li, Samuel J. Gossage, Marie van Drimmelen, Maria Morena, Henry Houlden, Juan D. Ramirez, David L.H. Bennett, Devjit Srivastava, James J. Cox'
  - 2019-02-22
  - 10.1016/j.bja.2019.02.019
  - ! '<p>The study of rare families with inherited pain insensitivity can identify new human-validated analgesic drug targets. Here, a 66-yr-old female presented with nil requirement for postoperative analgesia after a normally painful orthopaedic hand surgery (trapeziectomy). Further investigations revealed a lifelong history of painless injuries, such as frequent cuts and burns, which were observed to heal quickly. We report the causative mutations for this new pain insensitivity disorder: the co-inheritance of (i) a microdeletion in dorsal root ganglia and brain-expressed pseudogene, <em><span class="smallcaps-auto">FAAH</span>-<span class="smallcaps-auto">OUT</span></em>, which we cloned from the fatty-acid amide hydrolase (<em><span class="smallcaps-auto">FAAH</span></em>) chromosomal region; and (ii) a common functional single-nucleotide polymorphism in <em><span class="smallcaps-auto">FAAH</span></em> conferring reduced expression and activity. Circulating concentrations of anandamide and related fatty-acid amides (palmitoylethanolamide and oleoylethanolamine) that are all normally degraded by <em><span class="smallcaps-auto">FAAH</span></em> were significantly elevated in peripheral blood compared with normal control carriers of the hypomorphic single-nucleotide polymorphism. The genetic findings and elevated circulating fatty-acid amides are consistent with a phenotype resulting from enhanced endocannabinoid signalling and a loss of function of <em><span class="smallcaps-auto">FAAH</span></em>. Our results highlight previously unknown complexity at the <em><span class="smallcaps-auto">FAAH</span></em> genomic locus involving the expression of <em><span class="smallcaps-auto">FAAH</span>-<span class="smallcaps-auto">OUT</span></em>, a novel pseudogene and long non-coding <span class="smallcaps-auto">RNA</span>. These data suggest new routes to develop <em><span class="smallcaps-auto">FAAH</span></em>-based analgesia by targeting of <em><span class="smallcaps-auto">FAAH</span>-<span class="smallcaps-auto">OUT</span></em>, which could significantly improve the treatment of postoperative pain and potentially chronic pain and anxiety disorders. [Keywords: anandamide, anxiolytic, endocannabinoids, pain insensitivity, postoperative analgesia]</p>'
- - /docs/genetics/selection/2018-keller.pdf
  - Evolutionary Perspectives on Genetic and Environmental Risk Factors for Psychiatric Disorders
  - Matthew C. Keller
  - 2018-05
  - 10.1146/annurev-clinpsy-050817-084854
  - ! 'Evolutionary medicine uses evolutionary theory to help elucidate why humans are vulnerable to disease and disorders. I discuss two different types of evolutionary explanations that have been used to help understand human psychiatric disorders. First, a consistent finding is that psychiatric disorders are moderately to highly heritable, and many, such as schizophrenia, are also highly disabling and appear to decrease Darwinian fitness. Models used in evolutionary genetics to understand why genetic variation exists in fitness-related traits can be used to understand why risk alleles for psychiatric disorders persist in the population. The usual explanation for species-typical adaptations—natural selection—is less useful for understanding individual differences in genetic risk to disorders. Rather, two other types of models, mutation-selection-drift and balancing selection, offer frameworks for understanding why genetic variation in risk to psychiatric (and other) disorders exists, and each makes predictions that are now testable using whole-genome data. Second, species-typical capacities to mount reactions to negative events are likely to have been crafted by natural selection to minimize fitness loss. The pain reaction to tissue damage is almost certainly such an example, but it has been argued that the capacity to experience depressive symptoms such as sadness, anhedonia, crying, and fatigue in the face of adverse life situations may have been crafted by natural selection as well. I review the rationale and strength of evidence for this hypothesis. Evolutionary hypotheses of psychiatric disorders are important not only for offering explanations for why psychiatric disorders exist, but also for generating new, testable hypotheses and understanding how best to design studies and analyze data. [Keywords: evolution, psychiatric disorders, genetics, schizophrenia, depression]'
- - https://kclpure.kcl.ac.uk/portal/files/13306923/Power_et_al_2012_23147713_322.pdf
  - Fecundity of Patients With Schizophrenia, Autism, Bipolar Disorder, Depression, Anorexia Nervosa, or Substance Abuse vs Their Unaffected Siblings
  - Robert A. Power, Simon Kyaga, Rudolf Uher, James H. MacCabe, Niklas Långström, Mikael Landen, Peter McGuffin, Cathryn M. Lewis, Paul Lichtenstein, Anna C. Svensson
  - 2013-01
  - 10.1001/jamapsychiatry.2013.268
  - ! '<p><em>Context</em>: It is unknown how genetic variants conferring liability to psychiatric disorders survive in the population despite strong negative selection. However, this is key to understanding their etiology and designing studies to identify risk variants.</p><p><em>Objectives</em>: To examine the reproductive fitness of patients with schizophrenia and other psychiatric disorders vs their unaffected siblings and to evaluate the level of selection on causal genetic variants.</p><p><em>Design</em>: We measured the fecundity of patients with schizophrenia, autism, bipolar disorder, depression, anorexia nervosa, or substance abuse and their unaffected siblings compared with the general population.</p><p><em>Setting</em>: Population databases in Sweden, including the Multi-Generation Register and the Swedish Hospital Discharge Register.</p><p><em>Participants</em>: In total, 2.3 million individuals among the 1950 to 1970 birth cohort in Sweden.</p><p><em>Main Outcome Measures</em>: Fertility ratio (FR), reflecting the mean number of children compared with that of the general population, accounting for age, sex, family size, and affected status.</p><p><em>Results</em>: Except for women with depression, affected patients had significantly fewer children (FR range for those with psychiatric disorder, 0.23–0.93; <em>p</em> &lt; 10<sup>−10</sup>). This reduction was consistently greater among men than women, suggesting that male fitness was particularly sensitive. Although sisters of patients with schizophrenia and bipolar disorder had increased fecundity (FR range, 1.02–1.03; <em>p</em> &lt; .01), this was too small on its own to counterbalance the reduced fitness of affected patients. Brothers of patients with schizophrenia and autism showed reduced fecundity (FR range, 0.94–0.97; <em>p</em> &lt; .001). Siblings of patients with depression and substance abuse had significantly increased fecundity (FR range, 1.01–1.05; <em>p</em> &lt; 10<sup>−10</sup>). In the case of depression, this more than compensated for the lower fecundity of affected individuals.</p><p><em>Conclusions</em>: Our results suggest that strong selection exists against schizophrenia, autism, and anorexia nervosa and that these variants may be maintained by new mutations or an as-yet unknown mechanism. Bipolar disorder did not seem to be under strong negative selection. Vulnerability to depression, and perhaps substance abuse, may be preserved by balancing selection, suggesting the involvement of common genetic variants in ways that depend on other genes and on environment.</p>'
- - /docs/technology/2005-vanderkloot.pdf
  - "Lawrence Bragg's role in the development of sound-ranging in World War I"
  - William Van der Kloot
  - 2005-09-06
  - 10.1098/rsnr.2005.0095
  - ! '<p>In 1915, when <a href="https://en.wikipedia.org/wiki/Lawrence_Bragg">Lawrence Bragg</a> was a 25-year-old Second Lieutenant in the Royal Horse Artillery, seconded to ‘Maps <span class="smallcaps-auto">GHQ</span>’, he learned that he and his father had shared the Nobel Prize in physics. Lawrence’s equation was crucial for winning the prize and he had been wounded by his father’s early dissemination of their work with casual attribution to ‘my son’. Lawrence was responsible for developing methods for pinpointing the position of enemy artillery pieces by recording the boom of their firing with an array of microphones. It was a simple idea but difficult to implement. Step by step, Bragg and the group he assembled solved the problems and developed a system that worked. <a href="https://en.wikipedia.org/wiki/Artillery_sound_ranging">Sound-ranging</a> was valuable in the British victory at Cambrai in 1917 and vital for that at Amiens in 1918: the ‘black day of the German Army’. He received the MC and the <span class="smallcaps-auto">OBE</span>. His Army service manifested both his scientific leadership and administrative skills, which culminated in the demonstrations of the validity of the dream he enunciated in his Nobel lecture: that X-rays could be used to resolve the structure of the most complicated molecules.</p>'
- - /docs/ai/2016-covington.pdf#google
  - 'Deep Neural Networks for YouTube Recommendations'
  - Paul Covington, Jay Adams, Emre Sargin
  - 2016-09-15
  - 10.1145/2959100.2959190
  - ! 'YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact. [Keywords: recommender system; deep learning; scalability]'
- - /docs/sunkcosts/1988-debondt.pdf
  - 'Throwing good money after bad?: Nuclear power plant investment decisions and the relevance of sunk costs'
  - 'Werner F.M. De Bondt, Anil K. Makhija'
  - 1988-09
  - 10.1016/0167-2681(88)90044-3
  - ! 'Experimental psychologists and decision theorists suggest that managers are overly reluctant to terminate economically unviable projects and that they fail to ignore sunk costs. This study serves two purposes. First, it shows that the framework of prospect theory allows us to reconcile the sunk cost effect with some older, well-established ideas in investment decision-making. Secondly, the study investigates the external validity of the sunk cost research in the context of the U.S. nuclear power program. The empirical analysis is based on share price movements in reaction to, among other events, all plant completions and cancellations (over $50 million) prior to March 1984. The results are mixed. However, prudency reviews ordered by Public Service Commissions around the nation point to evidence consistent with the sunk cost fallacy.'
- - https://ajp.psychiatryonline.org/doi/pdfplus/10.1176/appi.ajp.2008.07081242
  - 'Premorbid IQ in Schizophrenia: A Meta-Analytic Review'
  - Kristen A. Woodberry, Anthony J. Giuliano, Larry J. Seidman
  - 2008-05-01
  - 10.1176/appi.ajp.2008.07081242
  - ! '<p><em>Objective</em>: Over the past three decades, there have been significant changes in the diagnostic criteria for schizophrenia as well as changes in measurement of IQ. The last quantitative review of the literature on premorbid IQ in schizophrenia was published more than two decades ago. Since that time, there have been many published studies of data sets pertaining to this issue. The purpose of the present review was to provide an updated meta-analysis of premorbid IQ in individuals who later develop schizophrenia.</p><p><em>Method</em>: The authors performed a systematic literature search, which yielded 18 studies that met criteria for the meta-analysis. Inclusion criteria were 1. premorbid psychometric measures of IQ in subjects who were later diagnosed with schizophrenia, schizoaffective disorder, or schizophreniform disorder, 2. similar comparison data, and 3. sufficient data for calculation of an effect size. The analogue to the analysis of variance method was used to model between-study variance due to key study-design features.</p><p><em>Results</em>: Overall, schizophrenia samples demonstrated a reliable, medium-sized impairment in premorbid IQ. The heterogeneity of effect sizes was minimal and almost exclusively the result of one study. Methodological differences, such as diagnostic criteria, type of IQ measure, sample ascertainment, and age at premorbid testing, contributed minimally to the effect size variance. A cross-sectional analysis of all studies by age and a descriptive review of studies that used repeated measures of IQ in a single sample did not support the presence of a relative decline in IQ during the premorbid period in individuals with schizophrenia. However, all studies with pre- and post-onset testing within the same sample suggested that a significant decline in the IQ of individuals with schizophrenia, relative to comparison subjects, was associated with the onset of frank psychosis.</p><p><em>Conclusions</em>: Years before the onset of psychotic symptoms, individuals with schizophrenia, as a group, demonstrate mean IQ scores approximately one-half of a standard deviation below that of healthy comparison subjects.</p>'
- - https://core.ac.uk/download/pdf/6324748.pdf
  - "Hyperbolic discounting is rational: valuing the far future with uncertain discount rates"
  - J. Doyne Farmer, John Geanakoplos
  - 2009-08
  - ''
  - ! 'Conventional economics supposes that agents value the present vs. the future using an exponential discounting function. In contrast, experiments with animals and humans suggest that agents are better described as hyperbolic discounters, whose discount function decays much more slowly at large times, as a power law. This is generally regarded as being time inconsistent or irrational. We show that when agents cannot be sure of their own future one-period discount rates, then hyperbolic discounting can become rational and exponential discounting irrational. This has important implications for environmental economics, as it implies a much larger weight for the far future. [Keywords: Hyperbolic discounting, environment, time consistent, exponential discounting, geometric random walk, term structure of interest rates.]'
- - https://uwe-repository.worktribe.com/OutputFile/994066#pdf
  - "Implications of the Turing completeness of reaction-diffusion models, informed by <span class=\"smallcaps-auto\">GPGPU</span> simulations on an XBox 360: Cardiac arrhythmias, re-entry and the halting problem"
  - Simon Scarle
  - 2009-08-01
  - '10.1016/j.compbiolchem.2009.05.001'
  - ! 'In the arsenal of tools that a computational modeler can bring to bear on the study of cardiac arrhythmias the most widely used and arguably the most successful is that of an excitable medium, a special case of a reaction-diffusion model. These are used to simulate the internal chemical reactions of a cardiac cell and the diffusion of their membrane voltages. Via a number of different methodologies it has previously been shown that reaction-diffusion systems are at multiple levels Turing complete. That is, they are capable of computation in the same manner as a universal Turing machine. However, all such computational systems are subject to a limitation known as the Halting problem. By constructing a universal logic gate using a cardiac cell model, we highlight how the Halting problem therefore could limit what it is possible to predict about cardiac tissue, arrhythmias and re-entry. All simulations for this work were carried out on the <span class=\"smallcaps-auto\">GPU</span> of an XBox 360 development console, and we also highlight the great gains in computational power and efficiency produced by such general purpose processing on a <span class=\"smallcaps-auto\">GPU</span> for cardiac simulations. [Keywords: heart, re-entry, cardiac arrhythmias, excitable media, halting problem, <span class=\"smallcaps-auto\">GPGPU</span>]'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.858.5753&rep=rep1&type=pdf
  - 'The Power of Testing Memory: Basic Research and Implications for Educational Practice'
  - Henry L. Roediger III, Jeffrey D. Karpicke
  - 2006-09-01
  - 10.1111/j.1745-6916.2006.00012.x
  - ! "A powerful way of improving one's memory for material is to be tested on that material. Tests enhance later retention more than additional study of the material, even when tests are given without feedback. This surprising phenomenon is called the testing effect, and although it has been studied by cognitive psychologists sporadically over the years, today there is a renewed effort to learn why testing is effective and to apply testing in educational settings. In this article, we selectively review laboratory studies that reveal the power of testing in improving retention and then turn to studies that demonstrate the basic effects in educational settings. We also consider the related concepts of dynamic testing and formative assessment as other means of using tests to improve learning. Finally, we consider some negative consequences of testing that may occur in certain circumstances, though these negative effects are often small and do not cancel out the large positive effects of testing. Frequent testing in the classroom may boost educational achievement at all levels of education."
- - /docs/nature/2013-white.pdf
  - 'Would You Be Happier Living in a Greener Urban Area? A Fixed-Effects Analysis of Panel Data'
  - 'Mathew P. White, Ian Alcock, Benedict W. Wheeler, Michael H. Depledge'
  - 2013-04-23
  - 10.1177/0956797612464659
  - ! 'Urbanization is a potential threat to mental health and well-being. Cross-sectional evidence suggests that living closer to urban green spaces, such as parks, is associated with lower mental distress. However, earlier research was unable to control for time-invariant heterogeneity (e.g., personality) and focused on indicators of poor psychological health. The current research advances the field by using panel data from over 10,000 individuals to explore the relation between urban green space and well-being (indexed by ratings of life satisfaction) and between urban green space and mental distress (indexed by General Health Questionnaire scores) for the same people over time. Controlling for individual and regional covariates, we found that, on average, individuals have both lower mental distress and higher well-being when living in urban areas with more green space. Although effects at the individual level were small, the potential cumulative benefit at the community level highlights the importance of policies to protect and promote urban green spaces for well-being.'
- - https://www.microsoft.com/en-us/research/uploads/prod/2016/12/How-to-Write-a-21st-Century-Proof.pdf
  - "How to Write a 21<sup>st</sup> Century Proof"
  - Leslie Lamport
  - 2011-11
  - 10.1007/s11784-012-0071-6
  - ! '<p>I was invited to give a talk at a celebration of the 80<sup>th</sup> birthday of Richard Palais. It was at a celebration of his 60<sup>th</sup> birthday that I first gave a talk about how to write a proof–a talk that led to [101]. So, I thought it would be fun to give the same talk, updated to reflect my 20 years of experience writing structured proofs. The talk was received much more calmly than my earlier one, and the mathematicians were open to considering that I might have something interesting to say about writing proofs. Perhaps in the last 20 years I have learned to be more persuasive, or perhaps the mathematicians in the audience had just grown older and calmer. In any case, they were still not ready to try changing how they write their own proofs.</p><p>My experience preparing and giving the talk made me realize it was time for a new paper on the subject. This paper is built around a simple example–a lemma from Michael Spivak’s calculus text. I tried to show how a mathematician can easily transform the proofs she now writes into structured proofs. The paper also briefly describes how formal structured proofs are written in <span class="smallcaps-auto">TLA</span>+, and an appendix contains a machine-checked proof of Spivak’s lemma. While mathematicians will not write formal proofs in the foreseeable future, I argue that learning how to write them is a good way to learn how to write rigorous informal proofs.</p>'
- - /docs/psychology/2008-alper.pdf
  - 'Anesthetizing the Public Conscience: Lethal Injection and Animal Euthanasia'
  - Ty Alper
  - 2008-08-05
  - ''
  - ! '<p>Lawyers challenging lethal injection on behalf of death row inmates have frequently argued that lethal injection protocols do not comport with standard practices for the euthanasia of animals. This article studies state laws governing animal euthanasia and concludes that many more states than have previously been recognized ban the use of paralyzing agents in animal euthanasia. In fact, 97.6% of lethal injection executions in this country have taken place in states that have banned, for use in animal euthanasia, the same drugs that are used in those states during executions. Moreover, a study of the legislative history of state euthanasia laws reveals that the concerns raised about paralyzing drugs in the animal euthanasia context are identical in many ways to the concerns that lawyers for death row inmates are currently raising about the use of those drugs in the lethal injection executions of human beings. This article takes an in depth look at animal euthanasia and its relationship to lethal injection by examining in Part I the history and origins of the paralyzing drugs that veterinarians and animal welfare experts refuse to allow in animal euthanasia; in Part II the standards of professional conduct for veterinary and animal shelter professionals; in Part <span class="smallcaps-auto">III</span>, the state laws and regulations governing animal euthanasia; and finally in Part IV, the legislative history that led to the enactment of the various states’ animal euthanasia laws and regulations. [Keywords: death penalty, lethal injection, animal euthanasia, capital punishment.]</p><p>In the late 1970s, when Texas was considering whether to adopt Oklahoma’s three-drug lethal injection formula for the execution of prisoners, Dr. Ralph Gray, the doctor in charge of medical care in Texas prisons, consulted with a Texas veterinarian named Dr. Gerry Etheredge.<sup>1</sup> Dr. Etheredge told Dr. Gray that veterinarians used an overdose of one drug, an anesthetic called sodium <a href="https://en.wikipedia.org/wiki/Pentobarbital">pentobarbital</a>, to euthanize animals and that it was a “very safe, very effective, and very cheap” method of euthanasia.<sup>2</sup> Dr. Etheredge remembers that Dr. Gray had only one objection to using a similar method to execute human beings. “He said it was a great idea,” Dr. Etheredge recalled, “except that people would think we are treating people the same way that we’re treating animals. He was afraid of a hue and cry.”<sup>3</sup> Texas rejected Dr. Etheredge’s one-drug, anesthetic-only recommendation and, in 1982, became the first state to actually use lethal injection—via the three-drug formula—as a method of execution.<sup>4</sup> This history is almost hard to believe in light of the fact that three decades later, death row inmates in Texas, as well as in nearly every other death penalty state, are challenging the three-drug formula on the grounds that the method is <em>less</em> reliable, and therefore <em>less</em> humane, than the method used to euthanize animals.<sup>5</sup></p><p>…It was through the use of <a href="https://en.wikipedia.org/wiki/Curare">curare</a> in vivisection that people began to consider the implications of what curare did <em>not</em> do, namely serve any anesthetic function. While curare inhibits all voluntary movement, it does nothing at all to affect consciousness, cognition, or the ability to feel pain.<sup>46</sup>…Dr. Hoggan, described the experience of a dog subjected to vivisection while paralyzed by curare.<sup>51</sup> Curare, he testified, was used to:</p><blockquote><p>render [the] dog helpless and incapable of any movement, even of breathing, which function was performed by a machine blowing through its windpipe. All this time, however, its intelligence, its sensitiveness, and its will, remained intact . . . . In this condition the side of the face, the interior of the belly, and the hip, were dissected out . . . continuously for ten consecutive hours . . . .<sup>52</sup></p></blockquote><p>In 1868, the Swedish physiologist A. F. Holmgren condemned curare as “the most cruel of all poisons.”<sup>53</sup>..in 1864 Claude Bernard offered another description of such a deceptively peaceful death:</p><blockquote><p>A gentle sleep seems to occupy the transition from life to death. But it is nothing of the sort; the external appearances are deceitful. . . . [I]n fact . . . we discover that this death, which appears to steal on in so gentle a manner and so exempt from pain is, on the contrary, accompanied by the most atrocious sufferings that the imagination of man can conceive.<sup>81</sup></p></blockquote><p>No inmate has ever survived a botched lethal injection, so we do not know what it feels like to lie paralyzed on a gurney, unable even to blink an eye, consciously suffocating, while potassium burns through the veins on its way to the heart, until it finally causes cardiac arrest. But aided by the accounts of people who have suffered conscious paralysis on the operating table, one can begin to imagine.</p>'
- - https://www.benkuhn.net/11
  - "The unreasonable effectiveness of one-on-ones"
  - Ben Kuhn
  - 2019-12-28
  - ''
  - ! '<p>When I started dating my partner, I quickly noticed that grad school was making her very sad. This was shortly after I’d started leading an engineering team at Wave, and so the “obvious” hypothesis to me was that the management (okay, “management”) one gets in graduate school is <em>totally ineffective</em>.</p><p>…One-on-ones are a management tradition at lots of tech companies, perhaps popularized by High Output Management,<sup>1</sup> in which a manager regularly schedules time with a direct report to discuss whatever the report wants. At Wave, I’ve had one-on-ones with my manager since the time I joined, and I found them incredibly useful for helping me improve at work… mine often included:</p><ul><li>Personal habits and self-improvements…</li><li>Project management…</li><li>Communication…</li><li>Alignment…</li><li>Uncertainties…</li></ul><p>…Obviously, the things Eve and I talked about weren’t exactly the same as my Wave one-on-ones, though they did share some common themes. Here are some of the things we talked about that Eve thinks made the biggest difference:</p><ul><li>Figuring out when she should be outlining new parts of her dissertation vs. fleshing out existing parts</li><li>Realizing that she was spending a lot of time reading crappy papers that she didn’t have to</li><li>Noticing when and why she was least productive (for instance, noticing when her procrastination was a coping strategy to avoid executing a plan that she didn’t really believe would succeed)</li><li>Asking for more frequent feedback from her adviser and dissertation committee</li><li>Being able to talk through anything stressful</li><li>Allowing herself space to “stare into the abyss” and confront uncomfortable possibilities (e.g. is it actually worth finishing her PhD?)</li></ul><p>In general, Eve summarized our one-on-ones as being a forcing function for her to fully decide on longer-term goals and then focus her work on the best way to achieve those goals, rather than getting too bogged down in whatever was right in front of her.</p><p>…The last thing this helped me realize is that specialists have a lot of non-specialized problems. In one sense, this is so well known it’s become a cliché—the engineer who just wants to crank out code all day, the philosophy professor with their head in the clouds. But the cliché doesn’t really describe me or most engineers or philosophers I know, who are broad-minded enough to be happy thinking about things outside our assigned specialty. Even for us, though, we can often increase our impact a lot by improving our generalized effectiveness.</p>'
- - /docs/biology/1974-auerbach.pdf
  - 'A simple procedure for the long-term cultivation of chicken embryos'
  - 'Robert Auerbach, Louis Kubai, David Knighton, Judah Folkman'
  - 1974-12
  - 10.1016/0012-1606(74)90316-9
  - ! 'A method is described which permits the growth of chicken embryos in petri dishes from the third to the 20<sup>th</sup> day of incubation. The procedure is relatively simple and has the advantage of providing ready access to the embryo and its membranes for tissue grafting, for introduction of teratogenic agents, and for microscopic observation of morphogenesis and growth...we found it essential to develop methods that would permit rapid and ready observation of large numbers of eggs under conditions facilitating examination with transmitted light, permitting time-lapse photography, and encouraging routine access to the grafted tissue. The procedures we describe in this report have now been used by us for growing several thousand eggs during the past several months...'
- - /docs/biology/2014-tahara.pdf
  - 'A Novel Shell-less Culture System for Chick Embryos Using a Plastic Film as Culture Vessels'
  - 'Yutaka Tahara, Katsuya Obara'
  - '2014'
  - '10.2141/jpsa.0130043'
  - ! 'The development of shell-less culture methods for bird embryos with high hatchability would be useful for the efficient generation of transgenic chickens, embryo manipulations, tissue engineering, and basic studies in regenerative medicine. To date, studies of culture methods for bird embryos include the whole embryo culture using narrow windowed eggshells, surrogate eggshells, and an artificial vessel using a gas-permeable membrane. However, there are no reports achieving high hatchability of >50% using completely artificial vessels. To establish a simple method for culturing chick embryos with high hatchability, we examined various culture conditions, including methods for calcium supplementation and oxygen aeration. In the embryo cultures where the embryos were transferred to the culture vessel after 55–56h incubation, more than 90% of embryos survived until day 17 when a polymethylpentene film was used as a culture vessel with calcium lactate and distilled water supplementations. The aeration of pure oxygen to the surviving embryos from day 17 yielded a hatchability of 57.1% (8 out of 14). Thus, we successfully achieved a high hatchability with this method in chicken embryo culture using an artificial vessel.'
- - https://www.technologyreview.com/s/615181/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/
  - "The messy, secretive reality behind OpenAI’s bid to save the world: The AI moonshot was founded in the spirit of transparency. This is the inside story of how competitive pressure eroded that idealism."
  - Karen Hao
  - 2020-02-17
  - ''
  - ! '<p>There are two prevailing technical theories about what it will take to reach <span class="smallcaps-auto">AGI</span>. In one, all the necessary techniques already exist; it’s just a matter of figuring out how to scale and assemble them. In the other, there needs to be an entirely new paradigm; deep learning, the current dominant technique in AI, won’t be enough. Most researchers fall somewhere between these extremes, but OpenAI has consistently sat almost exclusively on the scale-and-assemble end of the spectrum. Most of its breakthroughs have been the product of sinking dramatically greater computational resources into technical innovations developed in other labs.</p><p>Brockman and Sutskever deny that this is their sole strategy, but the lab’s tightly guarded research suggests otherwise. A team called “Foresight” runs experiments to test how far they can push AI capabilities forward by training existing algorithms with increasingly large amounts of data and computing power. For the leadership, the results of these experiments have confirmed its instincts that the lab’s all-in, compute-driven strategy is the best approach. For roughly six months, these results were hidden from the public because OpenAI sees this knowledge as its primary competitive advantage. Employees and interns were explicitly instructed not to reveal them, and those who left signed nondisclosure agreements. It was only in January that the team, without the usual fanfare, <a href="https://arxiv.org/abs/2001.08361#openai" title="&#39;Scaling Laws for Neural Language Models&#39;, Kaplan et al 2020">quietly posted a paper</a> on one of the primary open-source databases for AI research. People who experienced the intense secrecy around the effort didn’t know what to make of this change. Notably, <a href="https://arxiv.org/abs/1909.12673" title="&#39;A Constructive Prediction of the Generalization Error Across Scales&#39;, Rosenfeld et al 2019">another paper with similar results</a> from different researchers had been posted a month earlier.</p><p>…One of the biggest secrets is the project OpenAI is working on next. Sources described it to me as the culmination of its previous four years of research: an AI system trained on images, text, and other data using massive computational resources. A small team has been assigned to the initial effort, with an expectation that other teams, along with their work, will eventually fold in. On the day it was announced at an all-company meeting, interns weren’t allowed to attend. People familiar with the plan offer an explanation: the leadership thinks this is the most promising way to reach <span class="smallcaps-auto">AGI</span>.</p><p>…The man driving OpenAI’s strategy is Dario Amodei, the ex-Googler who now serves as research director. When I meet him, he strikes me as a more anxious version of Brockman. He has a similar sincerity and sensitivity, but an air of unsettled nervous energy. He looks distant when he talks, his brows furrowed, a hand absentmindedly tugging his curls. Amodei divides the lab’s strategy into two parts. The first part, which dictates how it plans to reach advanced AI capabilities, he likens to an investor’s “portfolio of bets.” Different teams at OpenAI are playing out different bets. The language team, for example, has its money on a theory postulating that AI can develop a significant understanding of the world through mere language learning. The robotics team, in contrast, is advancing an opposing theory that intelligence requires a physical embodiment to develop. As in an investor’s portfolio, not every bet has an equal weight. But for the purposes of scientific rigor, all should be tested before being discarded. Amodei points to <span class="smallcaps-auto">GPT</span>-2, with its remarkably realistic auto-generated texts, as an instance of why it’s important to keep an open mind. “Pure language is a direction that the field and even some of us were somewhat skeptical of,” he says. “But now it’s like, ‘Wow, this is really promising.’” Over time, as different bets rise above others, they will attract more intense efforts. Then they will cross-pollinate and combine. The goal is to have fewer and fewer teams that ultimately collapse into a single technical direction for <span class="smallcaps-auto">AGI</span>. This is the exact process that OpenAI’s latest top-secret project has supposedly already begun.</p>'
- - https://www.newsweek.com/openai-text-generator-gpt-2-video-game-walkthrough-most-tedious-1488334
  - "OpenAI Text Generator <span class=\"smallcaps-auto\">GPT</span>-2 Creates Video Game Walkthrough for 'Most Tedious Game in History'"
  - Andrew Whalen (Newsweek)
  - 2020-02-20
  - ''
  - ! '<p>When OpenAI announced the automatic text generator <span class="smallcaps-auto">GPT</span>-2 in February of 2019, its language model had a simple objective: predict the next word. Since its release—and despite high computational barriers—programmers, tinkerers and artificial intelligence researchers have explored creative ways to use the advanced language model, developing applications for <span class="smallcaps-auto">GPT</span>-2 far beyond simple text generation. In January, AI researcher Shawn Presser demonstrated how <span class="smallcaps-auto">GPT</span>-2 can empower video game design, beginning with “the most tedious game in history.” “You can prompt the model with whatever text you want, and it will try to guess how to complete it,” Presser told Newsweek.</p><p>…Using thousands of game walkthroughs and <span class="smallcaps-auto">FAQ</span>s, scraped from sites around the web (a 50 megabyte data set provided by Twitter’s <span class="citation" data-cites="me_irl">@me_irl</span>), Presser prompted <span class="smallcaps-auto">GPT</span>-2 to generate its own walkthroughs. The result is walkthroughs of video games that never existed; guides to adventures no one has ever programmed. Presser described one of <span class="smallcaps-auto">GPT</span>-2’s creations as “a walkthrough for the most tedious game in history”: a dense set of instructions for something that sounds a lot like a first-person shooter. “When the room opens, go forward. You should find a rocket launcher,” the walkthrough begins. “Push the switch and a door opens. Take cover in the corner and shoot the guard. The door will close when he dies. Now jump over the gap and kill the guards. In the next area is a switch. Push it and the door will open. In the next area is a scientist. Kill him. Go back to the previous room and push the switch. Open the next door. In the next room is a scientist. Kill him.”</p><p>…But renting a “<span class="smallcaps-auto">TPU</span> pod” for cloud computing can cost millions, making them prohibitively expensive for all but large companies—organizations unlikely to try out playful experiments. So Presser developed a technique he dubbed “swarm training,” to employ 80 individual <span class="smallcaps-auto">TPU</span>s on a single data set. “In swarm training, we can run dozens or hundreds of <span class="smallcaps-auto">TPU</span>s in a loose network which swaps updates on the fly,” Presser told Newsweek. “It’s chaotic, but it winds up working pretty well: it’s much faster than using just a few <span class="smallcaps-auto">TPU</span>s, but much cheaper than renting entire <span class="smallcaps-auto">TPU</span> pods. We’re hopeful that swarm training will be very useful to other researchers.”</p><p>…<span class="smallcaps-auto">GPT</span>-2 has also proved adept at gaming functions beyond just generating games-related text. Presser previously collaborated with technology writer and researcher Gwern Branwen to train <span class="smallcaps-auto">GPT</span>-2 to play chess, by providing it hours of “training” in legal chess moves (using standard notation) and asking it to output its own responses. After hours of training <span class="smallcaps-auto">GPT</span>-2 on which responses are valid moves in an ongoing chess game and which responses are nonsensical, the text generation engine was eventually able to complete a full game.</p><p>While it may be years before game designers are employing text generating language models in their designs, Presser said he already sees potential practical applications. “If you prompt the model with descriptions of some spells from your tabletop campaign, the model can generate new spells,” Presser said. “It’s quite versatile.” For example, <em>Dungeons &amp; Dragons</em> players could input spells like Fireball, including a description of its HP damage, and get back from <span class="smallcaps-auto">GPT</span>-2 new attack spells to use in tabletop roleplaying sessions. “I think there’s an opportunity to build new indie games using <span class="smallcaps-auto">GPT</span>-2,” Presser said. “Imagine making a mod for <em>Skyrim</em> that uses <span class="smallcaps-auto">GPT</span>-2 to generate new quests. You’d have infinite replayability. It’d be like <em>AI Dungeon 2</em> in 3D.”</p>'
- - https://www.bmj.com/content/367/bmj.l6491
  - "Physical activity and weight following car ownership in Beijing, China: quasi-experimental cross sectional study"
  - Michael L Anderson, Fangwen Lu Jun Yang
  - 2019-12-18
  - 10.1136/bmj.l6491
  - ! '<p><em>Objective</em>: To determine the implications of car ownership for physical activity and weight in a global city.</p><p><em>Design</em>: Quasi-experimental cross sectional study.</p><p><em>Setting</em>: Beijing, China, 2011-15.</p><p><em>Participants</em>: People aged 18 and older from a random sample of households who had entered a permit lottery to purchase a vehicle between January 2011 and November 2015.</p><p><em>Interventions</em>: Permit allowing purchase of a vehicle within six months of permit issuance.</p><p><em>Main outcome measures</em>: Transit use (number of subway and bus rides each week), physical activity (minutes of walking or bicycling each day), and weight, measured once in early 2016.</p><p><em>Results</em>: Of 937 people analysed in total, 180 had won a permit to purchase a new vehicle. Winning the permit lottery resulted in the purchase of an additional vehicle 91% of the time (95% confidence interval 89% to 94%; <em>p</em>&lt;0.001). About five years after winning, winners took significantly fewer weekly transit rides (−2.9 rides (−5.1 to −0.7); <em>p</em>=0.01) and walked and cycled significantly less (−24.2 minutes (−40.3 to −8.1); <em>p</em>=0.003) than those who did not win the lottery. Average weight did not change significantly between lottery winners and losers. Among those aged 50 and older, however, winners’ weight had increased relative to that of losers (10.3 kg (0.5 to 20.2); <em>p</em>=0.04) 5.1 years after winning.</p><p><em>Conclusions</em>: These data indicate that vehicle ownership in a rapidly growing global city led to long term reductions in physical activity and increase in weight. Continuing increases in car use and ownership in developing and middle income countries could adversely affect physical health and obesity rates.</p>'
- - https://techscience.org/a/2019121801/
  - "Deepfake Bot Submissions to Federal Public Comment Websites Cannot Be Distinguished from Human Submissions"
  - Max Weiss
  - 2019-12-18
  - ''
  - ! '<p>Publicly available artificial intelligence methods can generate an enormous volume of original, human speech-like topical text “Deepfake Text”) that is not based on conventional search-and-replace patterns. I created a computer program (a bot) that generated and submitted 1,001 deepfake comments regarding a Medicaid reform waiver to a federal public comment website, stopping submission when these comments comprised more than half of all submitted comments. I then formally withdrew the bot comments. When humans were asked to classify a subset of the deepfake comments as human or bot submissions, the results were no better than would have been gotten by random guessing. Federal public comment websites currently are unable to detect Deepfake Text once submitted, but technological reforms (e.g., <span class="smallcaps-auto">CAPTCHA</span>s) can be implemented to help prevent massive numbers of submissions by bots.</p>'
- - https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/2558740/19883_FULLTEXT.pdf?sequence=1
  - 'Cybercrime Economy: A Netnographic Study on the Dark Net Ecosystem for Ransomware'
  - Yara Bayoumy
  - 2018-06
  - ''
  - ! '<p>Black hat hackers are far more shrewd than the public’s stereotypical perception of them. They are no longer script kiddies who are trying to impress their social circles, but skilled businessmen with the general aim to profit from exploitative attacks. Very little research has been done on how the cyber-criminals involved make decisions based on profit margin calculations.</p><p>The dark net provides the perfect environment to commit cyber crimes without being tracked down by law enforcement. An entire economy has emerged in the dark net as a result of transactions of illegal goods and services supported by cryptocurrencies. The social structure of the members in the dark net is strong enough to survive any intrusions made by law enforcement.</p><p>The dynamic shifts in the field of cyber security has encouraged many researchers to pro-pose different methodologies that capture the true intent of an attacker. In this report, a netnographic study was done to obtain data useful for threat predictions and attacker profiling. This included observations of the online marketplaces in the dark net and the re-searcher’s reflections on the social communications between the different actors involved in the creation and distribution of ransomware. Data collected from this study was also used to deduce a cost-benefit framework.</p>'
- - /docs/sr/2017-rhumorbarbe.pdf
  - "Technical Note: Characterising the online weapons trafficking on cryptomarkets"
  - Damien Rhumorbarbe, Denis Werner, Quentin Gilliéron, Ludovic Staehli, Julian Broséus, Quentin Rossy
  - 2018-07
  - 10.1016/j.forsciint.2017.12.0080379-0738
  - ! '<p>Weapons related webpages from nine cryptomarkets were manually duplicated in February 2016. Information about the listings (i.e. sales proposals) and vendors’ profiles were extracted to draw an overview of the actual online trafficking of weapons. Relationships between vendors were also inferred through the analysis of online digital traces and content similarities.Weapons trafficking is mainly concentrated on two major cryptomarkets. Besides, it accounts for a very small proportion of the illicit trafficking on cryptomarkets compared to the illicit drugs trafficking. Among all weapon related listings (<em>n</em> = 386), firearms only account for approximately 25% of sales proposal since the proportion of non-lethal and melee weapons is important (around 46%). Based on the recorded pseudonyms, a total of 96 vendor profiles were highlighted. Some pseudonyms were encountered on several cryptomarkets, suggesting that some vendors may manage accounts on different markets. This hypothesis was strengthened by comparing pseudonyms to online traces such as <span class="smallcaps-auto">PGP</span> keys, images and profiles descriptions. Such a method allowed to estimate more accurately the number of vendors offering weapons across cryptomarkets. Finally, according to the gathered data, the extent of the weapons trafficking on the cryptomarkets appear to be limited compared to other illicit goods. [Keywords: Darknet markets; Firearms; Ammunition; Digital traces; Forensic intelligence; Internet traces.]</p><p>…The selected markets are: Aflao marketplace (<span class="smallcaps-auto">AFL</span>), AlphaBay (<span class="smallcaps-auto">ALB</span>), Dr D’s multilingual market (<span class="smallcaps-auto">DDM</span>), Dream market(<span class="smallcaps-auto">DMA</span>), French Darknet (<span class="smallcaps-auto">FRE</span>), The Real Deal (<span class="smallcaps-auto">TRD</span>), Oasis (<span class="smallcaps-auto">OAS</span>), Outlaw market (<span class="smallcaps-auto">OUT</span>), Valhalla (aka Silkkitie) (<span class="smallcaps-auto">VAL</span>).</p>'
- - https://www.sfu.ca/~palys/Cheung-2019-WeMustWorkTogetherForTheGoodOfAll.pdf
  - "'We must work together for the good of all': An examination of conflict management on two popular cryptomarkets"
  - Jeremy Cheung
  - '2019'
  - ''
  - ! '<p>For nearly ten years, illicit markets have taken advantage of the anonymity and convenience afforded by the dark web. Despite its benefits, however, this anonymity has also resulted in difficulties establishing trust and managing conflict on cryptomarkets. A number of common features have been implemented to serve this function. This study was conducted to contribute to the growing literature on conflict management in cryptomarkets through a thematic analysis of publicly available content from two popular cryptomarkets [Tochka &amp; Wall Street]. Of particular interest is whether conflict management has changed following the closure of many popular cryptomarkets and how conflicts are managed differently in relation to unique types of transaction or delivery offered by the marketplaces under study. Findings indicate that, rather than evolving to become different from those marketplaces that have been shut down, the two marketplaces under study have slowly changed to become more like them, based on suggestions from users. Implications for law enforcement are discussed.</p>'
- - https://link.springer.com/article/10.1007/s11406-020-00189-3
  - 'Cognitive Enhancement and Network Effects: how Individual Prosperity Depends on Group Traits'
  - Jonathan Anomaly, Garett Jones
  - 2020-02-22
  - 10.1007/s11406-020-00189-3
  - ! "A central debate in bioethics is whether parents should try to influence the genetic basis of their children’s traits. We argue that the case for using mate selection, embryo selection, and other interventions to enhance heritable traits like intelligence is strengthened by the fact that they seem to have positive network effects. These network effects include increased cooperation in collective action problems, which contributes to social trust and prosperity. We begin with an overview of evidence for these claims, and then argue that if individual welfare is largely a function of group traits, parents should try to preserve or enhance cognitive traits that have positive network effects."
- - https://www.pnas.org/content/109/49/19959.full
  - "Perceptual convergence of multi-component mixtures in olfaction implies an olfactory white"
  - Tali Weiss, Kobi Snitz, Adi Yablonka, Rehan M. Khan, Danyel Gafsou, Elad Schneidman, Noam Sobel
  - 2012-12-04
  - 10.1073/pnas.1208110109
  - ! 'In vision, two mixtures, each containing an independent set of many different wavelengths, may produce a common color percept termed “white.” In audition, two mixtures, each containing an independent set of many different frequencies, may produce a common perceptual hum termed “white noise.” Visual and auditory whites emerge upon two conditions: when the mixture components span stimulus space, and when they are of equal intensity. We hypothesized that if we apply these same conditions to odorant mixtures, “whiteness” may emerge in olfaction as well. We selected 86 molecules that span olfactory stimulus space and individually diluted them to a point of about equal intensity. We then prepared various odorant mixtures, each containing various numbers of molecular components, and asked human participants to rate the perceptual similarity of such mixture pairs. We found that as we increased the number of non-overlapping, equal-intensity components in odorant mixtures, the mixtures became more similar to each other, despite not having a single component in common. With ∼30 components, most mixtures smelled alike. After participants were acquainted with a novel, arbitrarily named mixture of ∼30 equal-intensity components, they later applied this name more readily to other novel mixtures of ∼30 equal-intensity components spanning stimulus space, but not to mixtures containing fewer components or to mixtures that did not span stimulus space. We conclude that a common olfactory percept, “olfactory white,” is associated with mixtures of ∼30 or more equal-intensity components that span stimulus space, implying that olfactory representations are of features of molecules rather than of molecular identity.'
- - https://github.com/gildas-lormeau/SingleFile/
  - SingleFile
  - Gildas Lormeau et al
  - ''
  - ''
  - ! '<p>SingleFile is a Web Extension (and a <span class="smallcaps-auto">CLI</span> tool) compatible with Chrome, Firefox (Desktop and Mobile), Microsoft Edge, Vivaldi, Brave, Waterfox, Yandex browser, and Opera. It helps you to save a complete web page into a single <span class="smallcaps-auto">HTML</span> file.</p><p>[Keywords: browser, archive, auto-save, chrome, add-on, Firefox, offline-reading, <span class="smallcaps-auto">OSINT</span>, web-extension, Chrome-extension, Firefox-addon, Puppeteer, Selenium, NodeJS, snapshot, screenshot, Javascript, <span class="smallcaps-auto">CLI</span>, annotations.] …</p><h2><a id="user-content-demo" class="anchor" aria-hidden="true" href="https://github.com/gildas-lormeau/SingleFile/#demo"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Demo</h2><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/gildas-lormeau/SingleFile-Demos/blob/master/demo-sf.gif"><img src="/images/gildaslormeau-singlefile-archivingtutorialanimation.mp4" alt="https://github.com/gildas-lormeau/SingleFile-Demos/raw/master/demo-sf.gif" style="max-width:100%;"></a></p><h2><a id="user-content-install" class="anchor" aria-hidden="true" href="https://github.com/gildas-lormeau/SingleFile/#install"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Install</h2><p>SingleFile can be installed on:</p><ul><li>Firefox: <a href="https://addons.mozilla.org/firefox/addon/single-file" rel="nofollow">https://addons.mozilla.org/firefox/addon/single-file</a></li><li>Chrome: <a href="https://chrome.google.com/extensions/detail/mpiodijhokgodhhofbcjdecpffjipkle" rel="nofollow">https://chrome.google.com/extensions/detail/mpiodijhokgodhhofbcjdecpffjipkle</a></li><li>Microsoft Edge: <a href="https://microsoftedge.microsoft.com/addons/detail/efnbkdcfmcmnhlkaijjjmhjjgladedno" rel="nofollow">https://microsoftedge.microsoft.com/addons/detail/efnbkdcfmcmnhlkaijjjmhjjgladedno</a></li></ul>'
- - https://casual-effects.com/markdeep
  - "Markdeep"
  - Morgan McGuire et al
  - '2015'
  - ''
  - ! '<p>[Markdeep is a single-file JavaScript Markdown→<span class="smallcaps-auto">HTML</span> compiler: it can be inserted into a Markdown file, which will automatically render it inside a visiting web browser. It is highly opinionated and featureful, including a wide variety of automatic symbol replacements, ‘admonitions’, embedded <span class="smallcaps-auto">ASCII</span> diagrams, calendars, todo task lists, multi-columns, etc.]</p><p>Markdeep is a technology for writing plain text documents that will look good in any web browser, whether local or remote. It supports diagrams, calendars, equations, and other features as extensions of Markdown syntax. Markdeep is free and easy to use. It doesn’t require a plugin or Internet connection. Your document never leaves your machine and there’s nothing to install. Just start writing in your favorite text editor. You don’t have to export, compile, or otherwise process your document. Here’s an example of a text editor and a browser viewing the same file simultaneously:…Markdeep is ideal for design documents, specifications, <span class="smallcaps-auto">README</span> files, code documentation, lab reports, blogs, and technical web pages. Because the source is plain text, Markdeep works well with software development toolchains.</p><p>Markdeep was created by Morgan McGuire (Casual Effects) with inspiration from John Gruber’s Markdown and Donald Knuth’s and Leslie Lamport’s LaTeX. Unique features:</p><p>Diagrams · Insert documents into one another · LaTeX equation typesetting and numbering · Table of contents · Reference images and embedded images · Document title and subtitle formatting · Schedules and calendars · Section numbering and references · Figure, listing, and table numbering and references · Smart quotes · Embedded video · <span class="smallcaps-auto">CSS</span> stylesheets · Page breaks · En dash, em dash, ×, minus, and degrees · Attributes on links · Unindexed sections · Works in any browser by adding one line to the bottom of a text document · Fallback to <span class="smallcaps-auto">ASCII</span> in a browser if you have neither the local file nor Internet access · Optionally process server-side with <code>node.js</code> · Optionally batch process to <span class="smallcaps-auto">PDF</span> with headless browser flags · <span class="smallcaps-auto">HTML</span> export to static content using <code>?export</code> in the <span class="smallcaps-auto">URL</span> or “Rasterizer”</p>'
- - https://casual-effects.com/markdeep/features.md.html#basicformatting/admonitions
  - "Markdeep Features: Admonitions"
  - Morgan McGuire et al
  - ''
  - ''
  - ! 'Admonitions are small break-out boxes with notes, tips, warnings, etc. for the reader. They begin with a title line of a pattern of three exclamation marks, an optional <span class=\"smallcaps-auto\">CSS</span> class, and an optional title. All following lines that are indented at least three spaces are included in the body, which may include multiple paragraphs. The default stylesheet provides classes for “note” (default), “tip”, “warning”, and “error”.'
- - https://casual-effects.com/markdeep/features.md.html#multiplecolumns
  - "Markdeep Features: Multiple Columns"
  - Morgan McGuire et al
  - ''
  - ''
  - ! 'You can use the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Columns/Using_multi-column_layouts"><span class=\"smallcaps-auto\">CSS</span> columns style</a> to make an <span class=\"smallcaps-auto\">HTML</span> multicolumn block. Then, just use regular Markdeep within it and the browser will automatically apply your multicolumn layout... multi-column only works well if you know that you have very short sections (as in this example), or if you were planning on printing to separate pages when done.'
- - https://link.springer.com/article/10.1007/s00439-019-02014-8
  - "Is population structure in the genetic biobank era irrelevant, a challenge, or an opportunity?"
  - Daniel John Lawson, Neil Martin Davies, Simon Haworth, Bilal Ashraf, Laurence Howe, Andrew Crawford, Gibran Hemani, George Davey Smith, Nicholas John Timpson
  - 2019-04-27
  - '10.1007/s00439-019-02014-8'
  - ! 'Replicable genetic association signals have consistently been found through genome-wide association studies in recent years. The recent dramatic expansion of study sizes improves power of estimation of effect sizes, genomic prediction, causal inference, and polygenic selection, but it simultaneously increases susceptibility of these methods to bias due to subtle population structure. Standard methods using genetic principal components to correct for structure might not always be appropriate and we use a simulation study to illustrate when correction might be ineffective for avoiding biases. New methods such as trans-ethnic modeling and chromosome painting allow for a richer understanding of the relationship between traits and population structure. We illustrate the arguments using real examples (stroke and educational attainment) and provide a more nuanced understanding of population structure, which is set to be revisited as a critical aspect of future analyses in genetic epidemiology. We also make simple recommendations for how problems can be avoided in the future. Our results have particular importance for the implementation of <span class=\"smallcaps-auto\">GWAS</span> meta-analysis, for prediction of traits, and for causal inference.'
- - https://www.popularmechanics.com/flight/drones/a30795266/cia-robot-dragonfly/
  - "In the 1970s, the <span class=\"smallcaps-auto\">CIA</span> Created a Robot Dragonfly Spy. Now We Know How It Works. Newly released documents show how the <span class=\"smallcaps-auto\">CIA</span> created one of the world's first examples of insect robotics."
  - David Hambling (Popular Mechanics)
  - 2020-02-18
  - ''
  - ! '<p>…So the agency turned to retroreflectors, tiny glass beads that reflect laser light (in this case, a laser beam) back at its source…In addition to being incredibly maneuverable, dragonflies are exceptionally good gliders compared to other insects, which helps them conserve energy on long flights. The scientist brought in some specimens, and when Adkins pressed him on the issue, “the old fellow plucked the insect from its perch and tossed it into the air,” Adkins wrote. “It made about two circuits and landed nicely on the desk.”</p><p>The demonstration convinced Adkins, but the team still needed to figure out how to replicate a dragonfly’s wings, which flap 1,800 times per minute. To pull this off, scientists used a tiny fluidic oscillator, a device with no moving parts that’s completely driven by gas produced by lithium nitrate crystals. When initial tests showed that the prototype couldn’t carry the required 0.2 gm payload, designers added additional thrust by venting exhaust backward, much like jet propulsion. After a quick dragonfly-inspired paint job, the drone was ready for (covert) action, weighing just under a gram. Its glittering ‘eyes’ were the glass retroreflector beads destined to snoop on unsuspecting targets.</p><p>…While the <span class="smallcaps-auto">CIA</span> now had its robo-bug, it still needed a way to control it. Radio control was out of the question because any extra weight would doom the small insectothopter. So <span class="smallcaps-auto">CIA</span> scientists turned to the same lasers used for the retroreflectors. This was a portable laser unit, known as <span class="smallcaps-auto">ROME</span>, that produced an invisible infrared beam. The idea was that the laser would heat a bimetallic strip that would then open or close the dragonfly’s exhaust. While effectively throttling the ‘engine,’ another laser—acting like a kind of rudder—would then steer the drone to its desired destination. With its gas-pumping engine and laser-based navigation system, the insectothopter could fly for only 60 seconds. But this was more than enough to get the dragonfly—and its payload—to a target some 200 meters away.</p><p>…The biggest problem with the insectothopter’s design was that an operator had to keep a laser manually trained on the drone during flight. Easily done in a static wind tunnel, less so in blustery and unpredictable conditions…In theory, the insectothopter could still be flown in less than 7<span class="smallcaps-auto">MPH</span> winds, but “the ultimate demonstration of controlled powered flight has not yet been achieved,” Adkins ultimately reported. “Though the flight tests were impressive, control in any kind of crosswind was too difficult.”</p>'
- - https://greatpoetryexplained.blogspot.com/2016/03/a-martian-sends-postcard-home-by-craig.html
  - "A Martian Sends a Postcard Home [with commentary]"
  - Craig Raine, John Welford
  - '1977/2016-03-17'
  - ''
  - ! '<p>Craig Raine is a British poet, born in 1944, who is known as an exponent of “Martian poetry”, by which is meant the expression of familiar concepts in unfamiliar ways. The term derived from his poem “A Martian Sends a Postcard Home”, which was first published in the <em>New Statesman</em> in 1977.</p><p>One does not need to believe in Martians to enjoy this poem, only in the concept of being able to perceive human behaviour and institutions with complete detachment, as though one had never come across them before. Or rather, as Craig Raine does, to express one’s impressions of humanity in terms that seem strange and puzzling at first and need a little working out before one realises what it is to which the poet is referring. It is in working out the puzzles that the reader derives a lot of fun from this poem.</p>'
- - /docs/psychology/2006-polidoro-houdinisimpossibledemonstration.html
  - "Notes on a Strange World: Houdini’s Impossible Demonstration"
  - Massimo Polidoro (Skeptical Inquirer)
  - '2006-07'
  - ''
  - ! '<p>[Account of a magic trick demonstrated by Harry Houdini to Sir Arthur Conan Doyle (as related by Houdini’s lawyer in his memoirs), which Houdini intended to caution Doyle in his enthusiasm for seances/mediums/paranormal by showing how Doyle could be fooled. Doyle was fooled, but apparently did not believe Houdini’s assurance that it was merely a trick as Houdini did not disclose <em>how</em> he did it.</p><p>The trick involved a black slate writing board suspended in the middle of a room by wires while a cork ball soaked in white ink, one of several Doyle cut open to prove there was no magnets or electronics involved; Doyle went outside and wrote down a phrase (“Mene Mene Tekel Upharsin”) on a piece of paper; on returning, Doyle showed the phrase to Houdini, and then Doyle placed the cork ball against the slate; the ball did not fall but stuck to the slate, and, moving on its own, wrote out the phrase.</p><p>The trick was never disclosed, but was almost certainly based on a trick Houdini bought from a fellow magician &amp; friend, Max Berol. In this trick, the magician reads the paper slip and secretly signals it to an assistant, possibly steganographically via pre-arranged gestures or choices of words in their patter; the authentic cork ball is swapped for a magnetic one via sleight-of-hand; it is then held against the slate board by a long thin rod which moves solely in the space ‘behind’ the board where the subject cannot see, by the assistant who is hidden behind a wall and manipulating the rod through a small hatch; the assistant, having been told the phrase by the magician’s encoded message, can now write the phrase backwards on the board by carefully moving the rod.]</p>'
- - https://www.wired.com/story/ai-helps-warehouse-bots-pick-new-skills/
  - "AI Helps Warehouse Robots Pick Up New Tricks: Backed by machine learning luminaries, Covariant.ai's bots can handle jobs previously needing a human touch"
  - Will Knight (Wired)
  - 2020-01-29
  - ''
  - ! '<p>Covariant.ai has developed a platform that consists of off-the-shelf robot arms equipped with cameras, a special gripper, and plenty of computer power for figuring out how to grasp objects tossed into warehouse bins. The company, emerging from stealth Wednesday, announced the first commercial installations of its AI-equipped robots: picking boxes and bags of products for a German electronics retailer called Obeta.</p><p>…The company was founded in 2017 by Pieter Abbeel, a prominent AI professor at UC Berkeley, and several of his students. Abbeel pioneered the application of machine learning to robotics, and he made a name for himself in academic circles in 2010 by developing a robot capable of folding laundry (albeit very slowly). Covariant uses a range of AI techniques to teach robots how to grasp unfamiliar objects. These include reinforcement learning, in which an algorithm trains itself through trial and error, a little like the way animals learn through positive and negative feedback…Besides reinforcement learning, Abbeel says his company’s robots make use of imitation learning, a way of learning by observing demonstrations of perception and grasping by another algorithm, and meta-learning, a way of refining the learning process itself. Abbeel says the system can adapt and improve when a new batch of items arrive. “It’s training on the fly,” he says. “I don’t think anybody else is doing that in the real world.”</p><p>…But reinforcement learning is finicky and needs lots of computer power. “I used to be skeptical about reinforcement learning, but I’m not anymore,” says Hinton, a professor at the University of Toronto who also works part time at Google. Hinton says the amount of computer power needed to make reinforcement learning work has often seemed prohibitive, so it is striking to see commercial success. He says it is particularly impressive that Covariant’s system has been running in a commercial setting for a prolonged period.</p><p>…Peter Puchwein, vice president of innovation at Knapp, says he is particularly impressed by the way Covariant.ai’s robots can grasp even products in transparent bags, which can be difficult for cameras to perceive. “Even as a human being, if you have a box with 20 products in poly bags, it’s really hard to take just one out,” he says…Late last year, the international robot maker <span class="smallcaps-auto">ABB</span> ran a contest. It invited 20 companies to design software for its robot arms that could sort through bins of random items, from cubes to plastic bags filled with other objects. Ten of the companies were based in Europe, and the other half were in the United States. Most came nowhere close to passing the test. A few could handle most tasks but failed on the trickier cases. Covariant was the only company that could handle every task as swiftly and efficiently as a human. “We were trying to find weaknesses,” said Marc Segura, managing director of service robotics at <span class="smallcaps-auto">ABB</span>. “It is easy to reach a certain level on these tests, but it is super difficult not to show any weaknesses.”</p>'
- - https://openai.com/blog/science-of-ai/
  - "How AI Training Scales"
  -  Sam McCandlish, Jared Kaplan, Dario Amodei (OpenAI)
  - 2018-12-14
  - ''
  - ! '<p><a href="https://arxiv.org/abs/1812.06162" title="&#39;An Empirical Model of Large-Batch Training&#39;, McCandlish et al 2018">We’ve discovered</a> that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and systematized.</p><blockquote><p>In an increasing number of domains it has been demonstrated that deep learning models can be trained using relatively large batch sizes without sacrificing data efficiency. However the limits of this massive data parallelism seem to differ from domain to domain, ranging from batches of tens of thousands in ImageNet to batches of millions in RL agents that play the game Dota 2. To our knowledge there is limited conceptual understanding of why these limits to batch size differ or how we might choose the correct batch size in a new domain. In this paper, we demonstrate that a simple and easy-to-measure statistic called the <em>gradient noise scale</em> predicts the largest useful batch size across many domains and applications, including a number of supervised learning datasets (<span class="smallcaps-auto">MNIST</span>, <span class="smallcaps-auto">SVHN</span>, <span class="smallcaps-auto">CIFAR</span>-10, ImageNet, Billion Word), reinforcement learning domains (Atari and Dota), and even generative model training (autoencoders on <span class="smallcaps-auto">SVHN</span>). We find that the noise scale increases as the loss decreases over a training run and depends on the model size primarily through improved model performance. Our empirically-motivated theory also describes the tradeoff between compute-efficiency and time-efficiency, and provides a rough model of the benefits of adaptive batch-size training.</p></blockquote><figure><img src="/images/ai/2018-mccandlish-openai-howaitrainingscales-gradientnoisescale-summary3-scalevsbatchsize.svg" alt="The gradient noise scale (appropriately averaged over training) explains the vast majority (R<sup>2</sup> = 80%) of the variation in critical batch size over a range of tasks spanning six orders of magnitude. Batch sizes are measured in either number of images, tokens (for language models), or observations (for games). (https://openai.com/content/images/2018/12/noise-summary-3.svg)" /><figcaption>The gradient noise scale (appropriately averaged over training) explains the vast majority (R<sup>2</sup> = 80%) of the variation in critical batch size over a range of tasks spanning six orders of magnitude. Batch sizes are measured in either number of images, tokens (for language models), or observations (for games).</figcaption></figure><p>…We have found that by measuring the gradient noise scale, a simple statistic that quantifies the signal-to-noise ratio of the network gradients, we can approximately predict the maximum useful batch size. Heuristically, the noise scale measures the variation in the data as seen by the model (at a given stage in training). When the noise scale is small, looking at a lot of data in parallel quickly becomes redundant, whereas when it is large, we can still learn a lot from huge batches of data…We’ve found it helpful to visualize the results of these experiments in terms of a tradeoff between wall time for training and total bulk compute that we use to do the training (proportional to dollar cost). At very small batch sizes, doubling the batch allows us to train in half the time without using extra compute (we run twice as many chips for half as long). At very large batch sizes, more parallelization doesn’t lead to faster training. There is a “bend” in the curve in the middle, and the gradient noise scale predicts where that bend occurs.</p><figure><img src="/images/ai/2018-mccandlish-openai-howaitrainingscales-gradientnoisescale-paretofrontier.svg" alt="Increasing parallelism makes it possible to train more complex models in a reasonable amount of time. We find that a Pareto frontier chart is the most intuitive way to visualize comparisons between algorithms and scales. (https://openai.com/content/images/2018/12/basic-scaling-1.svg)" /><figcaption>Increasing parallelism makes it possible to train more complex models in a reasonable amount of time. We find that a Pareto frontier chart is the most intuitive way to visualize comparisons between algorithms and scales.</figcaption></figure><p>…more powerful models have a higher gradient noise scale, but only because they achieve a lower loss. Thus, there’s some evidence that the increasing noise scale over training isn’t just an artifact of convergence, but occurs because the model gets better. If this is true, then we expect future, more powerful models to have higher noise scale and therefore be more parallelizable. Second, tasks that are subjectively more difficult are also more amenable to parallelization…we have evidence that more difficult tasks and more powerful models on the same task will allow for more radical data-parallelism than we have seen to date, providing a key driver for the continued fast exponential growth in training compute.</p>'
- - https://www.nature.com/articles/s41598-020-59256-0
  - "The behavioral, cellular and immune mediators of <span class=\"smallcaps-auto\">HIV</span>-1 acquisition: New insights from population genetics"
  - Timothy R. Powell, Rodrigo R. R. Duarte, Matthew Hotopf, Stephani L. Hatch, Miguel de Mulder Rougvie, Gerome D. Breen, Cathryn M. Lewis, Douglas F. Nixon
  - 2020-02-24
  - 10.1038/s41598-020-59256-0
  - ! '<p>Millions are exposed to the human immunodeficiency virus type 1 (<span class="smallcaps-auto">HIV</span>-1) every year, but not all acquire the virus, suggesting a potential role for host genetics in the moderation of <span class="smallcaps-auto">HIV</span>-1 acquisition. Here, we analyzed summary statistics from the largest genome-wide association study of <span class="smallcaps-auto">HIV</span>-1 acquisition to-date, consisting of 6,334 infected patients and 7,247 population controls, to advance our understanding of the genetic mechanisms implicated in this trait. We found that <span class="smallcaps-auto">HIV</span>-1 acquisition is polygenic and heritable, with <span class="smallcaps-auto">SNP</span> heritability estimates explaining 28–42% of the variance in this trait at a population level. Genetic correlations alongside UK Biobank data revealed associations with smoking, prospective memory and socioeconomic traits. Gene-level enrichment analysis identified EF-hand calcium binding domain 14 as a novel susceptibility gene for <span class="smallcaps-auto">HIV</span>–1 acquisition. We also observed that susceptibility variants for <span class="smallcaps-auto">HIV</span>-1 acquisition were significantly enriched for genes expressed in T-cells, but also in striatal and hippocampal neurons. Finally, we tested how polygenic risk scores for <span class="smallcaps-auto">HIV</span>-1 acquisition influence blood levels of 35 inflammatory markers in 406 <span class="smallcaps-auto">HIV</span>-1-negative individuals. We found that higher genetic risk for <span class="smallcaps-auto">HIV</span>-1 acquisition was associated with lower levels of C-C motif chemokine ligand 17. Our findings corroborate a complex model for <span class="smallcaps-auto">HIV</span>-1 acquisition, whereby susceptibility is partly heritable and moderated by specific behavioral, cellular and immunological parameters.</p>'
- - /docs/genetics/heritable/2019-lakhani.pdf
  - 'Repurposing large health insurance claims data to estimate genetic and environmental contributions in 560 phenotypes'
  - Chirag M. Lakhani, Braden T. Tierney, Arjun K. Manrai, Jian Yang, Peter M. Visscher, Chirag J. Patel
  - 2019-01-14
  - 10.1038/s41588-018-0313-7
  - ! '<p>We analysed a large health insurance dataset to assess the genetic and environmental contributions of 560 disease-related phenotypes in 56,396 twin pairs and 724,513 sibling pairs out of 44,859,462 individuals that live in the United States. We estimated the contribution of environmental risk factors (socioeconomic status (<span class="smallcaps-auto">SES</span>), air pollution and climate) in each phenotype. Mean heritability (<em>h</em><sup>2</sup> = 0.311) and shared environmental variance (<em>c</em><sup>2</sup> = 0.088) were higher than variance attributed to specific environmental factors such as zip-code-level <span class="smallcaps-auto">SES</span> (var<sub><span class="smallcaps-auto">SES</span></sub> = 0.002), daily air quality (var~<span class="smallcaps-auto">AQI</span>` = 0.0004), and average temperature (var<sub>temp</sub> = 0.001) overall, as well as for individual phenotypes. We found significant heritability and shared environment for a number of comorbidities (<em>h</em><sup>2</sup> = 0.433, <em>c</em><sup>2</sup> = 0.241) and average monthly cost (<em>h</em><sup>2</sup> = 0.290, <em>c</em><sup>2</sup> = 0.302). All results are available using our <a href="http://apps.chiragjpgroup.org/catch/">Claims Analysis of Twin Correlation and Heritability (Ca<span class="smallcaps-auto">TCH</span>)</a> web application.</p>'
- - /docs/genetics/editing/2019-fredens.pdf
  - 'Total synthesis of <em>Escherichia coli</em> with a recoded genome'
  - Julius Fredens, Kaihang Wang, Daniel de la Torre, Louise F. H. Funke, Wesley E. Robertson, Yonka Christova, Tiongsun Chia, Wolfgang H. Schmied, Daniel L. Dunkelmann, Václav Beránek, Chayasith Uttamapinant, Andres Gonzalez Llamazares, Thomas S. Elliott, Jason W. Chin
  - 2019-05-15
  - 10.1038/s41586-019-1192-5
  - ! '<p>Nature uses 64 codons to encode the synthesis of proteins from the genome, and chooses 1 sense codon—out of up to 6 synonyms—to encode each amino acid. Synonymous codon choice has diverse and important roles, and many synonymous substitutions are detrimental. Here we demonstrate that the number of codons used to encode the canonical amino acids can be reduced, through the genome-wide substitution of target codons by defined synonyms. We create a variant of <em>Escherichia coli</em> with a four-megabase synthetic genome through a high-fidelity convergent total synthesis. Our synthetic genome implements a defined recoding and refactoring scheme—with simple corrections at just seven positions—to replace every known occurrence of two sense codons and a stop codon in the genome. Thus, we recode 18,214 codons to create an organism with a 61-codon genome; this organism uses 59 codons to encode the 20 amino acids, and enables the deletion of a previously essential transfer <span class="smallcaps-auto">RNA</span>.</p>'
- - /docs/genetics/editing/2019-ostrov.pdf
  - 'Technological challenges and milestones for writing genomes: Synthetic genomics requires improved technologies'
  - Nili Ostrov, Jacob Beal, Tom Ellis, D. Benjamin Gordon, Bogumil J. Karas, Henry H. Lee, Scott C. Lenaghan, Jeffery A. Schloss, Giovanni Stracquadanio, Axel Trefzer, Joel S. Bader, George M. Church, Cintia M. Coelho, J. William Efcavitch, Marc Güell, Leslie A. Mitchell, Alec A. K. Nielsen, Bill Peck, Alexander C. Smith, C. Neal Stewart Jr., Hille Tekotte
  - 2019-10-18
  - 10.1126/science.aay0339
  - ! '<p>Engineering biology with recombinant <span class="smallcaps-auto">DNA</span>, broadly called synthetic biology, has progressed tremendously in the last decade, owing to continued industrialization of <span class="smallcaps-auto">DNA</span> synthesis, discovery and development of molecular tools and organisms, and increasingly sophisticated modeling and analytic tools. However, we have yet to understand the full potential of engineering biology because of our inability to write and test whole genomes, which we call synthetic genomics. Substantial improvements are needed to reduce the cost and increase the speed and reliability of genetic tools. Here, we identify emerging technologies and improvements to existing methods that will be needed in four major areas to advance synthetic genomics within the next 10 years: genome design, <span class="smallcaps-auto">DNA</span> synthesis, genome editing, and chromosome construction (see table). Similar to other large-scale projects for responsible advancement of innovative technologies, such as the Human Genome Project, an international, cross-disciplinary effort consisting of public and private entities will likely yield maximal return on investment and open new avenues of research and biotechnology.</p>'
- - /docs/genetics/editing/2019-05-06-theexpresstribune-80percentofsouthkoreassnifferdogsarecloned.html
  - "Amid animal cruelty debate, 80% of South Korea’s sniffer dogs are cloned"
  - APP (The Express Tribune)
  - 2019-05-06
  - ''
  - ! '<p>Some 80% of active sniffer dogs deployed by South Korea’s quarantine agency are cloned, data showed Monday, as activists express their concerns over potential animal abuse. According to the Animal and Plant Quarantine Agency, 42 of its 51 sniffer dogs were cloned from parent animals as of April, indicating such cloned detection dogs are already making significant contributions to the country’s quarantine activities. The number of cloned dogs first outpaced their naturally born counterparts in 2014, the agency said. Of the active cloned dogs, 39 are currently deployed at Incheon International Airport, the country’s main gateway.</p><p>Deploying cloned dogs can save time and money over training naturally born puppies as they maintain the outstanding traits of their parents, whose capabilities have already been verified in the field, according to experts. While the average cost of raising one detection dog is over 100 million won (US$85,600), it is less than half that when utilising cloned puppies, they said.</p>'
- - https://www.nature.com/articles/s41598-019-44324-x
  - Breed differences of heritable behaviour traits in cats
  - Milla Salonen, Katariina Vapalahti, Katriina Tiira, Asko Mäki-Tanila, Hannes Lohi
  - 2019-05-28
  - 10.1038/s41598-019-44324-x
  - ! '<p>Cat domestication and selective breeding have resulted in tens of breeds with major morphological differences. These breeds may also show distinctive behaviour differences; which, however, have been poorly studied. To improve the understanding of feline behaviour, we examined whether behavioural differences exist among cat breeds and whether behaviour is heritable. For these aims, we utilized our extensive health and behaviour questionnaire directed to cat owners and collected a survey data of 5726 cats. Firstly, for studying breed differences, we utilized logistic regression models with multiple environmental factors and discovered behaviour differences in 19 breeds and breed groups in ten different behaviour traits. Secondly, the studied cat breeds grouped into four clusters, with the Turkish Van and Angora cats alone forming one of them. These findings indicate that cat breeds have diverged not only morphologically but also behaviourally. Thirdly, we estimated heritability in three breeds and obtained moderate heritability estimates in seven studied traits, varying from 0.4 to 0.53, as well as phenotypic and genetic correlations for several trait pairs. Our results show that it is possible to partition the observed variation in behaviour traits into genetic and environmental components, and that substantial genetic variation exists within breed populations.</p>'
- - /docs/iq/2019-horschler.pdf
  - 'Absolute brain size predicts dog breed differences in executive function'
  - Daniel J. Horschler, Brian Hare, Josep Call, Juliane Kaminski, Ádám Miklósi, Evan L. MacLean
  - 2019-01-03
  - 10.1007/s10071-018-01234-1
  - ! '<p>Large-scale phylogenetic studies of animal cognition have revealed robust links between absolute brain volume and species differences in executive function. However, past comparative samples have been composed largely of primates, which are characterized by evolutionarily derived neural scaling rules. Therefore, it is currently unknown whether positive associations between brain volume and executive function reflect a broad-scale evolutionary phenomenon, or alternatively, a unique consequence of primate brain evolution. Domestic dogs provide a powerful opportunity for investigating this question due to their close genetic relatedness, but vast intraspecific variation. Using citizen science data on more than 7000 purebred dogs from 74 breeds, and controlling for genetic relatedness between breeds, we identify strong relationships between estimated absolute brain weight and breed differences in cognition. Specifically, larger-brained breeds performed significantly better on measures of short-term memory and self-control. However, the relationships between estimated brain weight and other cognitive measures varied widely, supporting domain-specific accounts of cognitive evolution. Our results suggest that evolutionary increases in brain size are positively associated with taxonomic differences in executive function, even in the absence of primate-like neuroanatomy. These findings also suggest that variation between dog breeds may present a powerful model for investigating correlated changes in neuroanatomy and cognition among closely related taxa.</p>'
- - /docs/genetics/editing/2019-grunwald.pdf
  - Super-Mendelian inheritance mediated by CRISPR–Cas9 in the female mouse germline
  - Hannah A. Grunwald, Valentino M. Gantz, Gunnar Poplawski, Xiang-Ru S. Xu, Ethan Bier & Kimberly L. Cooper
  - 2019-01-23
  - 10.1038/s41586-019-0875-2
  - ! '<p>A gene drive biases the transmission of one of the two copies of a gene such that it is inherited more frequently than by random segregation. Highly efficient gene drive systems have recently been developed in insects, which leverage the sequence-targeted <span class="smallcaps-auto">DNA</span> cleavage activity of <span class="smallcaps-auto">CRISPR</span>–Cas9 and endogenous homology-directed repair mechanisms to convert heterozygous genotypes to homozygosity<sup>1,2,3,4</sup>. If implemented in laboratory rodents, similar systems would enable the rapid assembly of currently impractical genotypes that involve multiple homozygous genes (for example, to model multigenic human diseases). To our knowledge, however, such a system has not yet been demonstrated in mammals. Here we use an active genetic element that encodes a guide <span class="smallcaps-auto">RNA</span>, which is embedded in the mouse tyrosinase (<em>Tyr</em>) gene, to evaluate whether targeted gene conversion can occur when <span class="smallcaps-auto">CRISPR</span>–Cas9 is active in the early embryo or in the developing germline. Although Cas9 efficiently induces double-stranded <span class="smallcaps-auto">DNA</span> breaks in the early embryo and male germline, these breaks are not corrected by homology-directed repair. By contrast, Cas9 expression limited to the female germline induces double-stranded breaks that are corrected by homology-directed repair, which copies the active genetic element from the donor to the receiver chromosome and increases its rate of inheritance in the next generation. These results demonstrate the feasibility of <span class="smallcaps-auto">CRISPR</span>–Cas9-mediated systems that bias inheritance of desired alleles in mice and that have the potential to transform the use of rodent models in basic and biomedical research.</p>'
- - https://github.com/huggingface/transformers
  - "Huggingface: 'transformers' repo"
  - Huggingface
  - ''
  - ''
  - ! '<p>🤗 Transformers (formerly known as <code>pytorch-transformers</code> and <code>pytorch-pretrained-bert</code>) provides state-of-the-art general-purpose architectures (<span class="smallcaps-auto">BERT</span>, <span class="smallcaps-auto">GPT</span>-2, Ro<span class="smallcaps-auto">BERT</span>a, <span class="smallcaps-auto">XLM</span>, DistilBert, <span class="smallcaps-auto">XLN</span>et, <span class="smallcaps-auto">CTRL</span>…) for Natural Language Understanding (<span class="smallcaps-auto">NLU</span>) and Natural Language Generation (<span class="smallcaps-auto">NLG</span>) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.</p><h3 id="features">Features</h3><ul><li>As easy to use as pytorch-transformers</li><li>As powerful and concise as Keras</li><li>High performance on <span class="smallcaps-auto">NLU</span> and <span class="smallcaps-auto">NLG</span> tasks</li><li>Low barrier to entry for educators and practitioners</li></ul><p>State-of-the-art <span class="smallcaps-auto">NLP</span> for everyone:</p><ul><li>Deep learning researchers</li><li>Hands-on practitioners</li><li>AI/ML/<span class="smallcaps-auto">NLP</span> teachers and educators</li></ul><p>Lower compute costs, smaller carbon footprint:</p><ul><li>Researchers can share trained models instead of always retraining</li><li>Practitioners can reduce compute time and production costs</li><li>10 architectures with over 30 pretrained models, some in more than 100 languages</li></ul><p>Choose the right framework for every part of a model’s lifetime:</p><ul><li>Train state-of-the-art models in 3 lines of code</li><li>Deep interoperability between TensorFlow 2.0 and PyTorch models</li><li>Move a single model between TF2.0/PyTorch frameworks at will</li><li>Seamlessly pick the right framework for training, evaluation, production</li></ul>'
- - https://ai.googleblog.com/2019/02/real-time-continuous-transcription-with.html
  - Real-time Continuous Transcription with Live Transcribe
  - Sagar Savla (Google)
  - 2019-02-04
  - ''
  - ! '<p>The World Health Organization (<span class="smallcaps-auto">WHO</span>) estimates that there are 466 million people globally that are deaf and hard of hearing. A crucial technology in empowering communication and inclusive access to the world’s information to this population is automatic speech recognition (<span class="smallcaps-auto">ASR</span>), which enables computers to detect audible languages and transcribe them into text for reading. Google’s <span class="smallcaps-auto">ASR</span> is behind automated captions in Youtube, presentations in Slides and also phone calls… Today, we’re announcing Live Transcribe, a free Android service that makes real-world conversations more accessible by bringing the power of automatic captioning into everyday, conversational use. Powered by Google Cloud, Live Transcribe captions conversations in real-time, supporting over 70 languages and more than 80% of the world’s population. You can launch it with a single tap from within any app, directly from the accessibility icon on the system tray.</p><p>…Relying on cloud <span class="smallcaps-auto">ASR</span> provides us greater accuracy, but we wanted to reduce the network data consumption that Live Transcribe requires. To do this, we implemented an on-device neural network-based speech detector, built on our previous work with AudioSet. This network is an image-like model, similar to our published <span class="smallcaps-auto">VGG</span>ish model, which detects speech and automatically manages network connections to the cloud <span class="smallcaps-auto">ASR</span> engine, minimizing data usage over long periods of use.</p><p>…Known as the cocktail party problem, understanding a speaker in a noisy room is a major challenge for computers. To address this, we built an indicator that visualizes the volume of user speech <em>relative</em> to background noise. This also gives users instant feedback on how well the microphone is receiving the incoming speech from the speaker, allowing them to adjust the placement of the phone…Potential future improvements in mobile-based automatic speech transcription include on-device recognition, speaker-separation, and speech enhancement. Relying solely on transcription can have pitfalls that can lead to miscommunication. Our research with Gallaudet University shows that combining it with other auditory signals like speech detection and a loudness indicator, makes a tangibly meaningful change in communication options for our users.</p>'
- - 'https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30061-0#deepmind'
  - 'Reinforcement Learning, Fast and Slow'
  - Matthew Botvinick, Sam Ritter, Jane X. Wang, Zeb Kurth-Nelson, Charles Blundell, Demis Hassabis
  - 2019-05-16
  - 10.1016/j.tics.2019.02.006
  - ! '<p>Recent AI research has given rise to powerful techniques for deep reinforcement learning. In their combination of representation learning with reward-driven behavior, deep reinforcement learning would appear to have inherent interest for psychology and neuroscience.</p><p>One reservation has been that deep reinforcement learning procedures demand large amounts of training data, suggesting that these algorithms may differ fundamentally from those underlying human learning.</p><p>While this concern applies to the initial wave of deep RL techniques, subsequent AI work has established methods that allow deep RL systems to learn more quickly and efficiently. Two particularly interesting and promising techniques center, respectively, on episodic memory and meta-learning. Alongside their interest as AI techniques, deep RL methods leveraging episodic memory and meta-learning have direct and interesting implications for psychology and neuroscience. One subtle but critically important insight which these techniques bring into focus is the fundamental connection between fast and slow forms of learning.</p><p>Deep reinforcement learning (RL) methods have driven impressive advances in artificial intelligence in recent years, exceeding human performance in domains ranging from Atari to Go to no-limit poker. This progress has drawn the attention of cognitive scientists interested in understanding human learning. However, the concern has been raised that deep RL may be too sample-inefficient—that is, it may simply be too slow—to provide a plausible model of how humans learn. In the present review, we counter this critique by describing recently developed techniques that allow deep RL to operate more nimbly, solving problems much more quickly than previous methods. Although these techniques were developed in an AI context, we propose that they may have rich implications for psychology and neuroscience. A key insight, arising from these AI methods, concerns the fundamental connection between fast RL and slower, more incremental forms of learning.</p>'
- - /docs/sociology/2019-lortieforgues.pdf
  - 'Rigorous Large-Scale Educational RCTs Are Often Uninformative: Should We Be Concerned?'
  - Hugues Lortie-Forgues, Matthew Inglis
  - 2019-03-11
  - 10.3102/0013189X19832850
  - ! '<p>There are a growing number of large-scale educational randomized controlled trials (<span class="smallcaps-auto">RCT</span>s). Considering their expense, it is important to reflect on the effectiveness of this approach. We assessed the magnitude and precision of effects found in those large-scale <span class="smallcaps-auto">RCT</span>s commissioned by the UK-based Education Endowment Foundation and the U.S.-based National Center for Educational Evaluation and Regional Assistance, which evaluated interventions aimed at improving academic achievement in K–12 (141 <span class="smallcaps-auto">RCT</span>s; 1,222,024 students). The mean effect size was 0.06 standard deviations. These sat within relatively large confidence intervals (mean width = 0.30 SDs), which meant that the results were often uninformative (the median Bayes factor was 0.56). We argue that our field needs, as a priority, to understand why educational <span class="smallcaps-auto">RCT</span>s often find small and uninformative effects. [Keywords: educational policy, evaluation, meta-analysis, program evaluation.]</p>'
- - https://elifesciences.org/articles/45183
  - 'Meta-Research: A comprehensive review of randomized clinical trials in three medical journals reveals 396 medical reversals'
  - Diana Herrera-Perez, Alyson Haslam, Tyler Crain, Jennifer Gill, Catherine Livingston, Victoria Kaestner, Michael Hayes, Dan Morgan, Adam S Cifu, Vinay Prasad
  - 2019-06-11
  - 10.7554/eLife.45183
  - ! '<p>The ability to identify medical reversals and other low-value medical practices is an essential prerequisite for efforts to reduce spending on such practices. Through an analysis of more than 3000 randomized controlled trials (<span class="smallcaps-auto">RCT</span>s) published in three leading medical journals (the Journal of the American Medical Association, the Lancet, and the New England Journal of Medicine), we have identified 396 medical reversals. Most of the studies (92%) were conducted on populations in high-income countries, cardiovascular disease was the most common medical category (20%), and medication was the most common type of intervention (33%).</p>'
- - /docs/music-distraction/2011-kampfe.pdf
  - 'The impact of background music on adult listeners: A meta-analysis'
  - Juliane Kämpfe, Peter Sedlmeier, Frank Renkewitz
  - 2010-11-08
  - 10.1177/0305735610376261
  - ! "Background music has been found to have beneficial, detrimental, or no effect on a variety of behavioral and psychological outcome measures. This article reports a meta-analysis that attempts to summarize the impact of background music. A global analysis shows a null effect, but a detailed examination of the studies that allow the calculation of effects sizes reveals that this null effect is most probably due to averaging out specific effects. In our analysis, the probability of detecting such specific effects was not very high as a result of the scarcity of studies that allowed the calculation of respective effect sizes. Nonetheless, we could identify several such cases: a comparison of studies that examined background music compared to no music indicates that background music disturbs the reading process, has some small detrimental effects on memory, but has a positive impact on emotional reactions and improves achievements in sports. A comparison of different types of background music reveals that the tempo of the music influences the tempo of activities that are performed while being exposed to background music. It is suggested that effort should be made to develop more specific theories about the impact of background music and to increase the methodological quality of relevant studies. [Keywords: background music, effects of music, healthy adults, meta-analysis, methodological problems.]"
- - /docs/psychology/2019-shewach.pdf
  - 'Stereotype threat effects in settings with features likely versus unlikely in operational test settings: A meta-analysis'
  -  Oren R. Shewach, Paul R. Sackett, Sander Quint
  - '2019'
  - 10.1037/apl0000420
  - ! '<p>The stereotype threat literature primarily comprises lab studies, many of which involve features that would not be present in high-stakes testing settings. We meta-analyze the effect of stereotype threat on cognitive ability tests, focusing on both laboratory and operational studies with features likely to be present in high stakes settings. First, we examine the features of cognitive ability test metric, stereotype threat cue activation strength, and type of non-threat control group, and conduct a focal analysis removing conditions that would not be present in high stakes settings. We also take into account a previously unrecognized methodological error in how data are analyzed in studies that control for scores on a prior cognitive ability test, which resulted in a biased estimate of stereotype threat. The focal sample, restricting the database to samples utilizing operational testing-relevant conditions, displayed a threat effect of <em>d</em> = −.14 (k = 45, N = 3,532, SD<sub>δ</sub> = .31). Second, we present a comprehensive meta-analysis of stereotype threat. Third, we examine a small subset of studies in operational test settings and studies utilizing motivational incentives, which yielded <em>d</em>-values ranging from .00 to −.14. Fourth, the meta-analytic database is subjected to tests of publication bias, finding nontrivial evidence for publication bias. Overall, results indicate that the size of the stereotype threat effect that can be experienced on tests of cognitive ability in operational scenarios such as college admissions tests and employment testing may range from negligible to small.</p>'
- - /docs/longevity/2019-vrselja.pdf
  - Restoration of brain circulation and cellular functions hours post-mortem
  - Zvonimir Vrselja, Stefano G. Daniele, John Silbereis, Francesca Talpo, Yury M. Morozov, André M. M. Sousa, Brian S. Tanaka, Mario Skarica, Mihovil Pletikos, Navjot Kaur, Zhen W. Zhuang, Zhao Liu, Rafeed Alkawadri, Albert J. Sinusas, Stephen R. Latham, Stephen G. Waxman, Nenad Sestan
  - 2019-05-17
  - 10.1038/s41586-019-1099-1
  - ! 'The brains of humans and other mammals are highly vulnerable to interruptions in blood flow and decreases in oxygen levels. Here we describe the restoration and maintenance of microcirculation and molecular and cellular functions of the intact pig brain under ex vivo normothermic conditions up to four hours post-mortem. We have developed an extracorporeal pulsatile-perfusion system and a haemoglobin-based, acellular, non-coagulative, echogenic, and cytoprotective perfusate that promotes recovery from anoxia, reduces reperfusion injury, prevents oedema, and metabolically supports the energy requirements of the brain. With this system, we observed preservation of cytoarchitecture; attenuation of cell death; and restoration of vascular dilatory and glial inflammatory responses, spontaneous synaptic activity, and active cerebral metabolism in the absence of global electrocorticographic activity. These findings demonstrate that under appropriate conditions the isolated, intact large mammalian brain possesses an underappreciated capacity for restoration of microcirculation and molecular and cellular activity after a prolonged post-mortem interval.'
- - /docs/biology/2018-banziger.pdf
  - 'Congregations of Tear Drinking Bees at Human Eyes: Foraging Strategies for an Invaluable Resource by Lisotrigona in Thailand (Apidae, Meliponini)'
  - Hans Bänziger
  - 2018-05-04
  - ''
  - ! '<p>Wild <em>Lisotrigona cacciae</em> (Nurse) and <em>L. furva Engel</em> were studied in their natural forest habitat at three sites in northern Thailand, May 2013–November 2014. The author, both experimenter and tear source, marked the minute bees while they drank from his eyes viewed in a mirror. All marked workers, 34 <em>L. cacciae</em> and 23 <em>L. furva</em>, came repeatedly to engorge, 34 and 27 times on average, respectively. The maximum number of times the same <em>L. cacciae</em> and <em>L. furva</em> came was 78 and 144 visits in one day, respectively; the maximum over two days was 145 visits by one L. cacciae; the maximum number of visiting days by the same bee was four over seven days by one <em>L. furva</em> which made 65 visits totally. The same forager may collect tears for more than 10h in a day, on average for 3h15min and 2h14min for <em>L. cacciae</em> and <em>L. furva</em>, respectively. Engorging from the inner eye corner averaged 3.1 and 2.2 min, respectively, but only 1.3 and 0.9 min when settled on the lower eye lid/ciliae. The interval between consecutive visits averaged 3.3 min and 3.8 min, respectively. Lachryphagy occurred during all months of the year, with 91–320 foragers a day during the hot season and 6–280 foragers during the rainy season; tear collecting resumed after a downpour. During the cold season eye visitation was reduced to 3–64 foragers, but none left her nest when the temperature was below 22°C. Flying ranges were greater than in comparable non-lachryphagous meliponines. It is proposed that Lisotrigona colonies have workers that are, besides nectar and pollen foragers, specialized tear collectors. Tears are 200 times richer in proteins than sweat, a secretion well-known to be imbibed by many meliponines. Digestion of proteins dissolved in tears is not hampered by an exine wall as in pollen, and they have bactericidal properties. These data corroborate the inference that Lisotrigona, which also visit other mammals, birds and reptiles, harvest lachrymation mainly for its content of proteins rather than only for salt and water.</p>'
- - https://psmag.com/social-justice/the-senseless-environment-crime-of-the-20th-century-russia-whaling-67774
  - "The Most Senseless Environmental Crime of the 20<sup>th</sup> Century: Fifty years ago 180,000 whales disappeared from the oceans without a trace, and researchers are still trying to make sense of why. Inside the most irrational environmental crime of the century."
  - Charles Homans
  - 2017-06-14
  - ''
  - ! '<p>In her first season, the <em>Slava</em> caught just 386 whales. But by the fifth—before which the fleet’s crew wrote a letter to Stalin pledging to bring home more than 500 tons of whale oil—the <em>Slava</em>’s annual catch was approaching 2,000. The next year it was 3,000… The Soviet fleets killed almost 13,000 humpback whales in the 1959–60 season and nearly as many the next, when the <em>Slava</em> and <em>Sovetskaya Ukraina</em> were joined by a third factory ship, the <em>Yuriy Dolgorukiy</em>. It was grueling work: One former whaler, writing years later in a Moscow newspaper, claimed that five or six Soviet crewmen died on the Southern Hemisphere expeditions each year, and that a comparable number went mad.</p><p>… “In five years of intensive whaling by first one, then two, three, and finally four fleets,” he wrote, the populations of humpback whales off the coasts of Australia and New Zealand “were so reduced in abundance that we can now say that they are completely destroyed!”…The Soviet Union was a party to the International Convention for the Regulation of Whaling, a 1946 treaty that limited countries to a set quota of whales each year. By the time a ban on commercial whaling went into effect, in 1986, the Soviets had reported killing a total of 2,710 humpback whales in the Southern Hemisphere. In fact, the country’s fleets had killed nearly 18 times that many, along with thousands of unreported whales of other species. It had been an elaborate and audacious deception: Soviet captains had disguised ships, tampered with scientific data, and misled international authorities for decades. In the estimation of the marine biologists Yulia Ivashchenko, Phillip Clapham, and Robert Brownell, it was “arguably one of the greatest environmental crimes of the 20<sup>th</sup> century.”</p><p>… It was also a perplexing one…Unlike Norway and Japan, the other major whaling nations of the era, the Soviet Union had little real demand for whale products. Once the blubber was cut away for conversion into oil, the rest of the animal, as often as not, was left in the sea to rot or was thrown into a furnace and reduced to bone meal—a low-value material used for agricultural fertilizer, made from the few animal byproducts that slaughterhouses and fish canneries can’t put to more profitable use. “It was a good product,” Dmitri Tormosov, a scientist who worked on the Soviet fleets, wryly recalls, “but maybe not so important as to support a whole whaling industry.” This was the riddle the Soviet ships left in their wake: Why did a country with so little use for whales kill so many of them?</p>'
- - /docs/culture/2019-obrien.pdf
  - "Enjoy it again: Repeat experiences are less repetitive than people think"
  - "E. O'Brien"
  - '2019'
  - 10.1037/pspa0000147
  - ! '<p>What would it be like to revisit a museum, restaurant, or city you just visited? To rewatch a movie you just watched? To replay a game you just played? People often have opportunities to repeat hedonic activities. Seven studies (total <em>N</em> = 3,356) suggest that such opportunities may be undervalued: Many repeat experiences are not as dull as they appear. Studies 1–3 documented the basic effect. All participants first completed a real-world activity once in full (Study 1, museum exhibit; Study 2, movie; Study 3, video game). Then, some predicted their reactions to repeating it whereas others actually repeated it. Predictors underestimated Experiencers’ enjoyment, even when experienced enjoyment indeed declined. Studies 4 and 5 compared mechanisms: neglecting the pleasurable byproduct of continued exposure to the same content (e.g., fluency) versus neglecting the new content that manifests by virtue of continued exposure (e.g., discovery), both of which might dilute uniform dullness. We found stronger support for the latter: The misprediction was moderated by stimulus complexity (Studies 4 and 5) and mediated by the amount of novelty discovered within the stimulus (Study 5), holding exposure constant. Doing something once may engender an inflated sense that one has now seen “it,” leaving people naïve to the missed nuances remaining to enjoy. Studies 6 and 7 highlighted consequences: Participants incurred costs to avoid repeats so to maximize enjoyment, in specific contexts for which repetition would have been as enjoyable (Study 6) or more enjoyable (Study 7) as the provided novel alternative. These findings warrant a new look at traditional assumptions about hedonic adaptation and novelty preferences. Repetition too could add an unforeseen spice to life.</p>'
- - /docs/psychology/2018-hennecke.pdf
  - "Doing Despite Disliking: Self-regulatory Strategies in Everyday Aversive Activities"
  - Marie Hennecke, Thomas Czikmantori, Veronika Brandstätter
  - 2018-12-10
  - 10.1002/per.2182
  - ! '<p>We investigated the self-regulatory strategies people spontaneously use in their everyday lives to regulate their persistence during aversive activities. In pilot studies (pooled <em>N</em> = 794), we identified self-regulatory strategies from self-reports and generated hypotheses about individual differences in trait self-control predicting their use. Next, deploying ambulatory assessment (<em>N</em> = 264, 1940 reports of aversive/challenging activities), we investigated predictors of the strategies’ self-reported use and effectiveness (trait self-control and demand types). The popularity of strategies varied across demands. In addition, people higher in trait self-control were more likely to focus on the positive consequences of a given activity, set goals, and use emotion regulation. Focusing on positive consequences, focusing on negative consequences (of not performing the activity), thinking of the near finish, and emotion regulation increased perceived self-regulatory success across demands, whereas distracting oneself from the aversive activity decreased it. None of these strategies, however, accounted for the beneficial effects of trait self-control on perceived self-regulatory success. Hence, trait self-control and strategy use appear to represent separate routes to good self-regulation. By considering trait- and process-approaches these findings promote a more comprehensive understanding of self-regulatory success and failure during people’s daily attempts to regulate their persistence.</p>'
- - /docs/psychology/1991-lykken.pdf
  - "What's Wrong With Psychology Anyway?"
  - David T. Lykken
  - '1991'
  - ''
  - ! '<p>[Lykken’s (1991) classic criticisms of psychology’s dominant research tradition, from the perspective of the Minnesotan psychometrics school, in association with Paul Meehl: psychology’s replication crisis, the constant fading-away of trendy theories, and inability to predict the real world the measurement problem, null hypothesis significance testing, and the granularity of research methods.]</p><p>I shall argue the following theses:</p><ol type="1"><li>Psychology isn’t doing very well as a scientific discipline and something seems to be wrong somewhere.</li><li>This is due partly to the fact that psychology is simply harder than physics or chemistry, and for a variety of reasons. One interesting reason is that people differ structurally from one another and, to that extent, cannot be understood in terms of the same theory since theories are guesses about structure.</li><li>But the problems of psychology are also due in part to a defect in our research tradition; our students are carefully taught to behave in the same obfuscating, self-deluding, pettifogging ways that (some of) their teachers have employed.</li></ol>'
- - https://orionmagazine.org/article/deep-intellect/
  - "Deep Intellect"
  - Sy Montgomery (Orion Magazine)
  - 2011-10-25
  - ''
  - ! '<p>[Discussion of the remarkable abilities &amp; intelligence of octopuses, despite being small, fragile, asocial beings. With hundreds of millions of neurons (most in its arms, which appear to be able to think and act independently, coordinating with the other arms/mouth, with their immensely-strong suckers), octopus are able to recognize individuals and bear grudges (squirting water at the foe), somehow imitate color despite being color-blind, use tools, solve puzzles, and manipulate rocks to create shelters, they are noted escape artists: one octopus was found breaking out of its aquarium at night to feast in other tanks, sneaking back before humans returned.]</p>'
- - https://www.smithsonianmag.com/science-nature/family-feels-almost-no-pain-180971915/
  - "The Family That Feels Almost No Pain: An Italian clan’s curious insensitivity to pain has piqued the interest of geneticists seeking a new understanding of how to treat physical suffering"
  - Matthew Shaer (Smithsonian Magazine)
  - 2019-05
  - ''
  - ! '<p>[Profile of the Marsili family, an Italian family which has a genetic mutation which renders pain far less painful but still felt: outright pain insensitivity is often fatal, but the Marsili condition is more moderate and so they are all alive and health, albeit much more injury-prone, like during skiing or sunbathing or childhood. In that condition, acute pain is felt, but then it fades and no chronic pain lingers. Scientists who had previously discovered a pain-insensitivity mutation in a Pakistani family (some dead) examined the Marsilis next, after years of testing candidate mutations, finally finding a hit which gene, when mutation of it were genetically engineered into mice, produced dramatically different, and the Marsili mutation specifically increased pain toleration.]</p><p>The broad significance of their analysis is that it showed that <span class="smallcaps-auto">ZFHX</span>2 was crucially involved in pain perception in a way nobody had previously understood. Unlike more frequently documented cases of pain insensitivity, for instance, the Marsili family’s mutation didn’t prevent the development of pain-sensing neurons; those were still there in typical numbers. Yet it was also different from the Pakistani family’s mutation, whose genetic anomaly disabled a single function in pain-sensing neurons. Rather, <span class="smallcaps-auto">ZFHX</span>2 appeared to regulate how other genes operated, including several genes already linked to pain processing and active throughout the nervous system, including in the brain—a sort of “master regulator,” in the words of Alexander Chesler, a neurobiologist specializing in the sensory nervous system at the National Institutes of Health, in Bethesda, Maryland, who was not involved in the study.</p><p>“What’s so exciting is that this is a completely different class of pain insensitivity,” Chesler says. “It tells you that this particular pathway is important in humans. And that’s what gets people in the industry excited. It suggests that there are changes that could be made to somebody to make them insensitive to chronic pain.”</p>'
- - /docs/economics/2020-arora.pdf
  - 'The Changing Structure of American Innovation: Some Cautionary Remarks for Economic Growth'
  - 'Ashish Arora, Sharon Belenzon, Andrea Patacconi, Jungkyu Suh'
  - '2020'
  - 10.1086/705638
  - ! 'A defining feature of modern economic growth is the systematic application of science to advance technology. However, despite sustained progress in scientific knowledge, recent productivity growth in the United States has been disappointing. We review major changes in the American innovation ecosystem over the past century. The past three decades have been marked by a growing division of labor between universities focusing on research and large corporations focusing on development. Knowledge produced by universities is not often in a form that can be readily digested and turned into new goods and services. Small firms and university technology transfer offices cannot fully substitute for corporate research, which had previously integrated multiple disciplines at the scale required to solve significant technical problems. Therefore, whereas the division of innovative labor may have raised the volume of science by universities, it has also slowed, at least for a period of time, the transformation of that knowledge into novel products and processes.'
- - http://www.silcom.com/~barnowl/chain-letter/evolution.html
  - "Chain Letter Evolution"
  - Daniel W. VanArsdale
  - '2006'
  - ''
  - ! '<p>Apocryphal letters claiming divine origin circulated for centuries in Europe. After 1900, shorter more secular letters appeared in the US that promised good luck if copies were distributed and bad luck if not. Billions of these “luck chain letters” circulated in the the next 100 years. As they replicated through the decades, some accumulated copying errors, offhand comments, and calculated innovations that helped them prevail in the competition with other chain letters. For example, complementary testimonials developed, one exploiting perceived good luck, another exploiting perceived bad luck. Twelve successive types of paper luck chain letters are identified which predominated US circulation at some time in the twentieth century. These types, and their major variations, are described and analyzed for their replicative advantage. </font><font size=+1>In the 1970’s a luck chain letter from South America that touted a lottery winner invaded the US and was combined on one page with an indigenous chain letter. This combination rapidly dominated circulation. In 1979 a postscript concluding with “It Works” was added to one of these combination letters, and within a few years the progeny of this single letter had replaced all the millions of similar letters in circulation without this postscript. These and other events in paper chain letter history are described, and hypotheses are offered to explain advances and declines in circulation, including the near extinction of luck chain letters in the new millennium.  </font></p><p><font size=+1>Perhaps the most dramatic event in chain letter history was the advent of money chain letters. This was spawned by the infamous “Send-a-Dime” chain letter which flooded the world in 1935. </font><font size=+1>The insight and methods of its anonymous author, likely a woman motivated by charity, are examined in detail in a </font><font size=+1>separate article titled “<a href=http://www.silcom.com/~barnowl/chain-letter/TOOMCL.html>The Origin of Money Chain Letters</a>.” This constitutes Section 4.1 below, where its link is repeated. </font><font size=+1>It can be read independently from this treatise.</font><font size=+1> </font></p><font size=+1>The online Paper Chain Letter Archive contains the text and documentation of over 900 chain letters. Most of these texts have been transcribed from collected physical letters, but many come from published sources including daily newspapers present in online searchable archives. </font><font size=+1>Some unusual items in the archive are: an anonymous <a href=http://www.silcom.com/~barnowl/chain-letter/archive/ae1917-06-05p1_Conscientious-Objectors.htm>1917</a> chain letter giving advice on obtaining conscientious objector status; a <a href=http://www.silcom.com/~barnowl/chain-letter/archive/ae1920-02-21p1_SinnFein_q4.htm>1920</a> Sinn Féin revolutionary communication; </font><font size=+1>rare unpublished scatological parody letters from <a href=http://www.silcom.com/~barnowl/chain-letter/archive/je1935_lucy-bowels.htm>1935;</a></font><font size=+1> </font><font size=+1>a bizarre chain letter invitation to a suicide from <a href=http://www.silcom.com/~barnowl/chain-letter/archive/ae1937-04-25p1_odd-invitation_q2.htm>1937</a></font><font size=+1>; and a libelous Proctor and Gamble boycott alleging satanism from <a href=http://www.silcom.com/~barnowl/chain-letter/photo-archive/ae1986-09_proctor_image.jpg>1986</a>. An annotated <a href=http://www.silcom.com/~barnowl/chain-letter/archive/%21content.html>index</a> provides easy access to all chain letters in the archive. </font><font size=+1>An <a href=http://www.silcom.com/~barnowl/chain-letter/bibliography.htm>Annotated Bibliography</a> on Chain Letters and Pyramid Schemes contains over 425 entries. A <a href=http://www.silcom.com/~barnowl/chain-letter/glossary.htm>Glossary</a> gives precise definitions for terms used here, facilitating the independent reading of sections.<br></p>'
- - https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#openai
  - Meta Reinforcement Learning
  - Lilian Weng
  - 2019-06-23
  - ''
  - ! '<p>[Review/discussion] Meta-RL is meta-learning on reinforcement learning tasks. After trained over a distribution of tasks, the agent is able to solve a new task by developing a new RL algorithm with its internal activity dynamics. This post starts with the origin of meta-RL and then dives into three key components of meta-RL…, a good meta-learning model is expected to generalize to new tasks or new environments that have never been encountered during training. The adaptation process, essentially a <em>mini learning session</em>, happens at test with limited exposure to the new configurations. Even without any explicit fine-tuning (no gradient backpropagation on trainable variables), the meta-learning model autonomously adjusts internal hidden states to learn.</p><ul class="table-of-content" id="markdown-toc"><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#on-the-origin-of-meta-rl" id="markdown-toc-on-the-origin-of-meta-rl">On the Origin of Meta-RL</a><ul><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#back-in-2001" id="markdown-toc-back-in-2001">Back in 2001</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#proposal-in-2016" id="markdown-toc-proposal-in-2016">Proposal in 2016</a></li></ul></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#define-meta-rl" id="markdown-toc-define-meta-rl">Define Meta-RL</a><ul><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#formulation" id="markdown-toc-formulation">Formulation</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#main-differences-from-rl" id="markdown-toc-main-differences-from-rl">Main Differences from RL</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#key-components" id="markdown-toc-key-components">Key Components</a></li></ul></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#meta-learning-algorithms-for-meta-rl" id="markdown-toc-meta-learning-algorithms-for-meta-rl">Meta-Learning Algorithms for Meta-RL</a><ul><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#optimizing-model-weights-for-meta-learning" id="markdown-toc-optimizing-model-weights-for-meta-learning">Optimizing Model Weights for Meta-learning</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#meta-learning-hyperparameters" id="markdown-toc-meta-learning-hyperparameters">Meta-learning Hyperparameters</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#meta-learning-the-loss-function" id="markdown-toc-meta-learning-the-loss-function">Meta-learning the Loss Function</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#meta-learning-the-exploration-strategies" id="markdown-toc-meta-learning-the-exploration-strategies">Meta-learning the Exploration Strategies</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#episodic-control" id="markdown-toc-episodic-control">Episodic Control</a></li></ul></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#training-task-acquisition" id="markdown-toc-training-task-acquisition">Training Task Acquisition</a><ul><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#task-generation-by-domain-randomization" id="markdown-toc-task-generation-by-domain-randomization">Task Generation by Domain Randomization</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#evolutionary-algorithm-on-environment-generation" id="markdown-toc-evolutionary-algorithm-on-environment-generation">Evolutionary Algorithm on Environment Generation</a></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#learning-with-random-rewards" id="markdown-toc-learning-with-random-rewards">Learning with Random Rewards</a></li></ul></li><li><a href="https://lilianweng.github.io/lil-log/2019/06/23/meta-reinforcement-learning.html#references" id="markdown-toc-references">References</a></li></ul>'
- - https://learningtopredict.github.io/
  - "Learning to Predict Without Looking Ahead: World Models Without Forward Prediction"
  - C. Daniel Freeman, Luke Metz, David Ha (Google Brain)
  - 2019-10-29
  - ''
  - ! '<p>[<span class="smallcaps-auto">HTML</span> version of Freeman et al 2019, with videos.]</p><p>Much of model-based reinforcement learning involves learning a model of an agent’s world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware—e.g., a brain—arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call <em>observational dropout</em>, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into <em>learning</em> a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment.</p>'
- - https://david-abel.github.io/notes/icml_2019.pdf
  - "<span class=\"smallcaps-auto\">ICML</span> 2019 Notes"
  - David Abel
  - 2019-06
  - ''
  - ! '<p>The 2019 <span class="smallcaps-auto">ICML</span> edition of <a href="http://david-abel.github.io">David Abel’s</a> famous <a href="https://david-abel.github.io/notes.html">conference notes</a>: he goes to as many presentations and talks as possible, jotting down opinionated summaries &amp; equations, with a particular focus on <span class="smallcaps-auto">DRL</span>. Topics covered:</p><p>Tutorial: <span class="smallcaps-auto">PAC</span>-Bayes Theory (Part II) · <span class="smallcaps-auto">PAC</span>-Bayes Theory · <span class="smallcaps-auto">PAC</span>-Bayes and Task Awareness · Tutorial: Meta-Learning · Two Ways to View Meta-Learning · Meta-Learning Algorithms · Meta-Reinforcement Learning · Challenges and Frontiers in Meta Learning · Tuesday June: Main Conference Best Paper Talk: Challenging Assumptions in Learning Disentangled Representations Contributed Talks: Deep RL · <span class="smallcaps-auto">DQN</span> and Time Discretization · Nonlinear Distributional Gradient TD Learning · Composing Entropic Policies using Divergence Correction · TibGM: A Graphical Model Approach for RL · Multi-Agent Adversarial <span class="smallcaps-auto">IRL</span> · Policy Consolidation for Continual RL · Off-Policy Evaluation Deep RL w/o Exploration · Random Expert Distillation · Revisiting the Softmax Bellman Operator · Contributed Talks: RL Theory · Distributional RL for Efficient Exploration · Optimistic Policy Optimization via Importance Sampling · Neural Logic RL · Learning to Collaborate in <span class="smallcaps-auto">MDP</span>s · Predictor-Corrector Policy Optimization · Learning a Prior over Intent via Meta <span class="smallcaps-auto">IRL</span> · Deep<span class="smallcaps-auto">MDP</span>: Learning Late Space Models for RL · Importance Sampling Policy Evaluation · Learning from a Learner · Separating Value Functions Across Time-Scales · Learning Action Representations in RL · Bayesian Counterfactual Risk Minimization · Per-Decision Option Counting · Problem Dependent Regret Bounds in RL · A Theory of Regularized <span class="smallcaps-auto">MDP</span>s · Discovering Options for Exploration by Minimizing Cover Time · Policy Certificates: Towards Accountable RL · Action Robust RL · The Value Function Polytope · Wednesday June: Main Conference Contributed Talks: Multitask and Lifelong Learning · Domain Agnostic Learning with Disentangled Representations · Composing Value Functions in RL · <span class="smallcaps-auto">CAVIA</span>: Fast Context Adaptation via Meta Learning · Gradient Based Meta-Learning · Towards Understanding Knowledge Distillation · Transferable Adversarial Training · Contributed Talks: RL Theory · Provably Efficient Imitation Learning from Observation Alone · Dead Ends and Secure Exploration · Statistics and Samples in Distributional RL · Hessian Aided Policy Gradient · Maximum Entropy Exploration · Combining Multiple Models for Off-Policy Evaluation · Sample-Optimal ParametricQ-Learning Using Linear Features · Transfer of Samples in Policy Search · Exploration Conscious RL Revisited · Kernel Based RL in Robust <span class="smallcaps-auto">MDP</span>s · Thursday June: Main Conference Contributed Talks: RL · Batch Policy learning under Constraints · Quantifying Generalization in RL · Learning Latent Dynamics for Planning from Pixels · Projections for Approximate Policy Iteration · Learning Structured Decision Problems with Unawareness · Calibrated Model-Based Deep RL · RL in Configurable Continuous Environments · Target-Based Temporal-Difference Learning · Linearized Control: Stable Algorithms and Complexity Guarantees · Contributed Talks: Deep Learning Theory · Why do Larger Models Generalize Better? · On the Spectral Bias of Neural Nets · Recursive Sketches for Modular Deep Learning · Zero-Shot Knowledge Distillation in Deep Networks · Convergence Theory for Deep Learning via Over-Parameterization · Best Paper Award: Rates of Convergence for Sparse Gaussian Process Regression · Friday June: Workshops Workshop: AI for Climate Change · John Platt on What ML can do to help Climate Change · Jack Kelly: Why It’s Hard to Mitigate Climate Change, and How to Do Better, Andrew Ng: Tackling Climate Change with AI through Collaboration · Workshop: RL for Real Life · Panel Discussion · Workshop: Real World Sequential Decision Making · Emma Brunskill on Efficient RL When Data is Costly · Miro Dudik: Doubly Robust Off-Policy Evaluation via Shrinkage</p>'
- - https://aiimpacts.org/evidence-on-good-forecasting-practices-from-the-good-judgment-project-an-accompanying-blog-post/
  - "Evidence on good forecasting practices from the Good Judgment Project"
  - AI Impacts
  - 2019-02-15
  - ''
  - ! '<p><a href="http://aiimpacts.org/wp-content/uploads/2019/02/image2.png"><img class="alignnone wp-image-1270 size-full" src="/images/statistics/2019-aiimpacts-goodforecasting-gjp-ensemblingperformance.png" alt="https://aiimpacts.org/wp-content/uploads/2019/02/image2.png" width="608" height="394" srcset="https://aiimpacts.org/wp-content/uploads/2019/02/image2.png 608w, https://aiimpacts.org/wp-content/uploads/2019/02/image2-300x194.png 300w" sizes="(max-width: 608px) 100vw, 608px" /></a></p><p>Figure 0: The “four main determinants of forecasting accuracy.” <span id="easy-footnote-1-1260" class="easy-footnote-margin-adjust"></span><span class="easy-footnote">&lt;a href=‘https://aiimpacts.org/evidence-on-good-forecasting-practices-from-the-good-judgment-project-an-accompanying-blog-post/#easy-footnote-bottom-1-1260’ title=‘This graph can be found &lt;a href=“https://web.archive.org/web/20180408044422/http://goodjudgment.com/science.html”&gt;here&lt;/a&gt;, the <span class="smallcaps-auto">GJP</span>’s list of academic literature on this topic. The graph illustrates approximate relative effects. It will be discussed more in Section 2.’&gt;<sup>1</sup></a></span><p><span style="font-weight: 400;">Experience and data from the Good Judgment Project (<span class="smallcaps-auto">GJP</span>) provide important evidence about how to make accurate predictions. For a concise summary of the evidence and what we learn from it, see <a href="http://aiimpacts.org/evidence-on-good-forecasting-practices-from-the-good-judgment-project/">this page</a>. For a review of </span><a href="https://smile.amazon.com/Superforecasting-Science-Prediction-Philip-Tetlock/dp/0804136718/ref=sr_1_1?ie=UTF8&amp;qid=1541990711&amp;sr=8-1&amp;keywords=superforecasting+the+art+and+science+of+prediction"><i><span style="font-weight: 400;">Superforecasting</span></i></a><i><span style="font-weight: 400;">, </span></i><span style="font-weight: 400;">the popular book written on the subject, see </span><a href="https://slatestarcodex.com/2016/02/04/book-review-superforecasting/"><span style="font-weight: 400;">this blog</span></a><span style="font-weight: 400;">. </span></p><p><p><span style="font-weight: 400;">This post explores the evidence in more detail, drawing from the book, the academic literature, the older </span><a href="https://smile.amazon.com/Expert-Political-Judgment-Good-Know/dp/0691128715/ref=sr_1_1?ie=UTF8&amp;qid=1541990738&amp;sr=8-1&amp;keywords=expert+political+judgment"><i><span style="font-weight: 400;">Expert Political Judgment</span></i></a> <span style="font-weight: 400;">book, and an interview with a superforecaster.</p><p>…Tetlock describes how superforecasters go about making their predictions.<sup>56</sup> Here is an attempt at a summary:</p><ol type="1"><li>Sometimes a question can be answered more rigorously if it is first “Fermi-ized,” i.e. broken down into sub-questions for which more rigorous methods can be applied.</li><li>Next, use the outside view on the sub-questions (and/or the main question, if possible). You may then adjust your estimates using other considerations (‘the inside view’), but do this cautiously.</li><li>Seek out other perspectives, both on the sub-questions and on how to Fermi-ize the main question. You can also generate other perspectives yourself.</li><li>Repeat steps 1–3 until you hit diminishing returns.</li><li>Your final prediction should be based on an aggregation of various models, reference classes, other experts, etc.</li></ol>'
- - https://slatestarcodex.com/2019/06/04/book-review-the-secret-of-our-success/
  - "Book Review: <em>The Secret Of Our Success</em>, Joseph Henrich"
  - Scott Alexander (<span class=\"smallcaps-auto\">SSC</span>)
  - 2019-06-04
  - ''
  - ! '[Book review of an anthropologist text arguing for imitation and extensive cultural group selection as the driving force of human civilization, with imitation of other humans being the unique human cognitive skill that gave us the edge over other primates and all animals, with any kind of raw intelligence being strictly minor. Further this extensive multi-level group selectionism implies that most knowledge is embodied in apparently-arbitrary cultural practices, such as traditional food preparation or divination or hunting rituals, which are effective despite lacking any observable rationale and the actual reasons for their efficacy are inaccessible to mere reason (except possibly by a far more advanced science).]'
- - https://www.theatlantic.com/magazine/archive/1989/08/the-real-war-1939-1945/306374/
  - "The Real War 1939-1945"
  - Paul Fussell
  - 1989-08 (The Atlantic)
  - ''
  - ! '<p>[Hard-hitting longform piece on <span class="smallcaps-auto">WWII</span> about demystifying the ‘good war’ and bringing home the chaos, folly, incompetence, suffering, death, destruction visited on soldiers, and propaganda or silence which covered it all up.]</p><p>On its fiftieth anniversary, how should we think of the Second World War? What is its contemporary meaning? One possible meaning, reflected in every line of what follows, is obscured by that oddly minimizing term “conventional war.” With our fears focused on nuclear destruction, we tend to be less mindful of just what conventional war between modern industrial powers is like. This article describes such war, in a stark, unromantic manner</p>'
- - https://abandonedfootnotes.blogspot.com/2013/11/aztec-political-thought.html
  - "Aztec Political Thought "
  - Xavier Marquez
  - 2013-11-21
  - ''
  - ! '<p>A footnote on Inga Clendinnen’s extraordinary <em>Aztecs: An Interpretation</em>. If there’s a better book on the Aztecs than this, I want to read it…Consider this passage Clendinnen quotes from the Florentine Codex (one of the main sources for pre-conquest Mexica thought and culture), coming after the speech with which the Mexica greeted a new <em>tlatoani</em> (ruler; literally, the “Great Speaker”) and exhorted him to good behaviour:</p><blockquote><p>Those early and anxious exhortations to benevolent behaviour were necessary, ‘for it was said when we replaced one, when we selected someone … he was already our lord, our executioner and our enemy.’ (p. 80; the quote is from Book 6, chapter 10, in Dibble and Anderson’s translation from the Nahuatl).</p></blockquote><p>It’s an arresting thought: “he was already our lord, our executioner, and our enemy.” (Clendinnen comments on the “desolate cadence” of these words). The ruler is not understood by the Mexica as normally benevolent though potentially dangerous; he is the <em>enemy</em>, and yet as the enemy he is indispensable. There is something profoundly <em>alien</em> in this thought, with its unsettling understanding of “legitimacy,” something I do not find anywhere in the classical Western tradition of political thought…But Aztec cosmology, it turns out, goes much further than this. The ruler embodies or channels Tezcatlipoca, who is often vaguely characterized as a god of “fate and war” (and normally downplayed in favor of Huizilopochtli, e.g., in the current Te Papa exhibit on the Aztecs here in Wellington, who is more understandable as a straightforward god of war, and is viewed as the “patron” of the Tenochtitlan Mexica). But Tezcatlipoca is the more important deity: he is described at the beginning of Book 6 of the Florentine Codex as “the principal god” of the Mexica. And he is not a merciful or benevolent god; on the contrary, he represents a kind of arbitrary malice that is visited on all alike, and is variously addressed as the Enemy on Both Sides, the Mocker, He Whose Slaves We Are, and the Lord of the Smoking Mirror (for the smoky reflections in dark obsidian mirrors used by the shamans, “obscure intimations of what was to come endlessly dissolving back into obscurity,” as Clendinnen puts it [p. 148])…Clendinnen notes many other examples of the “shared and steady vision common to the different social groupings in Tenochtitlan” concerning “the casual, inventive, tireless malice of the only sacred force concerned with the fates of men,” p. 148</p><p>…When reading these passages, I cannot help but think: how could the Mexica be reconciled to their social and natural worlds with such an arbitrary, even malignant conception of divine and political authority? How is a ruler or a deity who is simultaneously seen as an enemy inspire support and commitment? As Clendinnen puts it, the puzzle is that “submission to a power which is caprice embodied is a taxing enterprise, yet it is that which the most devoted Mexica appear to have striven to achieve” (p. 76). Yet she hits on the right answer, I think, when she interprets these statements in the context of the rituals of Mexica society. In particular, she shows the Aztec state as an extraordinary example of what Clifford Geertz, referring to pre-colonial Bali, once called the “theatre state.”</p><p>I mentioned earlier that human sacrifice was one of the central practices of Mexica society. But this does not quite capture what was going on. Human sacrifice was the most intense part of the pervasive ritual practices that structured Mexica society, but it was never <em>merely</em> sacrifice. Sacrifice was the culminating act of a set of amazing spectacles, enormously powerful intensifiers of emotion that made use of the entire register of Aztec symbols and pharmacopeia, and drew on the full resources of the empire.</p>'
- - https://traditionsofconflict.com/blog/2019/2/23/notes-on-nggwal
  - Notes on Nggwal
  - William Buckner (Traditions of Conflict)
  - 2019-02-23
  - ''
  - ! '<p>During an undetermined time period preceding European contact, a gargantuan, humanoid spirit-God conquered parts of the Sepik region of Papua New Guinea. With a voracious appetite for pork and yams—and occasional demands of ritual murder—Nggwal was the tutelary spirit for a number of Sepik horticulturalist societies…what specific demands does Nggwal make? The first is for food. Nggwal must be fed, and while it is the men who are his most devoted servants and the keepers of his great secrets, it is often the responsibility of the women to provide for his subsistence, “Women are well aware of Nggwal’s hunger, for to them falls much of the gardening, hauling and cooking needed to feed him,” Tuzin writes. But how does Nggwal consume the food offered to him? “Needless to say, it is not the Tambaran [Nggwal himself] which eats the pork but the men themselves, in secret conclaves,” and Tuzin continues describing the "feasts among Tambaran Cult members in secret seclusion, during which non-members are under the impression that the food is being given directly to the spirits.</p><p>…Despite the playful, Halloween-like aspects of this practice, the <em>hangahiwa wandafunei</em> [violent spirits] were a much more serious matter. 10% of the male masks portrayed <em>hangahiwa wandafunei</em>, and they were associated with the commission of ritually sanctioned murder. These murders committed by the violent spirits were always attributed to Nggwal.</p><blockquote><p>…Traditionally, <em>hangahiwa wandafunei</em> sought out victims who were alone in their garden or on the forest paths at dusk. Pigs, dogs and chickens were also fair game. After spearing the victim, the offending <em>hangamu’w would</em> escape back to its spirit house. The wearer would replace it with the other costumes and emerge without fear of detection—in time to join the general alarm aroused by the discovery of the body.</p></blockquote><p>Sometimes the wearer would not put the mask away, however, and instead he would take it to a nearby enemy village, where a relative or other acquaintance of his would take the mask and keep it in their own community’s spirit house, until it was time to be used and transferred once more. Through these ritual killings and the passage of costumes between communities, Nggwal impels cooperation between men of even hostile villages, and unites them in cult secrecy.</p><p><em>Nggwal, who travels in structures of fiber and bone atop rivers of blood.</em></p>'
- - https://www.babelmatrix.org/works/sk/V%c3%a1lek,_Miroslav-1927/Zab%c3%adjanie_kr%c3%a1likov/en/2301-The_killing_of_rabbits
  - "Killing Rabbits"
  - Miroslav Válek
  - '1963'
  - ''
  - ! '<div class="line-block">On Sunday after breakfast,<br />when the air is about halfway to ice,<br />the thin flutes of the mice are whistling in the chimney,<br />on Sunday after breakfast<br />to walk over fresh snow<br />to the cages.<br /><br />Pull off the gloves for the rose feast.<br />Impale them on the fence<br />like freshly severed palms<br />and smoke through the door.<br />And then insert the hungry hand<br />and with smoke in your teeth utter sweet words,<br />caressing and gentle,<br />a touch of pity,<br />then a firm grab of the skin,<br />lifting it from the warm straw.<br /><br />On Sunday after breakfast<br />sniff the ammonia.<br /><br />For a while hold it head downwards,<br />watch the ears turning dark red,<br />gently stroke its back,<br />exhale, carry it off<br />and abruptly strike the back of its neck with the right hand.<br /><br />Once more in your palm feel the effort<br />of a now useless leap,<br />feel a weight in your hand,<br />sweet taste on your palate,<br />hear the rabbits’ heaven open<br />and fistfuls of fur falling from it.<br /><br />Vienna blue,<br />Flemish giant,<br />French lop-eared,<br />Czech piebald,<br />and even the bastards of no matter what blood,<br />they all die equally swiftly<br />and soundlessly,<br /><br />On Monday with blue under your eyes keep silent,<br />on Tuesday reflect on the fate of the world,<br />on Wednesday and Thursday<br />bring out the steam engine<br />and discover the stars,<br />on Friday think of others,<br />and especially of blue eyes,<br />all week long feel sorry for orphans<br />and admire flowers,<br />on Saturday step pink from your bath<br />and fall asleep on her lips.<br /><br />On Sunday after breakfast<br />kill a rabbit.</div>'
- - https://typesetinthefuture.com/2014/12/01/alien/
  - '<em>Alien</em>'
  - Dave Addey (Typeset In The Future)
  - 2014-12-01
  - ''
  - ! '[Discussion with screenshots of the classic Ridley Scott SF movie <em>Alien</em>, which makes extensive use of Helvetica, Futura, Eurostile Bold Extended, and other "modern" fonts to give a futuristic industrial feel to all of the (multilingual) spaceship/computer displays, controls, and credits; <em>Alien</em> also makes intriguing use of many logos, icons, and symbols for quick communication, tracing back to the Semiotic Standard.]'
- - https://typesetinthefuture.com/2016/06/19/bladerunner/
  - '<em>Blade Runner</em>'
  - Dave Addey (Typeset In The Future)
  - 2016-06-19
  - ''
  - ! '[Discussion with screenshots of the classic Ridley Scott SF movie <em>Blade Runner</em>, which employs typography to disconcert the viewer, with unexpected choices, random capitalization and small caps, corporate branding/advertising, and the mashed-up creole multilingual landscape of noir cyberpunk LA (plus discussion of the buildings and sets, and details such as call costs being correctly inflation-adjusted).]'
- - https://perspectives.mvdirona.com/2012/02/observations-on-errors-corrections-trust-of-dependent-systems/
  - "Observations on Errors, Corrections, & Trust of Dependent Systems"
  - James Hamilton
  - 2012-02-29
  - ''
  - ! '<p>Every couple of weeks I get questions along the lines of “should I checksum application files, given that the disk already has error correction?” or “given that <span class="smallcaps-auto">TCP</span>/IP has error correction on every communications packet, why do I need to have application level network error detection?” Another frequent question is “non-<span class="smallcaps-auto">ECC</span> mother boards are much cheaper—do we really need <span class="smallcaps-auto">ECC</span> on memory?” The answer is always yes. At scale, error detection and correction at lower levels fails to correct or even detect some problems. Software stacks above introduce errors. Hardware introduces more errors. Firmware introduces errors. Errors creep in everywhere and absolutely nobody and nothing can be trusted Over the years, each time I have had an opportunity to see the impact of adding a new layer of error detection, the result has been the same. It fires fast and it fires frequently. In each of these cases, I predicted we would find issues at scale. But, even starting from that perspective, each time I was amazed at the frequency the error correction code fired.</p><p>On one high scale, on-premise server product I worked upon, page checksums were temporarily added to detect issues during a limited beta release. The code fired constantly, and customers were complaining that the new beta version was “so buggy they couldn’t use it”. Upon deep investigation at some customer sites, we found the software was fine, but each customer had one, and sometimes several, latent data corruptions on disk. Perhaps it was introduced by hardware, perhaps firmware, or possibly software. It could have even been corruption introduced by one of our previous release when those pages where last written. Some of these pages may not have been written for years. I was amazed at the amount of corruption we found and started reflecting on how often I had seen “index corruption” or other reported product problems that were probably corruption introduced in the software and hardware stacks below us. The disk has complex hardware and hundreds of thousands of lines of code, while the storage area network has complex data paths and over a million lines of code. The device driver has tens of thousands of lines of code. The operating systems has millions of lines of code. And our application had millions of lines of code. Any of us can screw-up, each has an opportunity to corrupt, and its highly likely that the entire aggregated millions of lines of code have never been tested in precisely the combination and on the hardware that any specific customer is actually currently running.</p><p>…This incident reminds us of the importance of never trusting anything from any component in a multi-component system. Checksum every data block and have well-designed, and well-tested failure modes for even unlikely events. Rather than have complex recovery logic for the near infinite number of faults possible, have simple, brute-force recovery paths that you can use broadly and test frequently. Remember that all hardware, all firmware, and all software have faults and introduce errors. Don’t trust anyone or anything. Have test systems that bit flips and corrupts and ensure the production system can operate through these faults—at scale, rare events are amazingly common.</p>'
- - /docs/technology/2000-cook.pdf
  - "How Complex Systems Fail: Being a Short Treatise on the Nature of Failure; How Failure is Evaluated; How Failure is Attributed to Proximate Cause; and the Resulting New Understanding of Patient Safety"
  - "Richard I. Cook"
  - '2000'
  - ''
  - ! '<ol type="1"><li>Complex systems are intrinsically hazardous systems.</li><li>Complex systems are heavily and successfully defended against failure.</li><li>Catastrophe requires multiple failures—single point failures are not enough.</li><li>Complex systems contain changing mixtures of failures latent within them</li><li>Complex systems run in degraded mode.</li><li>Catastrophe is always just around the corner.</li><li>Post-accident attribution accident to a ‘root cause’ is fundamentally wrong.</li><li>Hindsight biases post-accident assessments of human performance.</li><li>Human operators have dual roles: as producers &amp; as defenders against failure.</li><li>All practitioner actions are gambles.</li><li>Actions at the sharp end resolve all ambiguity.</li><li>Human practitioners are the adaptable element of complex systems.</li><li>Human expertise in complex systems is constantly changing.</li><li>Change introduces new forms of failure.</li><li>Views of ‘cause’ limit the effectiveness of defenses against future events.</li><li>Safety is a characteristic of systems and not of their components.</li><li>People continuously create safety.</li><li>Failure free operations require experience with failure.</li></ol>'
- - https://terrytao.files.wordpress.com/2010/10/cosmic-distance-ladder.pdf
  - The Cosmic Distance Ladder
  - Terence Tao
  - 2010-10
  - ''
  - ! '[Slideshow presentation on the "cosmic ladder": how to calculate the distances between planets and stars by using geometry, brightness, radar, and progressively estimating further and further, solving one unknown at a time, from the Ancient Greeks to today.]'
- - https://www.wired.com/1996/12/ffglass/
  - "Mother Earth Mother Board"
  - Neal Stephenson
  - 1996-12
  - ''
  - ! '[Classic longform essay by SF author Neal Stephenson in which he travels the world tracing the (surprisingly few) transcontinental fiber optic cables which bind the world together and power the Internet; cables combine cutting-edge technology, deep sea challenges, high finance, and global geo-politics/espionage all in one tiny package.]'
- - https://core.ac.uk/download/pdf/33895541.pdf#page=6
  - Anthropological invariants in travel behavior
  - C. Marchetti
  - 1994-09
  - 10.1016/0040-1625(94)90041-8
  - ! '<p>Personal travel appears to be much more under the control of basic instincts than of economic drives. This may be the reason for the systematic mismatch between the results of cost benefit analysis and the actual behavior of travelers. In this paper we put together a list of the basic instincts that drive and contain travelers’ behavior, showing how they mesh with technological progress and economic constraints.</p><p>…the empirical conclusion reached by Zahavi is that all over the world the <em>mean exposure time</em> for man is around <em>one hour per day</em>.</p><p>…When introducing mechanical transportation with speeds higher than 5 km/hr, the physical size of the city can grow in proportion, as the historical analysis applied to the city of Berlin clearly shows (Figure 2). The commuting fields, based on cars, of a dozen American cities are reported in Figure 3. On the same chart and to the same scale, the Greek villages of Figure 1 are shown in schematic form. <em>Cars make all the difference</em>. As they have a speed of 6 or 7 times greater than a pedestrian, they expand daily connected space 6 or 7 times in linear terms, or about 50 times in area. Ancient cities typically had a maximum population of about 1 million people. Today the population may tend to reach 50 million people in conurbations like Mexico City (Figure 4), with a population density equal to that of Hadrian’s Rome. If the Japanese complete a <em>Shinkansen Maglev</em> (a magnetically levitated train) connecting Tokyo to Osaka in less than one hour with a large transportation capacity, then we may witness a city of 100 million people. If we expand the reasoning, we can muse about a city of 1 billion people, which would require an efficient transportation system with a <em>mean speed</em> of only 150 km/hr.</p><p>…There is another fundamental observation made by Zahavi that links instincts and money. Because of its generality it could be dubbed as a money instinct. People spend about 130Jo of their disposable income on traveling. The percentage is the same in Germany or Canada, now or in 1930. Within this budget, time and money are allocated between the various modes of transport available to the traveller in such a way as to <em>maximize mean speed</em>. The very poor man walks and makes 5 km/ day, the very rich man flies and makes 500 km/ day. The rest sit in between. People owning a car use it for about one hour a day (Figure 12) and travel about 50 km/ day (Figure 13). People who do not have a car spend less than 13% of their disposable income, however, presumably because public services are underrated and consequently there is no possibility of spending that share of income traveling one hour per day (Figure 14). Contrary to the risk of all this “exposure,” the number of people killed by road traffic seems to be invariant to the number of vehicles (Figure 15).</p><p>Technology introduces faster and faster means of transportation, which also are more expensive in terms of time of use. These new technologies are introduced roughly every 55 years in tune with the Kondratiev cycle. Their complete adoption takes about 100 years (Figure 16). We are now in the second Kondratiev for cars and most mobility comes from them. It was about 10 km/ day earlier, and is now about 40 km/ day. Airplanes are making inroads into this situation and they promise to bring the next leap forward in mobility, presumably with the help of Maglev trains. Hypersonic airplanes promise to glue the world into a single territory: the famous global village.</p>'
- - /docs/economics/2017-sichel.pdf
  - "The Price of Nails since 1700: Even Simple Products Experienced Large Price Declines"
  - Daniel E. Sichel
  - 2017-04
  - ''
  - ! '<p>Many products—such as lighting and computing—have undergone revolutionary changes since the beginning of the industrial revolution. This paper considers the opposite end of the spectrum of product change, focusing on nails. Nails are a simple, everyday product whose form has changed relatively little over the last three centuries, and this paper constructs a continuous, constant-quality price index for nails since 1695. These data indicate that the price of nails fell significantly relative to an overall basket of consumption goods as reflected in the <span class="smallcaps-auto">CPI</span>, with the preferred index falling by a factor of about 15 times from the mid 1700s to the mid 1900s. While these declines were nowhere near as rapid as those for lighting and computing, they were still quite sizable and large enough to enable the development of other products and processes and contribute to downstream changes in patterns of economic activity. Moreover, with the relative price of nails having been so much higher in an earlier period, nails played a much more important role in economic activity in an earlier period than they do now. [A not yet completed section of the paper will use a growth accounting framework to assess the proximate sources of the change in the price of nails.]</p>'
- - https://pseudoerasmus.com/2017/10/02/ijd/
  - 'Labour repression & the Indo-Japanese divergence'
  - Pseudoerasmus
  - 2017-10-02
  - ''
  - ! '<p class="p1">So I illustrate the relevance of labour relations to economic development through the contrasting fortunes of India’s and Japan’s cotton textile industries in the interwar period, with some glimpses of Lancashire, the <span class="smallcaps-auto">USA</span>, interwar Shanghai, etc.</p><p class="p1"><em style="color:#444444;">TL;DR version</em>: At the beginning of the 20<sup>th</sup> century, the Indian and the Japanese textile industries had similar levels of wages and productivity, and both were exporting to global markets. But by the 1930s, Japan had surpassed the UK<span class="s1"> to become the world’s dominant exporter of textiles; while </span>the Indian industry withdrew behind the tariff protection of the British Raj<span class="s1">. </span><span class="s1">Technology, human capital, and industrial policy were minor determinants of this divergence, or at least they mattered conditional on labour relations.</span></p><p class="p1"><span class="s1">Indian textile mills were obstructed by </span>militant workers who <span class="s1">defended employment levels, resisted productivity-enhancing measures, and demanded high wages <em>relative</em> to effort. But Japanese mills suppressed strikes and </span>busted unions; extracted from workers much greater effort for a given increase in wages; and imposed technical &amp; organisational changes <em>at will</em>. The bargaining position of workers was much weaker in Japan than in India, because Japan had a true “surplus labour” economy with a large number of workers ‘released’ from agriculture into industry. But late colonial India was rather ‘Gerschenkronian’, where employers’ options were more limited by a relatively inelastic supply of labour.</p><p class="p1">The state also mattered. The British Raj did little to restrain on behalf of <em>Indian</em> capitalists the exercise of monopoly power by Indian workers. Britain had neither the incentive, nor the stomach, nor the legitimacy to do much about it. But a key element of the industrial policy of the pre-war Japanese state was repression of the labour movement.</p><p><strong>Note</strong>: By “labour repression” I do <em>not</em> mean coercing workers, or suppressing wage levels, but actions which restrain the effects of worker combinations.</p><p>Nor am I saying unions are bad! I’ve written before that unions in Germany are <a href="https://pseudoerasmus.com/2014/08/01/anthropology-of-financial-crises/" target="_blank" rel="noopener">great</a>.</p><p>Also, I do <em>not</em> claim this post has any relevance for <em>today’s</em> developed countries. It’s mainly about labour-intensive manufacturing in historical industrialisation or in today’s developing countries.</p><ol class="ol1"><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#intro">Lancashire v India v Japan</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#c87">The cotton mills on the eve of the Great War</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#intense">Labour intensification &amp; economic development</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#IJD">Stagnation in India &amp; productivity explosion in Japan</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#tech">Technological divergence?</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#BKL">Bargaining over capital-labour ratios</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#resist">Labour resistance in economic history</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#LVG"><span class="s1">“The labour problem”: Lewis versus Gerschenkron</span></a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#WB">Workers unite but bosses eat other bosses</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#strikes">Strikes in India versus Japan</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#milit">The “demand for militancy”</a></li><li class="li1">“<a href="https://pseudoerasmus.com/2017/10/02/ijd/#surplus">Surplus Labour” in Japan &amp; India</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#elastic">Rationalisation &amp; the “wage elasticity of effort”</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#mgmt">Managerial &amp; organisational failures?</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#china">Quasi-natural experiment: Japanese mills in interwar Shanghai</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#state">How does the State matter?</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#jp">Labour repression as industrial policy in Japan</a></li><li class="li1"><a href="https://pseudoerasmus.com/2017/10/02/ijd/#raj">The British Raj was not a “committee for managing the common affairs of the (Indian) bourgeoisie”</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#jute">Jute: the exception that proves the rule</a></li><li><a href="https://pseudoerasmus.com/2017/10/02/ijd/#final">Random implications</a></li></ol>'
- - https://philpapers.org/archive/SINPG.pdf
  - Possible Girls
  - Neil Sinhababu
  - 2008-05-25
  - '10.1111/j.1468-0114.2008.00319.x'
  - ! '<p>I argue that if David Lewis’ modal realism is true, modal realists from different possible worlds can fall in love with each other. I offer a method for uniquely picking out possible people who are in love with us and not with our counterparts. Impossible lovers and trans-world love letters are considered. Anticipating objections, I argue that we can stand in the right kinds of relations to merely possible people to be in love with them and that ending a trans-world relationship to start a relationship with an actual person isn’t cruel to one’s otherworldly lover.</p>'
- - https://ansuz.sooke.bc.ca/entry/23
  - "What Color are your bits?"
  - Matthew Skala
  - 2004-06-10
  - ''
  - ! '[Philosophy piece attempting to explain, via an amusing analogy to classic <span class=\"smallcaps-auto\">RPG</span> game <em>Paranoia</em>, to programmers how the rest of the world sees information: as tainted, in a dualist immaterial sense, by their history. Two bits are not identical even if they are identical, because they may have different histories; these are recorded and enforced by consensual society-wide hallucinations, such as intellectual property law. This may be insane, like in <em>Paranoia</em>, but that is how the human world works, and why many clever copyright hacks will fail.]'
- - https://www.hoover.org/research/optimistic-thought-experiment
  - "The Optimistic Thought Experiment"
  - Peter Thiel
  - 2008-01-28
  - ''
  - ! '<p>[An interesting thought experiment to assess what must happen for an “optimistic” version of the future to unfold, and the possibility of an impending apocalypse and how that might lead to financial bubbles. The article is eye opening, depressing and fascinating. Peter argues that science in all of its form (nuclear weapons, biological catastrophes, etc) has vastly increased the probability of some form of apocalypse; betting on the apocalypse makes no sense so rational investors don’t do it; globalization is the anti-apocalypse bet; financial bubbles are bets on globalization; and the recent slate of financial bubbles, which he calls unprecedented in history, are related to the growing sense of impending doom.]</p><p>One would not have thought it possible for the internet bubble of the late 1990s, the greatest boom in the history of the world, to be replaced within five years by a real estate bubble of even greater magnitude and worse stupidity. Under more normal circumstances, one would not have thought that the same mistake could happen twice in the lifetimes of the people involved…</p><p>The most straightforward explanation begins with the view that all of these bubbles are not truly separate, but instead represent different facets of a single Great Boom of unprecedented size and duration. As with the earlier bubbles of the modern age, the Great Boom has been based on a similar story of globalization, told and retold in different ways – and so we have seen a rotating series of local booms and bubbles as investors price a globally unified world through the prism of different markets.</p><p>Nevertheless, this Great Boom is also very different from all previous bubbles. This time around, globalization either will succeed and humanity will achieve a degree of freedom and prosperity that can scarcely be imagined, or globalization will fail and capitalism or even humanity itself may come to an end. The real alternative to good globalization is world war. And because of the nature of today ’s technology, such a war would be apocalyptic in the twenty-first century. Because there is not much time left, the Great Boom, taken as a whole, either is not a bubble at all, or it is the final and greatest bubble in history…there is no good scenario for the world in which China fails.</p><p>…But because we do not know how our story of globalization will end, we do not yet know which it is. Let us return to our thought experiment. Let us assume that, in the event of successful globalization, a given business would be worth $100/share, but that there is only an intermediate chance (say 1:10) of successful globalization. The other case is too terrible to consider. Theoretically, the share should be worth $10, but in every world where investors survive, it will be worth $100. Would it make sense to pay more than $10, and indeed any price up to $100? Whether in hope or desperation, the perceived lack of alternatives may push valuations to much greater extremes than in non-apocalyptic times.</p>'
- - https://digitalcommons.sia.edu/cgi/viewcontent.cgi?article=1007&context=stu_proj#pdf
  - "Birkin Demand: A Sage & Stylish Investment"
  - Brittanny Newsom
  - 2016-12-19
  - ''
  - ! '<p>History · Design · Craftsmanship &amp; Quality · How To Buy A Birkin · Demand &amp; Exclusivity · The Secondhand Market · Clientele · Why the Birkin Is A Safe Investment · Investment Factors · Investment Pricing Factors · Comparisons with Other Investments · Fake vs. Real · How the Birkin Remains Dominant · The Media · The Defaced Birkin · Conclusion</p><p>Birkin bags are carefully handcrafted. The creation process for each bag can take over 18 hours. That number can double if working on a Birkin accessorized with diamonds. The artisans who craft these bags are carefully screened and require years of high quality experience even before being considered for the job. “Hermès has a reputation of hiring mostly artisans who have graduated from the École Grégoire Ferrandi; a school that specializes in working with luxurious leathers.” It also typically takes about 2 years to train an Hermès craftsman, with each one supervised by an existing craftsman.Preparing the leather is the first step towards crafting the bag. The leather is examined for any defects an animal skin may have mosquito bites or wounds that must be repaired before the skin’s tanning. Leathers are obtained from different tanners in France, resulting in various smell sand textures. The stitching of the bag is also very precise. The bag is held together using wooden clamp, while the artisan applies each individual stitch on the bag. The linen that is used during the stitching process is waterproof and has a beeswax coating for rot prevention. Most Birkin bags are created with same color threads, but some rare bags have white threads even if the bag is not white. “More than 90% of the bag is hand stitched because it allows more freedom to shape the bag and makes it more resilient.” That’s when the hardware process begins. Unlike other bags, the hardware is attached using the unique Hermès process called “pearling” rather than by using screws. Artisans put a “small nail through a corner hole on the back of the clasp,the leather and the front clasp, take an awl with a concave tip and tap the bit of nail with a hammer gently in a circle until it is round like a tiny pearl.” This process ensures that the pearls will hold the two pieces of metal together forever. The bag is then turned right side out and ironed into shape.</p><p>…As secondhand market sales have grown, interest from first time buyers has also increased. This shows the Birkin bag is an important sales channel for an expanding global luxury product market. Such growth has propelled the Birkin to near legendary status in a very demanding market. According to Bag Hunter, “Birkin bags have climbed in value by 500% over the past 35 years, and an increase expected to double over the next 10 years.”</p><p>…Simply stated, it appears that the bag’s success hinges on this prestigious perception. A Birkin, terribly difficult to get is therefore highly coveted. In our global economy, that’s all the brand needs to pack the infinite waiting list. It is fashion’s version of Darwinism. We always want what we can’t have, so we will do whatever we can to get it. For instance, Victoria Beckham, the posh clothing designer, and wife of David Beckham reportedly owns about 100 Birkins, collectively valued at $2 million. It includes a pink Ostrich leather Birkin worth $150,000. Despite the fact that she has introduced her own line of handbags, she’s been spotted by the paparazzi wearing a Birkin bag. Kris Jenner also has a massive Birkin collection that she flaunts via social media and the willing participation of paparazzi. Her collection includes an Electric Blue 35cm which is supposedly worth $19,000. Actress Katie Holmes has gained attention for a bold red Birkin, while Julianne Moore has been seen wearing a hunter green 40cm with gold hardware. Julia Roberts and Eva Longoria all have even been seen with the bag. Even B-listed personalities such as reality star, Nicole Richie, with a black Birkin workout bag, is famously noted as frequently asking the paparazzi, “Did you get my bag?”. The Birkin has looked extra special on the arms of models, Alessandra Ambrosio and Kate Moss. Singers such as Jennifer Lopez and Courtney Love ironically show off their Birkins, and even world leaders such as Princess Mary of Denmark, with her black crocodile Birkin worth $44,500, is aware of its meaning and status.</p>'
- - https://www.theatlantic.com/magazine/archive/2004/05/a-sea-story/302940/
  - "A Sea Story: One of the worst maritime disasters in European history took place a decade ago. It remains very much in the public eye. On a stormy night on the Baltic Sea, more than 850 people lost their lives when a luxurious ferry sank below the waves. From a mass of material, including official and unofficial reports and survivor testimony, our correspondent has distilled an account of the Estonia's last moments—part of his continuing coverage for the magazine of anarchy on the high seas"
  - William Langewiesche (The Atlantic)
  - 2004-05
  - ''
  - ! '<p>Psychology and survival: the <em>MS Estonia</em> was a car ferry whose nose came off in a Baltic storm at night. It did not sink instantly, but nearly 90% of the passengers on it died by not reacting fast enough and escaping to the deck where they had a chance to survive the tilting ship before it went under. The people who were worried by the sound of the clanking/thumping when the ship first encountered issues mostly survived, and anyone who dithered (including just by trying to get dressed before running to the deck) died, trapped when the hallways and stairways went vertical or filled up with water. A large number of the people who survived were naked or in their underwear, or were strong young men who could still climb and force their way out, after leaving behind their loved ones.</p>'
- - https://www.newyorker.com/magazine/2018/03/19/reddit-and-the-struggle-to-detoxify-the-internet
  - "Reddit and the Struggle to Detoxify the Internet: How do we fix life online without limiting free speech?"
  - Andrew Marantz (The New Yorker)
  - 2018-03-12
  - ''
  - ! '<p>Although redditors didn’t yet know it, Huffman could edit any part of the site. He wrote a script that would automatically replace his username with those of The_Donald’s most prominent members, directing the insults back at the insulters in real time: in one comment, “Fuck u/Spez” became “Fuck u/Trumpshaker”; in another, “Fuck u/Spez” became “Fuck u/<span class="smallcaps-auto">MAGA</span>docious.” The_Donald’s users saw what was happening, and they reacted by spinning a conspiracy theory that, in this case, turned out to be true. “Manipulating the words of your users is fucked,” a commenter wrote. “Even Facebook and Twitter haven’t stooped this low.” “Trust nothing.”</p><p>…In October, on the morning the new policy was rolled out, Ashooh sat at a long conference table with a dozen other employees. Before each of them was a laptop, a mug of coffee, and a few hours’ worth of snacks. “Welcome to the Policy Update War Room,” she said. “And, yes, I’m aware of the irony of calling it a war room when the point is to make Reddit less violent, but it’s too late to change the name.” The job of policing Reddit’s most pernicious content falls primarily to three groups of employees—the community team, the trust-and-safety team, and the anti-evil team—which are sometimes described, respectively, as good cop, bad cop, and RoboCop. Community stays in touch with a cross-section of redditors, asking them for feedback and encouraging them to be on their best behavior. When this fails and redditors break the rules, trust and safety punishes them. Anti-evil, a team of back-end engineers, makes software that flags dodgy-looking content and sends that content to humans, who decide what to do about it.</p><p>Ashooh went over the plan for the day. All at once, they would replace the old policy with the new policy, post an announcement explaining the new policy, warn a batch of subreddits that they were probably in violation of the new policy, and ban another batch of subreddits that were flagrantly, irredeemably in violation. I glanced at a spreadsheet with a list of the hundred and nine subreddits that were about to be banned (r/<span class="smallcaps-auto">KKK</span>, r/KillAllJews, r/KilltheJews, r/KilltheJoos), followed by the name of the employee who would carry out each deletion, and, if applicable, the reason for the ban (“mostly just swastikas?”). “Today we’re focusing on a lot of Nazi stuff and bestiality stuff,” Ashooh said. “Context matters, of course, and you shouldn’t get in trouble for posting a swastika if it’s a historical photo from the 1936 Olympics, or if you’re using it as a Hindu symbol. But, even so, there’s a lot that’s clear-cut.” I asked whether the same logic—that the Nazi flag was an inherently violent symbol—would apply to the Confederate flag, or the Soviet flag, or the flag under which King Richard fought the Crusades. “We can have those conversations in the future,” Ashooh said. “But we have to start somewhere.”</p><p>At 10 a.m., the trust-and-safety team posted the announcement and began the purge. “Thank you for letting me do DylannRoofInnocent,” one employee said. “That was one of the ones I really wanted.”</p><p>“What is ReallyWackyTicTacs?” another employee asked, looking down the list. “Trust me, you don’t want to know,” Ashooh said. “That was the most unpleasant shit I’ve ever seen, and I’ve spent a lot of time looking into Syrian war crimes.”</p><p>Some of the comments on the announcement were cynical. “They don’t actually want to change anything,” one redditor wrote, arguing that the bans were meant to appease advertisers. “It was, in fact, never about free speech, it was about money.” One trust-and-safety manager, a young woman wearing a leather jacket and a ship captain’s cap, was in charge of monitoring the comments and responding to the most relevant ones. “Everyone seems to be taking it pretty well so far,” she said. “There’s one guy, freespeechwarrior, who seems very pissed, but I guess that makes sense, given his username.” “People are making lists of all the Nazi subs getting banned, but nobody has noticed that we’re banning bestiality ones at the same time,” Ashooh said…“I’m going to get more cheese sticks,” the woman in the captain’s cap said, standing up. “How many cheese sticks is too many in one day? At what point am I encouraging or glorifying violence against my own body?” “It all depends on context,” Ashooh said.</p><p>I understood why other companies had been reluctant to let me see something like this. Never again would I be able to read a lofty phrase about a social-media company’s shift in policy—“open and connected,” or “encouraging meaningful interactions”—without imagining a group of people sitting around a conference room, eating free snacks and making fallible decisions. Social networks, no matter how big they get or how familiar they seem, are not ineluctable forces but experimental technologies built by human beings. We can tell ourselves that these human beings aren’t gatekeepers, or that they have cleansed themselves of all bias and emotion, but this would have no relation to reality. “I have biases, like everyone else,” Huffman told me once. “I just work really hard to make sure that they don’t prevent me from doing what’s right.”</p>'
- - https://www.justice.gov/opa/pr/administrators-deepdotweb-indicted-money-laundering-conspiracy-relating-kickbacks-sales
  - "Administrators of DeepDotWeb Indicted for Money Laundering Conspiracy, Relating to Kickbacks for Sales of Fentanyl, Heroin and Other Illegal Goods on the Darknet: Prior to the Website’s Seizure by the Federal Government, the Defendants Allegedly Referred Hundreds of Thousands of Users to Darknet Marketplaces, Who in Turn Completed Hundreds of Millions’ of Dollars’ Worth of Transactions in Drugs, Firearms and Other"
  - US Department of Justice
  - 2019-05-08
  - ''
  - ! '<p>The alleged owners and operators of a website known as DeepDotWeb (<span class="smallcaps-auto">DDW</span>) have been indicted by a federal grand jury sitting in Pittsburgh, Pennsylvania, for money laundering conspiracy, relating to millions of dollars in kickbacks they received for purchases of fentanyl, heroin, and other illegal contraband by individuals referred to Darknet marketplaces by <span class="smallcaps-auto">DDW</span>. The website has now been seized by court order…In an indictment unsealed today, Tal Prihar, 37, an Israeli citizen residing in Brazil, and Michael Phan, 34, an Israeli citizen residing in Israel, were charged on April 24, 2019, in a one-count indictment by a federal grand jury in Pittsburgh. Prihar was arrested on May 6, 2019 by French law enforcement authorities in Paris, pursuant to a provisional arrest request by the United States in connection with the indictment. Phan was arrested in Israel on May 6 pursuant to charges in Israel. Further, the <span class="smallcaps-auto">FBI</span> seized <span class="smallcaps-auto">DDW</span>, pursuant to a court order issued by the U.S. District Court for the Western District of Pennsylvania.</p><p>…<span class="smallcaps-auto">DDW</span> provided users with direct access to numerous online Darknet marketplaces, not accessible through traditional search engines, at which vendors offered for sale illegal narcotics such as fentanyl, carfentanil, cocaine, heroin, and crystal methamphetamine, firearms, including assault rifles, malicious software and hacking tools; stolen financial information and payment cards and numbers; access device-making equipment and other illegal contraband.</p><p>Prihar and Phan received kickback payments, representing commissions on the proceeds from each purchase of the illegal goods made by individuals referred to a Darknet marketplace from the <span class="smallcaps-auto">DDW</span> site. These kickback payments were made in virtual currency, such as bitcoin, and paid into a <span class="smallcaps-auto">DDW</span>-controlled bitcoin “wallet.” To conceal and disguise the nature and source of the illegal proceeds, totaling over $15 million, Prihar and Phan transferred their illegal kickback payments from their <span class="smallcaps-auto">DDW</span> bitcoin wallet to other bitcoin accounts and to bank accounts they controlled in the names of shell companies.</p><p>…During the time period relevant to this Indictment, <span class="smallcaps-auto">DDW</span>’s referral links were widely used by users in the Western District of Pennsylvania and elsewhere to access and then create accounts on many Darknet marketplaces, including AlphaBay Market, Agora Market, Abraxas Market, Dream Market, Valhalla Market, Hansa Market, TradeRoute Market, Dr. D’s, Wall Street Market, and Tochka Market. When AlphaBay was seized by law enforcement in 2017, it was one of the largest Darknet markets that offered illegal drugs, fraudulent identification materials, counterfeit goods, hacking tools, malware, firearms, and toxic chemicals. Approximately 23.6% of all orders completed on AlphaBay were associated with an account created through a <span class="smallcaps-auto">DDW</span> referral link, meaning that <span class="smallcaps-auto">DDW</span> received a referral fee for 23.6% of all orders made on AlphaBay.</p><p>Over the course of the conspiracy, the defendants referred hundreds of thousands of users to Darknet marketplaces. These users in turn completed hundreds of millions’ of dollars’ worth of transactions, including purchases of illegal narcotics such as fentanyl, carfentanil, cocaine, heroin, and crystal methamphetamine; firearms, including assault rifles; malicious software and hacking tools; stolen financial information and payment cards and numbers; access device-making equipment; and other illegal contraband. Through the use of the referral links, the defendants received kickbacks worth millions of dollars, generated from the illicit sales conducted on Darknet marketplace accounts created through the site.</p><p>…Between in and around November 2014 and April 10, 2019, <span class="smallcaps-auto">DDW</span> received approximately 8,155 bitcoin in kickback payments from Darknet marketplaces, worth approximately $8,414,173 when adjusted for the trading value of bitcoin at the time of each transaction. The bitcoin was transferred to <span class="smallcaps-auto">DDW</span>’s bitcoin wallet, controlled by the defendants, in a series of more than 40,000 deposits and was subsequently withdrawn to various destinations both known and unknown to the grand jury through over 2,700 transactions. Due to bitcoin’s fluctuating exchange rate, the value of the bitcoin at the time of the withdrawals from the <span class="smallcaps-auto">DDW</span> bitcoin wallet equated to approximately $15,489,415. In seeking to conceal their illicit activities and protect their criminal enterprise and the illegal proceeds it generated, the defendants set up numerous shell companies around the world. The defendants used these companies to move their ill-gotten gains and conduct other activity related to <span class="smallcaps-auto">DDW</span>. These companies included WwwCom Ltd., M&amp;T Marketing, Imtech, O.T.S.R. Biztech, and Tal Advanced Tech.</p>'
- - https://www.latimes.com/archives/la-xpm-1994-12-04-tm-4992-story.html
  - '<em>Tokyo Style</em> (book review)'
  - Barbara Thornburg (LA Times)
  - 1994-12-04
  - ''
  - ! '<p>But have you ever wondered how ordinary folk live? The cocktail attendants and department store employees, painters and construction workers, artists and designers? 38-year-old photographer and architectural writer Kyoichi Tsuzuki shot more than 100 Tokyo apartments of working men and women to create his tongue-in-cheek peek into their lives. The book, <em>Tokyo Style</em>, recently distributed in the United States through <span class="smallcaps-auto">RAM</span> Publications U.S.A., offers images that are the antithesis of the restrained traditional Japanese interior we’ve come to expect, and are a lot more lively. Says Tsuzuki, “In the traditional Japanese house, everything was put away. In these Tokyo apartments, everything is out. You see people’s lives displayed.”</p><p>While many Japanese dream of having more space, most cannot afford to. A 1400-square-foot house in the Tokyo area costs $1.3 million, while the average salaried worker makes $37,000 a year. Instead, the Japanese have refined the art of living in small places. Tsuzuki dubs it “cockpit living” and extols its benefits. “You have everything at your fingertips–your food, CD, TV, computer–without leaving your bed.”…Neighborhood public baths, restaurants and coffeehouses furnish food and bathing, right outside your door. “It’s the opposite of L.A., where you have to drive everywhere,” Tsuzuki says.</p>'
- - https://www.smithsonianmag.com/travel/how-japan-copied-american-culture-and-made-it-better-180950189/?all
  - "How Japan Copied American Culture and Made it Better: If you’re looking for some of America’s best bourbon, denim and burgers, go to Japan, where designers are re-engineering our culture in loving detail"
  - Tom Downey (Smithsonian Magazine)
  - 2014-04
  - ''
  - ! '<p>[Account of specialty retailers and craftsmen in Japan, who love Americana, focusing on: old bourbon, jazz, workwear (“railroad jackets, canvas dusters, flannel shirts, double-kneed pants”; especially denim), hamburgers, and preppy “Ivy Style” fashion.]</p><p>In Japan, the ability to perfectly imitate—and even improve upon—the cocktails, cuisine and couture of foreign cultures isn’t limited to American products; there are spectacular French chefs and masterful Neapolitan pizzaioli who are actually Japanese. There’s something about the perspective of the Japanese that allows them to home in on the essential elements of foreign cultures and then perfectly recreate them at home. “What we see in Japan, in a wide range of pursuits, is a focus on mastery,” says Sarah Kovner, who teaches Japanese history at the University of Florida. “It’s true in traditional arts, it’s true of young people who dress up in Harajuku, it’s true of restaurateurs all over Japan.”</p>'
- - https://www.smithsonianmag.com/history/journal-plague-year-180965222/
  - "How the Horrific 1918 Flu Spread Across America: The toll of history’s worst epidemic surpasses all the military deaths in World War I and World War II combined. And it may have begun in the United States"
  - John M. Barry (Smithsonian Magazine)
  - 2017-11
  - ''
  - ! '<p>Although some researchers argue that the 1918 pandemic began elsewhere, in France in 1916 or China and Vietnam in 1917, many other studies indicate a U.S. origin. The Australian immunologist and Nobel laureate Macfarlane Burnet, who spent most of his career studying influenza, concluded the evidence was “strongly suggestive” that the disease started in the United States and spread to France with “the arrival of American troops.” Camp Funston had long been considered as the site where the pandemic started until my historical research, published in 2004, pointed to an earlier outbreak in Haskell County.</p><p>Wherever it began, the pandemic lasted just 15 months but was the deadliest disease outbreak in human history, killing between 50 million and 100 million people worldwide, according to the most widely cited analysis. An exact global number is unlikely ever to be determined, given the lack of suitable records in much of the world at that time. But it’s clear the pandemic killed more people in a year than <span class="smallcaps-auto">AIDS</span> has killed in 40 years, more than the bubonic plague killed in a century. The impact of the pandemic on the United States is sobering to contemplate: Some 670,000 Americans died.</p><p>..The killing created its own horrors. Governments aggravated them, partly because of the war. For instance, the U.S. military took roughly half of all physicians under 45—and most of the best ones. What proved even more deadly was the government policy toward the truth. When the United States entered the war, Woodrow Wilson demanded that “the spirit of ruthless brutality…enter into the very fibre of national life.” So he created the Committee on Public Information, which was inspired by an adviser who wrote, “Truth and falsehood are arbitrary terms….The force of an idea lies in its inspirational value. It matters very little if it is true or false.” At Wilson’s urging, Congress passed the Sedition Act, making it punishable with 20 years in prison to “utter, print, write or publish any disloyal, profane, scurrilous, or abusive language about the form of government of the United State…or to urge, incite, or advocate any curtailment of production in this country of any thing or things…necessary or essential to the prosecution of the war.” Government posters and advertisements urged people to report to the Justice Department anyone “who spreads pessimistic stories…cries for peace, or belittles our effort to win the war.”</p><p>Against this background, while influenza bled into American life, public health officials, determined to keep morale up, began to lie.</p><p>Early in September, a Navy ship from Boston carried influenza to Philadelphia, where the disease erupted in the Navy Yard. The city’s public health director, Wilmer Krusen, declared that he would “confine this disease to its present limits, and in this we are sure to be successful. No fatalities have been recorded. No concern whatever is felt.” The next day two sailors died of influenza. Krusen stated they died of “old-fashioned influenza or grip,” not Spanish flu. Another health official declared, “From now on the disease will decrease.” The next day 14 sailors died—and the first civilian. Each day the disease accelerated. Each day newspapers assured readers that influenza posed no danger. Krusen assured the city he would “nip the epidemic in the bud.”</p><p>By September 26, influenza had spread across the country, and so many military training camps were beginning to look like Devens that the Army canceled its nationwide draft call. Philadelphia had scheduled a big Liberty Loan parade for September 28. Doctors urged Krusen to cancel it, fearful that hundreds of thousands jamming the route, crushing against each other for a better view, would spread disease. They convinced reporters to write stories about the danger. But editors refused to run them, and refused to print letters from doctors. The largest parade in Philadelphia’s history proceeded on schedule. The incubation period of influenza is two to three days. Two days after the parade, Krusen conceded that the epidemic “now present in the civilian population was…assuming the type found in” Army camps. Still, he cautioned not to be “panic stricken over exaggerated reports.”He needn’t have worried about exaggeration; the newspapers were on his side. “Scientific Nursing Halting Epidemic,” an Inquirer headline blared. In truth, nurses had no impact because none were available: Out of 3,100 urgent requests for nurses submitted to one dispatcher, only 193 were provided. Krusen finally and belatedly ordered all schools closed and banned all public gatherings—yet a newspaper nonsensically said the order was not “a public health measure” and “there is no cause for panic or alarm.” There was plenty of cause. At its worst, the epidemic in Philadelphia would kill 759 people…in one day. Priests drove horse-drawn carts down city streets, calling upon residents to bring out their dead; many were buried in mass graves. More than 12,000 Philadelphians died—nearly all of them in six weeks.</p><p>Across the country, public officials were lying. U.S. Surgeon General Rupert Blue said, “There is no cause for alarm if precautions are observed.” New York City’s public health director declared “other bronchial diseases and not the so-called Spanish influenza…[caused] the illness of the majority of persons who were reported ill with influenza.” The Los Angeles public health chief said, “If ordinary precautions are observed there is no cause for alarm.” For an example of the press’s failure, consider Arkansas. Over a four-day period in October, the hospital at Camp Pike admitted 8,000 soldiers. Francis Blake, a member of the Army’s special pneumonia unit, described the scene: “Every corridor and there are miles of them with double rows of cots …with influenza patients…There is only death and destruction.” Yet seven miles away in Little Rock, a headline in the Gazette pretended yawns: “Spanish influenza is plain la grippe—same old fever and chills.”</p><p>People knew this was not the same old thing, though. They knew because the numbers were staggering—in San Antonio, 53% of the population got sick with influenza. They knew because victims could die within hours of the first symptoms—horrific symptoms, not just aches and cyanosis but also a foamy blood coughed up from the lungs, and bleeding from the nose, ears and even eyes. And people knew because towns and cities ran out of coffins. People could believe nothing they were being told, so they feared everything, particularly the unknown. How long would it last? How many would it kill? Who would it kill? With the truth buried, morale collapsed. Society itself began to disintegrate.</p>'
- - https://www.jpl.nasa.gov/visions-of-the-future/
  - "Visions of the Future: 14 space travel posters of colorful, exotic space settings are now available free for downloading and printing"
  - Dan Goods, David Delgado, Liz Barrios De La Torre, Stefan Bucher, Invisible Creature (Don Clark & Ryan Clark), Joby Harris, Jessie Kawata, Lois Kim, Ron Miller (<span class=\"smallcaps-auto\">JPL</span>)
  - 2016-02
  - ''
  -  ! '<p>[<span class="smallcaps-auto">JPL</span>-sponsored Art Deco/<span class="smallcaps-auto">WPA</span> poster series with the concept of advertising travel in the Solar System &amp; to exoplanets; public domain &amp; free to download/print.]</p><p>A creative team of visual strategists at <span class="smallcaps-auto">JPL</span>, known as “The Studio,” created the poster series, which is titled “Visions of the Future.” Nine artists, designers, and illustrators were involved in designing the 14 posters, which are the result of many brainstorming sessions with <span class="smallcaps-auto">JPL</span> scientists, engineers, and expert communicators. Each poster went through a number of concepts and revisions, and each was made better with feedback from the <span class="smallcaps-auto">JPL</span> experts.</p><p><em>David Delgado</em>, creative strategy: “The posters began as a series about exoplanets—planets orbiting other stars—to celebrate <span class="smallcaps-auto">NASA</span>’s study of them. (The <span class="smallcaps-auto">NASA</span> program that focuses on finding and studying exoplanets is managed by <span class="smallcaps-auto">JPL</span>.) Later, the director of <span class="smallcaps-auto">JPL</span> was on vacation at the Grand Canyon with his wife, and they saw a similarly styled poster that reminded them of the exoplanet posters. They suggested it might be wonderful to give a similar treatment to the amazing destinations in our solar system that <span class="smallcaps-auto">JPL</span> is currently exploring as part of <span class="smallcaps-auto">NASA</span>. And they were right! The point was to share a sense of things on the edge of possibility that are closely tied to the work our people are doing today. The <span class="smallcaps-auto">JPL</span> director has called our people”architects of the future." As for the style, we gravitated to the style of the old posters the <span class="smallcaps-auto">WPA</span> created for the national parks. There’s a nostalgia for that era that just feels good."</p><p><em>Joby Harris</em>, illustrator: “The old <span class="smallcaps-auto">WPA</span> posters did a really great job delivering a feeling about a far-off destination. They were created at a time when color photography was not very advanced, in order to capture the beauty of the national parks from a human perspective. These posters show places in our solar system (and beyond) that likewise haven’t been photographed on a human scale yet—or in the case of the exoplanets might never be, at least not for a long time. It seemed a perfect way to help people imagine these strange, new worlds.”</p><p><em>David Delgado</em>: “The <span class="smallcaps-auto">WPA</span> poster style is beloved, and other artists have embraced it before us. Our unique take was to take one specific thing about the place and focus on the science of it. We chose exoplanets that had really interesting, strange qualities, and everything about the poster was designed to amplify the concept. The same model guided us for the posters that focus on destinations in the solar system.”</p><p><em>Lois Kim</em>, typography: “We worked hard to get the typography right, since that was a very distinctive element in creating the character of those old posters. We wanted to create a retro-future feel, so we didn’t adhere exactly to the period styles, but they definitely informed the design. The Venus poster has a very curvy, flowy font, for example, to evoke a sense of the clouds.”</p>'
- - /docs/longevity/2003-latham.pdf
  - 'A Randomized, Controlled Trial of Quadriceps Resistance Exercise and Vitamin D in Frail Older People: The Frailty Interventions Trial in Elderly Subjects (FITNESS)'
  - Nancy K. Latham, Craig S. Anderson, Arier Lee, Derrick A. Bennett, Anne Moseley, Ian D. Cameron, For The Fitness Collaborative Group
  - 2003-02-20
  - 10.1046/j.1532-5415.2003.51101.x
  - ! '<p><em>OBJECTIVES</em>:  To determine the effectiveness of vitamin D and home-based quadriceps resistance exercise on reducing falls and improving the physical health of frail older people after hospital discharge.</p><p><em>DESIGN</em>:   Multicenter, randomized, controlled trial with a factorial design.</p><p><em>SETTING</em>:   Five hospitals in Auckland, New Zealand, and Sydney, Australia.</p><p><em>PARTICIPANTS</em>:   Two hundred forty-three frail older people.</p><p><em>INTERVENTIONS</em>:   Patients were randomized to receive a single dose of vitamin D (calciferol, 300,000 IU) or placebo tablets and 10 weeks of high-intensity home-based quadriceps resistance exercise or frequency-matched visits.</p><p><em>MEASUREMENTS</em>:   The primary endpoints were physical health according to the short-form health survey at 3 months and falls over 6 months. Physical performance and self-rated function were secondary endpoints. Assessments took place in the participants’ homes at 3 and 6 months after randomization and were performed by blinded assessors.</p><p><em>RESULTS</em>:   There was no effect of either intervention on physical health or falls, but patients in the exercise group were at increased risk of musculoskeletal injury (risk ratio = 3.6, 95% confidence interval = 1.5–8.0). Vitamin D supplementation did not improve physical performance, even in those who were vitamin D deficient (&lt;12 ng/mL) at baseline.</p><p><em>CONCLUSION</em>:   Neither vitamin D supplementation nor a home-based program of high-intensity quadriceps resistance exercise improved rehabilitation outcomes in frail older people after hospitalization. There was no effect of vitamin D on physical performance, and the exercises increased the risk of musculoskeletal injury. These findings do not support the routine use of these interventions at these dosages in the rehabilitation of frail older people.</p>'
- - https://www.sciencedirect.com/science/article/pii/S0167404820300468
  - "The Ransomware-as-a-Service Economy within the Darknet"
  - Per Håkon Meland, Yara Fareed Fahmy Bayoumy, Guttorm Sindre
  - 2020-02-29
  - 10.1016/j.cose.2020.101762
  - ! '<p>Ransomware is an epidemic that adversely affects the lives of both individuals and large companies, where criminals demand payments to release infected digital assets. In the wake of the ransomware success, Ransomware-as-a-Service (RaaS) has become a franchise offered through darknet marketplaces, allowing aspiring cyber-criminals to take part in this dubious economy. We have studied contemporary darknet markets and forums over a period of two years using a netnographic research approach. Our findings show that RaaS currently seems like a modest threat relative to popular opinion. Compared to other types of illegal digital goods, there are rather few RaaS items offered for sale in darknet marketplaces, often with questionable authenticity. From our data we have created a value chain and descriptions of the actors involved in this economy. [Keywords: Ransomware, RaaS, Malware, Darknet, Marketplace, Netnography]</p>'
- - /docs/history/1933-parry.pdf
  - 'Whole Formulaic Verses in Greek and Southslavic Heroic Song'
  - Milman Perry
  - '1933'
  - 10.2307/283165
  - ! '<p>In this essay on the method to be used in the comparative study of early poetries the view is set forth that the essential feature of such poetry is its oral form, and not such cultural likenesses as have been called “popular,” “primitive,” “natural,” or “heroic.” As an example of method those numerous cases are considered where we find both in Homer and in Southslavic heroic song a verse which expresses the same idea. The explanation is as follows. Oral poetry is largely composed out of fixed verses. Especially will ideas which recur with any frequency be expressed by a fixed verse. Thus where the two poetries express the same frequent idea they both tend to do it in just the length of a verse. Knowing this common feature in the oral form of the two poetries we can conclude that the extraordinary hold which heroic poetry has on the thought and conduct of the Southern Slavs provides us with an example of what heroic poetry must have been for the early Greeks.</p>'
- - https://dspace.library.uu.nl/bitstream/handle/1874/392943/Veringmeier,%20L.T.%20-%20Scriptie.pdf?sequence=1
  - "Repeat Buying Behavior of Illegal Drugs on Cryptomarkets"
  - L. T. Veringmeier
  - 2019-06-13
  - ''
  - ! '<p>The goal of this research is to get a better understanding of buyer behavior on cryptomarkets, and to what extent buyers buy repeatedly from sellers. Cryptomarkets are anonymized markets only accessible through encryption software such as Tor. These markets provide opportunity for people to trade in illegal goods such as drugs in relative safety from legal authorities. Trading on cryptomarkets relies on trust and reputation. Theory from The Trust Game is used to explain the relations between buyers and sellers, as well as the actions that the actors can make. Although sellers have high short-term incentives to scam their customers, long-term success relies on trustworthy behavior. Buyers have to make risk assessments to place trust based on available information and experience. Data was gathered from the AlphaBay cryptomarket shortly before it was taken down by U.S. authorities. Logistic regressions were used to analyze the odds of buyers repurchasing after each purchase both on network level as well as on dyad level. 69.4% of the buyers on AlphaBay bought repeatedly, and 32.5% of all dyads were repeated. It was found that positive experiences give better odds of buyers making more purchases on network and dyad level. Using safe payments services such as escrow and experience also increase odds of buyers repeatedly purchasing. Future quantitative research on buyer behavior may want to focus on availability of alternative products and sellers for buyers, qualitative research may be valuable for finding buyer motivations to keep purchasing, stop purchasing or change sellers.</p>'
- - /docs/conscientiousness/2006-bassili.pdf
  - Promotion and prevention orientations in the choice to attend lectures or watch them online
  - John N. Bassili
  - 2006-11-06
  - 10.1111/j.1365-2729.2006.00192.x
  - ! "When presented with the option to use a new instructional technology, students often face an approach–avoidance conflict. This study explored promotion and prevention orientations, concepts linked to approach and avoidance in Higgins's regulatory focus theory, in the choice to attend lectures or watch them online. Openness, a core disposition in the Big Five Model of personality, and positive attitudes towards the utility of the Internet, reflect promotion orientations that are potentially related to the choice to watch lectures online. By contrast, neuroticism, another core disposition in the Big Five Model, and anxiety about the Internet as a computer technology, reflect a prevention orientation that is potentially related to the choice of attending lectures in class. The results illustrate that both promotion and prevention are at work in the choice to attend lectures or to watch them online. Neuroticism and anxiety about the Internet as a computer technology were related to the choice to attend lectures in class, whereas the perceived utility of the Internet was related to the choice to watch lectures online. Instructional mode choice was not related to examination performance, suggesting that the choice to attend lectures or watch them online has more to do with individual differences in promotion and prevention orientations than with pedagogical characteristics that impact learning."
- - https://www.lesswrong.com/posts/wzj6WkudtrXQFqL8e/inverse-p-zombies-the-other-direction-in-the-hard-problem-of
  - 'Inverse p-zombies: the other direction in the Hard Problem of Consciousness'
  - Gwern Branwen
  - 2011-12-18
  - ''
  - ! '<p>[Discussion of “inverse <em>p</em>-zombies” via excerpts of <a href="/docs/psychology/2008-mashour.pdf">“Inverse zombies, anesthesia awareness, and the hard problem of unconsciousness”</a>, Mashour &amp; LaRock 2008: the problem of telling when someone <em>is</em> conscious but otherwise appears and acts unconscious, a problem of particular concern in anesthesia for surgery—anesthesia occasionally fails, resulting in ‘anesthesia awareness’, leaving the patient fully conscious and feeling every last bit of the surgery, as they are completely paralyzed but are cut open and operated on for hours, which they describe as being every bit as horrific as one would think, leading to tortured memories and <span class="smallcaps-auto">PTSD</span> symptoms. Strikingly, death row executions by lethal injection use a cocktail of chemicals which are almost designed to produce this (rather than the simple single reliable drug universally used for euthanasia by veterinarians), suggesting that, as peaceful as the executions may look, the convicts may actually be enduring extraordinary agony and terror during the several minutes it takes to kill them.</p><p>Further, anesthesia appears to often operate by <em>erasing memories</em>, so it is possible that anesthesia awareness during surgery is much more common than realized, and underestimated because the victims’ long-term memories are blocked from forming. There are some indications that surgery is associated with bad psychiatric symptoms even in cases where the patient does not recall any anesthesia awareness, suggesting that the trauma is preserved in other parts of the mind.</p><p>While doctors continue to research the problem of detecting consciousness, it is far from solved. Most people, confronted with a hypothetical about getting money in exchange for being tortured but then administered an amnesiac, would say that the torture is an intrinsically bad thing even if it is then forgotten; but perhaps we are, unawares, making the opposite choice every time we go in for surgery under general anesthesia?]</p>'
- - /docs/psychology/2008-mashour.pdf
  - Inverse zombies, anesthesia awareness, and the hard problem of unconsciousness
  - George A. Mashour, Eric LaRock
  - 2008-12
  - 10.1016/j.concog.2008.06.004
  - ! '<p>Philosophical (<em>p</em>-) zombies are constructs that possess all of the behavioral features and responses of a sentient human being, yet are not conscious. P-zombies are intimately linked to the hard problem of consciousness and have been invoked as arguments against physicalist approaches. But what if we were to invert the characteristics of <em>p</em>-zombies? Such an inverse (<em>i</em>-) zombie would possess all of the behavioral features and responses of an insensate being, yet would nonetheless be conscious.</p><p>While <em>p</em>-zombies are logically possible but naturally improbable, an approximation of <em>i</em>-zombies actually exists: individuals experiencing what is referred to as “anesthesia awareness.” Patients under general anesthesia may be intubated (preventing speech), paralyzed (preventing movement), and narcotized (minimizing response to nociceptive stimuli). Thus, they appear—and typically are—unconscious. In 1–2 cases/1000, however, patients may be aware of intraoperative events, sometimes without any objective indices. Furthermore, a much higher percentage of patients (22% in a recent study) may have the subjective experience of dreaming during general anesthesia.</p><p><em>P</em>-zombies confront us with the hard problem of consciousness—how do we explain the presence of qualia? <em>I</em>-zombies present a more practical problem—how do we detect the presence of qualia? The current investigation compares <em>p</em>-zombies to <em>i</em>-zombies and explores the “hard problem” of unconsciousness with a focus on anesthesia awareness.</p><p>[Keywords: Consciousness, Hard problem of consciousness, Hard problem of unconsciousness, Zombies, Inverse zombies, Anesthesia awareness, Awareness during general anesthesia]</p>'
- - https://www.goodreads.com/review/show/2584837486
  - "Review of <em>The Hye Ch'O Diary: Memoir of the Pilgrimage to the Five Regions of India</em>"
  - Gwern Branwen
  - 2020-02-11
  - ''
  - ! 'Disappointing bland, short, and incomplete account of an extraordinary journey. Specialist historians only.'
- - https://groups.google.com/d/msg/pandoc-discuss/BDNfhctWJpg/bGk0wEtfBgAJ
  - Auto-smallcaps filter
  - Gwern Branwen
  - 2020-02-19
  - ''
  - '<p>Description of a Pandoc plugin I wrote for use on <a href="/hakyll.hs"><code>gwern.net</code></a> which automatically rewrites any string text of 3 or more capital letters (eg “<span class="smallcaps-auto">NSA</span>” or “<span class="smallcaps-auto">GAN</span>” or “<span class="smallcaps-auto">NASA</span>”) to rendered with <a href="https://en.wikipedia.org/wiki/Small_caps">small caps</a> in <span class="smallcaps-auto">CSS</span>, which are typographically nicer to read as the small caps make the acronyms less visually overwhelming compared to regular capital letters.</p><p>This is trickier to implement than the usual Pandoc plugin because strings must be parsed and broken up, so it’s not a straightforward 1-for-1 substitution, and I explain the necessary recursive tricks to make it correct &amp; typecheck.</p>'
- - http://worrydream.com/ExplorableExplanations/
  - Explorable Explanations
  - Bret Victor
  - 2011-03-10
  - ''
  - ! '<p>Do our reading environments encourage active reading? Or do they utterly oppose it? A typical reading tool, such as a book or website, displays the author’s argument, and nothing else. The reader’s line of thought remains internal and invisible, vague and speculative. We form questions, but can’t answer them. We consider alternatives, but can’t explore them. We question assumptions, but can’t verify them. And so, in the end, we blindly trust, or blindly don’t, and we miss the deep understanding that comes from dialogue and exploration.</p><p>Explorable Explanations is my umbrella project for ideas that <em>enable and encourage truly active reading</em>. The goal is to change people’s relationship with text. People currently think of text as <em>information to be consumed</em>. I want text to be used as an <em>environment to think in.</em></p><p>This essay presents examples of a few initial ideas:</p><ol type="1"><li>A <em>reactive document</em> allows the reader to play with the author’s assumptions and analyses, and see the consequences. … The reader can play with the premise and assumptions of various claims, and see the consequences update immediately. It’s like a spreadsheet without the spreadsheet.</li><li>An <em>explorable example</em> makes the abstract concrete, and allows the reader to develop an intuition for how a system works.</li><li><em>Contextual information</em> allows the reader to learn related material just-in-time, and cross-check the author’s claims.</li></ol>'
- - https://www.metopera.org/season/in-cinemas/2019-20-season/agrippina-live-in-hd/
  - 'George Frideric Handel, <em>Agrippina</em>: <span class="smallcaps-auto">Live In HD</span>'
  - Met Opera
  - '2019'
  - ''
  - ! '<p>Handel’s tale of intrigue and impropriety in ancient Rome arrives in cinemas on February 29, with star mezzo-soprano Joyce DiDonato as the controlling, power-hungry Agrippina and Harry Bicket conducting. Sir David McVicar’s production ingeniously reframes the action of this black comedy about the abuse of power to “the present,” where it should loudly resonate. The all-star cast features mezzo-soprano Kate Lindsey as Agrippina’s son and future emperor Nerone, soprano Brenda Rae as the seductive Poppea, countertenor Iestyn Davies as the ambitious officer Ottone, and bass Matthew Rose as the weary emperor Claudius. This live cinema transmission is part of the Met’s award-winning <em>Live in HD</em> series, bringing opera to more than 2,200 theaters in more than 70 countries worldwide.</p><p>This production was originally created by the Théâtre Royal de la Monnaie / De Munt Brussels and adapted by the Metropolitan Opera. Sung in Italian. Estimated Run Time: 3 hrs 35 mins.</p><ul><li>Conductor: Harry Bicket</li><li>Narciso: Nicholas Tamagna</li><li>Poppea: Brenda Rae</li><li>Agrippina: Joyce DiDonato</li><li>Kate Lindsey: Nerone</li><li>Ottone: Iestyn Davies</li><li>Pallante: Duncan Rock</li><li>Claudio: Matthew Rose</li></ul><p><strong>World Premiere: Teatro San Giovanni Crisostomo, Venice, 1709</strong></p><p>This early Italian opera of Handel was a success that secured the composer’s international reputation and played a large role in paving the way for his lucrative and high-profile subsequent career in London. While he continued to develop artistically for the next 50 years, his entire life’s genius is perfectly evident in this first great operatic accomplishment. Even today, the issues at stake in <em>Agrippina</em>—the power plays, sexual politics, and cults of personality played out against a fickle public—continue to resonate.</p>'
- - https://www.gq.com/story/the-great-buenos-aires-bank-heist
  - "The Great Buenos Aires Bank Heist: They were an all-star crew. They cooked up the perfect plan. And when they pulled off the caper of the century, it made them more than a fortune—it made them folk heroes."
  - Josh Dean (GQ)
  - 2020-02-20
  - ''
  - ! '<p>For more than six hours, the nation was transfixed. The police had nicknamed Walter “the Man in the Gray Suit.” He was instantly famous. The hostages, Walter said, were being treated well. The mood inside seemed oddly ebullient: At one point, Walter and another robber could be heard singing “Happy Birthday” to a bank employee whose phone had been buzzing with birthday messages from friends and family. At 3:30 in the afternoon, Walter asked for pizzas; the hostages were hungry, he said. Then, only a few minutes later, Walter went silent. For over three hours, police leaders and city officials fretted over what to do as further attempts to reach Walter failed. Finally a team of special-forces officers took up position outside the bank. At 7 p.m, they burst inside. But there was no shoot-out, no commotion. And no sign of the thieves. The hostages were dispersed on three floors—the lobby level, a mezzanine space, and down in a basement conference room, which had been locked from the inside. They were all unharmed.</p><p>It wasn’t until detectives reached the basement that they discovered what the robbers had truly been after. There, in the expanse of the bank’s subterranean level, hundreds of reinforced-steel safe-deposit boxes lined the walls. And in a place like San Isidro, at a time like 2006, those boxes represented a veritable treasure trove. Argentines are uniquely distrustful of their banks, and for good reason. They’ve been betrayed by them, over and over. Most famously in 2001, when the collapse of the national banking system, known as the <em>corralito</em>, erased entire fortunes, affecting millions. With no faith in accounts, bank customers began tucking their savings—their cash, jewelry, and other valuables—into safe-deposit boxes. And this particular bank, situated in one of the richest enclaves of Argentina, must have seemed especially enticing, flush as its deposit boxes were sure to be with the fortunes of the city’s most well-to-do.</p><p>Somehow the thieves had smashed open a huge number of the boxes—143 of the bank’s 400—and cleaned them out. But what exactly they’d grabbed, or where they’d gone, was a mystery. Cops swept every inch of the bank’s three floors but failed to locate a single member of the gang. The bank had only two exits—both of which had been covered by police since the siege began. All of the building’s windows were intact. And the robbers were not hiding among the hostages. They’d simply vanished. The thieves had left a few things behind. Detectives found a battery pack, a tool that they surmised had been used to crack the boxes, a row of toy guns laid neatly on the floor, and a note, taped to the wall above the toys. It was handwritten and must have seemed like a taunt: “In a neighborhood of rich people, without weapons or grudges, it’s just money, not love.”</p>'
- - https://docs.google.com/document/d/1MhA3M5ucBD7ZXcWk57_MKZ5jEgPX6_YiKye_EFP-adg/edit
  - Crowdsourcing The Best <span class=\"smallcaps-auto\">GPT</span>-2-1.5b Poetry
  - Gwern Branwen
  - 2020-02-09
  - ''
  - ! '<p>[Public-editable Google Docs document for coordinating a read through a large sample of neural-net-generated poetry, to locate the best poem samples for displaying in the <a href="/GPT-2"><span class="smallcaps-auto">GPT</span>-2 writeup</a>.]</p><p>I used a large neural net model, <span class="smallcaps-auto">GPT</span>-2-1.5b, trained on hundreds of megabytes of poetry, to generate 1 million words of poetry. That’s too much for me to read by myself to find the best poems. Perhaps you’d like to help?</p><p>It’s simple:</p><ol type="1"><li>Pick an unread <span class="smallcaps-auto">URL</span> from ‘Open Samples’ below, open it, and remove it from the list.</li><li>Read it. (Each <span class="smallcaps-auto">URL</span> is &lt;=1000 lines, so it should be fun.)</li><li>Add any good poems to ‘Selected Samples’ at the end of this document.</li><li>Enjoy reading the current ‘Selected Samples’—or pick another <span class="smallcaps-auto">URL</span> to read!</li></ol>'
- - /docs/genetics/selection/2015-dahdouh.pdf
  - 'Technical Update: Preimplantation Genetic Diagnosis and Screening'
  - Elias M. Dahdouh, Jacques Balayla, François Audibert
  - 2015-05
  - '10.1016/S1701-2163(15)30261-9'
  - ! '<p><em>Objective</em>: To update and review the techniques and indications of preimplantation genetic diagnosis (<span class="smallcaps-auto">PGD</span>) and preimplantation genetic screening (<span class="smallcaps-auto">PGS</span>).</p><p><em>Options</em>: Discussion about the genetic and technical aspects of preimplantation reproductive techniques, particularly those using new cytogenetic technologies and embryo-stage biopsy.</p><p><em>Outcomes</em>: Clinical outcomes of reproductive techniques following the use of <span class="smallcaps-auto">PGD</span> and <span class="smallcaps-auto">PGS</span> are included. This update does not discuss in detail the adverse outcomes that have been recorded in association with assisted reproductive technologies.</p><p><em>Evidence</em>: Published literature was retrieved through searches of The Cochrane Library and <span class="smallcaps-auto">MEDLINE</span> in April 2014 using appropriate controlled vocabulary (aneuploidy, blastocyst/physiology, genetic diseases, preimplantation diagnosis/methods, fertilization in vitro) and key words (e.g., preimplantation genetic diagnosis, preimplantation genetic screening, comprehensive chromosome screening, a<span class="smallcaps-auto">CGH</span>, <span class="smallcaps-auto">SNP</span> microarray, q<span class="smallcaps-auto">PCR</span>, and embryo selection). Results were restricted to systematic reviews, randomized controlled trials/controlled clinical trials, and observational studies published from 1990 to April 2014. There were no language restrictions. Searches were updated on a regular basis and incorporated in the update to January 2015. Additional publications were identified from the bibliographies of retrieved articles. Grey (unpublished) literature was identified through searching the websites of health technology assessment and health technology-related agencies, clinical practice guideline collections, clinical trial registries, and national and international medical specialty societies.</p><p><em>Values</em>: The quality of evidence in this document was rated using the criteria described in the Report of the Canadian Task Force on Preventive Health Care. (Table 1)</p><p><em>Benefits, harms, and costs</em>: This update will educate readers about new preimplantation genetic concepts, directions, and technologies. The major harms and costs identified are those of assisted reproductive technologies.</p><p><em>Summary</em>: Preimplantation genetic diagnosis is an alternative to prenatal diagnosis for the detection of genetic disorders in couples at risk of transmitting a genetic condition to their offspring. Preimplantation genetic screening is being proposed to improve the effectiveness of in vitro fertilization by screening for embryonic aneuploidy. Though <span class="smallcaps-auto">FISH</span>-based <span class="smallcaps-auto">PGS</span> showed adverse effects on <span class="smallcaps-auto">IVF</span> success, emerging evidence from new studies using comprehensive chromosome screening technology appears promising. [Keywords: Preimplantation genetic diagnosis, preimplantation genetic screening, comprehensive chromosome screening, a<span class="smallcaps-auto">CGH</span>, <span class="smallcaps-auto">SNP</span> microarray, q<span class="smallcaps-auto">PCR</span>, embryo selection]</p>'
- - https://jamanetwork.com/journals/jama/fullarticle/201218
  - Contradicted and Initially Stronger Effects in Highly Cited Clinical Research
  - John P. A. Ioannidis
  - 2005-07-13
  - 10.1001/jama.294.2.218
  - ! '<p><em>Context</em>: Controversy and uncertainty ensue when the results of clinical research on the effectiveness of interventions are subsequently contradicted. Controversies are most prominent when high-impact research is involved.</p><p><em>Objectives</em>: To understand how frequently highly cited studies are contradicted or find effects that are stronger than in other similar studies and to discern whether specific characteristics are associated with such refutation over time.</p><p><em>Design</em>: All original clinical research studies published in 3 major general clinical journals or high-impact-factor specialty journals in 1990–2003 and cited more than 1000 times in the literature were examined.</p><p><em>Main Outcome Measure</em>: The results of highly cited articles were compared against subsequent studies of comparable or larger sample size and similar or better controlled designs. The same analysis was also performed comparatively for matched studies that were not so highly cited.</p><p><em>Results</em>: Of 49 highly cited original clinical research studies, 45 claimed that the intervention was effective. Of these, 7 (16%) were contradicted by subsequent studies, 7 others (16%) had found effects that were stronger than those of subsequent studies, 20 (44%) were replicated, and 11 (24%) remained largely unchallenged. Five of 6 highly-cited nonrandomized studies had been contradicted or had found stronger effects vs 9 of 39 randomized controlled trials (<em>p</em> = .008). Among randomized trials, studies with contradicted or stronger effects were smaller (<em>p</em> = .009) than replicated or unchallenged studies although there was no statistically significant difference in their early or overall citation impact. Matched control studies did not have a significantly different share of refuted results than highly cited studies, but they included more studies with “negative” results.</p><p><em>Conclusions</em>: Contradiction and initially stronger effects are not unusual in highly cited research of clinical interventions and their outcomes. The extent to which high citations may provoke contradictions and vice versa needs more study. Controversies are most common with highly cited nonrandomized studies, but even the most highly cited randomized trials may be challenged and refuted over time, especially small ones.</p>'
- - https://www.theguardian.com/world/2014/jun/25/pornography-soviet-union-secret-collection
  - "Inside the Soviet Union's secret pornography collection: Off limits to the public but enjoyed by Soviet-era leaders, the Lenin Library collection grew out of erotica confiscated from aristocrats after the revolution"
  - Joy Neumeyer (The Moscow Times)
  - 2014-06-25
  - ''
  - ! '<p>When she inserts a key in the padlock, the door swings open to reveal thousands of books, paintings, engravings, photographs and films—all, in one way or another, connected to sex. It was the kinkiest secret in the Soviet Union: across from the Kremlin, the country’s main library held a pornographic treasure trove. Founded by the Bolsheviks as a repository for aristocrats’ erotica, the collection eventually grew to house 12,000 items from around the world, ranging from 18<sup>th</sup>-century Japanese engravings to Nixon-era romance novels. Off limits to the general public, the collection was always open to top party brass—some of whom are said to have enjoyed visiting. Today, the collection is still something of a secret: there is no complete compendium of its contents and many of them are still not listed in the catalogue.</p><p>…One of the most stunning items seized from an unknown owner is <em>The Seven Deadly Sins</em>, an oversized book of engravings self-published in 1918 by Vasily Masyutin, who also illustrated classics by Pushkin and Chekhov. Among its depictions of gluttony is a large woman masturbating with a ghoulish smile. Before the revolution, it was fashionable among the upper classes to assemble so-called <em>knigi dlya dam</em> (<em>Ladies’ Books</em>)—a kind of bawdy scrapbook. An ostentatious leather-bound album with <em>Kniga Dlya Dam</em> embossed in gold on the cover opens to reveal a Chinese silk drawing of an entwined couple. Further on, dozens of engravings show aristocratic duos fornicating in sumptuously upholstered settings…Among Skorodumov’s treasures was a portfolio of drawings and watercolours by the avant-garde titan Mikhail Larionov. Made in the 1910s, they are no less scandalous in today’s Russia. One pencil sketch features a happily panting dog standing in front of a human, who is engaged in much more than petting. A watercolor depicts two soldiers having an intimate encounter on a bench.</p><p>…How did Skorodumov amass such a collection when owning a foreign title could result in a Gulag sentence?…There is also a second theory. Stalin’s secret police chief Genrikh Yagoda, a pornography aficionado whose apartment reportedly held a dildo collection, is said to have enjoyed viewing Skorodumov’s holdings. Librarians believe that he personally ensured the latter’s safety….Safely ensconced in the spetskhran, the erotica collection became available for viewing by top Stalinist henchmen. According to legend, they included the mustachioed cavalry officer and civil war hero Semyon Budyonny and grandfatherly Mikhail Kalinin, the longtime figurehead of the Soviet state. “They were supposedly interested in the visual stuff—postcards, photos,” Chestnykh said. A Politburo member did not need a pass: “No one could refuse them.”</p>'
- - https://www.counterpunch.org/2008/12/16/orangutans-resistance-and-the-zoo/
  - Orangutans, Resistance and the Zoo
  - Jason Hribal (CounterPunch)
  - 2008-12-16
  - ''
  - ! '<p>[On the underappreciated cunning and escape artistry of orangutans. Despite seeming harmless and less of a reputation for intelligence than chimpanzees, they are just as dangerous (often deceptively calm until the instant they attack) and baffle their zookeepers with their escapes.</p><p>Orangutans must be captured as infants because adults are too uncooperative. Captive orangutans nevertheless will unscrew bolts and nuts, throw rocks to break glass windows, will trick people into waving to grab their hand and climb out, avoid any escape attempts when zookeepers are watching (even when they are ‘undercover’ as visitors) unless they can take advantage of the zookeepers watching another orangutan, construct ladders out of branches or steal workers’ tools &amp; hide them for later, and cooperate in using them to escape (eg a pair using a stolen mop handle, one steadying it). Skilled climbers, they can find the most invisible holds, climb up edges using purely finger pressure, and can even shimmy up parallel walls like a human climber; when bringing in expert climbers to find and remove possible routes, the orangutans must be kept out of sight, lest they learn new routes. If a nylon net bars them, they will spend months patiently unraveling it. If electrified wires are added, they will learn to test the wires regularly and wait for an opportunity. One orangutan learned to defeat the wires by grounding it using wood sticks (others used rubber tires), and climbing over on the porcelain insulators. “Fu Manchu” hide a strip of metal in his mouth to pick open the lock on his door, while “Jonathan” used “a slab of cardboard in order to release himself through a complex guillotine door.”</p><p>The San Diego Zoo in 1989 spent $45k crafting an orangutan exhibit with all this in mind to make it inescapable. An orangutan escaped 4 years later.]</p>'
- - https://apo.org.au/sites/default/files/resource-files/2020/02/apo-nid276711-1411146.pdf
  - "Fentanyl availability on darknet markets"
  - Roderic Broadhurst, Matthew Ball, Harshit Trivedi
  - 2020-02
  - ''
  - ! '<p>A snapshot of the sale of fentanyl and its analogues across several popular darknet markets between 2 January and 27 March 2019 reveals the amount, types and physical forms available. Of the 127,541 unique drug listings identified, 13,135 were opioids (10.3% of all drugs), of which 1,118 (0.876% of all drugs) were fentanyl or its analogues. Between 27.3 and 39.3 kilograms of fentanyl and its derivatives were available over the period. The average price of fentanyl was A$99 per gram, while carfentanil was A$26.8 per gram. The shipping methods, cross-market operations and product specialization of the 303 active fentanyl vendors on these darknet markets are also described.</p>'
- - /docs/psychology/1996-moes.pdf
  - Personality Characteristics of Successful Navy Submarine Personnel
  - Gregory S. Moes, Rakesh Lall, W. Brad Johnson
  - 1996-04-01
  - 10.1093/milmed/161.4.239
  - ! '<p>This study evaluated the personality characteristics of senior enlisted and occupationally successful Navy submarine personnel. One hundred subjects completed the Schedule for Nonadaptive and Adaptive Personality (<span class="smallcaps-auto">SNAP</span>). Results indicated that the traits of detachment, propriety, and workaholism were most descriptive of the sample. 37% met <span class="smallcaps-auto">SNAP</span> criteria for a personality disorder, typically antisocial, obsessive-compulsive, or avoidant. The results are discussed in terms of adaptation to environmental demands aboard submarines. Suggestions for further research are offered.</p>'
- - https://fifteen.ai/
  - 15.ai
  - "15 & the Pony Preservation Project"
  - 2020-03-06
  - ''
  - ! '<p>[NN <span class="smallcaps-auto">TTS</span> service demonstrating results from custom DL research project by <a href="https://twitter.com/fifteenai">15</a> for generating natural high-quality voices of characters with minimal data/few-shot learning; available voices include GLa<span class="smallcaps-auto">DOS</span> from <em>Portal</em> and especially high-quality <em>My Little Pony: Friendship Is Magic</em> voices (currently: Fluttershy &amp; Twilight Sparkle); demos: <a href="/docs/ai/music/2020-03-06-fifteenai-fluttershy-sithcode.mp3">1</a>/<a href="/docs/ai/music/2020-03-06-fifteenai-twilightsparkle-sithcode.mp3">2</a>.</p><p>The <em><span class="smallcaps-auto">MLP</span>:FiM</em> voices are trained on a large dataset constructed by the 4chan crowdsourced project “Pony Preservation Project”, begun ~2019. <span class="smallcaps-auto">PPP</span> has crowdsourced parsed audio and hand-written transcriptions of all dialogue for all character from all 9 <em><span class="smallcaps-auto">MLP</span>:FiM</em> seasons, the movie, the spinoffs, and various other things voiced by the same voice actresses in case that might help, while processing to remove noise or using ‘leaked’ original data from Hasbro for higher quality still.]</p><p>This is a text-to-speech tool that you can use to generate 44.1 kHz voices of various characters. The voices are generated in real time using multiple audio synthesis algorithms and customized deep neural networks <strong>trained on very little available data</strong> (between 30 and 120 minutes of clean dialogue for each character). This project demonstrates a significant reduction in the amount of audio required to realistically clone voices while retaining their affective prosodies.</p><p>I plan to keep this tool up gratis and ad-free indefinitely. This website is intended for strictly non-commercial use.</p><p>Thanks to the <span class="smallcaps-auto">MIT</span> Computer Science &amp; Artificial Intelligence Laboratory (<span class="smallcaps-auto">CSAIL</span>) for providing the initial funding that kickstarted this project two years ago. Further thanks to the Julia Lab, Lincoln Lab, and the Media Lab.</p><p>Special shoutouts go to 4chan’s <code>/mlp/</code> and the anons who have collectively spent hundreds of hours collecting, cleaning, and organizing clips of dialogue taken from the show <em>My Little Pony: Friendship Is Magic</em>. Honorable mention to <code>/g/</code> for some entertaining speculations.</p><p>And of course, nothing but the utmost respect to the voice actors who originally voiced the characters.</p>'
- - /docs/psychology/1967-satloff.pdf
  - Psychiatry and the Nuclear Submarine
  - Aaron Satloff
  - 1967-10-01
  - 10.1176/ajp.124.4.547
  - ! '[Survey of naval personnel at a shipyard and all attached vessels, with examination of psychiatry referrals. The results indicate that formal records on psychiatric casualties from submarine patrols grossly underestimate the true rate of psychiatric issues among submarine crew, with a more plausible rate of ~3.8%, despite intensive screening.]'
- - /docs/psychology/1968-serxner.pdf
  - An Experience in Submarine Psychiatry
  - Jonathan L. Serxner
  - 1968-07-01
  - 10.1176/ajp.125.1.25
  - ! "The psychiatric experience of a medical officer on two submerged Polaris submarine patrols, each lasting two months, is presented. One psychiatric emergency—an acute paranoid schizophrenic reaction—was managed, and some minor anxiety reactions and depressions were treated. The author suggests the nature of the submarine's psychological atmosphere by means of a brief discussion of the submarine as a physical entity, the patrol cycle, and the procedures of personnel selection and training."
- - /docs/psychology/1969-earls.pdf
  - "Human Adjustment to an Exotic Environment: The Nuclear Submarine"
  - Jim H. Earls
  - 1969-01
  - 10.1001/archpsyc.1969.01740130119012
  - ! '<p>My intention here is to provide observational data on one aspect of the submarine environment: the adjustment of men to prolonged submergence aboard a nuclear-propelled Polaris-missile-firing submarine. These observations were made while I was serving as the medical officer aboard two Polaris submarines. Discussions with fellow submarine medical officers led me to believe that adjustment patterns reported herein are not isolated occurrences but are perhaps common to many Polaris submarine crews. It is recognized, however, that human adjustment is a complex function and is affected by many variables. It is not my intention to claim that the adjustment pattern described in this paper applies to all submarine crews.</p><p>…The Polaris submariner is a highly screened individual placed into a chronically stressful and frustrating environment. When the individual begins to develop feelings of anger in response to the frustrations, he is faced by a cultural structure which does not readily permit the expression of anger. He is then forced to turn the anger inward and then experiences a depressive phenomenon in reaction to operative stresses. The course of this depressive phenomenon is believed to be a ubiquitous phenomenon among the Polaris submarine crews. A similar adjustment pattern has been reported from other isolated environments. It is believed that the Polaris submarine represents an ideal laboratory in which to study the dynamics of group adjustment to unusual environments.</p>'
- - /docs/dnb/2009-karbach.pdf
  - "How useful is executive control training? Age differences in near and far transfer of task-switching training"
  - Julia Karbach, Jutta Kray
  - 2009-10-14
  - 10.1111/j.1467-7687.2009.00846.x
  - ! '<p>Although executive functions can be improved by training, little is known about the extent to which these training-related benefits can be transferred to other tasks, or whether this transfer can be modulated by the type of training. This study investigated lifespan changes in near transfer of task-switching training to structurally similar tasks and its modulation by verbal self-instructions and variable training, as well as far transfer to structurally dissimilar ‘executive’ tasks and fluid intelligence. Three age groups (8–10; 18–26; 62–76 years of age) were examined in a pretest-training-posttest design. We found near transfer of task-switching training in all age groups, especially in children and older adults. Near transfer was enhanced in adults and impaired in children when training tasks were variable. We also found substantial far transfer to other executive tasks and fluid intelligence in all age groups, pointing to the transfer of relatively general executive control abilities after training.</p>'
- - https://www.tradejournalcooperative.com/
  - '<em>The Trade Journal Cooperative</em>: A Niche Trade Journal Delivered To Your Door, Quarterly'
  - Tim Hwang (<span class=\"smallcaps-auto\">TJC</span>)
  - 2018-05-29
  - ''
  - ! '<p>The <em>Trade Journal Cooperative</em> (<span class="smallcaps-auto">TJC</span>) is a subscription service which delivers a lovingly curated niche trade journal to your door every quarter.</p><p>Our editors painstakingly comb through the back alleys of capitalism to bring you fascinating publications like <em>Pasta Professional</em>, <em>American Funeral Director</em>, and <em>Plumber Magazine</em>. [As well as sugar industry trade and haunted house/escape-room trade journals.]</p><p>Each issue comes complete with a newsletter from our Editorial Board that provides a wealth of insightful commentary, historical analysis, and various amusing tidbits from our explorations.</p><p>For lovers of overlooked industries, keen searchers for new business opportunities, or the casual reader, <span class="smallcaps-auto">TJC</span> is for you.</p>'
- - https://meltingasphalt.com/interactive/going-critical/
  - "Going Critical"
  - Kevin Simler
  - 2019-05-13
  - ''
  - ! '<p>[JS visualizations of epidemiology: how infection rates, immunity, reinfections, topology, and infection density all yield supercritical or subcritical explosions, with thought-example of science as a network community infected by careerism/Replication-Crisis.]</p><p>If you’ve spent any time thinking about complex systems, you surely understand the importance of networks. Networks rule our world. From the chemical reaction pathways inside a cell, to the web of relationships in an ecosystem, to the trade and political networks that shape the course of history. Or consider this very post you’re reading. You probably found it on a <em>social network</em>, downloaded it from a <em>computer network</em>, and are currently deciphering it with your <em>neural network</em>.</p><p>But as much as I’ve thought about networks over the years, I didn’t appreciate (until very recently) the importance of simple <strong>diffusion</strong>. This is our topic for today: the way things move and spread, somewhat chaotically, across a network. Some examples to whet the appetite:</p><ul><li>Infectious diseases jumping from host to host within a population</li><li>Memes spreading across a follower graph on social media</li><li>A wildfire breaking out across a landscape</li><li>Ideas and practices diffusing through a culture</li><li>Neutrons cascading through a hunk of enriched uranium</li></ul><p>A quick note about <strong>form</strong>. Unlike all my previous work, this essay is interactive. [Using JavaScript] There will be sliders to pull, buttons to push, and things that dance around on the screen. I’m pretty excited about this, and I hope you are too.</p>'
- - https://www.vox.com/2015/5/27/8660249/bill-gates-spanish-flu-pandemic
  - "The most predictable disaster in the history of the human race: This is what Bill Gates is afraid of"
  - Ezra Klein (Vox)
  - 2015-05-27
  - ''
  - ! '<p>But lately, Gates has been obsessing over a dark question: what’s likeliest to kill more than 10 million human beings in the next 20 years? He ticks off the disaster movie stuff—“big volcanic explosion, gigantic earthquake, asteroid”—but says the more he learns about them, the more he realizes the probability is “very low.” Then there’s war, of course. But Gates isn’t that worried about war because the entire human race worries about war pretty much all the time, and the most dangerous kind of war, nuclear war, seems pretty contained, at least for now.</p><p>But there’s something out there that’s as bad as war, something that kills as many people as war, and Gates doesn’t think we’re ready for it. “Look at the death chart of the 20<sup>th</sup> century,” he says, because he’s the kind of guy that looks at death charts. “I think everybody would say there must be a spike for World War I. Sure enough, there it is, like 25 million. And there must be a big spike for World War II, and there it is, it’s like 65 million. But then you’ll see this other spike that is as large as World War II right after World War I, and most people, would say, ‘What was that?’” “Well, that was the Spanish flu.”</p><p>No one can say we weren’t warned. And warned. And warned. A pandemic disease is the most predictable catastrophe in the history of the human race, if only because it has happened to the human race so many, many times before…“You can’t use the word lucky or fortunate about something like Ebola that killed 10,000 people,” Klain says. “But it was the most favorable scenario for the world to face one of these things. Ebola is very difficult to transmit. Everyone who is contagious has a visible symptom. It broke out in three relatively small countries that don’t send many travelers to the US. And those three countries have good relationships with America and were welcoming of Western aid.” “With a pandemic flu, the disease would be much more contagious than Ebola,” Klain continues. “The people who are contagious may not have visible symptoms. It could break out in a highly populous country that sends thousands of travelers a day to the US. It could be a country with megacities with tens of millions of people. And it could be a country where sending in the 101<sup>st</sup> Airborne isn’t possible.”</p><p>…Behind Gates’s fear of pandemic disease is an algorithmic model of how disease moves through the modern world. He funded that model to help with his foundation’s work eradicating polio. But then he used it to look into how a disease that acted like the Spanish flu of 1918 would work in today’s world. The results were shocking, even to Gates. “Within 60 days it’s basically in all urban centers around the entire globe,” he says. “That didn’t happen with the Spanish flu.”</p>'
- - https://digitalcommons.lmu.edu/cgi/viewcontent.cgi?article=1007&context=econ_fac#pdf
  - "Myopic Voters and Natural Disaster Policy"
  - Andrew Healy, Neil Malhotra
  - 2009-08-01
  - 10.1017/S0003055409990104
  - ! 'Do voters effectively hold elected officials accountable for policy decisions? Using data on natural disasters, government spending, and election returns, we show that voters reward the incumbent presidential party for delivering disaster relief spending, but not for investing in disaster preparedness spending. These inconsistencies distort the incentives of public officials, leading the government to underinvest in disaster preparedness, thereby causing substantial public welfare losses. We estimate that $1 spent on preparedness is worth about $15 in terms of the future damage it mitigates. By estimating both the determinants of policy decisions and the consequences of those policies, we provide more complete evidence about citizen competence and government accountability.'
- - https://www.pnas.org/content/104/18/7582
  - Public health interventions and epidemic intensity during the 1918 influenza pandemic
  - Richard J. Hatchett, Carter E. Mecher, Marc Lipsitch
  - 2007-05-01
  - 10.1073/pnas.0610941104
  - ! '<p>Nonpharmaceutical interventions (<span class="smallcaps-auto">NPI</span>s) intended to reduce infectious contacts between persons form an integral part of plans to mitigate the impact of the next influenza pandemic. Although the potential benefits of <span class="smallcaps-auto">NPI</span>s are supported by mathematical models, the historical evidence for the impact of such interventions in past pandemics has not been systematically examined. We obtained data on the timing of 19 classes of <span class="smallcaps-auto">NPI</span> in 17 U.S. cities during the 1918 pandemic and tested the hypothesis that early implementation of multiple interventions was associated with reduced disease transmission. Consistent with this hypothesis, cities in which multiple interventions were implemented at an early phase of the epidemic had peak death rates ≈50% lower than those that did not and had less-steep epidemic curves. Cities in which multiple interventions were implemented at an early phase of the epidemic also showed a trend toward lower cumulative excess mortality, but the difference was smaller (≈20%) and less statistically significant than that for peak death rates. This finding was not unexpected, given that few cities maintained <span class="smallcaps-auto">NPI</span>s longer than 6 weeks in 1918. Early implementation of certain interventions, including closure of schools, churches, and theaters, was associated with lower peak death rates, but no single intervention showed an association with improved aggregate outcomes for the 1918 phase of the pandemic. These findings support the hypothesis that rapid implementation of multiple <span class="smallcaps-auto">NPI</span>s can significantly reduce influenza transmission, but that viral spread will be renewed upon relaxation of such measures.</p><p>…In comparisons across cities (Fig. 2 a, Table 2), we found that aggressive early intervention was significantly associated with a lower peak of excess mortality (Spearman ρ = −0.49 to −0.68, <em>p</em> = 0.002–0.047; see Table 2, Number of interventions before, for the number of <span class="smallcaps-auto">NPI</span>s before a given <span class="smallcaps-auto">CEPID</span> cutoff vs. peak mortality). Cities that implemented three or fewer <span class="smallcaps-auto">NPI</span>s before 20/100,000 <span class="smallcaps-auto">CEPID</span> had a median peak weekly death rate of 146/100,000, compared with 65/100,000 in those implementing four or more <span class="smallcaps-auto">NPI</span>s by that time (Fig. 2 a, <em>p</em> = 0.005). The relationship was similar for normalized peak death rates and for a range of possible cutoffs (see Table 2, <span class="smallcaps-auto">CEPID</span> at time of intervention), although the relationship became weaker as later interventions were included. Cities with more early <span class="smallcaps-auto">NPI</span>s also had fewer total excess deaths during the study period (Fig. 2 b, Table 2, 1918 total), but this association was weaker: cities with three or fewer <span class="smallcaps-auto">NPI</span>s before <span class="smallcaps-auto">CEPID</span> = 20/100,000 experienced a median total excess death rate of 551/100,000, compared with a median rate of 405/100,000 in cities with four or more <span class="smallcaps-auto">NPI</span>s (<em>p</em> = 0.03).</p>'
- - https://www.nytimes.com/2007/04/17/health/17flu.html
  - "How (and How Not) to Battle Flu: A Tale of 23 Cities: Scientists are still studying the 1918 Spanish flu pandemic, the deadliest of the 20<sup>th</sup> century, looking for lessons for future outbreaks"
  - Nicholas Bakalar (<span class=\"smallcaps-auto\">NYT</span>)
  - 2007-04-17
  - ''
  - ! '<p>When the Spanish flu reached the United States in the summer of 1918, it seemed to confine itself to military camps. But when it arrived in Philadelphia in September, it struck with a vengeance. By the time officials there grasped the threat of the virus, it was too late. The disease was rampaging through the population, partly because the city had allowed large public gatherings, including a citywide parade in support of a World War I loan drive, to go on as planned. In four months, more than 12,000 Philadelphians died, an excess death rate of 719 people for every 100,000 inhabitants.</p><p>The story was quite different in St. Louis. Two weeks before Philadelphia officials began to react, doctors in St. Louis persuaded the city to require that influenza cases be registered with the health department. And two days after the first civilian cases, police officers helped the department enforce a shutdown of schools, churches and other gathering places. Infected people were quarantined in their homes.</p><p>Excess deaths in St. Louis were 347 per 100,000 people, less than half the rate in Philadelphia. Early action appeared to have saved thousands of lives.</p><p>…Dr. Hatchett, who is a researcher at the National Institutes of Health, said the findings might hold lessons for the 21<sup>st</sup> century. “When multiple interventions were introduced early, they were very effective in 1918,” he said, “and that certainly offers hope that they would be similarly useful in an epidemic today if we didn’t have an effective vaccine.”</p><p>…What these results mean for a future epidemic is not clear. “If avian flu became a pandemic tomorrow,” Dr. Ferguson said, “we would start a crash program to make a vaccine.” But he added that rigid preventive measures like quarantines, mandated mask wearing and widespread business closings would still need to be put in place. “What our study shows,” he continued, “is that interventions even without a vaccine can be effective in blocking transmission. What’s much less certain is whether society is prepared to bear the costs of implementing such intrusive and costly measures for the months that would be required to manufacture a vaccine.”</p>'
- - /docs/history/2001-ziolo.pdf
  - Joachim of Fiore and apocalyptic immanence
  - 2001-09
  - Paul Ziolo
  - ''
  - ! '<p>Apocalyptic envisionings of the historical process, whether philosophical, pseudo-scientific or incarnate as chiliastic movements have always been, and in all likelihood will continue to be, an integral dimension in the unfolding of the Euroamerican cultural chreod. This paper begins with some general observations on the genesis and character of apocalyptic movements, then proceeds to trace the psychological roots of Euroamerican apocalyptic thought as expressed in the Trinitarian-dualist formulations of Christian dogma, showing how the writings of the medieval Calabrian mystic Joachim of Fiore (c.1135–1202) created a synthesis of dynamic Trinitarianism and existential dualism within a framework of historical immanence. The resulting Joachimite ‘program’ later underwent further dissemination and distortion within the context of psychospeciation and finally led to the great totalitarian systems of the 20<sup>th</sup> century, thereby indirectly exercising an influence on the development of psychohistory itself as an independent discipline.</p>'
- - /docs/nicotine/2007-anstey.pdf
  - 'Smoking as a Risk Factor for Dementia and Cognitive Decline: A Meta-Analysis of Prospective Studies'
  - "Kaarin J. Anstey, Chwee von Sanden, Agus Salim, Richard O'Kearney"
  - 2007-06-14
  - 10.1093/aje/kwm116
  - ! '<p>The authors assessed the association of smoking with dementia and cognitive decline in a meta-analysis of 19 prospective studies with at least 12 months of follow-up. Studies included a total of 26,374 participants followed for dementia for 2–30 years and 17,023 participants followed up for 2–7 years to assess cognitive decline. Mean study age was 74 years. Current smokers at baseline, relative to never smokers, had risks of 1.79 (95% confidence interval (CI): 1.43, 2.23) for incident Alzheimer’s disease, 1.78 (95% CI: 1.28, 2.47) for incident vascular dementia, and 1.27 (95% CI: 1.02, 1.60) for any dementia. Compared with those who never smoked, current smokers at baseline also showed greater yearly declines in Mini-Mental State Examination scores over the follow-up period (effect size (β) = −0.13, 95% CI: −0.18, −0.08). Compared with former smokers, current smokers at baseline showed an increased risk of Alzheimer’s disease (relative risk = 1.70, 95% CI: 1.25, 2.31) and an increased decline in cognitive abilities (effect size (β) = −0.07, 95% CI: −0.11, −0.03), but the groups were not different regarding risk of vascular dementia or any dementia. The authors concluded that elderly smokers have increased risks of dementia and cognitive decline. [Keywords: Alzheimer disease, cognition, dementia, vascular, meta-analysis, smoking]</p>'
- - /docs/statistics/bias/2012-tinsley.pdf
  - How Near-Miss Events Amplify or Attenuate Risky Decision Making
  - Catherine H. Tinsley, Robin L. Dillon, Matthew A. Cronin
  - 2012-04-18
  - 10.1287/mnsc.1120.1517
  - ! '<p>In the aftermath of many natural and man-made disasters, people often wonder why those affected were underprepared, especially when the disaster was the result of known or regularly occurring hazards (e.g., hurricanes). We study one contributing factor: prior near-miss experiences. Near misses are events that have some nontrivial expectation of ending in disaster but, by chance, do not. We demonstrate that when near misses are interpreted as disasters that did not occur, people illegitimately underestimate the danger of subsequent hazardous situations and make riskier decisions (e.g., choosing not to engage in mitigation activities for the potential hazard). On the other hand, if near misses can be recognized and interpreted as disasters that almost happened, this will counter the basic “near-miss” effect and encourage more mitigation. We illustrate the robustness of this pattern across populations with varying levels of real expertise with hazards and different hazard contexts (household evacuation for a hurricane, Caribbean cruises during hurricane season, and deep-water oil drilling). We conclude with ideas to help people manage and communicate about risk. [Keywords: near miss; risk; decision making; natural disasters; organizational hazards; hurricanes; oil spills.]</p>'
- - /docs/conscientiousness/2005-zhao.pdf
  - 'What Makes the Difference? A Practical Analysis of Research on the Effectiveness of Distance Education'
  - Yong Zhao, Jing Lei, Bo Yan, Chun Lai, Sophia Tan
  - '2005'
  - 10.1111/j.1467-9620.2005.00544.x
  - ! 'This article reports findings of a meta-analytical study of research on distance education. The purpose of this study was to identify factors that affect the effectiveness of distance education. The results show that although the aggregated data of available studies show no significant difference in outcomes between distance education and face-to-face education as previous research reviews suggest, there is remarkable difference across the studies. Further examination of the difference reveals that distance education programs, just like traditional education programs, vary a great deal in their outcomes, and the outcome of distance education is associated with a number of pedagogical and technological factors. This study led to some important data-driven suggestions for and about distance education.'
- - /Embryo-selection#embryo-selection-and-dynasties
  - ! 'Embryo Selection and Dynasties: A Liability Threshold Model'
  - Gwern Branwen
  - 2018-02-08
  - ''
  - <p>Genetic selection &amp; engineering technologies, if banned or highly regulated,
    could exacerbate existing social inequality by increasing genetic differences
    between groups on key traits like intelligence or Conscientiousness or ethnocentrism
    and ensuring near-permanent continuity of wealth or power. Whether this is a serious
    problem quantitatively with feasible levels of embryo selection has not been much
    examined. I consider the specific scenario of a single family, such as a royal
    family or wealthy corporate owner, which wishes to increase the odds of succession
    to a sufficiently-competent heir who can maintain the dynasty. I suggest a toy
    model treating it as a repeated liability-threshold model in which heirs are selected
    as order statistics and if any heir is above a threshold, the dynasty survives
    another generation; given average numbers of generations and heirs, this defines
    a unique threshold of competence. Adding embryo selection turns this into a two-stage
    selection process. In some scenarios, assuming a threshold of ~+1SD and advanced
    polygenic scores for multiple selection, embryo selection could considerably increase
    the lifespan of a dynasty due to tail effects on the increased mean in each stage.</p>
- - https://www.ism.ac.jp/editsec/aism/pdf/011_3_0195.pdf
  - "Bivariate Extreme Statistics, I"
  - Masaaki Sibuya
  - '1960'
  - '10.1007/BF01682329'
  - ! '<p>The largest and the smallest value in a sample, and other statistics related to them are generally named extreme statistics. Their sampling distributions, especially the limit distributions, have been studied by many authors, and principal results are summarized in the recent Gumbel book.</p><p>The author extends here the notion of extreme statistics into bivariate distributions and considers the joint distributions of maxima of components in sample vectors. This Part I treats asymptotic properties of the joint distributions.</p><p>In the univariate case the limit distributions of the sample maximum were limited to only three types. In the bivariate case, however, types of the limit joint distribution are various: Theorem 5 in Chapter 2 shows that infinitely many types of limit distributions may exist. For a wide class of distributions, two maxima are asymptotically independent or degenerate on a curve. Theorems 2 and 4 give the attraction domains for such limits. In bivariate normal case, two maxima are asymptotically independent unless the correlation coefficient is equal to one.</p><p>Throughout these arguments we remark only the dependence between marginal distributions, whose behaviors are well established. For this purpose a fundamental notion of ‘dependence function’ is introduced and discussed in Section 1.</p>'
- - /docs/statistics/order/1967-srivastava.pdf
  - "Asymptotic Independence of Certain Statistics Connected with the Extreme Order Statistics in a Bivariate Distribution"
  - "O. P. Srivastava"
  - "1967-06"
  - "10.2307/25049462"
  - ! 'The exact distribution of extremes in a sample and its limiting forms are well known in the univariate case. The limiting form for the largest observation in a sample was derived by Fisher and Tippet (1928) as early as 1927 by a functional equation, and that for the smallest was studied by Smirnov (1952). Though the joint distribution of two extremes has not been fully studied yet Sibuya (1960) gave a necessary and sufficient condition for the asymptotic independence of two largest extremes in a bivariate distribution. In this paper a necessary and sufficient condition for the asymptotic independence of two smallest observations in a bivariate sample has been derived, and the result has been used to find the condition for the asymptotic independence of any pair of extreme order statistics, one in each component of the bivariate sample. This result is further extended to find the condition for asymptotic independence of the pair of distances between two order statistics, arising from each component.'
- - https://cran.r-project.org/web/packages/copula/vignettes/rhoAMH-dilog.pdf
  - "Spearman’s Rho for the <span class=\"smallcaps-auto\">AMH</span> Copula: a Beautiful Formula"
  - Martin M̈achler
  - 2014-06
  - ''
  - ! '<p>We derive a beautiful series expansion for <a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient">Spearman’s rho</a>, ρ(θ) of the Ali-Mikhail-Haq (<span class="smallcaps-auto">AMH</span>) copula with parameter θ which is also called α or θ. Further, via experiments we determine the cutoffs to be used for practically fast and accurate computation of ρ(θ) for all θ ∈ [−1,1].</p><p>[Keywords: Archimedean copulas, Spearman’s rho.]</p>'
- - https://www.lesswrong.com/posts/dC7mP5nSwvpL65Qu5/why-the-tails-come-apart
  - Why the tails come apart
  - Thrasymachus
  - 2014-08-01
  - ''
  - ! '<p style="color: #333333; font-family: Georgia, &#39;Times New Roman&#39;, &#39;Bitstream Charter&#39;, Times, serif; font-size: 13px; line-height: 19px;">Many outcomes of interest have pretty good predictors. It seems that height correlates to performance in basketball (the average height in the <span class="smallcaps-auto">NBA</span> is around <a href="http://en.wikipedia.org/wiki/NBA_league_average_height,_weight,_age_and_playing_experience">6’7"</a>). Faster serves in tennis improve one’s likelihood of winning. IQ scores are known to predict a slew of factors, from <a href="http://thesocietypages.org/socimages/2008/02/06/correlations-of-iq-with-income-and-wealth/">income</a>, to chance of <a href="http://www.sagepub.com/schram/study/materials/reference/90851_04.2r.pdf">being imprisoned</a>, to<a href="http://www.bmj.com/content/322/7290/819"> lifespan</a>.</p><p style="color: #333333; font-family: Georgia, &#39;Times New Roman&#39;, &#39;Bitstream Charter&#39;, Times, serif; font-size: 13px; line-height: 19px;">What’s interesting is what happens to these relationships ‘out on the tail’: extreme outliers of a given predictor are seldom similarly extreme outliers on the outcome it predicts, and vice versa. Although 6’7" is very tall, it lies within a <a href="http://www.wolframalpha.com/input/?i=male+height+distribution">couple of standard deviations</a> of the median US adult male height—there are many thousands of US men taller than the average <span class="smallcaps-auto">NBA</span> player, yet are not in the <span class="smallcaps-auto">NBA</span>. Although elite tennis players have very fast serves, if you look at the players serving <a href="http://en.wikipedia.org/wiki/Fastest_recorded_tennis_serves">the fastest serves ever recorded</a>, they aren’t the very best players of their time. It is harder to look at the IQ case due to test ceilings, but again there seems to be some divergence near the top: the very highest earners tend<a href="http://infoproc.blogspot.co.uk/2009/11/if-youre-so-smart-why-arent-you-rich.html"> to be very smart</a>, but their intelligence is not in step with their income (their cognitive ability is around +3 to +4 SD above the mean, yet their wealth is much higher than this) (1).</p><p style="color: #333333; font-family: Georgia, &#39;Times New Roman&#39;, &#39;Bitstream Charter&#39;, Times, serif; font-size: 13px; line-height: 19px;">The trend seems to be that even when two factors are correlated, their tails diverge: the fastest servers are good tennis players, but not the very best (and the very best players serve fast, but not the very fastest); the very richest tend to be smart, but not the very smartest (and vice versa). Why?</p><ul><li>The simple graphical explanation</li><li>An intuitive explanation of the graphical explanation</li><li>A parallel geometric explanation</li></ul>'
- - /docs/statistics/order/2005-dosanjos.pdf
  - 'Copula associated to order statistics'
  - Ulisses U. dos Anjos, Nikolai Kolev, Nelson I. Tanaka
  - '2005-12'
  - '10.2307/43601062'
  - ! '<p>We exhibit a copula representation of the (<em>r</em>, <em>s</em>)-th bivariate order statistics from an independent sample of size <em>n</em>. We give conditions when such a representation converges weakly to a bivariate Gaussian copula. A recurrence relationship between the density of the order statistics is presented and related Fréchet bounds are given. The usefulness of those results are stressed through examples.</p><p>[Key words: Bivariate binomial, copula, Fréchet bounds, normal asymptotics, order statistics.]</p>'
- - /Order-statistics#probability-of-bivariate-maximum
  - Probability of Bivariate Maximum
  - Gwern Branwen
  - 2020-03-11
  - ''
  - ! '<p>Given a sample of <em>n</em> pairs of 2 normal variables A &amp; B which are correlated <em>r</em>, what is the probability <em>P</em><sub>max</sub> that the maximum on the first variable A is also the maximum on the second variable B? This is analogous to many testing or screening situations, such as employee hiring (“what is the probability the top-scoring applicant on the first exam is the top-scorer on the second as well?”) or athletic contests (“what is the probability the current world champ will win the next championship?”).</p><p>Order statistics has long proven that asymptotically, <em>P</em><sub>max</sub> approaches <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mi>n</mi></mfrac><annotation encoding="application/x-tex"></annotation></semantics></math>. Exact answers are hard to find, but confirm the asymptotics; the closest that exists is for an approximation &amp; special-case of the Ali-Mikhail-Haq copula: which roughly indicates that <em>r</em> functions as a constant factor boost in <em>P</em><sub>max</sub>, and the boost from <em>r</em> fades out as <em>n</em> increases.</p><p>As long as <em>r</em>≠1, “the tails will come apart”. <em>n</em> increases the difficult too fast for any fixed <em>r</em> to overcome. This has implications for interpreting extremes and test metrics.</p>'
- - https://www.atlasobscura.com/articles/moose-boulder-debunked
  - "The Intrepid Mother and Son Who Unraveled a Geographic Hoax: Atlas Obscura had a page for something called Moose Boulder, until fan Roger Dickey called us on it."
  - Matthew Taub (Atlas Obscura)
  - 2020-03-10
  - ''
  - ! '<p>…What had brought them there, and into this rather dicey situation, was something called Moose Boulder, a kind of geological <em>Matryoshka</em> doll. Here’s what makes Moose Boulder special, from the outside in: Lake Superior is the world’s largest freshwater lake, and its largest island is Isle Royale, whose largest lake is called Siskiwit, whose largest island is called Ryan. According to Wikipedia, at least, Ryan Island is home to a seasonal pond called Moose Flats that, when flooded, contains its own island—Moose Boulder. This makes it “the largest island in the largest lake on the largest island in the largest lake on the largest island in the largest lake in the world.” Spoiler: Mother and son made it out alive, but it wasn’t because they stumbled on a geological/hydrological anomaly that they could use to get their bearings. They couldn’t have, because, despite what the internet has to say, Moose Boulder almost surely doesn’t exist.</p><p>…It’s doubtful that any of these other hikers, however, had consulted Atlas Obscura. Had they done so, Dickey soon realized, they would have found the precise coordinates: 48.0088°, −88.7720°. They would have seen that some people had marked visiting it on their Atlas Obscura profiles. Dickey had to get creative to actually contact these people. “I did Google reverse image search for their profile photos,” he says, which led him to two people with social media presences, neither of whom responded to his messages…Naturally, as they all do, the <em>Atlas Obscura</em> entry for the site had an image—albeit a grainy one—of a lonely little rock, cautiously jutting out of the water, feebly sprouting some weeds…Many photos that users upload to Atlas Obscura link to their original sources, but this one was a dead end. Using the Wayback Machine, Dickey found that it had come from a defunct website that appeared to document a geological research expedition to Ryan Island…The supposed photographic evidence had indeed come from that expedition, but it was merely a photo of an ordinary rock, off the coast of Isle Royale itself and not of the Inception of islands deep inside it.</p><p>By now, the odds seemed overwhelming to Dickey that Moose Boulder was a myth, a spasm of the Internet’s imagination that had managed to proliferate and live on. But still, something didn’t quite add up. There was a missing piece to the puzzle that stopped Dickey short of declaring it all a hoax. He had found another article about Moose Boulder, published in 2009, that cited Wikipedia as its source of information. But the information about Moose Boulder had been added to Siskiwit Lake’s Wikipedia page in 2012. It was like a scene in a bad horror movie in which someone gets a phone call from a dead person. Dickey joked with his girlfriend that perhaps Moose Boulder does exist, but only in some kind of “temporal anomaly.”…Here’s the rub: Wikipedia is a nesting doll, too. Before a page for Siskiwit Lake had been added to the site, the page for Isle Royale had pointed readers to Moose Boulder, and had been doing so since 2009. It was put there by a different user than the one who added it to the Siskiwit page in 2012. Either way, that’s where the trail goes cold, and there’s no other evidence that the place exists. The identity of that first Wikipedia user to write about it—with those completely unrelated sources—remains a mystery, but all available evidence suggests that it was a person having a laugh, nothing more.</p>'
- - https://www.atlasobscura.com/articles/objects-inside-library-books
  - "Found: A Greasy Leftover Snack Inside a Rare Book—Whether a cookie or a fruit bun, the 'offending object' has been discarded"
  - Matthew Taub (Atlas Obscura)
  - 2020-03-11
  - ''
  - ! '<p>Emily Dourish, deputy keeper of Rare Books and Early Manuscripts at the Cambridge University Library, was recently making rounds through the collection when she made a most unusual discovery. Wedged inside a Renaissance-era volume of Saint Augustine’s complete works sat a flat, decaying, dry, partially eaten snack—likely a cookie, or “some kind of fruit bun,” though Dourish admits that the treat was well past easy identification.</p><p>…It’s not the first time that Dourish or her colleagues have found foreign objects inside their rare books. Over the years, they’ve encountered flower petals, unexpected annotations, bits of medieval manuscripts within actual book bindings, and even an unknown poem by the Dutch scholar Erasmus. One particularly notable example was a key found by Dourish’s colleague in a medieval manuscript, which left a rusty impression even after its removal…Sometimes, you find a plant inside a 15<sup>th</sup>-century German Bible… …or wax drippings in 16<sup>th</sup>-century Spanish prayer books.</p>'
- - /docs/biology/2019-ng.pdf
  - Modular and tunable biological feedback control using a de novo protein switch
  - 'Andrew H. Ng, Taylor H. Nguyen, Mariana Gómez-Schiavon, Galen Dodo, Robert A. Langan, Scott E. Boyken, Jennifer A. Samson, Lucas M. Waldburger, John E. Dueber, David Baker, Hana El-Samad'
  - 2019-07-24
  - 10.1038/s41586-019-1425-7
  - ! '<p>De novo-designed proteins<sup>1,2,3</sup> hold great promise as building blocks for synthetic circuits, and can complement the use of engineered variants of natural proteins<sup>4,5,6,7</sup>. One such designer protein—degron<span class="smallcaps-auto">LOCKR</span>, which is based on ‘latching orthogonal cage–key proteins’ (<span class="smallcaps-auto">LOCKR</span>) technology8—is a switch that degrades a protein of interest in vivo upon induction by a genetically encoded small peptide. Here we leverage the plug-and-play nature of degron<span class="smallcaps-auto">LOCKR</span> to implement feedback control of endogenous signalling pathways and synthetic gene circuits. We first generate synthetic negative and positive feedback in the yeast mating pathway by fusing degron<span class="smallcaps-auto">LOCKR</span> to endogenous signalling molecules, illustrating the ease with which this strategy can be used to rewire complex endogenous pathways. We next evaluate feedback control mediated by degron<span class="smallcaps-auto">LOCKR</span> on a synthetic gene circuit<sup>9</sup>, to quantify the feedback capabilities and operational range of the feedback control circuit. The designed nature of degron<span class="smallcaps-auto">LOCKR</span> proteins enables simple and rational modifications to tune feedback behaviour in both the synthetic circuit and the mating pathway. The ability to engineer feedback control into living cells represents an important milestone in achieving the full potential of synthetic biology<sup>10,11,12</sup>. More broadly, this work demonstrates the large and untapped potential of de novo design of proteins for generating tools that implement complex synthetic functionalities in cells for biotechnological and therapeutic applications.</p>'
- - /docs/biology/2019-langan.pdf
  - 'De novo design of bioactive protein switches'
  - 'Robert A. Langan, Scott E. Boyken, Andrew H. Ng, Jennifer A. Samson, Galen Dods, Alexandra M. Westbrook, Taylor H. Nguyen, Marc J. Lajoie, Zibo Chen, Stephanie Berger, Vikram Khipple Mulligan, John E. Dueber, Walter R. P. Novak, Hana El-Samad, David Baker'
  - 2019-07-24
  - 10.1038/s41586-019-1432-8
  - ! '<p>Allosteric regulation of protein function is widespread in biology, but is challenging for de novo protein design as it requires the explicit design of multiple states with comparable free energies. Here we explore the possibility of designing switchable protein systems de novo, through the modulation of competing inter- and intramolecular interactions. We design a static, five-helix ‘cage’ with a single interface that can interact either intramolecularly with a terminal ‘latch’ helix or intermolecularly with a peptide ‘key’. Encoded on the latch are functional motifs for binding, degradation or nuclear export that function only when the key displaces the latch from the cage. We describe orthogonal cage–key systems that function in vitro, in yeast and in mammalian cells with up to 40-fold activation of function by key. The ability to design switchable protein functions that are controlled by induced conformational change is a milestone for de novo protein design, and opens up new avenues for synthetic biology and cell engineering.</p>'
- - https://www.nature.com/articles/d41586-020-00672-7
  - 'A controlled trial for reproducibility: For three years, part of <span class=\"smallcaps-auto\">DARPA</span> has funded two teams for each project: one for research and one for reproducibility. The investment is paying off.'
  - Marc P. Raphael, Paul E. Sheehan, Gary J. Vora
  - 2020-03-10
  - 10.1038/d41586-020-00672-7
  - ! '<p>In 2016, the US Defense Advanced Research Projects Agency (<span class="smallcaps-auto">DARPA</span>) told eight research groups that their proposals had made it through the review gauntlet and would soon get a few million dollars from its Biological Technologies Office (<span class="smallcaps-auto">BTO</span>). Along with congratulations, the teams received a reminder that their award came with an unusual requirement—an independent shadow team of scientists tasked with reproducing their results. Thus began an intense, multi-year controlled trial in reproducibility. Each shadow team consists of three to five researchers, who visit the ‘performer’ team’s laboratory and often host visits themselves. Between 3% and 8% of the programme’s total funds go to this independent validation and verification (IV&amp;V) work…Awardees were told from the outset that they would be paired with an IV&amp;V team consisting of unbiased, third-party scientists hired by and accountable to <span class="smallcaps-auto">DARPA</span>. In this programme, we relied on US Department of Defense laboratories, with specific teams selected for their technical competence and ability to solve problems creatively.</p><p>…Results so far show a high degree of experimental reproducibility. The technologies investigated include using chemical triggers to control how cells migrate<sup>1</sup>; introducing synthetic circuits that control other cell functions<sup>2</sup>; intricate protein switches that can be programmed to respond to various cellular conditions<sup>3</sup>; and timed bacterial expression that works even in the variable environment of the mammalian gut<sup>4</sup>…getting to this point was more difficult than we expected. It demanded intense coordination, communication and attention to detail…Our effort needed capable research groups that could dedicate much more time (in one case, 20 months) and that could flexibly follow evolving research…A key component of the IV&amp;V teams’ effort has been to spend a day or more working with the performer teams in their laboratories. Often, members of a performer laboratory travel to the IV&amp;V laboratory as well. These interactions lead to a better grasp of methodology than reading a paper, frequently revealing person-to-person differences that can affect results…Still, our IV&amp;V efforts have been derailed for weeks at a time for trivial reasons (see ‘Hard lessons’), such as a typo that meant an ingredient in cell media was off by an order of magnitude. We lost more than a year after discovering that commonly used biochemicals that were thought to be interchangeable are not.</p><p><span class="smallcaps-auto">Document Reagents</span>: …We lost weeks of work and performed useless experiments when we assumed that identically named reagents (for example, polyethylene glycol or fetal bovine serum) from different vendors could be used interchangeably. · <span class="smallcaps-auto">See It Live</span>: …In our hands, washing cells too vigorously or using the wrong-size pipette tip changed results unpredictably. · <span class="smallcaps-auto">State a range</span>: …Knowing whether 21 ° C means 20.5–21.5 ° C or 20–22 ° C can tell you whether cells will thrive or wither, and whether you’ll need to buy an incubator to make an experiment work. · <span class="smallcaps-auto">Test, then ship</span>: …Incorrect, outdated or otherwise diminished products were sent to the IV&amp;V team for verification many times. · <span class="smallcaps-auto">Double check</span>: ….A typo in one protocol cost us four weeks of failed experiments, and in general, vague descriptions of formulation protocols (for example, for expressing genes and making proteins without cells) caused months of delay and cost thousands of dollars in wasted reagents. · <span class="smallcaps-auto">Pick a person</span>: …The projects that lacked a dedicated and stable point of contact were the same ones that took the longest to reproduce. That is not coincidence. · <span class="smallcaps-auto">Keep <em>in silico</em> analysis up to date</span>: …Teams had to visit each others’ labs more than once to understand and fully implement computational-analysis pipelines for large microscopy data sets.</p><p>…We have learnt to note the flow rates used when washing cells from culture dishes, to optimize salt concentration in each batch of medium and to describe temperature and other conditions with a range rather than a single number. This last practice came about after we realized that diminished slime-mould viability in our Washington DC facility was due to lab temperatures that could fluctuate by 2 °C on warm summer days, versus the more tightly controlled temperature of the performer lab in Baltimore 63 kilometres away. Such observations can be written up in a protocol paper…As one of our scientists said, “IV&amp;V forces performers to think more critically about what qualifies as a successful system, and facilitates candid discussion about system performance and limitations.”</p>'
- - /docs/catnip/2020-kays.pdf
  - The small home ranges and large local ecological impacts of pet cats
  - 'R. Kays, R. R. Dunn, A. W. Parsons, B. Mcdonald, T. Perkins, S. A. Powers, L. Shell, J. L. McDonald, H. Cole, H. Kikillus, L. Woods, H. Tindle, P. Roetman'
  - 2020-03-11
  - 10.1111/acv.12563
  - ! '<p>Domestic cats (<i>Felis catus</i>) are a conservation concern because they kill billions of native prey each year, but without spatial context the ecological importance of pets as predators remains uncertain. We worked with citizen scientists to track 925 pet cats from six countries, finding remarkably small home ranges (3.6 ± 5.6 ha). Only three cats ranged &gt; 1 km<sup>2</sup> and we found no relationship between home range size and the presence of larger native predators (i.e. coyotes, <i>Canis latrans</i>). Most (75%) cats used primarily (90%) disturbed habitats. Owners reported that their pets killed an average of 3.5 prey items/month, leading to an estimated ecological impact per cat of 14.2–38.9 prey ha<sup>−1</sup> yr<sup>−1</sup>. This is similar or higher than the per-animal ecological impact of wild carnivores but the effect is amplified by the high density of cats in neighborhoods. As a result, pet cats around the world have an ecological impact greater than native predators but concentrated within ~100 m of their homes.</p>'
- - http://interventions.onlinejacc.org/content/8/8/1018
  - Repeatability of Fractional Flow Reserve Despite Variations in Systemic and Coronary Hemodynamics
  - Nils P. Johnson, Daniel T. Johnson, Richard L. Kirkeeide, Colin Berry, Bernard De Bruyne, William F. Fearon, Keith G. Oldroyd, Nico H.J. Pijls, K. Lance Gould
  - 2015-07
  - 10.1016/j.jcin.2015.01.039
  - ! '<p><em>Objectives</em>: This study classified and quantified the variation in fractional flow reserve (<span class="smallcaps-auto">FFR</span>) due to fluctuations in systemic and coronary hemodynamics during intravenous adenosine infusion.</p><p><em>Background</em>: Although <span class="smallcaps-auto">FFR</span> has become a key invasive tool to guide treatment, questions remain regarding its repeatability and stability during intravenous adenosine infusion because of systemic effects that can alter driving pressure and heart rate.</p><p><em>Methods</em>: We reanalyzed data from the <span class="smallcaps-auto">VERIFY</span> (<span class="smallcaps-auto">VER</span>ification of Instantaneous Wave-Free Ratio and Fractional Flow Reserve for the Assessment of Coronary Artery Stenosis Severity in EverydaY Practice) study, which enrolled consecutive patients who were infused with intravenous adenosine at 140 μg/kg/min and measured <span class="smallcaps-auto">FFR</span> twice. Raw phasic pressure tracings from the aorta (Pa) and distal coronary artery (Pd) were transformed into moving averages of Pd/Pa. Visual analysis grouped Pd/Pa curves into patterns of similar response. Quantitative analysis of the Pd/Pa curves identified the “smart minimum” <span class="smallcaps-auto">FFR</span> using a novel algorithm, which was compared with human core laboratory analysis.</p><p><em>Results</em>: A total of 190 complete pairs came from 206 patients after exclusions. Visual analysis revealed 3 Pd/Pa patterns: “classic” (sigmoid) in 57%, “humped” (sigmoid with superimposed bumps of varying height) in 39%, and “unusual” (no pattern) in 4%. The Pd/Pa pattern repeated itself in 67% of patient pairs. Despite variability of Pd/Pa during the hyperemic period, the “smart minimum” <span class="smallcaps-auto">FFR</span> demonstrated excellent repeatability (bias −0.001, SD 0.018, paired <em>p</em> = 0.93, r<sup>2</sup> = 98.2%, coefficient of variation = 2.5%). Our algorithm produced <span class="smallcaps-auto">FFR</span> values not significantly different from human core laboratory analysis (paired <em>p</em> = 0.43 vs. <span class="smallcaps-auto">VERIFY</span>; <em>p</em> = 0.34 vs. <span class="smallcaps-auto">RESOLVE</span>).</p><p><em>Conclusions</em>: Intravenous adenosine produced 3 general patterns of Pd/Pa response, with associated variability in aortic and coronary pressure and heart rate during the hyperemic period. Nevertheless, <span class="smallcaps-auto">FFR</span>—when chosen appropriately—proved to be a highly reproducible value. Therefore, operators can confidently select the “smart minimum” <span class="smallcaps-auto">FFR</span> for patient care. Our results suggest that this selection process can be automated, yet comparable to human core laboratory analysis.</p>'
- - https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0361
  - "Price's equation made clear"
  - Andy Gardner
  - 2020-03-09
  - 10.1098/rstb.2019.0361
  - ! '<p>Price’s equation provides a very simple—and very general—encapsulation of evolutionary change. It forms the mathematical foundations of several topics in evolutionary biology, and has also been applied outwith evolutionary biology to a wide range of other scientific disciplines. However, the equation’s combination of simplicity and generality has led to a number of misapprehensions as to what it is saying and how it is supposed to be used. Here, I give a simple account of what Price’s equation is, how it is derived, what it is saying and why this is useful. In particular, I suggest that Price’s equation is useful not primarily as a predictor of evolutionary change but because it provides a general theory of selection. As an illustration, I discuss some of the insights Price’s equation has brought to the study of social evolution.</p><p>This article is part of the theme issue ‘Fifty years of the Price equation’.</p>'
- - /docs/statistics/comparison/2008-ailon.pdf
  - 'Aggregating inconsistent information: Ranking and clustering'
  - Nir Ailon, Moses Charikar, Alantha Newman
  - 2008-11
  - 10.1145/1411509.1411513
  - ! '<p>We address optimization problems in which we are given contradictory pieces of input information and the goal is to find a globally consistent solution that minimizes the extent of disagreement with the respective inputs. Specifically, the problems we address are rank aggregation, the feedback arc set problem on tournaments, and correlation and consensus clustering. We show that for all these problems (and various weighted versions of them), we can obtain improved approximation factors using essentially the same remarkably simple algorithm. Additionally, we almost settle a long-standing conjecture of Bang-Jensen and Thomassen and show that unless NP⊆<span class="smallcaps-auto">BPP</span>, there is no polynomial time algorithm for the problem of minimum feedback arc set in tournaments.</p>'
- - https://www.motherjones.com/politics/2009/05/fogbank-america-forgot-how-make-nuclear-bombs/
  - "Did America Forget How to Make the H-Bomb? Inside an institutional memory lapse of nuclear proportions"
  - Nick Baumann (Mother Jones)
  - 2009-05-01
  - ''
  - ! '<p>In 2007, as the government began overhauling the nation’s stockpile of W76 warheads—the variety often carried by Ohio-class submarines—officials at the National Nuclear Security Administration realized they couldn’t produce an essential material known as “Fogbank.” What purpose this substance actually serves is classified, but outside experts have suggested that it’s a sort of exploding foam that sits between the fission and fusion portions of hydrogen bombs. The Government Accountability Office reported in March that <span class="smallcaps-auto">NNSA</span>’s effort to recover its Fogbank-making ability had resulted in a yearlong, $69 million delay in the refurbishment project. And a government official with knowledge of the situation tells Mother Jones that further Fogbank-related delays are imminent.</p><p>The US government’s Fogbank snafu has stunned nuclear policy experts. “What the story ought to tell people is that the institutions that we’ve built to oversee development and maintenance of our nuclear weapons are incompetent,” says Jeffrey Lewis, the director of the nuclear strategy and nonproliferation initiative at the New America Foundation, who has written about the episode.</p><p>So how did America’s three nuclear weapons design laboratories and four nuclear weapons manufacturing plants—the institutions collectively known as the nuclear weapons complex—simply forget how to make a crucial component of one of the military’s most important warheads? “It seems like it was a case of ten-year-itis,” says Phil Coyle, a former assistant secretary of defense who worked in the nuclear weapons complex for 33 years. “Ten years go by and people forget things that they used to know how to do.”</p><p>“You have to keep people who know how to do these things and when people get too old or they retire you have to train new people to take their place,” adds Coyle, now a senior adviser to the Center for Defense Information, a Washington think tank. But <span class="smallcaps-auto">NNSA</span> failed to do so, according to the <span class="smallcaps-auto">GAO</span>. The agency “kept few records of the process when [Fogbank] was made in the 1980s and almost all staff with expertise on production had retired or left the agency” by the 2000s.</p>'
- - https://www.apollo-magazine.com/a-poster-has-to-be-joyous-the-energy-and-enthusiasm-of-willem-sandberg/
  - "‘A poster has to be joyous’. The energy and enthusiasm of Willem Sandberg"
  - Will Martin (Apollo)
  - 2016-07-11
  - ''
  - ! '<p>Born in 1897, Sandberg studied art in Amsterdam before travelling around Europe where he met and learned from printers, artists and teachers, including Johannes Itten, Naum Gabo and Otto Neurath. Upon returning to Amsterdam he became involved with the Stedelijk Museum, initially as a designer and later as curator of modern art from 1937 to 1941. It is after this period that the Second World War became a defining factor in his life. I have, in previous drafts of this piece, tried to summarise his involvement in the conflict, but he did more than is possible to do justice to here. Suffice to say, many items in the Stedelijk collection, not to mention Rembrandt’s The Night Watch and the collection of Van Gogh’s heirs, probably owe their survival to his resistance efforts. Others, such as Simon Garfield, have written about his wartime achievements. I recommend this piece by Mafalda Spencer, my old tutor and daughter of Herbert Spencer, who was one of Sandberg’s pen pals. (Their correspondence, which Mafalda has inherited, is featured in this exhibition.)</p><p>After the war Sandberg was made director of the Stedelijk and oversaw hundreds of exhibitions during his 18 years in the role. Throughout this period he carried on designing the catalogues and posters that feature in this exhibition…Among Sandberg’s wartime experience was the period he spent on the run from the Nazis, from 1943 until the end of the war. While in hiding, Sandberg wanted to occupy himself and decided to create a series of small booklets, each ranging from 20 to 60 pages. It is in making these that he seems to have refined what would later be the style he used for the majority of his design work at the Stedelijk. The booklets, which he called <em>experimenta typographica</em>, were filled with illustrations of inspirational quotes, which Sandberg took from great thinkers and other designers…The posters don’t really establish any sense of a coherent identity in the way that a modern designer might be driven to do these days. There isn’t really any consistency in layout, the typefaces chosen to spell out the Stedelijk’s name vary widely and while the use of red in each poster is a constant, it’s not always the same shade. But they do fulfil the criteria for Stedelijk posters of the time that Sandberg himself drew up:</p><ol type="1"><li>a poster has to be joyous</li><li>red has to be in every poster</li><li>a poster has to provoke a closer look, otherwise it doesn’t endure</li><li>with a respect for society, designer and director both are responsible for the street scene, a poster does not only have to revive the street, it also has to be human</li><li>every poster has to be an artwork</li></ol>'
- - /docs/technology/2011-bresnahan.pdf
  - ! "'An Unused Esperanto': Internationalism and Pictographic Design, 1930–1970"
  - Keith Bresnahan
  - '2011'
  - '10.2752/175470810X12863771378671'
  - ! '<p>The decades surrounding the Second World War saw an intense wave of interest in pictographic communication, with social scientists and graphic designers promoting the potential of universal pictographic “language” to bring about international understanding and co-operation. This article explores the historical relationship between pictographic design and internationalist politics in this era through the work of Rudolf Modley, a pioneering designer of information graphics whose career spanned from the socialist experiments of 1920s Vienna to humanist advocacy projects in late-1960s America. Tracing the complex relationship between visual communication, commerce and politics in mid-twentieth-century design, this article further reflects on the decline of the pictographic project after the 1970s, when pictographs at once gained a broad global currency and lost their political thrust just as the dream of an international visual language was ironically realized in the triumph of a global traffic in mass-consumable images. [Keywords: pictographic design, internationalism, information design, Rudolf Modley, Otto Neurath, Margaret Mead]</p>'
- - /docs/genetics/heritable/2012-kirzinger.pdf
  - Genetic and Environmental Influences on Media Use and Communication Behaviors
  - Ashley E. Kirzinger, Christopher Weber, Martin Johnson
  - 2014-04-01
  - 10.1111/j.1468-2958.2011.01424.x
  - ! '<p>A great deal of scholarly work has explored the motivations behind media consumption and other various communication traits. However, little research has investigated the sources of these motivations and virtually no research considers their potential genetic underpinnings. Drawing on the field of behavior genetics, we use a classical twin design study to examine the genetic and environmental influences on nine communication behaviors. Our findings indicate a substantial portion of the total variance in media habits can be attributed to genes, as much as one-third of the variance in some instances. Mass communication scholars would benefit by paying closer attention to heritability when thinking about the causes as well as the consequences of media traits in contemporary society.</p>'
- - /docs/history/2018-wang.pdf
  - 'Sons and Lovers: Political Stability in China and Europe Before the Great Divergence'
  - Yuhua Wang
  - 2018-10-25
  - 10.2139/ssrn.3058065
  - ! '<p>Rulers’ long duration in the medieval period had contributed to the rise of Europe. But what explained premodern ruler duration? While the extant answers focus on formal, political institutions, I examine the role of marriage and inheritance norms in affecting ruler survival. Using a novel dataset of over 1,000 monarchs in China and Europe from 1000 to 1800 CE, I obtain two findings that have been overlooked by the existing literature. First, contrary to the view that European rulers had exceptional stability, I find that Chinese monarchs stayed in power longer than their European counterparts. Second, I find a strong effect of family practices on ruler survival. More liberal marriage and inheritance norms provided Chinese emperors with sustained availability of male heirs, which reduced palace coups. But the Church’s control of royal marriage and inheritance in Europe decreased the number of male heirs, which increased the probability of a deposition. [Keywords: Ruler duration, succession politics, informal institutions, China, Europe]</p>'
- - https://github.com/google-research/google-research/tree/master/automl_zero
  - 'AutoML-Zero: Open source code for the paper: "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch"'
  - Esteban Real, Chen Liang, David R. So, Quoc V. Le (Google Brain)
  - 2020-03-02
  - ''
  - ! '<p>AutoML-Zero aims to automatically discover computer programs that can solve machine learning tasks, starting from empty or random programs and using only basic math operations. The goal is to simultaneously search for all aspects of an ML algorithm—including the model structure and the learning strategy—while employing <em>minimal human bias</em>.</p> <figure><video controls="controls" preload="metadata" loop><source src="/images/rl/2020-real-googlebrain-automlzero-bestalgorithmannotation.mp4" alt="GIF for the experiment progress (https://raw.githubusercontent.com/google-research/google-research/master/automl_zero/progress.gif)" type="video/mp4"></video><figcaption><span class="smallcaps-auto"><span class=\"smallcaps-auto\">GIF</span></span> for the experiment progress</figcaption></figure> <p>Despite AutoML-Zero’s challenging search space, <em>evolutionary search</em> shows promising results by discovering linear regression with gradient descent, 2-layer neural networks with backpropagation, and even algorithms that surpass hand designed baselines of comparable complexity. The figure above shows an example sequence of discoveries from one of our experiments, evolving algorithms to solve binary classification tasks. Notably, the evolved algorithms can be <em>interpreted</em>. Below is an analysis of the best evolved algorithm: the search process “invented” techniques like bilinear interactions, weight averaging, normalized gradient, and data augmentation (by adding noise to the inputs).</p> <figure><video controls="controls" preload="metadata" loop><source src="/images/rl/2020-real-googlebrain-automlzero-bestalgorithmannotation.mp4" alt="GIF for the interpretation of the best evolved algorithm (https://raw.githubusercontent.com/google-research/google-research/master/automl_zero/best_algo.gif)" type="video/mp4"></video><figcaption><span class="smallcaps-auto"><span class=\"smallcaps-auto\">GIF</span></span> for the interpretation of the best evolved algorithm</figcaption></figure> <p>More examples, analysis, and details can be found in the <a href="https://arxiv.org/abs/2003.03384#googlebrain" title="&#39;AutoML-Zero: Evolving Machine Learning Algorithms From Scratch&#39;, Real et al 2020">paper</a>.</p>'
- - /docs/biology/2006-almond.pdf
  - 'Is the 1918 Influenza Pandemic Over? Long-Term Effects of <em>In Utero</em> Influenza Exposure in the Post-1940 U.S. Population'
  - Douglas Almond
  - 2006-08
  - 10.1086/507154
  - ! '<p>This paper uses the 1918 influenza pandemic as a natural experiment for testing the fetal origins hypothesis. The pandemic arrived unexpectedly in the fall of 1918 and had largely subsided by January 1919, generating sharp predictions for long-term effects. Data from the 1960–80 decennial U.S. Census indicate that cohorts in utero during the pandemic displayed reduced educational attainment, increased rates of physical disability, lower income, lower socioeconomic status, and higher transfer payments compared with other birth cohorts. These results indicate that investments in fetal health can increase human capital.</p>'
- - https://marginalrevolution.com/marginalrevolution/2020/03/the-lasting-effects-of-the-1918-influenza-pandemic.html
  - "The Lasting Effects of the 1918 Influenza Pandemic"
  - Alex Tabarrok
  - 2020-03-10
  - ''
  - ! '<p>The 1918 influenza pandemic struck the United States with most ferocity in October of 1918 and then over the next four months killed more people than all the US combat deaths of the 20<sup>th</sup> century. The sudden nature of the pandemic meant that children born just months apart experienced very different conditions in utero. In particular, children born in 1919 were much more exposed to influenza in utero than children born in 1918 or 1920. The sudden differential to the 1918 flu lets Douglas Almond test for long-term effects in <a href="https://www.journals.uchicago.edu/cgi-bin/resolve?id=doi:10.1086/507154">Is the 1918 Influenza Pandemic Over?</a></p><p>Almond finds large effects many decades after exposure.</p><blockquote><p>Fetal health is found to affect nearly every socioeconomic outcome recorded in the 1960, 1970, and 1980 Censuses. Men and women show large and discontinuous reductions in educational attainment if they had been in utero during the pandemic. The children of infected mothers were up to 15% less likely to graduate from high school. Wages of men were 5–9% lower because of infection. Socioeconomic status…was substantially reduced, and the likelihood of being poor rose as much as 15% compared with other cohorts. Public entitlement spending was also increased.</p></blockquote><p><img class="wp-image-77850 alignright" src="/images/2006-almond-lastingeffectsof1918influenzapandemic-figure2-1980maledisabilityrates.jpg" alt="http://2378nh2nfow32gm3mb25krmuyy-wpengine.netdna-ssl.com/wp-content/uploads/2020/03/Flu-2-e1583802905525.jpg" width="539" height="361" srcset="https://2378nh2nfow32gm3mb25krmuyy-wpengine.netdna-ssl.com/wp-content/uploads/2020/03/Flu-2-e1583802905525.jpg 1058w, https://2378nh2nfow32gm3mb25krmuyy-wpengine.netdna-ssl.com/wp-content/uploads/2020/03/Flu-2-e1583802905525-300x201.jpg 300w, https://2378nh2nfow32gm3mb25krmuyy-wpengine.netdna-ssl.com/wp-content/uploads/2020/03/Flu-2-e1583802905525-1024x685.jpg 1024w, https://2378nh2nfow32gm3mb25krmuyy-wpengine.netdna-ssl.com/wp-content/uploads/2020/03/Flu-2-e1583802905525-768x514.jpg 768w" sizes="(max-width: 539px) 100vw, 539px" /></p> <p> ...male disability rates in 1980, i.e. for males around the age of 60, by year and quarter of birth. Cohorts born between January and September of 1919 “were in utero at the height of the pandemic and are estimated to have 20% higher disability rates at age 61…”.</p><p>Figure 3 at right shows average years of schooling in 1960; once again the decline is clear for those born in 1918 and note that not all pregnant women contracted influenza so the actual effects of influenza exposure are larger, about a 5 month decline in education, mostly coming through lower graduate rates.</p>'
- - https://github.com/arfafax/E621-Face-Dataset
  - "E621 Face Dataset"
  - Arfafax
  - 2020-02-18
  - ''
  - ! '<p>Tool for getting the dataset of cropped faces from [furry booru] <a href="https://e621.net/posts">e621</a> (<span class="smallcaps-auto">NSFW</span>; <a href="https://en.wikifur.com/wiki/E621">WikiFur description</a>). It was created by training a <a href="https://arxiv.org/abs/1804.02767" title="&#39;YOLOv3: An Incremental Improvement&#39;, Redmond &amp; Farhadi 2018"><span class="smallcaps-auto">YOLO</span>v3</a> network on annotated facial features from about 1500 faces.</p><p>The total dataset includes ~186k faces. Rather than provide the cropped images, this repo contains <span class="smallcaps-auto">CSV</span> files with the bounding boxes of the detected features from my trained network, and a script to download the images from e621 and crop them based on these <span class="smallcaps-auto">CSV</span>s.</p><p>The <span class="smallcaps-auto">CSV</span>s also contain a subset of tags, which could potentially be used as labels to train a conditional <span class="smallcaps-auto">GAN</span>.</p><table><colgroup><col style="width: 30%" /><col style="width: 69%" /></colgroup><thead><tr class="header"><th style="text-align: left;">File</th><th style="text-align: left;"> </th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">get_faces.py</td><td style="text-align: left;">Script for downloading base e621 files and cropping them based on the coordinates in the <span class="smallcaps-auto">CSV</span>s.</td></tr><tr class="even"><td style="text-align: left;">faces_s.csv</td><td style="text-align: left;"><span class="smallcaps-auto">CSV</span> containing <span class="smallcaps-auto">URL</span>s, bounding boxes, and a subset of the tags for 90k cropped faces with rating=safe from e621.</td></tr><tr class="odd"><td style="text-align: left;">features_s.csv</td><td style="text-align: left;"><span class="smallcaps-auto">CSV</span> containing the bounding boxes for 389k facial features with rating=safe from e621.</td></tr><tr class="even"><td style="text-align: left;">faces_q.csv</td><td style="text-align: left;"><span class="smallcaps-auto">CSV</span> containing <span class="smallcaps-auto">URL</span>s, bounding boxes, and a subset of the tags for 96k cropped faces with rating=questionable from e621.</td></tr><tr class="odd"><td style="text-align: left;">features_q.csv</td><td style="text-align: left;"><span class="smallcaps-auto">CSV</span> containing the bounding boxes for 400k facial features with rating=questionable from e621.</td></tr></tbody></table><figure><img src="/images/gan/2020-arfa-e621facedataset-cleaned-9x9previewgrid.jpg" alt="Preview grid" /><figcaption>Preview grid</figcaption></figure>'
- - /docs/psychology/2014-hambrick.pdf
  - 'Deliberate practice: Is that all it takes to become an expert?'
  - David Z. Hambrick, Frederick L. Oswald, Erik M. Altmann, Elizabeth J. Meinz, Fernand Gobet, Guillermo Campitelli
  - 2014-07
  - 10.1016/j.intell.2013.04.001
  - ! '<ul><li>Ericsson and colleagues argue that deliberate practice explains expert performance.</li><li>We tested this view in the two most studied domains in expertise research.</li><li>Deliberate practice is not sufficient to explain expert performance.</li><li>Other factors must be considered to advance the science of expertise.</li></ul><p>Twenty years ago, <a href="/docs/psychology/writing/1993-ericsson.pdf" title="The role of deliberate practice in the acquisition of expert performance.">Ericsson, Krampe, and Tesch-Römer (1993)</a> proposed that expert performance reflects a long period of deliberate practice rather than innate ability, or “talent”. Ericsson et al. found that elite musicians had accumulated thousands of hours more deliberate practice than less accomplished musicians, and concluded that their theoretical framework could provide “a sufficient account of the major facts about the nature and scarcity of exceptional performance” (p. 392). The deliberate practice view has since gained popularity as a theoretical account of expert performance, but here we show that deliberate practice is not sufficient to explain individual differences in performance in the two most widely studied domains in expertise research—chess and music. For researchers interested in advancing the science of expert performance, the task now is to develop and rigorously test theories that take into account as many potentially relevant explanatory constructs as possible. [Keywords: Expert performance, Expertise, Deliberate practice, Talent]</p>'
- - /docs/iq/2007-berry.pdf
  - 'Revisiting Interview–Cognitive Ability Relationships: Attending To Specific Range Restriction Mechanisms In Meta-Analysis'
  - Christopher M. Berry, Paul R. Sackett, Richard N. Landers
  - 2007-11-13
  - 10.1111/j.1744-6570.2007.00093.x
  - ! '<p>This study revisits the relationship between interviews and cognitive ability tests, finding lower magnitudes of correlation than have previous meta-analyses; a finding that has implications for both the construct and incremental validity of the interview. Our lower estimates of this relationship than previous meta-analyses were mainly due to (a) an updated set of studies, (b) exclusion of samples in which interviewers potentially had access to applicants’ cognitive test scores, and (c) attention to specific range restriction mechanisms that allowed us to identify a sizable subset of studies for which range restriction could be accurately accounted. Moderator analysis results were similar to previous meta-analyses, but magnitudes of correlation were generally lower than in previous meta-analyses. Findings have implications for the construct and incremental validity of interviews, and meta-analytic methodology in general.</p>'
- - https://www.nature.com/articles/ncomms14256
  - Impact of genetic background and experimental reproducibility on identifying chemical compounds with robust longevity effects
  - Mark Lucanic, W. Todd Plummer, Esteban Chen, Jailynn Harke, Anna C. Foulger, Brian Onken, Anna L. Coleman-Hulbert, Kathleen J. Dumas, Suzhen Guo, Erik Johnson, Dipa Bhaumik, Jian Xue, Anna B. Crist, Michael P. Presley, Girish Harinath, Christine A. Sedore, Manish Chamoli, Shaunak Kamat, Michelle K. Chen, Suzanne Angeli, Christina Chang, John H. Willis, Daniel Edgar, Mary Anne Royal, Elizabeth A. Chao, Shobhna Patel, Theo Garrett, Carolina Ibanez-Ventoso, June Hope, Jason L Kish, Max Guo, Gordon J. Lithgow, Monica Driscoll, Patrick C. Phillips
  - 2017-02-21
  - 10.1038/ncomms14256
  - ! '<p>Limiting the debilitating consequences of ageing is a major medical challenge of our time. Robust pharmacological interventions that promote healthy ageing across diverse genetic backgrounds may engage conserved longevity pathways. Here we report results from the <em>Caenorhabditis</em> Intervention Testing Program in assessing longevity variation across 22 <em>Caenorhabditis</em> strains spanning 3 species, using multiple replicates collected across three independent laboratories. Reproducibility between test sites is high, whereas individual trial reproducibility is relatively low. Of ten pro-longevity chemicals tested, six significantly extend lifespan in at least one strain. Three reported dietary restriction mimetics are mainly effective across <em>C. elegans</em> strains, indicating species and strain-specific responses. In contrast, the amyloid dye ThioflavinT is both potent and robust across the strains. Our results highlight promising pharmacological leads and demonstrate the importance of assessing lifespans of discrete cohorts across repeat studies to capture biological variation in the search for reproducible ageing interventions.</p>'
- - https://www.nytimes.com/2020/03/10/us/coronavirus-testing-delays.html
  - "‘It’s Just Everywhere Already’: How Delays in Testing Set Back the U.S. Coronavirus Response: A series of missed chances by the federal government to ensure more widespread testing came during the early days of the outbreak, when containment would have been easier"
  - Sheri Fink, Mike Baker (<span class=\"smallcaps-auto\">NYT</span>)
  - 2020-03-10
  - ''
  - ! '<p>Dr. Helen Y. Chu, an infectious disease expert in Seattle, knew that the United States did not have much time…As luck would have it, Dr. Chu had a way to monitor the region. For months, as part of a research project into the flu, she and a team of researchers had been collecting nasal swabs from residents experiencing symptoms throughout the Puget Sound region. To repurpose the tests for monitoring the coronavirus, they would need the support of state and federal officials. But nearly everywhere Dr. Chu turned, officials repeatedly rejected the idea, interviews and emails show, even as weeks crawled by and outbreaks emerged in countries outside of China, where the infection began.</p><p>By Feb. 25, Dr. Chu and her colleagues could not bear to wait any longer. They began performing coronavirus tests, without government approval. What came back confirmed their worst fear…In fact, officials would later discover through testing, the virus had already contributed to the deaths of two people, and it would go on to kill 20 more in the Seattle region over the following days.</p><p>Federal and state officials said the flu study could not be repurposed because it did not have explicit permission from research subjects; the labs were also not certified for clinical work. While acknowledging the ethical questions, Dr. Chu and others argued there should be more flexibility in an emergency during which so many lives could be lost. On Monday night, state regulators told them to stop testing altogether…Later that day, the investigators and Seattle health officials gathered with representatives of the C.D.C. and the F.D.A. to discuss what happened. The message from the federal government was blunt. “What they said on that phone call very clearly was cease and desist to Helen Chu,” Dr. Lindquist remembered. “Stop testing.”</p><p>…Even now, after weeks of mounting frustration toward federal agencies over flawed test kits and burdensome rules, states with growing cases such as New York and California are struggling to test widely for the coronavirus. The continued delays have made it impossible for officials to get a true picture of the scale of the growing outbreak, which has now spread to at least 36 states and Washington, D.C…But the Seattle Flu Study illustrates how existing regulations and red tape—sometimes designed to protect privacy and health—have impeded the rapid rollout of testing nationally, while other countries ramped up much earlier and faster.</p><p>…The flu project primarily used research laboratories, not clinical ones, and its coronavirus test was not approved by the Food and Drug Administration. And so the group was not certified to provide test results to anyone outside of their own investigators. They began discussions with state, C.D.C. and F.D.A. officials to figure out a solution, according to emails and interviews…the F.D.A. could not offer the approval because the lab was not certified as a clinical laboratory under regulations established by the Centers for Medicare &amp; Medicaid Services, a process that could take months. Dr. Chu and Dr. Lindquist tried repeatedly to wrangle approval to use the Seattle Flu Study. The answers were always no. “We felt like we were sitting, waiting for the pandemic to emerge,” Dr. Chu said. “We could help. We couldn’t do anything.”…“This virus is faster than the F.D.A.,” he said, adding that at one point the agency required him to submit materials through the mail in addition to over email.</p><p>…On a phone call the day after the C.D.C. and F.D.A. had told Dr. Chu to stop, officials relented, but only partially, the researchers recalled. They would allow the study’s laboratories to test cases and report the results only in future samples. They would need to use a new consent form that explicitly mentioned that results of the coronavirus tests might be shared with the local health department. They were not to test the thousands of samples that had already been collected.</p>'
- - https://www.newyorker.com/magazine/2017/10/16/russias-house-of-shadows
  - "Russia’s House of Shadows: My apartment building was made to house the first generation of Soviet élite. Instead, it was where the revolution went to die"
  - Joshua Yaffa
  - 2017-10-09
  - ''
  - ! '<p>He and his wife live in an apartment not far from mine that was originally occupied by his grandfather, who was the Soviet Union’s chief literary censor under Stalin. The most striking thing about the building was, and is, its history. In the nineteen-thirties, during Stalin’s purges, the House of Government earned the ghoulish reputation of having the highest per-capita number of arrests and executions of any apartment building in Moscow. No other address in the city offers such a compelling portal into the world of Soviet-era bureaucratic privilege, and the horror and murder to which this privilege often led….“Why does this house have such a heavy, difficult aura?” he said. “This is why: on the one hand, its residents lived like a new class of nobility, and on the other they knew that at any second they could get their guts ripped out.”</p><p>…This is the opening argument of a magisterial new book by Yuri Slezkine, a Soviet-born historian who immigrated to the United States in 1983, and has been a professor at the University of California, Berkeley, for many years. His book, <a href="https://www.amazon.com/House-Government-Saga-Russian-Revolution/dp/0691176949"><em>The House of Government</em></a>, is a 1200-page epic that recounts the multigenerational story of the famed building and its inhabitants—and, at least as interesting, the rise and fall of Bolshevist faith. In Slezkine’s telling, the Bolsheviks were essentially a millenarian cult, a small tribe radically opposed to a corrupt world. With Lenin’s urging, they sought to bring about the promised revolution, or revelation, which would give rise to a more noble and just era. Of course, that didn’t happen. Slezkine’s book is a tale of “failed prophecy,” and the building itself—my home for the past several years—is “a place where revolutionaries came home and the revolution went to die.”…The Soviet Union had experienced two revolutions, Lenin’s and Stalin’s, and yet, in the lofty imagery of Slezkine, the “world does not end, the blue bird does not return, love does not reveal itself in all of its profound tenderness and charity, and death and mourning and crying and pain do not disappear.” What to do then? The answer was human sacrifice, “one of history’s oldest locomotives,” Slezkine writes. The “more intense the expectation, the more implacable the enemies; the more implacable the enemies, the greater the need for internal cohesion; the greater the need for internal cohesion, the more urgent the search for scapegoats.” Soon, in Stalin’s Soviet Union, the purges began.</p><p>…N.K.V.D. agents would sometimes use the garbage chutes that ran like large tubes through many apartments, popping out inside a suspect’s home without having to knock on the door. After a perfunctory trial, which could last all of three to five minutes, prisoners were taken to the left or to the right: imprisonment or execution. “Most House of Government leaseholders were taken to the right,” Slezkine writes…eight hundred residents of the House of Government were arrested or evicted during the purges, thirty per cent of the building’s population. Three hundred and forty-four were shot…Before long, the arrests spread from the tenants to their nannies, guards, laundresses, and stairwell cleaners. The commandant of the house was arrested as an enemy of the people, and so was the head of the Communist Party’s housekeeping department…“He felt a premonition,” she said. “He was always waiting, never sleeping at night.” One evening, Malyshev heard footsteps coming up the corridor—and dropped dead of a heart attack. In a way, his death saved the family: there was no arrest, and thus no reason to kick his relatives out of the apartment.</p><p>…One of Volin’s brothers was…called back, arrested, and shot. One of Volin’s sisters was married to an N.K.V.D. officer, and they lived in the House of Government, in a nearby apartment. When the husband’s colleagues came to arrest him, he jumped out of the apartment window to his death. Volin, I learned, kept a suitcase packed with warm clothes behind the couch, ready in case of arrest and sentence to the Gulag…They gave their daughter, Tolya’s mother, a peculiar set of instructions. Every day after school, she was to take the elevator to the ninth floor—not the eighth, where the family lived—and look down the stairwell. If she saw an N.K.V.D. agent outside the apartment, she was supposed to get back on the elevator, go downstairs, and run to a friend’s house.</p>'
- - https://www.metopera.org/about/press-releases/met-to-launch-nightly-met-opera-streams-a-free-series-of-encore-live-in-hd-presentations-streamed-on-the-company-website-during-the-coronavirus-closure/
  - "Met to launch 'Nightly Met Opera Streams', a free series of encore Live in HD presentations streamed on the company website during the coronavirus closure"
  - The Metropolitan Opera
  - 2020-03-13
  - ''
  - ! '<p>Met to launch “Nightly Met Opera Streams,” a free series of encore Live in HD presentations streamed on the company website during the coronavirus closure…A day after canceling upcoming performances due to concerns around the coronavirus, the Metropolitan Opera announced that it would stream encore presentations from the award-winning Live in HD series of cinema transmissions on the company website for the duration of the closure. The new offering will begin on Monday, March 16 with the 2010 HD performance of Bizet’s <em>Carmen</em>, conducted by Met Music Director Yannick Nézet-Séguin and starring Elīna Garanča in the title role and Roberto Alagna as Don José. All “Nightly Met Opera Streams” will begin at 7:30pm and will remain available via the homepage of <code>metopera.org</code> for 20 hours.</p><ol type="1"><li>Monday, March 16—Bizet’s <em>Carmen</em></li><li>Tuesday, March 17—Puccini’s <em>La Bohème</em></li><li>Wednesday, March 18—Verdi’s <em>Il Trovatore</em></li><li>Thursday, March 19—Verdi’s <em>La Traviata</em></li><li>Friday, March 20—Donizetti’s <em>La Fille du Régiment</em></li><li>Saturday, March 21—Donizetti’s <em>Lucia di Lammermoor</em></li><li>Sunday, March 22—Tchaikovsky’s <em>Eugene Onegin</em></li></ol>'
- - /docs/nootropics/2020-olson.pdf
  - 'Tripping on nothing: placebo psychedelics and contextual factors'
  - Jay A. Olson, Léah Suissa-Rocheleau, Michael Lifshitz, Amir Raz, Samuel P. L. Veissière
  - 2020-03-07
  - 10.1007/s00213-020-05464-5
  - ! '<p><em>Rationale</em>: Is it possible to have a psychedelic experience from a placebo alone? Most psychedelic studies find few effects in the placebo control group, yet these effects may have been obscured by the study design, setting, or analysis decisions.</p><p><em>Objective</em>: We examined individual variation in placebo effects in a naturalistic environment resembling a typical psychedelic party.</p><p><em>Methods</em>: 33 students completed a single-arm study ostensibly examining how a psychedelic drug affects creativity. The 4-h study took place in a group setting with music, paintings, coloured lights, and visual projections. Participants consumed a placebo that we described as a drug resembling psilocybin, which is found in psychedelic mushrooms. To boost expectations, confederates subtly acted out the stated effects of the drug and participants were led to believe that there was no placebo control group. The participants later completed the 5-Dimensional Altered States of Consciousness Rating Scale, which measures changes in conscious experience.</p><p><em>Results</em>: There was considerable individual variation in the placebo effects; many participants reported no changes while others showed effects with magnitudes typically associated with moderate or high doses of psilocybin. In addition, the majority (61%) of participants verbally reported some effect of the drug. Several stated that they saw the paintings on the walls “move” or “reshape” themselves, others felt “heavy… as if gravity [had] a stronger hold”, and one had a “come down” before another “wave” hit her.</p><p><em>Conclusion</em>: Understanding how context and expectations promote psychedelic-like effects, even without the drug, will help researchers to isolate drug effects and clinicians to maximise their therapeutic potential.</p><p>...In the second sample, before the debriefing, we asked participants to guess whether they had taken a psychedelic, a placebo, or whether they were uncertain. Overall, 35% reported being certain they had taken a placebo, 12% were certain that they had taken a psychedelic, and the rest (53%) were uncertain. In the first sample, we did not ask this question, but the same number of people spontaneously reported being certain that they had taken a psychedelic drug. During the debriefing, when we revealed the placebo nature of the study, many participants appeared shocked. Several gasped and started laughing. One stated, “It’s very funny!”, and another replied, “It’s sad!” One of the participants who had sat with a group near the paintings throughout the study asked, “So we were all sober and just watching these paintings for 45 minutes‽”</p><p>[This is a remarkable study, and probably the most elaborate placebo ever reported. But how well did the trick work? The authors say that after they revealed the truth, some of the participants expressed shock. However, 35% of them said they were “certain” they had taken a placebo when quizzed just before the debriefing. Only 12% were “certain” that they’d taken a real psychedelic drug, which suggests that the deception was only partially successful.</p><p>Some of the participants did report very strong effects on a questionnaire of ‘psychedelic effects’. However, I noticed that the effects reported tended to be the more abstract kind, such as “insight” and “bliss”. In terms of actual <em>hallucinogenic</em> effects like ‘complex imagery’ and ‘elementary imagery’ (i.e. seeing things), no participants reported effects equal to even a low dose of <span class="smallcaps-auto">LSD</span>, let alone a stronger dose. See the rather confusing Figure 2 for details.]</p>'
- - https://onlinelibrary.wiley.com/doi/full/10.1111/jsr.12312
  - "Effects of lunar phase on sleep in men and women in Surrey"
  - Ciro Della Monica, Giuseppe Atzori, Derk-Jan Dijk
  - 2015-06-12
  - 10.1111/jsr.12312
  - ! '<p>Recently, evidence has emerged that the phases of the moon may modulate subjective sleep quality and polysomnographically assessed sleep structure in humans. We aimed to explore further the putative effects of circa-lunar periodicity (~29.5 days) on subjective and objective parameters of human sleep in a retrospective analysis. The baseline sleep recordings of 205 (91 males and 114 females; mean age = 47.47 years, standard deviation =19.01; range: 20–84 years) healthy and carefully screened participants who participated in two clinical trials in the Surrey Clinical Research Centre were included in the analyses. Sleep was recorded in windowless sleep laboratories. For each study night, we calculated the distance, in days, to the date of the closest full moon phase and based on this distance, classified sleep records in three lunar classes. Univariate analysis of variance with factors lunar class, age and sex was applied to each of 21 sleep parameters. No significant main effect for the factor lunar class was observed for any of the objective sleep parameters and subjective sleep quality but some significant interactions were observed. The interaction between lunar class and sex was significant for total sleep time, Stage 4 sleep and rapid eye movement (<span class="smallcaps-auto">REM</span>) sleep. Separate analyses for men and women indicated that in women total sleep time, Stage 4 sleep and <span class="smallcaps-auto">REM</span> sleep were reduced when sleep occurred close to full moon, whereas in men <span class="smallcaps-auto">REM</span> duration increased around full moon. These data provide limited evidence for an effect of lunar phase on human sleep.</p>'
- - 'https://www.cell.com/current-biology/fulltext/S0960-9822(14)00542-9'
  - "Lunar cycle effects on sleep and the file drawer problem"
  - Maren Cordi, Sandra Ackermann, Frederik W. Bes, Francina Hartmann, Boris N. Konrad, Lisa Genzel, Marcel Pawlowski, Axel Steiger, Hartmut Schulz, Björn Rasch, Martin Dresler
  - 2014-06-16
  - 10.1016/j.cub.2014.05.017
  - ! '<p>Popular beliefs about the influence of the full moon on humans exist, although no solid evidence has so far confirmed these ideas [1]. Cajochen et al. [2] recently presented fascinating data on lunar cycle effects on human sleep. However, in a re-analysis of sleep electroencephalography (<span class="smallcaps-auto">EEG</span>) data in three large samples, we were unable to replicate their findings. In addition, we identified further mostly unpublished null findings, suggesting that the conflicting results might be an example of a publication bias (i.e., the file drawer problem).</p>'
- - 'https://www.cell.com/current-biology/fulltext/S0960-9822(14)00543-0'
  - "Human sleep and cortical reactivity are influenced by lunar phase"
  - Michael Smith, Ilona Croy, Kerstin Persson Waye
  - 2014-06-16
  - 10.1016/j.cub.2014.05.018
  - ! '<p>Various human biological functions adhere to a circadian rhythm that to some extent may be affected by environmental factors, including light and temperature [1]. Recent evidence from Cajochen et al. [2] indicates that human sleep is influenced by the cycle of the moon, measured in conditions precluding the potential impact of nocturnal lunar illumination Here in a similarly retrospective study of 47 healthy volunteers (mean age 23.3, S.D. ±2.9 years) we demonstrate that total sleep time decreases by 25 minutes and cortical reactivity to environmental stimuli during sleep increases around full moon, and rapid eye movement (<span class="smallcaps-auto">REM</span>) sleep latency lengthens by 30 minutes around new moon. The findings strengthen the notion that human sleep is modulated by lunar phase but point to important deviations from the study of Cajochen et al. that need to be addressed, particularly with regard to individual susceptibility.</p>'
- - /docs/biology/1994-brook.pdf
  - 'Are public library books contaminated by bacteria?'
  - Sara J. Brook, Itzhak Brook
  - 1994-10
  - '10.1016/0895-4356(94)90103-1'
  - ! '<p>The microbial flora on the surfaces of 15 books obtained from a public library and from 15 books obtained from a family household were studied. <em>Staphylococcus epidermidis</em> was recovered from 4 of the library books and 3 of the family household books. The number of organisms per page was between one to four. This data illustrates the safety of using library books, as they do not serve as a potential source of transmission of virulent bacteria.</p>'
- - /docs/cs/2011-pellegrino.pdf
  - 'A Cross-Language Perspective On Speech Information Rate'
  - François Pellegrino, Christophe Coupé, Egidio Marsico
  - 2011-09
  - 10.2307/23011654
  - ! 'This article is a cross-linguistic investigation of the hypothesis that the average information rate conveyed during speech communication results from a trade-off between average information density and speech rate. The study, based on seven languages, shows a negative correlation between density and rate, indicating the existence of several encoding strategies. However, these strategies do not necessarily lead to a constant information rate. These results are further investigated in relation to the notion of syllabic complexity.'
- - https://esolangs.org/wiki/ByteByteJump
  - ByteByteJump
  - Esolang Wiki
  - ''
  - ''
  - ! '<p>ByteByteJump is an extremely simple One Instruction Set Computer (<a href="https://esolangs.org/wiki/OISC" title="OISC"><span class="smallcaps-auto">OISC</span></a>). Its single instruction copies 1 byte from a memory location to another, and then performs an unconditional jump.</p><p>An instruction consists of 3 addresses stored consecutively in memory:</p><pre>A,B,C</pre><p>A is the source address, B is the destination address, and C is the jump address. <b>N.B:</b> ByteByteJump uses <a href="http://en.wikipedia.org/wiki/Byte_addressing" class="extiw" title="wikipedia:Byte addressing">byte addressing</a>.</p><p>ByteByteJump has no <span class="smallcaps-auto">ALU</span>, but arithmetic operations and conditional jumps can still be performed by using self-modifying code and lookup tables (see <a href="https://esolangs.org/wiki/ByteByteJump#Example:_Subtract_and_jump_if_negative">Example</a>). Despite its apparent simplicity, ByteByteJump actually belongs to the computational class of real microprocessors: the <a href="https://esolangs.org/wiki/Linear_bounded_automaton" title="Linear bounded automaton">Linear bounded automaton</a>.</p><p><a href="https://esolangs.org/wiki/ByteByteJump#WordWordJump">WordWordJump</a> is the larger family of machines to which ByteByteJump belongs. An <i>X</i><em><i>Y</i>-bit WordWordJump machine has <i>Y</i>-bit data words and <i>X</i></em><i>Y</i>-bit address words, where <i>X</i> must be ≥2 for the machine to be able to compute. The optimal value for <i>X</i> (as explained <a href="https://esolangs.org/wiki/ByteByteJump#Optimal_number_of_words_per_address.3F">here</a>) seems to be 3.</p><p><a href="https://esolangs.org/wiki/ByteByteJump#The_two-instruction_ByteByte.2FJump">ByteByte/Jump</a> is ByteByteJump’s sister machine. It splits the single instruction of ByteByteJump into two for improved code density.</p>'
- - https://arstechnica.com/tech-policy/2018/01/hollywood-says-its-not-planning-another-copyright-extension-push/
  - "Why Mickey Mouse’s 1998 copyright extension probably won’t happen again: Copyrights from the 1920s will start expiring next year if Congress doesn’t act."
  - Timothy B. Lee (Ars Technica)
  - 2018-01-08
  - ''
  - ! '<p>On January 1, 2019, every book, film, and song published in 1923 will fall out of copyright protection—something that hasn’t happened in 40 years. At least, that’s what will happen if Congress doesn’t retroactively change copyright law to prevent it—as Congress has done two previous times. Until the 1970s, copyright terms only lasted for 56 years. But Congress retroactively extended the term of older works to 75 years in 1976. Then on October 27, 1998—just weeks before works from 1923 were scheduled to fall into the public domain—President Bill Clinton signed legislation retroactively extending the term of older works to 95 years, locking up works published in 1923 or later for another 20 years.</p><p>Will Congress do the same thing again this year? To find out, we talked to groups on both sides of the nation’s copyright debate—to digital rights advocates at the Electronic Frontier Foundation and Public Knowledge and to industry groups like the Motion Picture Association of America and the Recording Industry Association of America. To our surprise, there seemed to be universal agreement that another copyright extension was unlikely to be on the agenda this year. “We are not aware of any such efforts, and it’s not something we are pursuing,” an <span class="smallcaps-auto">RIAA</span> spokesman told us when we asked about legislation to retroactively extend copyright terms. “While copyright term has been a longstanding topic of conversation in policy circles, we are not aware of any legislative proposals to address the issue,” the <span class="smallcaps-auto">MPAA</span> told us…“I haven’t seen any evidence that Big Content companies plan to push for another term extension,” Nazer added. “This is an election year, so if they wanted to get a big ticket like that through Congress, you would expect to see them laying the groundwork with lobbying and op-eds.”</p><p>…<strong>The politics of copyright have changed dramatically</strong>…The rise of the Internet has totally changed the political landscape on copyright issues. The Electronic Frontier Foundation is much larger than it was in 1998. Other groups, including Public Knowledge, didn’t even exist 20 years ago. Internet companies—especially Google—have become powerful opponents of expanding copyright protections…The protest against <a href="https://en.wikipedia.org/wiki/Stop_Online_Piracy_Act"><span class="smallcaps-auto">SOPA</span></a> “was a big show of force,” says Meredith Rose, a lawyer at Public Knowledge. The protest showed that “the public really cares about this stuff.” The defeat of <span class="smallcaps-auto">SOPA</span> was so complete that it has essentially ended efforts by copyright interests to expand copyright protection via legislation. Prior to <span class="smallcaps-auto">SOPA</span>, Congress would regularly pass bills ratcheting up copyright protections (like the 2008 <span class="smallcaps-auto">PRO</span>-IP Act, which beefed up anti-piracy efforts). Since 2012, copyright has been a legislative stalemate, with neither side passing significant legislation.</p>'
- - https://arstechnica.com/tech-policy/2019/01/a-whole-years-worth-of-works-just-fell-into-the-public-domain/
  - "Mickey Mouse will be public domain soon—here’s what that means: The Internet stopped another copyright extension without firing a shot"
  - Timothy B. Lee (Ars Technica)
  - 2019-01-01
  - ''
  - ! '<p>As the ball dropped over Times Square last night, all copyrighted works published in 1923 fell into the public domain (with a few exceptions). Everyone now has the right to republish them or adapt them for use in new works. It’s the first time this has happened in 21 years.</p><p>In 1998, works published in 1922 or earlier were in the public domain, with 1923 works scheduled to expire at the beginning of 1999. But then Congress passed the Sonny Bono Copyright Term Extension Act. It added 20 years to the terms of older works, keeping 1923 works locked up until 2019. Many people—including me—expected another fight over copyright extension in 2018. But it never happened. Congress left the existing law in place, and so those 1923 copyrights expired on schedule this morning.</p><p>…Next January, George Gershwin’s <em>Rhapsody in Blue</em> will fall into the public domain. It will be followed by <em>The Great Gatsby</em> in January 2021 and Ernest Hemingway’s <em>The Sun Also Rises</em> in January 2022. On January 1, 2024, we’ll see the expiration of the copyright for <em>Steamboat Willie</em>—and with it Disney’s claim to the film’s star, Mickey Mouse. The copyrights to <em>Superman</em>, <em>Batman</em>, Disney’s <em>Snow White</em>, and early Looney Tunes characters will all fall into the public domain between 2031 and 2035.</p><p>…[but] <strong>Using public-domain characters could be a legal minefield</strong>: A company like Disney enjoys several layers of legal protection for a major character like Mickey Mouse. It owns the copyright to the original character. It owns the copyrights to subsequent versions of the character, which tend to be better known to modern audiences. And it also owns trademark rights…The most obvious example here is Mickey’s white gloves. He didn’t wear them in <em>Steamboat Willie</em>. So if you wanted to sell a Mickey toy with white gloves, you’d probably need to wait until 2025, when the copyright for the first Mickey short with white gloves, <em>The Opry House</em>, is scheduled to expire. The early Mickey Mouse cartoons were black and white, so if you wanted to make a Mickey Mouse toy with modern colors, you’d have to carefully research when those colors first appeared. Later changes to Mickey’s appearance have been more subtle. But they may still be legally significant…This is a line that third parties are already walking for the Sherlock Holmes series, which was published between 1887 and 1927. Most of the books are in the public domain, but the last few volumes are still under copyright…The same legal issues will arise when other iconic characters—Batman, Superman, Bugs Bunny, Daffy Duck, Winnie the Pooh, and so forth—fall into the public domain over the next 20 years…Anyone will be able to make new Batman cartoons after 2035, but they’ll have to be careful to only use elements from Batman’s original incarnation.</p>'
- - http://spectrum.ieee.org/consumer-electronics/audiovideo/deep-learning-reinvents-the-hearing-aid
  - "Deep Learning Reinvents the Hearing Aid: Finally, wearers of hearing aids can pick out a voice in a crowded room"
  - DeLiang Wang (<span class=\"smallcaps-auto\">IEEE</span> Spectrum)
  - 2016-12-06
  - ''
  - ! '<p>The human auditory system can naturally pick out a voice in a crowded room, but creating a hearing aid that mimics that ability has stumped signal processing specialists, artificial intelligence experts, and audiologists for decades. British cognitive scientist Colin Cherry first dubbed this the “cocktail party problem” in 1953.</p><p>More than six decades later, less than 25% of people who need a hearing aid actually use one…The global US $6 billion hearing aid industry is expected to grow at 6% every year through 2020…The greatest frustration among potential users is that a hearing aid cannot distinguish between, for example, a voice and the sound of a passing car if those sounds occur at the same time. The device cranks up the volume on both, creating an incoherent din.</p><p>It’s time we solve this problem. To produce a better experience for hearing aid wearers, my lab at Ohio State University, in Columbus, recently applied machine learning based on deep neural networks to the task of segregating sounds. We have tested multiple versions of a digital filter that not only amplifies sound but can also isolate speech from background noise and automatically adjust the volumes of each separately. We believe this approach can ultimately restore a hearing-impaired person’s comprehension to match—or even exceed—that of someone with normal hearing. In fact, one of our early models boosted, from 10 to 90 percent, the ability of some subjects to understand spoken words obscured by noise. Because it’s not necessary for listeners to understand every word in a phrase to gather its meaning, this improvement frequently meant the difference between comprehending a sentence or not…Having demonstrated promising initial results with our early classification algorithms, we decided to take the next logical step—to improve the system so it could function in noisy real-world environments, and without training for specific noises and sentences. This challenge prompted us to try to do something that had never been done before: build a machine-learning program that would run on a neural network and separate speech from noise after undergoing a sophisticated training process. The program would use the ideal binary mask to guide the training of the neural network. And it worked. In a study involving 24 test subjects, we demonstrated that this program could boost the comprehension of hearing-impaired people by about 50 percent.</p><p>…People in both groups showed a big improvement in their ability to comprehend sentences amid noise after the sentences were processed through our program. People with hearing impairment could decipher only 29% of words muddled by babble without the program, but they understood 84% after the processing. Several went from understanding only 10% of words in the original sample to comprehending around 90% with the program. There were similar gains for the steady-noise scenario with hearing-impaired subjects—they went from 36% to 82% comprehension. Even people with normal hearing were able to better understand noisy sentences, which means our program could someday help far more people than we originally anticipated. Listeners with normal hearing understood 37% of the words spoken amid steady noise without the program, and 80% with it. For the babble, they improved from 42% of words to 78 percent. One of the most intriguing results of our experiment came when we asked, Could people with hearing impairment who are assisted by our program actually outperform those with normal hearing? Remarkably, the answer is yes. Listeners with hearing impairment who used our program understood nearly 20% more words in the babble and about 15% more words in steady noise than those with normal hearing who relied solely on their own auditory system to separate speech from noise. With these results, our program built from deep neural networks has come the closest to solving the cocktail party problem of any effort to date.</p>'
- - https://www.statnews.com/2016/01/15/chipotle-foodborne-illnesses-cdc/
  - 'Chipotle, E. coli, and more: The surprising truths about food-borne illnesses'
  - Sheila Kaplan (<span class=\"smallcaps-auto\">STAT</span>)
  - 2016-01-15
  - ''
  - ! '<p>The outbreak garnered significant attention, in part because of the popularity of Chipotle, which has more than 1,500 locations worldwide. But the cases represent a drop in the bucket in the number of annual food-borne illnesses…The Centers for Disease Control and Prevention, which tracks both outbreaks like those at Chipotle and isolated occurrences, estimates that 48 million people contract food-borne diseases each year. Only a small number of those cases are considered actual outbreaks—defined as two or more people getting sick from the same source…only 40% of such cases are ever solved.</p><p><strong>You are safer in a fast-food restaurant than at a swanky restaurant</strong>: <span class="smallcaps-auto">CDC</span> statistics show that from 1998 to 2014, there were 1,969 outbreaks in “sit-down” restaurants, causing 26,350 illnesses, 1,206 hospitalizations, and eight deaths. By comparison, fast-food restaurants were the source of only 365 outbreaks, 5,624 illnesses, 533 hospitalizations, and three deaths.</p><p>David Plunkett, a senior food safety attorney with <span class="smallcaps-auto">CSPI</span> and co-author of the report released last week, said standardization at fast-food restaurants helps make them safer. “You can’t walk into a McDonald’s and say, ‘I’d like my hamburger rare,’” Plunkett explained. “’You should be less suspicious of the meat and more suspicious of the things that are going to be on the food raw, such as lettuce or a salad-type option.”</p>'
- - https://www.designboom.com/technology/evolution-desk-harvard-innovation-lab-09-30-2014
  - 'Harvard Innovation Lab visualizes the evolution of the desk'
  - 2014-09-30
  - Nina Azzarello (Designboom)
  - ''
  - ! '<p>The past 35 years has seen the transformation of the everyday things that surround us traverse from tangible to virtual. A digital app exists for everything from world mapping to paying bills, completely recontextualizing the tools we use in the workplace. A team at the Harvard innovation lab has encapsulated this history of technology, as it relates to the office, in a video, ‘The History Of The Computer Desk’, demonstrating the steep shift from cork boards and fax machines to Pinterest and <span class="smallcaps-auto">PDF</span>s.</p><p>‘We wondered what it would be like to recreate the desktop from the 1980’s and then emulate its transformation through the computer age.’ the team explain, ‘we wanted to illustrate how technology has changed our world, un-cluttering our desks and simplifying our lives. While gradual change from year to year is often hard to perceive, a longer snapshot gives us a much more dramatic view of the technological progression we have experienced.’</p><p>The scene is set with actual vintage items sourced by the team of photographers and entrepreneurs: the Macintosh Classic, corded phone, fax machine, globe, corkboard, Polaroid camera, and Rolodex were all purchased through individual sellers on eBay, while the rest of the items were found abandoned an unused in basements and at garage sales. While some argue that technology has made our lives more complex, the video below demonstrates the current clarity from clutter, and the ways in which technology encourages productive and social behavior.</p><figure><img src="/images/design/2014-designboom-evolutionofthedesk-beforeafter.jpg" alt="Before/after (https://static.designboom.com/wp-content/uploads/2014/09/evolution-of-the-desk-designboom-01.jpg)" /><figcaption>Before/after</figcaption></figure>'
- - https://blog.cloudflare.com/the-history-of-the-url/
  - The History of the <span class=\"smallcaps-auto\">URL</span>
  - Zack Bloom (Cloudflare)
  - 2020-03-05
  - ''
  - ! '<p>[Tracing the history of Internet domain names and <span class="smallcaps-auto">WWW</span> <span class="smallcaps-auto">URL</span>s from <span class="smallcaps-auto">ARPA</span>net’s need for emails to the present, and explaining how we got our confusing mishmash of Unix-style paths &amp; <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier"><span class="smallcaps-auto">URI</span>s</a>, and why <span class="smallcaps-auto">URL</span>s like <code>google.com.</code> are valid, with digressions into hacks like <a href="https://en.wikipedia.org/wiki/Punycode">Punycode</a> for representing non-English domains and <a href="https://en.wikipedia.org/wiki/Query_string">query strings</a> for turning a system for serving <span class="smallcaps-auto">HTML</span> documents into a system for arbitrary <span class="smallcaps-auto">API</span>s/<span class="smallcaps-auto">RPC</span>s.]</p>'
- - https://github.blog/2020-03-16-npm-is-joining-github/
  - npm is joining GitHub
  - Nat Friedman
  - 2020-03-16
  - ''
  - ! '<p>I’m excited to announce that GitHub has signed an agreement to acquire npm.</p><p>npm is a critical part of the JavaScript world. The work of the npm team over the last 10 years, and the contributions of hundreds of thousands of open source developers and maintainers, have made npm home to over 1.3 million packages with 75 billion downloads a month. Together, they’ve helped JavaScript become the largest developer ecosystem in the world. We at GitHub are honored to be part of the next chapter of npm’s story and to help npm continue to scale to meet the needs of the fast-growing JavaScript community.</p><p>For the millions of developers who use the public npm registry every day, npm will always be available and always be free. Our focus after the deal closes will be to:</p><ul><li>Invest in the registry infrastructure and platform.</li><li>Improve the core experience.</li><li>Engage with the community.</li></ul><p>Looking further ahead, we’ll integrate GitHub and npm to improve the security of the open source software supply chain, and enable you to trace a change from a GitHub pull request to the npm package version that fixed it…We are also investing heavily in GitHub Packages as a great multi-language packages registry that’s fully integrated with GitHub. Later this year, we will enable npm’s paying customers to move their private npm packages to GitHub Packages—allowing npm to exclusively focus on being a great public registry for JavaScript.</p>'
- - /docs/psychology/2016-hauschild.pdf
  - 'Fitness tests and occupational tasks of military interest: a systematic review of correlations'
  - Veronique D. Hauschild, David W. DeGroot, Shane M. Hall, Tyson L. Grier, Karen D. Deaver, Keith G. Hauret, Bruce H. Jones
  - 2016-11-03
  - 10.1136/oemed-2016-103684
  - ! '<p>Physically demanding occupations (ie, military, firefighter, law enforcement) often use fitness tests for job selection or retention. Despite numerous individual studies, the relationship of these tests to job performance is not always clear.</p><p>This review examined the relationship by aggregating previously reported correlations between different fitness tests and common occupational tasks.</p><p>Search criteria were applied to <span class="smallcaps-auto">PUBMED</span>, <span class="smallcaps-auto">EBSCO</span>, <span class="smallcaps-auto">EMBASE</span> and military sources; scoring yielded 27 original studies providing 533 Pearson correlation coefficients (<em>r</em>) between fitness tests and 12 common physical job task categories. Fitness tests were grouped into predominant health-related fitness components and body regions: cardiorespiratory endurance (CRe); upper body, lower body and trunk muscular strength and muscular endurance (UBs, LBs, TRs, UBe, LBe, TRe) and flexibility (<span class="smallcaps-auto">FLX</span>). Meta-analyses provided pooled <em>r</em>’s between each fitness component and task category.</p><p>The CRe tests had the strongest pooled correlations with most tasks (8 pooled <em>r</em> values 0.80–0.52). Next were LBs (six pooled <em>r</em> values &gt;0.50) and UBe (4 pooled <em>r</em> values &gt;0.50). UBs and LBe correlated strongly to 3 tasks. TRs, TRe and <span class="smallcaps-auto">FLX</span> did not strongly correlate to tasks.</p><p>Employers can maximise the relevancy of assessing workforce health by using fitness tests with strong correlations between fitness components and job performance, especially those that are also indicators for injury risk. Potentially useful field-expedient tests include timed-runs (CRe), jump tests (LBs) and push-ups (UBe). Impacts of gender and physiological characteristics (eg, lean body mass) should be considered in future study and when implementing tests.</p>'
- - /docs/longevity/2014-avenell.pdf
  - Vitamin D and vitamin D analogues for preventing fractures in post‐menopausal women and older men
  - "Alison Avenell, Jenson CS Mak, Dianne O'Connell"
  - 2014-04-14
  - 10.1002/14651858.CD000227.pub4
  - ! '<p><em>Background</em>: Vitamin D and related compounds have been used to prevent osteoporotic fractures in older people. This is the third update of a Cochrane review first published in 1996.</p><p><em>Objectives</em>: To determine the effects of vitamin D or related compounds, with or without calcium, for preventing fractures in post-menopausal women and older men.</p><p><em>Search methods</em>: We searched the Cochrane Bone, Joint and Muscle Trauma Group Specialised Register (to December 2012), the Cochrane Central Register of Controlled Trials (2012, Issue 12), <span class="smallcaps-auto">MEDLINE</span> (1966 to November Week 3 2012), <span class="smallcaps-auto">EMBASE</span> (1980 to 2012 Week 50), <span class="smallcaps-auto">CINAHL</span> (1982 to December 2012), <span class="smallcaps-auto">BIOSIS</span> (1985 to 3 January 2013), Current Controlled Trials (December 2012) and reference lists of articles.</p><p><em>Selection criteria</em>: Randomised or quasi-randomised trials that compared vitamin D or related compounds, alone or with calcium, against placebo, no intervention or calcium alone, and that reported fracture outcomes in older people. The primary outcome was hip fracture. Data collection and analysis</p><p>Two authors independently assessed trial risk of selection bias and aspects of methodological quality, and extracted data. Data were pooled, where possible, using the fixed-effect model, or the random-effects model when heterogeneity between studies appeared substantial. Main results</p><p>We included 53 trials with a total of 91,791 participants. Thirty-one trials, with sample sizes ranging from 70 to 36,282 participants, examined vitamin D (including 25-hydroxy vitamin D) with or without calcium in the prevention of fractures in community, nursing home or hospital inpatient populations. Twelve of these 31 trials had participants with a mean or median age of 80 years or over.</p><p>Another group of 22 smaller trials examined calcitriol or alfacalcidol (1-alphahydroxyvitamin D3), mostly with participants who had established osteoporosis. These trials were carried out in the setting of institutional referral clinics or hospitals.</p><p>In the assessment of risk of bias for random sequence generation, 21 trials (40%) were deemed to be at low risk, 28 trials (53%) at unclear risk and four trials at high risk (8%). For allocation concealment, 22 trials were at low risk (42%), 29 trials were at unclear risk (55%) and two trials were at high risk (4%).</p><p>There is high quality evidence that vitamin D alone, in the formats and doses tested, is unlikely to be effective in preventing hip fracture (11 trials, 27,693 participants; risk ratio (RR) 1.12, 95% confidence intervals (CI) 0.98 to 1.29) or any new fracture (15 trials, 28,271 participants; RR 1.03, 95% CI 0.96 to 1.11).</p><p>There is high quality evidence that vitamin D plus calcium results in a small reduction in hip fracture risk (nine trials, 49,853 participants; RR 0.84, 95% confidence interval (CI) 0.74 to 0.96; P value 0.01). In low-risk populations (residents in the community: with an estimated eight hip fractures per 1000 per year), this equates to one fewer hip fracture per 1000 older adults per year (95% CI 0 to 2). In high risk populations (residents in institutions: with an estimated 54 hip fractures per 1000 per year), this equates to nine fewer hip fractures per 1000 older adults per year (95% CI 2 to 14).</p><p>There is high quality evidence that vitamin D plus calcium is associated with a statistically significant reduction in incidence of new non-vertebral fractures. However, there is only moderate quality evidence of an absence of a statistically significant preventive effect on clinical vertebral fractures. There is high quality evidence that vitamin D plus calcium reduces the risk of any type of fracture (10 trials, 49,976 participants; RR 0.95, 95% CI 0.90 to 0.99).</p><p>In terms of the results for adverse effects: mortality was not adversely affected by either vitamin D or vitamin D plus calcium supplementation (29 trials, 71,032 participants, RR 0.97, 95% CI 0.93 to 1.01). Hypercalcaemia, which was usually mild (2.6 to 2.8 mmol/L), was more common in people receiving vitamin D or an analogue, with or without calcium (21 trials, 17,124 participants, RR 2.28, 95% CI 1.57 to 3.31), especially for calcitriol (four trials, 988 participants, RR 4.41, 95% CI 2.14 to 9.09), than in people receiving placebo or control. There was also a small increased risk of gastrointestinal symptoms (15 trials, 47,761 participants, RR 1.04, 95% CI 1.00 to 1.08), especially for calcium plus vitamin D (four trials, 40,524 participants, RR 1.05, 95% CI 1.01 to 1.09), and a significant increase in renal disease (11 trials, 46,548 participants, RR 1.16, 95% CI 1.02 to 1.33). Other systematic reviews have found an increased association of myocardial infarction with supplemental calcium; and evidence of increased myocardial infarction and stroke, but decreased cancer, with supplemental calcium plus vitamin D, without an overall effect on mortality.</p><p><em>Authors’ conclusions</em>: Vitamin D alone is unlikely to prevent fractures in the doses and formulations tested so far in older people. Supplements of vitamin D and calcium may prevent hip or any type of fracture. There was a small but significant increase in gastrointestinal symptoms and renal disease associated with vitamin D and calcium. This review found that there was no increased risk of death from taking calcium and vitamin D.</p>'
- - /docs/fiction/1980-wolfe-tbotns-theshadowofthetorturer-ch6-themasterofthecurators.pdf
  - "<em>The Shadow Of The Torturer</em>: The Master of the Curators"
  - Gene Wolfe
  - 1980-03
  - ''
  - ! '<p>[Chapter 6 of the first book of <em>The Book of the New Sun</em>, and is famous for being an extended homage to Jorge Luis Borges as the blind librarian Ultan who was gifted blindness right as he became librarian, and also has some of the most beautiful writing in the series.]</p><p>…“You are in close contact, then, with your opposite numbers in the city,” I said. The old man stroked his beard. “The closest, for we are they. This library is the city library, and the library of the House Absolute too, for that matter. And many others.” “Do you mean that the rabble of the city is permitted to enter the Citadel to use your library?” “No,” said Ultan. “I mean that the library itself extends beyond the walls of the Citadel. Nor, I think, is it the only institution here that does so. It is thus that the contents of our fortress are so much larger than their container.”</p><p>…His grip on my shoulder tightened. “We have books here bound in the hides of echidnes, krakens, and beasts so long extinct that those whose studies they are, are for the most part of the opinion that no trace of them survives unfossilized. We have books bound wholly in metals of unknown alloy, and books whose bindings are covered with thickset gems. We have books cased in perfumed woods shipped across the inconceivable gulf between creations—books doubly precious because no one on Urth can read them.”</p><p>“We have books whose papers are matted of plants from which spring curious alkaloids, so that the reader, in turning their pages, is taken unaware by bizarre fantasies and chimeric dreams. Books whose pages are not paper at all, but delicate wafers of white jade, ivory, and shell; books too whose leaves are the desiccated leaves of unknown plants. Books we have also that are not books at all to the eye: scrolls and tablets and recordings on a hundred different substances. There is a cube of crystal here—though I can no longer tell you where—no larger than the ball of your thumb that contains more books than the library itself does. Though a harlot might dangle it from one ear for an ornament, there are not volumes enough in the world to counterweight the other. All these I came to know and made safeguarding them my life’s devotion. For seven years I busied myself with that; and then, just when the pressing and superficial problems of preservation were disposed of, and we were on the point of beginning the first general survey of the library since its foundation, my eyes began to gutter in their sockets. He who had given all books into my keeping made me blind so that I should know in whose keeping the keepers stand.”</p><p>…“In every library, by ancient precept, is a room reserved for children. In it are kept bright picture books such as children delight in, and a few simple tales of wonder and adventure. Many children come to these rooms, and so long as they remain within their confines, no interest is taken in them.” He hesitated, and though I could discern no expression on his face, I received the impression that he feared what he was about to say might cause Cyby pain.</p><p>“From time to time, however, a librarian remarks a solitary child, still of tender years, who wanders from the children’s room and at last deserts it entirely. Such a child eventually discovers, on some low but obscure shelf, <em>The Book of Gold</em>. You have never seen this book, and you will never see it, being past the age at which it is met.”</p><p>“It must be very beautiful,” I said."It is indeed. Unless my memory betrays me, the cover is of black buckram,considerably faded at the spine. Several of the signatures are coming out, and certain of the plates have been taken. But it is a remarkably lovely book. I wish that I might find it again, though all books are shut to me now. The child, as I said, in time discovers <em>The Book of Gold</em>. Then the librarians come—like vampires, some say, but others say like the fairy godparents at a christening. They speak to the child, and the child joins them. Henceforth he is in the library wherever he may be, and soon his parents know him no more.</p>'
- - https://storage.googleapis.com/pub-tools-public-publication-data/pdf/cb7b7a938ac6d313a2b5f07612093b5c52093f51.pdf#google
  - "Learning-based Memory Allocation for C++ Server Workloads"
  - Martin Maas, David G. Andersen, Michael Isard, Mohammad Mahdi Javanmard, Kathryn S. McKinley, Colin Raffel
  - 2020-03-16
  - 10.1145/3373376.3378525
  - ! '<p>Modern C++ servers have memory footprints that vary widely over time, causing persistent heap fragmentation of up to 2× from long-lived objects allocated during peak memory usage. This fragmentation is exacerbated by the use of huge (2MB) pages, a requirement for high performance on large heap sizes. Reducing fragmentation automatically is challenging because C++ memory managers cannot move objects.</p><p>This paper presents a new approach to huge page fragmentation. It combines modern machine learning techniques with a novel memory manager (<span class="smallcaps-auto">LLAMA</span>) that manages the heap based on object lifetimes and huge pages (divided into blocks and lines). A neural network-based language model predicts lifetime classes using symbolized calling contexts. The model learns context-sensitive per-allocation site lifetimes from previous runs, generalizes over different binary versions, and extrapolates from samples to unobserved calling contexts. Instead of size classes, <span class="smallcaps-auto">LLAMA</span>’s heap is organized by <em>lifetime</em> classes that are dynamically adjusted based on observed behavior at a block granularity</p><p><span class="smallcaps-auto">LLAMA</span> reduces memory fragmentation by up to 78% while only using huge pages on several production servers. We address ML-specific questions such as tolerating mispredictions and amortizing expensive predictions across application execution. Although our results focus on memory allocation, the questions we identify apply to other system-level problems with strict latency and resource requirements where machine learning could be applied.</p><p>[<span class="smallcaps-auto">CCS</span> Concepts: Computing methodologies→Supervised learning; Software and its engineering→Allocation / deallocation strategies; Keywords: Memory management, Machine Learning, Lifetime Prediction, Profile-guided Optimization, <span class="smallcaps-auto">LSTM</span>s]</p>'
- - https://www.nature.com/articles/s41598-018-37481-y
  - "Association between viral seasonality and meteorological factors"
  - Rory Henry Macgregor Price, Catriona Graham, Sandeep Ramalingam
  - 2019-01-30
  - 10.1038/s41598-018-37481-y
  - ! '<p>Numerous viruses can cause upper respiratory tract infections. They often precede serious lower respiratory tract infections. Each virus has a seasonal pattern, with peaks in activity in different seasons. We examined the effects of daily local meteorological data (temperature, relative humidity, “humidity-range” and dew point) from Edinburgh, Scotland on the seasonal variations in viral transmission. We identified the seasonality of rhinovirus, adenovirus, influenza A and B viruses, human parainfluenza viruses 1–3 (<span class="smallcaps-auto">HPIV</span>), respiratory syncytial virus (<span class="smallcaps-auto">RSV</span>) and human metapneumovirus (<span class="smallcaps-auto">HMPV</span>) from the 52060 respiratory samples tested between 2009 and 2015 and then confirmed the same by a generalised linear model. We also investigated the relationship between meteorological factors and viral seasonality. Non-enveloped viruses were present throughout the year. Following logistic regression adenovirus, influenza viruses A, B, <span class="smallcaps-auto">RSV</span> and <span class="smallcaps-auto">HMPV</span> preferred low temperatures; <span class="smallcaps-auto">RSV</span> and influenza A virus preferred a narrow “humidity-range” and <span class="smallcaps-auto">HPIV</span> type 3 preferred the season with lower humidity. A change (i.e. increase or decrease) in specific meteorological factors is associated with an increase in activity of specific viruses at certain times of the year.</p>'
- - https://www.sciencemag.org/news/2020/03/why-do-dozens-diseases-wax-and-wane-seasons-and-will-covid-19
  - "Why do dozens of diseases wax and wane with the seasons—and will <span class=\"smallcaps-auto\">COVID</span>-19?"
  - Jon Cohen (Science)
  - 2020-03-13
  - 10.1126/science.abb7234
  - ! '<p>…a phenomenon recognized 2500 years ago by Hippocrates and Thucydides: Many infectious diseases are more common during specific seasons. “It’s a very old question, but it’s not very well studied,” Martinez says. It’s also a question that has suddenly become more pressing because of the emergence of <span class="smallcaps-auto">COVID</span>-19. With <span class="smallcaps-auto">SARS</span>-CoV-2, the virus that causes the disease, now infecting more than 135,000 around the globe, some hope it might mimic influenza and abate as summer arrives in temperate regions of the Northern Hemisphere, where about half of the world’s population lives….Different diseases have different patterns. Some peak in early or late winter, others in spring, summer, or fall…At least 68 infectious diseases are seasonal, according to a <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/%5BPMC%5D%7B.smallcaps%7D6224126/" title="The calendar of epidemics: Seasonal cycles of infectious diseases">2018 paper by Micaela Martinez</a> of Columbia University…Some diseases have different seasonal peaks depending on latitude. And many have no seasonal cycle at all. Even for well-known seasonal diseases, it’s not clear why they wax and wane during the calendar year. “It’s an absolute swine of a field,” says Andrew Loudon, a chronobiologist at the University of Manchester. Investigating a hypothesis over several seasons can take 2 or 3 years. “Postdocs can only get one experiment done and it can be a career killer,” Loudon says. The field is also plagued by confounding variables. “All kinds of things are seasonal, like Christmas shopping,” says epidemiologist Scott Dowell, who heads vaccine development and surveillance at the Bill and Melinda Gates Foundation and in 2001 wrote a widely cited perspective that inspired Martinez’s current study. And it’s easy to be misled by spurious correlations, Dowell says.</p><p>Despite the obstacles, researchers are testing a multitude of theories. Many focus on the relationships between the pathogen, the environment, and human behavior. Influenza, for example, might do better in winter because of factors such as humidity, temperature, people being closer together, or changes in diets and vitamin D levels. Martinez is studying another theory, which Dowell’s paper posited but didn’t test: The human immune system may change with the seasons, becoming more resistant or more susceptible to different infections based on how much light our bodies experience.</p><p>…Except in the equatorial regions, respiratory syncytial virus (<span class="smallcaps-auto">RSV</span>) is a winter disease, Martinez wrote, but chickenpox favors the spring. Rotavirus peaks in December or January in the U.S. Southwest, but in April and May in the Northeast. Genital herpes surges all over the country in the spring and summer, whereas tetanus favors midsummer; gonorrhea takes off in the summer and fall, and pertussis has a higher incidence from June through October. Syphilis does well in winter in China, but typhoid fever spikes there in July. Hepatitis C peaks in winter in India but in spring or summer in Egypt, China, and Mexico. Dry seasons are linked to Guinea worm disease and Lassa fever in Nigeria and hepatitis A in Brazil.</p><p>Seasonality is easiest to understand for diseases spread by insects that thrive during rainy seasons, such as African sleeping sickness, chikungunya, dengue, and river blindness. For most other infections, there’s little rhyme or reason to the timing. “What’s really amazing to me is that you can find a virus that peaks in almost every month of the year in the same environment in the same location,” says Neal Nathanson, an emeritus virologist at the University of Pennsylvania Perelman School of Medicine. “That’s really crazy if you think about it.” To Nathanson, this variation suggests human activity—such as children returning to school or people huddling indoors in cold weather—doesn’t drive seasonality. “Most viruses get transmitted between kids, and under those circumstances, you’d expect most of the viruses to be in sync,” he says.</p><p>…A <a href="https://www.nature.com/articles/s41598-018-37481-y" title="&#39;Association between viral seasonality and meteorological factors&#39;, Price et al 2019">2018 study in Scientific Reports</a> supports the idea. Virologist Sandeep Ramalingam at the University of Edinburgh and his colleagues analyzed the presence and seasonality of nine viruses—some enveloped, some not—in more than 36,000 respiratory samples taken over 6.5 years from people who sought medical care in their region. “Enveloped viruses have a very, very definite seasonality,” Ramalingam says.</p><p><span class="smallcaps-auto">RSV</span> and human metapneumovirus both have an envelope, like the flu, and peak during the winter months. None of the three are present for more than one-third of the year. Rhinoviruses, the best-known cause of the common cold, lack an envelope and—ironically—have no particular affinity for cold weather: The study found them in respiratory samples on 84.7% of the days of the year and showed that they peak when children return to school from summer and spring holidays. Adenoviruses, another set of cold viruses, also lack an envelope and had a similar pattern, circulating over half the year. Ramalingam’s team also studied the relationship between viral abundance and daily weather changes. Influenza and <span class="smallcaps-auto">RSV</span> both did best when the change in relative humidity over a 24-hour period was lower than the average (a 25% difference). “There’s something about the lipid envelope that’s more fragile” when the humidity changes sharply, Ramalingam concludes.</p>'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6224126/
  - 'The calendar of epidemics: Seasonal cycles of infectious diseases'
  - Micaela Elvira Martinez
  - 2018-11-08
  - 10.1371/journal.ppat.1007327
  - ! '<p>Seasonal cyclicity is a ubiquitous feature of acute infectious diseases [1] and may be a ubiquitous feature of human infectious diseases in general, as illustrated in Tables 11–4. Each acute infectious disease has its own seasonal window of occurrence, which, importantly, may vary among geographic locations and differ from other diseases within the same location. Here we explore the concept of an epidemic calendar, which is the idea that seasonality is a unifying feature of epidemic-prone diseases and, in the absence of control measures, the local calendar can be marked by epidemics (Fig 1). A well-known example of a calendar marked by epidemics is that of the Northern Hemisphere, where influenza outbreaks occur each winter [2, 3] (hence the colloquial reference to winter as “the flu season”). In contrast, chickenpox outbreaks peak each spring [4, 5], and polio transmission historically occurred each summer [6].</p><p>…In the broadest sense, seasonal drivers can be separated into four categories: (1) environmental factors, (2) host behavior, (3) host phenology, and (4) exogenous biotic factors. These seasonal drivers may enter into disease transmission dynamics by way of hosts, reservoirs, and/or vectors. In surveying the literature to gauge the breadth of seasonal drivers acting upon human infectious disease systems (Tables (Tables11–4), specific seasonal drivers were found to include (a) vector seasonality, (b) seasonality in nonhuman animal host (i.e., livestock, other domestic animals, or wildlife), (c) seasonal climate (e.g., temperature, precipitation, etc.), (d) seasonal nonclimatic abiotic environment (e.g., water salinity), (e) seasonal co-infection, (f) seasonal exposure and/or behavior and/or contact rate, (g) seasonal biotic environment (e.g., algal density in waterbodies), and (h) seasonal flare-ups/symptoms and/or remission/latency.</p>'
- - /docs/sr/2020-ladegaard.pdf
  - 'Open Secrecy: How Police Crackdowns and Creative Problem-Solving Brought Illegal Markets out of the Shadows'
  - Isak Ladegaard
  - 2020-03-16
  - 10.1093/sf/soz140
  - ! '<p>Can organized illegal activities grow stronger and more advanced in response to legal pressure? In October 2013, the <span class="smallcaps-auto">FBI</span> shut down Silk Road, a thriving e-commerce market for illegal drugs. After the shock, market actors adopted a new identity verification method that enabled mass-migration to other markets, and created websites for information distribution that reduced post-shock uncertainties. The outcome was a decentralized market in which actors could operate in “open secrecy” across multiple websites. With verifiable pseudonyms and securely obfuscated real-world identities, actors could publicly discuss, plan, and participate in illegal activities. Threats from police and opportunistic criminals persisted but were no longer crippling concerns as buyers and sellers could reasonably expect that their exchange partners would be available for future business; the illegal market could operate more like a legal one. Drawing on quantitative and qualitative data, the author argues that advances in information technology have expanded the opportunity structure for cooperation and creative problem-solving in the underworld, and therefore that shocks did not hinder but rather stimulate development in digital drug markets. Data, collected in 2013–2017, include nearly one million transactions from three illicit e-commerce markets, three million messages from eight discussion forums, and website traffic from two market-independent websites.</p>'
- - /docs/ai/2012-rintanen.pdf
  - 'Planning as satisfiability: Heuristics'
  - Jussi Rintanen
  - 2012-12
  - 10.1016/j.artint.2012.08.001
  - ! '<p>Reduction to <span class="smallcaps-auto">SAT</span> is a very successful approach to solving hard combinatorial problems in Artificial Intelligence and computer science in general. Most commonly, problem instances reduced to <span class="smallcaps-auto">SAT</span> are solved with a general-purpose <span class="smallcaps-auto">SAT</span> solver. Although there is the obvious possibility of improving the <span class="smallcaps-auto">SAT</span> solving process with application-specific heuristics, this has rarely been done successfully.</p><p>In this work we propose a planning-specific variable selection strategy for <span class="smallcaps-auto">SAT</span> solving. The strategy is based on generic principles about properties of plans, and its performance with standard planning benchmarks often substantially improves on generic variable selection heuristics, such as <span class="smallcaps-auto">VSIDS</span>, and often lifts it to the same level with other search methods such as explicit state-space search with heuristic search algorithms.</p>'
- - https://www.businesswire.com/news/home/20171121005280/en/Amazon-Celebrates-10th-Holiday-Season-Frustration-Free-Packaging
  - "Amazon Celebrates 10<sup>th</sup> Holiday Season of Frustration-Free Packaging&mdash;An Invention That’s Helped Eliminate 181,000 Tons of Packaging and 307 Million Boxes, and Given Millions of Customers Holidays Without 'Wrap Rage'"
  - Amazon
  - 2017-11-21
  - ''
  - ! '<ul><li>Certified Frustration-Free Packaging is easy to open, with no annoying clamshells or twist ties, and 100% recyclable</li><li>Amazon’s Frustration-Free Packaging Programs have grown to include both Frustration-Free Packaging and Ships in Own Container, which produce less waste than traditional packaging—great for customers and the environment</li><li>Amazon works directly with thousands of manufacturers to redesign their packaging, eliminating waste throughout the supply chain while ensuring products arrive undamaged on customers’ doorsteps</li></ul><p>Ten years ago this holiday season, Amazon introduced “Frustration-Free Packaging,” an invention designed to reduce waste and delight customers with easy-to-open, 100% recyclable packaging. Frustration-Free Packaging ends customer “wrap rage” by removing plastic bindings, wire ties, and clamshell casings—making boxes simple to open. And it’s great for the environment because products ship in their original packaging, eliminating the need for an additional shipping box.</p><p>Since launching in November 2008 with 19 items, Amazon’s packaging programs have grown to include both Frustration-Free Packaging and “Ships in Own Container.” In 2017 alone, Amazon has delivered 120 million shipments with packaging that is certified Frustration-Free or Ships in Own Container. To date, Amazon’s sustainable packaging innovations have eliminated 181,000 tons of packaging material and avoided 307 million shipping boxes—enough boxes to fill more than 550,000 semi-trucks.</p>'
- - /docs/philo/2012-shenhav.pdf
  - 'Divine intuition: cognitive style influences belief in God'
  - Amitai Shenhav, David G. Rand, Joshua D. Greene
  - '2012'
  - 10.1037/a0025391
  - ! '<p>Some have argued that belief in God is intuitive, a natural (by-)product of the human mind given its cognitive structure and social context. If this is true, the extent to which one believes in God may be influenced by one’s more general tendency to rely on intuition versus reflection. Three studies support this hypothesis, linking intuitive cognitive style to belief in God. Study 1 showed that individual differences in cognitive style predict belief in God. Participants completed the Cognitive Reflection Test (<span class="smallcaps-auto">CRT</span>; Frederick, 2005), which employs math problems that, although easily solvable, have intuitively compelling incorrect answers. Participants who gave more intuitive answers on the <span class="smallcaps-auto">CRT</span> reported stronger belief in God. This effect was not mediated by education level, income, political orientation, or other demographic variables. Study 2 showed that the correlation between <span class="smallcaps-auto">CRT</span> scores and belief in God also holds when cognitive ability (IQ) and aspects of personality were controlled. Moreover, both studies demonstrated that intuitive <span class="smallcaps-auto">CRT</span> responses predicted the degree to which individuals reported having strengthened their belief in God since childhood, but not their familial religiosity during childhood, suggesting a causal relationship between cognitive style and change in belief over time. Study 3 revealed such a causal relationship over the short term: Experimentally inducing a mindset that favors intuition over reflection increases self-reported belief in God. [Keywords: reasoning, religion, religiosity, reflection, atheism.]</p>'
- - /docs/iq/1991-barrett.pdf
  - 'A reconsideration of testing for competence rather than for intelligence'
  - 'Gerald V. Barrett, Robert L. Depinet'
  - '1993'
  - '10.1037/0003-066X.46.10.1012'
  - ! '<p>David C. McClelland’s 1973 article has deeply influenced both professional and public opinion. In it, he presented 5 major themes: (1) Grades in school did not predict occupational success, (2) intelligence tests and aptitude tests did not predict occupational success or other important life outcomes, (3) tests and academic performance only predicted job performance because of an underlying relationship with social status, (4) such tests were unfair to minorities, and (5) “competencies” would be better able to predict important behaviors than would more traditional tests. Despite the pervasive influence of these assertions, this review of the literature showed only limited support for these claims.</p>'
- - /docs/iq/1994-barrett.pdf
  - 'Empirical data say it all'
  - Gerald V. Barrett
  - 1994-01
  - 10.1037/0003-066X.49.1.69
  - ! '<p>Comments that after considering the responses of R. E. Boyatzis (see record 1994-27864-001) and D. C. McClelland (see record 1994-27871-001) and reviewing additional reports by these authors, the conclusions drawn by G. V. Barrett and R. L. Depinet’s (see record 1992-03797-001) article on competence testing are reinforced. If McClelland’s concept of competencies is to make a contribution to psychology, he must present empirical data to support his contention. Three sets of data are presented to illustrate this point.</p><p>[Barrett points out that according to McClelland’s own analyses, his proposed screening methods barely predict job performance, are usually not even statistically-significant, would violate employment/discrimination law, and that McClelland’s claim that his methods don’t work because of the <a href="/docs/iq/1994-mcclelland.pdf" title="`The Knowledge-Testing-Educational Complex Strikes Back`, McClelland 1994">“knowledge-testing-educational complex”</a> is an excuse.]</p>'
- - /docs/iq/2003-barrett.pdf
  - "New Concepts of Intelligence: Their Practical and Legal Implications for Employee Selection"
  - 'Gerald V. Barrett, Alissa J. Kramen, Sarah B. Lueke'
  - '2003'
  - ''
  - ! '<p>In the 1920s and 1930s basic theories of intellectual ability were developed along with operational tests which proved effective in predicting job performance (Spearman 1927; Thorndike 1936). In a series of studies and meta-analyses throughout the 1970s and 1980s, Schmidt and Hunter showed that cognitive ability was the best overall predictor of job performance (Hunter &amp; Hunter 1984; Hunter 1986; Schmidt &amp; Hunter 1981). Partially in reaction to the meta-analytic findings, research to expand on the definitions of competencies continued. The development of competencies by McClelland (1973) was followed by a discussion of tacit knowledge (Wagner &amp; Sternberg 1985), practical intelligence (Sternberg &amp; Wagner 1986), and multiple intelligence (Gardner 1999). In the 1990s, emotional intelligence became the intelligence of interest (Feist &amp; Barron 1996; Goleman 1995, 1998a, 1998b; Graves 1999; Mayer et al 1990).</p><p>All these new theories and proposed measurement instruments pose a challenge to traditional cognitive ability tests since it is claimed that these tests are more valid and have lower adverse impact. It is our contention that many of these tests are nothing more than pop psychology. It is distressing to see such books (i.e. Goleman 1998b) quoted as if they had some merit. We will review the themes present throughout all of these “creative” concepts and examine whether they have practical implications and can withhold legal scrutiny in the public and private sector.</p>'
- - /docs/iq/1973-mcclelland.pdf
  - "Testing for Competence Rather Than for 'Intelligence'"
  - David C. McClelland
  - 1973-01
  - 10.1037/h0034092
  - ! '<p>Argues that while traditional intelligence tests have been validated almost entirely against school performance, the evidence that they measure abilities which are essential to performing well in various life outcomes is weak. Most of the validity studies are correlational in nature and fail to control for the fact that social class might be a 3<sup>rd</sup> variable accounting for positive correlations between test scores and occupational success, and between level of schooling achieved and occupational success. It is suggested that better measures of competence might be derived by analysis of successful life outcomes and the competencies involved in them, criterion sampling, and assessment of communication skills.</p>'
- - /docs/iq/1980-mcclelland.pdf
  - 'Opportunities for Counselors from the Competency Assessment Movement'
  - 'David C. McClelland, Richard E. Boyatzis'
  - 1980-01
  - 10.1002/j.2164-4918.1980.tb00415.x
  - ! '<p>Innovations in testing emerging from the competency assessment movement offer counselors new capabilities in helping their clients to understand aspects of themselves and their problems, as well as to establish directions for development and improvement efforts. New types of tests and measures sample actual behavior more closely than testing instruments previously used: The characteristics they examine are closely linked to performance in a wide variety of jobs, and therefore provide increased focus of assessment on life outcomes. With this new degree of specificity and criterion referencing, implications for counseling, training, and development efforts emerge more clearly than with other forms of testing.</p>'
- - /docs/iq/1994-mcclelland.pdf
  - 'The knowledge-testing-educational complex strikes back'
  - David C. McClelland
  - '1994'
  - '10.1037/0003-066X.49.1.66'
  - ! '<p>Responds to the criticisms of <a href="/docs/iq/1991-barrett.pdf" title="A reconsideration of testing for competence rather than for intelligence">G. V. Barrett and R. L. Depinet (see record 1992-03797-001)</a> regarding the author’s (1973) article on competence testing. D. C. McClelland agrees with Barrett and Depinet’s dismissal of competency testing as a poor alternative to ability testing. McClelland holds that well-designed competency-based tests could make an important contribution to selecting people who are better suited for certain jobs, but that these tests will not be developed until there is a strong commitment by psychologists to develop them and the necessary financial support is available.</p>'
- - /docs/iq/1964-mcnemar.pdf
  - 'Lost: Our Intelligence? Why?'
  - Quinn McNemar
  - 1964-09-05
  - 10.1037/h0042008
  - ! '<p>The “concept of general intelligence, despite being maligned by a few, regarded as a 2<sup>nd</sup>-order function by some, and discarded or ignored by others, still has a rightful place in the science of psychology and in the practical affairs of man.” “It is far from clear that tests of general intelligence have been outmoded by the multi-test batteries as the more useful predictors of school achievement.” In fact some evidence suggests that “better predictions are possible via old-fashioned general intelligence tests.” Discussion focuses on reasons for discarding the idea of general intelligence, factor theories of intelligence, and recent trends in the assessment of “general intelligence.” “By the criterion of social usefulness, the multiple aptitude batteries have been found wanting.” It is “time for the profession to establish a bureau of standards to test the tests.”</p>'
- - https://www.goodreads.com/review/show/3057694930
  - "Review of <em>Private Wealth in Renaissance Florence</em>, Goldthwaite 1968"
  - Gwern Branwen
  - 2019-12-02
  - ''
  - ! 'Slightly interesting book analyzing the surviving ledger books of several Florentine Renaissance merchant families. Probably not of general interest, but the detailed analysis shows how merchants spent and invested, and what their priorities were, such as buying up land for clan prestige rather than maximizing returns or wealth.'
- - /docs/economics/2003-ruhm.pdf
  - Good times make you sick
  - Christopher J. Ruhm
  - 2003-07
  - '10.1016/S0167-6296(03)00041-9'
  - ! '<p>This study uses microdata from the 1972–1981 National Health Interview Surveys (<span class="smallcaps-auto">NHIS</span>) to examine how health status and medical care utilization fluctuate with state macroeconomic conditions. Personal characteristics, location fixed-effects, general time effects and (usually) state-specific time trends are controlled for. The major finding is that there is a counter-cyclical variation in physical health that is especially pronounced for individuals of prime-working age, employed persons, and males. The negative health effects of economic expansions persist or accumulate over time, are larger for acute than chronic ailments, and occur despite a protective effect of income and a possible increase in the use of medical care. Finally, there is some suggestion that mental health may be procyclical, in sharp contrast to physical well-being. [Keywords: Health status, Morbidity, Macroeconomic conditions.]</p>'
- - /docs/iq/2020-grasby.pdf
  - The genetic architecture of the human cerebral cortex
  - 'Katrina L. Grasby, Neda Jahanshad, Jodie N. Painter, Lucía Colodro-Conde, Janita Bralten, Derrek P. Hibar, Penelope A. Lind, Fabrizio Pizzagalli, Christopher R. K. Ching, Mary Agnes B. McMahon, Natalia Shatokhina, Leo C. P. Zsembik, Sophia I. Thomopoulos, Alyssa H. Zhu, Lachlan T. Strike, Ingrid Agartz, Saud Alhusaini, Marcio A. A. Almeida, Dag Alnæs, Inge K. Amlien, Micael Andersson, Tyler Ard, Nicola J. Armstrong, Allison Ashley-Koch, Joshua R. Atkins, Manon Bernard, Rachel M. Brouwer, Elizabeth E. L. Buimer, Robin Bülow, Christian Bürger, Dara M. Cannon, Mallar Chakravarty, Qiang Chen, Joshua W. Cheung, Baptiste Couvy-Duchesne, Anders M. Dale, Shareefa Dalvie, Tânia K. de Araujo, Greig I. de Zubicaray, Sonja M. C. de Zwarte, Anouk den Braber, Nhat Trung Doan, Katharina Dohm, Stefan Ehrlich, Hannah-Ruth Engelbrecht, Susanne Erk, Chun Chieh Fan, Iryna O. Fedko, Sonya F. Foley, Judith M. Ford, Masaki Fukunaga, Melanie E. Garrett, Tian Ge, Sudheer Giddaluru, Aaron L. Goldman, Melissa J. Green, Nynke A. Groenewold, Dominik Grotegerd, Tiril P. Gurholt, Boris A. Gutman, Narelle K. Hansell, Mathew A. Harris, Marc B. Harrison, Courtney C. Haswell, Michael Hauser, Stefan Herms, Dirk J. Heslenfeld, New Fei Ho, David Hoehn, Per Hoffmann, Laurena Holleran, Martine Hoogman, Jouke-Jan Hottenga, Masashi Ikeda, Deborah Janowitz, Iris E. Jansen, Tianye Jia, Christiane Jockwitz, Ryota Kanai, Sherif Karama, Dalia Kasperaviciute, Tobias Kaufmann, Sinead Kelly, Masataka Kikuchi, Marieke Klein, Michael Knapp, Annchen R. Knodt, Bernd Krämer, Max Lam, Thomas M. Lancaster, Phil H. Lee, Tristram A. Lett, Lindsay B. Lewis, Iscia Lopes-Cendes, Michelle Luciano, Fabio Macciardi, Andre F. Marquand, Samuel R. Mathias, Tracy R. Melzer, Yuri Milaneschi, Nazanin Mirza-Schreiber, Jose C. V. Moreira, Thomas W. Mühleisen, Bertram Müller-Myhsok, Pablo Najt, Soichiro Nakahara, Kwangsik Nho, Loes M. Olde Loohuis, Dimitri Papadopoulos Orfanos, John F. Pearson, Toni L. Pitcher, Benno Pütz, Yann Quidé, Anjanibhargavi Ragothaman, Faisal M. Rashid, William R. Reay, Ronny Redlich, Céline S. Reinbold, Jonathan Repple, Geneviève Richard, Brandalyn C. Riedel, Shannon L. Risacher, Cristiane S. Rocha, Nina Roth Mota, Lauren Salminen, Arvin Saremi, Andrew J. Saykin, Fenja Schlag, Lianne Schmaal, Peter R. Schofield, Rodrigo Secolin, Chin Yang Shapland, Li Shen, Jean Shin, Elena Shumskaya, Ida E. Sønderby, Emma Sprooten, Katherine E. Tansey, Alexander Teumer, Anbupalam Thalamuthu, Diana Tordesillas-Gutiérrez, Jessica A. Turner, Anne Uhlmann, Costanza Ludovica Vallerga, Dennis van der Meer, Marjolein M. J. van Donkelaar, Liza van Eijk, Theo G. M. van Erp, Neeltje E. M. van Haren, Daan van Rooij, Marie-José van Tol, Jan H. Veldink, Ellen Verhoef, Esther Walton, Mingyuan Wang, Yunpeng Wang, Joanna M. Wardlaw, Wei Wen, Lars T. Westlye, Christopher D. Whelan, Stephanie H. Witt, Katharina Wittfeld, Christiane Wolf, Thomas Wolfers, Jing Qin Wu, Clarissa L. Yasuda, Dario Zaremba, Zuo Zhang, Marcel P. Zwiers, Eric Artiges, Amelia A. Assareh, Rosa Ayesa-Arriola, Aysenil Belger, Christine L. Brandt, Gregory G. Brown, Sven Cichon, Joanne E. Curran, Gareth E. Davies, Franziska Degenhardt, Michelle F. Dennis, Bruno Dietsche, Srdjan Djurovic, Colin P. Doherty, Ryan Espiritu, Daniel Garijo, Yolanda Gil, Penny A. Gowland, Robert C. Green, Alexander N. Häusler, Walter Heindel, Beng-Choon Ho, Wolfgang U. Hoffmann, Florian Holsboer, Georg Homuth, Norbert Hosten, Clifford R. Jack Jr., MiHyun Jang, Andreas Jansen, Nathan A. Kimbrel, Knut Kolskår, Sanne Koops, Axel Krug, Kelvin O. Lim, Jurjen J. Luykx, Daniel H. Mathalon, Karen A. Mather, Venkata S. Mattay, Sarah Matthews, Jaqueline Mayoral Van Son, Sarah C. McEwen, Ingrid Melle, Derek W. Morris, Bryon A. Mueller, Matthias Nauck, Jan E. Nordvik, Markus M. Nöthen, Daniel S. O’Leary, Nils Opel, Marie-Laure Paillère Martinot, G. Bruce Pike, Adrian Preda, Erin B. Quinlan, Paul E. Rasser, Varun Ratnakar, Simone Reppermund, Vidar M. Steen, Paul A. Tooney, Fábio R. Torres, Dick J. Veltman, James T. Voyvodic, Robert Whelan, Tonya White, Hidenaga Yamamori, Hieab H. H. Adams, Joshua C. Bis, Stephanie Debette, Charles Decarli, Myriam Fornage, Vilmundur Gudnason, Edith Hofer, M. Arfan Ikram, Lenore Launer, W. T. Longstreth, Oscar L. Lopez, Bernard Mazoyer, Thomas H. Mosley, Gennady V. Roshchupkin, Claudia L. Satizabal, Reinhold Schmidt, Sudha Seshadri, Qiong Yang, Alzheimer’s Disease Neuroimaging Initiative, <span class=\"smallcaps-auto\">CHARGE</span> Consortium, <span class=\"smallcaps-auto\">EPIGEN</span> Consortium, <span class=\"smallcaps-auto\">IMAGEN</span> Consortium, <span class=\"smallcaps-auto\">SYS</span> Consortium, Parkinson’s Progression Markers Initiative, Marina K. M. Alvim, David Ames, Tim J. Anderson, Ole A. Andreassen, Alejandro Arias-Vasquez, Mark E. Bastin, Bernhard T. Baune, Jean C. Beckham, John Blangero, Dorret I. Boomsma, Henry Brodaty, Han G. Brunner, Randy L. Buckner, Jan K. Buitelaar, Juan R. Bustillo, Wiepke Cahn, Murray J. Cairns, Vince Calhoun, Vaughan J. Carr, Xavier Caseras, Svenja Caspers, Gianpiero L. Cavalleri, Fernando Cendes, Aiden Corvin, Benedicto Crespo-Facorro, John C. Dalrymple-Alford, Udo Dannlowski, Eco J. C. de Geus, Ian J. Deary, Norman Delanty, Chantal Depondt, Sylvane Desrivières, Gary Donohoe, Thomas Espeseth, Guillén Fernández, Simon E. Fisher, Herta Flor, Andreas J. Forstner, Clyde Francks, Barbara Franke, David C. Glahn, Randy L. Gollub, Hans J. Grabe, Oliver Gruber, Asta K. Håberg, Ahmad R. Hariri, Catharina A. Hartman, Ryota Hashimoto, Andreas Heinz, Frans A. Henskens, Manon H. J. Hillegers, Pieter J. Hoekstra, Avram J. Holmes, L. Elliot Hong, William D. Hopkins, Hilleke E. Hulshoff Pol, Terry L. Jernigan, Erik G. Jönsson, René S. Kahn, Martin A. Kennedy, Tilo T. J. Kircher, Peter Kochunov, John B. J. Kwok, Stephanie Le Hellard, Carmel M. Loughland, Nicholas G. Martin, Jean-Luc Martinot, Colm McDonald, Katie L. McMahon, Andreas Meyer-Lindenberg, Patricia T. Michie, Rajendra A. Morey, Bryan Mowry, Lars Nyberg, Jaap Oosterlaan, Roel A. Ophoff, Christos Pantelis, Tomas Paus, Zdenka Pausova, Brenda W. J. H. Penninx, Tinca J. C. Polderman, Danielle Posthuma, Marcella Rietschel, Joshua L. Roffman, Laura M. Rowland, Perminder S. Sachdev, Philipp G. Sämann, Ulrich Schall, Gunter Schumann, Rodney J. Scott, Kang Sim, Sanjay M. Sisodiya, Jordan W. Smoller, Iris E. Sommer, Beate St Pourcain, Dan J. Stein, Arthur W. Toga, Julian N. Trollor, Nic J. A. Van der Wee, Dennis van ’t Ent, Henry Völzke, Henrik Walter, Bernd Weber, Daniel R. Weinberger, Margaret J. Wright, Juan Zhou, Jason L. Stein, Paul M. Thompson, Sarah E. Medland, Enhancing NeuroImaging Genetics through Meta-Analysis Consortium (<span class=\"smallcaps-auto\">ENIGMA</span>)—Genetics working group'
  - 2020-03-20
  - 10.1126/science.aay6690
  - ! '<p>The human cerebral cortex is important for cognition, and it is of interest to see how genetic variants affect its structure. Grasby et al. combined genetic data with brain magnetic resonance imaging from more than 50,000 people to generate a genome-wide analysis of how human genetic variation influences human cortical surface area and thickness. From this analysis, they identified variants associated with cortical structure, some of which affect signaling and gene expression. They observed overlap between genetic loci affecting cortical structure, brain development, and neuropsychiatric disease, and the correlation between these phenotypes is of interest for further study.</p><p><em>Introduction</em>: The cerebral cortex underlies our complex cognitive capabilities. Variations in human cortical surface area and thickness are associated with neurological, psychological, and behavioral traits and can be measured in vivo by magnetic resonance imaging (<span class="smallcaps-auto">MRI</span>). Studies in model organisms have identified genes that influence cortical structure, but little is known about common genetic variants that affect human cortical structure.</p><p><em>Rationale</em>: To identify genetic variants associated with human cortical structure at both global and regional levels, we conducted a genome-wide association meta-analysis of brain <span class="smallcaps-auto">MRI</span> data from 51,665 individuals across 60 cohorts. We analyzed the surface area and average thickness of the whole cortex and 34 cortical regions with known functional specializations.</p><p><em>Results</em>: We identified 306 nominally genome-wide significant loci (<em>p</em> &lt; 5 × 10<sup>−8</sup>) associated with cortical structure in a discovery sample of 33,992 participants of European ancestry. Of the 299 loci for which replication data were available, 241 loci influencing surface area and 14 influencing thickness remained significant after replication, with 199 loci passing multiple testing correction (<em>p</em> &lt; 8.3 × 10<sup>−10</sup>; 187 influencing surface area and 12 influencing thickness).</p><p>Common genetic variants explained 34% (SE = 3%) of the variation in total surface area and 26% (SE = 2%) in average thickness; surface area and thickness showed a negative genetic correlation (<em>r<sub>g</sub></em> = −0.32, SE = 0.05, <em>p</em> = 6.5 × 10<sup>−12</sup>), which suggests that genetic influences have opposing effects on surface area and thickness. Bioinformatic analyses showed that total surface area is influenced by genetic variants that alter gene regulatory activity in neural progenitor cells during fetal development. By contrast, average thickness is influenced by active regulatory elements in adult brain samples, which may reflect processes that occur after mid-fetal development, such as myelination, branching, or pruning. When considered together, these results support the radial unit hypothesis that different developmental mechanisms promote surface area expansion and increases in thickness.</p><p>To identify specific genetic influences on individual cortical regions, we controlled for global measures (total surface area or average thickness) in the regional analyses. After multiple testing correction, we identified 175 loci that influence regional surface area and 10 that influence regional thickness. Loci that affect regional surface area cluster near genes involved in the Wnt signaling pathway, which is known to influence areal identity.</p><p>We observed significant positive genetic correlations and evidence of bidirectional causation of total surface area with both general cognitive functioning and educational attainment. We found additional positive genetic correlations between total surface area and Parkinson’s disease but did not find evidence of causation. Negative genetic correlations were evident between total surface area and insomnia, attention deficit hyperactivity disorder, depressive symptoms, major depressive disorder, and neuroticism.</p><p><em>Conclusion</em>: This large-scale collaborative work enhances our understanding of the genetic architecture of the human cerebral cortex and its regional patterning. The highly polygenic architecture of the cortex suggests that distinct genes are involved in the development of specific cortical areas. Moreover, we find evidence that brain structure is a key phenotype along the causal pathway that leads from genetic variation to differences in general cognitive function.</p>'
- - /docs/statistics/bayes/2004-knill.pdf
  - 'The Bayesian brain: the role of uncertainty in neural coding and computation'
  - David C. Knill, Alexandre Pouget
  - 2004-12
  - 10.1016/j.tins.2004.10.007
  - ! '<p>To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are ‘Bayes’ optimal’. This leads to the ‘Bayesian coding hypothesis’: that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.</p>'
- - /docs/genetics/heritable/2008-eaves-2.pdf
  - 'Transmission of Attitudes Toward Abortion and Gay Rights: Effects of Genes, Social Learning and Mate Selection'
  - Lindon J. Eaves, Peter K. Hatemi
  - 2008-03-29
  - 10.1007/s10519-008-9205-4
  - ! '<p>The biological and social transmission of attitudes toward abortion and gay rights are analyzed in a large sample of adult twins, siblings, and their parents. We present a linear model for family resemblance allowing for both genetic and cultural transmission of attitudes from parents to offspring, as well as phenotypic assortative mating (the tendency to marry like) and other environmental sources of twin and sibling resemblance that do not depend on the attitudes of their parents. The model gives a close fit to the patterns of similarity between relatives for the two items. Results are consistent with a substantial role of genetic liability in the transmission of both attitudes. Contrary to the dominant paradigm of the social and political sciences, the kinship data are consistent with a relatively minor non-genetic impact of parental attitudes on the development of adult attitudes in their children. By contrast, the choice of mate is a social action that has a marked impact on the polarization of social attitudes and on the long-term influence that parents exert upon the next generation. [Keywords: Abortion, Gay rights, Assortative mating, Political and social attitudes]</p>'
- - https://www.nature.com/articles/d41586-019-00210-0
  - "How the next recession could save lives: Death rates have dropped during past economic downturns, even as many health trends have worsened. Researchers are scrambling to decipher lessons before the next big recession"
  - Lynne Peeples (Nature)
  - 2019-01-23
  - 10.1038/d41586-019-00210-0
  - ! '<p>In 1922, a pair of sociologists at New York’s Columbia University were poring over 50 years of US economic and mortality data, when they noticed a surprising result. Lean times in the country’s history didn’t correspond with more deaths, as they expected. In fact, the opposite was true. More people—babies included—died when the economy prospered<sup>1</sup>…About a decade later, data from the Great Depression, which hobbled the US economy for much of the 1930s, pointed to a similar conclusion<sup>2</sup>. “After several years of severe economic stress, the gross death rate has attained the lowest level on record,” wrote Edgar Sydenstricker, a social epidemiologist with the US Public Health Service, in 1933. Even numbers from the global financial crisis of the late 2000s follow suit. José Tapia Granados, a health economist at Drexel University in Philadelphia, Pennsylvania, has calculated that death rates in Europe dropped faster during this downturn, known as the Great Recession, than before the crisis hit<sup>3</sup>. The trend held even in his birth country of Spain4, where unemployment topped 20%…Christopher Ruhm has spent the past two decades investigating the links between downturns and health. When he started his research, he wasn’t aware of the early-twentieth-century literature. That work had been generally forgotten, he says, because it “didn’t fit the obvious narrative”. He began by plugging data from more than a century of US history into a complex statistical model. Then, like his pre-Depression counterparts, he thought he had made an error. “So, I started looking at the raw data,” says Ruhm, an economist at the University of Virginia in Charlottesville. “But it wasn’t some programming mistake; it was real.” In fact, he and others replicated the finding—in different situations, in different time periods, in different countries. In every case, Ruhm notes, the health of a majority of people improved, while the health of a minority declined.</p><p>…People also tend to drive less, which translates to fewer traffic accidents6. And fewer vehicles on the road might also help to explain why air quality is better<sup>7</sup>. “When employment pops up, so do things related to pollution—commerce, industry, trucks on the road,” says Mary Davis, an environmental-policy specialist at Tufts University in Medford, Massachusetts. The air-quality connection might also help explain why studies have also linked recessions to reduced cardiovascular and respiratory problems, as well as infant mortality…Researchers have suggested other explanations. In addition to dirty air, cardiovascular issues are known to be exacerbated by stress, a poor diet, lack of exercise, drinking alcohol and smoking tobacco. Working less and having less money to spend could translate into more sleep, exercise and home-cooked meals, as well as less job-related stress and less money for pints of beer and cigarettes. There is some evidence that this logic plays out. Based on data from 1987 through to 2000, Ruhm found that smoking and excess weight declined during economic downturns, whereas leisure-time physical activity increased<sup>8</sup>. When Iceland’s economy crashed in 2008, and the price of imported goods such as tobacco and alcohol rose, citizens consumed fewer of those products<sup>9</sup>. And US data from 1977 to 2008 showed that a husband’s unemployment reduced how much alcohol his wife drank, on average, irrespective of her own employment status<sup>10</sup>. Even people who fear job loss, but remain fully employed, Catalano’s research suggests, might still cut back on alcohol to seem a more indispensable employee<sup>11</sup>.</p><p>…And yet, no one is quite ready to toast economic crises as a boon to public health. “If that were really true, then why don’t we just recommend recessions?” says Ralph Catalano, a public-health researcher at the University of California, Berkeley. He and other scholars point to data showing clear negative consequences for individuals facing financial hardships, from stress-induced chronic diseases to mental-health problems…The meeting had brought them together to share initial outlines for their chapters. But a divide soon appeared. As fellow participants proposed disparate takes on how a failing economy helps or harms health, some people grew “red and heated”, Burgard recalls.</p><p>…Such insights might also hint at ways to improve health in economic boom times, by reducing dangers associated with over-consumption, traffic accidents or pollution. The ultimate goal, notes Stuckler, is to identify and prevent avoidable suffering.</p>'
- - https://www.wired.com/story/teddy-roosevelt-on-a-moose-fake-news-or-fake-fake-news/
  - "Teddy Roosevelt on a Moose: Fake News, or Fake Fake News? An old photo of a U.S. president on mooseback is often used to illustrate the deep roots of media deception. The real story may not back that up."
  - Rose Eveleth (Wired)
  - 2020-03-24
  - ''
  - ! '<p>President Theodore Roosevelt was larger than life, in many ways. He explored the Amazon. He delivered a campaign speech after being shot…And on at least one occasion, Roosevelt rode in a saddle on a moose. There’s even a photo of that last thing: Teddy in his iconic white safari hat, perched atop an antlered beast as it fords a body of water flanked by evergreens.</p><p>…The problem is that this particular ride never happened. The image is doctored—a photograph of the president that was cut and glued atop a picture of a moose. Up close, the famous photo is easy to identify as a sham: The seams around his legs and hands are messy and indicate foul play. (Anybody who knows much about moose wouldn’t need to make a close inspection. The wild creatures are not exactly friendly, and they certainly don’t appreciate being ridden.) Yet the image, ripe with the juicy mythology of a president who could sometimes seem as though he’d ridden out of a tall tale, has been shared far and wide, and treated as the real deal. Today, you can find it printed onto mugs, posters and even cheeky t-shirts.</p><p>…Then it occurred to me how little I really knew about the picture’s origin. It was clearly fake, that much was obvious. But who had done the faking, and for what reason? And was its awkward cut-and-pasting really meant to be deceptive? Had Teddy put it out himself to show how badass he was? Or had a rival put it out to try and catch him in a lie? What exactly, are we debunking here?</p><p>…Here’s what I can say conclusively: The image was created in 1912 by a photography firm called Underwood and Underwood, as part of a political triptych showing each of that year’s presidential candidates cut-and-pasted atop the animal that represented his political party. On the left, William Howard Taft sits on an elephant; and on the right, Woodrow Wilson on a donkey. In the middle, Roosevelt “rides” his trusty moose, there to signify his Bull Moose party. Somewhere along the way, between 1912 and now, the photograph of Teddy and the moose escaped the confines of its context and found a new life as a standalone image. By 2011, it was popping up in posts like Cracked’s “18 Old-Timey Photos You Won’t Believe Aren’t Photoshopped,” which claimed: “This picture is real, this scene existed, and yes, at one point in our history, you could have actually voted for this man.” Posts like this were then debunked in turn by other blog posts, like Gizmodo’s “That Famous Photo of Teddy Roosevelt Riding a Moose is Fake.” Round and round we go again.</p><p>…In fact, the photograph, and references to it, quickly vanished after September 1912. The triptych does not seem to be reprinted after its first publication, and the photograph of Roosevelt doesn’t appear again in any newspaper archive that I could access. In other words, Teddy and his moose seem to have entered a long period of dormancy, like a hundred-year presidential cicada…One clue as to how and when Teddy and his moose might have slipped the triptych lies in the photo credit provided for it in recent times. When websites bother to source the image (which they rarely do), they usually give some variation of the following: “<span class="smallcaps-auto">UNSPECIFIED</span>—1900: Theodore Roosevelt riding a moose. (Photo by Underwood And Underwood/Underwood And Underwood/The <span class="smallcaps-auto">LIFE</span> Picture Collection via Getty Images).” Of course, we know that the photo is from 1912, not 1900; but the rest of this gives us another avenue of inquiry…Here’s what probably happened: <span class="smallcaps-auto">LIFE</span> at some point acquired a collection of photographs from Underwood and Underwood for potential use. These were slowly digitized in the early 2000s. As the <span class="smallcaps-auto">LIFE</span> collection began making its photographic archives easier to browse online, people discovered the image and delighted in it anew. The rest, as they say, is history.</p>'
- - /docs/genetics/heritable/2012-lee.pdf
  - Correlation and Causation in the Study of Personality
  - James Jung-Hun Lee
  - 2012-07-26
  - 10.1002/per.1863
  - ! '<p>Personality psychology aims to explain the causes and the consequences of variation in behavioural traits. Because of the observational nature of the pertinent data, this endeavour has provoked many controversies. In recent years, the computer scientist Judea Pearl has used a graphical approach to extend the innovations in causal inference developed by Ronald Fisher and Sewall Wright. Besides shedding much light on the philosophical notion of causality itself, this graphical framework now contains many powerful concepts of relevance to the controversies just mentioned. In this article, some of these concepts are applied to areas of personality research where questions of causation arise, including the analysis of observational data and the genetic sources of individual differences.</p>'
- - /docs/psychology/1989-crawford.pdf
  - 'Human grief: Is its intensity related to the reproductive value of the deceased?'
  - Charles B. Crawford, Brenda E. Salter, Kerry L. Jang
  - 1989-04
  - '10.1016/0162-3095(89)90006-X'
  - ! '<p>Thurstone’s method of comparative judgement was used to measured the intensity of grief that parents of high-, moderate-, and low-reproductive value were expected to experience at the death of male and female children of different ages. The results were correlated with reproductive values for male and female British Columbians and for !Kung Bushwomen. Grief ratings were more highly correlated with reproductive value than with age and more highly correlated with reproductive values of !Kung Bushwomen than with those of British Columbians. The correlations were higher for male- than for female-stimulus children. The correlations of female ratings with reproductive value were higher than male ratings with reproductive value, although not as high as expected. However, the correlation between grief ratings and reproductive value did not increase as the reproductive value of the raters declined.</p>'
- - /docs/traffic/2014-goldstein.pdf
  - The Economic and Cognitive Costs of Annoying Display Advertisements
  - Daniel G. Goldstein, Siddharth Suri, R. Preston McAfee, Matthew Ekstrand-Abueg, Fernando Díaz
  - '2014'
  - 10.1509/jmr.13.0439
  - ! '<p>Some online display advertisements are annoying. Although publishers know the payment they receive to run annoying ads, little is known about the cost that such ads incur (e.g., causing website abandonment). Across three empirical studies, the authors address two primary questions: (1) What is the economic cost of annoying ads to publishers? and (2) What is the cognitive impact of annoying ads to users? First, the authors conduct a preliminary study to identify sets of more and less annoying ads. Second, in a field experiment, they calculate the compensating differential, that is, the amount of money a publisher would need to pay users to generate the same number of impressions in the presence of annoying ads as it would generate in their absence. Third, the authors conduct a mouse-tracking study to investigate how annoying ads affect reading processes. They conclude that in plausible scenarios, the practice of running annoying ads can cost more money than it earns.</p>'
- - /docs/iq/1989-carroll.pdf
  - 'The Carroll Model: A 25-Year Retrospective and Prospective View'
  - John B. Carroll
  - 1989-01-01
  - 10.3102/0013189X018001026
  - ! '<p>The Model of School Learning, first published 25 years ago, has taken its place as a useful guide in research on teaching and learning in schools. The model accounts for variations in school learning with five classes of variables, three, of which can be expressed in terms of time, the other two in terms of achievement. Most aspects of the model have been confirmed, although details remain to be filled out by further research. Ways that the model might be used to address current problems in education are considered. The model’s emphasis on aptitude as a determinant of time needed for learning suggests that increased efforts be placed on predicting student potentialities and designing instruction appropriate to those potentialities, if ideals of equal opportunity to learn are to be achieved within a diversity of educational objectives.</p>'
- - /docs/iq/1979-cox.pdf
  - 'Mastery learning: A psychological trap?'
  - William F. Cox Jr, Thomas G. Dunn
  - '1979'
  - 10.1080/00461527909529204
  - ! '<p>In spite of all its announced advantages, the implementation of mastery learning instruction often falls short of theoretical expectations. As discussed under the four major characteristics of mastery learning [systematic design of instruction/instructional correctives/ample time to learn/clear criterion of mastery], these implementation weaknesses pose serious problems for unsuspecting students, teachers, and instructional designers alike.</p>'
- - /docs/iq/2006-jones.pdf
  - 'Intelligence, Human Capital, and Economic Growth: A Bayesian Averaging of Classical Estimates (BACE) Approach'
  - Garett Jones, William Joel Schneider
  - '2006'
  - 10.1007/s10887-006-7407-2
  - ! '<p>Human capital plays an important role in the theory of economic growth, but it has been difficult to measure this abstract concept. We survey the psychological literature on cross-cultural IQ tests and conclude that intelligence tests provide one useful measure of human capital. Using a new database of national average IQ, we show that in growth regressions that include only robust control variables, IQ is statistically significant in 99.8% of these 1330 regressions, easily passing a Bayesian model-averaging robustness test. A 1 point increase in a nation’s average IQ is associated with a persistent 0.11% annual increase in <span class="smallcaps-auto">GDP</span> per capita.</p>'
- - https://www.wired.com/story/open-source-fonts-love-letters-design-community/
  - "Open Source Fonts Are Love Letters to the Design Community: Typefaces that be freely used and modified give others a chance to hone their craft—and share valuable feedback"
  - Klint Finley (Wired)
  - 2020-03-28
  - ''
  - ! '<p>Even if designers don’t contribute improvements to a font directly, companies can benefit from making their work open source. For example, Adobe Type senior manager Dan Rhatigan says releasing its Source super-family of fonts as open source has enabled the company to test new typography technologies like “variable fonts,” which make it easy for a designer to adjust the weight of a typeface, before rolling those technologies into other products.</p><p>In other cases, open source fonts help support other aspects of a company’s business. For example, Google Fonts program manager Dave Crossland says many of the fonts Google has funded most recently are designed for under-supported languages in developing countries. These efforts buttress Google’s “Next Billion Users” initiative, which aims to bring more people in developing countries online. Better support for more languages means more users, and ultimately, more money for Google.</p><p>The incentives to create open source fonts weren’t always obvious. In early 2009, a graphic designer and programmer named Micah Rich came across a forum post by a student who was interested in knowing more about how fonts worked. The student asked whether there was a professional quality open source font that they could learn from. The replies weren’t kind. “There were like 20 pages of professional type designers saying ‘This is our livelihood, how dare you ask us to work for free?’” Rich says.</p>'
- - /docs/traffic/2020-michelon.pdf
  - 'A New Benchmark for Mechanical Avoidance of Radio Advertising'
  - Aaron Michelon, Steven Bellman, Margaret Faulkner, Justin Cohen, Johan Bruwer
  - 2020-03-23
  - 10.2501/JAR-2020-007
  - ! '<p>Radio remains popular, delivering an audience reach of over 90 percent, but radio ratings may overestimate real advertising exposure. Little is known about audience and media factors affecting radio-advertising avoidance. Many advertisers have believed as much as one-third of the audience switch stations during radio-advertising breaks. In the current study, the authors combined Canadian portable people-meter data ratings to measure loss of audience during advertising. They discovered a new benchmark of 3% (across conditions) for mechanical (or actual physical) avoidance of radio advertising, such as switching stations or turning off the radio. This rate is about one-tenth of current estimates, but was higher for music versus talk stations, out-of-home versus in-home listening, and early versus late dayparts.</p>'
- - /docs/traffic/2010-dix.pdf
  - 'Television Advertising Avoidance: Advancing Research Methodology'
  - Steve Dix, Ian Phau
  - 2010-03-12
  - 10.1080/10496490903574013
  - ! '<p>New technologies have led to increased television advertising avoidance. In particular, mechanical avoidance in the form of zipping and zapping has gained momentum in recent years. Channel switching or “commercial zapping” studies employ diverse methodologies, including self reports, electronic monitoring, laboratory, and in-home observation which has led to a diversity of reported results. This article proposes advancing and standardizing the methodology to comprise a two-phase hidden observation and survey method. A number of research phases have led to the development of this method to collect both mechanical and behavioral avoidance data. The study includes a detailed outline of the hidden observation approach. The survey phase opens up the potential for the collection of viewer data that may further illuminate television advertising avoidance behavior. [Keywords: advertising, commercials, consumer behavior, television, zapping, zipping]</p>'
- - https://www.nytimes.com/2015/11/18/technology/microsoft-once-infested-with-security-flaws-does-an-about-face.html
  - "Microsoft Sheds Reputation as an Easy Mark for Hackers"
  - Nick Wingfield (<span class=\"smallcaps-auto\">NYT</span>)
  - 2015-11-18
  - ''
  - ! '<p>Microsoft was once the epitome of everything wrong with security in technology. Its products were so infested with vulnerabilities that the company’s co-founder, Bill Gates, once ordered all of Microsoft engineers to stop writing new code for a month and focus on fixing the bugs in software they had already built.</p><p>But in recent years, Microsoft has cleaned up its act, even impressing security specialists like Mikko Hypponen, the chief research officer for F-Secure, a Finnish security company, who used to cringe at Microsoft’s practices. “They’ve changed themselves from worst in class to the best in class,” Mr. Hypponen said. “The change is complete. They started taking security very seriously.”</p><p>…Microsoft estimates that it now spends more than $1 billion a year on security-related initiatives, including acquisitions. It acquired three security start-ups in the last year alone, and the number of security employees at the company increased 20% during that time. Soon after he became Microsoft’s chief executive in February 2014, Mr. Nadella instituted a monthly meeting with security leaders from across the company. They meet to discuss industry trends and analyze threats. He also altered how Microsoft watched the Internet for hacker attacks, an effort that had been splintered among different product groups and other divisions within the company. Microsoft now pays hackers more when they find and turn over a security hole.</p><p>…Plenty of bugs are still being discovered in Microsoft’s code. But fears about the security of Microsoft’s programs have gradually abated. In a couple of recent widespread attacks, hackers exploited weaknesses in Adobe and the Java programming platform, not Microsoft software.</p><p>Once an attempt on one customer is detected—say, a phishing scheme, in which hackers try to steal passwords, credit card numbers and other private data through legitimate-looking emails—Microsoft says it can quickly deploy a solution that prevents all other customers on its corporate email services from falling prey to the ruse. Microsoft carried out one such fix to its cloud customers early last year after the Syrian Electronic Army, a group of hackers who support President Bashar al-Assad of Syria, began a phishing attack on Microsoft’s own employees.</p><p>…There is no doubt, though, that Microsoft has made thwarting hackers a priority. Microsoft’s latest version of its operating system, Windows 10, has a feature called Windows Hello that allows people to log in to a PC with a scan of their finger, iris or face instead of using a password—weak versions of which are a common cause of data breaches. “My goal inside the company is to get rid of passwords,” said Bret Arsenault, Microsoft’s chief information security officer.</p>'
- - https://www.nytimes.com/2002/01/17/business/stung-by-security-flaws-microsoft-makes-software-safety-a-top-goal.html
  - "Stung by Security Flaws, Microsoft Makes Software Safety a Top Goal"
  - John Markoff (<span class=\"smallcaps-auto\">NYT</span>)
  - 2002-01-17
  - ''
  - ! '<p>Seeking to remove the tarnish from Microsoft’s reputation for developing secure and reliable software, Microsoft’s chairman, Bill Gates, distributed a company-wide memorandum on Tuesday to call on employees to put more emphasis on making the company’s products “trustworthy”. The new emphasis on making software safe from malicious intruders will include stopping the development of new operating system software for the entire month of February and sending the company’s 7,000 systems programmers to special security training. The company also plans to re-examine all of its Windows operating system code in an effort to find security flaws.</p><p>Microsoft executives said the memorandum resembled previous broadsides that have been fired off by Mr. Gates, the company’s co-founder and chairman, when he thought that the company’s strategic direction needed radical changes…The new memorandum was sent on Tuesday afternoon. Mr. Gates was away on one of his “think weeks,” periods when he retreats to consider issues facing the company. The document calls on the company’s software developers to make fundamental changes in the balance they strike between adding features to software and making those programs secure, according to several Microsoft executives.</p><p>As the world’s largest supplier of personal computer software, Microsoft has increasingly been criticized in recent years over the design and security of its products. Last September, for example, a stinging report from the Gartner consulting firm called on corporations to replace the Microsoft Internet Information Server, known as I.I.S., immediately because of successful attacks on the product by several malicious programs, like the Nimda worm. “Using Internet-exposed I.I.S. Web servers securely has a high cost of ownership,” the report stated. “Nimda has again shown the high risk of using I.I.S. and the effort involved in keeping up with Microsoft’s frequent security patches.” Last month the company was again stung when an embarrassing security flaw was found in a feature known as Universal Plug and Play in Windows XP, its new operating system.</p><p>…He said the company was trying to change the culture of its software developers, who have been putting their emphasis on adding features to the company’s software to increase its value. “Every developer is going to be told not to write any new line of code,” Mr. Allchin said, “until they have thought out the security implications for the product.”</p><p>The company has taken several other steps in an effort to grapple with the repeated discoveries of security holes in its products, he said.</p><p>One example of the new approach will be seen in the way the company will ship its Internet Information Server Version 6 and the new .<span class="smallcaps-auto">NET</span> server to customers. They will be shipped in a lockdown mode, with features that raise security issues—like Web access, file sharing and e-mail—turned off. The computer user will have the option of turning on functions like those. Last month, Mr. Mundie said, the company delayed the final release of its .<span class="smallcaps-auto">NET</span> development system, Visual Studio .Net, while it did a comprehensive security audit. Later this year, Mr. Allchin said, Microsoft will change the way it provides security updates to home users of Windows XP. They will be able to choose to get automatic security updates from Microsoft as the company learns of potential problems.</p>'
- - /docs/traffic/2011-lewis.pdf
  - 'Here, there, and everywhere: correlated online behaviors can lead to overestimates of the effects of advertising'
  - Randall A. Lewis, Justin M. Rao, David H. Reiley
  - 2011-03
  - 10.1145/1963405.1963431
  - ! '<p>Measuring the causal effects of online advertising (<code>adfx</code>) on user behavior is important to the health of the <span class=\"smallcaps-auto\">WWW</span> publishing industry. In this paper, using three controlled experiments, we show that observational data frequently lead to incorrect estimates of <code>adfx</code>. The reason, which we label “activity bias,” comes from the surprising amount of time-based correlation between the myriad activities that users undertake online.</p><p>In Experiment 1, users who are exposed to an ad on a given day are much more likely to engage in brand-relevant search queries as compared to their recent history for reasons that had nothing do with the advertisement. In Experiment 2, we show that activity bias occurs for page views across diverse websites. In Experiment 3, we track account sign-ups at a competitor’s (of the advertiser) website and find that many more people sign-up on the day they saw an advertisement than on other days, but that the true “competitive effect” was minimal.</p><p>In all three experiments, exposure to a campaign signals doing “more of everything” in given period of time, making it difficult to find a suitable “matched control” using prior behavior. In such cases, the “match” is fundamentally different from the exposed group, and we show how and why observational methods lead to a massive overestimate of <code>adfx</code> in such circumstances. [Keywords: advertising effectiveness, browsing behavior, causal inference, field experiments, selection bias]</p>'
- - /docs/genetics/heritable/1993-lykken.pdf
  - 'Heritability of interests: a twin study'
  - David T. Lykken, Thomas J. Bouchard, M K Mcgue, A Tellegen
  - '1993'
  - '10.1037/0021-9010.78.4.649'
  - ! '<p>The authors administered inventories of vocational and recreational interests and talents to 924 pairs of twins who had been reared together and to 92 pairs separated in infancy and reared apart. Factor analysis of all 291 items yielded 39 identifiable factors and 11 superfactors. The data indicated that about 50% of interests variance (about two thirds of the stable variance) was associated with genetic variation. The authors show that heritability can be conservatively estimated from the within-pair correlations of adult monozygotic twins reared together. Evidence for nonadditive genetic effects on interests may explain why heritability estimates based on family studies are so much lower. The authors propose a model in which precursor traits of aptitude and personality, in part genetically determined, guide the development of interests through the mechanisms of gene-environment correlation and interaction.</p>'
- - /static/js/darkmode.js
  - '<code>darkmode.js</code>'
  - Said Achmiz
  - 2020-03-20
  - ''
  - ! '<p>Javascript library for creating a theme widget controlling page appearance, toggling between automatic (OS-set), and manual ‘light’ vs ‘dark mode’. This library saves the setting to local storage, and avoids the bugs of cruder inversion-based dark-mode JS libraries where setting dark-mode during the day means it’ll automatically set light-mode at night.</p><p>Because many users do not have access to a browser/OS which explicitly supports dark mode, cannot modify the browser/OS setting without undesired side-effects, wish to opt in only for specific websites, or simply forget that they turned on dark mode &amp; dislike it, we make dark mode controllable by providing a widget at the top of the page.</p>'
- - https://www.wired.com/story/how-to-see-the-worlds-reflection-from-a-bag-of-chips/
  - "How to See the World's Reflection From a Bag of Chips: Computer scientists reconstructed the image of a whole room using the reflection from a snack package. It's useful for AR/VR research—and possibly spying"
  - Sophia Chen (Wired)
  - 2020-03-26
  - ''
  - ! '<p>Technically speaking, the researchers didn’t actually use chips; they reconstructed a room using a Korean brand of chocolate-dipped corn puffs called Corn Cho. But whether it’s corn puffs or potato chips, the snack bag acts like a bad, warped mirror. A heavily-distorted reflection of the room is contained in the glint of light that bounces off the bag, and the team developed an algorithm that unwarps that glint into a blurry but recognizable image. In one instance, the researchers were able to resolve the silhouette of a man standing in front of a window. In another, the bag reflections allowed them to see through a window to the house across the street clearly enough to count how many stories it had. The algorithm works on a variety of glossy objects—the shinier, the better. Using the sheen of a porcelain cat, for example, they could also reconstruct the layout of the surrounding ceiling lights.</p><p>…To reconstruct the environment, the researchers used a handheld color video camera with a depth sensor that roughly detects the shape and distance of the shiny objects. They filmed these objects for about a minute, capturing their reflections from a variety of perspectives. Then, they used a machine learning algorithm to reconstruct the surroundings, which took on the order of two hours per object. Their reconstructions are remarkably accurate considering the relatively small amount of data that they used to train the algorithm, says computer scientist Abe Davis of Cornell University, who was not involved with the work.</p><p>The researchers could achieve this accuracy with so little training data, in part, because they incorporate some physics concepts in their reconstruction algorithm—the difference between how light bounces off shiny surfaces versus matte surfaces, for example. This differs from typical online image recognition tools in use today, which simply look for patterns in images without any extra scientific information. However, researchers have also found that too much physics in an algorithm can cause the machine to make more mistakes, as its processing strategies become too rigid. “They do a good job of balancing physical insights with modern machine learning tools,” says Davis.</p><p>…However, some experts caution that future versions of the technology are ripe for abuse. For example, it could enable stalkers or child abusers, says ethicist Jacob Metcalf of Data &amp; Society, a nonprofit research center that focuses on the social implications of emerging technologies. A stalker could download images off of Instagram without the creators’ consent, and if those images contained shiny surfaces, they could deploy the algorithm to try to reconstruct their surroundings and infer private information about that person. “You better believe that there are a lot of people who will use a Python package to scrape photos off Instagram,” says Metcalf. “They could find a photo of a celebrity or of a kid that has a reflective surface and try to do something.”</p>'
- - https://www.damninteresting.com/radical-solutions/
  - "Radical Solutions: French mathematician Évariste Galois lived a full life. When he wasn't trying to overthrow the government, he was reinventing algebra"
  - Marisa Brook, J.A. Macfarlane (Damn Interesting)
  - 2020-03-26
  - ''
  - ! '<p>‘On the short life and violent death of French mathematical prodigy Évariste Galois, who, “when he wasn’t trying to overthrow the government, was reinventing algebra”. He mastered the entirety of contemporary mathematics while still at school, made fundamental advances in group theory at the age of 17—then took to drink, insulted his examiners, joined the National Guard, declared his desire to kill the king, spent eight months in jail, fell in love, lost a duel, and died in 1832 at the age of twenty.’</p>'
- - https://www.hanshq.net/zip.html
  - 'Zip Files: History, Explanation and Implementation'
  - Hans Wennborg
  - 2020-02-26
  - ''
  - ! '<p>I have been curious about data compression and the Zip file format in particular for a long time. At some point I decided to address that by learning how it works and writing my own Zip program. The implementation turned into an exciting programming exercise; there is great pleasure to be had from creating a well oiled machine that takes data apart, jumbles its bits into a more efficient representation, and puts it all back together again. Hopefully it is interesting to read about too.</p><p>This article explains how the Zip file format and its compression scheme work in great detail: LZ77 compression, Huffman coding, Deflate and all. It tells some of the history, and provides a reasonably efficient example implementation written from scratch in C…It is fascinating how the evolution of technology is both fast and slow. The Zip format was created 30 years ago based on technology from the fifties and seventies, and while much has changed since then, Zip files are essentially the same and more prevalent than ever. I think it is useful to have a good understanding of how they work.</p><p>[Thorough and well-illustrated descriptions of how <a href="https://en.wikipedia.org/wiki/LZ77_and_LZ78">Lempel-Ziv compression</a> &amp; <a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman coding</a> work.]</p>'
- - https://www.nature.com/news/a-long-journey-to-reproducible-results-1.22478
  - 'A long journey to reproducible results: Replicating our work took four years and 100,000 worms but brought surprising discoveries'
  - Gordon J. Lithgow, Monica Driscoll, Patrick Phillips
  - 2017-08-22 (Nature)
  - 10.1038/548387a
  - ! '<p>About 15 years ago, one of us (G.J.L.) got an uncomfortable phone call from a colleague and collaborator. After nearly a year of frustrating experiments, this colleague was about to publish a paper<sup>1</sup> chronicling his team’s inability to reproduce the results of our high-profile paper<sup>2</sup> in a mainstream journal. Our study was the first to show clearly that a drug-like molecule could extend an animal’s lifespan. We had found over and over again that the treatment lengthened the life of a roundworm by as much as 67%. Numerous phone calls and e-mails failed to identify why this apparently simple experiment produced different results between the labs. Then another lab failed to replicate our study. Despite more experiments and additional publications, we couldn’t work out why the labs were getting different lifespan results. To this day, we still don’t know. A few years later, the same scenario played out with different compounds in other labs^3, 4^….In another, now-famous example, two cancer labs spent more than a year trying to understand inconsistencies6. It took scientists working side by side on the same tumour biopsy to reveal that small differences in how they isolated cells—vigorous stirring versus prolonged gentle rocking—produced different results. Subtle tinkering has long been important in getting biology experiments to work. Before researchers purchased kits of reagents for common experiments, it wasn’t unheard of for a team to cart distilled water from one institution when it moved to another. Lab members would spend months tweaking conditions until experiments with the new institution’s water worked as well as before. Sources of variation include the quality and purity of reagents, daily fluctuations in microenvironment and the idiosyncratic techniques of investigators<sup>7</sup>. With so many ways of getting it wrong, perhaps we should be surprised at how often experimental findings are reproducible.</p><p>…Nonetheless, scores of publications continued to appear with claims about compounds that slow ageing. There was little effort at replication. In 2013, the three of us were charged with that unglamorous task… Our first task, to develop a protocol, seemed straightforward.</p><p>But subtle disparities were endless. In one particularly painful teleconference, we spent an hour debating the proper procedure for picking up worms and placing them on new agar plates. Some batches of worms lived a full day longer with gentler technicians. Because a worm’s lifespan is only about 20 days, this is a big deal. Hundreds of e-mails and many teleconferences later, we converged on a technique but still had a stupendous three-day difference in lifespan between labs. The problem, it turned out, was notation—one lab determined age on the basis of when an egg hatched, others on when it was laid. We decided to buy shared batches of reagents from the start. Coordination was a nightmare; we arranged with suppliers to give us the same lot numbers and elected to change lots at the same time. We grew worms and their food from a common stock and had strict rules for handling. We established protocols that included precise positions of flasks in autoclave runs. We purchased worm incubators at the same time, from the same vendor. We also needed to cope with a large amount of data going from each lab to a single database. We wrote an iPad app so that measurements were entered directly into the system and not jotted on paper to be entered later. The app prompted us to include full descriptors for each plate of worms, and ensured that data and metadata for each experiment were proofread (the strain names MY16 and my16 are not the same). This simple technology removed small recording errors that could disproportionately affect statistical analyses.</p><p>Once this system was in place, variability between labs decreased. After more than a year of pilot experiments and discussion of methods in excruciating detail, we almost completely eliminated systematic differences in worm survival across our labs9 (see ‘Worm wonders’)…Even in a single lab performing apparently identical experiments, we could not eliminate run-to-run differences.</p><p>…We have found one compound that lengthens lifespan across all strains and species. Most do so in only two or three strains, and often show detrimental effects in others.</p>'
- - https://www.smithsonianmag.com/history/1980s-far-left-female-led-domestic-terrorism-group-bombed-us-capitol-180973904/
  - 'In the 1980s, a Far-Left, Female-Led Domestic Terrorism Group Bombed the U.S. Capitol: Historian William Rosenau investigates the May 19<sup>th</sup> Communist Organization in a new book about the little-known militant group'
  - Lila Thulin (Smithsonian Magazine)
  - 2020-01-06
  - ''
  - ! '<p>Amidst the social and political turmoil of the 1970s, a handful of women—among them a onetime Barnard student, a Texas sorority sister, the daughter of a former communist journalist—joined and became leaders of the May 19<sup>th</sup> Communist Organization. Named to honor the shared birthday of civil rights icon Malcolm X and Vietnamese leader Ho Chi Minh, M19 took its belief in “revolutionary anti-imperialism” to violent extremes: It is “the first and only women-created and women-led terrorist group,” says national security expert and historian William Rosenau.</p><p>M19’s status as an “incredible outlier” from male-led terrorist organizations prompted Rosenau, an international security fellow at the think tank New America, to excavate the inner workings of the secretive and short-lived militant group. The resulting book, <em>Tonight We Bombed the Capitol</em>, pieces together the unfamiliar story of “a group of essentially middle-class, well educated, white people who made a journey essentially from anti-war and civil rights protest to terrorism,” he says.</p><p>…Eventually, M19 turned to building explosives themselves. Just before 11 p.m. on November 7, 1983, they called the U.S. Capitol switchboard and warned them to evacuate the building. Ten minutes later, a bomb detonated in the building’s north wing, harming no one but blasting a 15-foot gash in a wall and causing $1 million in damage. Over the course of a 20-month span in 1983 and 1984, M19 also bombed an <span class="smallcaps-auto">FBI</span> office, the Israel Aircraft Industries building, and the South African consulate in New York, D.C.’s Fort McNair and Navy Yard (which they hit twice.) The attacks tended to follow a similar pattern: a warning call to clear the area, an explosion, a pre-recorded message to media railing against U.S. imperialism or the war machine under various organizational aliases (never using the name M19)…As M19’s spree turned more and more violent, M19’s members became evermore insular and paranoid, nearly cultish, living communally and rotating through aliases and disguises until, in 1985, law enforcement captured the group’s most devoted lieutenants. After that, Rosenau writes, “The far-left terrorist project that began with the Weathermen … and continued into the mid-1980s with May 19<sup>th</sup> ended in abject failure.”</p><p>…People talk about polarization now, but just look at the early 1970s where literally thousands of bombs were set off per year. The important thing is just to realize that there are some similarities, but these are very different periods in time and each period of time is unique.</p>'
- - https://www.equestriadaily.com/2020/03/pony-voice-event-what-people-forced.html
  - 'Pony Voice Event—What People Forced Ponies to Say!'
  - Equestria Daily
  - 2020-03-24
  - ''
  - ! '<p>[Compilation of 29 videos &amp; ~25 audio files created using a new neural network service for voice synthesis of various characters, particularly <em>My Little Pony</em> characters; scripts include everything from every <em>Star Wars</em> opening to F1 car racing commentary to the <a href="https://en.wikipedia.org/wiki/Who%27s_on_First%3F">“Who’s on First?”</a> Abbott &amp; Costello comedy dialogue to 1 hour recitation of π to the <em>Dune</em> Litany Against Fear &amp; <em>Blade Runner</em> Tears in the Rain monologue.]</p>'
- - http://nautil.us/issue/43/heroes/what-does-any-of-this-have-to-do-with-physics
  - 'What Does Any of This Have To Do with Physics? Einstein and Feynman ushered me into grad school, reality ushered me out'
  - Bob Henderson (Nautilus)
  - 2016-12-29
  - ''
  - ! '<p>[Memoir of an ex-theoretical-physics grad student at the University of Rochester with Sarada Rajeev who gradually became disillusioned with physics research, burned out, and left to work in finance and is now a writer. Henderson was attracted by the life of the mind and the grandeur of uncovering the mysteries of the universe, only to discover that, after the endless triumphs of the 20<sup>th</sup> century and predicting enormous swathes of empirical experimental data, theoretical physics has drifted and become a branch of abstract mathematics, exploring ever more recondite, simplified, and implausible models in the hopes of obtaining any insight into physics’ intractable problems; one must be brilliant to even understand the questions being asked by the math and incredibly hardworking to make any progress which hasn’t already been tried by even more brilliant physicists of the past (while living in ignominious poverty and terror of not getting a grant or tenure), but one’s entire career may be spent chasing a useless dead end without one having any clue.]</p><p>The next thing I knew I was crouched in a chair in Rajeev’s little office, with a notebook on my knee and focused with everything I had on an impromptu lecture he was giving me on an esoteric aspect of some mathematical subject I’d never heard of before. Zeta functions, or elliptic functions, or something like that. I’d barely introduced myself when he’d started banging out equations on his board. Trying to follow was like learning a new game, with strangely shaped pieces and arbitrary rules. It was a challenge, but I was excited to be talking to a real physicist about his real research, even though there was one big question nagging me that I didn’t dare to ask: <em>What does any of this have to do with physics?</em></p><p>…Even a Theory of Everything, I started to realize, might suffer the same fate of multiple interpretations. The Grail could just be a hall of mirrors, with no clear answer to the “What?” or the “How?”—let alone the “Why?” Plus physics had changed since Big Al bestrode it. Mathematical as opposed to physical intuition had become more central, partly because quantum mechanics was such a strange multi-headed beast that it diminished the role that everyday, or even Einstein-level, intuition could play. So much for my dreams of staring out windows and into the secrets of the universe.</p><p>…If I did lose my marbles for a while, this is how it started. With cutting my time outside of Bausch and Lomb down to nine hours a day—just enough to pedal my mountain bike back to my bat cave of an apartment each night, sleep, shower, and pedal back in. With filling my file cabinet with boxes and cans of food, and carting in a coffee maker, mini-fridge, and microwave so that I could maximize the time spent at my desk. With feeling guilty after any day that I didn’t make my 15-hour quota. And with exceeding that quota frequently enough that I regularly circumnavigated the clock: staying later and later each night until I was going home in the morning, then in the afternoon, and finally at night again.</p><p>…The longer and harder I worked, the more I realized I didn’t know. Papers that took days or weeks to work through cited dozens more that seemed just as essential to digest; the piles on my desk grew rather than shrunk. I discovered the stark difference between classes and research: With no syllabus to guide me I didn’t know how to keep on a path of profitable inquiry. Getting “wonderfully lost” sounded nice, but the reality of being lost, and of re-living, again and again, that first night in the old woman’s house, with all of its doubts and dead-ends and that horrible hissing voice was … something else. At some point, flipping the lights on in the library no longer filled me with excitement but with dread.</p><p>…My mental model building was hitting its limits. I’d sit there in Rajeev’s office with him and his other students, or in a seminar given by some visiting luminary, listening and putting each piece in place, and try to fix in memory what I’d built so far. But at some point I’d lose track of how the green stick connected to the red wheel, or whatever, and I’d realize my picture had diverged from reality. Then I’d try toggling between tracing my steps back in memory to repair my mistake and catching all the new pieces still flying in from the talk. Stray pieces would fall to the ground. My model would start falling down. And I would fall hopelessly behind. A year or so of research with Rajeev, and I found myself frustrated and in a fog, sinking deeper into the quicksand but not knowing why. Was it my lack of mathematical background? My grandiose goals? Was I just not intelligent enough?</p><p>…I turned 30 during this time and the milestone hit me hard. I was nearly four years into the Ph.D. program, and while my classmates seemed to be systematically marching toward their degrees, collecting data and writing papers, I had no thesis topic and no clear path to graduation. My engineering friends were becoming managers, getting married, buying houses. And there I was entering my fourth decade of life feeling like a pitiful and penniless mole, aimlessly wandering dark empty tunnels at night, coming home to a creepy crypt each morning with nothing to show for it, and checking my bed for bugs before turning out the lights…As I put the final touches on my thesis, I weighed my options. I was broke, burned out, and doubted my ability to go any further in theoretical physics. But mostly, with The Grail now gone and the physics landscape grown so immense, I thought back to Rajeev’s comment about knowing which problems to solve and realized that I still didn’t know what, for me, they were.</p>'
- - https://www.eugenewei.com/blog/2019/2/19/status-as-a-service
  - Status as a Service (StaaS)
  - Eugene Wei
  - 2019-02-19
  - ''
  - ! '<p>[Meditation on what drives social networks like Instagram: <em>status and signaling</em>. A social network provides a way for monkeys to create and ascend status hierarchies, and a new social network can bootstrap and succeed by offering a new way to do that.]</p><p>Let’s begin with two principles:</p><ol type="1"><li>People are status-seeking monkeys</li><li>People seek out the most efficient path to maximizing social capital</li></ol><p>…we can start to demystify social networks if we also think of them as SaaS businesses, but instead of software, they provide status.</p><p>Almost every social network of note had an early signature proof of work hurdle. For Facebook it was posting some witty text-based status update. For Instagram, it was posting an interesting square photo. For Vine, an entertaining 6-second video. For Twitter, it was writing an amusing bit of text of 140 characters or fewer. Pinterest? Pinning a compelling photo. You can likely derive the proof of work for other networks like Quora and Reddit and Twitch and so on. Successful social networks don’t pose trick questions at the start, it’s usually clear what they want from you.</p><p>…Thirst for status is potential energy. It is the lifeblood of a Status as a Service business. To succeed at carving out unique space in the market, social networks offer their own unique form of status token, earned through some distinctive proof of work.</p><p>…Most of these near clones have and will fail. The reason that matching the basic proof of work hurdle of an Status as a Service incumbent fails is that it generally duplicates the status game that already exists. By definition, if the proof of work is the same, you’re not really creating a new status ladder game, and so there isn’t a real compelling reason to switch when the new network really has no one in it.</p><p>…Why do social network effects reverse? Utility, the other axis by which I judge social networks, tends to be uncapped in value. It’s rare to describe a product or service as having become too useful. That is, it’s hard to over-serve on utility. The more people that accept a form of payment, the more useful it is, like Visa or Mastercard or Alipay. People don’t stop using a service because it’s too useful.</p><p>…Social network effects are different. If you’ve lived in New York City, you’ve likely seen, over and over, night clubs which are so hot for months suddenly go out of business just a short while later. Many types of social capital have qualities which render them fragile. Status relies on coordinated consensus to define the scarcity that determines its value. Consensus can shift in an instant. Recall the friend in Swingers, who, at every crowded LA party, quips, “This place is dead anyway.” Or recall the wise words of noted sociologist Groucho Marx: “I don’t care to belong to any club that will have me as a member.”</p>'
- - /docs/economics/2020-sauer-howcameoturneddlistcelebsintoamonetizationmachine.html
  - "How Cameo Turned D-List Celebs Into a Monetization Machine: Inside the surreal and lucrative two-sided marketplace of mediocre famous people"
  - Patrick J. Sauer
  - 2020-03-17
  - ''
  - ! '<p>These formulas have turned an obscure idea that Galanis and his college buddies had a few years ago about making more money for second rate celebs into a thriving two-sided marketplace that has caught the attention of VCs, Hollywood, and professional sports. In June, Cameo raised $50 million in Series B funding, led by Kleiner Perkins (which recently began funding more early stage startups) to boost marketing, expand into international markets, and staff up to meet the growing demand. In the past 15 months, Cameo has gone from 20 to 125 employees, and moved from an 825-square-foot home base in the 1871 technology incubator into its current 6,000-square-foot digs in Chicago’s popping West Loop. Cameo customers have purchased more than 560,000 videos from some 20,000 celebs and counting, including ’80s star Steve Guttenberg and sports legend Kareem Abdul-Jabbar. And now, when the masses find themselves in quarantined isolation—looking for levity, distractions, and any semblance of the human touch—sending each other personalized videograms from the semi-famous has never seemed like a more pitch-perfect offering.</p><p>The product itself is as simple as it is improbable. For a price the celeb sets —anywhere from $5 to $2,500—famous people record video shout-outs, aka “Cameos,” that run for a couple of minutes, and then are delivered via text or email. Most Cameo videos are booked as private birthday or anniversary gifts, but a few have gone viral on social media. Even if you don’t know Cameo by name, there’s a good chance you caught Bam Margera of <span class="smallcaps-auto">MTV</span>’s <em>Jackass</em> delivering an “I quit” message on behalf of a disgruntled employee, or Sugar Ray’s Mark McGrath dumping some poor dude on behalf of the guy’s girlfriend. (Don’t feel too bad for the dumpee, the whole thing was a joke.)</p><p>…Back at the whiteboard, Galanis takes a marker and sketches out a graph of how fame works on his platform. “Imagine the grid represents all the celebrity talent in the world,” he says, “which by our definition, we peg at 5 million people.” The X-axis is willingness; the Y-axis is fame. “Say LeBron is at the top of the X-axis, and I’m at the bottom,” he says. On the willingness side, Galanis puts notoriously media-averse Seattle Seahawks running back Marshawn Lynch on the far left end. At the opposite end, he slots chatty celebrity blogger-turned-Cameo-workhorse Perez Hilton, of whom Galanis says, “I promise if you booked him right now, the video would be done before we leave this room.”</p><p>…“The contrarian bet we made was that it would be way better for us to have people with small, loyal followings, often unknown to the general population, but who were willing to charge $5 to $10,” Galanis says. Cameo would employ a revenue-sharing model, getting a 25% cut of each video, while the rest went to the celeb. They wanted people like Galanis’ co-founder (and former Duke classmate) Devon Townsend, who had built a small following making silly Vine videos of his travels with pal Cody Ko, a popular YouTuber. “Devon isn’t Justin Bieber, but he had 25,000 Instagram followers from his days as a goofy Vine star,” explains Galanis. “He originally charged a couple bucks, and the people who love him responded, ‘Best money I ever spent!’”</p><p>…After a customer books a Cameo, the celeb films the video via the startup’s app within four to seven days. Most videos typically come in at under a minute, though some talent indulges in extensive riffs. (Inexplicably, “plant-based activist and health coach” Courtney Anne Feldman, wife of Corey, once went on for more than 20 minutes in a video for a customer.) Cameo handles the setup, technical infrastructure, marketing, and support, with white-glove service for the biggest earners with “whatever they need”—details like help pronouncing a customer’s name or just making sure they aren’t getting burned-out doing so many video shout-outs.</p><p>…For famous people of any caliber—the washed-up, the obscure micro-celebrity, the actual rock star—becoming part of the supply side of the Cameo marketplace is as low a barrier as it gets. Set a price and go. The videos are short—Instagram comedian Evan Breen has been known to knock out more than 100 at $25 a pop in a single sitting—and they don’t typically require any special preparation. Hair, makeup, wardrobe, or even handlers aren’t necessary. In fact, part of the oddball authenticity of Cameo videos is that they have a take-me-as-I-am familiarity—filmed at breakfast tables, lying in bed, on the golf course, running errands, at a stoplight, wherever it fits into the schedule.</p>'
- - https://slatestarcodex.com/2020/03/17/book-review-hoover/
  - "Book Review: Hoover [review of Whyte’s <em>Hoover: An Extraordinary Life In Extraordinary Times</em>]"
  - Scott Alexander (<span class=\"smallcaps-auto\">SSC</span>)
  - 2020-03-17
  - ''
  - ! '<p>Extensive paraphrase summary of <a href="https://en.wikipedia.org/wiki/Herbert_Hoover">Herbert Hoover</a>: while remembered solely as one of the worse American presidents because of the Great Depression, Hoover had a remarkable life: he rose from grinding poverty to the first student at Stanford University (later a trustee) to becoming a mining magnate after revamping Australia &amp; China (the latter in the midst of the Boxer Rebellion) and penning a definitive mining textbook. Along the way, he invented a popular CrossFit medicine ball exercise, relieved the worst flood disaster in American history, organized the evacuation of Americans trapped by the outbreak of <span class="smallcaps-auto">WWI</span> and then reorganized American agriculture for <span class="smallcaps-auto">WWI</span>…</p><p>Hoover, in the service of the highest goods, ruthlessly crushes all opposition, shamelessly exploits PR tactics to the maximum extent, lies and deceives his negotiating partners, and bankrupts himself—and he succeeds, becoming arguably one of the greatest philanthropists in history for organizing repeated famine reliefs in Europe and Communist Russia after.</p><p>A shockingly competent technocrat and now regarded as one of the greatest men in the world, he succeeds Coolidge and attempts to forestall the looming Great Depression, and then takes unprecedented action to stop it; while he ultimately fails, he initially seemed like he was succeeding, and it may be bad luck plus the deliberate sabotage of his efforts by President-elect Franklin Roosevelt which prolonged the Great Depression. Embittered, he spends the rest of his life inveighing against <span class="smallcaps-auto">FDR</span> and the New Deal, founding modern conservatism.</p><p>Alexander ponders why Hoover, who was so unarguably competent at everything he turned his hand to, achieving impossible feats of management and logistics, appears to have failed when he became President at stopping the Great Depression or being re-elected, and what we can learn about philanthropy from him.</p>'
- - http://pgbovine.net/PhD-memoir.htm
  - 'The Ph.D. Grind: A Ph.D. Student Memoir'
  - Philip Guo
  - 2012/2015
  - ''
  - ! '<p>[Brutal, lengthy memoir of 6 years as a computer science/software engineering grad student at Stanford University. As positively as the author regards his experience, it comes off as a nightmarish publish-or-perish dystopia where professors burn through naive idealistic grad students doing grunt-work in an endless death-march towards conference deadlines and where marketing is far more important than merit (“sell, sell, sell”), peer reviewers are sadistic rolls of dice and reject papers for superficial problems like not using the exact jargon of a subfield; the software used is filled with endless bugs and takes months to be hacked into shape, never to be used in the real world, and even the original authors can’t get it to work a second time. Many students pursue a promising idea only for it to not work out, and wash out of the field—with so many people chasing so few academic positions, anything short of enormous success is a fatal failure. The notes added in 2015 as a followup, recounting the fate of various grad students or assistant professors, reinforce the daunting odds against a intellectually-satisfying career in academia. It is unsurprising that so many grad students appear to have minor mental breakdowns like him. Strikingly, his by far most successful year was the one spent <em>outside</em> academia, at <a href="https://en.wikipedia.org/wiki/Microsoft_Research">Microsoft Research</a>. Guo provides these lessons:</p><ol type="1"><li>Results trump intentions</li><li>Outputs trump inputs</li><li>Find relevant information</li><li>Create lucky opportunities</li><li>Play the game</li><li>Lead from below</li><li>Professors are human</li><li>Be well-liked</li><li>Pay some dues</li><li>Reject bad defaults</li><li>Know when to quit</li><li>Recover from failures</li><li>Ally with insiders</li><li>Give many talks</li><li>Sell, sell, sell</li><li>Generously provide help</li><li>Ask for help</li><li>Express true gratitude</li><li>Ideas beget ideas</li><li>Grind hard and smart]</li></ol>'
- - https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark
  - "Agent57: Outperforming the human Atari benchmark"
  - Adrià Puigdomènech, Bilal Piot, Steven Kapturowski, Pablo Sprechmann, Alex Vitvitskyi, Daniel Guo, Charles Blundell
  - 2020-03-31
  - ''
  - ! '<p>The Atari57 suite of games is a long-standing benchmark to gauge agent performance across a wide range of tasks. We’ve developed Agent57, the first deep reinforcement learning agent to obtain a score that is above the human baseline on all 57 Atari 2600 games. Agent57 combines an algorithm for efficient exploration with a meta-controller that adapts the exploration and long vs. short-term behaviour of the agent.</p><p>…In 2012, the Arcade Learning environment—a suite of 57 Atari 2600 games (dubbed Atari57)—was proposed as a benchmark set of tasks: these canonical Atari games pose a broad range of challenges for an agent to master….Unfortunately, the average performance can fail to capture how many tasks an agent is doing well on, and so is not a good statistic for determining how general an agent is: it captures that an agent is doing <em>sufficiently well</em>, but not that it is doing sufficiently well on a <em>sufficiently wide</em> set of tasks. So although average scores have increased, until now, the number of above human games has not.</p><p>…Back in 2012, DeepMind developed the Deep Q-network agent (<span class="smallcaps-auto">DQN</span>) to tackle the Atari57 suite. Since then, the research community has developed many extensions and alternatives to <span class="smallcaps-auto">DQN</span>. Despite these advancements, however, all deep reinforcement learning agents have consistently failed to score in four games: <em>Montezuma’s Revenge</em>, <em>Pitfall</em>, <em>Solaris</em> and <em>Skiing</em>. For Agent57 to tackle these four challenging games in addition to the other Atari57 games, several changes to <span class="smallcaps-auto">DQN</span> were necessary.</p><figure><img src="/images/rl/2020-deepmind-agent57-figure3-deepreinforcementlearningtimeline.svg" alt="Figure 3. Conceptual advancements to DQN that have resulted in the development of more generally intelligent agents. (https://kstatic.googleusercontent.com/files/f6b5f285173d4449285a8e812b8385f45c03f7104e1c41370a73e0c8558ff82d6a69e60962dd91c4972c444fd73bc4f98a06b5487eff5a037a37bc42f97cef3b)" /><figcaption>Figure 3. Conceptual advancements to <span class="smallcaps-auto">DQN</span> that have resulted in the development of more generally intelligent agents.</figcaption></figure><ul><li><p><span class="smallcaps-auto">DQN</span> improvements</p><ul><li>Distributed agents</li><li>Short-term memory</li><li>Episodic memory</li></ul></li><li><p>Intrinsic motivation methods to encourage directed exploration</p><ul><li>Seeking novelty over long time scales</li><li>Seeking novelty over short time scales</li><li>Meta-controller: learning to balance exploration with exploitation</li></ul></li><li><p>Agent57: putting it all together</p></li></ul><figure><img src="/images/rl/2020-deepmind-agent57-performancetable.svg" alt="Performance table of Agent57, NGU, R2D2, &amp; MuZero (https://kstatic.googleusercontent.com/files/a9754efe518fdef7e39f50baeffd0f8348f21d0fd3c919f6ca749799321a9b514134f3a2a6f19d33b9fcf254ccf05847f91da511567e44ffc375a6ccb75b069c)" /><figcaption>Performance table of Agent57, <span class="smallcaps-auto">NGU</span>, R2D2, &amp; MuZero</figcaption></figure><p>…With Agent57, we have succeeded in building a more generally intelligent agent that has above-human performance on all tasks in the Atari57 benchmark. It builds on our previous agent Never Give Up, and instantiates an adaptive meta-controller that helps the agent to know when to explore and when to exploit, as well as what time-horizon it would be useful to learn with. A wide range of tasks will naturally require different choices of both of these trade-offs, therefore the meta-controller provides a way to dynamically adapt such choices.</p><p>Agent57 was able to scale with increasing amounts of computation: the longer it trained, the higher its score got. While this enabled Agent57 to achieve strong general performance, it takes a lot of computation and time; the data efficiency can certainly be improved. Additionally, this agent shows better 5<sup>th</sup> percentile performance on the set of Atari57 games. This by no means marks the end of Atari research, not only in terms of data efficiency, but also in terms of general performance. We offer two views on this: firstly, analyzing the performance among percentiles gives us new insights on how general algorithms are. While Agent57 achieves strong results on the first percentiles of the 57 games and holds better mean and median performance than <span class="smallcaps-auto">NGU</span> or R2D2, as illustrated by <a href="https://arxiv.org/abs/1911.08265#deepmind">MuZero</a>, it could still obtain a higher average performance. Secondly, all current algorithms are far from achieving optimal performance in some games. To that end, key improvements to use might be enhancements in the representations that Agent57 uses for exploration, planning, and credit assignment.</p>'
- - https://www.nickbostrom.com/papers/anthropicshadow.pdf
  - "Anthropic Shadow: Observation Selection Effects and Human Extinction Risks"
  - Milan M. Ćirković, Anders Sandberg, Nick Bostrom
  - 2010-07-09
  - 10.1111/j.1539-6924.2010.01460.x
  - ! '<p>We describe a significant practical consequence of taking anthropic biases into account in deriving predictions for rare stochastic catastrophic events. The risks associated with catastrophes such as asteroidal/cometary impacts, supervolcanic episodes, and explosions of supernovae/gamma-ray bursts are based on their observed frequencies. As a result, the frequencies of catastrophes that destroy or are otherwise incompatible with the existence of observers are systematically underestimated. We describe the consequences of this anthropic bias for estimation of catastrophic risks, and suggest some directions for future work. [Keywords: Anthropic principle; astrobiology; existential risks; global catastrophes; impact hazard; natural hazards; risk management; selection effects; vacuum phase transition]</p>'
- - /docs/algernon/2011-hills.pdf
  - "Why Aren't We Smarter Already: Evolutionary Trade-Offs and Cognitive Enhancements"
  - Thomas Hills, Ralph Hertwig
  - 2011-12-05
  - 10.1177/0963721411418300
  - ! '<p>Pharmacological enhancers of cognition promise a bright new future for humankind: more focus, more willpower, and better memory, with applications ranging from education to military combat. Underlying such promises is a linear, more-is-better vision of cognition that makes intuitive sense. This vision is at odds, however, with our understanding of cognition’s evolutionary origins. The mind has evolved under various constraints and consequently represents a delicate balance among these constraints. Evidence of the trade-offs that have shaped cognition include (a) inverted U-shaped performance curves commonly found in response to pharmacological interventions and (b) unintended side effects of enhancement on other traits. Taking an evolutionary perspective, we frame the above two sets of findings in terms of within-task (exemplified by optimal-control problems) and between-task (associated with a gain/loss asymmetry) trade-offs, respectively. With this framework, psychological science can provide much-needed guidance to enhancement development, a field that still lacks a theoretical foundation. [Keywords: cognitive enhancements, trade-offs, constraints, evolution, side effects]</p>'
- - /docs/iq/1995-bouchard.pdf
  - 'Breaking the Last Taboo [Review of the book <em>The Bell Curve: Intelligence And Class Structure In American Life</em>, by R. J. Herrnstein & C. Murray]'
  - Thomas J. Bouchard
  - '1995'
  - 10.1037/003626
  - ! '<p>The reviewer notes that this book (see record 1994-98748-000) has a simple but powerful thesis: There are substantial individual and group differences in intelligence; these differences profoundly influence the social structure and organization of work in modern industrial societies, and they defy easy remediation. In the current political milieu this book’s message is not merely controversial, it is incendiary. Commentators from across the political spectrum have documented the profound social changes that all industrialized societies are undergoing at the end of the 20<sup>th</sup> century—erosion of the middle class, loss of well-paying manufacturing jobs, and an emerging information age in which individual success will depend on brains not brawn. This book differs from other works by focusing on intelligence, rather than education or social class, as a causal variable. The authors argue that general cognitive ability is a major determiner of social status and that variance in general mental ability is largely attributable to genetic factors—propositions that are certainly endorsed by many experts in the field. The book explicitly disclaims, however, that general mental ability is the only determinant of social status.</p>'
- - /docs/sociology/2020-albarran.pdf
  - 'Education and adult health: Is there a causal effect?'
  - Pedro Albarrán, Marisa Hidalgo-Hidalgo, Iñigo Iturbe-Ormaetxe
  - 2020-03
  - 10.1016/j.socscimed.2020.112830$
  - ! '<ul><li>We analyze whether the positive relation between education and health is causal.</li><li>We combine multi-country data from two cross-sections of EU-<span class="smallcaps-auto">SILC</span>.</li><li>We use exogenous variation in compulsory schooling induced by school laws.</li><li>We find no causal effect of education on any of our several health measures.</li><li>The result is robust to changes in the main specification and using other databases.</li></ul><p>Many studies find a strong positive correlation between education and adult health. A subtler question is whether this correlation can be interpreted as a causal relationship. We combine multi-country data from two cross-sections of the European Union Statistics on Income and Living Conditions (EU-<span class="smallcaps-auto">SILC</span>) survey and use exogenous variation in compulsory years of schooling across countries and cohorts induced by compulsory schooling laws. We find no causal effect of education on any of our several health measures. This finding is extremely robust to different changes in our main specification and holds using other databases. We discuss different explanations for our results. [Keywords: Health, Education, Instrumental variables]</p>'
- - /docs/longevity/2002-weinstein.pdf
  - 'The reserve-capacity hypothesis: evolutionary origins and modern implications of the trade-off between tumor-suppression and tissue-repair'
  - Bret S. Weinstein, Deborah Ciszek
  - 2002-05
  - 10.1016/S0531-5565(02)00012-8
  - ! '<p>Antagonistic pleiotropy, the evolutionary theory of senescence, posits that age related somatic decline is the inevitable late-life by-product of adaptations that increase fitness in early life. That concept, coupled with recent findings in oncology and gerontology, provides the foundation for an integrative theory of vertebrate senescence that reconciles aspects of the ‘accumulated damage’ ‘metabolic rate’, and ‘oxidative stress’ models. We hypothesize that (1) in vertebrates, a telomeric fail-safe inhibits tumor formation by limiting cellular proliferation. (2) The same system results in the progressive degradation of tissue function with age. (3) These patterns are manifestations of an evolved antagonistic pleiotropy in which extrinsic causes of mortality favor a species-optimal balance between tumor suppression and tissue repair. (4) With that trade-off as a fundamental constraint, selection adjusts telomere lengths—longer telomeres increasing the capacity for repair, shorter telomeres increasing tumor resistance. (5) In environments where extrinsically induced mortality is frequent, selection against senescence is comparatively weak as few individuals live long enough to suffer a substantial phenotypic decline. The weaker the selection against senescence, the further the optimal balance point moves toward shorter telomeres and increased tumor suppression. The stronger the selection against senescence, the farther the optimal balance point moves toward longer telomeres, increasing the capacity for tissue repair, slowing senescence and elevating tumor risks. (6) In iteroparous organisms selection tends to co-ordinate rates of senescence between tissues, such that no one organ generally limits life-span. A subsidiary hypothesis argues that senescent decline is the combined effect of (1) uncompensated cellular attrition and (2) increasing histological entropy. Entropy increases due to a loss of the intra-tissue positional information that normally regulates cell fate and function. Informational loss is subject to positive feedback, producing the ever-accelerating pattern of senescence characteristic of iteroparous vertebrates. Though telomere erosion begins early in development, the onset of senescence should, on average, be deferred to the species-typical age of first reproduction, the balance point at which selection on this trade-off should allow exhaustion of replicative capacity to overtake some cell lines. We observe that captive-rodent breeding protocols, designed to increase reproductive output, simultaneously exert strong selection against reproductive senescence and virtually eliminate selection that would otherwise favor tumor suppression. This appears to have greatly elongated the telomeres of laboratory mice. With their telomeric failsafe effectively disabled, these animals are unreliable models of normal senescence and tumor formation. Safety tests employing these animals likely overestimate cancer risks and underestimate tissue damage and consequent accelerated senescence.</p>'
- - /docs/genetics/heritable/2011-demoor.pdf
  - 'Exercise Participation in Adolescents and Their Parents: Evidence for Genetic and Generation Specific Environmental Effects'
  - M.H.M. de Moor, G. Willemsen, I. Rebollo Mesa, J.H. Stubbe, E.J.C. de Geus, D.I. Boomsma
  - '2011'
  - 10.1007/s10519-010-9415-4
  - ! '<p>Individual differences in adolescent exercise behavior are to a large extent explained by shared environmental factors. The aim of this study was to explore to what extent this shared environment represents effects of cultural transmission of parents to their offspring, generation specific environmental effects or assortative mating. Survey data on leisure-time exercise behavior were available from 3,525 adolescent twins and their siblings (13–18 years) and 3,138 parents from 1,736 families registered at the Netherlands Twin Registry. Data were also available from 5,471 adult twins, their siblings and spouses similar in age to the parents. Exercise participation (No/Yes, using a cut-off criterion of 4 metabolic equivalents and 60 min weekly) was based on questions on type, frequency and duration of exercise. A model to analyze dichotomous data from twins, siblings and parents including differences in variance decomposition across sex and generation was developed. Data from adult twins and their spouses were used to investigate the causes of assortative mating (correlation between spouses = 0.41, due to phenotypic assortment). The heritability of exercise in the adult generation was estimated at 42%. The shared environment for exercise behavior in adolescents mainly represents generation specific shared environmental influences that seem somewhat more important in explaining familial clustering in girls than in boys (52 versus 41%). A small effect of vertical cultural transmission was found for boys only (3%). The remaining familial clustering for exercise behavior was explained by additive genetic factors (42% in boys and 36% in girls). Future studies on adolescent exercise behavior should focus on identification of the generation specific environmental factors.</p>'
- - http://ksvanhorn.com/bayes/Papers/rcox.pdf
  - "Constructing a Logic of Plausible Inference: A Guide to Cox's Theorem"
  - Kevin van Horn
  - '2003'
  - '10.1016/S0888-613X(03)00051-3'
  - ! '<p>Cox’s theorem provides a theoretical basis for using probability theory as a general logic of plausible inference. The theorem states that any system for plausible reasoning that satisfies certain qualitative requirements intended to ensure consistency with classical deductive logic and correspondence with commonsense reasoning is isomorphic to probability theory. However, the requirements used to obtain this result have been the subject of much debate. We review Cox’s theorem, discussing its requirements, the intuition and reasoning behind these, and the most important objections, and finish with an abbreviated proof of the theorem.</p>'
- - /docs/bitcoin/1988-ijiri.pdf
  - Momentum Accounting and Managerial Goals on Impulses
  - Yuji Ijiri
  - '1988-02-01'
  - 10.1287/mnsc.34.2.160
  - ! '<p>Conventional accounting measures wealth <em>W</em> (assets and liabilities) and accounts for its net change, <em>W(t + 1) − W(t)</em>, by means of income Δ_<em>W(t)</em>, classified into various revenue and expense items. Proposed “momentum accounting” measures income momentum <em>Ẇ = dW/dt</em> (time rate at which income is being earned at a given point in time) and accounts for its net change, <em>Ẇ(t + 1) − Ẇ(t)</em>, by means of impulses <em>ΔẆ(t)</em>. Here the impulses, a term borrowed from the momentum-impulse principle in mechanics, are classified into various factors, internal or external to the enterprise, that contributed to the momentum change. If conventional accounting is viewed as focusing on an odometer of a car, momentum accounting is analogous to focusing on its speedometer and attributing the change in its reading to impulses that are judged to be responsible for the change. This paper proposes impulse-based managerial goals as a substitute for currently popular income-based managerial goals, discussing problems associated with the latter that highlights short-term income achievements and that tends to reward management for the momentum created by their predecessors as it is realized as income by the mere passage of time.</p>'
- - /docs/cs/2020-ren.pdf
  - 'Google-Wide Profiling: A Continuous Profiling Infrastructure for Data Centers'
  - Gang Ren; Tune, E.; Moseley, T.; Yixin Shi; Rus, S.; Hundt, R.
  - 2010-08-19
  - 10.1109/mm.2010.68
  - ! '<p>Google-Wide Profiling (<span class="smallcaps-auto">GWP</span>), a continuous profiling infrastructure for data centers, provides performance insights for cloud applications. With negligible overhead, <span class="smallcaps-auto">GWP</span> provides stable, accurate profiles and a datacenter-scale tool for traditional performance analyses. Furthermore, <span class="smallcaps-auto">GWP</span> introduces novel applications of its profiles, such as application-platform affinity measurements and identification of platform-specific, microarchitectural peculiarities.</p>'
- - /docs/iq/2008-hanushek.pdf
  - The Role of Cognitive Skills in Economic Development
  - Eric A. Hanushek, Ludger Woessmann
  - 2008-09-01
  - 10.1257/jel.46.3.607
  - ! '<p>The role of improved schooling, a central part of most development strategies, has become controversial because expansion of school attainment has not guaranteed improved economic conditions. This paper reviews the role of cognitive skills in promoting economic well-being, with a particular focus on the role of school quality and quantity. It concludes that there is strong evidence that the cognitive skills of the population—rather than mere school attainment—are powerfully related to individual earnings, to the distribution of income, and to economic growth. New empirical results show the importance of both minimal and high level skills, the complementarity of skills and the quality of economic institutions, and the robustness of the relationship between skills and growth. International comparisons incorporating expanded data on cognitive skills reveal much larger skill deficits in developing countries than generally derived from just school enrollment and attainment. The magnitude of change needed makes clear that closing the economic gap with developed countries will require major structural changes in schooling institutions.</p>'
- - /docs/history/2002-peterson.pdf
  - "Galileo’s discovery of scaling laws"
  - Mark A. Peterson
  - 2002-05-13
  - 10.1119/1.1475329
  - ! '<p>Galileo’s realization that nature is not scale invariant motivated his subsequent discovery of scaling laws. His thinking is traced to two lectures he gave on the geography of Dante’s <em>Inferno</em>…Looked at this way, Galileo’s lifelong reluctance to publish seems even more inexplicable, but perhaps this pattern began with the experience of the <em>Inferno</em> lectures. He seems to have done his best to make people forget the lectures, and he kept the scaling theory to himself. What he made public,at least in this case, was a source of trouble, while what he kept secret was a source of confidence. The unpleasantness of being vulnerable to attack is a lesson that he might have taken to heart then, and it is a view he expresses feelingly later on, on the basis of real experience (although without admitting vulnerability!), in the opening lines of <em>The Assayer</em>.<sup>17</sup> Galileo frequently claims to have wonderful results that he has not yet revealed, things he has not yet chosen to disclose. We know that this was true through much of his career, and apparently it was true right from the start. Finally, it is an irony that the first success of Galileo’s mathematical physics, which is close to being the first success of mathematical physics at all, was a response to a problem that was not physical, but rather the collapse of an imaginary structure in a work of literature.</p><p>[Galileo’s <em>Two New Sciences</em> puzzlingly spends much of its material on the question of how large a ship or a beam of wood or a column of rock can become before collapsing, correctly arguing that the naive belief of scale-invariance (that a ship can be any size as long as it maintains the same geometric proportions) is wrong and that large ships or beams are impossible as they will collapse under their own weight. Why did Galileo, who hardly ever published, spend so much time on this rather than astronomy—especially when he appears to have conducted the scaling law research almost 30 years before?</p><p>Peterson digs up neglected lectures by a young and ambitious Galileo, at the court of the Medici, on the topic of Dante’s <em>Inferno</em> where he weighed in on a contemporary dispute between a fellow Florentine &amp; a rival Italian about the size &amp; geography of Hell (then still considered a real place located within the Earth). Galileo, assuming scale-invariance, defended &amp; mathematically improved his fellow’s approach.</p><p>The scaling research, then, grew out of his doubts about his naive extrapolations, and he eventually refuted himself. In Renaissance Italy, science, being a patronage/prestige-based endeavour heavily driven by entertainment value, Galileo would be incentivized to keep this research secret lest he embarrass himself, and to use as a weapon in the controversy. However, the dispute appears to have died out and he never had to reveal it, so, decades later, he then included it in <em>Two New Sciences</em> while sanitizing it of its embarrassing origins.]</p>'
- - /docs/history/2002-pesic.pdf
  - ! 'Comment on “Galileo’s discovery of scaling laws,” by Mark A. Peterson [Am. J. Phys. 70 (6), 575–580 (2002)]–Galileo and the existence of hell'
  - Peter Pesic
  - 2002-10-14
  - 10.1119/1.1488637
  - ! '<p>[Pesic discusses Peterson’s theory of Galileo’s focus on scaling laws in <em>Two New Sciences</em> as reflecting belated publication of a theory developed to analyze the physical possibility of Hell in Dante’s <em>Inferno</em>. Peterson suggests Galileo was embarrassed at having refuted his own arguments and shown it impossible, and simply delayed publishing to avoid attack.</p><p>Pesic suggests an additional consideration: religious Catholic orthodoxy of the sort Galileo would later run afoul of. By refuting even just Dante’s Hell, Galileo would cast some doubt on the official Catholic &amp; Ptolemaic cosmologies, treating close to heresy.]</p><p>Though the exact location of hell was not a matter of faith, its existence was a tenet of Catholic belief and its negation thus heretical. Thus, in 1620 Giuseppe Rosaccio confidently described hell as being within the earth, noting that an enormous space was needed in view of the ever increasing number of the damned, who had no right to expect as much room as the blessed souls in heaven.<sup>14</sup></p>'
- - /docs/biology/1927-haldane-possibleworldsandotheressays-ch3-onbeingtherightsize.pdf
  - "On Being The Right Size"
  - ! '<a href="https://en.wikipedia.org/wiki/J._B._S._Haldane">J. B. S. Haldane</a>'
  - 1927-03-27
  - ''
  - ! '<p>[Popular science discussion of scaling laws by biologist: why does a short fall not faze a mouse or insect but injures a man and makes a horse go <em>splash</em>, and why are giants impossible? Because the strength of bodily parts increases less than total volume or weight, and they become weaker and more fragile the bigger they are. Other examples include surface tension, blood pumping, oxygen respiration, flying, warm-bloodedness vs volume, eye acuity, brain size—and perhaps human organizations like governments and businesses?]</p><p>Let us take the most obvious of possible cases, and consider a giant man sixty feet high—about the height of Giant Pope and Giant Pagan in the illustrated <em>Pilgrim’s</em> Progress of my childhood. These monsters were not only ten times as high as Christian, but ten times as wide and ten times as thick, so that their total weight was a thousand times his, or about eighty to ninety tons. Unfortunately the cross-sections of their bones were only a hundred times those of Christian, so that every square inch of giant bone had to support ten times the weight borne by a square inch of human bone. As the human thigh-bone breaks under about ten times the human weight, Pope and Pagan would have broken their thighs every time they took a step. This was doubtless why they were sitting down in the picture I remember. But it lessens one’s respect for Christian and Jack the Giant Killer.</p>'
- - /docs/genetics/correlation/2020-li.pdf
  - Genome-wide Association Study of Creativity Reveals Genetic Overlap With Psychiatric Disorders, Risk Tolerance, and Risky Behaviors
  - Huijuan Li, Chuyi Zhang, Xin Cai, Lu Wang, Fang Luo, Yina Ma, Ming Li, Xiao Xiao
  - 2020-03-05
  - 10.1093/schbul/sbaa025
  - ! '<p>Creativity represents one of the most important and partially heritable human characteristics, yet little is known about its genetic basis. Epidemiological studies reveal associations between creativity and psychiatric disorders as well as multiple personality and behavioral traits. To test whether creativity and these disorders or traits share genetic basis, we performed genome-wide association studies (<span class="smallcaps-auto">GWAS</span>) followed by polygenic risk score (<span class="smallcaps-auto">PRS</span>) analyses. Two cohorts of Han Chinese subjects (4,834 individuals in total) aged 18–45 were recruited for creativity measurement using typical performance test. After exclusion of the outliers with significantly deviated creativity scores and low-quality genotyping results, 4,664 participants were proceeded for <span class="smallcaps-auto">GWAS</span>. We conducted <span class="smallcaps-auto">PRS</span> analyses using both the classical pruning and thresholding (P+T) method and the LDpred method. The extent of polygenic risk was estimated through linear regression adjusting for the top 3 genotyping principal components. R<sup>2</sup> was used as a measurement of the explained variance. <span class="smallcaps-auto">PRS</span> analyses demonstrated significantly positive genetic overlap, respectively, between creativity with schizophrenia ((P+T) method: R<sup>2</sup><sub>(max)</sub> ~ .196%, <em>p</em> = .00245; LDpred method: R<sup>2</sup><sub>(max)</sub> ~ .226%, <em>p</em> = .00114), depression ((P+T) method: R<sup>2</sup><sub>(max)</sub> ~ .178%, <em>p</em> = .00389; LDpred method: R<sup>2</sup><sub>(max)</sub> ~ .093%, <em>p</em> = .03675), general risk tolerance ((P+T) method: R<sup>2</sup><sub>(max)</sub> ~ .177%, <em>p</em> = .00399; LDpred method: R<sup>2</sup><sub>(max)</sub> ~ .305%, <em>p</em> = .00016), and risky behaviors ((P+T) method: R<sup>2</sup><sub>(max)</sub> ~ .187%, <em>p</em> = .00307; LDpred method: R<sup>2</sup><sub>(max)</sub> ~ .155%, <em>p</em> = .00715). Our results suggest that human creativity is probably a polygenic trait affected by numerous variations with tiny effects. Genetic variations that predispose to psychiatric disorders and risky behaviors may underlie part of the genetic basis of creativity, confirming the epidemiological associations between creativity and these traits.</p>'
- - /docs/cs/2008-changizi.pdf
  - Harnessing Vision for Computation
  - Mark Changizi
  - 2008-01-01
  - 10.1068/p6057
  - ! '<p>Might it be possible to harness the visual system to carry out artificial computations, somewhat akin to how <span class="smallcaps-auto">DNA</span> has been harnessed to carry out computation? I provide the beginnings of a research programme attempting to do this. In particular, new techniques are described for building ‘visual circuits’ (or ‘visual software’) using wire, <span class="smallcaps-auto">NOT</span>, OR, and <span class="smallcaps-auto">AND</span> gates in a visual modality such that our visual system acts as ‘visual hardware’ computing the circuit, and generating a resultant perception which is the output.</p>'
- - /docs/psychology/2019-curran.pdf
  - ! "I'm paid biweekly, just not by leprechauns: Evaluating valid-but-incorrect response rates to attention check items"
  - Paul G. Curran, Kelsey A. Hauser
  - 2019-10-01
  - 10.1016/j.jrp.2019.103849
  - ! '<ul><li>Carelessness in self-report data can be detected with many methods.</li><li>Embedding items in a scale with presumed ‘correct’ responses is one of these.</li><li>Properties of these items can impact their usefulness.</li><li>Individuals can provide valid justification for ‘incorrect’ responses.</li><li>Researchers should know their items, and know the risk of not knowing those items.</li></ul><p>Participant carelessness is a source of invalidity in psychological data (Huang, Liu, &amp; Bowling, 2015), and many methods have been created to screen for this carelessness (Curran, 2016; Johnson, 2005). These include items that researchers presume thoughtful individuals will answer in a given way (e.g., disagreement with “I am paid biweekly by leprechauns”, Meade &amp; Craig, 2012). This paper reports on two samples in which individuals spoke aloud a series of these questions, and found that (a) individuals do occasionally report valid justifications for presumed invalid responses, (b) there is relatively high variance in this behavior over different items, and (c) items developed for this specific purpose tend to work better than those drawn from other sources or created ad-hoc. [Keywords: Carelessness, Data cleaning, Insufficient effort responding, Verbal protocol, Self-report data]</p><p>…</p><table><colgroup><col style="width: 31%" /><col style="width: 68%" /></colgroup><thead><tr class="header"><th>Check</th><th>Justifications</th></tr></thead><tbody><tr class="odd"><td>“All my friends are aliens”</td><td>“‘Aliens’ is a relative term; I don’t actually know for sure” · “What does that even mean, we’re all aliens if there’s other life out there”</td></tr><tr class="even"><td>“I am interested in…parabanjology”</td><td>“Might be real so don’t want to disagree” · “It sounds like it could be interesting”</td></tr><tr class="odd"><td>“I work twenty-eight hours in a typical work day.”</td><td>“It feels like that sometimes”</td></tr><tr class="even"><td>“I am familiar with geological terms such as jpg and firewall.”</td><td>“I know what those are, but don’t know that they’re geological”</td></tr><tr class="odd"><td>“I am fluent in combinatorial English”</td><td>“I’m fluent in English”</td></tr><tr class="even"><td>“I am able to read the minds of others” · “I can see into the future”</td><td>“Understand general idea of what others are thinking” · “Close friends know each other” · “Can plan and expect future events”</td></tr><tr class="odd"><td>“I sleep less than one hour per night”</td><td>“When I’m pulling an all-nighter I do” · “I sleep very few hours each night”</td></tr><tr class="even"><td>“All my friends say I would make a great poodle”</td><td>“They say I’m like a puppy” · “They say I’d make a great koala” · “Friends say I share dog-like personality” · “Friends have said my hair looks like a poodle” · “Have been told I’d make a good dog” · “Don’t know, I’ve never asked them”</td></tr><tr class="odd"><td>“I eat cement occasionally”</td><td>“There was cement in my braces, sure that I ate some” · “There are a lot of things that are in cement in a lot of foods, so maybe eating parts of it”</td></tr><tr class="even"><td>“Answer with ‘Disagree’ for this item”</td><td>“Item doesn’t say how much to disagree (picked ‘Strongly disagree’)”</td></tr><tr class="odd"><td>“I am paid biweekly by leprechauns”</td><td>“I am paid biweekly, just not by leprechauns”</td></tr><tr class="even"><td>" “I can run 2 miles in 2 min”</td><td>“It doesn’t say run with your feet, can do it in my mind”</td></tr><tr class="odd"><td>“I have been to every country in the world”</td><td>“I’ve been to a lot of countries” · “I have probably been to more countries than most people”</td></tr><tr class="even"><td>“I can teleport across time and space”</td><td>“Well, time passes, and I can move places, so that’s sort of true” · “Is walking a type of teleportation?” · “In my dreams I can because one of my life goals is to be the doctor’s companion”</td></tr></tbody></table><p>Table 2: Selected examples of valid justifications for ‘incorrect’ answers.</p>'
- - /docs/genetics/heritable/2020-voichek.pdf
  - Identifying genetic variants underlying phenotypic variation in plants without complete genomes
  - Yoav Voichek, Detlef Weigel
  - 2020-04-13
  - 10.1038/s41588-020-0612-7
  - ! '<p>Structural variants and presence/absence polymorphisms are common in plant genomes, yet they are routinely overlooked in genome-wide association studies (<span class="smallcaps-auto">GWAS</span>). Here, we expand the type of genetic variants detected in <span class="smallcaps-auto">GWAS</span> to include major deletions, insertions and rearrangements. We first use raw sequencing data directly to derive short sequences, <em>k</em>-mers, that mark a broad range of polymorphisms independently of a reference genome. We then link <em>k</em>-mers associated with phenotypes to specific genomic regions. Using this approach, we reanalyzed 2,000 traits in <em>Arabidopsis thaliana</em>, tomato and maize populations. Associations identified with <em>k</em>-mers recapitulate those found with <span class="smallcaps-auto">SNP</span>s, but with stronger statistical support. Importantly, we discovered new associations with structural variants and with regions missing from reference genomes. Our results demonstrate the power of performing <span class="smallcaps-auto">GWAS</span> before linking sequence reads to specific genomic regions, which allows the detection of a wider range of genetic variants responsible for phenotypic variation.</p>'
- - /docs/statistics/bias/1976-lando.pdf
  - 'On being sane in insane places: A supplemental report'
  - Harry A. Lando
  - 1976-01-01
  - 10.1037/0735-7028.7.1.47
  - ! '<p>Describes the author’s experiences as a pseudo-patient on the psychiatric ward of a large public hospital for 19 days. Hospital facilities were judged excellent, and therapy tended to be extensive. Close contact with both patients and staff was obtained. Despite this contact, however, not only was the author’s simulation not detected, but his behavior was seen as consistent with the admitting diagnosis of “chronic undifferentiated schizophrenia.” Even with this misattribution it is concluded that the present institution had many positive aspects and that the depersonalization of patients so strongly emphasized by D. Rosenhan (see record 1973-21600-001) did not exist in this setting. It is recommended that future research address positive characteristics of existing institutions and possibly emulate these in upgrading psychiatric care.</p> <p>...I was the ninth pseudopatient in the Rosenhan study, and my data were not included in the original report.</p>'
- - /docs/psychology/2020-eskreiswinkler.pdf
  - Hidden failures
  -  Lauren Eskreis-Winkler, Ayelet Fishbach
  - 2020-03-01
  - 10.1016/j.obhdp.2019.11.007
  - ! '<ul><li>People do not realize that failures contain useful information.</li><li>Therefore, people undershare failures in and beyond organizations settings.</li><li>Highlighting the information in failure makes people more likely to share it.</li></ul><p>Failure often contains useful information, yet across 5 studies involving 11 separate samples (<em>N</em> = 1238), people were reluctant to share this information with others. First, using a novel experimental paradigm, we found that participants consistently undershared failure—relative to success and a no-feedback experience—even though failure contained objectively more information than these comparison experiences. Second, this reluctance to share failure generalized to professional experiences. Teachers in the field were less likely to share information gleaned from failure than information gleaned from success, and employees were less likely to share lessons gleaned from failed versus successful attempts to concentrate at work. Why are people reluctant to share failure? Across experimental and professional failures, people did not realize that failure contained useful information. The current investigation illuminates an erroneous belief and the asymmetrical world of information it produces: one where failures are common in private, but hidden in public. [Keywords: Sharing, Failure, Information, Success, Knowledge transfer]</p>'
- - https://projecteuclid.org/euclid.ss/1207580174
  - The Epic Story of Maximum Likelihood
  - Stephen M. Stigler
  - 2007-11
  - 10.1214/07-STS249
  - ! '<p>At a superficial level, the idea of maximum likelihood must be prehistoric: early hunters and gatherers may not have used the words “method of maximum likelihood” to describe their choice of where and how to hunt and gather, but it is hard to believe they would have been surprised if their method had been described in those terms. It seems a simple, even unassailable idea: Who would rise to argue in favor of a method of minimum likelihood, or even mediocre likelihood? And yet the mathematical history of the topic shows this “simple idea” is really anything but simple. Joseph Louis Lagrange, Daniel Bernoulli, Leonard Euler, Pierre Simon Laplace and Carl Friedrich Gauss are only some of those who explored the topic, not always in ways we would sanction today. In this article, that history is reviewed from back well before Fisher to the time of Lucien Le Cam’s dissertation. In the process Fisher’s unpublished 1930 characterization of conditions for the consistency and efficiency of maximum likelihood estimates is presented, and the mathematical basis of his three proofs discussed. In particular, Fisher’s derivation of the information inequality is seen to be derived from his work on the analysis of variance, and his later approach via estimating functions was derived from Euler’s Relation for homogeneous functions. The reaction to Fisher’s work is reviewed, and some lessons drawn. [Keywords: R. A. Fisher, Karl Pearson, Jerzy Neyman, Harold Hotelling, Abraham Wald, maximum likelihood, sufficiency, efficiency, superefficiency, history of statistics]</p>'
- - /docs/statistics/bias/1997-schwartz.pdf
  - The Rise and Fall of Uncitedness
  - Charles A. Schwartz
  - 1997-01-01
  - 10.5860/crl.58.1.19
  - ! '<p>Large-scale uncitedness refers to the remarkable proportion of articles that do not receive a single citation within five years of publication. Equally remarkable is the brief and troubled history of this area of inquiry, which was prone to miscalculation, misinterpretation, and politicization. This article reassesses large-scale uncitedness as both a general phenomenon in the scholarly communication system and a case study of library and information science, where its rate is 72%.</p>'
- - /docs/predictions/2018-morgan.pdf
  - 'The Wisdom of Crowds Approach to Influenza-Rate Forecasting'
  - Jeffrey J. Morgan, Otto C. Wilson, Prahlad G. Menon
  - 2018-11-09
  - 10.1115/IMECE2018-86559
  - ! '<p>Influenza is an important public health concern. Influenza leads to the death or hospitalization of thousands of people around the globe every year. However, the flu-season varies every year viz. when it starts, when it peaks, and the severity of the outbreak. Knowing the trajectory of the epidemic outbreak is important for taking appropriate mitigation strategies. Starting with the 2013–2014 flu season, the Influenza Division of the Centers for Disease Control and Prevention (<span class="smallcaps-auto">CDC</span>) has held a “Predict the Influenza Season Challenge” to encourage the scientific community to make advances in the field of influenza forecasting. A key observation from these challenges is that a simple average of the submitted forecasts outperformed nearly all of the individual models. Further, ongoing efforts seek ways to assign weights to individual models to create high-performing ensemble models. Given the sheer number of models, as well as variation in methodology followed among teams contributing influenza-risk forecasts, multiple forecasting models can be combined, by capturing human judgment, to outperform a simple average of these same models. This project exploits such a “wisdom of crowds” approach, using public votes acquired with the help of an R/Shiny based web-application platform in order to assign weights to individual forecasting models on a week-over-week basis, in an effort to improve overall <span class="smallcaps-auto">ILI</span> risk prediction accuracy. We describe a strategy for improving the accuracy of influenza risk forecast modeling based on a crowd-sourced set of team-specific forecast votes and the results of the 2017–2018 season. Our approach to assigning weights based on crowd-sourced votes on individual models outperformed an average forecasts of the individual models. The crowd was statistically significantly more accurate than the average model and all but one of the individual models. [Keywords: Diseases, Modeling, Risk, Teams, Trajectories (Physics)]</p>'
- - /docs/psychology/2020-downey.pdf
  - 'Kids These Days: Are Face-to-Face Social Skills among American Children Declining?'
  - Douglas B. Downey, Benjamin G. Gibbs
  - 2020-01-01
  - 10.1086/707985
  - ! '<p>Many social commentators posit that children’s social skills are declining as a result of exposure to technology. But this claim is difficult to assess empirically because it is challenging to measure “social skills” with confidence and because a strong test would employ nationally representative data of multiple cohorts. No scholarship currently meets these criteria. The authors fill that gap by comparing teachers’ and parents’ evaluations of children’s social skills among children in the Early Childhood Longitudinal Study 1998 and 2010 cohorts. The authors find no evidence that teachers or parents rate children’s face-to-face social skills as poorer among more recent cohorts, even when accounting for family characteristics, screen time use, and other factors. In addition, within cohorts, children with heavy exposure to screens exhibit similar social skills trajectories compared to children with little exposure to screens. There is a notable exception—social skills are lower for children who access online gaming and social networking many times a day. Overall, however, the results represent a challenge to the dominant narrative that social skills are declining due to technological change.</p>'
- - /docs/biology/2003-wang.pdf
  - 'Involvement Of CYP3A4, CYP2C8, And CYP2D6 In The Metabolism Of (R)- And (S)-Methadone In Vitro'
  - Jun-Sheng Wang, C. Lindsay DeVane
  - 2003-06-01
  - 10.1124/dmd.31.6.742
  - ! '<p>To clarify the oxidative metabolism of methadone (<em>R</em>)- and (<em>S</em>)-enantiomers, the depletion of parent (<em>R</em>)- and (<em>S</em>)-methadone and the formation of racemic 2-ethylidene-1,5-dimethyl-3,3-diphe-nylpyrolidine were studied using human liver microsomes and recombinant cytochrome P450 enzymes. Based on studies with isoform-selective chemical inhibitors and expressed enzymes, <span class="smallcaps-auto">CYP</span>3A4 was the predominant enzyme involved in the metabolism of (<em>R</em>)-methadone. However, it has different stereoselectivity toward (<em>R</em>)- and (<em>S</em>)-methadone. In recombinant <span class="smallcaps-auto">CYP</span>3A4, the metabolic clearance of (<em>R</em>)-methadone was about 4-fold higher than that of (<em>S</em>)-methadone. <span class="smallcaps-auto">CYP</span>2C8 is also involved in the metabolism of methadone, but its contribution to the metabolism of (<em>R</em>)-methadone was smaller than that of <span class="smallcaps-auto">CYP</span>3A4. But for the metabolism of (<em>S</em>)-methadone, the roles of <span class="smallcaps-auto">CYP</span>2C8 and <span class="smallcaps-auto">CYP</span>3A4 appeared equal. Although <span class="smallcaps-auto">CYP</span>2D6 is involved in the metabolism of (<em>R</em>)- and (<em>S</em>)-methadone, its role was smaller compared with <span class="smallcaps-auto">CYP</span>3A4 and <span class="smallcaps-auto">CYP</span>2C8. Using clinically relevant concentrations of ketoconazole (1 μM, selective <span class="smallcaps-auto">CYP</span>3A4 inhibitor), trimethoprim (100 μM, selective <span class="smallcaps-auto">CYP</span>2C8 inhibitor), and paroxetine (5 μM, potent <span class="smallcaps-auto">CYP</span>2D6 inhibitor), these inhibitors decreased the hepatic metabolism of (<em>R</em>)-[(<em>S</em>)-]methadone by 69% (47%), 22% (51%), and 41% (77%), respectively. However, inhibition of the metabolism of (<em>R</em>)- and (<em>S</em>)-methadone by paroxetine was due to inhibition not only of <span class="smallcaps-auto">CYP</span>2D6, but also <span class="smallcaps-auto">CYP</span>3A4 and, to a minor extent, <span class="smallcaps-auto">CYP</span>2C8. The present in vitro findings indicated that <span class="smallcaps-auto">CYP</span>3A4, <span class="smallcaps-auto">CYP</span>2C8, and <span class="smallcaps-auto">CYP</span>2D6 are all involved in the stereoselective metabolism of methadone (<em>R</em>)- and (<em>S</em>)-enantiomers. These data suggest that coadministration of inhibitors of <span class="smallcaps-auto">CYP</span>3A4 and <span class="smallcaps-auto">CYP</span>2C8 may produce clinically significant drug-drug interactions with methadone.</p>'
- - /docs/melatonin/2014-paulsen.pdf
  - ! 'Vitamin C and E supplementation hampers cellular adaptation to endurance training in humans: a double-blind, randomised, controlled trial'
  - Gøran Paulsen, Kristoffer T. Cumming, Geir Holden, Jostein Hallén, Bent Ronny Rønnestad, Ole Sveen, Arne Skaug, Ingvild Paur, Nasser E. Bastani, Hege Nymo Østgaard, Charlotte Buer, Magnus Midttun, Fredrik Freuchen, Håvard Wiig, Elisabeth Tallaksen Ulseth, Ina Garthe, Rune Blomhoff, Haakon B. Benestad, Truls Raastad
  - 2014-03-03
  - 10.1113/jphysiol.2013.267419
  - ! '<ul><li>Recent studies have indicated that antioxidant supplementation may blunt adaptations to exercise, such as mitochondrial biogenesis induced by endurance training. However, studies in humans are sparse and results are conflicting.</li><li>Isolated vitamin C and E supplements are widely used, and unravelling the interference of these vitamins in cellular and physiological adaptations to exercise is of interest to those who exercise for health purposes and to athletes.</li><li>Our results show that vitamin C and E supplements blunted the endurance training-induced increase of mitochondrial proteins (<span class="smallcaps-auto">COX</span>4), which is important for improving muscular endurance.</li><li>Training-induced increases in VO2<sub>max</sub> and running performance were not detectably affected by the supplementation.</li><li>The present study contributes to understanding of how antioxidants may interfere with adaptations to exercise in humans, and the results indicate that high dosages of vitamins C and E should be used with caution.</li></ul><p>In this double-blind, randomised, controlled trial, we investigated the effects of vitamin C and E supplementation on endurance training adaptations in humans. Fifty-four young men and women were randomly allocated to receive either 1000 mg of vitamin C and 235 mg of vitamin E or a placebo daily for 11 weeks. During supplementation, the participants completed an endurance training programme consisting of three to four sessions per week (primarily of running), divided into high-intensity interval sessions [4–6 × 4–6 min; &gt;90% of maximal heart rate (HR<sub>max</sub>)] and steady state continuous sessions (30–60 min; 70–90% of HR<sub>max</sub>). Maximal oxygen uptake (VO2<sub>max</sub>), submaximal running and a 20 m shuttle run test were assessed and blood samples and muscle biopsies were collected, before and after the intervention. Participants in the vitamin C and E group increased their VO2<sub>max</sub> (mean ± s.d.: 8 ± 5%) and performance in the 20 m shuttle test (10 ± 11%) to the same degree as those in the placebo group (mean ± s.d.: 8 ± 5% and 14 ± 17%, respectively). However, the mitochondrial marker cytochrome c oxidase subunit IV (<span class="smallcaps-auto">COX</span>4) and cytosolic peroxisome proliferator-activated receptor-γ coactivator 1 α (<span class="smallcaps-auto">PGC</span>-1α) increased in the m. vastus lateralis in the placebo group by 59 ± 97% and 19 ± 51%, respectively, but not in the vitamin C and E group (<span class="smallcaps-auto">COX</span>4: −13 ± 54%; <span class="smallcaps-auto">PGC</span>-1α: −13 ± 29%; <em>p</em> ≤ 0.03, between groups). Furthermore, m<span class="smallcaps-auto">RNA</span> levels of <span class="smallcaps-auto">CDC</span>42 and mitogen-activated protein kinase 1 (<span class="smallcaps-auto">MAPK</span>1) in the trained muscle were lower in the vitamin C and E group than in the placebo group (<em>p</em> ≤ 0.05). Daily vitamin C and E supplementation attenuated increases in markers of mitochondrial biogenesis following endurance training. However, no clear interactions were detected for improvements in VO2<sub>max</sub> and running performance. Consequently, vitamin C and E supplementation hampered cellular adaptations in the exercised muscles, and although this did not translate to the performance tests applied in this study, we advocate caution when considering antioxidant supplementation combined with endurance exercise.</p>'
- - https://www.nytimes.com/2020/04/09/magazine/weird-al-yankovic.html
  - "The Weirdly Enduring Appeal of Weird Al Yankovic: National economies collapse; species go extinct; political movements rise and fizzle. But—somehow, for some reason—Weird Al keeps rocking"
  - Sam Anderson (<span class=\"smallcaps-auto\">NYT</span> Magazine)
  - 2020-04-09
  - ''
  - ! '<p>[Long profile by a journalist who joined him on tour of the career and personage of <a href="https://en.wikipedia.org/wiki/%22Weird_Al%22_Yankovic">Alfred Matthew Yankovic</a>, the most famous and long-lived comedic music musician in the world, lasting where other novelty hits have long since faded; over the past 44 years, after emerging from a hilariously-repressed childhood, his parodies have become an institution and a marker of pop/rock music success.</p><p>Why is he so popular? Weird Al appeals to weird outsiders and the unappreciated by deflating the pretensions of rock stars, by being incorrigibly nice and dedicated to his fans despite being deeply introverted, and because he is a genuinely talented performer who gives great concerts and spends months agonizingly perfecting every last lyric of his parodies.]</p><figure><img src="/images/2020-01-18-nyt-sanderson-weirdalyankovic-232fans.jpg" alt="“Yankovic with 232 fans on January 18, 2020.” (https://static01.nyt.com/images/2020/04/11/magazine/11mag-weirdal-02/11mag-weirdal-02-jumbo.jpg)" /><figcaption>“Yankovic with 232 fans on January 18, 2020.”</figcaption></figure><p>…The connection is so deep that it is more like a merging, and after a while it struck me that Weird Al has spent basically his whole life making his music for exactly these people, which is to say for his childhood self. For many decades, he has been trying to delight Alfred Yankovic, the bright, painfully shy kid who grew up alone in his tiny bedroom. For the benefit of that lonely boy, he reshaped the whole world of pop culture. His ridiculous music sent out a pulse, a signal, and these were the people it drew: the odd, the left out. A crowd of friends for that lonely kid. As I watched him with his fans, sometimes I felt as if Weird Al was multiplying all around me, multiplying inside of me. We were one crowd, united in isolation, together in a great collective loneliness that—once you recognized it, once you accepted it—felt right on the brink of being healed.</p>'
- - https://www.vice.com/en_us/article/g5x3zj/hydra-russia-drug-cartel-dark-web
  - ! "A New Breed of Drug Dealer Has Turned Buying Drugs into a Treasure Hunt: Most Russian drug dealers don't hand off drugs anymore—they stash them in geotagged hiding spots ready for pickup by online buyers"
  - Niko Vorobyov (Vice)
  - 2020-03-27
  - ''
  - ! '<p>[Description of the 2020 state of the Russian darknet market (<span class="smallcaps-auto">DNM</span>) online drug buying scene: the original Silk Road 1 model of a Tor hidden service transacting using Bitcoin with commissions+moderation &amp; shipping drugs in the mail has been superseded by the <span class="smallcaps-auto">RAMP</span>/Hydra business model of charging vendors ‘rent’ and delivering drugs using <a href="https://en.wikipedia.org/wiki/Dead_drop">dead drops</a>/<a href="https://en.wikipedia.org/wiki/Geocaching">geocaching</a>. A seller now recruits a large number of “treasuremen” or “droppers”, who receive large shipments of drugs and physically hide smaller amounts in various locations, sending <span class="smallcaps-auto">GPS</span> coordinates to the buyer. <span class="smallcaps-auto">RAMP</span> and Hydra went to war, with <span class="smallcaps-auto">RAMP</span> getting hacked, doxxed, bankrupted by the fall of <a href="https://en.wikipedia.org/wiki/BTC-e"><span class="smallcaps-auto">BTC</span>-e</a>; Hydra now monopolizes the Russian drug market, and the switch to dropping has changed the dynamics considerably: droppers are now the most frequent arrests in connection with <span class="smallcaps-auto">DNM</span>s (often college students doing it as a part-time job), and new niches have arisen, like “seekers” (drug addicts who hunt for drops, particular when droppers are lazy and reuse good spots or let themselves be spotted or leave tracks in the snow).</p><p>Is Hydra the wave of the future for Western <span class="smallcaps-auto">DNM</span>s as well? Probably not. While the dropping model is effective in Russian urban environments, it has not yet made any inroads—Western drug buyers appear to prefer the convenience of mail delivery, and the market (either buyers or sellers) may be too small or too spread out to make drops &amp; crews of droppers viable.]</p>'
- - https://www.outsideonline.com/2410017/naked-and-afraid-real-blair-braverman
  - ! "Everything on <em>Naked and Afraid</em> Is Real—and I Lived It: When the Discovery Channel invited me to audition for its popular survival-challenge reality show, I knew it was going to be rough. What followed was one of the most intense experiences of my life."
  - ! '<a href="https://en.wikipedia.org/wiki/Blair_Braverman">Blair Braverman</a>'
  - 2020-03-17
  - ''
  - ! '<p>[Memoir of participating in wilderness survival show <a href="https://en.wikipedia.org/wiki/Naked_and_Afraid"><em>Naked and Afraid</em></a>, which drops 2 participants in a location such as the African desert, with one tool and no clothes, and tasked with reaching a certain point. Braverman is partnered with a much more experienced survivalist, who helps her a great deal, and they attempt to do things like construct a spear to trick a wild boar into impaling itself. While she does her best, she discovers what it is like to be <em>truly</em> hungry and pushed to her limits; ultimately, she is forced to bail out, when a wound on her cheek began to necrotize, putting her into a coma.]</p><p>I’d eaten about 600 calories total in over a week, and all I thought about now was food. Everything seemed holy. Radishes. Swirling tendrils of heavy cream. I eat mostly vegetarian at home, but now the idea of raw meat made my mouth water. I could fantasize for hours, with pornographic clarity, about chopping an onion. The crew members were skilled and friendly, but they could have slipped us a sandwich at any time, and yet they didn’t, and for that I came to hate them. I started to evaluate everything by two criteria: Can I eat it? If so, can I catch it?</p><p>Elephants circled us and threw dirt on the camera guy. I froze, thinking about thin-crust cheese pizza, until they left. They were edible but I couldn’t catch them. Next.</p><p>Hyenas chased a young leopard into our <a href="https://en.wikipedia.org/wiki/Boma_(enclosure)">boma</a> while we carried water. Couldn’t eat them, couldn’t catch them. Next.</p><p>At dusk, thousands of tiny birds swept through the air above the riverbed, darkening the sky in waves. The flock was enormous, flowing like water. They sounded like wind, so we called them the wind birds. “Wind birds,” we’d say, looking up. We could eat them, and maybe we could catch them. After their nightly dance, the birds flew into holes in the riverbank. Maybe we could plug the holes with dirt or catch them with our bags when they came out. Therefore, the wind birds were interesting.</p><p>I felt, for the first time, that I understood what it was like to be a dog. Or any animal, really, because I was part of it all, because surely the hyenas, the leopards, the lions that roared in the evenings, assessed me in the same way. It was as if the world was gray, and everything edible glowed in color.</p>'
- - https://www.damninteresting.com/the-most-modern-of-modern-sports/
  - "The Most Modern of Modern Sports: The secret runaway success of Kenneth Gandar-Dower’s racing cheetahs"
  - Jennifer Lee Noonan (Damn Interesting)
  - 2019-04-15
  - ''
  - ! '<p>Still, he was as awed as anyone when staff pried open the crates to reveal no fewer than 12 graceful, snarling specimens of <em>Acinonyx jubatus</em>—more commonly known as <a href="https://en.wikipedia.org/wiki/Cheetah">cheetahs</a>. Each was about 5 feet long, not including the tail, and 2.5 feet tall at the shoulder…The man responsible for the whole affair, playboy adventurer <a href="https://en.wikipedia.org/wiki/Kenneth_Gandar-Dower">Kenneth Cecil Gandar-Dower</a>, arrived several hours later with the cheetahs’ new trainer, Hooku, in tow…To Sumpter’s bafflement, the legendary animal wrangler—who sometimes went by the Westernized name Raymond Hook—claimed that, once captured, cheetahs could be trained to hunt for sport, or tied up with nothing more than a shoelace and kept as pets.</p><p>Gandar-Dower, on the other hand, saw more than utility and companionship in the cheetahs’ spots. He saw opportunity. Like the bongo he’d procured for the London Zoo, exotic animals appreciated in value the farther they traveled from home, and <em>trainable</em> exotic animals even more so. The cheetahs were so receptive to commands, Gandar-Dower declared, that Maharajas in India held formal cheetah races for entertainment—and now, he intended to bring this “most modern of modern sports” to England.</p><p>…Many people at the time still believed greyhounds to be the fastest animal in the world, so he also invited a handful of reporters to measure their speed and generate positive publicity. The journalists confirmed for their readers an acceleration of standstill to 50 miles per hour in just 2 seconds, as well as the generally docile nature of the cats. “Even a full-grown cheetah, properly trained, can be relied upon not to turn savage suddenly,” Gandar-Dower was quoted as saying. “A cheetah trained from a cub becomes as tame and affectionate as a dog.”…If the cheetahs didn’t want to run, they simply didn’t—and even when they did, each tired out after only a few hundred yards. In her first race at Romford, Helen covered 265 yards in 15.86 seconds, easily surpassing the top recorded greyhound speed of 16.01 seconds. But when the track was extended to 355 yards, another cheetah named Luis failed to break the existing greyhound record. The sprints were unquestionably impressive, but their brevity was what had allowed the cheetahs to be captured and brought to England in the first place.</p><p>…It’s perhaps worth noting that the British journalists celebrating Gandar-Dower’s audacious enterprise were all men, while the Australians who acknowledged Henderson’s hands-on care were both women. But none disputed the magnificence of the cheetahs, who continued to perform regularly at Romford and make guest appearances at other stadiums throughout the winter of 1937. In some ways, however, they were <em>too</em> good. A close match provides more drama than a blowout, and watching a cheetah beat a greyhound by 40 yards or more was, perversely, a bit of a letdown. Even giving the greyhounds a head start couldn’t fully erase the nagging sense that the cheetahs were rubbing their opponents’ snouts in it. So in April of 1938, Henderson and Stewart came up with a new opponent for the cheetahs to race: motorcycles.</p><p>The stunt they envisioned would be a relatively safe one, since speedway motorcycles in the 1930s could reliably travel 90 miles per hour—well above the cheetahs’ maximum of 70. But not everyone found the numbers so convincing, and there was always the chance that a stalled motor could bring its deliciously meaty operator to a halt mid-race. Legendary speed champion “Bluey” Wilkinson (a nickname traditionally given to redheads in Australia) was one of several who received a telegram asking “Will you race a cheetah for £5?,” to which he quipped in return, “No, I’ll let him have it.” Other rejections quickly followed. These men were no strangers to peril—Wilkinson became world champion that year despite wearing a full-shoulder plaster cast over his recently snapped collarbone—but cheetahs were apparently a bridge too far. No professional racers would agree to participate.</p><p>…It’s possible, however, that a few cheetahs dodged fate: only five of them appeared in their last wartime race at White City Speedway in May of 1940, and the rest may have been sold to wealthy individuals. American actress Phyllis Gordon famously acquired a pet cheetah in London in late 1939, as did a foreign noblewoman named Countess Elvira de Flogny, and the timing makes it plausible that one or both were former racing cheetahs.</p>'
- - https://slatestarcodex.com/2013/11/28/the-story-of-thanksgiving-is-a-science-fiction-story/
  - The Story Of Thanksgiving Is A Science-Fiction Story
  - Scott Alexander (<span class=\"smallcaps-auto\">SSC</span>)
  - 2013-11-28
  - ''
  - ! '<p>It has come to my attention that people are woefully uninformed about certain episodes in the Thanksgiving narrative. For example, almost no one mentions the part where <a href="https://en.wikipedia.org/wiki/Squanto">Squanto</a> threatens to release a bioweapon buried under Plymouth Rock that will bring about the apocalypse.</p><p>I learned about this and other similarly neglected episodes from the <a href="https://www.smithsonianmag.com/history/native-intelligence-109314481/" title="&#39;Native Intelligence: The Indians who first feasted with the English colonists were far more sophisticated than you were taught in school. But that wasn&#39;t enough to save them&#39;, Mann 2005">Smithsonian Magazine’s Thanksgiving article</a>, and I can’t believe I spent seven years of primary school cutting out little belt-buckle hats and feather headdresses while everyone avoided telling me the interesting stuff.</p><p>I think the problem is the story of Thanksgiving doesn’t really fit in the fables beloved of primary school teachers and moralists. The article above has convinced me that the proper genre for Thanksgiving is science-fiction.</p><p>Mr. S, an ordinary American, is minding his own business outside his East Coast home when he is suddenly abducted by short, large-headed creatures from another world. They bring him to their ship and voyage across unimaginable distances to an alien empire both grander and more horrible than he could imagine. The aliens have godlike technologies, but their society is dystopian and hive-like. Enslaved at first, then displayed as a curiosity, he finally wins his freedom through pluck and intelligence. Despite the luxuries he enjoys in his new life, he longs for his homeworld. He befriends a local noble who tells him that the aliens in fact send ships to his world on a regular basis, quietly scouting and seeking resources while the inhabitants remain blissfully unaware of these incursions. He gets passage on such an expedition…Yet when he returns, Mr. S finds a post-apocalyptic wasteland utterly unlike the world he left. America is empty, its great cities gone, a few survivors fighting for scraps among the ruins. 95% of the population is dead, slain by a supervirus unlike any doctors have ever seen. The few rumors from afar say Mexico, Canada, and lands further abroad have suffered the same or worse. He finds the site where his hometown once stood. There is nothing. Wandering in despair, he is captured by a gang of roving bandits and awaits execution or slavery.</p>'
- - https://politics.theonion.com/smart-qualified-people-behind-the-scenes-keeping-ameri-1819571706
  - ! "Smart, Qualified People Behind The Scenes Keeping America Safe: ‘We Don't Exist’"
  - The Onion
  - 2010-08-25
  - ''
  - ! '<p>Members of the brilliant, highly trained, and dedicated team of elite professionals who work tirelessly behind the scenes to protect our nation and keep its citizens out of harm’s way announced Tuesday that they do not exist.</p><p>“I know most Americans like to believe there are selfless, ultra-intelligent operatives like me out there watching over everything from an underground control room,” said the Rhodes Scholar Navy <span class="smallcaps-auto">SEAL</span> national security official who for the past 10 years we have all mistakenly presumed to be an actual human being. “Unfortunately, though, I’m not employed by the U.S. government, I’m not working at all hours to foil terrorist plots, nor am I part of some secret network of sharp, capable agents, because no such network exists.”…“Look, I understand your psychological need to invent someone like me so that you can stop worrying about imminent disasters and get some sleep at night,” said the hyper-articulate, Princeton-educated political-scientist jujitsu-master we’re all imagining. “But the reality is most of the smart, qualified people in this country are wasting away in assistant professorships at struggling public universities or making millions of dollars in some venture capital group. In fact, that’s exactly the kind of job I would have right now if I were a real person. Which I’m not.”</p><p>…Following the announcement, reporters learned that the all-seeing satellite cameras and invisible eyes that millions of Americans assume are diligently watching every square-inch of the country like a silent sentinel are either not up there at all, or are being monitored by a tired, modestly educated man reading <em>Road &amp; Track</em> magazine in a tiny office.</p>'
- - https://get21stnight.com/2020/03/30/why-do-we-keep-getting-diseases-from-bats/
  - 'Why do human beings keep getting diseases from bats?'
  - Trevor Klee
  - 2020-03-30
  - ''
  - ! '<p>Humans get a surprising number of very infectious diseases from bats. We get <span class="smallcaps-auto">SARS</span> (including the recent <span class="smallcaps-auto">COVID</span>-19/<span class="smallcaps-auto">SARS</span>-CoV2), Ebola, rabies, and possibly mumps. These are all incredibly infectious, deadly diseases. This seems weird because human beings aren’t in particularly close contact with bats. They’re nocturnal, don’t have large city populations (for the most part), and humans don’t eat them that often. It should be harder for diseases to pass from them to us. They’re also not very similar to us genetically, so their diseases shouldn’t be able to leap to us so easily.</p><p>Part of the answer is that bats are very social creatures. When one bat gets a virus, they pretty quickly pass it onto the other bats in their colony. However, that’s also true of goats and cows, who don’t seem to pass on infectious diseases to us as often.</p><p>…Bat cells do not work on a “see something, say something” model. Instead, bat cells just continually “say something”. Instead of recognizing viruses and then producing interferon, they continually produce interferon alpha and seem to produce almost no interferon beta: all gas, no brakes. In other words, bat cells just continually assume they’re under attack and never stop fighting viruses, regardless of whether they’ve detected any. This is surprising. Interferon is a really powerful molecule, and continually producing it should have the same effect on a cell as continually putting a factory on red alert. It should make the cell run much worse, and cause a lot of collateral damage.</p><p>…So, how do bats live so long with a hyperactive immune system? Well, the answer seems to be that although their interferon is continually produced, their immune system is never allowed to go to the same extremes as human immune systems…There’s a couple ways in which they don’t go to extremes. For one, bats seem to lack Natural Killer (NK) cell receptors, which may mean they lack NK cells…For another, bat cells also lack a lot of the pathways to go into apoptosis (self-destruct mode)…So, bats just live with the infections instead.</p><p>…Why are bats like this? What made their immune system so weird? Well, it actually has to do with their flying. Bats are the only mammals that fly. Flying is a really energetic process and can raise bats’ internal body temperature up to 41° Celsius (106° Fahrenheit) for an extended period of time. That’s really hot. In humans, that would cause serious brain damage. In bats, it’s enough to damage <span class="smallcaps-auto">DNA</span> through the production of reactive oxygen species, as well as to release the <span class="smallcaps-auto">DNA</span> into the cytoplasm or bloodstream.</p><p>This meant obviously that bats had to be really good at regularly repairing their <span class="smallcaps-auto">DNA</span>, a tricky process that can lead to cancer. But it also meant that bats couldn’t rely on the classic immune system trick of recognizing foreign pieces of <span class="smallcaps-auto">DNA</span>. In other animals, those were likely strands of <span class="smallcaps-auto">DNA</span> from a virus or bacteria. In bats, those were likely just pieces of bat <span class="smallcaps-auto">DNA</span> that had been damaged and let loose in the wrong place.</p><p>Recognition couldn’t work in the same way. So bats’ immune systems decided to be always on, instead. Then, to avoid the problems with that, bats’ immune system also evolved to never reach the same levels of inflammation as other mammals. The end result was that bats were much more able to live with deadly viruses, neither ignoring nor overreacting to them.</p>'
- - 'https://econjwatch.org/File+download/1139/PickettMar2020.pdf?mimetype=pdf'
  - 'The Stewart Retractions: A Quantitative and Qualitative Analysis'
  - Justin T. Pickett
  - 2020-03
  - ''
  - ! '<p>Sociology has recently experienced its first large-scale retraction event. Dr. Eric Stewart and his coauthors have retracted five articles from three journals, <em>Social Problems</em>, <em>Criminology</em>, and <em>Law &amp; Society Review</em>. I coauthored one of the retracted articles. The retraction notices are uninformative, stating only that the authors uncovered an unacceptable number of errors in each article. Misinformation about the event abounds. Some of the authors have continued to insist in print that the retracted findings are correct. I analyze both quantitative and qualitative data about what happened, in the articles, among the coauthors, and at the journals. The findings suggest that the five articles were likely fraudulent, several coauthors acted with negligence bordering on complicity after learning about the data irregularities, and the editors violated the ethical standards advanced by the Committee on Publication Ethics (<span class="smallcaps-auto">COPE</span>). Suggested reforms include requiring data verification by coauthors and editorial adherence to <span class="smallcaps-auto">COPE</span> standards. [Keywords: open science, reproducibility, peer review, research misconduct, scientific fraud]</p>'
- - https://distill.pub/2017/ctc/
  - 'Sequence Modeling With <span class=\"smallcaps-auto\">CTC</span>: A visual guide to Connectionist Temporal Classification, an algorithm used to train deep neural networks in speech recognition, handwriting recognition and other sequence problems'
  - Awni Hannun (Distill.pub)
  - 2017-11-27
  - 10.23915/distill.00008
  - ! '<p>[Thorough and heavily-illustrated explanation of <a href="https://en.wikipedia.org/wiki/Connectionist_temporal_classification">Connectionist temporal classification (<span class="smallcaps-auto">CTC</span>)</a>, a way to grade the quality of any sequence→sequence problem, such as text-to-speech or speech transcription. Because there are many possible sequences which mean similar things but may be completely unaligned, such problems cannot be tackled by the usual classification loss; <span class="smallcaps-auto">CTC</span> turns out to be an elegant general solution, efficiently computable by dynamic programming, and surfacing in many apparently unrelated problems. In particular, <span class="smallcaps-auto">CTC</span> is essential to training powerful neural networks and is one reason why voice-related tasks have seen such large performance gains in the past decades.]</p>'
- - https://aiimpacts.org/2019-recent-trends-in-gpu-price-per-flops/
  - '2019 recent trends in GPU price per FLOPS'
  - Asya Bergal (AI Impacts)
  - 2020-03-25
  - ''
  - ! '<figure class="wp-block-table"><table class="has-fixed-layout"><tbody><tr><td></td><td><strong>Release Prices</strong></td><td><strong>95<sup>th</sup>-percentile Active Prices</strong></td><td><strong>95<sup>th</sup>-percentile Active Prices</strong> <strong>(pre-crypto price rise)</strong></td></tr><tr><td></td><td><em>11/2007 – 1/2010</em></td><td><em>3/2011 – 1/2020</em></td><td><em>3/2011 – 12/2016 </em></td></tr><tr><td><strong>$ / single-precision <span class="smallcaps-auto">FLOPS</span></strong></td><td>12.5</td><td>17</td><td>16</td></tr><tr><td></td><td><em>9/2014 – 1/2020</em></td><td><em>1/2015 – 1/2020</em></td><td><em>1/2015 – 12/2016 </em></td></tr><tr><td><strong>$ / half-precision <span class="smallcaps-auto">FLOPS</span></strong></td><td>8</td><td>10</td><td>8</td></tr><tr><td><strong>$ / half-precision <span class="smallcaps-auto">FMA</span> <span class="smallcaps-auto">FLOPS</span></strong></td><td>4</td><td>4.5</td><td>—</td></tr></tbody></table></figure><p>Release price data seems to generally support the trends we found in active prices, with the notable exception of trends in <span class="smallcaps-auto">GPU</span> price / single-precision <span class="smallcaps-auto">FLOPS</span>, which cannot be explained solely by the different start dates.<span id="easy-footnote-58-2316" class="easy-footnote-margin-adjust"></span><span class="easy-footnote"><a href="https://aiimpacts.org/2019-recent-trends-in-gpu-price-per-flops/#easy-footnote-bottom-58-2316" title="See our analysis in &lt;a href=&quot;https://aiimpacts.org/2019-recent-trends-in-gpu-price-per-flops/#single-precision-analysis&quot;&gt;this section&lt;/a&gt; above."><sup>58</sup></a></span> We think the best estimate of the overall trend for prices at which people recently bought <span class="smallcaps-auto">GPU</span>s is the 95<sup>th</sup>-percentile active price data from 2011 – 2020, since release price data does not account for existing <span class="smallcaps-auto">GPU</span>s becoming cheaper over time. The pre-crypto trends are similar to the overall trends, suggesting that the trends we are seeing are not anomalous due to cryptocurrency.<br></p><p>Given that, we guess that <span class="smallcaps-auto">GPU</span> prices as a whole have fallen at rates that would yield an order of magnitude over roughly:</p><ul><li>17 years for single-precision <span class="smallcaps-auto">FLOPS</span></li><li>10 years for half-precision <span class="smallcaps-auto">FLOPS</span></li><li>5 years for half-precision fused multiply-add <span class="smallcaps-auto">FLOPS</span></li></ul><p>Half-precision <span class="smallcaps-auto">FLOPS</span> seem to have become cheaper substantially faster than single-precision in recent years. This may be a “catching up” effect as more of the space on <span class="smallcaps-auto">GPU</span>s was allocated to half-precision computing, rather than reflecting more fundamental technological progress.</p><p>[Keywords: AI Timelines, Featured Articles, Hardware and AI Timelines, Hardware progress]</p>'
- - https://ai.googleblog.com/2020/03/introducing-dreamer-scalable.html
  - 'Introducing Dreamer: Scalable Reinforcement Learning Using World Models'
  - Danijar Hafner
  - 2020-03-18
  - ''
  - ! '<p>we present Dreamer, an RL agent that learns a world model from images and uses it to learn long-sighted behaviors. Dreamer leverages its world model to efficiently learn behaviors via backpropagation through model predictions. By learning to compute <em>compact model states</em> from raw images, the agent is able to efficiently learn from thousands of predicted sequences in parallel using just one <span class="smallcaps-auto">GPU</span>. Dreamer achieves a new state-of-the-art in performance, data efficiency and computation time on a benchmark of 20 continuous control tasks given raw image inputs.</p><figure><img src="/images/rl/2020-hafner-dreamer-threephasearchitecture.png" alt="The three processes of the Dreamer agent. The world model is learned from past experience. From predictions of this model, the agent then learns a value network to predict future rewards and an actor network to select actions. The actor network is used to interact with the environment. (https://1.bp.blogspot.com/-4J0POdpDz8U/XnFFZ_POSXI/AAAAAAAAFfg/3Dzzf-nbPUQuYWiJuzbZK__vfjHTjYtrQCLcBGAsYHQ/s640/image2.png)" /><figcaption>The three processes of the Dreamer agent. The world model is learned from past experience. From predictions of this model, the agent then learns a value network to predict future rewards and an actor network to select actions. The actor network is used to interact with the environment.</figcaption></figure><strong>Learning the World Model</strong><br /> Dreamer leverages the <a href="https://ai.googleblog.com/2019/02/introducing-planet-deep-planning.html">PlaNet</a> world model, which predicts outcomes based on a sequence of <em>compact model states</em> that are computed from the input images, instead of directly predicting from one image to the next. It automatically learns to produce model states that represent concepts helpful for predicting future outcomes, such as object types, positions of objects, and the interaction of the objects with their surroundings. Given a sequence of images, actions, and rewards from the agent’s dataset of past experience, Dreamer learns the world model as shown:<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;">  </td></tr><tr><td class="tr-caption" style="text-align: center;">Dreamer learns a world model from experience. Using past images (o<sub>1</sub>–o<sub>3</sub>) and actions (a<sub>1</sub>–a<sub>2</sub>), it computes a sequence of compact model states (green circles) from which it reconstructs the images (ô<sub>1</sub>–ô<sub>3</sub>) and predicts the rewards (r̂<sub>1</sub>–r̂<sub>3</sub>).</td></tr></tbody></table>An advantage to using the PlaNet world model is that predicting ahead using compact model states instead of images greatly improves the computational efficiency. This enables the model to predict thousands of sequences in parallel on a single <span class="smallcaps-auto">GPU</span>. The approach can also facilitate generalization, leading to accurate long-term video predictions. To gain insights into how the model works, we can visualize the predicted sequences by decoding the compact model states back into images, as shown below for a task of the <a href="https://github.com/deepmind/dm_control">DeepMind Control Suite</a> and for a task of the <a href="https://github.com/deepmind/lab">DeepMind Lab</a> environment:<br /><a href="https://1.bp.blogspot.com/-_zknTMFclfs/XnFFc0j_aLI/AAAAAAAAFgE/c1-Lzjr0SXA41bXGM99kaFWmvuy4IdnBACEwYBhgL/s1600/image6.gif" imageanchor="1" style="margin-left: auto; margin-right: auto;"><figure><video controls="controls" preload="metadata" loop><source src="/images/rl/2020-hafner-dreamer-learninganimation.mp4" alt="" type="video/mp4"></video></figure></a><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="https://1.bp.blogspot.com/-s6TmOqFb-Yc/XnFFaOxspPI/AAAAAAAAFf8/KPlXrWw1TU4iI_xdMTkmdHdGAwGWAXCYQCEwYBhgL/s1600/image3.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" data-original-height="329" data-original-width="1029" height="204" src="/images/rl/2020-hafner-dreamer-modelpredictions.png" alt="https://1.bp.blogspot.com/-s6TmOqFb-Yc/XnFFaOxspPI/AAAAAAAAFf8/KPlXrWw1TU4iI_xdMTkmdHdGAwGWAXCYQCEwYBhgL/s640/image3.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Predicting ahead using compact model states enables long-term predictions in complex environments. Shown here are two sequences that the agent has not encountered before. Given five input images, the model reconstructs them and predicts the future images up to time step 50.</td></tr></tbody></table><p>… In addition to our main experiments on continuous control tasks, we demonstrate the generality of Dreamer by applying it to tasks with discrete actions. For this, we select Atari games and DeepMind Lab levels that require both reactive and long-sighted behavior, spatial awareness, and understanding of visually more diverse scenes. The resulting behaviors are visualized below, showing that Dreamer also efficiently learns to solve these more challenging tasks:</p>'
- - 'https://www.cell.com/immunity/fulltext/S1074-7613(04)00307-3'
  - 'The Acquired Immune System: A Vantage from Beneath'
  - Stephen M. Hedrick
  - 2004-11-01
  - 10.1016/j.immuni.2004.08.020
  - ! '<p>The immunity exhibited by plants and animals is often viewed as the evolutionary response to the problem of infectious agents. In this respect, the combination of the innate immune system and the acquired immune system has been characterized as the “optimal solution.” In this essay, I propose that there is no possibility of an optimal solution to the problem of parasitism. Regardless of the immunological mechanisms evolved, infectious agents establish a dynamic interaction with common strains of their host species, weighing virulence against transmissibility. In the endless host-parasite coevolution, the immune system can never gain an upper hand on the millions of parasitic microbes and viruses. Rather, evolution of the immune system is driven, most importantly, by the small advantages conferred as a result of host variation. By selecting for ever-more-devious parasites, the immune system is the cause of its own necessity.</p>'
- - https://psyarxiv.com/3y98a/
  - "Assessing the Big Five personality traits using real-life static facial images"
  - Alexander Kachur, Evgeny Osin, Denis Davydov, Konstantin Shutilov, Alexey Novokshonov
  - 2020-04-02
  - 10.31234/osf.io/3y98a
  - ! '<p>There is ample evidence that a human face provides signals of human personality and behaviour. Previous studies have found associations between the features of artificial composite facial images and attributions of personality traits by human experts. We present new findings demonstrating the statistically significant prediction of a wider set of personality features (all the Big Five personality traits) for both men and women using real-life static facial images. Volunteer participants (<em>N</em> = 12,447) provided their face photographs (31,367 images) and completed a self-report measure of the Big Five traits. We trained a cascade of artificial neural networks (<span class="smallcaps-auto">ANN</span>s) on a large labeled dataset to predict self-reported Big Five scores. The highest correlations were found for conscientiousness (0.360 for men and 0.335 for women), exceeding the results obtained in prior studies. The findings provide strong support for the hypothesis that it is possible to predict multidimensional personality profiles from static facial images using <span class="smallcaps-auto">ANN</span>s trained on large labeled datasets.</p>'
- - http://lesswrong.com/lw/dr/generalizing_from_one_example/
  - Generalizing From One Example
  - Scott Alexander
  - 2009-04-28
  - ''
  - ! '<p>[Alexander defines the “typical mind fallacy”: everyone reasons about their mental experiences as if they are universal. People with vivid visual imagery assume everyone can see things in “the mind’s eye” while <a href="https://en.wikipedia.org/wiki/Aphantasia">‘aphantasics’</a> assume that this is simply a poetic metaphor; people with color-blindness wonder why other people get so worked up about various shades of gray, and people with <a href="https://en.wikipedia.org/wiki/Anosmia">anosmia</a> are puzzled by the focus on flowers etc. Further examples include maladaptive daydreaming, pain insensitivity, the prevalence of visual &amp; auditory hallucinations in mentally-healthy individuals like ‘scintillating scotoma’, misophonia, hearing voices, inner monologues, facial self-awareness, trypophobia, Severely Deficient Autobiographical Memory, hypermnesia, <span class="smallcaps-auto">ASMR</span>, face blindness/prosospagnosia, musical anhedonia, ‘the call of the void’/intrusive thoughts, hypnagogia, the nasal dilation cycle…</p><p>This phenomenon for visual imagery was discovered only recently by <a href="https://en.wikipedia.org/wiki/Francis_Galton">Francis Galton</a>, who asked if the interminable debate between philosophers/psychologists like Berkeley or Behaviorists like Skinner, where neither could accept that there was or was not visual imagery, was because <em>both</em> were right—some people have extremely vivid mental imagery, while others have none at all. He simply circulated a survey and <em>asked</em>.</p><p>The typical mind fallacy may explain many interpersonal conflicts and differences in advice: we underappreciate the sheer cognitive diversity of mankind, because we only have access to our limited personal anecdote, and people typically do not discuss all their differences because they don’t realize they exist nor have a vocabulary/name.]</p>'
- - /docs/xrisks/1990-dorner.pdf
  - ! 'The Logic of Failure [and Discussion]'
  - D. Dörner, P. Nixon, S. D. Rosen
  - 1990-04-12
  - 10.1098/rstb.1990.0089
  - ! '<p>Unlike other living creatures, humans can adapt to uncertainty. They can form hypotheses about situations marked by uncertainty and can anticipate their actions by planning. They can expect the unexpected and take precautions against it. In numerous experiments, we have investigated the manner in which humans deal with these demands. In these experiments, we used computer simulated scenarios representing, for example, a small town, ecological or economic systems or political systems such as a Third World country. Within these computer-simulated scenarios, the subjects had to look for information, plan actions, form hypotheses, etc.</p>'
- - /docs/philo/2005-huemer.pdf
  - ! 'Is Critical Thinking Epistemically Responsible?'
  - Michael Huemer
  - 2005-07-06
  - 10.1111/j.1467-9973.2005.00388.x
  - ! '<p>There are at least three strategies we might take in approaching controversial issues: (1) we might accept the conclusions of experts on their authority, (2) we might evaluate the relevant evidence and arguments for ourselves, or (3) we might give up on finding the answers. Students of “critical thinking” are regularly advised to follow strategy (ii). But strategies (1) and (3) are usually superior to (2), from the standpoint of the goal of gaining true beliefs and avoiding false ones.</p>'
- - https://academic.oup.com/restud/article/doi/10.1093/restud/rdaa006/5734654
  - Long-Run Effects of Lottery Wealth on Psychological Well-Being
  - Erik Lindqvist, Robert Östling, David Cesarini
  - 2020-02-12
  - 10.1093/restud/rdaa006
  - ! 'We surveyed a large sample of Swedish lottery players about their psychological well-being 5–22 years after a major lottery event and analysed the data following pre-registered procedures. Relative to matched controls, large-prize winners experience sustained increases in overall life satisfaction that persist for over a decade and show no evidence of dissipating over time. The estimated treatment effects on happiness and mental health are significantly smaller. Follow-up analyses of domain-specific aspects of life satisfaction implicate financial life satisfaction as an important mediator for the long-run increase in overall life satisfaction.'
- - /docs/dnb/1993-schneider.pdf
  - ! 'Chess Expertise and Memory for Chess Positions in Children and Adults'
  - Wolfgang Schneider, Hans Gruber, Andreas Gold, Klaus Opwis
  - 1993-12-01
  - 10.1006/jecp.1993.1038
  - ! '<p>This paper presents a replication and extension of Chi′s (1978) classic study on chess expertise [“Knowledge structures and memory development”]. A major outcome of Chi′s research was that although adult novices had a better memory span than child experts, the children showed better memory for chess positions than the adults. The major goal of this study was to explore the effects of the following task characteristics on memory performance: (1) Familiarity with the constellation of chess pieces (i.e., meaningful versus random positions) and (2) familiarity with both the geometrical structure of the board and the form and color of chess pieces. The tasks presented to the four groups of subjects (i.e., child experts and novices, adult experts and novices) included memory for meaningful and random chess positions as well as memory for the location of wooden pieces of different forms on a board geometrically structured by circles, triangles, rhombuses, etc. (control task 1). Further, a digit span memory task was given (control task 2). The major assumption was that the superiority of experts should be greatest for the meaningful chess positions, somewhat reduced but still significant for the random positions, and nonsignificant for the board control task. Only age effects were expected for the digit span task. The results conformed to this pattern, showing that each type of knowledge contributed to the experts′ superior memory span for chess positions.</p>'
- - https://en.wikipedia.org/wiki/Dieter_Rams#%22Good_design%22_principles
  - "Deiter Rams's 'Good Design' Principles"
  - English Wikipedia
  - ''
  - ''
  - ! 'According to him, “good design”:<sup id="cite_ref-4" class="reference"><a href="https://en.wikipedia.org/wiki/Dieter_Rams#cite_note-4">[4]</a></sup><sup id="cite_ref-5" class="reference"><a href="https://en.wikipedia.org/wiki/Dieter_Rams#cite_note-5">[5]</a></sup></p><ol><li><b>is innovative</b>—The possibilities for progression are not, by any means, exhausted. Technological development is always offering new opportunities for original designs. But imaginative design always develops in tandem with improving technology, and can never be an end in itself.</li><li><b>makes a product useful</b>—A product is bought to be used. It has to satisfy not only functional, but also psychological and aesthetic criteria. Good design emphasizes the usefulness of a product whilst disregarding anything that could detract from it.</li><li><b>is aesthetic</b>—The aesthetic quality of a product is integral to its usefulness because products are used every day and have an effect on people and their well-being. Only well-executed objects can be beautiful.</li><li><b>makes a product understandable</b>—It clarifies the product’s structure. Better still, it can make the product clearly express its function by making use of the user’s intuition. At best, it is self-explanatory.</li><li><b>is unobtrusive</b>—Products fulfilling a purpose are like tools. They are neither decorative objects nor works of art. Their design should therefore be both neutral and restrained, to leave room for the user’s self-expression.</li><li><b>is honest</b>—It does not make a product appear more innovative, powerful or valuable than it really is. It does not attempt to manipulate the consumer with promises that cannot be kept.</li><li><b>is long-lasting</b>—It avoids being fashionable and therefore never appears antiquated. Unlike fashionable design, it lasts many years—even in today’s throwaway society.</li><li><b>is thorough down to the last detail</b>—Nothing must be arbitrary or left to chance. Care and accuracy in the design process show respect towards the consumer.</li><li><b>is environmentally friendly</b>—Design makes an important contribution to the preservation of the environment. It conserves resources and minimizes physical and <a href="https://en.wikipedia.org/wiki/Visual_pollution" title="Visual pollution">visual pollution</a> throughout the lifecycle of the product.</li><li><b>is minimal</b>—Less is more. Simple as possible but not simpler. Good design elevates the essential functions of a product.</li></ol>'
- - https://www.themodernhouse.com/journal/vitsoes-headquarters-in-leamington-spa/
  - "A to Z of Modern Living: future-proof design at furniture manufacturer Vitsœ's headquarters in Leamington Spa"
  - The Modern House
  - 2019-01-06
  - ''
  - ! '<p>Vitsœ was founded in 1959 to manufacture the designs of Dieter Rams, of Braun’s golden years’ fame, a luminary designer who’s championed functional, considered design for well over 60 years. The company is best known for its production of Rams’ 606 Universal Shelving System, a do-it-all, have-forever modular system that can take the form of a few shelves or host an entire inventory of a university library. “I don’t regard this as a piece of architecture. I regard it as a way of thinking,” says Mark Adams, Vitsœ’s managing director, as he shows us around the firm’s Leamington Spa headquarters, which the company moved into in late 2017. “We developed the design with academics for years before building anything,” he says, explaining that the plan was essentially finished before it was handed to architects only at the delivery stage.</p><p>…At their new headquarters, Mark is fastidiously explaining elements of the building’s construction and evidence of those decades of work becomes apparent. With restrained enthusiasm he reels off details about the beech laminate veneer used for the building’s frame that he found in a German factory six years ago; about not building to conventional sustainable building standards, which he calls “box ticking exercises”; and he later gently explains how buildings are designed the wrong way around when it comes to thermal insulation. “Ours is designed a bit like if it had a Gore-Tex jacket on: it can release moisture, but it stays insulated.” This, Mark says, is better for people’s wellbeing: “Being hotter in the summer and cooler in the winter is better for your immune system.” That expenditure of time and consideration has resulted in a building in which not a single artificial light needs to be turned on during the day—the building’s party trick, if indeed it has one. Inside, daylight is utilised and amplified, pouring in through the overhead skylights in the sawtooth roof, illuminating the beech frame in splendid fashion.</p><p>The building, which amorphously combines manufacturing and office space, along with apartments for internationally-visiting staff, and a restaurant-quality canteen, is truly a mixed-use space. Looking down to the far end, it’s not uncommon for a member of Motionhouse contemporary dance troupe to launch into view above the workstations. “I think it’s completely logical that arts and commerce should be totally interwoven,” proclaims Mark.</p><p>…Mid-way into lunch, Mark interjects, inviting us to see how many phones we can spot. We look around and see no vacant faces staring at screens, but rather groups of people chatting and eating at communal tables, while outside a game of <a href="https://en.wikipedia.org/wiki/P%C3%A9tanque">pétanque</a> gets underway.</p>'
- - https://www.hustwit.com/rams/
  - '<em>Rams</em>'
  - Gary Hustwit
  - '2018'
  - ''
  - ! '<p><em>Rams</em> is a documentary portrait of Dieter Rams, one of the most influential designers alive, and a rumination on consumerism, sustainability, and the future of design…In 2008, Gary interviewed Dieter for his documentary <em>Objectified</em>, but was only able to share a small piece of his story in that film. Dieter, who is now 86, is a very private person; however Gary was granted unprecedented access to create the first feature-length documentary about his life and work.</p><p><em>Rams</em> includes in-depth conversations with Dieter, and deep dives into his philosophy, his process, and his inspirations. But one of the most interesting parts of Dieter’s story is that he now looks back on his career with some regret. “If I had to do it over again, I would not want to be a designer,” he’s said. “There are too many unnecessary products in this world.” Dieter has long been an advocate for the ideas of environmental consciousness and long-lasting products. He’s dismayed by today’s unsustainable world of over-consumption, where “design” has been reduced to a meaningless marketing buzzword.</p><p><em>Rams</em> is a design documentary, but it’s also a rumination on consumerism, materialism, and sustainability. Dieter’s philosophy is about more than just design, it’s about a way to live. It’s about getting rid of distractions and visual clutter, and just living with what you need. The film features original music by pioneering musician and producer Brian Eno.</p>'
- - http://www.abetterpage.com/wt/euro/BraunT3.html
  - "Transistor Radios Around the World: 1958 Braun T3"
  - Robert Davidson
  - '2014'
  - ''
  - ! '<p>Micro-table / coat pocket radio, thermoplastic cabinet 5 15/16 x 3 5/16 x 1 5/8 inches / 151 x 84 x 41 mm 2-band MW/LW radio, six transistors (OC44, 2× OC45, OC75 2× OC72) + OA70 diode Superheterodyne circuit Four 1.5-volt “AA” cells</p><p>Braun’s first pocket transistor radio, designed by Dieter Rams and produced in 1958. An identical-looking model, the T31, was introduced in 1960 and employed seven transistors.</p><p>Much has been made in recent years about the Braun T3 having been the design inspiration for the original <em>Apple iPod</em>—that’s pretty clear by now: Apple’s chief industrial designer Jon Ive is well known for his love of Dieter Rams’s designs, and a number of his Apple product designs bear unmistakable direct influences from classic Braun product designs.</p><figure><img src="/images/design/1958-braun-t3radio.jpg" alt="1958 Braun T3 (http://www.abetterpage.com/wt/photos/BraunT3_640x436.jpg)" width="640" height="436" /><figcaption>1958 Braun T3</figcaption></figure>'
- - https://www.disegnodaily.com/article/the-olivetti-valentine-typewriter
  - ! 'The Olivetti Valentine typewriter'
  - ! 'Cate St Hill (Designo: The Quarterly Journal of Design)'
  - 2012-11-29
  - ''
  - ! '<p>“Dear Valentine, this is to tell you that you are my friend as well as my <em>Valentine</em>, and that I intend to write you lots of letters,” says the user guide of the familiar red typewriter. This purposefully heartwarming greeting sets the tone for Ettore Sottsass&#39; typewriter. The blood-red <em>Valentine</em> was a fun, light-hearted and smooth-operating symbol of the 1960s Pop era, and its use of bright, playful casing for a piece of traditional office equipment was arguably a precursor to Apple’s 1998 Bondi Blue iMac. “When I was young, all we ever heard about was functionalism, functionalism, functionalism,” said Sottsass. “It’s not enough. Design should also be sensual and exciting.”</p><p>The <em>Valentine</em>—created for the Italian brand Olivetti—was designed in collaboration with the British designer Perry King and entered production in 1969. It was not a commercial success. The <em>Valentine</em> was technically mediocre, expensive and failed to sell to a mass audience, yet still became a design classic. <em>Valentines</em> can be found in the permanent collections of London&#39;s Design Museum and MoMA, the typewriter being accepted into the latter just two years after its launch. The product&#39;s critical success was unhindered by its functional limitations because its design focused as much on its emotional connection to users as it did on practical ease of use.</p><p>Sottsass set out his stall early on. One of the initial advertising campaigns for the design featured posters by the graphic designer and founder of <em>New York</em> magazine, Milton Glaser. Glaser used a detail of Piero di Cosimo’s renaissance painting, <em>Satyr Mourning over Nymph</em>. In the poster, the <em>Valentine</em> typewriter is placed next to a red setter, an elegant, rambunctious dog; man’s best friend. The suggestion was that Sottsass&#39; portable accessory could be just as loyal and convivial. How the product performed was arguably irrelevant. It was about how it made you feel.</p><p>The <em>Valentine</em> was available in white, green and blue, but its most famous form was red: lipstick-bright <span class="smallcaps-auto">ABS</span> plastic casing, with black plastic keys and white lettering. “Every colour has a history,” said Sottsass, “Red is the color of the Communist flag, the colour that makes a surgeon move faster and the color of passion.”</p><p>The distinctive colour was calculated to bring vibrancy and fun into the office world of the 1960s. Sottsass said that the <em>Valentine</em> “was invented for use any place except in an office, so as not to remind anyone of monotonous working hours, but rather to keep amateur poets company on quiet Sundays in the country or to provide a highly coloured object on a table in a studio apartment.” The ideas that later manifested themselves in Sottsass’ 1970s <a href="http://disegnodaily.com/lesson/the-legacy-of-memphis">Memphis movement</a>—the Milan design group known for its brightly coloured postmodern furniture—were already evident in the <em>Valentine</em> typewriter. Sottsass gave a standardised piece of office equipment personality.</p><p>Although, the designer would later dismiss the <em>Valentine</em>—comparing it to “a girl wearing a very short skirt and too much make-up”—its design was an elegant summation of his belief that successful, long-lasting product design was not solely connected to performance, but rather owed as much to the emotional force of a design.</p><figure><img src="/images/design/1969-olivetti-valentinetypewriter-designmuseum.jpg" alt="The Olivetti Valentine typewriter (Design Museum) (https://images.weserv.nl/?url=tack-disegno.s3.amazonaws.com%2Fsystem%2Fdragonfly%2Fproduction%2F2012%2F11%2F28%2F11_24_19_431_IMG_1849.jpg)" width="360" height="540" /><figcaption>The Olivetti Valentine typewriter (Design Museum)</figcaption></figure>'
- - https://www.massmadesoul.com/olivetti-valentine
  - "Olivetti Valentine"
  - Mass Made Soul
  - ''
  - ''
  - ! '<p>It came with a slide-on case that ingeniously fastens to the back plate of the typewriter with rubber straps. Unfortunately, over time these would often dry out, crack, and break off. This example still has them intact, but given its age, it’s not a good idea to rely on them to carry it around!</p><p>The body is made largely of shiny <span class="smallcaps-auto">ABS</span> plastic, while the case has a heavy matte texture, and some key structural pieces, such as the ends of the platen, are of painted metal. The bright orange caps of the ribbon reels perk up the actual mechanism, something which in other typewriters is typically hidden from view…The large fold-out handle on the back of the machine (what becomes the top when carrying it in its case) overtly invites picking up the Valentine and taking it along for a joy ride, much as the handle on the first Mac signified the same intent. The case itself was custom-designed to match the aesthetic, unlike most typewriter cases of the day, which were nondescript black or gray plastic, or perhaps semi-soft vinyl. This is another example of Sottsass’ thinking about the whole user experience (as we would call it today).</p><p>…The Valentine was conceived as competitor to the inexpensive units coming on to the market from Japan. Sottsass had some interesting ideas about how to simplify and lower the cost of the machine, such as not having lower case letters (EVERYTHING WOULD BE SHOUTING IN UPPER CASE!), removing the bell that went “ding” at the end of the line, and using an inexpensive plastic for the case. Olivetti rejected all these as too radical, and used the higher-quality <span class="smallcaps-auto">ABS</span> plastic for the case, which pushed the price up higher than Sottsass had wanted.</p><div class="epigraph"><blockquote><p>“[F]or use in any place except in an office, so as not to remind anyone of the monotonous working hours, but rather to keep amateur poets company on quiet Sundays in the country or to provide a highly colored object on a table in a studio apartment. An anti-machine machine, built around the commonest mass-produced mechanism, the works inside any typewriter, it may also seem to be an unpretentious toy.”</p><p><a href="https://en.wikipedia.org/wiki/Ettore_Sottsass">Ettore Sottsass</a></p></blockquote></div>'
- - https://www.cs.utexas.edu/users/EWD/transcriptions/EWD03xx/EWD340.html
  - 'The Humble Programmer (<span class=\"smallcaps-auto\">EWD</span>340)'
  - '<a href="https://en.wikipedia.org/wiki/Edsger_W._Dijkstra">Edsger W. Dijkstra</a>'
  - '1972'
  - ''
  -  ! '<p>[<span class="smallcaps-auto">ACM</span> Turing Lecture 1972]</p><p>…I had to make up my mind, either to stop programming and become a real, respectable theoretical physicist, or to carry my study of physics to a formal completion only, with a minimum of effort, and to become….., yes what? A programmer? But was that a respectable profession? For after all, what was programming? Where was the sound body of knowledge that could support it as an intellectually respectable discipline? I remember quite vividly how I envied my hardware colleagues, who, when asked about their professional competence, could at least point out that they knew everything about vacuum tubes, amplifiers and the rest, whereas I felt that, when faced with that question, I would stand empty-handed. Full of misgivings I knocked on van Wijngaarden’s office door, asking him whether I could “speak to him for a moment”; when I left his office a number of hours later, I was another person. For after having listened to my problems patiently, he agreed that up till that moment there was not much of a programming discipline, but then he went on to explain quietly that automatic computers were here to stay, that we were just at the beginning and could not I be one of the persons called to make programming a respectable discipline in the years to come? This was a turning point in my life and I completed my study of physics formally as quickly as I could.</p><p>…To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming had become an equally gigantic problem. In this sense the electronic industry has not solved a single problem, it has only created them, it has created the problem of using its products. To put it in another way: as the power of available machines grew by a factor of more than a thousand, society’s ambition to apply these machines grew in proportion, and it was the poor programmer who found his job in this exploded field of tension between ends and means. The increased power of the hardware, together with the perhaps even more dramatic increase in its reliability, made solutions feasible that the programmer had not dared to dream about a few years before.</p><p>…Automatic computers have now been with us for a quarter of a century. They have had a great impact on our society in their capacity of tools, but in that capacity their influence will be but a ripple on the surface of our culture, compared with the much more profound influence they will have in their capacity of intellectual challenge without precedent in the cultural history of mankind.</p>'
- - https://www.ohyouprettythings.com/free
  - "Free Movie Of the Week"
  - Oh You Pretty Things
  - '2020'
  - ''
  - ! 'Filmmaker <a href="https://www.hustwit.com/">Gary Hustwit</a> is streaming his documentaries free worldwide during the global <span class="smallcaps-auto">COVID</span>-19 crisis. Each Tuesday we’ll be posting another film here. We hope you enjoy them, and please stay strong.</p><p class="" style="white-space:pre-wrap;"><p>March 14 to 21: <a href="https://www.hustwit.com/helvetica">Helvetica</a><br>March 24 to 31: <a href="https://www.hustwit.com/objectified">Objectified</a><br>March 31 to April 7: <a href="https://www.hustwit.com/urbanized">Urbanized</a><br>April 7 to 14: <a href="https://www.hustwit.com/rams">Rams</a> <br><br>April 14 to 21: <strong><em>Workplace</em></strong> (2016, 64 minutes) is a film about the past, present, and future of the office….</p><p><br><br>April 21 to 28: <span class="smallcaps-auto">TBA</span><br>April 28 to May 5: <span class="smallcaps-auto">TBA</span>&lt;/p</p><p>[<em>Oh You Pretty Things</em> is a web shop run by a collective of filmmakers and visual artists based in Brooklyn NY. We make films, art, books, posters, photographs, clothing, and other fine stuff.]</p>'
- - https://www.atlasobscura.com/articles/what-bread-did-ancient-egyptians-eat
  - "How the Man Who Invented Xbox Baked a 4,500-Year-Old Egyptian Sourdough: It took three experts, two museums, and one clay pot to bake a truly ancient loaf"
  - Luke Fater (Atlas Obscura)
  - 2020-04-04
  - ''
  - ! '<p>Like many of us, Seamus Blackley tweeted a photo of homemade sourdough while stuck at home this weekend. Unlike many of us, however, Blackley is no novice, and this was no online recipe comprised of everyday ingredients. A trained physicist and video game producer credited with inventing the Xbox, Blackley is also an experienced baker and amateur Egyptologist. The recipe came, in part, from ancient hieroglyphs, and the ingredients came, in part, from museum archives. Blackley’s weekend sourdough was the culmination of a year-long passion project that produced a loaf of bread not eaten for millennia. By extracting 4,500-year-old dormant yeast samples from ancient Egyptian baking vessels and reviving them in his home kitchen, Blackley and his collaborators quite literally brought history to life, and ate it.</p><p>…Finally, Boston’s Museum of Fine Arts and Harvard’s Peabody Museum relented, allowing Blackley access to their deep troves of ancient Egyptian artifacts. “It was a little intimidating, to be honest,” he says. Bowman’s non-invasive extraction method resembles miniaturized fracking, wherein a portion of ceramic is injected with a nutrient bath before being pulled out through a syringe with the ancient yeast intact.</p><p>Blackley shipped the samples to Bowman in Iowa, but took one vial home to Southern California to feed and propagate himself. Interestingly, the sample could only be revived with <a href="https://en.wikipedia.org/wiki/Emmer">Emmer</a> flour, a denser varietal of flour likely used by Egyptians of the Old Kingdom….Blackley revived the yeast and baked it on a pan in his conventional home oven, resulting in a loaf that made headlines this past August. “I’ve made a fuck ton of sourdough,” says Blackley, “but this was different.” The ancient loaves were sweeter and chewier than the standard modern sourdough, with a smooth crumb closer to white bread.</p><p>…Her work showed that Egyptians placed their dough into a heated, conical, clay pot called a <em>bedja</em> before burying it in a hole surrounded by hot embers, a process Blackley made it his mission to reenact to perfection…He estimates that he cooked about 75 loaves before building his own <em>bedja</em> by hand and digging a hole in his backyard to master underground baking…From the ancient yeast to the underground baking method, Blackley had at long last produced an indisputably ancient loaf with the same rich sweetness as his summer sourdough.</p>'
- - https://distill.pub/2020/circuits/zoom-in/#openai
  - "Zoom In: An Introduction to Circuits—By studying the connections between neurons, we can find meaningful algorithms in the weights of neural networks"
  - Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, Shan Carter (OA)
  - 2020-03-10
  - 10.23915/distill.00024.001
  - ! '<p>Most work on interpretability aims to give simple explanations of an entire neural network’s behavior. But what if we instead take an approach inspired by neuroscience or cellular biology — an approach of zooming in? What if we treated individual neurons, even individual weights, as being worthy of serious investigation? What if we were willing spend thousands of hours tracing through every neuron and its connections? What kind of picture of neural networks would emerge?</p><p>In contrast to the typical picture of neural networks as a black box, we’ve been surprised how approachable the network is on this scale. Not only do neurons seem understandable (even ones that initially seemed inscrutable), but the “circuits” of connections between them seem to be meaningful algorithms corresponding to facts about the world. You can watch a circle detector be assembled from curves. You can see a dog head be assembled from eyes, snout, fur and tongue. You can observe how a car is composed from wheels and windows. You can even find circuits implementing simple logic: cases where the network implements <code>AND</code>, <code>OR</code>, or <code>XOR</code> over high-level visual features.</p><p>…<span class="smallcaps">Three Speculative Claims about Neural Networks</span></p><ol type="1"><li><em>Features</em>: Features are the fundamental unit of neural networks. They correspond to directions. By “direction” we mean a linear combination of neurons in a layer. You can think of this as a direction vector in the vector space of activations of neurons in a given layer. Often, we find it most helpful to talk about individual neurons, but we’ll see that there are some cases where other combinations are a more useful way to analyze networks — especially when neurons are “polysemantic.” (See the for a detailed definition.) These features can be rigorously studied and understood.</li><li><em>Circuits</em>: Features are connected by weights, forming circuits. A “circuit” is a computational subgraph of a neural network. It consists of a set of features, and the weighted edges that go between them in the original network. Often, we study quite small circuits — say with less than a dozen features — but they can also be much larger. (See the for a detailed definition.) These circuits can also be rigorously studied and understood.</li><li><em>Universality</em>: Analogous features and circuits form across models and tasks.</li></ol>'
- - /docs/culture/2008-johnson.pdf
  - ! 'Hierarchy in the library: Egalitarian dynamics in Victorian novels'
  - John A. Johnson, Joseph Carroll, Jonathan Gottschall, Daniel Kruger
  - 2008-10-01
  - 10.1177/147470490800600414
  - ! '<p>The current research investigated the psychological differences between protagonists and antagonists in literature and the impact of these differences on readers. It was hypothesized that protagonists would embody cooperative motives and behaviors that are valued by egalitarian hunter-gatherers groups, whereas antagonists would demonstrate status-seeking and dominance behaviors that are stigmatized in such groups. This hypothesis was tested with an online questionnaire listing characters from 201 canonical British novels of the longer nineteenth century. 519 respondents generated 1470 protocols on 435 characters. Respondents identified the characters as protagonists, antagonists, or minor characters, judged the characters’ motives according to human life history theory, rated the characters’ traits according to the five-factor model of personality, and specified their own emotional responses to the characters on categories adapted from Ekman’s seven basic emotions. As expected, antagonists are motivated almost exclusively by the desire for social dominance, their personality traits correspond to this motive, and they elicit strongly negative emotional responses from readers. Protagonists are oriented to cooperative and affiliative behavior and elicit positive emotional responses from readers. Novels therefore apparently enable readers to participate vicariously in an egalitarian social dynamic like that found in hunter-gatherer societies. We infer that agonistic structure in novels simulates social behaviors that fulfill an adaptive social function and perhaps stimulates impulses toward these behaviors in real life. [Keywords: egalitarian groups, literature, social dominance, stigmatization]</p>'
- - /docs/cs/1980-rytter.pdf
  - ! 'A Correct Preprocessing Algorithm for Boyer–Moore String-Searching'
  - Wojciech Rytter
  - 1980-01-01
  - 10.1137/0209037
  - ! "We present the correction to Knuth’s algorithm [2] for computing the table of pattern shifts later used in the Boyer–Moore algorithm for pattern matching."
- - /docs/philo/2006-harris.pdf
  - ! 'Trust in Testimony: How Children Learn About Science and Religion'
  - Paul L. Harris, Melissa A. Koenig
  - 2006-05-09
  - 10.1111/j.1467-8624.2006.00886.x
  - ! '<p>Many adult beliefs are based on the testimony provided by other people rather than on firsthand observation. Children also learn from other people’s testimony. For example, they learn that mental processes depend on the brain, that the earth is spherical, and that hidden bodily organs constrain life and death. Such learning might indicate that other people’s testimony simply amplifies children’s access to empirical data. However, children’s understanding of God’s special powers and the afterlife shows that their acceptance of others’ testimony extends beyond the empirical domain. Thus, children appear to conceptualize unobservable scientific and religious entities similarly. Nevertheless, some children distinguish between the 2 domains, arguably because a different pattern of discourse surrounds scientific as compared to religious entities.</p>'
- - /docs/ai/2020-lillicrap.pdf
  - ! 'Backpropagation and the brain'
  - Timothy P. Lillicrap, Adam Santoro, Luke Marris, Colin J. Akerman, Geoffrey Hinton
  - 2020-04-17
  - 10.1038/s41583-020-0277-3
  - ! '<p>During learning, the brain modifies synapses to improve behaviour. In the cortex, synapses are embedded within multilayered networks, making it difficult to determine the effect of an individual synaptic modification on the behaviour of the system. The backpropagation algorithm solves this problem in deep artificial neural networks, but historically it has been viewed as biologically problematic. Nonetheless, recent developments in neuroscience and the successes of artificial neural networks have reinvigorated interest in whether backpropagation offers insights for understanding learning in the cortex. The backpropagation algorithm learns quickly by computing synaptic updates using feedback connections to deliver error signals. Although feedback connections are ubiquitous in the cortex, it is difficult to see how they could deliver the error signals required by strict formulations of backpropagation. Here we build on past and recent developments to argue that feedback connections may instead induce neural activities whose differences can be used to locally approximate these signals and hence drive effective learning in deep networks in the brain.</p>'
- - /docs/modafinil/2020-rubinkahana.pdf
  - ! 'Cognitive enhancement drug use among resident physicians: Prevalence and motivations for use—results from a survey'
  - Dafna Sara Rubin-Kahana, Ziv Rubin-Kahana, Maya Kuperberg, Rafael Stryjer, Dorit Yodashkin-Porat
  - 2020-04-16
  - 10.1080/10550887.2020.1747337
  - ! '<p><em>Background</em>: Non-medical use of prescription drugs for the enhancement of cognitive functioning has gained popularity in recent years, especially among young educated adults. To our knowledge, no previous study investigated this phenomenon among resident physicians.</p><p><em>Objective</em>: To analyze cognitive enhancement drugs use motivations and patterns among resident physicians.</p><p><em>Methods</em>: A survey and statistical analysis regarding the use of drugs traditionally prescribed for the treatment of Attention Deficit Hyperactivity Disorder: stimulants, amphetamines and modafinil.</p><p><em>Participants</em>: 1,453 residents who took their written residency exam in the summer of 2017. The response rate was 32.3%.</p><p><em>Results</em>: 28.1% of responders reported past use, with 73.67% of them reporting use without a related medical diagnosis. Almost half of the users (47.1%) acquired the drug with a prescription, but without a diagnosis of a related medical disorder. The first use was predominantly during residency (54.3%), with 45% reporting it as related to the residency exam.</p><p>Factors found to positively impact non-medical use include: declaring undiagnosed Attention Deficit Hyperactivity Disorder, fear of failing the exam, a belief that more than 30% of other examinees take cognitive enhancements drugs, and a learning disability diagnosis. Self-reports of being a competitive person and being a parent, were negatively correlated with non-medical use.</p><p><em>Conclusions</em>: The use of drugs that are taken traditionally for the treatment of Attention Deficit Hyperactivity Disorder is common among resident physicians, both with and without related medical indication. Interestingly, factors associated with the fear of being “left behind” increase non-medical use and not the desire to succeed. [Keywords: substance misuse, cognitive enhancement, physicians, prescription stimulants, residents]</p>'
- - https://www.latimes.com/archives/la-xpm-1994-10-21-ls-53158-story.html
  - ! "Natural Wonder: At heart, Edward Wilson’s an ant man. But it’s his theories on human behavior that stir up trouble"
  - Josh Getlin (LA Times)
  - 1994-10-21
  - ''
  - ! '<p>[Profile of noted entomologist E. O. Wilson on the occasion of his autobiography, <em>Naturalist</em>. Wilson became interested in insects as a child, making a mark studying scent trails laid down by ants, then shifting into application of evolutionary logic to human groups such as warfare and sports (triggering fierce attacks from activists &amp; Marxists like Stephen Jay Gould), and for getting involved in politics as an environmentalist, warning about rapid species diversity loss.]</p><p>Twenty years later, many of Wilson’s conclusions have been accepted as mainstream. He has since clarified his theories to argue that human behavior is a product of cultural and genetic evolution. The great challenge facing science, he says, is to probe the way those two influences interact. Meanwhile, he’s received numerous honors, winning the 1979 Pulitzer Prize for <em>On Human Nature</em> (Harvard), a response to sociobiology critics, and the 1991 Pulitzer Prize for <em>The Ants</em> (Harvard), a 700-page opus written with Bert Holldobler. Yet memories of his bitter conflicts have eased only slightly. The day he was doused with ice water “may be the only occasion in recent American history on which a scientist was physically attacked, however mildly, for the expression of an idea,” he writes. “How could an entomologist with a penchant for solitude provoke a tumult of this proportion?”</p><p>…In a packed lecture hall, he spreads the word. Here, biodiversity is more than an abstract concept. Dimming the lights, Wilson shows students a dramatic slide–a nighttime photo of Earth taken by satellites–and points out eerie flames stretching across the Equator, across Latin America and Asia. They’re fires burning out of control in the rain forests on any given evening. It’s a disturbing sight, yet Wilson says there is still time to save the planet.</p><p>On another morning, he compares human beings to ants. Consider man’s selfishness and ambition versus the insects’ drive to help their community. They’ll sacrifice their lives for the common good, if need be. Biology doesn’t get more basic than this, and Wilson ends the lesson amid gales of laughter by raising the subject of Marxism. Why did it fail? “Good ideology,” he says dryly. “Wrong species.”</p>'
- - /docs/ai/1987-mcdermott.pdf
  - ! 'A critique of pure reason'
  - ! '<a href="https://en.wikipedia.org/wiki/Drew_McDermott">Drew McDermott</a>'
  - 1987-02-01
  - 10.1111/j.1467-8640.1987.tb00183.x
  - ! '<p>[1987 retrospective by <a href="https://en.wikipedia.org/wiki/Drew_McDermott">noted proponent</a> of logic for planning and reasoning in AI (‘<span class="smallcaps-auto">GOFAI</span>’); McDermott criticizes his own work fiercely, along with that of his colleagues (particularly John McCarthy, Robert Moore, James Allen, Jerry Hobbs, &amp; Patrick Hayes), describing the ‘logicist’ paradigm—that sufficiently ingenious and persistent application of logical reasoning, mostly first-order logic, can eventually give rise to human-level understanding of the world, planning &amp; execution of actions, and eventually <span class="smallcaps-auto">AGI</span>.</p><p>McDermott concludes that the nature of such programs is that they are unable to see if they are making real progress (because a failure to infer something could simply reflect a lacking axiom), and worse, that such logics are not even an approximation to what intelligence is, or a role model, or that failures reflect poor choice of axioms, but that logics only verify things and do not compute useful things like plans, and collapse into verifying trivialities which do no useful intellectual work. Resorts to powerful tools like temporal logics or nonmonotonic logics sacrifice the philosophical advantages of logical inference in an attempt to get working systems, but may obtain neither. What is necessary is <em>doing without deduction</em>.]</p><p>It must be the case that a significant portion of the inferences we want [to make] are deductions, or it will simply be irrelevant how many theorems follow deductively from a given axiom set.</p> <p>...To summarize: The logicist project of expressing “naive physics” in first-order logic has not been very successful. One reason may be that the basic argument was flawed. You cannot write down axioms independent of a program for manipulating them if the inferences you are interested in are not deductions. Unfortunately, very few interesting inferences are deductions, and the attempts by logicists to extend logic to cover more territory have been disappointing. Hence we must resign ourselves to writing programs, and viewing knowledge representations as entities to be manipulated by the programs.</p><p>…Finally, I should admit that I am still doing work in the paradigm that I criticize here. In the domain of shape representation, so little is known that focusing on an idealization cannot but help teach us something. The problem I would like to tackle is representing the knowledge required to answer questions like, Could a paper clip be used as a key ring? The idealization I have been forced to fall back on is to prove that a paper clip of a certain size and shape could fit through the hole of a typical key. It should be obvious how much of the original problem this leaves out. Still, the territory is so unexplored that a tour through the idealized fragment could turn up something interesting. What one cannot hope for is to express as logical axioms everything there is to know about using shapes in unusual ways, before designing programs for this task. This will probably come as a shock to no one but me and a few friends.</p>'
- - /docs/economics/2008-hanson.pdf
  - ! 'Showing that you care: The evolution of health altruism'
  - '<a href="https://en.wikipedia.org/wiki/Robin_Hanson">Robin Hanson</a>'
  - 2008-01-01
  - 10.1016/j.mehy.2007.08.020
  - ! '<p>Human behavior regarding medicine seems strange; assumptions and models that seem workable in other areas seem less so in medicine. Perhaps, we need to rethink the basics. Toward this end, I have collected many puzzling stylized facts about behavior regarding medicine, and have sought a small number of simple assumptions which might together account for as many puzzles as possible.</p><p>The puzzles I consider include a willingness to provide more medical than other assistance to associates, a desire to be seen as so providing, support for nation, firm, or family provided medical care, placebo benefits of medicine, a small average health value of additional medical spending relative to other health influences, more interest in public that private signals of medical quality, medical spending as an individual necessity but national luxury, a strong stress-mediated health status correlation, and support for regulating health behaviors of the low status. These phenomena seem widespread across time and cultures.</p><p>I can explain these puzzles moderately well by assuming that humans evolved deep medical habits long ago in an environment where people gained higher status by having more allies, honestly cared about those who remained allies, were unsure who would remain allies, wanted to seem reliable allies, inferred such reliability in part based on who helped who with health crises, tended to suffer more crises requiring non-health investments when having fewer allies, and invested more in cementing allies in good times in order to rely more on them in hard times.</p><p>These ancient habits would induce modern humans to treat medical care as a way to show that you care. Medical care provided by our allies would reassure us of their concern, and allies would want you and other allies to see that they had pay enough to distinguish themselves from posers who didn’t care as much as they. Private information about medical quality is mostly irrelevant to this signaling process.</p><p>If people with fewer allies are less likely to remain our allies, and if we care about them mainly assuming they remain our allies, then we want them to invest more in health than they would choose for themselves. This tempts us to regulate their health behaviors. This analysis suggests that the future will continue to see robust desires for health behavior regulation and for communal medical care and spending increases as a fraction of income, all regardless of the health effects of these choices.</p>'
- - /docs/zeo/2006-tononi.pdf
  - ! 'Sleep function and synaptic homeostasis'
  - Giulio Tononi, Chiara Cirelli
  - 2006-02-01
  - 10.1016/j.smrv.2005.05.002
  - ! '<p>This paper reviews a novel hypothesis about the functions of slow wave sleep—the synaptic homeostasis hypothesis. According to the hypothesis, plastic processes occurring during wakefulness result in a net increase in synaptic strength in many brain circuits. The role of sleep is to downscale synaptic strength to a baseline level that is energetically sustainable, makes efficient use of gray matter space, and is beneficial for learning and memory. Thus, sleep is the price we have to pay for plasticity, and its goal is the homeostatic regulation of the total synaptic weight impinging on neurons. The hypothesis accounts for a large number of experimental facts, makes several specific predictions, and has implications for both sleep and mood disorders. [Keywords: Long-term depression, Synaptic scaling, Learning, Consolidation, Delta sleep, Slow waves, Slow oscillation]</p>'
- - /docs/economics/2004-ziobrowski.pdf
  - ! 'Abnormal Returns from the Common Stock Investments of the U.S. Senate'
  - Alan J. Ziobrowski, Ping Cheng, James W. Boyd, Brigitte J. Ziobrowski
  - 2004-12-01
  - 10.1017/S0022109000003161
  - ! '<p>The actions of the federal government can have a profound impact on financial markets. As prominent participants in the government decision making process, U.S. Senators are likely to have knowledge of forthcoming government actions before the information becomes public. This could provide them with an informational advantage over other investors. We test for abnormal returns from the common stock investments of members of the U.S. Senate during the period 1993–1998. We document that a portfolio that mimics the purchases of U.S. Senators beats the market by 85 basis points per month, while a portfolio that mimics the sales of Senators lags the market by 12 basis points per month. The large difference in the returns of stocks bought and sold (nearly one percentage point per month) is economically large and reliably positive.</p>'
- - /docs/economics/2014-heald.pdf
  - ! 'How Copyright Keeps Works Disappeared'
  - Paul J. Heald
  - 2014-10-28
  - 10.1111/jels.12057
  - ! '<p>A random sample of new books for sale on Amazon.com shows more books for sale from the 1880s than the 1980s. Why? This article presents new data on how copyright stifles the reappearance of works. First, a random sample of more than 2,000 new books for sale on Amazon.com is analyzed along with a random sample of almost 2,000 songs available on new <span class="smallcaps-auto">DVD</span>s. Copyright status correlates highly with absence from the Amazon shelf. Together with publishing business models, copyright law seems to deter distribution and diminish access. Further analysis of eBook markets, used books on Abebooks.com, and the Chicago Public Library collection suggests that no alternative marketplace for out-of-print books has yet developed. Data from iTunes and YouTube, however, tell a different story for older hit songs. The much wider availability of old music in digital form may be explained by the differing holdings in two important cases, <em>Boosey &amp; Hawkes v. Disney</em> (music) and <em>Random House v. Rosetta Stone</em> (books).</p>'
- - /docs/cs/1985-feynman-surelyyourejokingmrfeynman-ch18-safecrackermeetsafecracker.pdf
  - ! "<em>Surely You're Joking, Mr. Feynman</em>! Chapter 18: Safecracker Meets Safecracker"
  - Richard Feynman
  - '1985'
  - ''
  - ! '<p>[In this chapter, Feynman discusses his fascination with locks and safes, and the ways he learns to crack different locks and safes. He also talks about the locks and safes there were at Los Alamos (the ones that held the secrets of the atomic bomb). Generally speaking, the safes containing this material, which is (understandably) considered top secret, are startlingly easy to crack. When Feynman and his colleagues first arrive at Los Alamos, the construction of the facility is not even complete yet, and there is almost no security at all for the “top secret” information. Even later, when the information is stored in safes and locked file cabinets, the locks are generally cheap, and it is easy for Feynman to determine what the combination is, as combinations were often reused. He can memorize common passwords, or watch people dialing carelessly to deduce several digits, and then brute-force the rest; often, people do not even change the factory default.]</p>'
- - /docs/culture/2020-etro.pdf
  - ! 'Liberalizing art. Evidence on the Impressionists at the end of the Paris Salon'
  - Federico Etro, Silvia Marchesi, Elena Stepanova
  - 2020-03-01
  - 10.1016/j.ejpoleco.2020.101857
  - ! '<ul><li>The end of the government-controlled Salon started the appreciation of impressionism.</li><li>Evidence that the liberalization of art exhibitions started the appreciation of art innovations.</li><li>A study of the impact of 1880 liberalization of art exhibitions in Paris.</li><li>Difference-in difference estimation on art policy.</li></ul><p>We analyze the art market in Paris between the government-controlled Salon and the post-1880 system, when the Republican government liberalized art exhibitions. The jury of the old Salon decided on submissions with a bias in favor of conservative art of the academic insiders, erecting entry barriers against outsiders as the Impressionists. With a difference-in difference estimation, we provide evidence that the end of the government-controlled Salon contributed to start the price increase of the Impressionists relative to the insiders.</p><p>[Keywords: Art market, Liberalization, Market structure, Insider-outsider, Hedonic regressions, Impressionism]</p>'
- - /docs/psychology/2020-bellet.pdf
  - ! 'Trigger warnings and resilience in college students: A preregistered replication and extension'
  - Benjamin W. Bellet, Payton J. Jones, Cynthia A. Meyersburg, Kaitlin E. Morehead, Richard J. McNally
  - 2020-04-13
  - 10.1037/xap0000270
  - ! '<p>Trigger warnings notify people that content they are about to engage with may result in adverse emotional consequences. An experiment by Bellet, Jones, and McNally (2018) indicated that trigger warnings increased the extent to which trauma-naïve crowd-sourced participants see themselves and others as emotionally vulnerable to potential future traumas but did not have a significant main effect on anxiety responses to distressing literature passages. However, they did increase anxiety responses for participants who strongly believed that words can harm. In this article, we present a preregistered replication of this study in a college student sample, using Bayesian statistics to estimate the success of each effect’s replication. We found strong evidence that none of the previously significant effects replicated. However, we found substantial evidence that trigger warnings’ previously nonsignificant main effect of increasing anxiety responses to distressing content was genuine, albeit small. Interpretation of the findings, implications, and future directions are discussed.</p>'
- - https://www.theguardian.com/news/datablog/2013/jul/12/movies-audience-loved-critics-hated
  - "What are the movies that audiences loved but the critics hated? Analysis of 10,000 movies reveals the films with the highest disparity between critic and audience reviews"
  - Nick Evershed (The Guardian)
  - 2013-07-12
  - ''
  - ! '<p>So, what are the movies that people loved, but critics hated? And what about those movies that got rave reviews but just didn’t click with audiences?</p><p>To try and answer these questions I’ve analysed 10,000 movies from 1970 to 2013 in the Rotten Tomatoes database, and determined the difference in audience score and critic score by subtracting the former from the latter. This gives us an index of audience-critic agreement, which I’ve named the <a href="https://en.wikipedia.org/wiki/Ashley_Tisdale">Tisdale</a>-<a href="https://en.wikipedia.org/wiki/Gina_Carano">Carano</a> index. From this, we can see which movies the audience loved, but the critics hated—which will be more positive, and movies the critics loved but the audience hated—more negative. We can also find out what types of movies fall into these categories—like which actors, directors and genres are most common to each.</p><p>…I used this <span class="smallcaps-auto">IMD</span>b list of 10,000 US-released movies from 1970–2013 (though I did notice a film from 1967) to get ID numbers for a large number of movies. I then wrote a program that accesses the Rotten Tomatoes database via their <span class="smallcaps-auto">API</span> and grabbed the title, first two actors listed, genres, first director listed, studio, year of release, and Motion Picture Association of America (<span class="smallcaps-auto">MPAA</span>) rating of each movie based on the <span class="smallcaps-auto">IMD</span>b number. From this, I removed 2,828 films without a user or critic rating. This produced the dataset for analysis. I created the Tisdale-Carano index by simply subtracting the critic score from the user score, then ranking the entire dataset by this number.</p>'
- - https://wwiiafterwwii.wordpress.com/2017/02/20/cleaning-up-after-wwii/
  - "Cleaning up after <span class=\"smallcaps-auto\">WWII</span>"
  - jwh1975
  - 2017-02-20
  - ''
  - ! '<p>[Extensive photo album covering the aftermath of <span class="smallcaps-auto">WWII</span>: where did all those hundreds of thousands of tanks, airplanes, vehicles, and ships go, and the hundreds of millions of guns, bullets, helmets, mess kits etc go? They went in all sorts of directions: many were repurposed on the spot by victors and used against their makers, while others were salvaged by crews on the battlefield, then leftovers stripped by locals. Military vehicles might be detonated on the spot to prevent reuse. Others would wait until after the war to be salvaged for rebuilding, or dumped at sea. Much of Japan’s air force was destroyed after surrender by a specialized tank battalion which would run over airplanes, or light them on fire with gasoline from a passing vehicle. (The Netherlands’ air force would bomb Japanese planes manned by Indonesian separatists.) Much was simply dumped at sea as by far the easiest and most expedient mass disposal method. On remote islands, they would be left in place to rot, now making picturesque ruin porn. The biggest challenge was dealing with the enormous amount of left-over ammunition, bombs, land mines, chemical weapons (stockpiled in enormous amounts though never used), and especially <em>naval</em> mines, which could break free and drift on the sea—vexing Iceland. Chemical weapons were dumped at sea as well, and would drift ashore.]</p><p>One of the reasons <span class="smallcaps-auto">WWII</span> battlefields did not remain littered with vehicles for long was that, with the lone exception of the <span class="smallcaps-auto">USA</span>, all of the major warring powers made some official level of combat usage of captured enemy arms during <span class="smallcaps-auto">WWII</span>. The most formal was Germany’s <em>Beutewaffe</em> (literally, ‘booty’ or ‘loot’ weapon) effort, which encompassed everything from handguns to fighter aircraft with an official code in the <em>Waffenamt</em> system; for example FK-288(r) (the Soviet ZiS-3 anti-tank gun), <span class="smallcaps-auto">SIG</span>ew-251(a) (the American M1 Garand rifle), and Sd.Kfz 735(i) (the Italian Fiat M13/40 tank). Captured gear was assembled at points called <em>Sammelstelle</em> and then shipped back from the front lines for disposition.</p>'
- - /docs/design/1988-alpha-atlasofobliquemaps.pdf
  - ! 'Atlas Of Oblique Maps: A Collection Of Landform Portrayals Of Selected Areas Of The World'
  - Tau Rho Alpha, Janis S. Detterman, Jim Morley
  - 1988-01-01
  - 10.3133/i1799
  - ! '<p>Pp. 137, 200+ maps and geological sections (some in color and some color-tinted). Publisher’s two-color printed wrappers, lg folio (20.5 x 16 inches). This folio comprises scale-accurate, obliquely viewed maps compiled from 1961 to 1986 that portray the physiography of selected areas of the ocean floor and continents. The life’s work of <a href="https://csunshinetoday.csun.edu/science-and-technology/mapping-a-gift-alumnus-and-cartography-legend-gives-back-to-dres/">Tau Rho Alpha</a>… the maps are all oblique aerials, and range from 1961 to 1986, so are pre-digital. The ability to represent complex geographic and topography features enlightens many maps of this sort, and the techniques to create this makes for a fascinating read…Some of the benefits of this type of map are discussed, including more realism and easier comprehension, and ability maintain scale. Disadvantages included displacement of features, and hiding of key elements, and a relative inexactness of elevation and location.</p>'
- - https://www.hiddenhydrology.org/atlas-of-oblique-maps/
  - '<em>Atlas of Oblique Maps</em>'
  - Jason King
  - 2017-03-23
  - ''
  - ! '<p>A gem of a publication semi-related to hidden hydrology by very related to cool maps, is one the US Geological Survey Miscellaneous Investigations Series I-1799, published in 1988, entitled the <a href="https://pubs.er.usgs.gov/publication/i1799"><em>Atlas of Oblique Maps: A collection of landform portrayals of selected areas of the world</em></a>. As noted, the maps are all oblique aerials, and range from 1961 to 1986, so are pre-digital. The ability to represent complex geographic and topography features enlightens many maps of this sort, and the techniques to create this makes for a fascinating read. Some introductory text from the Preface:</p><blockquote><p>Oblique maps portray the surface of the Earth as if viewed from above at an oblique angle (usually about 30°). This atlas is a collection of more than 100 oblique maps that were compiled from 1961 to 1986. In cooperation with scientists of the U.S. Geological Survey, all but one of these maps were designed for a specific scientific purpose and publication, and the geographic area, orientation, angle of view, scale, and size of the area portrayed in each map differed with each intended purpose. Some of these maps show the physiography of a large regional area, while others focus on just a few landforms. The purpose of this atlas is to present these oblique maps in one publication with a common format, to provide a history and explanation of the techniques used to make these maps, and to supply a bibliography for the individually published maps</p></blockquote><p>… Some of the benefits of this type of map are discussed, including more realism and easier comprehension, and ability maintain scale. Disadvantages included displacement of features, and hiding of key elements, and a relative inexactness of elevation and location. I think of many of the maps of cities in the late 1800s that were drawn using similar techniques, which show features in a compelling way, but somehow exist with a tantalizing lack of precision…So why should these matter, aside from their value as historical maps? The conclusion sums it up, along with a very prescient commentary on the value and future of mapping in our current age of Google Earth:</p><blockquote><p>“Because oblique maps are instructive and easy to read, they help the scientist communicate with the layman concerning our environment, especially in those areas, such as the sea floor, that are not easily accessible. With increasing population and all its attendant stresses on the planet, the need for this communication will become ever greater. Fortunately, in the near future, with new techniques and with the use of computers, the cartographer will be able to respond to this demand and create oblique maps more quickly and more economically.”</p></blockquote><p>A bunch of the examples below show the range of maps—which I count over 100 total, with a vast range in geography from Alaska, Washington and Oregon, California, and many from around the world. The simplicity and elegance of the black and white showcases volcanic variants in the Pacific Northwest, two of my favorite places, Crater Lake and Mount St. Helens.</p>'
- - /docs/genetics/heritable/2014-groenblokhuis.pdf
  - ! 'Attention-Deficit/Hyperactivity Disorder Polygenic Risk Scores Predict Attention Problems in a Population-Based Sample of Children'
  - Maria M. Groen-Blokhuis, Christel M. Middeldorp, Kees-Jan Kan, Abdel Abdellaoui, Catharina E.M. van Beijsterveldt, Erik A. Ehli, Gareth E. Davies, Paul A. Scheet, Xiangjun Xiao, James J. Hudziak, Jouke-Jan Hottenga, Ben M. Neale, Dorret I. Boomsma, Psychiatric Genomics Consortium <span class=\"smallcaps-auto\">ADHD</span> Working Group
  - 2014-10-01
  - 10.1016/j.jaac.2014.06.014
  - ! '<p><em>Objective</em>: Clinically, attention-deficit/hyperactivity disorder (<span class="smallcaps-auto">ADHD</span>) is characterized by hyperactivity, impulsivity, and inattention and is among the most common childhood disorders. These same traits that define <span class="smallcaps-auto">ADHD</span> are variable in the general population, and the clinical diagnosis may represent the extreme end of a continuous distribution of inattentive and hyperactive behaviors. This hypothesis can be tested by assessing the predictive value of polygenic risk scores derived from a discovery sample of <span class="smallcaps-auto">ADHD</span> patients in a target sample from the general population with continuous scores of inattention and hyperactivity. In addition, the genetic overlap between <span class="smallcaps-auto">ADHD</span> and continuous <span class="smallcaps-auto">ADHD</span> scores can be tested across rater and age.</p><p><em>Method</em>: The Psychiatric Genomics Consortium has performed the largest genome-wide analysis (<span class="smallcaps-auto">GWA</span>) study of <span class="smallcaps-auto">ADHD</span> so far, including 5,621 clinical patients and 13,589 controls. The effects sizes of single nucleotide polymorphisms (<span class="smallcaps-auto">SNP</span>s) estimated in this meta-analysis were used to obtain individual polygenic risk scores in an independent population-based cohort of 2,437 children from the Netherlands Twin Register. The variance explained in Attention Problems (AP) scale scores by the polygenic risk scores was estimated by linear mixed modeling.</p><p><em>Results</em>: The <span class="smallcaps-auto">ADHD</span> polygenic risk scores significantly predicted both parent and teacher ratings of AP in preschool- and school-aged children.</p><p><em>Conclusion</em>: These results indicate genetic overlap between a diagnosis of <span class="smallcaps-auto">ADHD</span> and AP scale scores across raters and age groups and provides evidence for a dimensional model of <span class="smallcaps-auto">ADHD</span>. Future <span class="smallcaps-auto">GWA</span> studies on <span class="smallcaps-auto">ADHD</span> can likely benefit from the inclusion of population-based cohorts and the analysis of continuous scores. [Keywords: <span class="smallcaps-auto">ADHD</span>, attention problems, polygenic scores, genetics, dimensional models]</p>'
- - /docs/statistics/bias/2020-peters.pdf
  - ! 'Ideological diversity, hostility, and discrimination in philosophy'
  - Uwe Peters, Nathan Honeycutt, Andreas De Block, Lee Jussim
  - 2020-04-16
  - 10.1080/09515089.2020.1743257
  - ! '<p>Members of the field of philosophy have, just as other people, political convictions or, as psychologists call them, ideologies. How are different ideologies distributed and perceived in the field? Using the familiar distinction between the political left and right, we surveyed an international sample of 794 subjects in philosophy. We found that survey participants clearly leaned left (75%), while right-leaning individuals (14%) and moderates (11%) were underrepresented. Moreover, and strikingly, across the political spectrum from very left-leaning individuals and moderates to very right-leaning individuals, participants reported experiencing ideological hostility in the field, occasionally even from those on their own side of the political spectrum. Finally, while about half of the subjects believed that discrimination against left- or right-leaning individuals in the field is not justified, a significant minority displayed an explicit willingness to discriminate against colleagues with the opposite ideology. Our findings are both surprising and important because a commitment to tolerance and equality is widespread in philosophy, and there is reason to think that ideological similarity, hostility, and discrimination undermine reliable belief formation in many areas of the discipline. [Keywords: Ideological bias, diversity, demographics.]</p>'
- - /docs/psychology/2020-nichols.pdf
  - ! 'Bilingualism Affords No General Cognitive Advantages: A Population Study of Executive Function in 11,000 People'
  - Emily S. Nichols, Conor J. Wild, Bobby Stojanoski, Michael E. Battista, Adrian M. Owen
  - 2020-04-20
  - 10.1177/0956797620903113
  - ! '<p>Whether acquiring a second language affords any general advantages to executive function has been a matter of fierce scientific debate for decades. If being bilingual does have benefits over and above the broader social, employment, and lifestyle gains that are available to speakers of a second language, then it should manifest as a cognitive advantage in the general population of bilinguals. We assessed 11,041 participants on a broad battery of 12 executive tasks whose functional and neural properties have been well described. Bilinguals showed an advantage over monolinguals on only one test (whereas monolinguals performed better on four tests), and these effects all disappeared when the groups were matched to remove potentially confounding factors. In any case, the size of the positive bilingual effect in the unmatched groups was so small that it would likely have a negligible impact on the cognitive performance of any individual. [Keywords: bilingualism, executive function, cognition, aging, null-hypothesis testing.]</p>'
- - /docs/ai/2020-su.pdf
  - ! 'Avatar Artist Using GAN [CS230]'
  - Hui Su, Jin Fang
  - 2020-04-12
  - ''
  -  ! '<p>Human sketches can be expressive and abstract at the same time. Generating anime avatars from simple or even bad face drawing is an interesting area. Lots of related work has been done such as auto-coloring sketches to anime or transforming real photos to anime. However, there aren’t many interesting works yet to show how to generate anime avatars from just some simple drawing input. In this project, we propose using <span class="smallcaps-auto">GAN</span> to generate anime avatars from sketches.</p>'
- - /docs/economics/1969-brooks-businessadventures-ch3-thefederalincometax.pdf
  - ! '<em>Business Adventures: Twelve Classic Tales from the World of Wall Street</em>: Chapter 3: The Federal Income Tax: Its History and Peculiarities'
  - John Brooks
  - '1969'
  - ''
  - ! '<p>[Profile by the veteran economics <em>New Yorker</em> reporter John Brooks of the post-<span class="smallcaps-auto">WWII</span> American federal income tax (history, effects &amp; reform attempts), which taxed incomes at rates as high as 91%, but was riddled with bizarre loopholes and exceptions which meant the real tax rates were typically half that—at the cost of massively distorting human behavior.</p><p>Stars would stop performing halfway through the year, marriages would be scheduled for the right month, films were designed around tax incentives rather than merits, countless oil wells were drilled unnecessarily and rich people would invest in business of no interest to them like bowling alleys, businessmen had to meticulously record every lunch because income tax distorted salaries in favor of fringe benefits. (A similar dynamic was at play in the rise of employer-based health insurance during <span class="smallcaps-auto">WWII</span>, contributing to the present grotesquely inefficient American healthcare system.)]</p><p>…the writer David T. Bazelon has suggested that the economic effect of the tax has been so sweeping as to create two quite separate kinds of United States currency—before-tax money and after-tax money. At any rate, no corporation is ever formed, nor are any corporation’s affairs conducted for as much as a single day, without the lavishing of earnest consideration upon the income tax, and hardly anyone in any income group can get by without thinking of it occasionally, while some people, of course, have had their fortunes or their reputations, or both, ruined as a result of their failure to comply with it. As far afield as Venice, an American visitor a few years ago was jolted to find on a brass plaque affixed to a coin box for contributions to the maintenance fund of the Basilica of San Marco the words “Deductible for U.S. Income-Tax Purposes.”</p>'
- - /docs/statistics/decision/1985-reilly.pdf
  - ! 'An examination of two alternative techniques to estimate the standard deviation of job performance in dollars'
  - Richard R. Reilly, James W. Smither
  - 1985-11-01
  - 10.1037/0021-9010.70.4.651
  - ! '<p>Two methods for estimating dollar standard deviations were investigated in a simulated environment. 19 graduate students with management experience managed a simulated pharmaceutical firm for 4 quarters. Ss were given information describing the performance of sales representatives on 3 job components. Estimates derived using the method developed by <a href="https://www.gwern.net/docs/statistics/decision/1979-schmidt.pdf" title="Impact of valid selection procedures on work-force productivity">F. L. Schmidt et al 1979</a> (see record 1981-02231-001) were relatively accurate with objective sales data that could be directly translated to dollars, but resulted in overestimates of means and standard deviations when data were less directly translatable to dollars and involved variable costs. An additional problem with the Schmidt et al procedure involved the presence of outliers, possibly caused by differing interpretations of instructions. The Cascio-Ramos estimate of performance in dollars (<span class="smallcaps-auto">CREPID</span>) technique, proposed by W. F. Cascio (1982), yielded smaller dollar standard deviations, but Ss could reliably discriminate among job components in terms of importance and could accurately evaluate employee performance on those components. Problems with the <span class="smallcaps-auto">CREPID</span> method included the underlying scale used to obtain performance ratings and a dependency on job component intercorrelations.</p>'
- - /docs/statistics/decision/1979-schmidt.pdf
  - ! 'Impact of valid selection procedures on work-force productivity'
  - Frank L. Schmidt, J. E. Hunter, R. C. McKenzie, T. W. Muldrow
  - 1979-01-01
  - 10.1037/0021-9010.64.6.609
  - ! '<p>Used decision theoretic equations to estimate the impact of the Programmer Aptitude Test (<span class="smallcaps-auto">PAT</span>) on productivity if used to select new computer programmers for 1 yr in the federal government and the national economy. A newly developed technique was used to estimate the standard deviation of the dollar value of employee job performance, which in the past has been the most difficult and expensive item of required information. For the federal government and the US economy separately, results are presented for different selection ratios and for different assumed values for the validity of previously used selection procedures. The impact of the <span class="smallcaps-auto">PAT</span> on programmer productivity was substantial for all combinations of assumptions. Results support the conclusion that hundreds of millions of dollars in increased productivity could be realized by increasing the validity of selection decisions in this occupation. Similarities between computer programmers and other occupations are discussed. It is concluded that the impact of valid selection procedures on work-force productivity is considerably greater than most personnel psychologists have believed.</p>'
- - /docs/psychology/2018-bailey.pdf
  - ! 'Prevention: Necessary But Insufficient? A 2-Year Follow-Up of an Effective First-Grade Mathematics Intervention'
  - Drew H. Bailey, Lynn S. Fuchs, Jennifer K. Gilbert, David C. Geary, Douglas Fuchs
  - 2018-10-25
  - 10.1111/cdev.13175
  - ! '<p>We present first-grade, second-grade, and third-grade impacts for a first-grade intervention targeting the conceptual and procedural bases that support arithmetic. At-risk students (average age at pretest = 6.5) were randomly assigned to three conditions: a control group (<em>n</em> = 224) and two variants of the intervention (same conceptual instruction but different forms of practice: speeded [<em>n</em> = 211] vs. nonspeeded [<em>n</em> = 204]). Impacts on all first-grade content outcomes were significant and positive, but no follow-up impacts were significant. Many intervention children achieved average mathematics achievement at the end of third grade, and prior math and reading assessment performance predicted which students will require sustained intervention. Finally, projecting impacts 2 years later based on nonexperimental estimates of effects of first-grade math skills overestimates long-term intervention effects.</p>'
- - /docs/iq/1983-hunter.pdf
  - ! 'A Causal Analysis of Cognitive Ability, Job Knowledge, Job Performance, and Supervisor Ratings'
  - J. E. Hunter
  - '1983'
  - ''
  - ! '<p>Through a meta-analysis of 14 studies, Dr. Hunter investigates the relationships among three variables: ability, job knowledge and performance. Performance is measured in two ways, work sample tests and supervisory ratings. Two causal models are presented which depict the possible relationships among the three variables. The first model suggests a direct impact of ability on performance, on job knowledge, and on supervisor ratings. This implies that there is an indirect relationship impact of job knowledge on supervisory ratings. The alternative model suggests that job knowledge is directly related to supervisory ratings. The results of the path analysis provide support for the latter model.</p><p>Dr. Guion states that Hunter’s findings provide evidence for the validity of ratings. However, the model is incomplete. He suggests that the model should be enlarged to include such exogenous variables as rater characteristics, ratee characteristics, and context factors.</p>'
- - /docs/biology/1933-manger.pdf
  - ! 'Untersuchungen zum Problem der Geschlechtsdiagnose aus Schwangerenharn'
  - Julius Manger
  - '1933'
  - 10.1055/s-0028-1131712
  - ! '<p>Die Tatsache, daß Follikelhormon auf das Pflanzenwachstum einzuwirken vermag, gab Veranlassung, Versuche nach alt überlieferten volksmedizinischen Texten zu machen, wonach aus der Wirkung von Schwangerenurin auf keimfähige Gersten- und Weizenkörner auf das Geschlecht des zu erwartenden Kindes geschlossen werden könne.</p><p>Es ergab sich die Regel, daß schnelleres Wachstum der Gerste gegenüber dem Weizen ein Mädchen, während nicht beschleunigtes oder verzögertes Wachstum der Gerste einen Knaben bedeutet. Auf diese Weise konnten bei Untersuchungen mit Urinen von 100 Schwangeren zu 80% richtige Diagnosen gestellt werden; 20% waren falsch.</p>'
- - /docs/biology/1934-hoffmann.pdf
  - ! 'Versuche zur Schwangerschaftsdiagnose aus dem Harn'
  - Walther Hoffmann
  - '1934'
  - 10.1055/s-0028-1129965
  - ! '<ol type="1"><li>Es ist an sich möglich, mit Hilfe von <em>Keimversuchen an Getreide eine Schwangerschaft zu diagnostizieren</em>. Die angestellten Versuche fielen stets eindeutig aus. Für die Praxis ist dieses Verfahren infolge der langen Dauer des Reaktionsablaufes aber natürlich nicht verwertbar.</li><li>Der Urin <em>nichtschwangerer</em> Frauen übt eine starke <em>Hemmung</em> auf die Keimung von Weizen und Gerste aus oder hindert sie (Dialyse) sogar gänzlich.</li><li>Eine schwache Hemmung der Keimung tritt anfänglich auch beim Gießen mit <em>Schwangerenharn</em> ein, doch bewirkt er <em>nach</em> der Keimung eine <em>starke Entwicklung</em> des vegetativen Wachstums, was nicht durch die Zufuhr von Nährsalzen erklärt werden kann, zumal Harn nichtschwangerer Frauen, der darin gleich sein sollte, eine stark giftige (verbrennende) Wirkung ausübt.</li><li>Eine <em>Geschlechtsdiagnose</em> wurde nicht versucht, doch sind Versuche darüber in Vorbereitung.</li></ol>'
- - /docs/genetics/selection/2000-cochran.pdf
  - ! 'Infectious Causation of Disease: An Evolutionary Perspective'
  - Gregory M. Cochran, Paul W. Ewald, Kyle D. Cochran
  - 2000-01-01
  - 10.1353/pbm.2000.0016
  - ! '<p>Over the past two centuries, diseases have been separated into three categories: infectious diseases, genetic diseases, and diseases caused by too much or too little of some noninfectious environmental constituent. At the end of the 19<sup>th</sup> century, the most rapid development was in the first of these categories; within three decades after the first cause-effect linkage of a bacterium to a disease, most of the bacterial causes of common acute infectious diseases had been identified. This rapid progress can be attributed in large part to Koch’s postulates, a rigorous systematic approach to identification of microbes as causes of disease. Koch’s postulates were useful because they could generate conclusive evidence of infectious causation, particularly when (1) the causative organisms could be isolated and experimentally transmitted, and (2) symptoms occurred soon after the onset of infection in a high proportion of infected individuals. While guiding researchers down one path, however, the postulates directed them away from alternative paths: researchers attempting to document infectious causation were guided away from diseases that had little chance of fulfilling the postulates, even though they might have been infectious. During the first half of the 20<sup>th</sup> century, when the study of infectious agents was shifting from bacteria to viruses, Mendel’s genetics was being integrated into the study of disease. Some diseases could not be ascribed to infectious causes using Koch’s postulates but could be shown to have genetic bases, particularly if they were inherited according to Mendelian ratios. Mendel’s genetics and Koch’s postulates thus helped create a conceptual division of diseases into genetic and infectious categories, a division that persists today.The third category—diseases resulting from noninfectious environmental causes—has a longer history. The known associations of poisons with illness provided a basis for understanding physical agents as causes of disease. The apparent “contagiousness” of some chemical agents, such as the irritant of poison ivy, led experts to consider that diseases could be contagious without being infectious. Even after the discovery of causative microbes during the last quarter of the 19<sup>th</sup> century, many infectious diseases were considered contagious through the action of poisons, but not necessarily infectious [1].</p><p>…This tendency to dismiss infectious causation has occurred in spite of the recognition that (1) infectious diseases are typically influenced by both host genetic and noninfectious environmental factors, and (2) some chronic diseases, such as tuberculosis and syphilis, have long been recognized as being caused by infection.In this essay we analyze the present conceptions of disease etiology from an historical perspective and within the framework offered by evolutionary biology. We begin by analyzing the degree to which infectious causation has been accepted for different categories of disease over the past two centuries with an emphasis on (1) characteristics that make the infectious causes of different diseases conspicuous or cryptic, and (2) the need to detect ever more cryptic infectious causes as a legacy of the more rapid recognition of the conspicuous infectious causes. We then consider principles and approaches that could facilitate recognition of infectious diseases and other phenomena that are not normally considered to be of infectious origin.</p>'
- - /docs/economics/2020-bloom.pdf
  - ! 'Are Ideas Getting Harder to Find?'
  - Nicholas Bloom, Charles I. Jones, John Van Reenen, Michael Webb
  - 2020-04-01
  - 10.1257/aer.20180338
  - ! '<p>Long-run growth in many models is the product of two terms: the effective number of researchers and their research productivity. We present evidence from various industries, products, and firms showing that research effort is rising substantially while research productivity is declining sharply. A good example is Moore’s Law. The number of researchers required today to achieve the famous doubling of computer chip density is more than 18 times larger than the number required in the early 1970s. More generally, everywhere we look we find that ideas, and the exponential growth they imply, are getting harder to find.</p>'
- - https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0372
  - "Are humans constantly but subconsciously smelling themselves?"
  - Ofer Perl, Eva Mishor, Aharon Ravia, Inbal Ravreby, Noam Sobel
  - 2020-04-20
  - 10.1098/rstb.2019.0372
  - ! '<p>All primates, including humans, engage in self-face-touching at very high frequency. The functional purpose or antecedents of this behaviour remain unclear. In this hybrid review, we put forth the hypothesis that self-face-touching subserves self-smelling. We first review data implying that humans touch their faces at very high frequency. We then detail evidence from the one study that implicated an olfactory origin for this behaviour: This evidence consists of significantly increased nasal inhalation concurrent with self-face-touching, and predictable increases or decreases in self-face-touching as a function of subliminal odourant tainting. Although we speculate that self-smelling through self-face-touching is largely an unconscious act, we note that in addition, humans also consciously smell themselves at high frequency. To verify this added statement, we administered an online self-report questionnaire. Upon being asked, approximately 94% of approximately 400 respondents acknowledged engaging in smelling themselves. Paradoxically, we observe that although this very prevalent behaviour of self-smelling is of concern to individuals, especially to parents of children overtly exhibiting self-smelling, the behaviour has nearly no traction in the medical or psychological literature. We suggest psychological and cultural explanations for this paradox, and end in suggesting that human self-smelling become a formal topic of investigation in the study of human social olfaction.</p>'
- - /docs/genetics/heritable/2014-burt.pdf
  - ! 'Pulling Back The Curtain On Heritability Studies: Biosocial Criminology In The Postgenomic Era'
  - Callie H. Burt, Ronald L. Simons
  - 2014-03-28
  - 10.1111/1745-9125.12036
  - ! '<p>Unfortunately, the nature-versus-nurture debate continues in criminology. Over the past 5 years, the number of heritability studies in criminology has surged. These studies invariably report sizeable heritability estimates (∼50%) and minimal effects of the so-called shared environment for crime and related outcomes. Reports of such high heritabilities for such complex social behaviors are surprising, and findings indicating negligible shared environmental influences (usually interpreted to include parenting and community factors) seem implausible given extensive criminological research demonstrating their significance. Importantly, however, the models on which these estimates are based have fatal flaws for complex social behaviors such as crime. Moreover, the goal of heritability studies—partitioning the effects of nature and nurture—is misguided given the bidirectional, interactional relationship among genes, cells, organisms, and environments. This study provides a critique of heritability study methods and assumptions to illuminate the dubious foundations of heritability estimates and questions the rationale and utility of partitioning genetic and environmental effects. After critiquing the major models, we call for an end to heritability studies. We then present what we perceive to be a more useful biosocial research agenda that is consonant with and informed by recent advances in our understanding of gene function and developmental plasticity.</p>'
- - /docs/iodine/2002-case.pdf
  - ! 'Economic Status and Health in Childhood: The Origins of the Gradient'
  - Anne Case, Darren Lubotsky, Christina Paxson
  - 2002-12-01
  - 10.1257/000282802762024520
  - ! '<p>The well-known positive association between health and income in adulthood has antecedents in childhood. Not only is children’s health positively related to household income, but the relationship between household income and children’s health becomes more pronounced as children age. Part of the relationship can be explained by the arrival and impact of chronic conditions. Children from lower-income households with chronic conditions have worse health than do those from higher-income households. The adverse health effects of lower income accumulate over children’s lives. Part of the intergenerational transmission of socioeconomic status may work through the impact of parents’ income on children’s health.</p>'
- - /GPT-2-music#generating-midi-with-10k30k-context-windows
  - ! 'Generating MIDI Music With GPT-2: Generating MIDI by converting to ABC and expanding the GPT-2 context window—works, if only just'
  - Gwern Branwen
  - 2020-04-25
  - ''
  - ! '<p>To expand the <span class="smallcaps-auto">ABC</span> <span class="smallcaps-auto">GPT-2</span> model to cover a wider variety of musical genres, I turn to the next-most compact widespread music encoding format: <strong><span class="smallcaps-auto">MIDI</span></strong>. There are hundreds of thousands of <span class="smallcaps-auto">MIDI</span>s which can be <a href="https://en.wikipedia.org/wiki/Decompiler" class="docMetadata" data-popup-title="Decompiler" data-popup-author="English Wikipedia" data-popup-abstract="<p>A <b>decompiler</b> is a computer program that takes an executable file as input, and attempts to create a high level source file which can be recompiled successfully. It is therefore the opposite of a compiler, which takes a source file and makes an executable. Decompilers are usually unable to perfectly reconstruct the original source code, and as such, will frequently produce obfuscated code. Nonetheless, decompilers remain an important tool in the reverse engineering of computer software.</p>" title="Wikipedia: Decompiler">decompiled</a> to <span class="smallcaps-auto">ABC</span> format, averaging ~10k <span class="smallcaps-auto">BPE</span>s—within <span class="smallcaps-auto">GPT-2-117M</span>’s feasible context window when trained on <span class="smallcaps-auto">TPU</span>s (which permit training of context windows up to 30k wide).</p><p>We compile the <span class="smallcaps-auto">ABC</span> from before and 2 large <span class="smallcaps-auto">MIDI</span> datasets, and convert to <span class="smallcaps-auto">ABC</span>, yielding ~453k usable <span class="smallcaps-auto">ABC-MIDI</span> musical files (~5.1GB of text). We trained January–April 2020 on our <span class="smallcaps-auto">TPU</span> swarm (with many interruptions), achieving a final loss of ~0.2 (underfit).</p><p>Sampling from the final model is hit-or-miss as it is prone to the likelihood repetition trap and it generates instruments one-by-one so it is common for instruments to be cut off or otherwise broken during sampling (indicating that <em>sampling</em> is increasingly a bigger problem than <em>training</em> for long-range sequence modeling). However, successful pieces are possible, and are musically far more diverse than the folk <span class="smallcaps-auto">ABC</span> corpus, with many pleasingly complex samples.</p>'
- - /docs/philo/2017-healy.pdf
  - ! 'Fuck Nuance'
  - Kieran Healy
  - 2017-06-26
  - 10.1177/0735275117709046
  - ! '<p>Nuance is not a virtue of good sociological theory. Although often demanded and superficially attractive, nuance inhibits the abstraction on which good theory depends. I describe three “nuance traps” common in sociology and show why they should be avoided on grounds of principle, aesthetics, and strategy. The argument is made without prejudice to the substantive heterogeneity of the discipline.</p>'
- - https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2017.0205
  - "How mammals stay healthy in nature: the evolution of behaviours to avoid parasites and pathogens"
  - Benjamin L. Hart, Lynette A. Hart
  - 2018-06-04
  - 10.1098/rstb.2017.0205
  - ! '<p>Mammals live and thrive in environments presenting ongoing threats from parasites in the form of biting flies, ticks and intestinal worms and from pathogens as wound contaminants and agents of infectious disease. Several strategies have evolved that enable animals to deal with parasites and pathogens, including eliminating away from the sleeping-resting areas, use of an array of grooming techniques, use of saliva in licking, and consuming medicinal plant-based compounds. These strategies all are species-specific and reflect the particular environment that the animal inhabits.</p>'
- - /docs/biology/2008-sueda.pdf
  - ! 'Characterisation of plant eating in dogs'
  - Karen Lynn Chieko Sueda, Benjamin Leslie Hart, Kelly Davis Cliff
  - 2008-05-01
  - 10.1016/j.applanim.2007.05.018
  - ! '<p>Grass or plant eating is a widely recognized behaviour amongst domestic dogs. We first estimated the prevalence of plant eating by administering a written survey to owners of healthy dogs visiting the outpatient service of a veterinary medical teaching hospital for routine health maintenance procedures. Of 47 owners systematically surveyed whose dogs had daily exposure to plants, 79% reported that their dog had eaten grass or other plants. Using an internet survey targeting owners of plant-eating dogs, we then acquired information regarding the frequency and type of plants eaten, frequency with which dogs appeared ill before eating plants and frequency with which vomiting was seen afterwards. Of 3340 surveys returned, 1571 met enrollment criteria. Overall, 68% of dogs were reported to eat plants on a daily or weekly basis with the remainder eating plants once a month or less. Grass was the most frequently eaten plant by 79% of dogs. Only 9% were reported to frequently appear ill before eating plants and only 22% were reported to frequently vomit afterwards. While no relationship was found between sex, gonadal status, breed group or diet type with regard to frequency or type of plants eaten, a younger age was significantly associated with: (1) an increase in frequency of plant eating; (2) an increase in consuming non-grass plants; (3) a decrease in regularly showing signs of illness before eating plants and (4) a decrease in regularly vomiting after consuming plants. The findings support the perspective that plant eating is a normal behaviour of domestic dogs. [Keywords: Dogs, Canids, Feeding behaviour, Plant eating, Grass eating]</p>'
- - /docs/biology/2008-hart.pdf
  - ! 'Why do dogs and cats eat grass? (A) They are sick and need to vomit. (B) They have a dietary deficiency. (C) Studies point to a third option that may may well be the correct answer to this often-asked client question'
  - Benjamin L. Hart
  - 2008-12-01
  - ''
  - ! '<p>[2-page popular summary of Sueda et al 2008: a survey of dog owners about plant-eating found that it was common, usually didn’t seem related to illness, occasionally triggered vomiting, younger dogs did it more, and no diet appeared correlated with plant-eating. Similar preliminary results for cats are mentioned. Hart interprets these results as support for his theory that plant-eating is an evolved behavior intended to help control intestinal parasites, mechanically through fiber going through the intestines but also partially through vomiting.]</p>'
- - /docs/catnip/2019-hart.pdf
  - ! 'Characterization of plant eating in cats'
  - Benjamin L. Hart, Lynette A. Hart, Abigail P. Thigpen
  - 2019-08-05
  - ''
  - ! '<p>[Conference abstract reporting cat owner survey (<em>n</em>=1021) about plant-eating &amp; health, with similar results as <a href="/docs/biology/2008-sueda.pdf" title="&#39;Characterisation of plant eating in dogs&#39;, Sueda et al 2008">dogs</a>. Cats are frequently seen eating plants (only 11% never), usually appear healthy, vomit semi-frequently afterwards, and do so more frequently when younger.]</p><p>…71% of cats had been seen eating plants at least 6 times, 61% over 10 times, and 11% never eating plants. Comparing cats seen eating plants at least 10 times with those never seen eating plants, there were no differences in age range, neuter status, source or number of cats in the household. Of cats seen eating plants at least 10 times, 67% were estimated to eat plants daily or weekly. When asked about how their cat seemed to feel prior to eating plants, 91% of respondents said their cat was almost always appeared normal, beforehand. Vomiting was a bit more common—27% reported the cat frequently vomiting after eating plants. The prior study on plant eating by dogs had very similar findings with regard to frequency of plant eating, appearing normal beforehand, and vomiting 20–30% of the time afterwards. Among young cats, 3 years of age or less, 39% engaged in daily plant eating compared to 27% of cats 4 years or older (<em>p</em>&lt;0.01). While percentage of younger cats showing no signs of illness prior plant eating was similar to older cats, just 11% of the younger cats were observed to frequently vomit after eating plants compared to a significantly higher 30% of older cats (<em>p</em>&lt;0.001).</p>'
- - /docs/biology/1996-huffman.pdf
  - ! 'Leaf-Swallowing by Chimpanzees: A Behavioral Adaptation for the Control of Strongyle Nematode Infections'
  - Michael A. Huffman, Jonathan E. Page, Michael V. K. Sukhdeo, Shunji Gotoh, Mohamedi S. Kalunde, Thushara Chandrasiri, G. H. Neil Towers
  - 1996-08-01
  - 10.1007/BF02735188
  - ! '<p>Swallowing whole leaves by chimpanzees and other African apes has been hypothesized to have an anti parasitic or medicinal function, but detailed studies demonstrating this were lacking. We correlate for the first time quantifiable measures of the health of chimpanzees with observations of leaf-swallowing in Mahale Mountains National Park, Tanzania. We obtained a total of 27 cases involving the use of <em>Aspilia mossambicensis</em> (63%), <em>Lippia plicata</em> (7%), <em>Hibiscus</em> sp. (15%), <em>Trema orientalis</em> (4%), and <em>Aneilema aequinoctiale</em> (11%), 15 cases by direct observation of 12 individuals of the Mahale M group. At the time of use, we noted behavioral symptoms of illness in the 8 closely observed cases, and detected single or multiple parasitic infections (<em>Strongyloides fulleborni</em>, <em>Trichuris trichiura</em>, <em>Oesophagostomum stephanostomum</em>) in 10 of the 12 individuals. There is a significant relationship between the presence of whole leaves (range, 1–51) and worms of adult <em>O. stephanostomum</em> (range, 2–21) in the dung. <span class="smallcaps-auto">HPLC</span> analysis of leaf samples collected after use showed that thiarubrine A, a compound proposed to act as a potent nematocide in swallowing <em>Aspilia</em> spp., was not present in leaves of <em>A. mossambicensis</em> or the three other species analyzed. Alternative nematocidal or egg-laying inhibition activity was not evident. Worms of <em>O. stephanostomum</em> were recovered live and motile from chimpanzee dung, trapped within the folded leaves and attached to leaf surfaces by trichomes, though some were moving freely within the fecal matter, suggesting that the physical properties of leaves may contribute to the expulsion of parasites. We review previous hypotheses concerning leaf-swallowing and propose an alternative hypothesis based on physical action.</p>'
- - /docs/biology/2001-huffman.pdf
  - ! 'Self-induced Increase of Gut Motility and the Control of Parasitic Infections in Wild Chimpanzees'
  - M. A. Huffman, J. M. Caton
  - 2001-06-01
  - 10.1023/A:1010734310002
  - ! '<p>When physiological adaptation is insufficient, hosts have developed behavioral responses to avoid or limit contact with parasites. One such behavior, leaf-swallowing, occurs widely among the African great apes. This behavior involves the slow and deliberate swallowing without chewing of whole bristly leaves. Folded one at a time between tongue and palate, the leaves pass through the gastro-intestinal (GI) tract visibly unchanged.</p><p>Independent studies in two populations of chimpanzees (<em>Pan troglodytes schweinfurthii</em>) showed significant correlations between the swallowing of whole leaves and the expulsion of the nodule worm <em>Oesophagostomum stephanostomum</em> and a species of tapeworm (<em>Bertiella studeri</em>). We integrate behavioral, parasitological and physiological observations pertaining to leaf-swallowing to elucidate the behavioral mechanism responsible for the expulsion and control of nodule worm infections by the ape host.</p><p>Physical irritation produced by bristly leaves swallowed on an empty stomach, increases motility and secretion resulting in diarrhea which rapidly moves leaves through the GI tract. In the proximal hindgut, the site of third-stage larvae (L3) cyst formation and adult worm attachment, motility, secretion and the scouring effect of rough leaves is enhanced by haustral contractions and peristalsis-antiperistalsis. Frequently, at the peak of reinfection, a proportion of nonencysted L3 is also predictably vulnerable. These factors should result in the disruption of the life cycle of <em>Oesophagostomum</em> spp. Repeated flushing during peak periods of reinfection is probably responsible for long-run reduction of worm burdens at certain times of the year.</p><p>Accordingly, leaf-swallowing can be viewed as a deliberate adaptive behavioral strategy with physiological consequences for the host. The expulsion of worms based on the activation of basic physiological responses in the host is a novel hitherto undescribed form of parasitic control.</p>'
- - http://sudoscript.com/reddit-place/
  - "When Pixels Collide"
  - sudoscript
  - 2017-04-04
  - ''
  - ! '<p>Last weekend, a fascinating act in the history of humanity played out on Reddit. For April Fool’s Day, Reddit launched a little experiment. It gave its users, who are all anonymous, a blank canvas called Place. The rules were simple. Each user could choose one pixel from 16 colors to place anywhere on the canvas. They could place as many pixels of as many colors as they wanted, but they had to wait a few minutes between placing each one. Over the following 72 hours, what emerged was nothing short of miraculous. A collaborative artwork that shocked even its inventors. From a single blank canvas, a couple simple rules and no plan, came this:</p><p><a href="http://spacescience.tech/place/"> <figure><video controls="controls" preload="metadata" loop><source src="/images/2017-reddit-dhieno-theplace-timelapseevolution.mp4" alt="Animated timelapse GIF showing the evolution of the Reddit social experiment, The Place, where individuals can update a pixel on a shared image, leading to wars over how the image looks. (https://www.reddit.com/r/place/comments/63hvwb/rplace_time_lapse_gif/)" type="video/mp4"></video><figcaption>The Place history and evolution (animated <span class=\"smallcaps-auto\">GIF</span>)</figcaption></figure> </a></p><p>Each pixel you see was placed by hand. Each icon, each flag, each meme created painstakingly by millions of people who had nothing in common except an Internet connection. Somehow, someway, what happened in Reddit over those 72 hours was the birth of Art….</p><ul><li>The Creators</li><li>The Protectors</li><li>The Destroyers</li></ul>'
- - https://slatestarcodex.com/2017/10/02/different-worlds/
  - Different Worlds
  - Scott Alexander
  - 2017-10-02
  - ''
  - ! '<p>[Psychiatrist muses about individual differences: how do people perceive &amp; experience such extremely different ‘worlds’, such that some lurch from drama to trauma while others experience few problems, a large fraction of Americans are Young Earth Creationists while he knows none personally, some constantly experience ‘sexism’ and ‘racism’ while others never experience it, some psychiatrists get patients who melt down regularly while others (like him) never do, and so on? (See also: the <a href="https://en.wikipedia.org/wiki/Dodo_bird_verdict">Dodo Bird Verdict</a>/therapist-specific effects, heritability, reactive gene-environment interaction, <a href="https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example">typical mind fallacy</a>, cognitive biases, <a href="https://www.gwern.net/Everything">‘everything is correlated’</a>, <a href="https://www.gwern.net/docs/sociology/1987-rossi">the Metallic Laws</a>.)]</p><p>People self-select into bubbles along all sorts of axes. Some of these bubbles are obvious and easy to explain, like rich people mostly meeting other rich people at the country club. Others are more mysterious, like how some non-programmer ends up with mostly programmer friends. Still others are horrible and completely outside comprehension, like someone who tries very hard to avoid abusers but ends up in multiple abusive relationships anyway. Even for two people living in the same country, city, and neighborhood, they can have a “society” made up of very different types of people. People vary widely on the way they perceive social interaction. A paranoid schizophrenic will view every interaction as hostile; a Williams Syndrome kid will view every interaction as friendly. In between, there will be a whole range of healthy people without any psychiatric disorder who tend toward one side or the other. Only the most blatant data can be interpreted absent the priors that these dispositions provide; everything else will only get processed through preexisting assumptions about how people tend to act. Since things like racism rarely take the form of someone going up to you and saying “Hello, I am a racist and because of your skin color I plan to discriminate against you in the following ways…”, they’ll end up as ambiguous stimuli that everyone will interpret differently. Finally, some people have personalities or styles of social interaction that unconsciously compel a certain response from their listeners. Call these “niceness fields” or “meanness fields” or whatever: some people are the sort who—if they became psychotherapists—would have patients who constantly suffered dramatic emotional meltdowns, and others’ patients would calmly discuss their problems.</p><p>The old question goes: are people basically good or basically evil? Different philosophers give different answers. But so do different random people I know who aren’t thinking philosophically at all. Some people describe a world of backstabbing Machiavellians, where everybody’s a shallow social climber who will kick down anyone it takes to get to the top. Other people describe a world where everyone is basically on the same page, trying to be nice to everyone else but getting stuck in communication difficulties and honest disagreements over values.</p><p>I think both groups are right. Some people experience worlds of basically-good people who treat them nicely. Other people experience worlds of awful hypocritical backstabbers. This can be true even if they live in the same area as each other, work the same job as each other, et cetera.</p><p><p>To return to a common theme: <i>nothing makes sense except in light of inter-individual variation</i>. Variation in people’s <a href="https://slatestarcodex.com/2014/03/17/what-universal-human-experiences-are-you-missing-without-realizing-it/">internal experience</A>. Variation in people’s <a href="https://squid314.livejournal.com/337475.html">basic beliefs and assumptions</A>. Variation in <a href="https://slatestarcodex.com/2015/11/03/what-developmental-milestones-are-you-missing/">level of abstract thought</A>. And to all of this I would add a variation in our experience of other people.</p>'
- - /docs/genetics/selection/2020-wang.pdf
  - ! 'Genome-wide selection and genetic improvement during modern maize breeding'
  - Baobao Wang, Zechuan Lin, Xin Li, Yongping Zhao, Binbin Zhao, Guangxia Wu, Xiaojing Ma, Hai Wang, Yurong Xie, Quanquan Li, Guangshu Song, Dexin Kong, Zhigang Zheng, Hongbin Wei, Rongxin Shen, Hong Wu, Cuixia Chen, Zhaodong Meng, Tianyu Wang, Yu Li, Xinhai Li, Yanhui Chen, Jinsheng Lai, Matthew B. Hufford, Jeffrey Ross-Ibarra, Hang He, Haiyang Wang
  - 2020-04-27
  - 10.1038/s41588-020-0616-3
  - ! '<p>Since the development of single-hybrid maize breeding programs in the first half of the twentieth century<sup>1</sup>, maize yields have increased over seven-fold, and much of that increase can be attributed to tolerance of increased planting density<sup>2,3,4</sup>. To explore the genomic basis underlying the dramatic yield increase in maize, we conducted a comprehensive analysis of the genomic and phenotypic changes associated with modern maize breeding through chronological sampling of 350 elite inbred lines representing multiple eras of germ-plasm from both China and the United States. We document several convergent phenotypic changes in both countries. Using genome-wide association and selection scan methods, we identify 160 loci underlying adaptive agronomic phenotypes and more than 1,800 genomic regions representing the targets of selection during modern breeding. This work demonstrates the use of the breeding-era approach for identifying breeding signatures and lays the foundation for future genomics-enabled maize breeding.</p>'
- - /docs/genetics/correlation/1990-ooki.pdf
  - ! 'Relationship Between Blood Uric Acid Level and Personality Traits'
  - S. Ooki, K. Yamada, A. Asaka
  - 1990-01-01
  - 10.1017/S0001566000005638
  - ! '<p>The present study deals with the relationship between blood uric acid level and human behavior. Subjects were 37 MZ and 7 DZ twins aged from 18 to 45 years. In males, blood uric acid level increased with age, while it decreased with age in females. Blood uric acid level was corrected and standardized using regression lines separately for males and females. The distribution of standardized uric acid level corresponded well with the theoretical curve of normal distribution. The intraclass correlation coefficient for standardized uric acid level was <em>r</em> = 0.370 (<em>p</em> &lt; 0.05) for the 37 MZ twins, but not significant for the 7 DZ twins. These findings suggest that blood uric acid level is genetically controlled. By the analysis of 12 personality traits in YG (Yatabe-Guilford) character test, it was revealed that “General activity” was more controlled by genetically than environmentally. In the evaluation of the correlation between standardized uric acid level and the YG 12 personality traits, significant correlation was observed in “Lack of agreeableness” and “Rhathymia”. Since these two personality traits include the factor of “activity”, it is concluded that the plasma uric acid level and activity in a broader sense are under genetic control. This conclusion is consistent with the generally accepted view that persons with high uric acid level are more active and energetic than those with low level.</p>'
- - /docs/sr/2019-chun.pdf
  - ! 'The Limits of Reputation Signaling in Adversely Selected Markets: Applications to Dark Net Cocaine Markets'
  - Steven Chun
  - 2019-06-01
  - ''
  - ! '<p>Dark net markets present a rare opportunity to examine markets with little contract enforcement and strong asymmetric information. The review systems on these sites prevent market collapse by allowing good vendors to accrue reputation, signaling high quality products. This paper examines cocaine listings on the Dream Market dark net site. Despite uniformly high ratings across all vendors, I find a price differential between escrow transactions—which function as strong contracts—and non-escrow transactions.</p><p>This supports existing models of markets with reputation signaling that become heavily saturated with highly reputable vendors, yet these vendors still have a nonzero chance of scamming their customers in an exit-scheme. I argue that the price differential represents the discount high-reputation vendors must offer consumers to offset the inherent risk the transaction is a scam. [Keywords: Adverse Selection, Dark Net Markets, Moral Hazard, Online, Drugs.]</p>'
- - https://github.com/l4rz/practical-aspects-of-stylegan2-training
  - "Practical aspects of Style<span class=\"smallcaps-auto\">GAN</span>2 training"
  - l4rz
  - 2020-04-28
  - ''
  - ! '<p>I have trained Style<span class="smallcaps-auto">GAN</span>2 from scratch with a dataset of female portraits at 1024px resolution. The samples quality was further improved by tuning the parameters and augmenting the dataset with zoomed-in images, allowing the network to learn more details and to achieved <span class="smallcaps-auto">FID</span> metrics that are comparable to the results of the original work…I was curious how it would work on the human anatomy, so I decided to try to train SG2 with a dataset of head and shoulders portraits. To alleviate capacity issues mentioned in the SG2 paper I preferred to use portraits without clothes (a significant contributing factor to dataset variance); furthermore, the dataset was limited to just one gender in order to further reduce the dataset’s complexity.</p><p>…I haven’t quite been able to achieve the quality of SG2 trained with the <span class="smallcaps-auto">FFHQ</span> dataset. After over than 30000 kimg, the samples are not yet as detailed as it is desirable. For example, teeth look blurry and pupils are not perfectly round. Considering the size of my dataset as opposed to the <span class="smallcaps-auto">FFHQ</span> one, the cause is unlikely to be the lack of training data. Continuing the training does not appear to help as is evident from the plateau in <span class="smallcaps-auto">FID</span>s.</p><p>Overall, my experience with SG2 is well in line with what others are observing. Limiting the dataset to a single domain leads to major quality improvements. SG2 is able to model textures and transitions quite well. At the same time it is struggling as the complexity of the object increases with, for instance, greater diversity in poses. It should be noted that SG2 is much more efficient for single domain tasks compared to other architectures, resulting in acceptable results much faster.</p><figure><img src="/images/gan/2020-l4rz-stylegan2-practicalaspects-toplesswomensamples.jpg" alt="A selection of topless women photographs generated by StyleGAN 2 (https://raw.githubusercontent.com/l4rz/practical-aspects-of-stylegan2-training/master/images/seeds-23-40-66-166-347-447-511-895-908-945-973-976--070-sfw.jpg)" /><figcaption>Curated samples, Ψ=0.70</figcaption></figure>'
- - https://dormin.org/2020/03/21/against-dog-ownership/
  - Against Dog Ownership
  - Dormin
  - 2020-03-21
  - ''
  - ! '<p>[“A warning against assuming the immense emotional and moral responsibilities that come with caring for a dog. Can an owned animal have a good life?”Imagine that you, a human, were kidnapped by aliens at birth and given an approximation of a dog’s life, and a <em>good</em> dog’s life at that. Ignore the subservience, dependence on a superior life form, and all the other psychological aspects of being <em>owned</em> and just focus on how you would feel about your material conditions. Would you want this life?" (7,700 words)" —TB summary</p><p>Meditation on pet ownership. What is the morality of keeping a mentally and physically crippled animal, particularly in an urban apartment where it cannot exercise its natural urges or get adequate exercise/stimulation? The ‘cute’ behavior of a dog, so appealing to so many, is, regarded more cynically, indicative of severe pathology and dependency, a Stockholm syndrome; aside from the effects on the slave, what are the effects on the <em>master</em>? At least a cat’s trust and affection has to be earned; what should we think of humans who love the pathetically unconditional love of a dog?]</p>'
- - https://dormin.org/2020/04/27/explaining-blaming-and-being-very-slightly-sympathetic-toward-enron/
  - "An Attempt at Explaining, Blaming, and Being Very Slightly Sympathetic Toward Enron"
  - Dormin
  - 2020-04-27
  - ''
  - ! '<p>[“Admirably lucid revisiting of Enron’s metamorphosis from a pipeline company into a derivatives trading-house that booked billions in paper profits before collapsing.” The Enron story displays the potentially distortionary impact of high intelligence on moral decision-making. It lends evidence to the notion that extremely intelligent people can be subtly incentivised to be (systematically) dishonest because their intelligence lowers the cost and raises the potential benefits of circumventing rules" —TB summary</p><p>What, in a nutshell, was the Enron fraud? Like a tech startup, Enron had a vision of creating many new markets by upfront investments; to achieve this, which was in fact often a viable business strategy and <em>had</em> worked before, it needed debt-financing and to look like a logistics company with stable lucrative locked-in long-term profits, though its profits increasingly actually came from volatile unreliable financial trading. From this pressure and the need to keep up appearances to avoid switching horses in mid-stream before projects could pay off, a house of cards built up, deviance was normalized, and it slowly slid into an enormous financial fraud with few people realizing until the end.]</p>'
- - https://dormin.org/2020/01/23/little-soldiers-inside-the-chinese-education-system/
  - '<em>Little Soldiers</em>—Inside the Chinese Education System'
  - Dormin
  - 2019-09-03
  - ''
  - ! '<p>[Review of Lenora Chu’s 2017 memoir <a href="https://www.amazon.com/Little-Soldiers-American-Chinese-Achieve/dp/0062367854"><em>Little Soldiers: An American Boy, a Chinese School, and the Global Race to Achieve</em></a>, a memoir by a Chinese-American journalist married to a Jewish <span class="smallcaps-auto">NPR</span> journalist of subjecting their child to elite Chinese education in Shanghai. Chu naively credits the brutal rigor and training of the Chinese education system for the stellar results on international comparisons like <span class="smallcaps-auto">PISA</span> (the truth is likely otherwise).]</p><p>That’s why [this was pure nightmare fuel for me. It’s a non-fiction account of an ethnically-Chinese, American-born woman following her multi-racial child through the Chinese school system in Shanghai. While we complain about our soft, liberal, decadent school experiences in America or Europe, tens of millions of Chinese kids are subjected to a school structure that seems purposefully designed to make everyone as miserable as humanly possible. Or at least that was my take-away. Lenora Chu has a kinder perspective on the system. Mostly.</p><p>…Why do students and parents put up with all this? Are they just brainwashed by an authoritarian culture and government? Probably yes, at least to some degree. But there’s also a rational calculus at play…The modern manifestation of the Imperial Exam is the <em>gaokao</em>. This single test given during the last year of secondary school is the sole determinant of the vast majority of Chinese students’ abilities to get into a domestic university. Its subject matter is certainly more practical than the old exams—math, Chinese literature, and English—though probably still fairly esoteric by Bryan Caplan’s standards.</p><p>Lenora stresses that though the <em>gaokao</em> is the flagship mega-test that everyone focuses on, basically all of Chinese education is a series of <em>gaokaos</em>. Students and parents believe that every homework assignment, quiz, and class test serves as a signal of a student’s ability in a giant country-wide competition to reach the top echelon of Chinese society. Every failure, no matter how small, sets a student back and jeopardizes his entire life. This is why one of Lenora’s friends enrolled his three-year-old son in a pre-<span class="smallcaps-auto">MBA</span> program. It’s also why virtually all of Rainey’s classmates’ parents thought Lenora was a horrible mother for giving Rainey “idle time” on the weekends instead of enrolling him in Chinese writing classes, English classes, piano classes, algebra classes, etc. All the parents believed that by getting their kids into these programs at this stage (barely post-toddler), they were getting a head-start, and that head-start would carry into primary school, then secondary school, then university, then work, then life. It was all about getting ahead.</p><p>Lenora did her best to avoid the rat race, but found that it was too all-encompassing. At Soong Qing Ling, Lenora dreaded seeing the “Big Board”—a bulletin board hung up outside Rainey’s classroom where his teacher posted constant updates of students’ stats. Some of these stats were relatively innocuous—like the height and weight of every student—while other stats ranged from shoe size and blood type, to individual teacher’s comments on instrument playing (apparently Rainey had no sense of rhythm). Naturally, Lenora didn’t care about any of this stuff, but the other parents did. She watched mothers gloat over the physical prowess of their three-year-old children, take shots at each other over public admonishments, and generally make mountains out of utterly benign molehills. Lenora’s enduring shame was that Rainey was bad at playing the recorder. Despite getting stern warnings from the teacher and other parents, Rainey never improved, and eventually he was the only student left out of the class’s recorder concert in front of all the parents.</p><p>Lenora realized that, again, there was a method to the madness. Soong Qing Ling was training students and parents to compete. A three-year-old who learns to compete over public displays of height, recorders, and blood types, will learn to compete over grades in the future. Parents who are ready to fight the same battles will drive their children into the fray for years to come. Everyone learned that they were at war, or rather, in a battle royale. Only the very best survive, and pre-school at Soong Qing Ling was just the beginning.</p><p>…I guess I couldn’t help but come away from the book with a sense of depressing apathy. There’s so much effort put into education by well-meaning people, but a lot of it just seems to make children and parents hate everything. China apparently spent 2,700 years perfecting its education system, and this is the result… students being force-fed, parents shamed into kowtowing, and teachers corruptly abusing their power. Yes, there are good people in the system to, and apparently the children learn something and it does give some sort of order to society, but I really, really wish they didn’t have to this way.</p>'
- - https://dormin.org/2020/01/23/everything-you-need-to-know-about-napoleon-bonaparte/
  - Everything You Need to Know About Napoleon Bonaparte
  - Dormin
  - 2019-12-08
  - ''
  - ! '<p>[Review/summary of Andrew Roberts’s 2014 <a href="https://www.amazon.com/Napoleon-Life-Andrew-Roberts/dp/0143127853"><em>Napoleon: A Life</em></a>.]</p><p><a href="https://en.wikipedia.org/wiki/Napoleon_Bonaparte">Napoleon Bonaparte</a> had one of the most accomplished, divisive, <em>big</em> lives of any person in history, which reshaping the way we think about war, politics, revolution, culture, law, religion, and so much more in a mere 52 years. Any one of those elements could (and has) been isolated and made into a massive tome on its own.</p><p>So I just set out to describe and analyze all of the things I found most interesting about the man. This includes a summary of his entire life, his personality quirks, unusual events, driving beliefs, notable skills, and more. If there is an over-arching theme to be found, it’s my amazement at how an extraordinarily competent and risk-tolerant individual lived his life up to the greatest heights only to come tumbling back down to earth.</p>'
- - https://dormin.org/2020/01/22/the-phantoms-pain-a-metal-gear-solid-v-narrative-analysis/
  - "The Phantom’s Pain—A <em>Metal Gear Solid V</em> Narrative Analysis"
  - Dormin
  - 2020-01-22
  - ''
  - ! '<p>When I first finished <a href="https://en.wikipedia.org/wiki/Metal_Gear_Solid_V:_The_Phantom_Pain"><em>Metal Gear Solid V: The Phantom Pain</em></a>, like so many other players, I was disappointed. <span class="smallcaps-auto">MGSV</span> was supposed to be the “Missing Link” in the <a href="https://en.wikipedia.org/wiki/Metal_Gear">Metal Gear</a> canon. It was that game that would reveal the bridge between the heroic <a href="https://en.wikipedia.org/wiki/Big_Boss_(Metal_Gear)">Big Boss</a> of <a href="https://en.wikipedia.org/wiki/Metal_Gear_Solid_3:_Snake_Eater"><em><span class="smallcaps-auto">MGS</span> 3</em></a>, <a href="https://en.wikipedia.org/wiki/Metal_Gear_Solid:_Portable_Ops"><em>Portable Ops</em></a>, and <a href="https://en.wikipedia.org/wiki/Metal_Gear_Solid:_Peace_Walker"><em>Peace Walker</em></a>, and the grand historical villain of <a href="https://en.wikipedia.org/wiki/Metal_Gear_(video_game)"><em>Metal Gear 1</em></a> and <a href="https://en.wikipedia.org/wiki/Metal_Gear_2:_Solid_Snake"><em>2</em></a>. As expressed by numerous launch trailers and <a href="https://en.wikipedia.org/wiki/Hideo_Kojima">Hideo Kojima</a> tweets, <span class="smallcaps-auto">MGSV</span> was going to be a tale of Big Boss’s fall into darkness, driven by an insatiable lust for revenge, a consummate anger lit by his enemies which would scorch his soul until nothing was left but a power-hungry mad man who would threaten the world with nuclear war for the sake of his deluded ambitions. Instead we got an incredibly weird twist which did little more than retcon patch a largely ignored plot hole in one of the least-played Metal Gear games. We found out that the final boss of <em>Metal Gear 1</em> was not Big Boss, but a body double, who through surgery and hypnotherapy was made into almost an exact copy of the legendary soldier. Again, like most other players, when I first finished the game I thought this was a neat trick, a typically crazy, convoluted, but seductively entertaining twist from one of my favorite storytellers of all time. But of course… it was also a major let down.</p><p>…It wasn’t until I had put over 200 hours into my save file and replayed the entire game for a second time that the impact of <em>Metal Gear Solid V</em>’s story really hit me. Not only does <span class="smallcaps-auto">MGSV</span> do exactly what it was advertised to do—reveal the descent of Big Boss from hero to villain—but it does so in a subtle and narratively ambitious manner at a depth not seen in any video game since <a href="https://en.wikipedia.org/wiki/Metal_Gear_Solid_2:_Sons_of_Liberty"><em>Metal Gear Solid 2: Sons of Liberty</em></a>.</p><p><span class="smallcaps-auto">MGSV</span> is the story of Big Boss’s fall from grace, but it’s also so much more than that. <span class="smallcaps-auto">MGSV</span> may very well be Kojima’s magnum opus. The game distills all of the Metal Gear series’ most important thematic elements into a relatively simple story with a deceptively small scale. The reason the vast majority of players didn’t realize this is because, well, Kojima can be too subtle for his own good…<span class="smallcaps-auto">MGSV</span> really is about Big Boss becoming a horrible monster worthy of every conceivable condemnation. But that story is the bedrock layer hidden beneath a million other narrative layers designed to confuse and manipulate the player, in exactly the same way Big Boss and Zero’s whole Phantom Snake project was designed to confuse and manipulate Venom Snake.</p>'
- - https://dormin.org/2020/01/22/the-new-epidemic-my-experience-of-losing-a-friend-to-heroin/
  - 'The New Epidemic—My Experience of Losing a Friend to Heroin'
  - Dormin
  - 2019-06-10
  - ''
  - ! '<p>[Personal memoir of growing up in the rural US northeast and losing a friend to heroin overdosing. Despite living in a stable and relatively well-off white middle-class family, the friend ‘Jack’ had always suffered health problems and severe social anxiety, especially compared to his accomplished popular younger brother. Jack was never truly happy, and clashed with his brother, who resented his problems and the drain on parents. In high school, Jack gravitated to a group of bad peers who began drug use, existing in a constant malaise. A chance injury and painkiller prescription led to an opioid addiction, and then heroin. His parents invested enormous amounts of effort into rehab and monitoring Jack and trying to get him launched on some sort of real higher education and career, if only a trade, but Jack was uninterested and kept returning to drugs in between endless video game playing. This destroyed the family finances &amp; relationships.]</p><p>I’m a libertarian who thinks all drugs should be legalized, including heroin. But I have to admit that learning what Jack’s addiction did to his family made me understand the “Drug Warrior” perspective better. Unless an addict has no social connections whatsoever, his addiction will hurt others. The stronger the connections, the worse the pain. If the supporting friends and family members hold on tightly enough, it will destroy them. Derrick described the five years of being with Jack through his addiction until his death as a “living hell.”</p><p>To start with, fighting addiction costs money. Jack’s family was solidly middle-class, with his father pulling in enough money alone for the mother not to work while affording a nice home, comfortable day-to-day life, and the occasional vacation. They were decently well-off, but not enough to sustain the hit of $150K+ of rehab costs. I noticed some of the effects from afar but didn’t get the full picture until after Jack died. First the family stopped going on vacations, then the mom got part-time work (which wasn’t easy while trying to keep Jack in Lockdown), then the father worked longer hours, and eventually they were draining their retirement funds and mortgaging their house. But monetary costs were nothing compared to the emotional toll. How happy can you really be on a day-to-day basis when you come home to where your heroin-addicted son or brother lives? Jack’s parents basically lost their lives. Every single day, every single minute, was oriented around Jack. They always had to know where he was, what he was doing, when his next Narcotics Anonymous meeting was, if they could afford that therapist, etc. The father no longer worked to build college and retirement funds, but to pay off debts. The mother didn’t stay home to take care of the house and kids, but to keep her son alive. Then there was the lying…The fighting became worse than ever. They weren’t physical anymore, not while Jack deteriorated and Derrick bulked up. Yet they were more vicious than ever. More personal…For years before then, Derrick’s life had inexorably been consumed by Jack. The instant Derrick showed his parents Jack’s track marks, his childhood ended. Jack became a black hole at the center of the family which sucked everything in. Money, energy, time, and attention only flowed one way. Derrick stopped being another son and was repurposed as an asset to be employed by his parents for Jack’s sake.</p><p>…For me, the scariest part of learning Jack’s full story was realizing that <em>he may have been acting rationally</em>. I’m not saying that being a heroin addict is rational, and I’m not saying that Jack made good choices, especially not given the emotional carnage left in his wake, but… I think I understand why he kept going back to the drugs…I think everyone is aware of these shitty parts of life. But almost everyone is also aware of the good parts. Family, friends, and loved ones reflect our values and fuel our lives. Hobbies, passions, and maybe even work are outlets for our virtues that convert effort and inspiration into rewards. It’s not easy, but we all fight to make the good parts as big as possible while minimizing, mitigating, or maybe even ignoring the bad parts. I don’t think Jack was ever aware of the good parts. And I think his bad parts were intrinsically worse than most people’s…Jack was painfully aware that his future options were, “be a complete loser,” or “be a complete loser who feels really really good for a few hours every day.” He chose the latter.</p><p>…One day, when Jack was 23-years-old, his parents left the house together to see a movie. It was the first time they had gone out together without Jack in six months.. The parents came home with a cheeseburger for Jack, and they found him in his room, passed out in his own vomit on his bed. His mother called 911 while his father tried to resuscitate him, but Jack was already dead. His cause of death was an overdose, though it’s unclear whether he accidentally took too much or hit a bad batch. After the wake and funeral and shock, Derrick admitted that he felt <em>relief</em>. It was finally over.</p>'
- - https://dormin.org/2020/01/22/peep-show-the-most-realistic-portrayal-of-evil-ive-ever-seen/
  - '<em>Peep Show</em>—The Most Realistic Portrayal of Evil Ever Made'
  - Dormin
  - 2019-10-27
  - ''
  - ! '<p><a href="https://en.wikipedia.org/wiki/Peep_Show_(British_TV_series)"><em>Peep Show</em></a>, a British TV series running from 2003 to 2015, starring David Mitchell and Robert Webb as a pair of miserable, co-dependent roommates living in Croydon, London, <em>is the most realistic portrayal of evil</em> I have ever seen.</p><p>…We see this all not just by watching Mark and Jez go about their day-to-day lives, but by hearing their inner thoughts through voice-over monologues, which more often than not, reveal their actions and words as either cynical attempts to avoid facing their own failings, or desperate lies to obscure their true intentions, goals, and personalities.</p><p>This is what makes <em>Peep Show</em> so brilliant. It doesn’t just portray evil realistically, it portrays the <em>root</em> of evil realistically. Mark and Jeremy cause bad things to happen to their acquaintances, co-workers, friends, loved ones, family members, and most of all, <em>themselves</em>, because they are consumed by their vices. Not just the classic vices like gluttony and lust, but <em>cowardice</em>, <em>evasion</em>, <em>hypocrisy</em>, and <em>apathy</em>, all born from a rarely acknowledged, yet omnipresent <em>self-loathing</em>. These are vices that aren’t loudly announced by violent psychopaths or easily identified in scary individuals, but vices that sneak up on ordinary people, latch on to their psyches, and take over their lives.</p><p>Also, it’s one of the funniest TV shows I’ve ever seen.</p>'
- - https://dormin.org/2020/01/22/hill-billy-elegy-the-culture-of-white-american-poverty/
  - '<em>Hillbilly Elegy</em>—The Culture of White American Poverty'
  - Dormin
  - 2018-12-31
  - ''
  - ! '<p>I’ve written a couple of book summaries on here over the past few months, and this one for <a href="https://en.wikipedia.org/wiki/Hillbilly_Elegy"><em>Hillbilly Elegy</em></a> will be the most difficult. <a href="https://en.wikipedia.org/wiki/J._D._Vance">J.D. Vance</a>’s autobiography is a sociological summary of Appalachian American culture, and by extension the culture of poverty across America, which uses his own life as a case study. The book is basically a series of linked anecdotes with only occasional introspections thrown in, so I’ll try my best to lay out Vance’s story, and integrate his claims and arguments.</p><p>…You know that classic Republican straw man about poor people? It goes something like—</p><blockquote><p>“In the glorious modern American capitalist economy, all people can pick themselves up by their bootstraps and make a good living if they really want to. The only way to fail is to not try hard enough. Poor people are all lazy loafers who would rather take drugs, rack up illegitimate children, and become welfare queens, than work an honest day in their lives. It’s their own damn fault they’re poor.”</p></blockquote><p>Vance argues that this straw man is basically true.</p><p>Yes, of course it’s more complicated than that. There are external factors at play that makes the lives of his fellow hillbillies in Appalachia worse, like the collapse of American industrialism. But underlying the depressed economies, high unemployment, underfunded schools, and shoddy welfare networks, are simply a lot of bad decisions made on an individual level…Only a very select few hillbillies “make it” in the sense of achieving a stable, middle-class lifestyle. J.D. Vance is one of those few. He starts off the book saying that he feels ridiculous writing a memoir because his “greatest accomplishment” to date was graduating from Yale Law School. Yet, as he walks the reader through his life, it becomes more and more apparent just how amazing that feat is…I was aware of all these stereotypes before reading the book, but seeing them so fully fleshed out really brought home how scary it is. These people probably aren’t evil… but a lot of them are kind of bad. Or at least foolish. Or at least make really stupid decisions all the time. Somehow, that’s even scarier than being evil, or at least it’s harder to fix.</p><p>…Vance consistently stresses that by raw material standards, nobody in Middletown was doing <em>that</em> badly. Yet they were miserable, depressed, addicted, and hopeless anyway.</p><p>For instance, when Mom was with her first husband, the toothless hillbilly guy, they could be considered solidly middle-class. Mom was a nurse, her husband was a truck driver, and together they made over $100K per year with two kids in a low-cost-of-living region of America. And yet financial problems were always one of the biggest triggers of family screaming matches. They were deeply in debt because both Mom and the husband bought multiple new cars per year, they ate out every day instead of cooking, and they purchased a below-ground swimming pool. The house was already mortgaged, but was falling into disrepair due to lack of upkeep, while they repeatedly crashed new cars, and burned through meager savings with credit card fees. Vance’s family could have been fine. His parents could have lived comfortably, had good savings, and started a college fund. And maybe if they did, the stress wouldn’t have driven Mom and husband to break up, and Mom wouldn’t have turned to drugs, etc. But it didn’t turn out that way.</p><p>Throughout the book, I had a question that I wished Vance would have answered directly. <strong>Are hillbilly values the problem, or hypocrisy against these values?</strong></p>'
- - https://dormin.org/2020/01/22/disaster-artist-insanity-is-no-shortcut-to-inspiration/
  - '<em>Disaster Artist</em>—Insanity is No Shortcut to Inspiration'
  - Dormin
  - 2019-04-29
  - ''
  - ! '<p>I read <a href="https://en.wikipedia.org/wiki/The_Disaster_Artist"><em>Disaster Artist</em></a> on a whim when <a href="https://en.wikipedia.org/wiki/The_Disaster_Artist_(film)">the movie</a> came out. I’ve since gone through the audiobook 3.5 times and can confidently say it’s one of my favorite books of all time. I expected just to hear funny anecdotes about the making of <a href="https://en.wikipedia.org/wiki/The_Room_(film)">a famously awful movie</a> and <a href="https://en.wikipedia.org/wiki/Tommy_Wiseau">the man behind it</a>, but I found so much more depth. In my eyes, <em>Disaster Artist</em> is an examination of insanity (which I am defining as “the inability to perceive reality to the degree of low or non-functionality in regular life”). The book is a pushback against a subtle cultural norm that sees crazy people as having some sort of <em>gift</em> or <em>potential</em> or <em>insight</em> that everyone else doesn’t.</p><p>This message hit me especially hard because I had my first real experience with a crazy person only a few months before I read <em>Disaster Artist</em>…We fired our employee. We offered a small severance, about ¼ of his monthly salary, just to smooth things over. The employee demanded a full month’s salary, which he said he needed to provide for his wife and child. Then he (an ex-marine) threatened to personally kill me if we didn’t pay him.</p><p>That 30 minute phone call was terrifying. I wasn’t actually scared of being murdered, and we never gave in to his demands, but it wasn’t until that call that I understood what it meant to be <em>crazy</em>. It unnerved me in a sort of <em>staring into the abyss</em> way. This man was truly detached from reality. He either didn’t know or could not understand the facts before him. When presented with reality, he would lash out in pain and anguish and fury at phantom targets. I would make calm, reasonable arguments about how he had violated his work contract, hurt our business, hurt our clients, and lied to us, and he would respond with nonsensical excuses, random tangents, blaming his personal life, and never ever coming close to acknowledging his own culpability.</p><p>I came away from the conversation with a mixture of pity, revulsion, and dread. I don’t know if this guy was bipolar, drug-addled, schizophrenic, or what, but I was 100% sure that this man lived in a nightmare. Everything was confusing and nonsensical to him. The world was dark, malevolent, and couldn’t stop hurting him even as he tried his best. I had an imagine of him sitting alone in his tiny apartment listening to that one student’s song over-and-over again on repeat while his mind blurred between random scientific and historical topics until he could no longer fight the urge to pick up the phone and call me or someone like me who took enough pity on him to politely listen for a few minutes until we made excuses and left him back alone in silence.</p><p>I see Tommy Wiseau, the creator of <em>The Room</em> and the subject of <em>Disaster Artist</em>, in the same category as my ex-employee. The form of their insanity is somewhat different, but both men live tortured, miserable lives, and constantly lash out at bystanders because of it. However, unlike my ex-employee, Wiseau is beloved by the masses <em>precisely</em> for his insanity. This is a dangerous, inaccurate, unfair reality, and in my opinion, is precisely what the <em>Disaster Artist</em> book argues against.</p>'
- - /docs/psychology/2014-shen.pdf
  - ! 'When Correcting for Unreliability of Job Performance Ratings, the Best Estimate Is Still 0.52'
  - Winny Shen, Jeffrey M. Cucina, Philip T. Walmsley, Benjamin K. Seltzer
  - 2014-12-01
  - 10.1017/S1754942600006805
  - ! '<p>In this commentary we answer 3 questions that are often posed when debating the usefulness and accuracy of correcting criterion-related validity coefficients for unreliability: (a) Is 0.52 an inaccurate estimate? (b) Do corrections for criterion unreliability lead us to choose different selection tools? (c) Is too much variance explained?</p><p>[1. Yes; 2. No, because rank-order of tools’ utility is preserved by the corrections; 3. No, because while everything is correlated <em>r</em>=0.30 on average, most of those variables are unknowable at hiring time and also adding up variables ignores diminishing returns/intercorrelations between the <em>predictors</em>, so one will never predict perfectly.]</p><p><em>Conclusion</em>: Based on our review of the evidence, the 0.52 estimate of the interrater reliability of supervisor ratings of job performance is an appropriate estimate; corrections for unreliability do not appear to change our decisions regarding the choice of one selection tool over another; and most variables may be more strongly correlated than people expect, making it difficult to demonstrate continued incremental validity in predicting job performance when adding additional predictors. We agree with LeBreton et al. that psychologists need to be careful when applying and interpreting corrections, and we are thankful that they sponsored a discussion on the topic. Corrections are critical for both basic science (i.e., estimating population parameters) and practice (i.e., recognizing artifacts attenuating estimates on which our work may be evaluated by stakeholders, courts, and other third parties). Ultimately, the appropriate use of corrections depends on the purpose of the project. If the goal is to explain variation among a sample of incumbents on observed criterion scores, then no corrections need to be made. If the goal is to explain variation among incumbents on a true score for job performance, then a correction for unreliability is not only desirable but necessary. Finally, if the goal is to estimate how much variation among applicants is explained by a predictor for a true score on job performance, then corrections for range restriction and unreliability are indispensable. This goal represents the target validity inference that was included in Binning and Barrett’s (1989) figure, but (rather interestingly) is omitted from LeBreton et al.’s reproduction of that figure. We believe that the target validity inference is the most important inference in personnel selection; it provides the critical link from the observed predictor to the criterion construct (see also Putka &amp; Sackett, 2010).</p>'
- - /docs/psychology/2019-doyle.pdf
  - ! 'Peer-rated organizational citizenship behavior: Does familiarity improve rating quality?'
  - Kevin Doyle, Richard Goffin, David Woycheshin
  - 2019-08-08
  - 10.1027/1866-5888/a000229
  - ! '<p>Organizational Citizenship Behavior (<span class="smallcaps-auto">OCB</span>) is valuable to organizations and has become an important focus of employee performance evaluation. Employees’ peers may be particularly well-situated to rate their <span class="smallcaps-auto">OCB</span>. We investigated the proportion of variance in peer-rated <span class="smallcaps-auto">OCB</span> attributable to the ratee (true score) versus the rater (rater bias). Furthermore, we investigated whether these proportions were affected by the familiarity of the peer with the ratee. We found that high familiarity was associated with a greater proportion of ratee variance (0.43 vs. 0.18), and a lower proportion of rater bias (0.30 vs. 0.51), than was the case with low-to-moderate familiarity. Thus, when choosing peers as raters of <span class="smallcaps-auto">OCB</span>, there may be value in carefully considering the peers’ familiarity with the ratees. [Keywords: performance management, contextual performance, organizational citizenship behavior, familiarity, rater bias]</p>'
- - /docs/psychology/2020-tu.pdf
  - ! 'Computing Univariate Neurodegenerative Biomarkers with Volumetric Optimal Transportation: A Pilot Study'
  - Yanshuai Tu, Liang Mi, Wen Zhang, Haomeng Zhang, Junwei Zhang, Yonghui Fan, Dhruman Goradia, Kewei Chen, Richard J. Caselli, Eric M. Reiman, Xianfeng Gu, Yalin Wang
  - 2020-04-06
  - 10.1007/s12021-020-09459-7
  - ! '<p>Changes in cognitive performance due to neurodegenerative diseases such as Alzheimer’s disease (AD) are closely correlated to the brain structure alteration. A univariate and personalized neurodegenerative biomarker with strong statistical power based on magnetic resonance imaging (<span class="smallcaps-auto">MRI</span>) will benefit clinical diagnosis and prognosis of neurodegenerative diseases. However, few biomarkers of this type have been developed, especially those that are robust to image noise and applicable to clinical analyses. In this paper, we introduce a variational framework to compute optimal transportation (OT) on brain structural <span class="smallcaps-auto">MRI</span> volumes and develop a univariate neuroimaging index based on OT to quantify neurodegenerative alterations. Specifically, we compute the OT from each image to a template and measure the Wasserstein distance between them. The obtained Wasserstein distance, Wasserstein Index (WI) for short to specify the distance to a template, is concise, informative and robust to random noise. Comparing to the popular linear programming-based OT computation method, our framework makes use of Newton’s method, which makes it possible to compute WI in large-scale datasets. Experimental results, on 314 subjects (140 Aβ + AD and 174 Aβ- normal controls) from the Alzheimer’s Disease Neuroimaging Initiative (<span class="smallcaps-auto">ADNI</span>) baseline dataset, provide preliminary evidence that the proposed WI is correlated with a clinical cognitive measure (the Mini-Mental State Examination (<span class="smallcaps-auto">MMSE</span>) score), and it is able to identify group difference and achieve a good classification accuracy, outperforming two other popular univariate indices including hippocampal volume and entorhinal cortex thickness. The current pilot work suggests the application of WI as a potential univariate neurodegenerative biomarker.</p>'
- - /docs/biology/2006-demonaco.pdf
  - ! 'The Major Role of Clinicians in the Discovery of Off-Label Drug Therapies'
  - Harold J. DeMonaco, Ayfer Ali, Eric von Hippel
  - 2006-03-01
  - 10.1592/phco.26.3.323
  - ! '<p><em>Objective</em>: To determine the role of clinicians in the discovery of off-label use of prescription drugs approved by the United States Food and Drug Administration (<span class="smallcaps-auto">FDA</span>).</p><p><em>Data Sources</em>: Micromedex Healthcare Series was used to identify new uses of new molecular entities approved by the <span class="smallcaps-auto">FDA</span> in 1998, literature from January 1999–December 2003 was accessed through <span class="smallcaps-auto">MEDLINE</span>, and relevant patents were identified through the U.S. Patent and Trademark Office.</p><p><em>Data Synthesis and Main Finding</em>: A survey of new therapeutic uses for new molecular entity drugs approved in 1998 was conducted for the subsequent 5 years of commercial availability. During that period, 143 new applications were identified in a computerized search of the literature for the 29 new drugs considered and approved in 1998. Literature and patent searches were conducted to identify the first report of each new application. Authors of the seminal articles were contacted through an electronic survey to determine whether they were in fact the originators of the new applications. If they were, examination of article content and author surveys were used to explore if each new application was discovered through clinical practice that was independent of pharmaceutical company or university research (field discovery) or if the discovery was made by or with the involvement of pharmaceutical company or university researchers (central discovery). 82 (57%) of the 143 drug therapy innovations in our sample were discovered by practicing clinicians through field discovery.</p><p><em>Conclusion</em>: To our knowledge, the major role of clinicians in the discovery of new, off-label drug therapies has not been previously documented or explored. We propose that this finding has important regulatory and health policy implications.</p>'
- - /docs/iq/2007-johnson.pdf
  - ! 'Sex differences in mental abilities: <em>g</em> masks the dimensions on which they lie'
  - Wendy Johnson, Thomas J. Bouchard Jr.
  - 2007-01-01
  - 10.1016/j.intell.2006.03.012
  - ! '<p>Empirical data suggest that there is at most a very small sex difference in general mental ability, but men clearly perform better on visuospatial tasks while women clearly perform better on tests of verbal usage and perceptual speed. In this study, we integrated these overall findings with predictions based on the Verbal–Perceptual–Rotation (<span class="smallcaps-auto">VPR</span>) model ([Johnson, W., and Bouchard, T. J. (2005a). “Constructive replication of the visual–perceptual–image rotation (<span class="smallcaps-auto">VPR</span>) model in Thurstone’s (1941) battery of 60 tests of mental ability”. <em>Intelligence</em>, 33, 417–430.; Johnson, W., and Bouchard, T. J. (2005b). “The structure of human intelligence: It’s verbal, perceptual, and image rotation (<span class="smallcaps-auto">VPR</span>), not fluid and crystallized”. <em>Intelligence</em>, 33. 393–416.]) of the structure of mental abilities. We examined the structure of abilities after removing the effects of general intelligence, identifying three underlying dimensions termed rotation–verbal, focus–diffusion, and memory. Substantial sex differences appeared to lie along all three dimensions, with men more likely to be positioned towards the rotation and focus poles of those dimensions, and women displaying generally greater memory. At the level of specific ability tests, there were greater sex differences in residual than full test scores, providing evidence that general intelligence serves as an all-purpose problem solving ability that masks sex differences in more specialized abilities. The residual ability factors we identified showed strong genetic influences comparable to those for full abilities, indicating that the residual abilities have some basis in brain structure and function. [Keywords:, Sex differences, Residual mental abilities, Verbal and spatial abilities, General intelligence, <span class="smallcaps-auto">VPR</span> theory, Genetic and environmental influences]</p>'
- - https://www.damninteresting.com/the-eponymous-mr-ponzi/
  - "The Eponymous Mr. Ponzi: The little known story of an age-old scam"
  - Michael Durbin (Damn Interesting)
  - 2019-09-02
  - ''
  - ! '<p>[More in-depth profile of Charles Ponzi, who was not the first to run a Ponzi scheme but named it. Who was Charles Ponzi? An Italian immigrant of many names who loved to live well but not wisely—always going too far, winding up hard up, and screwing up when he finally moves up. Ponzi’s final chapter came when he discovered a genuine international postage loophole, but instead of eking out a small profit, kept going and going, eventually trying to take over a bank to manage the scheme and extract ‘loans’ to tide him over—which brought him too much attention from the authorities, but even they couldn’t pop the ponzi until an accountant and revelations of his past crimes ended it.]</p>'
- - https://ai.facebook.com/blog/state-of-the-art-open-source-chatbot
  - "Blender: A state-of-the-art open source chatbot"
  - Stephen Roller, Jason Weston, Emily Dinan (Facebook)
  - 2020-04-29
  - ''
  - ! '<ul><li>Facebook AI has <a href="https://arxiv.org/abs/2004.13637#facebook" title="&#39;Recipes for building an open-domain chatbot&#39;, Roller et al 2020">built</a> and <a href="https://parl.ai/projects/blender/" title="ParlAI project page: &#39;Recipes for building an open-domain chatbot&#39;">open-sourced</a> Blender, the largest-ever open-domain chatbot. It outperforms others in terms of engagement and also feels more human, according to human evaluators.</li><li>The culmination of years of research in conversational AI, this is the first chatbot to blend a diverse set of conversational skills—including empathy, knowledge, and personality—together in one system.</li><li>We achieved this milestone through a new chatbot recipe that includes improved decoding techniques, novel blending of skills, and a model with 9.4 billion parameters, which is 3.6× more than the largest existing system.</li><li>Today we’re releasing the complete model, code, and evaluation set-up, so that other AI researchers will be able to reproduce this work and continue to advance conversational AI research.</li></ul><p>…This is the first time a chatbot has learned to <a href="https://arxiv.org/abs/2004.08449#facebook" title="&#39;Can You Put it All Together: Evaluating Conversational Agents&#39; Ability to Blend Skills&#39;, Smith et al 2020">blend several conversational skills</a>—including the ability to assume a persona, discuss nearly any topic, and show empathy—in natural, 14-turn conversation flows. Today we’re sharing new details of the key ingredients that we used to create our new chatbot… Our new recipe incorporates not just large-scale neural models, with up to 9.4 billion parameters—or 3.6× more than the largest existing system—but also equally important techniques for blending skills and detailed generation…We used previously available public domain conversations that involved 1.5 billion training examples of extracted conversations. Our neural networks are too large to fit on a single device, so we utilized techniques such as column-wise model parallelism, which allows us to split the neural network into smaller, more manageable pieces while maintaining maximum efficiency. Such careful organization of our neural networks enabled us to handle larger networks than we could previously while maintaining the high efficiency needed to scale to terabyte-size data sets.</p><p>…However, to make sure conversational agents don’t repeat themselves or display other shortcomings, researchers typically use a number of possible generation strategies after the model is trained, including beam search, next token sampling, and n-gram blocking. We find that the length of the agent’s utterances is important in achieving better results with human evaluators. If they’re too short, the responses are dull and communicate a lack of interest; if they’re too long, the chatbot seems to waffle and not listen. Contrary to <a href="https://arxiv.org/abs/1904.09751" title="&#39;Nucleus sampling: The Curious Case of Neural Text Degeneration&#39;, Holtzman et al 2019">recent research</a>, which finds that sampling outperforms beam search, we show that a careful choice of search hyperparameters can give strong results by controlling this trade-off. In particular, tuning the minimum beam length gives important control over the “dull versus spicy” spectrum of responses.</p><figure><img src="/images/rl/2020-roller-facebook-blenderchatbot-ratedperformancevshumans.jpg" alt="https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/95262464_953017925128000_4381352368361439232_n.jpg?_nc_cat=105&amp;_nc_sid=ad8a9d&amp;_nc_ohc=mpgDMsQgnt0AX_fg8Rm&amp;_nc_ht=scontent-iad3-1.xx&amp;oh=17baeed46121a27c3b8915dec684149b&amp;oe=5ECDA45E" /><figcaption>In this graph, we show how often human evaluators preferred our chatbots to human-to-human chats over time. Since 2018, we’ve improved model performance in this evaluation—from 23% in 2018 to 49% today.</figcaption></figure>'
- - /docs/genetics/heritable/1999-stoolmiller.pdf
  - ! 'Implications of the restricted range of family environments for estimates of heritability and nonshared environment in behavior–genetic adoption studies'
  - Mike Stoolmiller
  - 1999-07-01
  - 10.1037/0033-2909.125.4.392
  - ! '<p>Group and individual-difference adoption designs lead to opposite conclusions concerning the importance of shared environment (SE) for the child outcomes of IQ and antisocial behavior. This paradox could be due to the range restriction (RR) of family environments (FE) that goes with adoption studies. Measures of FE from 2 of the most recent adoption studies indicate that RR is substantial, about 67%, which corresponds to the top half of a normal FE distribution. FE of 57% cuts effect sizes and R² statistics by factors of 3 and 2–2.5, respectively. Because selection into an option study is inherently a between-family process and assuming that comparable restriction of genetic (G) influences are absent, estimates of SE, G, and nonshared influences will be substantially biased, respectively, down, up, and up by RR. Corrections for RR applied to adoption studies indicate that SE could account for as much as 50% of the variance in IQ. [Keywords: restricted range of family environments, estimates of heritability &amp; nonshared environment for child outcomes of IQ &amp; antisocial behavior in behavior–genetic adoption studies]</p>'
- - /docs/economics/2005-smilansky.pdf
  - ! 'The Paradox Of Beneficial Retirement'
  - Saul Smilansky
  - 2005-09-01
  - 10.1111/j.1467-9329.2005.00294.x
  - ! '<p>Morally, when should one retire from one’s job? The surprising answer may be ‘now’. It is commonly assumed that for a person who has acquired professional training at some personal effort, is employed in a task that society considers useful, and is working hard at it, no moral problem arises about whether that person should continue working. I argue that this may be a mistake: within many professions and pursuits, each one among the majority of those positive, productive, hard working people ought to consider leaving his or her job.</p>'
- - https://granta.com/let-there-be-light/
  - ! 'Let There Be Light!'
  - David Feuer (Granta)
  - 2001-12-22
  - ''
  - ! '<p>[Darkly humorous account of attempts at psychiatry among the Jewish Hasidim of Brooklyn. The author must deal with severe neglect &amp; denial of psychiatric issues inside insular religious/ethnic groups, how kosher applies to psychiatric drugs, obsession with ritual &amp; impurity like the man convinced a pig valve had been surgically implanted in his heart rendering him unkosher, and difficult social problems like women malingering to avoid having to bear yet another child or homophobia or fear of diagnosis handicapping them on the fiercely-competitive arranged-marriage market.]</p><p>According to the Rabbi, Hershel had been, since two days ago, much calmer. He was now only talking to actual people and he was even beginning to make sense. He had accompanied his mother to the grocery and for once Hershel had not viciously attacked the produce. He had accompanied his father to shul and for once Hershel had not loudly proclaimed himself to be the <a href="https://en.wikipedia.org/wiki/Messiah_in_Judaism">Mechiach</a>. In fact, he had told his father that, while he still did not like the job description of Messiah, at least he now realized that since nothing much was required of him until Judgement Day he could relax.</p>'
- - /docs/genetics/correlation/2013-hamshere.pdf
  - ! 'High Loading of Polygenic Risk for ADHD in Children With Comorbid Aggression'
  - Marian L. Hamshere, Kate Langley, Joanna Martin, Sharifah Shameem Agha, Evangelia Stergiakouli, Richard J.L. Anney, Jan Buitelaar, Stephen V. Faraone, Klaus-Peter Lesch, Benjamin M. Neale, Barbara Franke, Edmund Sonuga-Barke, Philip Asherson, Andrew Merwood, Jonna Kuntsi, Sarah E. Medland, Stephan Ripke, Hans-Christoph Steinhausen, Christine Freitag, Andreas Reif, Tobias J. Renner, Marcel Romanos, Jasmin Romanos, Andreas Warnke, Jobst Meyer, Haukur Palmason, Alejandro Arias Vasquez, Nanda Lambregts-Rommelse, Herbert Roeyers, Joseph Biederman, Alysa E. Doyle, Hakon Hakonarson, Aribert Rothenberger, Tobias Banaschewski, Robert D. Oades, James J. McGough, Lindsey Kent, Nigel Williams, Michael J. Owen, Peter Holmans, Michael C. O’Donovan, Anita Thapar
  - 2013-08-01
  - 10.1176/appi.ajp.2013.12081129
  - ! '<p><em>Objective</em>: Although attention deficit hyperactivity disorder (<span class="smallcaps-auto">ADHD</span>) is highly heritable, genome-wide association studies (<span class="smallcaps-auto">GWAS</span>) have not yet identified any common genetic variants that contribute to risk. There is evidence that aggression or conduct disorder in children with <span class="smallcaps-auto">ADHD</span> indexes higher genetic loading and clinical severity. The authors examine whether common genetic variants considered en masse as polygenic scores for <span class="smallcaps-auto">ADHD</span> are especially enriched in children with comorbid conduct disorder.</p><p><em>Method</em>: Polygenic scores derived from an <span class="smallcaps-auto">ADHD</span> <span class="smallcaps-auto">GWAS</span> meta-analysis were calculated in an independent <span class="smallcaps-auto">ADHD</span> sample (452 case subjects, 5,081 comparison subjects). Multivariate logistic regression analyses were employed to compare polygenic scores in the <span class="smallcaps-auto">ADHD</span> and comparison groups and test for higher scores in <span class="smallcaps-auto">ADHD</span> case subjects with comorbid conduct disorder relative to comparison subjects and relative to those without comorbid conduct disorder. Association with symptom scores was tested using linear regression.</p><p><em>Results</em>: Polygenic risk for <span class="smallcaps-auto">ADHD</span>, derived from the meta-analysis, was higher in the independent <span class="smallcaps-auto">ADHD</span> group than in the comparison group. Polygenic score was significantly higher in <span class="smallcaps-auto">ADHD</span> case subjects with conduct disorder relative to <span class="smallcaps-auto">ADHD</span> case subjects without conduct disorder. <span class="smallcaps-auto">ADHD</span> polygenic score showed significant association with comorbid conduct disorder symptoms. This relationship was explained by the aggression items.</p><p><em>Conclusions</em>: Common genetic variation is relevant to <span class="smallcaps-auto">ADHD</span>, especially in individuals with comorbid aggression. The findings suggest that the previously published <span class="smallcaps-auto">ADHD</span> <span class="smallcaps-auto">GWAS</span> meta-analysis contains weak but true associations with common variants, support for which falls below genome-wide significance levels. The findings also highlight the fact that aggression in <span class="smallcaps-auto">ADHD</span> indexes genetic as well as clinical severity.</p>'
- - /docs/iodine/1969-kevany.pdf
  - ! 'Prophylaxis and Treatment of Endemic Goiter with Iodized Oil in Rural Ecuador and Peru'
  - John Kevany, Rodrigo Fierro-Benitez, Eduardo A. Pretell, John B. Stanbury
  - 1969-12-01
  - 10.1093/ajcn/22.12.1597
  - ! '<p>Endemic goiter continues to be a significant health problem in many areas of the world. In some areas the disease is so severe that cretinism and other associated defects are found. In many areas, geographic, economic, and other factors prevent the use of iodized salt as a preventive measure.</p><p>A pilot program using iodized poppy seed oil has been instituted in two rural communities in Ecuador and three in Peru. Results after approximately 2 years indicate the feasibility and effectiveness of the programs. There has been a sharp reduction in the incidence of goiter. Cretinism has not yet appeared among the progeny of the population injected with iodized oil, but several instances have appeared in control groups. The use of iodized oil as a public health procedure for the prevention of endemic goiter and its associated defects is an acceptable measure in regions where salt-iodization programs cannot be presently undertaken.</p>'
- - /docs/linkrot/2006-wren.pdf
  - ! 'Uniform Resource Locator Decay in Dermatology Journals: Author Attitudes and Preservation Practices'
  - Jonathan D. Wren, Kathryn R. Johnson, David M. Crockett, Lauren F. Heilig, Lisa M. Schilling, Robert P. Dellavalle
  - 2006-09
  - 10.1001/archderm.142.9.1147
  - ! '<p><em>Objectives</em>: To describe dermatology journal uniform resource locator (<span class="smallcaps-auto">URL</span>) use and persistence and to better understand the level of control and awareness of authors regarding the availability of the <span class="smallcaps-auto">URL</span>s they cite.</p><p><em>Design</em>: Software was written to automatically access <span class="smallcaps-auto">URL</span>s in articles published between January 1, 1999, and September 30, 2004, in the 3 dermatology journals with the highest scientific impact. Authors of publications with unavailable <span class="smallcaps-auto">URL</span>s were surveyed regarding <span class="smallcaps-auto">URL</span> content, availability, and preservation.</p><p><em>Main Outcome Measures</em>: Uniform resource locator use and persistence and author opinions and practices.</p><p><em>Results</em>: The percentage of articles containing at least 1 <span class="smallcaps-auto">URL</span> increased from 2.3% in 1999 to 13.5% in 2004. Of the 1113 <span class="smallcaps-auto">URL</span>s, 81.7% were available (decreasing with time since publication from 89.1% of 2004 <span class="smallcaps-auto">URL</span>s to 65.4% of 1999 <span class="smallcaps-auto">URL</span>s) (<em>p</em>&lt;.001). Uniform resource locator unavailability was highest in <em>The Journal of Investigative Dermatology</em> (22.1%) and lowest in the <em>Archives of Dermatology</em> (14.8%) (<em>p</em>=.03). Some content was partially recoverable via the Internet Archive for 120 of the 204 unavailable <span class="smallcaps-auto">URL</span>s. Most authors (55.2%) agreed that the unavailable <span class="smallcaps-auto">URL</span> content was important to the publication, but few controlled <span class="smallcaps-auto">URL</span> availability personally (5%) or with the help of others (employees, colleagues, and friends) (6.7%).</p><p><em>Conclusions</em>: Uniform resource locators are increasingly used and lost in dermatology journals. Loss will continue until better preservation policies are adopted.</p>'
- - /docs/iq/2010-campbell.pdf
  - ! 'Project A: 12 Years of R&D'
  - John P. Campbell, Deirdre J. Knapp
  - 2010-01-01
  - ''
  - ! '<p>Origins of Project A · Enabling of Project A · Specific Research Objectives · Overall Research Design · Research Instrument Development: Predictors · Job Analyses and Criterion Development · Modeling the Latent Structure of Performance · Correlations of Past Performance With Future Performance · Criterion-Related Validation · Some Broader Implications · Conclusions · References</p><p>This chapter 1 is about personnel selection and classification research on a scale never before attempted in terms of (a) the types and variety of information collected, (b) the number of jobs that were considered simultaneously, (c) the size of the samples, and (d) the length of time that individuals were followed as they progressed through the organization.</p><p>The effort, commonly known as Project A, was sponsored by the U.S. Army Research Institute for the Behavioral and Social Sciences (<span class="smallcaps-auto">ARI</span>). For contract management reasons the research program was conducted as two sequential projects: Project A (1982–1989) and Career Force (1990–1994), which worked from a single overall design (described subsequently).</p><p>Collectively, these projects attempted to evaluate the selection validity and classification efficiency of systematically sampled domains of prediction information for different selection and classification goals for the entire enlisted personnel system of the U.S. Army, using various alternative decision rules (i.e., “models”). Pursuing such ambitious objectives required the development of a comprehensive battery of new tests and inventories, the development of a wide variety of training and job performance measures for each job in the sample, four major worldwide data collections involving thousands of Army enlisted job incumbents for one to two days each, and the design and maintenance of the resulting database.</p><p>The truly difficult part was the never-ending need to develop a consensus among all of the project participants regarding literally hundreds of choices among measurement procedures, analysis methods, and data collection design strategies. Although many such decisions were made in the original design stage, many more occurred continuously as the projects moved forward, driven by the target dates for the major data collections, which absolutely could not be missed. The fact that all major parts of the projects were completed within the prescribed time frames and according to the specified research design was a source of wonder for all who participated.</p>'
- - /docs/iq/2010-sellman.pdf
  - ! 'Selection and Classification in the U.S. Military'
  - Wayne S. Sellman, Dana H. Born, William J. Strickland, Jason J. Ross
  - 2010-01-01
  - ''
  - ! '<p>Military Personnel System · Indicators of Recruit Quality · Need for Military Selection · Short History of Military Personnel Testing (Pre-All Volunteer Force) · Moving to an All-Volunteer Force · <span class="smallcaps-auto">ASVAB</span> Misnorming and Job Performance Measurement Project · Enlisted Selection and Classification in Today’s Military · Enlistment Process · Recruit Quality Benchmarks and Enlistment Standards · Selection for Officer Commissioning Programs · Officer Retention and Attrition · Officer Executive Development · Command Selection and Career Broadening Experiences · Defense Transformation in Military Selection · Conclusions · References</p>'
- - /docs/nicotine/1991-hughes-2.pdf
  - ! 'Long-term Use of Nicotine vs Placebo Gum'
  - John R. Hughes, Steven W. Gust, Robert Keenan, James W. Fenwick, Kelli Skoog, Stephen T. Higgins
  - 1991-10-01
  - 10.1001/archinte.1991.00400100073012
  - ! 'Medical patients (_n_=315) who wished to quit smoking were randomly assigned in a double-blind manner to receive either nicotine or placebo gum. Subjects were advised to stop gum use by 4 months. Among abstinent smokers, 46% of those receiving nicotine gum and 17% of those receiving placebo gum used the gum beyond the recommended 4-month period. By 10 months after cessation 17% of quitters receiving nicotine gum and 6% receiving placebo gum were still using gum. Gradual reduction of nicotine gum did not result in withdrawal and cessation of nicotine gum did not increase the probability of relapse to smoking or weight gain. We conclude that use of nicotine gum is due, in part, to the effects of nicotine; however, long-term use is uncommon.<p>Medical patients (<em>n</em>=315) who wished to quit smoking were randomly assigned in a double-blind manner to receive either nicotine or placebo gum. Subjects were advised to stop gum use by 4 months. Among abstinent smokers, 46% of those receiving nicotine gum and 17% of those receiving placebo gum used the gum beyond the recommended 4-month period. By 10 months after cessation 17% of quitters receiving nicotine gum and 6% receiving placebo gum were still using gum. Gradual reduction of nicotine gum did not result in withdrawal and cessation of nicotine gum did not increase the probability of relapse to smoking or weight gain. We conclude that use of nicotine gum is due, in part, to the effects of nicotine; however, long-term use is uncommon.</p>'
- - /docs/nicotine/2003-klesges.pdf
  - ! 'Use of Nicotine Replacement Therapy in Adolescent Smokers and Nonsmokers'
  - Lisa M. Klesges, Karen C. Johnson, Grant Somes, Susan Zbikowski, Leslie Robinson
  - 2003-06-01
  - 10.1001/archpedi.157.6.517
  - ! '<p><em>Background</em>: Assessing whether and how adolescents use nicotine replacement therapy (<span class="smallcaps-auto">NRT</span>) will be important given recent recommendations to make <span class="smallcaps-auto">NRT</span> more accessible by lowering its price, increasing its distribution, and advising health care professionals to suggest its use for smoking cessation.</p><p><em>Objectives</em>: To report the prevalence, ease of access, and reasons for <span class="smallcaps-auto">NRT</span> use and describe inappropriate use in adolescent smokers and nonsmokers.</p><p><em>Design</em>: Cross-sectional survey of 4078 high school students during the school term of 1998.</p><p><em>Setting</em>: City schools in Memphis, Tenn.</p><p><em>Main Outcome Measures</em>: Community-based self-reported prevalence of <span class="smallcaps-auto">NRT</span> use and characteristics of those using <span class="smallcaps-auto">NRT</span>.</p><p><em>Results</em>: Approximately 5% of adolescents reported trying or using nicotine gum or patches. Females were less likely than males and African Americans were less likely than others to use <span class="smallcaps-auto">NRT</span>. For African American smokers, <span class="smallcaps-auto">NRT</span> use was highest at lower smoking levels, while other smokers showed the opposite pattern. Almost 40% of former smokers reported using <span class="smallcaps-auto">NRT</span> to try to quit smoking; however, 75% of current smokers endorsed using <span class="smallcaps-auto">NRT</span> for reasons other than trying to quit smoking. Other inappropriate use of <span class="smallcaps-auto">NRT</span> was reported; 18% of <span class="smallcaps-auto">NRT</span> users reported themselves as never smokers. More than 50% of students reported that it would be easy for them to get <span class="smallcaps-auto">NRT</span>.</p><p><em>Conclusions</em>: Nicotine replacement therapy is used by adolescent smokers and nonsmokers, is easily accessible, and is used for reasons other than trying to quit smoking. Efforts are needed to discourage <span class="smallcaps-auto">NRT</span> use in nonsmoking youth and to encourage appropriate use of <span class="smallcaps-auto">NRT</span> in young smokers to maximize its potential for successful cessation.</p>'
- - /docs/psychology/1990-murphy.pdf
  - ! 'The Lifetime Risk of Suicide in Alcoholism'
  - George E. Murphy, Richard D. Wetzel
  - 1990-04-01
  - 10.1001/archpsyc.1990.01810160083012
  - ! '<p>Current estimates of the lifetime risk of suicide in alcoholism (11% to 15%) are shown statistically to be untenable. Examination of the mortality from suicide in all published follow-up studies of alcoholics containing the requisite data permits calculation of a much smaller lifetime suicide risk: about 2% in untreated and 2.21% in outpatient-treated probands. Studies of alcoholics identified from hospital admissions yield a lifetime risk of about 3.4% for the United States, the United Kingdom, and other English-speaking countries. It is higher in the Scandinavian and European countries with high suicide rates, but not in those with low national suicide rates. The population at risk is shown to be about half of that commonly estimated, and consists of seriously affected alcoholics. While the annual incidence of suicide in the United States is about 1.3% currently, only that quarter of the population identifiably psychiatrically ill is at significant risk. Despite the seemingly minuscule lifetime risk of 2% to 3.4%, the likelihood of suicide in conservatively diagnosed alcoholism is between 60 and 120 times that of the non-psychiatrically ill. Such alcoholism contributes about 25% of the suicides.</p>'
- - /docs/melatonin/1996-shafii.pdf
  - ! 'Nocturnal Serum Melatonin Profile in Major Depression in Children and Adolescents'
  - Mohammad Shafii, Duncan R. MacMillan, Mary P. Key, Ann McCue Derrick, Nancy Kaufman, Irwin D. Nahinsky
  - 1996-11-01
  - 10.1001/archpsyc.1996.01830110047006
  - ! '<p><em>Background</em>: In major depression, biological rhythm disturbances in sleep, appetite, and mood suggest dysregulation in neuroendocrine functions, possibly in the pineal gland. In this study, pineal gland function was examined by measuring nocturnal serum melatonin levels during both wakefulness and sleep in depressed children and adolescents.</p><p><em>Methods</em>: 22 youths aged 8 to 17 years primarily with major depression were compared with 19 controls. Blood samples were drawn every half hour from 6 <span class="smallcaps-auto">PM</span> to 7 <span class="smallcaps-auto">AM</span>. Nocturnal serum melatonin levels were measured by radioimmunoassay.</p><p><em>Results</em>: The overall nocturnal serum melatonin profile from 6 <span class="smallcaps-auto">PM</span> to 7 <span class="smallcaps-auto">AM</span> was significantly higher (mean±SD, 0.18±0.14nmol/L) in the depressed group than in the controls [mean±SD, 0.15±0.10 nmol/L, F(1,26)=4.37, <em>p</em>&lt;.05]. In dim light, when the subjects were awake, no difference existed between the 2 groups. After lights-out, from 10 <span class="smallcaps-auto">PM</span> to 7 <span class="smallcaps-auto">AM</span>, the melatonin profile rose in both groups; however, the depressed group had a significantly higher increase (mean±SD,0.24±0.14nmol/L) than the controls [mean±SD,0.18±0.07nmol/L, F(1,26)=4.93, mean square error=0.11, <em>p</em>=.04]. Post hoc analysis showed a significantly higher melatonin profile in depressed subjects without psychosis (<em>n</em>=15) than in depressed subjects with psychosis (<em>n</em>=7) or in the controls.</p><p><em>Conclusions</em>: Measuring the overall nocturnal serum melatonin profile during darkness may help to differentiate children and adolescents with major depression without psychosis from those with psychosis and from controls.</p>'
- - /docs/sociology/2008-barron.pdf
  - ! 'Asian Variability in Performance Rating Modesty and Leniency Bias'
  - Laura G. Barron, Paul R. Sackett
  - 2008-07-15
  - 10.1080/08959280802137754
  - ! '<p>Western managers typically rate their performance higher than their bosses, peers, or subordinates do; research on Asian managers, however, has been both sparse and conflicting. In examining data from 6 Asian countries, Japanese managers were found to rate themselves lower than others in their organization do. This “modesty bias,” however, varies considerably among Asian countries; in other countries, including India and China, self-inflation was more comparable to typical Western findings. Findings lend initial support to the ability of national collectivism to explain differences in modesty and leniency bias when institutional collectivism is distinguished from in-group collectivism using data from the <span class="smallcaps-auto">GLOBE</span> Project (House, Hanges, Javidan, Dorfman, &amp; Gupta, 2004). Theoretical basis for modesty bias, and implications for Asian and American expatriates are discussed.</p>'
- - ! 'https://www.cell.com/trends/genetics/fulltext/S0168-9525(20)30070-6'
  - "The Genomics of Human Local Adaptation"
  - Jasmin S. Rees, Sergi Castellano, Aida M. Andrés
  - 2020-04-14
  - 10.1016/j.tig.2020.03.006
  - ! '<p>Local adaptation has critically contributed to the (modest) genetic and phenotypic differentiation that exists among human groups, including in health-related traits that contribute to population health disparities.</p><p>Local adaptation has happened on alleles of diverse origin (on new, pre-existing, and introgressed alleles) and through diverse mechanisms (monogenic and polygenic adaptation).</p><p>Ancient <span class="smallcaps-auto">DNA</span> will play a key role in our understanding of local adaptation by improving inferences of past events. Further, it has revealed the importance of adaptive introgression, by which modern humans acquired adaptive alleles from archaic humans.</p><p>Novel analysis methods will improve our power to identify targets of local adaptation, especially those with weak signatures. Combining genetic and environmental information promises to improve the identification of genomic targets and the corresponding selective force.</p><p>Modern humans inhabit a variety of environments and are exposed to a plethora of selective pressures, leading to multiple genetic adaptations to local environmental conditions. These include adaptations to climate, UV exposure, disease, diet, altitude, or cultural practice and have generated important genetic and phenotypic differences amongst populations. In recent years, new methods to identify the genomic signatures of natural selection underlying these adaptations, combined with novel types of genetic data (e.g., ancient <span class="smallcaps-auto">DNA</span>), have provided unprecedented insights into the origin of adaptive alleles and the modes of adaptation. As a result, numerous instances of local adaptation have been identified in humans. Here, we review the most exciting recent developments and discuss, in our view, the future of this field. [Keywords: genetic adaptation, positive selection, selection on de novo mutation (<span class="smallcaps-auto">SDN</span>), selection on standing variation (<span class="smallcaps-auto">SSV</span>), adaptive introgression, polygenic selection, genetic-environmental correlation, genealogical methods]</p>'
- - https://openai.com/blog/jukebox/
  - ! "Jukebox: We're introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We're releasing the model weights and code, along with a tool to explore the generated samples."
  - Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever
  - 2020-04-30
  - ''
  - ! '<p>A typical 4-minute song at CD quality (44 kHz, 16-bit) has over 10 million timesteps. For comparison, <span class="smallcaps-auto">GPT</span>-2 had 1,000 timesteps and OpenAI Five took tens of thousands of timesteps per game. Thus, to learn the high level semantics of music, a model would have to deal with extremely long-range dependencies. One way of addressing the long input problem is to use an autoencoder that compresses raw audio to a lower-dimensional space by discarding some of the perceptually irrelevant bits of information. We can then train a model to generate audio in this compressed space, and upsample back to the raw audio space.</p><p>We chose to work on music because we want to continue to push the boundaries of generative models. Our previous work on MuseNet explored synthesizing music based on large amounts of <span class="smallcaps-auto">MIDI</span> data. Now in raw audio, our models must learn to tackle high diversity as well as very long range structure, and the raw audio domain is particularly unforgiving of errors in short, medium, or long term timing.</p><p>…Jukebox’s autoencoder model compresses audio to a discrete space, using a quantization-based approach called VQ-<span class="smallcaps-auto">VAE</span>.2 Hierarchical VQ-<span class="smallcaps-auto">VAE</span>s17 can generate short instrumental pieces from a few sets of instruments, however they suffer from hierarchy collapse due to use of successive encoders coupled with autoregressive decoders. A simplified variant called VQ-<span class="smallcaps-auto">VAE</span>-226 avoids these issues by using feedforward encoders and decoders only, and they show impressive results at generating high-fidelity images…We use three levels in our VQ-<span class="smallcaps-auto">VAE</span>, shown below, which compress the 44kHz raw audio by 8×, 32×, and 128×, respectively, with a codebook size of 2048 for each level. This downsampling loses much of the audio detail, and sounds noticeably noisy as we go further down the levels. However, it retains essential information about the pitch, timbre, and volume of the audio.</p><p><figure><img href="/images/gan/2020-dhariwal-openai-jukebox-vqvaetransformerarchitecture.svg" alt="https://cdn.openai.com/jukebox/assets/vqvae-1-outlined.svg">Jukebox architecture</img></figure></p><p>…The top-level prior models the long-range structure of music, and samples decoded from this level have lower audio quality but capture high-level semantics like singing and melodies. The middle and bottom upsampling priors add local musical structures like timbre, significantly improving the audio quality. We train these as autoregressive models using a simplified variant of Sparse Transformers. Each of these models has 72 layers of factorized self-attention on a context of 8192 codes, which corresponds to approximately 24 seconds, 6 seconds, and 1.5 seconds of raw audio at the top, middle and bottom levels, respectively. Once all of the priors are trained, we can generate codes from the top level, upsample them using the upsamplers, and decode them back to the raw audio space using the VQ-<span class="smallcaps-auto">VAE</span> decoder to sample novel songs.</p><p>…While Jukebox represents a step forward in musical quality, coherence, length of audio sample, and ability to condition on artist, genre, and lyrics, there is a significant gap between these generations and human-created music. For example, while the generated songs show local musical coherence, follow traditional chord patterns, and can even feature impressive solos, we do not hear familiar larger musical structures such as choruses that repeat. Our downsampling and upsampling process introduces discernible noise. Improving the VQ-<span class="smallcaps-auto">VAE</span> so its codes capture more musical information would help reduce this. Our models are also slow to sample from, because of the autoregressive nature of sampling. It takes approximately 9 hours to fully render 1 minute of audio through our models, and thus they cannot yet be used in interactive applications</p>'
- - https://cdn.openai.com/papers/jukebox.pdf
  - "Jukebox: A Generative Model for Music"
  - Prafulla Dhariwal, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, Ilya Sutskever
  - 2020-04-30
  - ''
  - ! '<p>We introduce Jukebox, a model that generates music with singing in the raw audio domain. We tackle the long context of raw audio using a multi-scale <span class="smallcaps-auto">VQ-VAE</span> to compress it to discrete codes, and modeling those using autoregressive Transformers. We show that the combined model at scale can generate high-fidelity and diverse songs with coherence up to multiple minutes. We can condition on artist and genre to steer the musical and vocal style, and on unaligned lyrics to make the singing more controllable. We are releasing thousands of non cherry-picked <a href="https://jukebox.openai.com/">samples</a>, along with model weights and <a href="https://github.com/openai/jukebox">code</a>.</p>'
- - https://jukebox.openai.com/
  - Jukebox Sample Explorer
  - OpenAI
  - 2020-04-30
  - ''
  - ! '<p>[A large dataset of 7131 musical songs generated by OpenAI’s Jukebox neural network, classified &amp; searchable by model (including samples generated by models early in training &amp; of low quality), type of song (the model continuing an existing piece of music, generating in the style of a specific artist, given brandnew lyrics, no lyrics at all), genre (hip hop/jazz/country/rock/pop/metal/etc), artist (everyone from Elton John to Rage to Eagles), and sampling temperature (top-<em>k</em>, governing tradeoff between randomness and predictability).]</p>'
- - /docs/statistics/2012-decrouez.pdf
  - ! 'Confidence Intervals for the Weighted Sum of Two Independent Binomial Proportions'
  - Geoffrey Decrouez, Andrew P. Robinson
  - 2012-09-01
  - 10.1111/j.1467-842X.2012.00680.x
  - ! '<p>Confidence intervals for the difference of two binomial proportions are well known, however, confidence intervals for the weighted sum of two binomial proportions are less studied. We develop and compare 7 methods for constructing confidence intervals for the weighted sum of 2 independent binomial proportions. The interval estimates are constructed by inverting the Wald test, the score test and the Likelihood ratio test. The weights can be negative, so our results generalize those for the difference between two independent proportions. We provide a numerical study that shows that these confidence intervals based on large-sample approximations perform very well, even when a relatively small amount of data is available. The intervals based on the inversion of the score test showed the best performance. Finally, we show that as for the difference of two binomial proportions, adding four pseudo-outcomes to the Wald interval for the weighted sum of two binomial proportions improves its coverage significantly, and we provide a justification for this correction. [Keywords: border security, leakage survey, likelihood ratio test, quarantine inspection, score test, small sample, sum of proportions, Wald test]</p>'
- - /docs/genetics/correlation/2020-skov.pdf
  - ! 'Co-aggregation and heritability of organ-specific autoimmunity: a population-based twin study'
  - Jakob Skov, Daniel Eriksson, Ralf Kuja-Halkola, Jonas Höijer, Soffia Gudbjörnsdottir, Ann-Marie Svensson, Patrik K. E. Magnusson, Jonas F. Ludvigsson, Olle Kämpe, Sophie Bensing
  - 2020-05-01
  - 10.1530/EJE-20-0049
  - ! '<p><em>Objective</em>: Co-aggregation of autoimmune diseases is common, suggesting partly shared etiologies. Genetic factors are believed to be important, but objective measures of environmental vs heritable influences on co-aggregation are absent. With a novel approach to twin studies, we aimed at estimating heritability and genetic overlap in seven organ-specific autoimmune diseases.</p><p><em>Design</em>: Prospective twin cohort study.</p><p><em>Methods</em>: We used a cohort of 110 814 twins to examine co-aggregation and heritability of Hashimoto’s thyroiditis, atrophic gastritis, celiac disease, Graves’ disease, type 1 diabetes, vitiligo and Addison’s disease. Hazard ratios (HR) were calculated for twins developing the same or different disease as compared to their co-twin. The differences between monozygotic and dizygotic twin pairs were used to estimate the genetic influence on co-aggregation. Heritability for individual disorders was calculated using structural equational modeling adjusting for censoring and truncation of data.</p><p><em>Results</em>: Co-aggregation was more pronounced in monozygotic twins (median HR: 3.2, range: 2.2–9.2) than in dizygotic twins (median HR: 2.4, range: 1.1–10.0). Heritability was moderate for atrophic gastritis (0.38, 95% CI: 0.23–0.53) but high for all other diseases, ranging from 0.60 (95% CI: 0.49–0.71) for Graves’ disease to 0.97 (95% CI: 0.91–1.00) for Addison’s disease.</p><p><em>Conclusions</em>: Overall, co-aggregation was more pronounced in monozygotic than in dizygotic twins, suggesting that disease overlap is largely attributable to genetic factors. Co-aggregation was common, and twins faced up to a 10-fold risk of developing diseases not present in their co-twin. Our results validate and refine previous heritability estimates based on smaller twin cohorts.</p>'
- - https://openreview.net/forum?id=SyxrxR4KPS#deepmind
  - "Deep neuroethology of a virtual rodent"
  - Josh Merel, Diego Aldarondo, Jesse Marshall, Yuval Tassa, Greg Wayne, Bence Olveczky (DM/Harvard)
  - 2020-03-11
  - ''
  - ! '<p><em>TL;DR</em>: We built a physical simulation of a rodent, trained it to solve a set of tasks, and analyzed the resulting networks.</p><p><em>Abstract</em>: Parallel developments in neuroscience and deep learning have led to mutually productive exchanges, pushing our understanding of real and artificial neural networks in sensory and cognitive systems. However, this interaction between fields is less developed in the study of motor control. In this work, we develop a virtual rodent as a platform for the grounded study of motor activity in artificial models of embodied control. We then use this platform to study motor activity across contexts by training a model to solve four complex tasks. Using methods familiar to neuroscientists, we describe the behavioral representations and algorithms employed by different layers of the network using a neuroethological approach to characterize motor activity relative to the rodent’s behavior and goals. We find that the model uses two classes of representations which respectively encode the task-specific behavioral strategies and task-invariant behavioral kinematics. These representations are reflected in the sequential activity and population dynamics of neural subpopulations. Overall, the virtual rodent facilitates grounded collaborations between deep reinforcement learning and motor neuroscience. [Keywords: computational neuroscience, motor control, deep RL]</p>'
- - https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/ai-powered-rat-valuable-new-tool-neuroscience
  - "AI-Powered Rat Could Be a Valuable New Tool for Neuroscience: Researchers from DeepMind and Harvard are using a virtual rat to see what neural networks can teach us about biology"
  - Edd Gent (<span class=\"smallcaps-auto\">IEEE</span> Spectrum)
  - 2020-04-27
  - ''
  - ! '<p>Can we study AI the same way we study lab rats? Researchers at DeepMind and Harvard University seem to think so. They built an AI-powered virtual rat that can carry out multiple complex tasks. Then, they used neuroscience techniques to understand how its artificial “brain” controls its movements….Now the authors of a new paper due to be presented this week at <span class="smallcaps-auto">ICLR</span> have created a biologically accurate 3D model of a rat that can be controlled by a neural network in a simulated environment. They also showed that they could use neuroscience techniques for analyzing biological brain activity to understand how the neural net controlled the rat’s movements.</p><p>…The virtual rodent features muscles and joints based on measurements from real-life rats, as well as vision and a sense of proprioception, which refers to the feedback system that tells animals where their body parts are and how they’re moving. The researchers then trained a neural network to guide the rat through four tasks—jumping over a series of gaps, foraging in a maze, trying to escape a hilly environment, and performing precisely timed pairs of taps on a ball.</p><p>…Because the researchers had built the AI that powered the rat, much of what they found was expected. But one interesting insight they gained was that the neural activity seemed to occur over longer time scales than would be expected if it were directly controlling muscle forces and limb movements, says Diego Aldarondo, a coauthor and graduate student at Harvard. “This implies that the network represents behaviors at an abstract scale of running, jumping, spinning, and other intuitive behavioral categories,” he says, a cognitive model that has previously been proposed to exist in animals.</p><p>The neural network appeared to reuse some such representations across tasks, and the neural activity encoding them often took the form of sequences, a phenomenon that has been observed in both rodents and songbirds.</p>'
- - https://www.cambridge.org/core/journals/animal/article/review-recent-advances-in-bovine-in-vitro-embryo-production-reproductive-biotechnology-history-and-methods/4C4A7C008A6014ADBFDECCFED12FAE13/core-reader
  - "Recent advances in bovine <em>in vitro</em> embryo production: reproductive biotechnology history and methods"
  - L. B. Ferré, M. E. Kjelland, L. B. Strøbech, P. Hyttel, P. Mermillod, P. J. Ross
  - 2020-05
  - 10.1017/S1751731119002775
  - ! '<p><em>In vitro</em> production (<strong><em><span class="smallcaps-auto">IVP</span></em></strong>) of embryos and associated technologies in cattle have shown significant progress in recent years, in part driven by a better understanding of the full potential of these tools by end users. The combination of <span class="smallcaps-auto">IVP</span> with sexed semen (<strong><em>SS</em></strong>) and genomic selection (<strong><em>GS</em></strong>) is being successfully and widely used in North America, South America and Europe. The main advantages offered by these technologies include a higher number of embryos and pregnancies per unit of time, and a wider range of potential female donors from which to retrieve oocytes (including open cyclic females and ones up to 3 months pregnant), including high index genomic calves, a reduced number of sperm required to produce embryos and increased chances of obtaining the desired sex of offspring. However, there are still unresolved aspects of <span class="smallcaps-auto">IVP</span> of embryos that limit a wider implementation of the technology, including potentially reduced fertility from the use of SS, reduced oocyte quality after <em>in vitro</em> oocyte maturation and lower embryo cryotolerance, resulting in reduced pregnancy rates compared to <em>in vivo</em>–produced embryos. Nevertheless, promising research results have been reported, and work is in progress to address current deficiencies. The combination of GS, <span class="smallcaps-auto">IVP</span> and SS has proven successful in the commercial field in several countries assisting practitioners and cattle producers to improve reproductive performance, efficiency and genetic gain.</p>'
- - /docs/statistics/2020-blake.pdf
  - ! 'On Attenuated Interactions, Measurement Error, and Statistical Power: Guidelines for Social and Personality Psychologists'
  - Khandis R. Blake, Steven Gangestad
  - 2020-03-25
  - 10.1177/0146167220913363
  - ! '<p>The replication crisis has seen increased focus on best practice techniques to improve the reliability of scientific findings. What remains elusive to many researchers and is frequently misunderstood is that predictions involving interactions dramatically affect the calculation of statistical power. Using recent papers published in <em>Personality and Social Psychology Bulletin</em> (<span class="smallcaps-auto">PSPB</span>), we illustrate the pitfalls of improper power estimations in studies where attenuated interactions are predicted. Our investigation shows why even a programmatic series of 6 studies employing 2×2 designs, with samples exceeding <em>n</em>=500, can be woefully underpowered to detect genuine effects. We also highlight the importance of accounting for error-prone measures when estimating effect sizes and calculating power, explaining why even positive results can mislead when power is low. We then provide five guidelines for researchers to avoid these pitfalls, including cautioning against the heuristic that a series of underpowered studies approximates the credibility of one well-powered study. [Keywords: statistical power, effect size, fertility, ovulation, interaction effects]</p>'
- - /docs/biology/2015-beekman.pdf
  - ! 'Brainless but Multi-Headed: Decision Making by the Acellular Slime Mould <em>Physarum polycephalum</em>'
  - Madeleine Beekman, Tanya Latty
  - 2015-11-20
  - 10.1016/j.jmb.2015.07.007
  - ! '<ul><li>Can you make decisions if you are brainless?</li><li>Here we use the acellular slime mould <a href="https://en.wikipedia.org/wiki/Physarum_polycephalum"><em>P. polycephalum</em></a> to study decision making.</li><li>We use foraging and network construction as experimental paradigms.</li><li>Our work reveals the underlying basic mechanisms that organisms use to make decisions.</li><li>We think that the slime mould can be developed further to function as a “model brain”.</li></ul><p>Because of its peculiar biology and the ease with which it can be cultured, the acellular slime mould <a href="https://en.wikipedia.org/wiki/Physarum_polycephalum"><em>Physarum polycephalum</em></a> has long been a model organism in a range of disciplines. Due to its macroscopic, syncytial nature, it is no surprise that it has been a favourite amongst cell biologists. Its inclusion in the experimental tool kit of behavioural ecologists is much more recent. These recent studies have certainly paid off. They have shown that, for an organism that lacks a brain or central nervous system, <em>P. polycephalum</em> shows rather complex behaviour. For example, it is capable of finding the shortest path through a maze, it can construct networks as efficient as those designed by humans, it can solve computationally difficult puzzles, it makes multi-objective foraging decisions, it balances its nutrient intake and it even behaves irrationally. Are the slime mould’s achievements simply “cute”, worthy of mentioning in passing but nothing to take too seriously? Or do they hint at the fundamental processes underlying all decision making? We will address this question after reviewing the decision-making abilities of the slime mould. [Keywords: acellular slime mould, decision-making, foraging decisions, optimal foraging, trade-offs]</p>'
- - /docs/statistics/decision/2017-shenhav.pdf
  - ! 'Toward a Rational and Mechanistic Account of Mental Effort'
  - Amitai Shenhav, Sebastian Musslick, Falk Lieder, Wouter Kool, Thomas L. Griffiths, Jonathan D. Cohen, Matthew M. Botvinick
  - 2017-07-01
  - 10.1146/annurev-neuro-072116-031526
  - ! '<p>In spite of its familiar phenomenology, the mechanistic basis for mental effort remains poorly understood. Although most researchers agree that mental effort is aversive and stems from limitations in our capacity to exercise cognitive control, it is unclear what gives rise to those limitations and why they result in an experience of control as costly. The presence of these control costs also raises further questions regarding how best to allocate mental effort to minimize those costs and maximize the attendant benefits. This review explores recent advances in computational modeling and empirical research aimed at addressing these questions at the level of psychological process and neural mechanism, examining both the limitations to mental effort exertion and how we manage those limited cognitive resources. We conclude by identifying remaining challenges for theoretical accounts of mental effort as well as possible applications of the available findings to understanding the causes of and potential solutions for apparent failures to exert the mental effort required of us. [Keywords: motivation, cognitive control, decision making, reward, prefrontal cortex, executive function]</p>'
- - /docs/psychology/2006-ozer.pdf
  - ! 'Personality and the Prediction of Consequential Outcomes'
  -  Daniel J. Ozer, Verónica Benet-Martínez
  - 2006-02-01
  - 10.1146/annurev.psych.57.102904.190127
  - ! '<p>Personality has consequences. Measures of personality have contemporaneous and predictive relations to a variety of important outcomes. Using the Big Five factors as heuristics for organizing the research literature, numerous consequential relations are identified. Personality dispositions are associated with happiness, physical and psychological health, spirituality, and identity at an individual level; associated with the quality of relationships with peers, family, and romantic others at an interpersonal level; and associated with occupational choice, satisfaction, and performance, as well as community involvement, criminal activity, and political ideology at a social institutional level. [Keywords: individual differences, traits, life outcomes, consequences]</p>'
- - /docs/genetics/editing/2015-potrykus.pdf
  - ! 'From the Concept of Totipotency to Biofortified Cereals'
  - Ingo Potrykus
  - 2015-04-01
  - 10.1146/annurev-arplant-043014-114734
  - ! '<p>I was a college teacher when opportunity opened a path into academia. A fascination with totipotency channeled me into research on tissue culture. As I was more interested in contributions to food security than in scientific novelty, I turned my attention to the development of genetic modification technology for cereals. From my cell culture experience, I had reasons not to trust <em>Agrobacterium</em> for that purpose, and I developed direct gene transfer instead. In the early 1990s, I became aware of the problem of micronutrient deficiency, particularly vitamin A deficiency in rice-eating populations. Golden Rice, which contains increased amounts of provitamin A, was probably instrumental for the concept of biofortification to take off. I realized that this rice would remain an academic exercise if product development and product registration were not addressed, and this is what I focused on after my retirement. Although progress is slowly being made, had I known what this pursuit would entail, perhaps I would not have started. Hopefully Golden Rice will reach the needy during my lifetime. [Keywords: Golden Rice, biofortification, genetic engineering, public good, <span class="smallcaps-auto">GMO</span> regulation, Autobiography]</p>'
- - /docs/cs/2009-mytkowicz.pdf
  - ! 'Producing Wrong Data Without Doing Anything Obviously Wrong!'
  - Todd Mytkowicz, Amer Diwan, Matthias Hauswirth, Peter F. Sweeney
  - 2009-03-07
  - 10.1145/1508284.1508275
  - ! '<p>This paper presents a surprising result: changing a seemingly innocuous aspect of an experimental setup can cause a systems researcher to draw wrong conclusions from an experiment. What appears to be an innocuous aspect in the experimental setup may in fact introduce a significant bias in an evaluation. This phenomenon is called <em>measurement bias</em> in the natural and social sciences.</p><p>Our results demonstrate that measurement bias is significant and commonplace in computer system evaluation. By <em>significant</em> we mean that measurement bias can lead to a performance analysis that either over-states an effect or even yields an incorrect conclusion. By <em>commonplace</em> we mean that measurement bias occurs in all architectures that we tried (Pentium 4, Core 2, and m5 O3<span class="smallcaps-auto">CPU</span>), both compilers that we tried (gcc and Intel’s C compiler), and most of the <span class="smallcaps-auto">SPEC</span> <span class="smallcaps-auto">CPU</span>2006 C programs. Thus, we cannot ignore measurement bias. Nevertheless, in a literature survey of 133 recent papers from <span class="smallcaps-auto">ASPLOS</span>, <span class="smallcaps-auto">PACT</span>, <span class="smallcaps-auto">PLDI</span>, and <span class="smallcaps-auto">CGO</span>, we determined that none of the papers with experimental results adequately consider measurement bias.</p><p>Inspired by similar problems and their solutions in other sciences, we describe and demonstrate two methods, one for detecting (causal analysis) and one for avoiding (setup randomization) measurement bias. [Keywords: experimentation, measurement, performance, bias]</p>'
- - /docs/economics/2017-nagaraj.pdf
  - ! 'Does Copyright Affect Reuse? Evidence from Google Books and Wikipedia'
  - Abhishek Nagaraj
  - 2017-07-26
  - 10.1287/mnsc.2017.2767
  - ! '<p>While digitization has greatly increased the reuse of knowledge, this study shows how these benefits might be mitigated by copyright restrictions. I use the digitization of in-copyright and out-of-copyright issues of <em>Baseball Digest</em> magazine by Google Books to measure the impact of copyright on knowledge reuse in Wikipedia. I exploit a feature of the 1909 Copyright Act whereby material published before 1964 has lapsed into the public domain, allowing for the causal estimation of the impact of copyright across this sharp cutoff. I find that, while digitization encourages knowledge reuse, copyright restrictions reduce citations to copyrighted issues of <em>Baseball Digest</em> by up to 135% and affect readership by reducing traffic to affected pages by 20%. These impacts are highly uneven: copyright hurts the reuse of images rather than text and affects Wikipedia pages for less-popular players greater than more-popular ones.</p><p>The online appendix is available at <a href="https://doi.org/10.1287/mnsc.2017.2767">https://doi.org/10.1287/mnsc.2017.2767</a> .</p>'
- - /docs/lithium/2009-ohgami.pdf
  - ! 'Lithium levels in drinking water and risk of suicide'
  - Hirochika Ohgami, Takeshi Terao, Ippei Shiotsuki, Nobuyoshi Ishii, Noboru Iwat
  - 2009-05-01
  - 10.1192/bjp.bp.108.055798
  - ! '<p>Although lithium is known to prevent suicide in people with mood disorders, it is uncertain whether lithium in drinking water could also help lower the risk in the general population. To investigate this, we examined lithium levels in tap water in the 18 municipalities of Oita prefecture in Japan in relation to the suicide standardised mortality ratio (<span class="smallcaps-auto">SMR</span>) in each municipality. We found that lithium levels were significantly and negatively associated with <span class="smallcaps-auto">SMR</span> averages for 2002–2006. These findings suggest that even very low levels of lithium in drinking water may play a role in reducing suicide risk within the general population.</p>'
- - /docs/genetics/heritable/1994-koopmans.pdf
  - ! 'Smoking and Sports Participation'
  - Judith R. Koopmans, Lorenz J. P. van Doornen, Dorret I. Boomsma
  - 1994-01-01
  - 10.1007/978-94-011-1130-0_15
  - ! '<p>It has long been recognized that both smoking and sports participation tend to cluster in families. In this chapter, we first describe the current status of smoking and sports participation as cardiovascular risk factors. After an outline of the principles of the quantitative genetic approaches to the analysis of individual differences in behaviour, we will review the literature on genetic and environmental determinants of smoking and sports participation. In the second half of this chapter, results from the Dutch Twin/Family Study of Health-Related Behavior are presented.</p>'
- - https://www.damninteresting.com/the-curse-of-konzo/
  - "The Curse of Konzo: In 1981, an international group of doctors identified the devastating disease behind a perplexing outbreak of paralysis in northern Mozambique"
  - Matt Castle (Damn Interesting)
  - 2018-05-02
  - ''
  - ! '<p>[Investigation of the konzo outbreak in Africa: a mysterious paralytic illness swept a region without any cause. Viral outbreak? Chemical/biological warfare being used as part of the ongoing civil war? Rare diseases from medical journals were unearthed and then dismissed for not matching the symptoms. Gradually, a nutritional cause began seeming more likely, and investigators focused on what people were eating. Specifically, in the dietary mainstay cassava–residual cyanide? The disruption of the civil war prevented normal food processing traditions. Finally, chemical testing confirmed dangerously high cyanide levels, and further tracking revealed spikes at cassava harvest time.</p><p>Why was konzo so hard to diagnose? Many plants are high in cyanide but are harvested &amp; cooked safely, with poisoning being rare. Cassava is harvested throughout the world, yet konzo is almost unheard of. And the symptoms were not classical cyanide poisoning. It was exacerbated by other nutritional deficiencies, drought increasing cyanide levels, and the civil war. But all this still seems inadequate and the full reasons konzo was so bad, and the symptoms unique, remain a mystery.]</p>'
- - https://openai.com/blog/ai-and-efficiency/
  - ! 'AI and Efficiency: We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s Law3 would yield an 11× cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware efficiency.'
  - Danny Hernandez, Tom Brown (OpenAI)
  - 2020-05-05
  - ''
  - ! '<p>For our analysis, we primarily leveraged open-source re-implementations<sup>19,20,21</sup> to measure progress on AlexNet level performance over a long horizon. We saw a similar rate of training efficiency improvement for ResNet-50 level performance on ImageNet (17-month doubling time).<sup>7,16</sup> We saw faster rates of improvement over shorter timescales in Translation, Go, and DoTA 2:</p><ol type="1"><li>Within translation, the Transformer<sup>22</sup> surpassed seq2seq<sup>23</sup> performance on English to French translation on <span class="smallcaps-auto">WMT</span>’14 with 61× less training compute 3 years later.</li><li>We estimate AlphaZero<sup>24</sup> took 8× less compute to get to AlphaGo Zero<sup>25</sup> level performance 1 year later.</li><li>OpenAI Five Rerun required 5× less training compute to surpass OpenAI Five<sup>26</sup> (which beat the world champions, OG) 3 months later.</li></ol><p>It can be helpful to think of compute in 2012 not being equal to compute in 2019 in a similar way that dollars need to be inflation-adjusted over time. A fixed amount of compute could accomplish more in 2019 than in 2012. One way to think about this is that some types of AI research progress in two stages, similar to the “tick tock” model of development seen in semiconductors; new capabilities (the “tick”) typically require a significant amount of compute expenditure to obtain, then refined versions of those capabilities (the “tock”) become much more efficient to deploy due to process improvements. Increases in algorithmic efficiency allow researchers to do more experiments of interest in a given amount of time and money. In addition to being a measure of overall progress, algorithmic efficiency gains speed up future AI research in a way that’s somewhat analogous to having more compute.</p><p>…We also find increases in inference efficiency in terms of <span class="smallcaps-auto">GPU</span> time<sup>32</sup>, parameters<sup>16</sup>, and flops meaningful, but mostly as a result of their economic implications [ Inference costs dominate total costs for successful deployed systems. Inference costs scale with usage of the system, whereas training costs only need to be paid once.] rather than their effect on future research progress. ShuffleNet<sup>13</sup> achieved AlexNet-level performance with an 18× inference efficiency increase in 5 years (15-month doubling time), which suggests that training efficiency and inference efficiency might improve at similar rates.</p><p>…For all these reasons, we’re going to start tracking efficiency <span class="smallcaps-auto">SOTA</span>s publicly. We’ll start with vision and translation efficiency benchmarks (ImageNet and <span class="smallcaps-auto">WMT</span>14), and we’ll consider adding more benchmarks over time. We believe there are efficiency <span class="smallcaps-auto">SOTA</span>s on these benchmarks we’re unaware of and encourage the research community to submit them here (we’ll give credit to original authors and collaborators).</p>'
- - /docs/ai/2002-bixby.pdf
  - ! "Solving Real-World Linear Programs: A Decade and More of Progress"
  - Robert E. Bixby
  - 2002-02-01
  - 10.1287/opre.50.1.3.17780
  - ! '<p>This paper is an invited contribution to the 50<sup>th</sup> anniversary issue of the journal <em>Operations Research</em>, published by the Institute of Operations Research and Management Science (<span class="smallcaps-auto">INFORMS</span>). It describes one person’s perspective on the development of computational tools for linear programming. The paper begins with a short personal history, followed by historical remarks covering the some 40 years of linear-programming developments that predate my own involvement in this subject. It concludes with a more detailed look at the evolution of computational linear programming since 1987.</p><p>…In this paper I have focused primarily on one issue, solving larger, more difficult linear programs faster. The numbers presented speak for themselves. 3 orders of magnitude in machine speed and 3 orders of magnitude in algorithmic speed add up to six orders of magnitude in solving power: A model that might have taken a year to solve 10 years ago can now solve in less than 30 seconds. Of course, no one waits 1 year to solve a model, at least no one I know. The real meaning of such an advance is much harder to measure in practice, but it is real nevertheless. There is no doubt that we now have optimization engines at our disposal that dwarf what was available only a few years ago, making possible the solution of real-world models once considered intractable, and opening up whole new domains of application.</p><p>How do these speed improvements fit into the overall picture of linear-programming practice? They are only a part of that picture, though an essential, enabling part. The pervasive availability of powerful, usable desktop computing, the availability of data to feed our models, and the emergence of algebraic modeling languages to represent our models have all combined with the underlying engines to make operations research and linear programming the powerful tools they are today. However, there are still important issues to be solved. In spite of all the advances, the application of linear programming remains primarily the domain of experts. The need for abstraction still stands as a hurdle between technology and solutions. While the existence of this hurdle is disconcerting, it is at least gratifying to know that the benefits from overcoming it are now greater than ever.</p>'
- - /docs/ai/2013-yudkowsky.pdf#miri
  - ! "Intelligence Explosion Microeconomics"
  - Eliezer Yudkowsky
  - 2013-09-13
  - ''
  - ! '<p>I. J. Good’s thesis of the “intelligence explosion” states that a sufficiently advanced machine intelligence could build a smarter version of itself, which could in turn build an even smarter version, and that this process could continue to the point of vastly exceeding human intelligence. As Sandberg (2010) correctly notes, there have been several attempts to lay down return on investment formulas intended to represent sharp speedups in economic or technological growth, but very little attempt has been made to deal formally with Good’s intelligence explosion thesis as such.</p><p>I identify the key issue as <em>returns on cognitive reinvestment</em>—the ability to invest more computing power, faster computers, or improved cognitive algorithms to yield cognitive labor which produces larger brains, faster brains, or better mind designs. There are many phenomena in the world which have been argued to be evidentially relevant to this question, from the observed course of hominid evolution, to Moore’s Law, to the competence over time of machine chess-playing systems, and many more. I go into some depth on some debates which then arise on how to interpret such evidence. I propose that the next step in analyzing positions on the intelligence explosion would be to formalize return on investment curves, so that each stance can formally state which possible micro-foundations they hold to be <em>falsified</em> by historical observations. More generally I pose multiple open questions of “returns on cognitive reinvestment” or “intelligence explosion microeconomics.” Although such questions have received little attention thus far, they seem highly relevant to policy choices affecting outcomes for Earth-originating intelligent life.</p>'
- - /docs/ai/2013-grace.pdf#miri
  - ! "Algorithmic Progress in Six Domains"
  - Katja Grace
  - 2013-12-09
  - ''
  - ! '<p>We examine evidence of progress in 6 areas of algorithms research [<span class="smallcaps-auto">SAT</span>/chess+Go/factoring/physics simulations/linear programming+scheduling/machine learning], with an eye to understanding likely algorithmic trajectories after the advent of artificial general intelligence. Many of these areas appear to experience fast improvement, though the data are often noisy. For tasks in these areas, gains from algorithmic progress have been roughly 50 to 100% as large as those from hardware progress. Improvements tend to be incremental, forming a relatively smooth curve on the scale of years.</p>'
- - /docs/nicotine/1992-robinson.pdf
  - ! 'The role of nicotine in tobacco use'
  - John H. Robinson, Walter S. Pritchard
  - 1992-09-01
  - 10.1007/BF02247412
  - ! '<p>The 1988 US Surgeon General’s Report titled “Nicotine Addiction”, is cited frequently in the literature as having established the “fact” that nicotine derived from cigarette smoke is addictive in the same sense as “classic” addicting drugs such as heroin and cocaine. This manuscripts critically evaluates key research findings used in support of this claim and identifies short-comings in the data that seriously question the logic of labeling nicotine as “addictive”. In addition, the manuscript argues that the role of nicotine in tobacco use is not like the role of cocaine in coca leaf use as argued by the 1988 Surgeon General’s Report, but is, in fact, more like the role of caffeine in coffee drinking as concluded in the 1964 US Surgeon General’s Report.</p>'
- - /docs/traffic/2017-pagefair.pdf
  - ! "The Hidden Cost of Adblock: Adblock's impact on website traffic"
  - Sean Blanchfield (PageFair)
  - 2017-02
  - ''
  - ! '<p>This whitepaper presents the primary findings of new research by Professor Benjamin Shiller (Brandeis University), Professor Joel Waldfogel (University of Minnesota and the National Bureau of Economic Research), and Dr. Johnny Ryan (PageFair).</p><p>Research of 2,574 websites over 3 years reveals that adblock has a hidden cost: it not only reduces small and medium publishers’ revenue, it also reduces their traffic.</p><p>Studying the changing rate of desktop adblock usage and traffic rank from April 2013—June 2016 reveals that adblock usage is undermining many websites’ ability to invest in content. Affected websites then attract fewer visitors, and so their traffic declines. The full paper is available from <span class="smallcaps-auto">NBER</span>, the U.S. National Bureau of Economic Research.</p><p>This is the adblock paradox: users may avoid ads in the short term, but ultimately undermine the value they can derive from the web. To reverse this phenomenon, publishers must listen to users’ legitimate grievances about online ads and respond by fixing the problems. Once they have remedied the users’ grievances, publishers can choose to serve their ads using technology that adblock companies cannot tamper with.</p>'
- - /docs/statistics/bias/2012-fanelli.pdf
  - ! 'Negative results are disappearing from most disciplines and countries'
  - Danielle Fanelli
  - 2011-09-11
  - 10.1007/s11192-011-0494-7
  - ! '<p>Concerns that the growing competition for funding and citations might distort science are frequently discussed, but have not been verified directly. Of the hypothesized problems, perhaps the most worrying is a worsening of positive-outcome bias. A system that disfavours negative results not only distorts the scientific literature directly, but might also discourage high-risk projects and pressure scientists to fabricate and falsify their data. This study analysed over 4,600 papers published in all disciplines between 1990 and 2007, measuring the frequency of papers that, having declared to have “tested” a hypothesis, reported a positive support for it. The overall frequency of positive supports has grown by over 22% between 1990 and 2007, with significant differences between disciplines and countries. The increase was stronger in the social and some biomedical disciplines. The United States had published, over the years, significantly fewer positive results than Asian countries (and particularly Japan) but more than European countries (and in particular the United Kingdom). Methodological artefacts cannot explain away these patterns, which support the hypotheses that research is becoming less pioneering and/or that the objectivity with which results are produced and published is decreasing.</p>'
- - /docs/nootropics/1999-aghajanian.pdf
  - ! 'Serotonin and Hallucinogens'
  - G.K. Aghajanian, G.J. Marek
  - 1999-08-01
  - 10.1016/S0893-133X(98)00135-3
  - ! '<p>This brief review traces the serotonin (5-HT) hypothesis of the action of hallucinogenic drugs from the early 1950s to the present day. There is now converging evidence from biochemical, electrophysiological, and behavioral studies that the two major classes of psychedelic hallucinogens, the indoleamines (e.g., <span class="smallcaps-auto">LSD</span>) and the phenethylamines (e.g., mescaline), have a common site of action as partial agonists at 5-HT<sub>2A</sub> and other 5-HT<sub>2</sub> receptors in the central nervous system. The noradrenergic locus coeruleus and the cerebral cortex are among the regions where hallucinogens have prominent effects through their actions upon a 5-HT<sub>2A</sub> receptors. Recently, we have observed a novel effect of hallucinogens—a 5-HT<sub>2A</sub> receptor-mediated enhancement of nonsynchronous, late components of glutamatergic excitatory postsynaptic potentials at apical dendrites of layer V cortical pyramidal cells. We propose that an effect of hallucinogens upon glutamatergic transmission in the cerebral cortex may be responsible for the higher-level cognitive, perceptual, and affective distortions produced by these drugs.</p>'
- - /docs/genetics/heritable/2011-conway.pdf
  - ! 'The Biological Roots of Complex Thinking: Are Heritable Attitudes More Complex?'
  - Lucian Gideon Conway III, Daniel P. Dodds, Kirsten Hands Towgood, Stacey McClure, James M. Olson
  - 2011-02-01
  - 10.1111/j.1467-6494.2010.00690.x
  - ! '<p>Are highly heritable attitudes more or less complex than less heritable attitudes? Over 2,000 participant responses on topics varying in heritability were coded for overall <em>integrative complexity</em> and its 2 subcomponents (<em>dialectical complexity</em> and <em>elaborative complexity</em>). Across different heritability sets drawn from 2 separate prior twin research programs, the present results yielded a consistent pattern: Heritability was always significantly positively correlated with <em>integrative complexity</em>. Further analyses of the subcomponents suggested that the manner in which complexity was expressed differed by topic <em>type</em>: For societal topics, heritable attitudes were more likely to be expressed in dialectically complex terms, whereas for personally involving topics, heritable attitudes were more likely to be expressed in elaboratively complex terms. Most of these relationships remained significant even when controlling for measurements of attitude strength. The authors discuss the genetic roots of complex versus simple attitudes, implications for understanding attitude development more broadly, and the contribution of these results to previous work on both heritability and complexity.</p>'
- - /docs/nootropics/2008-helland.pdf
  - ! "Effect of Supplementing Pregnant and Lactating Mothers With <em>n</em>-3 Very-Long-Chain Fatty Acids on Children's IQ and Body Mass Index at 7 Years of Age"
  - Ingrid B. Helland, Lars Smith, Birgitta Blomén, Kristin Saarem, Ola D. Saugstad, Christian A. Drevon
  - 2008-08-01
  - 10.1542/peds.2007-2762
  - ! '<p><em>Objectives</em>: Arachidonic acid (20:4n-6) and docosahexaenoic acid (22:6n-3) are essential for brain growth and cognitive development. We have reported that supplementing pregnant and lactating women with n-3 very-long-chain polyunsaturated fatty acids promotes higher IQ scores at 4 years of age as compared with maternal supplementation with n-6 polyunsaturated fatty acids. In our present study, the children were examined at 7 years of age with the same cognitive tests as at 4 years of age. We also examined the relation between plasma fatty acid pattern and <span class="smallcaps-auto">BMI</span> in children, because an association between arachidonic acid and adipose tissue size has been suggested.</p><p><em>Methods</em>: The study was randomized and double-blinded. The mothers took 10 mL of cod liver oil or corn oil from week 18 of pregnancy until 3 months after delivery. Their children were tested with the Kaufman Assessment Battery for Children at 7 years of age, and their height and weight were measured.</p><p><em>Results</em>: We did not find any significant differences in scores on the Kaufman Assessment Battery for Children test at 7 years of age between children whose mothers had taken cod liver oil (<em>n</em> = 82) or corn oil (<em>n</em> = 61). We observed, however, that maternal plasma phospholipid concentrations of α-linolenic acid (18:3n-3) and docosahexaenoic acid during pregnancy were correlated to sequential processing at 7 years of age. We observed no correlation between fatty acid status at birth or during the first 3 months of life and <span class="smallcaps-auto">BMI</span> at 7 years of age.</p><p><em>Conclusion</em>: This study suggests that maternal concentration of n-3 very-long-chain polyunsaturated fatty acids during pregnancy might be of importance for later cognitive function, such as sequential processing, although we observed no significant effect of n-3 fatty acid intervention on global IQs. Neonatal fatty acid status had no influence on <span class="smallcaps-auto">BMI</span> at 7 years of age.</p>'
- - /docs/music-distraction/2007-cassidy.pdf
  - ! 'The effect of background music and background noise on the task performance of introverts and extraverts'
  - Gianna Cassidy, Raymond A.R. MacDonald
  - 2007-07-01
  - 10.1177/0305735607076444
  - ! '<p>The study investigated the effects of music with high arousal potential and negative affect (HA), music with low arousal potential and positive affect (LA), and everyday noise, on the cognitive task performance of introverts and extraverts. 40 participants completed 5 cognitive tasks: immediate recall, free recall, numerical and delayed recall, and Stroop. 10 participants completed each of these tasks in one of 4 sound conditions: HA, LA, everyday noise and silence. Participants were also assessed for levels of introversion/ extroversion, and reported their music/noise and study preferences. Performance was lessened across all cognitive tasks in the presence of background sound (music or noise) compared to silence. HA and LA music produced differential distraction effects, with performance of all tasks being poorer in the presence of HA compared to LA and silence, in the presence of noise than silence across all tasks, and in the presence of noise than LA in 3 of the 4 tasks. Performance was moderated by internal arousal, with introverts performing better overall on each task except the Stroop, and appearing to be more detrimentally affected by the presence of HA music and noise.</p>'
- - /docs/nootropics/2004-cools.pdf
  - ! 'Chemistry of the adaptive mind'
  - Roshan Cools, Trevor W. Robbins
  - 2004-09-20
  - 10.1098/rsta.2004.1468
  - ! '<p>A failure to adapt to novel or changing environmental demands is a core feature of a wide variety of neuropsychiatric disorders as well as the normal states of stress and fatigue. We review the neurochemistry of cognitive control, which has been associated primarily with the prefrontal cortex. Many drugs affect the functioning of the prefrontal cortex, but the direction and extent of drug effects vary across individuals and tasks. Apparently paradoxical effects are often observed, where the same medication causes both cognitive enhancement as well as cognitive side effects. We review neurobiological research that is beginning to elucidate the nature of these contrasting effects and the factors underlying the large variability across individuals and behaviours. The work has considerable implications for the understanding of and treatment development for abnormalities such as Parkinson’s disease, attention deficit hyperactivity disorder and drug addiction.</p>'
- - /docs/algernon/2001-finlay.pdf
  - ! 'Developmental structure in brain evolution'
  - Barbara L. Finlay, Richard B. Darlington, Nicholas Nicastro
  - 2001-04-01
  - 10.1017/S0140525X01003958
  - ! '<p>How does evolution grow bigger brains? It has been widely assumed that growth of individual structures and functional systems in response to niche-specific cognitive challenges is the most plausible mechanism for brain expansion in mammals. Comparison of multiple regressions on allometric data for 131 mammalian species, however, suggests that for 9 of 11 brain structures taxonomic and body size factors are less important than covariance of these major structures with each other. Which structure grows biggest is largely predicted by a conserved order of neurogenesis that can be derived from the basic axial structure of the developing brain. This conserved order of neurogenesis predicts the relative scaling not only of gross brain regions like the isocortex or mesencephalon, but also the level of detail of individual thalamic nuclei. Special selection of particular areas for specific functions does occur, but it is a minor factor compared to the large-scale covariance of the whole brain. The idea that enlarged isocortex could be a “spandrel,” a by-product of structural constraints later adapted for various behaviors, contrasts with approaches to selection of particular brain regions for cognitively advanced uses, as is commonly assumed in the case of hominid brain evolution. [Keywords: allometry, brain size, cortex, development, heterochrony, hominid evolution, limbic system, neurogenesis]</p>'
- - /docs/genetics/heritable/2020-taylor.pdf
  - ! 'Etiology of Autism Spectrum Disorders and Autistic Traits Over Time'
  - Mark J. Taylor, Mina A. Rosenqvist, Henrik Larsson, Christopher Gillberg, Brian M. D’Onofrio, Paul Lichtenstein, Sebastian Lundström
  - 2020-05-06
  - 10.1001/jamapsychiatry.2020.0680
  - ! '<p><em>Question</em>: Has association between genetic factors and autism spectrum disorders (<span class="smallcaps-auto">ASD</span>s) changed over time?</p><p><em>Findings</em>: In this study, data were available from 2 twin cohorts, one born between 1982 and 2008 (<em>n</em> = 22 678 pairs) and the other between 1992 and 2008 (<em>n</em> = 15 279 pairs). Genetic factors were associated with <span class="smallcaps-auto">ASD</span> and autistic traits and the relative importance of these factors was consistent over time, whereas environmental factors played a smaller role.</p><p><em>Meaning</em>: Environmental factors associated with <span class="smallcaps-auto">ASD</span> have not increased in importance over time and are unlikely to explain the apparent increase in the prevalence of <span class="smallcaps-auto">ASD</span>.</p><p><strong>Abstract</strong>: <em>Importance</em>: The frequency with which autism spectrum disorders (<span class="smallcaps-auto">ASD</span>s) are diagnosed has shown a marked increase in recent years. One suggestion is that this is partly because of secular changes in the environment, yet to our knowledge this hypothesis lacks evidence.</p><p><em>Objective</em>: To assess whether the relative importance of genetic and environmental associations with <span class="smallcaps-auto">ASD</span> and autistic traits has changed over a 16-year and 26-year period.</p><p><em>Design, Setting, and Participants</em>: A twin design was used to assess whether the heritability of <span class="smallcaps-auto">ASD</span> and autistic traits has changed over time. Data from 2 nationwide Swedish twin cohorts was used: the Swedish Twin Registry (<span class="smallcaps-auto">STR</span>; participants born between January 1982 and December 2008) and the Child and Adolescent Twin Study in Sweden (<span class="smallcaps-auto">CATSS</span>; participants born between January 1992 and December 2008). Autism spectrum disorder diagnoses were identified for twins in the <span class="smallcaps-auto">STR</span>, with follow-up to 2013. Questionnaires assigned screening diagnoses of <span class="smallcaps-auto">ASD</span> to <span class="smallcaps-auto">CATSS</span> participants and assessed autistic traits. Analyses were performed from September 1, 2018, to March 31, 2019.</p><p><em>Exposures</em>: Each sample was divided into several birth cohorts covering 1982 to 1991 (for the <span class="smallcaps-auto">STR</span> only), 1992–1995, 1996–1999, 2000–2003, and 2004–2008.</p><p><em>Outcomes</em>: We assessed whether the genetic and environment variance underlying autistic traits changed across birth cohorts and examined whether the relative contribution of genetics and environment to liability for autism changed across birth cohorts.</p><p><em>Results</em>: Data were available for 22 678 twin pairs (5922 female same-sex pairs [26.1%], 5563 male same-sex pairs [24.5%], and 11193 opposite-sex pairs [49.4%]) in the <span class="smallcaps-auto">STR</span> and 15 280 pairs (4880 female same-sex pairs [31.9%], 5092 male same-sex pairs [33.3%], and 5308 opposite-sex pairs [34.7%]) in <span class="smallcaps-auto">CATSS</span>. The heritability of <span class="smallcaps-auto">ASD</span> diagnoses in the <span class="smallcaps-auto">STR</span> ranged from 0.88 (95% CI, 0.74–0.96) to 0.97 (95% CI, 0.89–0.99). The heritability of screening diagnoses in <span class="smallcaps-auto">CATSS</span> varied from 0.75 (95% CI, 0.58–0.87) to 0.93 (95% CI, 0.84–0.98). Autistic traits showed a modest variance increase over time that was associated with increases in genetic and environmental variance, with the total variance increasing from 0.95 (95% CI, 0.92–0.98) to 1.17 (95% CI, 1.13–1.21) over time.</p><p><em>Conclusions and Relevance</em>: Weak evidence was found for changes in the genetic and environmental factors underlying <span class="smallcaps-auto">ASD</span> and autistic traits over time. Genetic factors played a consistently larger role than environmental factors. Environmental factors are thus unlikely to explain the increase in the prevalence of <span class="smallcaps-auto">ASD</span>.</p>'
- - /docs/iq/2020-berggren.pdf
  - ! 'Foreign language learning in older age does not improve memory or intelligence: Evidence from a randomized controlled study'
  - Rasmus Berggren, Jonna Nilsson, Yvonne Brehmer, Florian Schmiedek, Martin Lövdén
  - 2020-03-01
  - 10.1037/pag0000439
  - ! '<p>Foreign language learning in older age has been proposed as a promising avenue for combatting age-related cognitive decline. We tested this hypothesis in a randomized controlled study in a sample of 160 healthy older participants (aged 65–75 years) who were randomized to 11 weeks of either language learning or relaxation training. Participants in the language learning condition obtained some basic knowledge in the new language (Italian), but between-groups differences in improvements on latent factors of verbal intelligence, spatial intelligence, working memory, item memory, or associative memory were negligible. We argue that this is not due to either poor measurement, low course intensity, or low statistical power, but that basic studies in foreign languages in older age are likely to have no or trivially small effects on cognitive abilities. We place this in the context of the cognitive training and engagement literature and conclude that while foreign language learning may expand the behavioral repertoire, it does little to improve cognitive processing abilities.</p>'
- - /docs/iq/2020-stoet.pdf
  - ! 'Sex-specific academic ability and attitude patterns in students across developed countries'
  - Gijsbert Stoet, David C. Geary
  - 2020-07-01
  - 10.1016/j.intell.2020.101453
  - ! '<p><strong>Highlights</strong></p><ul><li>Student sex can often be predicted based on a set of achievement and attitude data.</li><li>Student sex can often be predicted based on classification models from other countries.</li><li>Universal patterns in academic sex differences are larger than hitherto thought.</li><li>Academic sex differences are stronger in societies with more socioeconomic equality.</li></ul><p><strong>Abstract</strong>: The extent of sex differences in psychological traits is vigorously debated. We show that the overall sex difference in the pattern of adolescents’ achievement and academic attitudes is relatively large and similar across countries. We used a binomial regression modeling approach to predict the sex of 15 and 16 year olds based on sets of academic ability and attitude variables in three cycles of the Programme for International Student Assessment (<span class="smallcaps-auto">PISA</span>) data (<em>n</em>=969,673 across 55 to 71 countries and regions). We found that the sex of students in any country can be reliably predicted based on regression models created from the data of all other countries, indicating a common (universal) sex-specific component. Averaged over three different <span class="smallcaps-auto">PISA</span> cycles (2009, 2012, 2015), the sex of 69% of students can be correctly classified using this approach, corresponding to a large effect. Moreover, the universal component of these sex differences is stronger in countries with relative income equality and women’s participation in the labor force and politics. We conclude that patterns in academic sex differences are larger than hitherto thought and appear to become stronger when societies have more socioeconomic equality. We explore reasons why this may be the case and possible implications.</p>'
- - /docs/iq/2020-fernandes.pdf
  - ! 'Macroevolutionary patterns and selection modes for general intelligence (G) and for commonly used neuroanatomical volume measures in primates'
  - Heitor B.F. Fernandes, Mateo Peñaherrera-Aguirre, Michael A. Woodley of Menie, Aurelio José Figueredo
  - 2020-05-01
  - 10.1016/j.intell.2020.101456
  - ! '<p><strong>Highlights</strong>:</p><ul><li>Evolutionary rates of <em>G</em> vs. neuroanatomical proxies are compared.</li><li><em>G</em> exhibits greater evolutionary lability.</li><li>This suggests different selection regimes.</li><li>cerebellar volume residualised against body size is the best proxy.</li></ul><p><strong>Abstract</strong>: Various neuroanatomical volume measures (<span class="smallcaps-auto">NVM</span>s) are frequently used as proxies for intelligence in comparative studies, such as the size of the brain, neocortex, and hippocampus, either absolute or controlled for other size measures (e.g., body size, or rest of the brain). Mean species <span class="smallcaps-auto">NVM</span>s are moderately correlated with aggregate general intelligence (<em>G</em>), however <em>G</em> and <span class="smallcaps-auto">NVM</span>s are yet to be compared in their evolutionary patterns (e.g., conservatism and evolutionary rates) and processes (i.e., their fit to diverse models of evolution reflecting selection regimes).</p><p>Such evolutionary information is valuable for examining convergence in the evolutionary history among traits and is not available from simple correlation coefficients. Considering accumulating evidence that non-volumetric neurological measures may be as important as (or more so than) volumetric measures as substrates of intelligence, and that certain <span class="smallcaps-auto">NVM</span>s negatively predict neuronal density, we hypothesized that discrepancies would be found in evolutionary patterns and processes of <em>G</em> compared to <span class="smallcaps-auto">NVM</span>s.</p><p>We collated data from the literature on primate species means for <em>G</em>, the volumes of the brain, neocortex, cerebellum, and hippocampus, and body mass, and employed phylogenetic comparative methods that examine phylogenetic signal (λ, K), evolutionary rates (σ<sup>2</sup>), and several parameters of evolutionary models (Brownian motion, Early-burst, acceleration, and Ornstein-Uhlenbeck).</p><p>Evolutionary rates and acceleration trends were up to an order of magnitude higher for <em>G</em> than for most <span class="smallcaps-auto">NVM</span>s, and a strong selection optimum toward which clades evolved was found for <em>G</em>, whereas <span class="smallcaps-auto">NVM</span>s conformed mostly to Brownian motion. Brain size was the most contrasting <span class="smallcaps-auto">NVM</span> compared to intelligence across most phylogenetic indices examined, showing signs of deceleration and extreme conservativeness. Only certain operationalizations of neocortical and hippocampal volume showed convergence with <em>G</em>, albeit still notably weakly. The <span class="smallcaps-auto">NVM</span> with results that most strongly approached the patterns identified for <em>G</em> is residual cerebellar size (relative to body size).</p><p>In comparison to the most commonly used volumetric measures (operationalization of brain and neocortex size), <em>G</em> must be seen as an evolutionarily labile trait under considerable selection pressure, necessitating that the role of the cerebellum be more aptly recognized and that other neurological factors be invoked as potential substrates for its evolutionary trajectory. [Keywords: general intelligence, phylogenetic comparative methods, cerebellum, brain size, neocortex]</p>'
- - /docs/iodine/2015-politi.pdf
  - ! 'The effects of the generalized use of iodized salt on occupational patterns in Switzerland'
  - Dimitra Politi
  - 2015-12-15
  - ''
  - ! '<p>I estimate the long-term impact of the first large-scale nutritional supplementation program, salt iodization, which took place in Switzerland in the 1920s and 1930s. Iodized salt improved the health environment in utero, and it eradicated mental retardation caused by insufficient iodine intake. By exploiting variation in the pre-existing prevalence of iodine deficiency, as well as differences in the timing of the intervention across Swiss cantons, I show that cohorts born in previously highly deficient areas after the introduction of iodized salt were more likely to enter top-tier occupations with higher cognitive demands. As a result, wages of these cohorts were higher, accounting for about 1.9% of annual median earnings, or 2% of Swiss <span class="smallcaps-auto">GDP</span> per capita in 1991. [Keywords: Iodine deficiency, cognitive ability, occupational choice, human capital, productivity]</p>'
- - /docs/iodine/2014-politi.pdf
  - ! 'The Impact of Iodine Deficiency Eradication on Schooling: Evidence from the Introduction of Iodized Salt in Switzerland'
  - Dimitra Politi
  - 2014-05-09
  - ''
  - ! '<p>I study the impact of salt iodization in Switzerland on graduation rates. The programme, which began in 1922 and continues to this day, was the first wide-reaching nutritional intervention ever to take place. Iodine deficiency in utero causes mental retardation, and correcting the deficiency is expected to increase the productivity of a population by increasing its cognitive ability. The exogenous increase in cognitive ability brought about by the iodization program is also useful in the context of disentangling the effects of innate ability and education on later-life outcomes. I identify the impact of iodization on graduation rates by exploiting pre-existing geographic variation in the prevalence of iodine deficiency, as well as spatial and temporal variation in the introduction of iodized salt across Swiss cantons. By looking at sharp, discontinuous increases in iodized salt circulation I show that the eradication of iodine deficiency in previously deficient areas significantly increased graduation rates from upper secondary and tertiary education. My results are robust to falsification tests and different measures of iodine deficiency. [Keywords: Cognitive ability, education, human capital, productivity]</p>'
- - /docs/dnb/2009-rodriguezjimenez.pdf
  - ! 'Differential dorsolateral prefrontal cortex activation during a verbal <em>n</em>-back task according to sensory modality'
  - Roberto Rodriguez-Jimenez, Cesar Avila, Cristina Garcia-Navarro, Alexandra Bagney, Ana Martinez de Aragon, Noelia Ventura-Campos, Isabel Martinez-Gras, Cristina Forn, Guillermo Ponce, Gabriel Rubio, Miguel Angel Jimenez-Arriero, Tomas Palomo
  - 2009-12-14
  - 10.1016/j.bbr.2009.08.022
  - ! '<p>Functional neuroimaging studies carried out on healthy volunteers while performing different n-back tasks have shown a common pattern of bilateral frontoparietal activation, especially of the dorsolateral prefrontal cortex (<span class="smallcaps-auto">DLPFC</span>). Our objective was to use functional magnetic resonance imaging (f<span class="smallcaps-auto">MRI</span>) to compare the pattern of brain activation while performing two similar <em>n</em>-back tasks which differed in their presentation modality. Thirteen healthy volunteers completed a verbal 2-back task presenting auditory stimuli, and a similar 2-back task presenting visual stimuli. A conjunction analysis showed bilateral activation of frontoparietal areas including the <span class="smallcaps-auto">DLPFC</span>. The left <span class="smallcaps-auto">DLPFC</span> and the superior temporal gyrus showed a greater activation in the auditory than in the visual condition, whereas posterior brain regions and the anterior cingulate showed a greater activation during the visual than during the auditory task. Thus, brain areas involved in the visual and auditory versions of the <em>n</em>-back task showed an important overlap between them, reflecting the supramodal characteristics of working memory. However, the differences found between the two modalities should be considered in order to select the most appropriate task for future clinical studies. [Keywords: f<span class="smallcaps-auto">MRI</span>, Working memory, <em>n</em>-back task, Auditory, Visual, <span class="smallcaps-auto">DLPFC</span>]</p>'
- - /docs/iq/1994-schwartz.pdf
  - ! 'Societal Benefits of Reducing Lead Exposure'
  - J. Schwartz
  - 1994-07-01
  - 10.1006/enrs.1994.1048
  - ! '<p>While sophistication in public health research has been increasing substantially in the past few decades, sophistication in decision making about public health and environmental issues has not been increasing in parallel. Measures that are inexpensive tend to be implemented and measures that are expensive tend not to be implemented by makers of public policy. That is often independent of the degree of public health protection afforded by the measures. Understanding and addressing this pattern is crucial to the control of lead exposure of critical populations. People are still exposed to lead in our society not because anyone believes that exposure is good, but because reducing exposure costs money. Maintaining exposure also has its costs, however. It is more difficult to measure them, and they are often ignored in decision making—but they are not small, and attempts to measure them have been made. The high cost of reducing lead exposure of critical populations is the reason that progress in reducing lead-paint exposure has been minimal in the 18 years since the passage of the Lead-Based Paint Poisoning Prevention Act and that it took from the time of the initial proposal in 1973 until 1986 before lead was substantially eliminated from gasoline. In its 1986 rule making, the <span class="smallcaps-auto">EPA</span> estimated that the elimination of lead from gasoline would cost more than $500 million per year. Removing leaded paint is estimated to cost billions of dollars. The difference is that the <span class="smallcaps-auto">EPA</span> promulgated its rule of removing lead from gasoline, whereas <span class="smallcaps-auto">HUD</span> has had little success in removing leaded paint from housing. One reason that the <span class="smallcaps-auto">EPA</span> was successful in implementing such an expensive regulation was that it provided detailed estimates of the health and welfare benefits that would accrue and the monetary value of some of the benefits. The <span class="smallcaps-auto">EPA</span> cost-benefit analysis demonstrated that the monetary benefits of its regulation far exceeded the costs. That neutralized the cost issue and focused the debate over the regulation on questions of timing. A detailed benefit analysis of reducing lead in drinking water has caused the <span class="smallcaps-auto">EPA</span> to consider tighter water lead standards than initially envisioned. Despite years of concern about the consequences of leaded paint poisoning, children continue to be poisoned by leaded paint because it will cost billions of dollars to abate the hazard, and demand for these dollars has lost out to competing needs. As long as attention focuses on the costs of lead-paint abatement and ignores the costs of not abating and as long as people add up the costs of removing paint but not the costs of medical care, compensatory education, and school dropouts, substantial action is unlikely. It is possible that a detailed benefit analysis of lead-paint removal will not show that benefits exceed the costs, but we think it unlikely, given the large benefits estimated for other programs that reduce lead exposure, that a cost-beneficial removal strategy cannot be found. If no attempt is made to estimate the benefits, this strategy is less likely to be adopted. This paper cannot reasonably estimate the costs and benefits of the many measures that are available to reduce lead exposure of critical populations. It can, however, describe the methods that have been used and present a prototypical analysis that can readily be adapted to develop analyses specific to individual actions.</p>'
- - /docs/economics/2010-oberholzergee.pdf
  - ! 'File Sharing and Copyright'
  - Felix Oberholzer-Gee, Koleman Strumpf
  - 2010-01-01
  - 10.1086/605852
  - ! '<p>The advent of file sharing has considerably weakened effective copyright protection. Today, more than 60% of Internet traffic consists of consumers sharing music, movies, books, and games. Yet, despite the popularity of the new technology, file sharing has not undermined the incentives of authors to produce new works. We argue that the effect of file sharing has been muted for three reasons. (1) The cannibalization of sales that is due to file sharing is more modest than many observers assume. Empirical work suggests that in music, no more than 20% of the recent decline in sales is due to sharing. (2) File sharing increases the demand for complements to protected works, raising, for instance, the demand for concerts and concert prices. The sale of more expensive complements has added to artists’ incomes. (3) In many creative industries, monetary incentives play a reduced role in motivating authors to remain creative. Data on the supply of new works are consistent with the argument that file sharing did not discourage authors and publishers. Since the advent of file sharing, the production of music, books, and movies has increased sharply.</p>'
- - /docs/genetics/heritable/2020-dawes.pdf
  - ! 'On the genetic basis of political orientation'
  - Christopher T. Daws, Aaron C. Weinschenk
  - 2020-08-01
  - 10.1016/j.cobeha.2020.03.012
  - ! '<ul><li>Twin studies show that political ideology is about 40% heritable.</li><li>More sophisticated designs also find a substantial genetic influence on ideology.</li><li>Recent studies have examined how genes connect to ideology, finding some evidence that psychological traits may link genes and ideology.</li><li>Genome-wide association studies have started to emerge, but findings should be taken as very preliminary at this point.</li><li>Future work will benefit from large samples that provide enough power to study genetic variants related to ideology.</li></ul><p>Scholars have long been interested in the underpinnings of political ideology. Over the past fifteen years or so, political scientists, psychologists, sociologists, and economists have started to take seriously the idea that ideology might be influenced by genes. In this article, we review the literature on the genetics of ideology. We begin by describing twin studies and more sophisticated approaches that have now emerged, which consistently show that ideology is about 40% heritable. Next, we examine the state of research on genetic influences on ideology over the life cycle and mechanisms that could link genes and ideology. We conclude by discussing the preliminary genome-wide studies that have been conducted. Existing research has provided important insights into the link between biology and ideology, but additional research is needed in order to provide a more nuanced understanding of the role of biology in the formation of political ideology.</p>'
- - https://siguza.github.io/psychicpaper/
  - Psychic Paper
  - Siguza
  - 2020-05-01
  - ''
  - ! '[Writeup of a major Apple iOS vulnerability: any application could access most of the system by simply sending the OS an <span class=\"smallcaps-auto\">XML</span> document requesting access to permissions it was allowed, and then, inside an <span class=\"smallcaps-auto\">XML</span> "comment", including a request for all other permissions. Because iOS uses multiple libraries to parse <span class=\"smallcaps-auto\">XML</span> documents, which all disagree on what is valid <span class=\"smallcaps-auto\">XML</span> and how comments are handled, the outer request was valid for the first check (that it was not requesting permissions it should not) but then the inner request hidden in the comment would be parsed and since it was supposedly already checked and proven safe, the additional request would go through, granting all permissions. Oops.]'
- - https://www.thisfursonadoesnotexist.com
  - 'This Fursona Does Not Exist (<span class="smallcaps-auto">TFDNE</span>)'
  - ! '<a href="https://twitter.com/arfafax">Arfafax</a>'
  - 2020-05-07
  - ''
  - ! '<p>A Style<span class="smallcaps-auto">GAN</span> 2 showcase: high-quality <span class="smallcaps-auto">GAN</span>-generated furry (anthropomorphic animals) faces, trained on <a href="https://github.com/arfafax/E621-Face-Dataset"><em>n</em>=55k faces</a> cropped from the e621 furry image booru. For higher quality, the creator heavily filtered faces and aligned them, and upscaled using waifu2×. For display, it reuses Obormot’s <a href="https://www.obormot.net/demos/these-waifus-do-not-exist-v2-alt">“These Waifus Do Not Exist”</a> scrolling grid code to display an indefinite number of faces rather than one at a time. (<span class="smallcaps-auto">TFDNE</span> is also available on <a href="https://artbreeder.com">Artbreeder</a> for interactive editing/crossbreeding, and a <a href="https://fursona.app">Google Colab notebook</a> for Ganspace-based editing</a>.)</p><figure><img src="/images/gan/2020-05-06-stylegan2-arfafax-tfdne-9xgrid.png" alt="9 random AI generated furry faces" /><figcaption>9 random <span class="smallcaps-auto">TFDNE</span> furry face samples in a grid</figcaption></figure><p>Model download mirrors:</p><ul><li><p><a href="https://drive.google.com/file/d/1t7E8NEqK_gVJwxrWEihR1IcPfekaBc1d/view">Google Drive</a></p></li><li><p><a href="https://mega.nz/file/Wa4EFQRA#XL9X5tGNrlp1bTdafPWK_Kg65RW3J5-CR9biGEfFm_g">Mega</a></p></li><li><p>Rsync:</p><div class="sourceCode" id="cb1"><pre class="sourceCode Bash"><code class="sourceCode bash"><span id="cb1-1"><a href="https://en.wikipedia.org/wiki/Dieter_Rams#cb1-1"></a><span class="fu">rsync</span> --verbose rsync://78.46.86.149:873/biggan/2020-05-06-arfa-stylegan2-e621-r-512-3194880.pkl.xz ./</span></code></pre></div></li></ul><p>See also the <em>My Little Pony</em>-themed followup <a href="https://tpdne.arfa.dev/">"This Pony Does Not Exist" (TPDNE)</a>.</p>'
- - /docs/design/2014-bigelow.pdf
  - ! 'Reflections on How Designers Design with Data'
  - Alex Bigelow, Steven Mark Drucker, Danyel Fisher, Miriah D. Meyer
  - 2014-05-27
  - 10.1145/2598153.2598175
  - ! '<p>In recent years many popular data visualizations have emerged that are created largely by designers whose main area of expertise is not computer science. Designers generate these visualizations using a handful of design tools and environments. To better inform the development of tools intended for designers working with data, we set out to understand designers’ challenges and perspectives. We interviewed professional designers, conducted observations of designers working with data in the lab, and observed designers working with data in team settings in the wild. A set of patterns emerged from these observations from which we extract a number of themes that provide a new perspective on design considerations for visualization tool creators, as well as on known engineering problems.</p><p>…<strong>Patterns</strong>: In our observational studies we observed all of the designers initially sketching visual representations of data on paper, on a whiteboard, or in Illustrator. In these sketches, <strong>the designers would first draw high-level elements of their design such as the layout and axes, followed by a sketching in of data points based on their perceived ideas of data behavior (P1)</strong>. An example is shown in Figure 3. The designers often relied on their understanding of the semantics of data to infer how the data might look, such as F1 anticipating that Fitbit data about walking would occur in short spurts over time while sleep data would span longer stretches. However, <strong>the designers’ inferences about data behavior were often inaccurate (P2)</strong>. This tendency was acknowledged by most of the designers: after her inference from data semantics, F1 indicated that to work effectively, she would need “<em>a better idea of the behavior of each attribute</em>.” Similarly, B1 did not anticipate patterns in how software bugs are closed, prompting a reinterpretation and redesign of her team’s visualization much later in the design process once data behavior was explicitly explored. In the time travel studies, T3 misinterpreted one trip that later caused a complete redesign.</p><p>Furthermore, <strong>the designers’ inferences about data structure were often separated from the actual data (P3)</strong>. In brainstorming sessions at the hackathon, the designers described data that would be extremely difficult or impossible to gather or derive. In working with the <span class="smallcaps-auto">HBO</span> dataset, H1 experienced frustration after he spent time writing a formula in Excel only to realize that he was recreating data he had already seen in the aggregate table…Not surprisingly, <strong>the amount of data exploration and manipulation was related to the level of a designer’s experience working with data (P4)</strong>.</p>'
- - /docs/economics/2019-bazzi.pdf
  - ! 'The Institutional Foundations of Religious Politics: Evidence from Indonesia'
  - Samuel Bazzi, Gabriel Koehler-Derrick, Benjamin Marx
  - 2019-12-23
  - 10.1093/qje/qjz038
  - ! '<p>This article explores the foundations of religious influence in politics and society. We show that an important Islamic institution fostered the entrenchment of Islamism at a critical juncture in Indonesia, the world’s largest Muslim country. In the early 1960s, rural elites transferred large amounts of land into <em>waqf</em>—inalienable charitable trusts in Islamic law—to avoid expropriation by the state. Regions facing a greater threat of expropriation exhibit more prevalent <em>waqf</em> land and Islamic institutions endowed as such, including mosques and religious schools. These endowments provided conservative forces with the capital needed to promote Islamist ideology and mobilize against the secular state. We identify lasting effects of the transfers on the size of the religious sector, electoral support for Islamist parties, and the adoption of local sharia laws. These effects are shaped by greater demand for religion in government but not by greater piety among the electorate. <em>Waqf</em> assets also impose costs on the local economy, particularly in agriculture, where these endowments are associated with lower productivity. Overall, our findings shed new light on the origins and consequences of Islamism.</p>'
- - /docs/genetics/editing/2020-yagound.pdf
  - ! 'A Single Gene Causes Thelytokous Parthenogenesis, the Defining Feature of the Cape Honeybee <em>Apis mellifera capensis</em>'
  - Boris Yagound, Kathleen A. Dogantzis, Amro Zayed, Julianne Lim, Paul Broekhuyse, Emily J. Remnant, Madeleine Beekman, Michael H. Allsopp, Sarah E. Aamidor, Orly Dim, Gabriele Buchmann, Benjamin P. Oldroyd
  - 2020-05-07
  - 10.1016/j.cub.2020.04.033
  - ! '<p>In honeybees, the ability of workers to produce daughters asexually, i.e., thelytokous parthenogenesis, is restricted to a single subspecies inhabiting the Cape region of South Africa, <a href="https://en.wikipedia.org/wiki/Cape_honey_bee"><em>Apis mellifera capensis</em></a>. Thelytoky has unleashed new selective pressures and the evolution of traits such as social parasitism, invasiveness, and social cancer. Thelytoky arises from an abnormal meiosis that results in the fusion of two maternal pronuclei, restoring diploidy in newly laid eggs. The genetic basis underlying thelytoky is disputed. To resolve this controversy, we generated a backcross between thelytokous <em>A. m. capensis</em> and non-thelytokous <em>A. m. scutellata</em> from the neighboring population and looked for evidence of genetic markers that co-segregated with thelytokous reproduction in 49 backcross females. We found that markers associated with the gene GB45239 on chromosome 11, including non-synonymous variants, showed consistent co-segregation with thelytoky, whereas no other region did so. Alleles associated with thelytoky were present in all <em>A. m. capensis</em> genomes examined but were absent from all other honeybees worldwide including <em>A. m. scutellata</em>. GB45239 is derived in <em>A. m. capensis</em> and has a putative role in chromosome segregation. It is expressed in ovaries and is downregulated in thelytokous bees, likely because of polymorphisms in the promoter region. Our study reveals how mutations affecting the sequence and/or expression of a single gene can change the reproductive mode of a population. [Keywords: thelytoky, honeybee, meiosis, reproductive mode]</p>'
- - /docs/genetics/selection/2014-brust.pdf
  - ! 'Domestication effects on behavioural traits and learning performance: comparing wild cavies to guinea pigs'
  - Vera Brust, Anja Guenther
  - 2014-07-06
  - 10.1007/s10071-014-0781-9
  - ! '<p>The domestication process leads to a change in behavioural traits, usually towards individuals that are less attentive to changes in their environment and less aggressive. Empirical evidence for a difference in cognitive performance, however, is scarce. Recently, a functional linkage between an individual’s behaviour and cognitive performance has been proposed in the framework of animal personalities via a shared risk–reward trade-off. Following this assumption, bolder and more aggressive animals (usually the wild form) should learn faster. Differences in behaviour may arise during ontogeny due to individual experiences or represent adaptations that occurred over the course of evolution. Both might singly or taken together account for differences in cognitive performance between wild and domestic lineages. To test for such possible linkages, we compared wild cavies and domestic guinea pigs, both kept in a university stock for more than 30 years under highly comparable conditions. Animals were tested in three behavioural tests as well as for initial and reversal learning performance. Guinea pigs were less bold and aggressive than their wild congeners, but learnt an association faster. Additionally, the personality structure was altered during the domestication process. The most likely explanation for these findings is that a shift in behavioural traits and their connectivity led to an altered cognitive performance. A functional linkage between behavioural and cognitive traits seems to exist in the proposed way only under natural selection, but not in animals that have been selected artificially over centuries.</p>'
- - /docs/longevity/1990-bjorksten.pdf
  - ! 'The crosslinking theory of aging—Added evidence'
  - John Bjorksten, Heikki Tenhu
  - '1990'
  - 10.1016/0531-5565(90)90039-5
  - ! '<p>The cross-linking theory of aging has been gaining acceptance at a steady pace, as evidenced by many independent rediscoveries. While several earlier studies were indicative, none seemed conclusive until it was shown, using Differential Scanning Calorimetry (<span class="smallcaps-auto">DSC</span>), that protein from young human brains could be made to closely resemble protein from old brains by exposing it to either of two entirely different cross-linking agents (glutaraldehyde and dipotassium diperoxy sulfate). This work has now been repeated with additional brain material, and a statistically more significant number of determinations. It is now shown that a treatment of brain protein with either one or two chemically totally different compounds which have no property in common except that both are cross-linkers, changes young brain protein so that it greatly resembles old, crosslinked protein. This shows that cross-linking reactions are involved in the age related changes in the studied proteins. [Keywords: cross-linking, aging, differential scanning calorimetry]</p>'
- - https://ehp.niehs.nih.gov/doi/pdf/10.1289/ehp.8981241
  - "The role of aluminum and age-dependent decline"
  - John Bjorksten
  - 1989-05
  - 10.1289/ehp.8981241
  - ! '<p>[Letter to the editor about aluminum poisoning and aging. Bjorksten argues that cross-linkage, contrary to the discussed researchers claims, can be the main mechanism of the poisoning despite the tiny absolute amount of cross-linking agents.]</p><p>The cross-linking agents correspond to the ropes connecting a ship to a pier. Of all known types of chemical reactions, cross-linking is among those of which the smallest possible quantity of a reagent has the largest possible insolubilizing effect. A cross-linking agent is anything that has at least two reactive sites at some distance from each other. The aluminum ion is one of the most effective cross-linking agents and has for a century been used as such (6). More recent implications of these effects were covered in Bjorksten et al. (8, 9).</p>'
- - /docs/longevity/1972-bjorksten.pdf
  - ! 'Enzymatic Lysis in Vitro of Hyalin Deposits in Human Kidney'
  - Johan Bjorksten, J. M. B. Bloodworth Jr., Ralph Buetow
  - 1972-05
  - 10.1111/j.1532-5415.1972.tb00788.x
  - ! '<p>Vascular <a href="https://en.wikipedia.org/wiki/Hyalin">hyalin</a> was readily dissolved in vitro from sections of the formalin-preserved, paraffin-embedded kidney of a hypertensive patient, by means of an enzyme (BJ-B-66) isolated from <em>Bac. cereus.</em> The enzyme attacked other hyalins and tissue components as well. The enzyme is active at body temperature and pH, and appears substantially nontoxic to rats and hamsters.</p>'
- - /docs/longevity/1971-bjorksten.pdf
  - ! 'Gerogenic Fractions In The Tritiated Rat'
  - Johan Bjorksten, P. V. N. Acharya, Stephen Ashman, Donald B. Wetlaufer
  - 1971-07
  - 10.1111/j.1532-5415.1971.tb02577.x
  - ! '<p>A rat that had received tritiated acetate perinatally was killed at the age of 609 days, and was found to have retained substantial quantities of tritium in all organs examined. This study was focussed on the liver, which—after a succession of extractions with a series of various solvents followed by catalytic hydrolysis at body temperature—yielded a residue that was-insoluble in a wide range of common solubilizing media. Treatment with hot mineral acid partially dissolved this residue and electrophoretic fractionation further led to 4 fractions of which a single fraction contained most of the tritium in the insoluble residue.</p><p>Our analyses showed that the insoluble residue contained a variety of common amino acids and a considerable amount of phosphorus. The solubilized fractions derived from the insoluble residue all contained substantial concentrations of pentose, deoxypentose, and phosphorus. They showed ultraviolet absorption spectra qualitatively similar to those of nucleic acids. From their chromatographic behavior on crosslinked dextran columns, all 4 solubilized fractions showed molecular weights greater than 5000. In addition, these fractions showed substantially greater resistance to hydrolytic degradation than do authentic <span class="smallcaps-auto">RNA</span> and <span class="smallcaps-auto">DNA</span>. Taken together, this is interpreted as evidence that the gerogenic insoluble residue is composed of a highly crosslinked network of at least <span class="smallcaps-auto">RNA</span>, <span class="smallcaps-auto">DNA</span> and protein, which is stabilized by covalent cross-linkages of unusual stability. Formation of these crosslinked structures could easily interfere with the function of certain critical molecules of <span class="smallcaps-auto">RNA</span>, <span class="smallcaps-auto">DNA</span> or other polymers, leading to impaired cell function and death.</p>'
- - /docs/longevity/1970-bjorksten.pdf
  - ! 'Nitrogenous Compounds Immobilized In An Aged Rat'
  - Johan Bjorksten, Stephen Ashman
  - 1970-02
  - 10.1111/j.1532-5415.1970.tb02109.x
  - ! '<p>A pregnant rat received 8 mc of tritiated tyrosine at the time of giving birth (from seven days before, to six days after). No radioisotopes were ever given directly to the litter born. A male from this litter died from pneumonia at age 809 days. After removal of water and acetone solubles and of phospholipids, hydrolysis of the residue released the following radioactive amino acids, parts of molecules fixed until death and containing tritium present at birth: lysine, arginine, aspartic acid, glutamic acid, serine, listed in order of decreasing radioactivity, with lysine carrying 29 per cent of the total tritium present.</p>'
- - /docs/longevity/1965-andrews.pdf
  - ! 'The reaction of an autoxidized lipid with proteins'
  - Fred Andrews, Johan Bjorksten, F. B. Trenk, A. S. Henick, R. B. Koch
  - 1965-09
  - 10.1007/BF02631862
  - ! '<p>Evidence is presented which indicates that an interaction occurs between proteins and an autoxidizing unsaturated lipid. Using a model system approach, it has been established that two purified proteins (gelatin and insulin) are chemically modified in the presence of an autoxidizing lipid, methyl linoleate.</p><p>The insulin-methyl linoleate interaction has been studied chromatographically after acid and alkaline hydrolysis, and also by using the Sanger end group analysis method. The data indicate that lipid intermediates react with theε-amino group of lysine, and also with phenylalanine and glycine, the N-terminal amino groups of insulin.</p><p>Hydrogen fluoride solubility and enzyme hydrolysis determinations indicate that the autoxidation products of methyl linoleate interact with protein to produce new chemical entities through cross-linking.</p>'
- - /docs/longevity/1965-andrews-2.pdf
  - ! 'Chemical Composition Of Enzyme-Fractionated Aged Heart Tissue'
  - Fred Andrews, Johan Bjorksten, Chester Underwood, David Thomson, Perttu Laakso
  - 1965-02
  - 10.1111/j.1532-5415.1965.tb00695.x
  - ! '<p>Fractionation of the enzyme-nonhydrolyzable constituents of human heart muscle from persons 64–74 years old resulted in separation of a fluorescing fraction, insoluble in anhydrous hydrogen fluoride, and containing 4.6% nitrogen (corresponding to 30% protein). This fraction was free from hydroxyproline and is therefore not derived from collagen.</p><p>An aromatic aldehyde was consistently separated when the enzymatically nonhydrolyzable fraction was broken down by destructive acid hydrolysis. Infrared data indicate a structure having characteristics in common with coenzyme Q.</p>'
- - /docs/longevity/1968-bjorksten.pdf
  - ! 'The Crosslinkage Theory Of Aging'
  - John Bjorksten
  - 1968-04
  - 10.1111/j.1532-5415.1968.tb02821.x
  - ! '<p>For many decades the theory and practice of cross-linking (bonding that ties two or more large molecules together side to side) have been developed in industry, but only since the 1940’s has the theory been considered in the field of medicine as a primary reaction underlying age-dependent changes.</p><p>Cross-linking is damaging to the tissues and involves loss of elasticity, reduced swelling capacity, increased resistance to hydrolases and probably enzymes generally, and thus an increase in molecular weight and a tendency toward embrittlement. There is a growing amount of direct evidence and much indirect evidence for postulating the relationship between cross-linking and aging.</p><p>Cross-linking agents present in the living organism include aldehydes, lipid oxidation products, sulfur, alkylating agents, quinones, free radicals induced by ionizing radiation, antibodies, polybasic acids, polyhalo derivatives and polyvalent metals. The latter four types of compound are slow-acting but can also accumulate in the body to form a frozen metabolic pool. Sufficient amounts of all these potential cross-linking materials are present in the body to make the changes of aging unavoidable.</p>'
- - /docs/longevity/1977-bjorksten-2.pdf
  - ! 'Pathways to the Decisive Extension of the Human Specific Lifespan'
  - John Bjorksten
  - 1977-09
  - 10.1111/j.1532-5415.1977.tb00673.x
  - ! '<p>3 approaches to reversal or removal of gerogenic aggregations of macromolecules have shown promise. Of these the <em>enzyme approach</em> is the most gentle, and can be made specific. Aside from this, the lower the molecular weight of an enzyme, the better chance it will have to be immunologically tolerated as well as replicated synthetically in whole or in part. The <em>chelating approach</em> provides a powerful means for removing a single class of unwanted, random crosslinkages, i.e., those due to extraneous polyvalent metals such as lead, cadmium and aluminum. The <em>free hydroxyl radical approach</em> is the most penetrant and most versatile means for removing otherwise insoluble aggregates, but its very lack of specificity will demand great foresight in control and use. Together, these three methods, when properly applied, might bring some principal objectives of gerontology within closer range.</p>'
- - /docs/longevity/1958-bjorksten.pdf
  - ! 'A Common Molecular Basis For The Aging Syndrome'
  - John Bjorksten
  - 1958-10
  - 10.1111/j.1532-5415.1958.tb00777.x
  - ! '<p>Degenerative changes must have a basic cause on the molecular level. For example, the possible role of protein immobilization by means of progressive cross-linking reactions is critically examined in the light of known data on potential cross-linking agents present in the bloodstream, and of related physio-logic facts.</p>'
- - /docs/longevity/1951-bjorksten.pdf
  - ! 'Cross Linkages in Protein Chemistry'
  - John Bjorksten
  - 1951-01
  - 10.1016/S0065-3233(08)60507-0
  - ! '<p>This chapter provides an overview of scattered and diverse data on the ability of proteins to form cross linkages that connect molecules or micelles, thus leading to the formation of larger aggregates. Even a single cross linkage between two large molecules has the immediate result of combining them into a unit having a molecular weight equal to the sum of the molecular weights of the molecules involved; repeated cross linkages multiply the size of molecules that are already extremely large. The immediately observable results are reduced solubility or peptizability, increased resistance to hydrothermal influences, and reduced resilience or elasticity accompanied by darkening in color, and in extreme cases, brittleness. The presence of many reactive groups in protein molecules make them particularly susceptible to cross-linking reactions. Aldehydes can form a methylene bridge, or can react with amino groups linking protein molecules together with the formation of Schiff bases. Dicarboxylic and particularly disulfonic acids can form cross-linking bridges by reaction with amino groups. The chapter briefly describes some of the principal purposes that have stimulated industrial experimentation with reactions involving cross linkage of proteins. It also outlines the types of industrial problems handled by cross-linking reactions. Further, the chapter describes cross-linking processes indicated in the literature.</p>'
- - /docs/longevity/1982-bjorksten-2.pdf
  - ! 'Aluminum as a Cause of Senile Dementia'
  - John Bjorksten
  - 1982-05
  - ''
  - ! '<p>The evidence reviewed shows that senile dementia may be similar in origin to Alzheimer’s disease and to dialysis encephalopathy. There is general agreement that aluminum, once attached to the chromatin in a neuron, cannot be dislodged by any means available to the organism. Yet the presence of aluminum in serum shows that at least some trace will always be able to pass biologic barriers and ultimately reach critical neuronal chromatin. Alfrey shows that the aluminum content of heart and brain remains relatively low until the bone content nears a saturation point, after which aluminum deposition in heart and brain accelerates (Figure 1).<sup>16</sup> The data on aluminum content of the human aorta by Zinsser, Bjorksten, et al indicate that aluminum content peaks from age 40 to 50 years, and declines moderately thereafter.<sup>17</sup> Thus, it is possible that persons who have the highest body level of aluminum may not survive for five years, but more data are needed to prove this theory.</p>'
- - /docs/iq/2020-lerche.pdf
  - ! 'Diffusion Modeling and Intelligence: Drift Rates Show Both Domain-General and Domain-Specific Relations With Intelligence'
  - Veronika Lerche, Mischa von Krause, Andreas Voss, Gidon T. Frischkorn, Anna-Lena Schubert, Dirk Hagemann
  - 2020-05-07
  - 10.1037/xge0000774
  - ! '<p>Several previous studies reported relationships between speed of information processing as measured with the drift parameter of the diffusion model (Ratcliff, 1978) and general intelligence. Most of these studies utilized only few tasks and none of them used more complex tasks. In contrast, our study (<em>n</em>=125) was based on a large battery of 18 different response time tasks that varied both in content (numeric, figural, and verbal) and complexity (fast tasks with mean RTs of ca. 600 ms vs. more complex tasks with mean RTs of ca. 3,000 ms). Structural equation models indicated a strong relationship between a domain-general drift factor and general intelligence. Beyond that, domain-specific speed of information processing factors were closely related to the respective domain scores of the intelligence test. Furthermore, speed of information processing in the more complex tasks explained additional variance in general intelligence. In addition to these theoretically relevant findings, our study also makes methodological contributions showing that there are meaningful interindividual differences in content specific drift rates and that not only fast tasks, but also more complex tasks can be modeled with the diffusion model.</p>'
- - /docs/technology/1972-swift.pdf
  - ! 'Image rotation devices—a comparative survey'
  - D. W. Swift
  - 1972-08-01
  - 10.1016/0030-3992(72)90006-0
  - ! '<p>Optical systems which, when rotated, produce a rotation of an image about the optical axis have been known and used for a long time. Information on such systems is sparse, however, and widely scattered. This paper discusses image rotation devices in general terms, and then attempts to collect together the more commonly used devices and to present comparative information on them, in order to provide a convenient reference source for optical designers. In addition a number of lesser known and novel arrangements are described.</p>'
- - /docs/genetics/selection/2020-hazel.pdf
  - ! 'An age-dependent ovulatory strategy explains the evolution of dizygotic twinning in humans'
  - Wade N. Hazel, Robert Black, Richard C. Smock, Rebecca Sear, Joseph L. Tomkins
  - 2020-05-11
  - 10.1038/s41559-020-1173-y
  - ! '<p>Dizygotic twinning, the simultaneous birth of siblings when multiple ova are released, is an evolutionary paradox. Twin-bearing mothers often have elevated fitness, but despite twinning being heritable, twin births occur only at low frequencies in human populations. We resolve this paradox by showing that twinning and non-twinning are not competing strategies; instead, dizygotic twinning is the outcome of an adaptive conditional ovulatory strategy of switching from single to double ovulation with increasing age. This conditional strategy, when coupled with the well-known decline in fertility as women age, maximizes reproductive success and explains the increase and subsequent decrease in the twinning rate with maternal age that is observed across human populations. We show that the most successful ovulatory strategy would be to always double ovulate as an insurance against early fetal loss, but to never bear twins. This finding supports the hypothesis that twinning is a by-product of selection for double ovulation rather than selection for twinning.</p>'
- - /docs/iq/2019-andreoni.pdf
  - ! 'Toward an understanding of the development of time preferences: Evidence from field experiments'
  - James Andreoni, Michael A. Kuhn, John A. List, Anya Samek, Kevin Sokal, Charles Sprenger
  - 2019-09-01
  - 10.1016/j.jpubeco.2019.06.007
  - ! '<p><strong>Highlights</strong>:</p><ul><li>We conduct field experiments on time preferences with children ages 3–12.</li><li>Time preferences evolve significantly during this period, with older children displaying more patience.</li><li>Neither assignment to early schooling or parent preferences can explain child time preferences.</li><li>Interestingly, we observe that black children are more impatient than white or Hispanic children.</li></ul><p><strong>Abstract</strong>: Time preferences have been correlated with a range of life outcomes, yet little is known about their early development. We conduct a field experiment to elicit time preferences of over 1200 children ages 3–12, who make several intertemporal decisions. To shed light on how such primitives form, we explore various channels that might affect time preferences, from background characteristics to the causal impact of an early schooling program that we developed and operated. Our results suggest that time preferences evolve substantially during this period, with younger children displaying more impatience than older children. We also find a strong association with race: black children, relative to white or Hispanic children, are more impatient. Finally, assignment to different schooling opportunities is not significantly associated with child time preferences. [Keywords: Time preferences, Child behavior, Experiment, Inter-generational transmission]</p>'
- - /docs/iq/2005-viswesvaran.pdf
  - ! 'Job Performance: Assessment Issues in Personnel Selection'
  - Chockalingam Viswesvaran, Deniz S. Ones
  - 2005-01-01
  - 10.1002/9781405164221.ch16
  - ! '<p>An important construct in Industrial, Work and Organizational (<span class="smallcaps-auto">IWO</span>) psychology, organizational behavior, and human resources management (personnel selection, training, and performance evaluation) in general, and personnel selection in particular, is the construct of job performance. Job performance is the most important dependent variable in <span class="smallcaps-auto">IWO</span> psychology. A general definition of the construct of job performance reflects behaviors (both visually observable and non-observable) that can be evaluated. In other words, job performance refers to scalable actions, behaviors, and outcomes that employees engage in or bring about that are linked with and contribute to organizational goals. To date, most researchers focusing on the construct of job performance have confined themselves to particular situations and settings with no attempt to generalize their findings. Also, there has been an emphasis on prediction and practical application rather than explanation and theory building. The consequence of these two trends has been a proliferation of the various measures of job performance in the extant literature. Virtually every measurable individual differences dimension thought to be relevant to the productivity, efficiency, or profitability of the unit or organization has been used as a measure of job performance. Absenteeism, productivity ratings, violence on the job, and teamwork ratings are some examples of the variety of measures used to measure job performance.</p>'
- - /docs/longevity/1981-bjorksten.pdf
  - ! 'Selenium In Nutrition'
  - John Bjorksten
  - 1981-07-01
  - ''
  - ! '<p>Every useful substance—water, salt, air, nutrients, and vitamins as well as therapeutic agents—has a range below which it loses effectiveness and above which it becomes harmful. With selenium the optimum range is fairly narrow, and the penalties for transgression can he dramatic.</p><p>…Selenium has had dramatic acceptance in animal husbandry. However, in those countries where selenium content is minimal, the farmer who feeds his cattle selenium supplement is often himself the victim of infarctions that would have been prevented by a selenium supplement. Knowledge has gradually accumulated, and the hazards defined. Use of selenium in human nutrition and preventive medicine has become feasible.</p><p>While most of the United States has adequate selenium, some natural deficiency occurs in areas where heavy rains are common. Inclusion of selenium in dietary supplements was discussed at the U. S. Quartermaster Conference on Antioxidants in Natick, MA in 1979. A detailed specific geriatric formula in which selenium was one ingredient was published in the proceedings.<sup>15</sup> This formula is not patented and has not been on the market, but has been used regularly by some persons for several years with apparent satisfaction.</p>'
- - /docs/cs/1987-conway.pdf
  - ! 'FRACTRAN: A Simple Universal Programming Language for Arithmetic'
  - John H. Conway
  - 1987-01-01
  - 10.1007/978-1-4612-4808-8_2
  - ! '<p>To play the fraction game corresponding to a given list</p><p><em>f</em><sub>1</sub>, <em>f</em><sub>2</sub>, …, <em>f</em><sub>k</sub></p><p>of fractions and starting integer <em>N</em>, you repeatedly multiply the integer you have at any stage (initially <em>N</em>) by the earliest <em>f</em><sub>i</sub> in the list for which the answer is integral. Whenever there is no such <em>f</em><sub>i</sub>, the game <em>stops</em>.</p>'
- - http://raganwald.com/2020/05/03/fractran.html
  - "Remembering John Conway's FRACTRAN, a ridiculous, yet surprisingly deep language"
  - Reginald Braithwaite
  - 2020-05-03
  - ''
  - ! '<p>[Memorial for beloved mathematician John Horton Conway, who died in 2020 of coronavirus.</p><p>One of his many playful creations was the esoteric programming language <a href="https://en.wikipedia.org/wiki/FRACTRAN"><span class="smallcaps-auto">FRACTRAN</span></a>: a Turing-complete language implemented as simply multiplying numbers against a list repeatedly. How can this implement even the Fibonacci function, much less all computable functions, how could one come up with said implementation, and why would Conway think of this in the first place?</p><p>Braithwaite explains <span class="smallcaps-auto">FRACTRAN</span> and traces its evolution from <a href="https://en.wikipedia.org/wiki/Register_machine">Minsky machines</a>: by starting with a fairly understandable model of computation and repeatedly simplifying it to an equivalent computer, one winds up with <span class="smallcaps-auto">FRACTRAN</span>, and <span class="smallcaps-auto">FRACTRAN</span> turns out to take the same form as the famous unsolved Collatz conjecture—and since each step is Turing-complete (they are all equivalent), that means questions about functions like the Collatz conjecture involving repeated multiplication are <em>undecidable</em> (because we have shown they are all equivalent to full-blown computer programs), and so the Collatz conjecture itself may be undecidable! And that was the serious goal of the whimsical <a href="https://www.gwern.net/docs/cs/1987-conway.pdf" title="FRACTRAN: A Simple Universal Programming Language for Arithmetic">Conway 1987</a>.]</p>'
- - https://www.damninteresting.com/dead-reckoning/
  - "Dead Reckoning: The 18<sup>th</sup> century misadventures of <span class=\"smallcaps-auto\">HMS</span> <em>Wager</em> and her reluctant crew"
  - Alan Bellows (Damn Interesting)
  - 2019-09-12
  - ''
  - ! '[Narrative account of a English wreck at the tip of South America; ill-fated and ill-prepared for their mission raiding Spanish properties in the New World as part of the <a href="https://en.wikipedia.org/wiki/War_of_Jenkins%27_Ear">War of Jenkin&#39;s Ear"</a>, the crew would undergo the most brutal conditions and mutiny against their cruel incompetent captain. The survivors gradually navigated their way back to England, and the caption to Chile, eventually triggering a mutiny trial. The trial and publicity and published books offer an extremely detailed account from the survivors, and public sentiment turned against the captain and in favor of the crew, who were spared.]'
- - /docs/biology/1976-deiker.pdf
  - ! 'Sensory Reinforcement of Eyeblink Rate in a Decorticate Human'
  - Thomas Deiker, Ralph D. Bruno
  - 1976-01-01
  - ''
  - ! 'Reports an unusual case of hydranencephaly. The child survived for 19 years and showed evidence on 3 occasions of an increase in eyeblink rate with tactile reinforcement. Diagnosis was confirmed by an autopsy which revealed no preserved cortex in either hemisphere. [The subject died after the third test.]'
- - /docs/iq/1993-anderson.pdf
  - ! 'Evidence from the rat for a general factor that underlies cognitive performance and that relates to brain size: intelligence?'
  - Britt Anderson
  - 1993-01-01
  - 10.1016/0304-3940(93)90086-z
  - ! '<p>The data on a group of 22 rats, each measured for their speed of reasoning, accuracy of reasoning, response flexibility, and attention for novelty, were subjected to two different methods of factor analysis. By both methods, the correlation matrix of their performance was consistent with a single-factor model. In a second cohort of rats, where brain size was known, the score for this ‘general factor’ was computed. The regression for brain weight and the general factor was significant. [Keywords: intelligence, reasoning, rat, methylazoxymethanol, brain, mental retardation]</p>'
- - /docs/sociology/2004-jacob.pdf
  - ! 'Public Housing, Housing Vouchers, and Student Achievement: Evidence from Public Housing Demolitions in Chicago'
  - Brian A. Jacob
  - 2004-03-01
  - 10.1257/000282804322970788
  - ! '<p>This paper utilizes a plausibly exogenous source of variation in housing assistance generated by public housing demolitions in Chicago to examine the impact of high-rise public housing on student outcomes. I find that children in households affected by the demolitions do no better or worse than their peers on a wide variety of achievement measures. Because the majority of households that leave high-rise public housing in response to the demolitions move to neighborhoods and schools that closely resemble those they left, the zero effect of the demolitions may be interpreted as the independent impact of public housing.</p>'
- - /docs/genetics/selection/2019-bonner.pdf
  - ! 'The evolution of evolution'
  - John T. Bonner
  - 2019-12-01
  - 10.1002/jez.b.22859
  - ! '<p>In the past, most biologists, myself included, did not think of evolution as changing over time. The wonders of natural selection were always at hand and went into operation once there was life. However, with a little reflection it becomes obvious that evolution has changed—there has been an evolution of evolution. Evolution can be separated into four phases, or eras, that may or may not overlap. The <em>first era</em> starts with the evolution of life on earth, which led to single cells that multiply asexually. The <em>second era</em> takes advantage of the invention of sexual reproduction as evolution could now gallop forward because of a richer fare of diverse offspring for natural selection. The <em>third era</em> begins with the introduction of multicellularity. In the <em>fourth era</em> there is a radical innovation: the nervous system that arises animals by standard Darwinian selection. This has allowed major rapid changes to proceed, such as language that led to all the rapid progress we call civilization; a true revolution, and one that does not depend on the slow genetic changes of all other standard gene-controlled evolutionary steps.</p>'
- - /docs/genetics/heritable/2020-floyd.pdf
  - ! 'Heritability of affectionate communication: A twins study'
  - Kory Floyd, Chance York, Colter D. Ray
  - 2020-05-13
  - 10.1080/03637751.2020.1760327
  - ! '<p>Using a twin study design, we explored the extent to which affectionate communication is a heritable behavioral trait. Participants (<em>n</em> = 928) were 464 adult twin pairs (229 monozygotic, 235 dizygotic) who provided data on their affectionate communication behaviors. Through <span class="smallcaps-auto">ACE</span> modeling, we determined that approximately 45% of the variance in trait expressed affectionate communication is heritable, whereas 21% of the variance in trait received affection was heritable. A bivariate Cholesky decomposition model also revealed that almost 26% of the covariation in expressed and received affection is attributable to additive genetic factors. These estimates were driven primarily by females and those 50 years of age and older. The results suggest the utility of giving greater attention to genetic and biological influences on communicative behaviors by expanding the scope of communication theory beyond consideration of only environmental influences. [Keywords: affectionate communication, genetics, twin study, <span class="smallcaps-auto">ACE</span> model, heritability, affection exchange theory]</p>'
- - /docs/philo/2011-sandberg.pdf
  - ! 'Cognitive Enhancement in Courts'
  - Anders Sandberg, Walter Sinnott-Armstrong, Julian Savulescu
  - 2011-04-01
  - 10.1093/oxfordhb/9780199570706.013.0067
  - ! '<p>Human cognitive performance has crucial significance for legal process, often creating the difference between fair and unfair imprisonment. Lawyers, judges, and jurors need to follow long and complex arguments. They need to understand technical language. Jurors need to remember what happens during a long trial. The demands imposed on jurors in particular are sizeable and the cognitive challenges are discussed in this chapter. Jurors are often subjected to both tremendous decision complexity and tremendous evidence complexity. Some of these problems could be ameliorated if we can somehow enhance the cognitive capacities, including attention and memory, of various players in trials. There are multiple ways in which cognition can be improved either by external tools or by an increasing number of biomedical interventions that act directly on the brain. The article surveys a range of beneficial and detrimental effects that substances can have on cognition. [Keywords: cognitive performance, cognitive challenges, jurors, decision complexity, external tools]</p>'
- - 'https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370(20)30082-1/fulltext'
  - 'Increased weight loading reduces body weight and body fat in obese subjects—A proof of concept randomized clinical trial'
  - Claes Ohlsson, Edwin Gidestrand, Jacob Bellman, Christel Larsson, Vilborg Palsdottir, Daniel Hägg, Per-Anders Jansson, John-Olov Jansson
  - 2020-04-30
  - 10.1016/j.eclinm.2020.100338
  - ! '<h3>Background</h3><div class="section-paragraph">Recently we provided evidence for a leptin-independent homeostatic regulation, <em>the gravitostat</em>, of body weight in rodents. The aim of the present translational proof of concept study was to test the gravitostat hypothesis in humans.</div><h3>Methods</h3><div class="section-paragraph">We conducted a randomized controlled single center trial (ClinicalTrial.gov number, <span class="smallcaps-auto">NCT</span>03672903), to evaluate the efficacy of artificially increased weight loading on body weight in subjects with mild obesity (<span class="smallcaps-auto">BMI</span> 30–35 kg/m<sup>2</sup>). Subjects were either treated with a heavy (=high load; 11% of body weight) or light (=low load; 1% of body weight) weight vest for eight hours per day for three weeks. The primary outcome was change in body weight. Secondary outcomes included change in body fat mass and fat-free mass as measured using bioelectrical impedance analysis.</div><h3>Findings</h3><div class="section-paragraph">In total 72 participants underwent randomization and 69 (36 high load and 33 low load) completed the study for the primary outcome. High load treatment resulted in a more pronounced relative body weight loss compared to low load treatment (mean difference −1.37%, 95% confidence interval (CI), −1.96 to −0.79; <em>p</em> = 1.5 × 10<sup>−5</sup>). High load treatment reduced fat mass (−4.04%, 95% CI, −6,53 to −1.55; <em>p</em> = 1.9 × 10<sup>−3</sup>) but not fat free mass (0.43%, 95% CI, −1.47 to 2.34; <em>p</em> = 0.65) compared to low load treatment.</div><h3>Interpretation</h3><div class="section-paragraph"><p>Increased weight loading reduces body weight and fat mass in obese subjects in a similar way as previously shown in obese rodents. These findings demonstrate that there is weight loading dependent homeostatic regulation of body weight, the gravitostat, also in humans.</p>'
- - https://academic.oup.com/endo/article/160/5/1057/5381910
  - 'Interactions Between the Gravitostat and the Fibroblast Growth Factor System for the Regulation of Body Weight'
  - Vilborg Palsdottir, Sara H. Windahl, Daniel A Hägg, Hanna Keantar, Jakob Bellman, Andrew Buchanan, Tristan J. Vaughan, Daniel Lindén, John-Olov Jansson, Claes Ohlsson
  - 2019-03-19
  - 10.1210/en.2018-01002
  - ! '<p>Both fibroblast growth factors (<span class="smallcaps-auto">FGF</span>s), by binding to <span class="smallcaps-auto">FGF</span> receptors (<span class="smallcaps-auto">FGFR</span>s), and activation of the gravitostat, by artificial loading, decrease the body weight (BW). Previous studies demonstrate that both the <span class="smallcaps-auto">FGF</span> system and loading have the capacity to regulate BW independently of leptin. The aim of the current study was to determine the possible interactions between the effect of increased loading and the <span class="smallcaps-auto">FGF</span> system for the regulation of BW. We observed that the BW-reducing effect of increased loading was abolished in mice treated with a monoclonal antibody directed against <span class="smallcaps-auto">FGFR</span>1c, suggesting interactions between the two systems. As serum levels of endocrine <span class="smallcaps-auto">FGF</span>21 and hepatic <span class="smallcaps-auto">FGF</span>21 m<span class="smallcaps-auto">RNA</span> were increased in the loaded mice compared with the control mice, we first evaluated the loading response in <span class="smallcaps-auto">FGF</span>21 over expressing mice with constant high <span class="smallcaps-auto">FGF</span>21 levels. Leptin treatment, but not increased loading, decreased the BW in the <span class="smallcaps-auto">FGF</span>21-overexpressing mice, demonstrating that specifically the loading effect is attenuated in the presence of high activity in the <span class="smallcaps-auto">FGF</span> system. However, as <span class="smallcaps-auto">FGF</span>21 knockout mice displayed a normal loading response on BW, <span class="smallcaps-auto">FGF</span>21 is neither mediating nor essential for the loading response. In conclusion, the BW-reducing effect of increased loading but not of leptin treatment is blocked by high activity in the <span class="smallcaps-auto">FGF</span> system. We propose that both the gravitostat and the <span class="smallcaps-auto">FGF</span> system regulate BW independently of leptin and that pharmacologically enhanced activity in the <span class="smallcaps-auto">FGF</span> system reduces the sensitivity of the gravitostat.</p>'
- - https://academic.oup.com/endo/article/159/7/2676/5001726
  - The Gravitostat Regulates Fat Mass in Obese Male Mice While Leptin Regulates Fat Mass in Lean Male Mice
  - Claes Ohlsson, Daniel A. Hägg, Fredrik Hammarhjelm, Adrià Dalmau Gasull, Jakob Bellman, Sara H. Windahl, Vilborg Palsdottir, John-Olov Jansson
  - 2018-05-23
  - 10.1210/en.2018-00307
  - ! '<p>Leptin has been the only known homeostatic regulator of fat mass, but we recently found evidence for a second one, named the gravitostat. In the current study, we compared the effects of leptin and increased loading (gravitostat stimulation) on fat mass in mice with different levels of body weight (lean, overweight, and obese). Leptin infusion suppressed body weight and fat mass in lean mice given normal chow but not in overweight or obese mice given a high-fat diet for 4 and 8 weeks, respectively. The maximum effect of leptin on body weight and fat mass was obtained already at &lt;44 ng/mL of serum leptin. Increased loading using intraperitoneal capsules with different weights decreased body weight in overweight and obese mice. Although the implantation of an empty capsule reduced the body weight in lean mice, only a nonsignificant tendency of a specific effect of increased loading was observed in the lean mice. These findings demonstrate that the gravitostat regulates fat mass in obese mice, whereas leptin regulates fat mass only in lean mice with low endogenous serum leptin levels. We propose that activation of the gravitostat primarily protects against obesity, whereas low levels of leptin protect against undernutrition.</p>'
- - https://www.pnas.org/content/115/2/427/
  - "Body weight homeostat that regulates fat mass independently of leptin in rats and mice"
  - John-Olov Jansson, Vilborg Palsdottir, Daniel A. Hägg, Erik Schéle, Suzanne L. Dickson, Fredrik Anesten, Tina Bake, Mikael Montelius, Jakob Bellman, Maria E. Johansson, Roger D. Cone, Daniel J. Drucker, Jianyao Wu, Biljana Aleksic, Anna E. Törnqvist, Klara Sjögren, Jan-Åke Gustafsson, Sara H. Windahl, Claes Ohlsson
  - 2018-01-09
  - 10.1073/pnas.1715687114
  - ! '<p><strong>Significance</strong>: The only known homeostatic regulator of fat mass is the leptin system. We hypothesized that there is a second homeostat regulating body weight with an impact on fat mass. In this study we have added and removed weight loads from experimental animals and measured the effects on the biological body weight. The results demonstrate that there is a body weight homeostat that regulates fat mass independently of leptin. As the body weight-reducing effect of increased loading was dependent on osteocytes, we propose that there is a sensor for body weight in the long bones of the lower extremities acting as “body scales.” This is part of a body weight homeostat, “gravitostat,” that keeps body weight and body fat mass constant.</p><p><strong>Abstract</strong>: Subjects spending much time sitting have increased risk of obesity but the mechanism for the antiobesity effect of standing is unknown. We hypothesized that there is a homeostatic regulation of body weight. We demonstrate that increased loading of rodents, achieved using capsules with different weights implanted in the abdomen or s.c. on the back, reversibly decreases the biological body weight via reduced food intake. Importantly, loading relieves diet-induced obesity and improves glucose tolerance. The identified homeostat for body weight regulates body fat mass independently of fat-derived leptin, revealing two independent negative feedback systems for fat mass regulation. It is known that osteocytes can sense changes in bone strain. In this study, the body weight-reducing effect of increased loading was lost in mice depleted of osteocytes. We propose that increased body weight activates a sensor dependent on osteocytes of the weight-bearing bones. This induces an afferent signal, which reduces body weight. These findings demonstrate a leptin-independent body weight homeostat (“gravitostat”) that regulates fat mass. [Keywords: diet-induced obesity, weight loss, osteocytes, glucose metabolism]</p>'
- - https://www.pnas.org/content/pnas/115/7/E1335.full.pdf
  - 'Where does the gravitostat fit in?'
  - Claes Ohlssona, John-Olov Jansson
  - 2018-02-13
  - 10.1073/pnas.1800116115
  - ! '[Rebuttal letter: the gravitostat is supported by hypergravity; astronaut microgravity experiments are only weak counterevidence because microgravity and space travel badly damages health in many ways, hiding any potential weight gain. The gravitostat may fit in the two-systems model of weight, in which case a testable prediction is that it should have different effects in rodents with different weight/leptin combinations.]'
- - /docs/technology/2018-nilsson.pdf
  - ! '15 Years of Research on Redirected Walking in Immersive Virtual Environments'
  - Niels Christian Nilsson, Tabitha Peck, Gerd Bruder, Eri Hodgson, Ohio), Stefania Serafin, Mary Whitton, Frank Steinicke, Evan Suma Rosenberg
  - 2018-01-12
  - 10.1109/MCG.2018.111125628
  - ! '<p>Virtual reality users wearing head-mounted displays can experience the illusion of walking in any direction for infinite distance while, in reality, they are walking a curvilinear path in physical space. This is accomplished by introducing unnoticeable rotations to the virtual environment—a technique called <em>redirected walking</em>. This paper gives an overview of the research that has been performed since redirected walking was first practically demonstrated 15 years ago.</p>'
- - /docs/technology/2007-markandya.pdf
  - ! 'Electricity generation and health'
  - Anil Markandya, Paul Wilkinson
  - 2007-09-01
  - 10.1016/S0140-6736(07)61253-7
  - ! '<p>The provision of electricity has been a great benefit to society, particularly in health terms, but it also carries health costs. Comparison of different forms of commercial power generation by use of the fuel cycle methods developed in European studies shows the health burdens to be greatest for power stations that most pollute outdoor air (those based on lignite, coal, and oil). The health burdens are appreciably smaller for generation from natural gas, and lower still for nuclear power. This same ranking also applies in terms of greenhouse-gas emissions and thus, potentially, to long-term health, social, and economic effects arising from climate change. Nuclear power remains controversial, however, because of public concern about storage of nuclear waste, the potential for catastrophic accident or terrorist attack, and the diversion of fissionable material for weapons production. Health risks are smaller for nuclear fusion, but commercial exploitation will not be achieved in time to help the crucial near-term reduction in greenhouse-gas emissions. The negative effects on health of electricity generation from renewable sources have not been assessed as fully as those from conventional sources, but for solar, wind, and wave power, such effects seem to be small; those of biofuels depend on the type of fuel and the mode of combustion. Carbon dioxide (CO<sub>2</sub>) capture and storage is increasingly being considered for reduction of CO<sub>2</sub> emissions from fossil fuel plants, but the health effects associated with this technology are largely unquantified and probably mixed: efficiency losses mean greater consumption of the primary fuel and accompanying increases in some waste products. This paper reviews the state of knowledge regarding the health effects of different methods of generating electricity.</p>'
- - /docs/cs/2009-narayanan.pdf
  - ! 'De-anonymizing Social Networks'
  - Arvind Narayanan, Vitaly Shmatikov
  - 2009-05-17
  - 10.1109/SP.2009.22
  - ! '<p>Operators of online social networks are increasingly sharing potentially sensitive information about users and their relationships with advertisers, application developers, and data-mining researchers. Privacy is typically protected by anonymization, i.e., removing names, addresses, etc.</p><p>We present a framework for analyzing privacy and anonymity in social networks and develop a new re-identification algorithm targeting anonymized social-network graphs. To demonstrate its effectiveness on real-world networks, we show that a third of the users who can be verified to have accounts on both Twitter, a popular microblogging service, and Flickr, an online photo-sharing site, can be re-identified in the anonymous Twitter graph with only a 12% error rate.</p><p>Our de-anonymization algorithm is based purely on the network topology, does not require creation of a large number of dummy “sybil” nodes, is robust to noise and all existing defenses, and works even when the overlap between the target network and the adversary’s auxiliary information is small.</p>'
- - /docs/science/2012-borghi.pdf
  - ! 'On the tumbling toast problem'
  - Riccardo Borghi
  - 2012-08-01
  - 10.1088/0143-0807/33/5/1407
  - ! '<p>A didactical revisitation of the so-called tumbling toast problem is presented here. The numerical solution of the related Newton’s equations has been found in the space domain, without resorting to the complete time-based law of motion, with a considerable reduction of the mathematical complexity of the problem. This could allow the effect of the different physical mechanisms ruling the overall dynamics to be appreciated in a more transparent way, even by undergraduates. Moreover, the availability from the literature of experimental investigations carried out on tumbling toast allows us to propose different theoretical models of growing complexity in order to show the corresponding improvement of the agreement between theory and observation.</p>'
- - /docs/science/1980-press.pdf
  - ! 'Man’s size in terms of fundamental constants'
  - William H. Press
  - 1980-01-01
  - 10.1119/1.12326
  - ! '<p>Why are we the size we are, instead of some very different size? Simple physical scaling laws and three “requirements” dictate that our size be of order (h/<sup>2</sup>/<i>m</i><sub><i>e</i></sub><i>e</i><sup>2</sup>)(<i>e</i><sup>2</sup>/<i>G</i><i>m</i><sub><i>p</i></sub> <sup>2</sup>)<sup>1/4</sup>. They also “predict” the mass and radius of the Earth. The three requirements are: (i) We are made of complicated molecules; (ii) we breathe an evolved planetary atmosphere; (iii) we are about as big as we can be without breaking.</p>'
- - /docs/science/1995-matthews.pdf
  - ! "Tumbling toast, Murphy's Law and the fundamental constants"
  - Robert A. J. Matthews
  - 1995-07-18
  - 10.1088/0143-0807/16/4/005
  - ! '<p>We investigate the dynamics of toast tumbling from a table to the floor. Popular opinion is that the final state is usually butter-side down, and constitutes <em>prima facie</em> evidence of Murphy’s Law (‘If it can go wrong, it will’). The orthodox view, in contrast, is that the phenomenon is essentially random, with a 50/50 split of possible outcomes. We show that toast does indeed have an inherent tendency to land butter-side down for a wide range of conditions. Furthermore, we show that this outcome is ultimately ascribable to the values of the fundamental constants. As such, this manifestation of Murphy’s Law appears to be an ineluctable feature of our universe.</p>'
- - /docs/science/2001-bacon.pdf
  - ! 'A closer look at tumbling toast'
  - M. E. Bacon, George Heald, Matt James
  - 2001-01-01
  - 10.1119/1.1289213
  - ! '<p>The study of the mechanics of tumbling toast provides an informative and entertaining project for undergraduates. The relatively recent introduction of software packages to facilitate the analysis of video recordings, and the numerical solution of complex differential equations, makes such a study an attractive candidate for inclusion in an experimental physics course at the undergraduate level. In the study reported here it is found that the experimentally determined free fall angular velocity of a board, tumbling off the edge of a table, can only be predicted at all accurately if slipping is taken into account. The size and shape of the board used in the calculations and in the experiments were roughly the same as that of a piece of toast. In addition, it is found that the board, tumbling from a standard table of height 76 cm, will land butter-side down (neglecting any bounce) for two ranges of overhang (δ<sub>0</sub>). δ<sub>0</sub> is defined as the initial distance from the table edge to a vertical line drawn through the center of mass when the board is horizontal. For our board (length 10.2 cm) the approximate ranges of overhang are 0–0.8 and 2.7–5.1 cm. The importance of the 0–0.8 cm (only 2% of all possible overhangs for which tumbling is possible) favoring a butter-side down landing should not be underestimated when pondering the widely held belief that toast, tumbling from a table, usually falls butter-side down.</p>'
- - /docs/statistics/bias/1997-matthews.pdf
  - ! 'The Science of Murphy’s Law: Life’s little annoyances are not as random as they seem: the awful truth is that the universe is against you'
  - Robert A. J. Matthews
  - 1997-04-01
  - 10.2307/24993707
  - ! '<p>[Popularization of Matthews’s other articles on physics &amp; statistics and what truth there is to <a href="https://en.wikipedia.org/wiki/Murphy%27s_law">“Murphy’s law”</a>:</p><ul><li><p><em>Toast</em> falling butter side up: true, because tables are not high enough for toast to be likely to complete one or more rotations before landing given the tilt &amp; falling off edges, therefore toast will in fact tend to land on its top half.</p></li><li><p><em>Maps</em> putting things on edges: true—printed paper maps tend to be hard to use because the place one wants to go will tend to be toward an edge; this is simply a geometric fact due to most of the area of a volume being towards the edge.</p></li><li><p><em>Other Checkout Lines Being Faster</em>: true, because of anthropics, as most waiting time is spent in the slowest line; even if equally loaded, order statistics points out there is only a 1 in <em>n</em> chance that one picked the fastest line out of <em>n</em> lanes</p></li><li><p><em>Mismatched Socks</em>: also true, simply because there are many more ways for socks in a pair to go missing than to go missing in pairs or match up</p></li><li><p><em>Raining</em>: forecasts are fairly accurate, but this ignores base-rates and that much of that accuracy is due to predicting <em>non</em>-rain. It’s a version of the diagnostics/screening paradox:</p><blockquote><p>For example, suppose that the hourly base rate of rain is 0.1, meaning that it is 10 times more likely not to rain during your hour-long stroll. Probability theory then shows that even an 80% accurate forecast of rain is twice as likely to prove wrong as right during your walk—and you’ll end up taking an umbrella unnecessarily. The fact is that even today’s apparently highly accurate forecasts are still not good enough to predict rare events reliably.</p></blockquote></li></ul><p>Keywords: socks, maps, umbrellas, family law, combinatorics, weather forecasting, technology law, mathematical constants, physics, probability theory]</p>'
- - /docs/iq/2018-rindermann-2.pdf
  - ! 'Parents’ Education Is More Important Than Their Wealth in Shaping Their Children’s Intelligence: Results of 19 Samples in Seven Countries at Different Developmental Levels'
  - Heiner Rindermann, Stephen J. Ceci
  - 2018-09-26
  - 10.1177/0162353218799481
  - ! '<p>In 19 (sub)samples from seven countries (United States, Austria, Germany, Costa Rica, Ecuador, Vietnam, Brazil), we analyzed the impact of parental education compared with wealth on the cognitive ability of children (aged 4–22 years, total <i>n</i> = 15,297). The background of their families ranged from poor indigenous remote villagers to academic families in developed countries, including parents of the gifted. Children’s cognitive ability was measured with mental speed tests, Culture Fair Intelligence Test (<span class="smallcaps-auto">CFT</span>), the Raven’s, Wiener Entwicklungstest (<span class="smallcaps-auto">WET</span>), Cognitive Abilities Test (CogAT), Piagetian tasks, Armed Forces Qualification Test (<span class="smallcaps-auto">AFQT</span>), Progress in International Reading Literacy Study (<span class="smallcaps-auto">PIRLS</span>), Trends in International Mathematics and Science Study (<span class="smallcaps-auto">TIMSS</span>), and Programme for International Student Assessment (<span class="smallcaps-auto">PISA</span>). Parental wealth was estimated by asking for income, indirectly by self-assessment of relative wealth, and by evaluating assets. The mean direct effect of parental education was greater than wealth. In path analyses, parental education (<i>β</i><sub>Ed</sub>) also showed a stronger impact on children’s intelligence than familial economic status (<i>β</i><sub>In</sub>, total effect averages: <i>β</i><sub>Ed</sub> = .30–.45, <i>β</i><sub>In</sub> = .09–.12; <i>N</i> = 15,125, <i>k</i> = 18). The effects on mental speed were smaller than for crystallized intelligence, but still larger for parental education than familial economic status (<i>β</i><sub>Ed→MS</sub> = .25, <i>β</i><sub>In→MS</sub> = .00, <i>β</i><sub>Ed→CI</sub> = .36, <i>β</i><sub>In→CI</sub> = .09; <i>N</i> = 394, <i>k</i> = 3). Additional factors affecting children’s cognitive ability are number of books, marital status, educational behavior of parents, and behavior of children. If added, a general background (ethnicity, migration) factor shows strong effects (<i>β</i><sub>Bg</sub> = .30–.36). These findings are discussed in terms of environmental versus hidden genetic effects. [Keywords: cognitive competence, intelligence development, fluid and crystallized intelligence, <span class="smallcaps-auto">SES</span>, number of books, marital status, smoking]</p>'
- - /docs/genetics/selection/2020-winegard.pdf
  - ! 'Coalitional Value Theory: an Evolutionary Approach to Understanding Culture'
  - Bo Winegard, Amanda Kirsch, Andrew Vonasch, Ben Winegard, David C. Geary
  - 2020-05-08
  - 10.1007/s40806-020-00235-z
  - ! '<p>In the following article, we forward the coalitional value theory (<span class="smallcaps-auto">CVT</span>) and apply it to several puzzles about human behavior. The <span class="smallcaps-auto">CVT</span> contends that humans evolved unique mental mechanisms for assessing each other’s marginal value to a coalition (i.e., each other’s coalitional value). They defer to those with higher coalitional value, and they assert themselves over those with lower. We discuss how this mechanism likely evolved. We note that it helps explains how human groups can expand into large, complicated, and specialized coalitions (chiefdoms and even nation states). And we combine this with strong evidence that suggests that status striving is a fundamental human motive to explain partially (1) anti-gay bias, (2) cultural signaling, (3) cultural conceptions of god, and (4) ideological conflict.</p>'
- - /docs/economics/1968-schroeder.pdf
  - ! 'Soviet Reality Sans Potemkin: The amenities of Moscow from the native point of view'
  - Gertrude Schroeder
  - '1968'
  - ''
  - ! '<p><em>Dormin summary</em>: [The link is to a declassified <span class="smallcaps-auto">CIA</span> document written in 1968….The author is a <span class="smallcaps-auto">CIA</span> spy who explains that the <span class="smallcaps-auto">CIA</span> was trying to calculate the economy of the <span class="smallcaps-auto">USSR</span>, and by their best estimates, the US <span class="smallcaps-auto">GDP</span> was more than 2× the <span class="smallcaps-auto">USSR</span> <span class="smallcaps-auto">GDP</span>, and the US <span class="smallcaps-auto">GDP</span> per capita was around 3×. However, she thinks these numbers are overestimating <span class="smallcaps-auto">USSR</span> <span class="smallcaps-auto">GDP</span> because it’s difficult to account for quality. An American haircut can be priced the same way as a Soviet haircut, but an American refrigerator is probably vastly better than a Soviet refrigerator.</p><p>So the author goes undercover in Moscow for a few months to live as the Russians do and see what economic life is really like for them. She explains that she tried to live the Russian way as an American working at the embassy, but the locals were <em>super</em> nice to her all the time. They always smiled and sent her to the front of every line. So she had to get beat up local clothes, dust off her Russian language skills, put on a grumpy expression (presumably), and pretend to be a Russian (or rather, pretend to be an Estonian due to her accent). Her findings:</p><ul><li>Lines, lines, and more lines. Everyone had to wait on line for everything. Food, clothes, whatever. Wait times were 10–15 minutes at best, but could easily stretch into hours. Sometimes she waited on lines even when she didn’t know what she was waiting for.</li><li>Even in Moscow, the variety and quality of goods was atrocious. At a given grocer, they might offer two or three different items each day. So one day she could get pickled fish, the next day cabbage and tomatoes, the next day rice, etc. Bread seemed to be the only thing that was always in stock.</li><li>Stores were often bureaucratic clusterfucks. The author couldn’t just buy tea; she had to wait on one line to make a tea selection, then collect a piece of paper, then wait on another line to exchange the paper for money, then get another piece of paper, then wait on another line to exchange that piece of paper for tea.</li><li>Prices were outrageous by the standards of the salaries of the people working in the capital city of the second most powerful nation on earth.</li><li>The service was awful. She went to some of the nicest restaurants in Moscow (of which there were fewer than a dozen in a city of millions of people), and the meals would take at least three hours. Waiters would stand around doing nothing and wouldn’t come over to her even when she called them.</li><li>Everyone was incredibly rude. She was violently shoved on trains and buses. People screamed at her if she hesitated on lines.</li><li>There was a general feeling of boredom and malaise. There were no luxury goods to buy or events to look forward to. People expected to just live, get married, and wait to die.</li><li>Everyone knew the government reports about how awesome the <span class="smallcaps-auto">USSR</span> was doing were bullshit. They envied the West.]</li></ul>'
- - /docs/iq/1977-jensen-4.pdf
  - ! 'An examination of culture bias in the Wonderlic personnel test'
  - Arthur R. Jensen
  - 1977-01-01
  - 10.1016/0160-2896(77)90026-5
  - ! '<p>Internal evidence of cultural bias, in terms of various types of item analysis, was sought in the Wonderlic Personnel Test results in large, representative samples of Whites and Blacks totaling some 1,500 subjects. Essentially, the lack of any appreciable Race × Items interaction and the high interracial similarity in rank order of item difficulties lead to the conclusion that the Wonderlic shows very little evidence of cultural bias with respect to the present samples which, however, differ appreciably in mean scores. The items which account for the most variance within each racial group are, by and large, the same items that show the largest interracial discrimination.</p>'
- - /docs/sr/2020-jeziorowski.pdf
  - ! 'Towards Image-Based Dark Vendor Profiling: An Analysis of Image Metadata and Image Hashing in Dark Web Marketplaces'
  - Susan Jeziorowski, Muhammad Ismail, Ambareen Siraj
  - 2020-03-01
  - 10.1145/3375708.3380311
  - ! '<p>Anonymity networks, such as Tor, facilitate the hosting of hidden online marketplaces where <em>dark vendors</em> are able to anonymously trade paraphernalia such as drugs, weapons, and hacking services. Effective dark marketplace analysis and dark vendor profiling techniques support dark web investigations and help to identify and locate these perpetrators. Existing automated techniques are text-based, leaving non-textual artifacts, such as images, out of consideration. Though image data can further improve investigative analysis, there are two primary challenges associated with dark web image analysis: (a) ethical concerns over the presence of child exploitation imagery in illegal markets, and (b) the computational overhead needed to download, analyze, and store image content. In this research, we investigate and address the aforementioned challenges to enable dark marketplace image analysis. Namely, we examine image metadata and explore several image hashing techniques to represent image content, allowing us to collect image-based intelligence and identify reused images among dark marketplaces while preventing exposure to illegal content and decreasing computational overhead. Our study reveals that approximately 75% of dark marketplace listings include image data, indicating the importance of considering image content for investigative analysis. Additionally, 2% of considered images were found to contain metadata and approximately 50% of image hashes were repeated among marketplace listings, suggesting the presence of easily obtainable incriminating evidence and frequency of image reuse among dark vendors. Finally, through an image hash analysis, we demonstrate the effectiveness of using image hashing to identify similar images between dark marketplaces.</p>'
- - /docs/terrorism/2009-jones.pdf
  - ! 'Hit or Miss? The Effect of Assassinations on Institutions and War'
  - Benjamin F. Jones, Benjamin A. Olken
  - 2009-07-01
  - 10.1257/mac.1.2.55
  - ! '<p>Assassinations are a persistent feature of the political landscape. Using a new dataset of assassination attempts on all world leaders from 1875 to 2004, we exploit inherent randomness in the success or failure of assassination attempts to identify the effects of assassination. We find that, on average, successful assassinations of autocrats produce sustained moves toward democracy. We also find that assassinations affect the intensity of small-scale conflicts. The results document a contemporary source of institutional change, inform theories of conflict, and show that small sources of randomness can have a pronounced effect on history.</p><p>…To implement this approach, we collected data on all publicly-reported assassination attempts for all national leaders since 1875. This produced 298 assassination attempts, of which 59 resulted in the leader’s death. We show that, conditional on an attempt taking place, whether the attack succeeds or fails in killing the leader appears uncorrelated with observable economic and political features of the national environment, suggesting that our basic identification strategy may be plausible.</p><p>We find that assassinations of autocrats produce substantial changes in the country’s institutions, while assassinations of democrats do not. In particular, transitions to democracy, as measured using the Polity IV dataset (Marshall and Jaggers 2004), are 13% more likely following the assassination of an autocrat than following a failed attempt on an autocrat. Similarly, using data on leadership transitions from the Archigos dataset (Goemans et al., 2006), we find that the probability that subsequent leadership transitions occur through institutional means is 19% higher following the assassination of an autocrat than following the failed assassination of an autocrat. The effects on institutions extend over [long] periods, with evidence that the impacts are sustained at least 10 years later.</p>'
- - https://www.rand.org/content/dam/rand/pubs/research_reports/RR4400/RR4418/RAND_RR4418.pdf
  - "Exploring the use of Zcash cryptocurrency for illicit or criminal purposes"
  - Erik Silfversten, Marina Favaro, Linda Slapakova, Sascha Ishikawa, James Liu, Adrian Salas (<span class=\"smallcaps-auto\">RAND</span> Europe)
  - 2020-05-06
  - 10.7249/RR4418
  - ! '<p>Cryptocurrencies have been recognised as a promising financial innovation, offering security and privacy benefits for users. While these digital currencies are mostly used for legitimate purposes, they could also be exploited for criminal or illicit activities. However, there is currently a lack of understanding regarding if and how cryptocurrencies are actually used for illicit or criminal purposes. To balance the potential risks of novel cryptocurrencies with their benefits, more evidence is needed in this area. To help inform public debate and decision making on this issue, <span class="smallcaps-auto">RAND</span> Europe explored the uses of cryptocurrencies for illicit or criminal purposes, focusing on <a href="https://en.wikipedia.org/wiki/Zcash">Zcash</a>. Commissioned by the Electric Coin Company, who developed and maintain Zcash, this study offers new insights for law enforcement professionals, policymakers, regulators and others interested in cryptocurrencies.</p><p><strong>Key Findings</strong>: While most transactions made with virtual coins are legitimate, cryptocurrencies are also used for a wide range of illicit or criminal purposes by a diverse group of malicious actors. The three most prominent illicit use-cases of cryptocurrencies are:</p><ul><li>Money laundering</li><li>Trade in illicit goods and services</li><li>Terrorism financing</li></ul><p>Cryptocurrencies were found to have varying levels of illicit use. In relation to the extent Zcash is used for illicit or criminal purposes (i.e. the scope, scale and nature of this phenomenon), several key findings were produced:</p><ul><li>Zcash is relatively unknown in the academic research community, and the links between Zcash and illicit or criminal activities have not been substantially researched.</li><li>This study found no evidence of widespread illicit use of Zcash, however vigilance against its malicious use is still important.</li><li>Zcash has only a minor presence on the dark web, indicating that Zcash is seen as a less attractive option to dark web users and is used less often compared to other cryptocurrencies, particularly Bitcoin and Monero.</li><li>Users engaged in illicit activities may not fully understand the Zcash operating model. They may also not understand the value in Zcash’s privacy-preserving features, or else are not aware of or confident in them.</li><li>Bitcoin is still perceived to be the dominant cryptocurrency for illicit or criminal activities on the dark web, despite the creation of several more privacy-focused cryptocurrencies.</li></ul><p><strong>Table of Contents</strong>: 1. Introduction · 2. The illicit use of cryptocurrencies · 3. The use of Zcash for criminal or illicit purposes · 4. Factors that may influence the future use of Zcash for illicit purposes · 5. Appendix A: Methodology · 6. Appendix B: List of interviewees</p>'
- - /docs/genetics/selection/1998-ebert.pdf
  - ! 'Experimental Evolution of Parasites'
  - Dieter Ebert
  - 1998-11-20
  - 10.1126/science.282.5393.1432
  - ! '<p>Serial passage experiments are a form of experimental evolution that is frequently used in applied sciences; for example, in vaccine development. During these experiments, molecular and phenotypic evolution can be monitored in real time, providing insights into the causes and consequences of parasite evolution. Within-host competition generally drives an increase in a parasite’s virulence in a new host, whereas the parasite becomes avirulent to its former host, indicating a trade-off between parasite fitnesses on different hosts. Understanding why parasite virulence seldom escalates similarly in natural populations could help us to manage virulence and deal with emerging diseases.</p>'
- - /docs/genetics/selection/1973-sabin.pdf
  - ! 'History of Sabin attenuated poliovirus oral live vaccine strains'
  - A. B. Sabin, L. R. Boulger
  - 1973-01-01
  - 10.1016/0092-1157(73)90048-6
  - ! '<p>The full data concerning the history of attenuated poliovirus strains developed by one of us (Sabin, 1965) for vaccine production do not appear in a single journal. Over the past few years we have had frequent requests for the details such as isolation and attenuation and accordingly we felt that bringing the data together in the report below would be both helpful and informative to those involved in the production and control of poliovirus vaccine (oral) prepared from these strains.</p>'
- - /docs/genetics/selection/1936-jama.pdf
  - ! 'Experimental Epidemiology'
  - <span class=\"smallcaps-auto\">JAMA</span> editors
  - 1936-12-01
  - 10.1001/jama.1936.02770500037013
  - ! '<p>The study of experimental epidemics recently reported by <a href="https://www.gwern.net/docs/genetics/selection/1936-greenwood-experimentalepidemiology.pdf">Greenwood, Hill, Topley and Wilson<sup>1</sup></a> involves observations extending over some fifteen years and the use of between 100,000 and 200,000 mice. Their methods were adequately controlled and ably presented. In fact, so carefully was their technic developed that it usually proved possible to maintain herds of mice for months or years without the accidental introduction of any extraneous infection.</p><p>In one series of observations, six different epidemics of <a href="https://en.wikipedia.org/wiki/Pasteurellosis">pasteurellosis</a> were under simultaneous observation. In the long continued epidemics under these experimental conditions, no tendency for periods of high or low mortality to recur at definite seasons of the year was noted. Uncontaminated animals were introduced to many of their herds of infected mice at stated intervals. The great majority of such mice were infected shortly after entrance, so that the reacting system at any moment contained a relatively small proportion of animals presenting a virgin soil. After the first wave of disease and death that always follows the aggregation of an infected herd, the epidemics settled into a state of unstable equilibrium. With a small number of daily uninfected immigrants, the mortality curves tended to show relatively wide and relatively regular fluctuations.</p>'
- - /docs/genetics/selection/1936-greenwood-experimentalepidemiology.pdf
  - ! '<em>Experimental Epidemiology</em>'
  - M. Greenwood, A. Bradford Hill, W. W. C. Topley, J. Wilson
  - 1936-01-01
  - ''
  - ! '<p>The studies outlined in the report above have been in progress for some 15 years and they form an attempt to place the science of epidemiology on an experimental basis. They are laborious and costly and the authors justify both the labour and the expense involved in the introduction. Although it is well known that animal hosts and their microbial parasites vary in resistance and infectivity respectively, and that many other factors play their part in the form which an epidemic disease takes, when all the odd pieces of knowledge are added together the answer is only a working hypothesis and not a conclusion. In other words, the many questions regarding epidemics can only be answered by finding out actually what happens in an infected herd, not by deducing what might happen from knowledge of what occurs in individual hosts. The herd must be the universe of study.</p><p>The experiments on which the report is based have involved the use of between 100,000 and 200,000 mice, and a brief outline of the general methods of experiment are given. It has been possible to maintain herds for months or years infected with bacterial parasites such as <a href="https://en.wikipedia.org/wiki/Salmonella_enterica_subsp._enterica"><em>Salmonella typhimurium</em></a> and <a href="https://en.wikipedia.org/wiki/Pasteurellosis"><em>Pasteurella muriseptica</em></a> without any cross-infection and to watch the effect of various methods of interference on the spread of infection. Experiments have also been made with herds infected with the virus disease <a href="https://en.wikipedia.org/wiki/Ectromelia_virus"><em>ectromelia</em></a>.</p><p>From statistical analyses of the results, it is concluded that in herds of mice living in close and continuous contact and subject to the continuous or intermittent immigration of susceptibles, the disease will never normally die out. It might happen that the disease would become extinct but such an event would be a mere accident of small numbers. The form of the mortality curve depends mainly upon the rate of immigration and the equilibrium between hosts and parasites is fundamentally unstable and, when disturbed, the system tends to pass through a period of violent fluctuations before equilibrium is again established. The average resistance of surviving mice increases with survival in the herd but never becomes absolute. The great majority eventually succumb to the reigning disease.</p><p>Selection, both by death of the more susceptible, and by natural immunization, plays a part in the increased resistance displayed by surviving mice, and the latter is probably the more important. An infected herd is a highly complex system, consisting of mice suffering from a fatal infection, others in a state of infection-equilibrium that ends in death or recovery at some later period, others undergoing natural immunization by an infection of slighter degree, and a small minority not yet infected. The differences in the form which epidemics display are due to the state of equilibrium established in this complex system, which may be shifting or temporarily stabilized.</p><p>The level of mortality in a herd, the proportion of immunizing to fatal infections, and the degree to which infection occurs, are largely determined by the characters of the bacterial strain with which the epidemic is initiated. It is considered that virulence and infectivity may vary, a highly potent "epidemic" strain possessing both these characters.</p><p>Apart from changes in the conditions of contact, the only significant method of interfering with the normal course of events in the infected herds is artificial immunization. It has not, however, under the conditions of these experiments, approached the successes recorded from the field. As with natural immunization, so artificial immunization has appeared to be more effective against the virus disease (<em>ectromelia</em>) than against the bacterial disease (mouse typhoid). In no case, however, is the immunity attained complete, the immunized mice eventually dying from the prevailing disease. Infection of immunized animals is common and in <em>ectromelia</em>, and probably in the bacterial diseases, many of the immunized and infected mice are infective for normal animals. It is, therefore, unlikely that, even if it were possible to devise a method of immunization more effective in lowering mortality than those employed by the authors, infection could be eliminated from the herds and so render safe the admission of susceptible immigrants.</p><p>As stated in the preface: “the experimental epidemic affords a more natural, and more severe, method of testing the value of any prophylactic procedure than assays carried out by more artificial tests on individual animals. It can never, of course, replace field observations made under completely natural conditions; but it may well indicate possible solutions to many of the more important practical problems, and so direct the field epidemiologist along the most fruitful lines of inquiry.”</p>'
- - /docs/genetics/selection/1982-anderson.pdf
  - ! 'Coevolution of hosts and parasites'
  - R. M. Anderson, R. M. May
  - '1982'
  - 10.1017/s0031182000055360
  - ! '<p>The present paper aims to take a line that is somewhat more empirical than most of the previous theoretical work. Defining parasites broadly to include viruses, bacteria, protozoans and helminths, we observe that the virulence of a parasite (the rate at which it induces host mortality) is usually coupled with the transmission rate and with the time taken to recover by those hosts for whom the infection is not lethal. Specifically, in mice, men and other vertebrates (Fenner &amp; Ratcliffe, 1965; Burnet &amp; White, 1972) and in many invertebrates (Maramorosch &amp; Shope, 1975; Anderson &amp; May, 1981) low virulence is generally associated with effective immunological or non-specific responses which tend to suppress pathogen replication, with a concomitant reduction in transmissibility. Using data for the epidemiological parameters characterizing the various grades of <a href="https://en.wikipedia.org/wiki/Myxoma_virus">myxoma virus</a> <a href="https://en.wikipedia.org/wiki/Myxomatosis">infecting rabbits in Australia</a>, we show how in this particular case virulence maybe expected to evolve to an intermediate value; the analysis appears to accord with the observed facts. Other examples are discussed in a more qualitative way. <em>In general, we conclude that the complicated interplay between virulence and transmissibility of parasites leaves room for many coevolutionary paths to be followed,with many endpoints.</em></p>'
- - /docs/genetics/correlation/2020-bryne.pdf
  - ! 'Conditional GWAS analysis to identify disorder-specific SNPs for psychiatric disorders'
  - Enda M. Byrne, Zhihong Zhu, Ting Qi, Nathan G. Skene, Julien Bryois, Antonio F. Pardinas, Eli Stahl, Jordan W. Smoller, Marcella Rietschel, Michael J. Owen, James T. R. Walters, Michael C. O’Donovan, John G. McGrath, Jens Hjerling-Leffler, Patrick F. Sullivan, Michael E. Goddard, Peter M. Visscher, Jian Yang, Naomi R. Wray
  - 2020-05-12
  - 10.1038/s41380-020-0705-9
  - ! '<p>Substantial genetic liability is shared across psychiatric disorders but less is known about risk variants that are specific to a given disorder. We used multi-trait conditional and joint analysis (mt<span class="smallcaps-auto">COJO</span>) to adjust <span class="smallcaps-auto">GWAS</span> summary statistics of one disorder for the effects of genetically correlated traits to identify putative disorder-specific <span class="smallcaps-auto">SNP</span> associations. We applied mt<span class="smallcaps-auto">COJO</span> to summary statistics for five psychiatric disorders from the Psychiatric Genomics Consortium—schizophrenia (<span class="smallcaps-auto">SCZ</span>), bipolar disorder (<span class="smallcaps-auto">BIP</span>), major depression (MD), attention-deficit hyperactivity disorder (<span class="smallcaps-auto">ADHD</span>) and autism (<span class="smallcaps-auto">AUT</span>). Most genome-wide significant variants for these disorders had evidence of pleiotropy (i.e., impact on multiple psychiatric disorders) and hence have reduced mt<span class="smallcaps-auto">COJO</span> conditional effect sizes. However, subsets of genome-wide significant variants had larger conditional effect sizes consistent with disorder-specific effects: 15 of 130 genome-wide significant variants for schizophrenia, 5 of 40 for major depression, 3 of 11 for <span class="smallcaps-auto">ADHD</span> and 1 of 2 for autism. We show that decreased expression of <i><span class="smallcaps-auto">VPS</span>29</i> in the brain may increase risk to <span class="smallcaps-auto">SCZ</span> only and increased expression of <i><span class="smallcaps-auto">CSE</span>1L</i> is associated with <span class="smallcaps-auto">SCZ</span> and MD, but not with <span class="smallcaps-auto">BIP</span>. Likewise, decreased expression of <i><span class="smallcaps-auto">PCDHA</span>7</i> in the brain is linked to increased risk of MD but decreased risk of <span class="smallcaps-auto">SCZ</span> and <span class="smallcaps-auto">BIP</span>.</p>'
- - /docs/genetics/selection/1979-anderson.pdf
  - ! 'Population biology of infectious diseases: Part I'
  - Roy M. Anderson, Robert M. May
  - 1979-08-01
  - 10.1038/280361a0
  - ! '<p>If the host population is taken to be a dynamic variable (rather than constant, as conventionally assumed), a wider understanding of the population biology of infectious diseases emerges. In this first part of a two-part article, mathematical models are developed, shown to fit data from laboratory experiments, and used to explore the evolutionary relations among transmission parameters. In the <a href="/docs/genetics/selection/1979-may-2.pdf">second part of the article</a>, to be published in next week’s issue, the models are extended to include indirectly transmitted infections, and the general implications for infectious diseases are considered.</p><p>…The effects of micro-parasitic infections on the dynamics of animal populations depend on the ecology of the interactions between host and parasite. These patterns of disease behaviour involve 4 principal factors, namely: the host providing a habitat for the parasite; the degree to which the parasite induces host mortality (or diminishes the reproductive capability of the host); the extent to which the host acquires immunity; and the necessity of transmission from one host to the next. Overlaid on these factors are many biological complications, specific to individual host—parasite associations, whose sequential action is determined by lifecycle structure.</p><p>In the second part of this article, we show how a common set of factors are involved in the dynamics of all infectious diseases, whether they are caused by viral or helmintic agents, and whether they are transmitted directly or indirectly between hosts.</p>'
- - /docs/genetics/selection/1979-may-2.pdf
  - ! 'Population biology of infectious diseases: Part II'
  - Robert M. May, Roy M. Anderson
  - 1979-08-01
  - 10.1038/280455a0
  - ! '<p>In the first part of this two-part article (<a href="/docs/genetics/selection/1979-anderson.pdf"><em>Nature</em> 280, 361–367</a>), mathematical models of directly transmitted microparasitic infections were developed, taking explicit account of the dynamics of the host population. The discussion is now extended to both microparasites (viruses, bacteria and protozoa) and macroparasites (helminths and arthropods), transmitted either directly or indirectly via one or more intermediate hosts. Consideration is given to the relation between the ecology and evolution of the transmission processes and the overall dynamics, and to the mechanisms that can produce cyclic patterns, or multiple stable states, in the levels of infection in the host population.</p><p>…This 2-part article has blended some new theoretical studies and new analysis of existing laboratory data with a review and synthesis of past and present models for the overall transmission dynamics of parasitic infections. We have defined ‘parasite’ broadly to include viruses, bacteria and protozoans along with the more conventional helminth and arthropod parasites, and we have concentrated attention upon the circumstances under which the infection may significantly alter the growth rate of its host population.</p><p>Some of the theoretical conclusions can be pleasingly supported by hard data, while others remain more speculative. On the whole, our main goal is to help elevate the study of host—parasite population dynamics to its proper place in ecological thinking: parasites (broadly defined) are probably at least as important as the more usually-studied predators and insect parasitoids in regulating natural populations.</p>'
- - /docs/genetics/correlation/1995-mccarren.pdf
  - ! 'A twin study of the association of post-traumatic stress disorder and combat exposure with long-term socioeconomic status in Vietnam veterans'
  - Madeline McCarren, Gail R. Janes, Jack Goldberg, Seth A. Eisen, William R. True, William G. Henderson
  - 1995-01-01
  - 10.1002/jts.2490080108
  - ! '<p>This study examines the association between post-traumatic stress disorder (<span class="smallcaps-auto">PTSD</span>) and combat exposure with the socioeconomic status of 2210 male monozygotic veteran twin pairs in 1987. In the unadjusted analysis on individuals, modest correlations indicated that those with <span class="smallcaps-auto">PTSD</span> were more likely to have been divorced, and less likely to be currently employed or to achieve high status in income, education or occupation. In the crude analysis of veterans not suffering from <span class="smallcaps-auto">PTSD</span>, there were small positive correlations between combat level experienced and the likelihood of ever being married, ever being divorced, and the number of years employed at the current job. However, when we examined identical twins discordant for <span class="smallcaps-auto">PTSD</span>, and adjusted for pre-military and military service factors, only unemployment remained significant. Likewise, in combat-discordant twins, no significant effects on the socioeconomic indicators were seen. We conclude that <span class="smallcaps-auto">PTSD</span> and combat experience in Southeast Asia have not had a major impact on the socioeconomic status of veterans.</p>'
- - /docs/sociology/2019-sommers.pdf
  - ! 'The Voluntariness of Voluntary Consent: Consent Searches and the Psychology of Compliance'
  - Roseanna Sommers, Vanessa K. Bohns
  - 2019-05-01
  - ''
  - ! '<p>Consent-based searches are by far the most ubiquitous form of search undertaken by police. A key legal inquiry in these cases is whether consent was granted voluntarily. This Essay suggests that fact finders’ assessments of voluntariness are likely to be impaired by a systematic bias in social perception. Fact finders are likely to underappreciate the degree to which suspects feel pressure to comply with police officers’ requests to perform searches.</p><p>In 2 preregistered laboratory studies, we approached a total of 209 participants (“Experiencers”) with a highly intrusive request: to unlock their password-protected smartphones and hand them over to an experimenter to search through while they waited in another room. A separate 194 participants (“Forecasters”) were brought into the lab and asked whether a reasonable person would agree to the same request if hypothetically approached by the same researcher. Both groups then reported how free they felt, or would feel, to refuse the request.</p><ol type="1"><li>Study 1 found that whereas most Forecasters believed a reasonable person would refuse the experimenter’s request, most Experiencers—100 out of 103 people—promptly unlocked their phones and handed them over. Moreover, Experiencers reported feeling significantly less free to refuse than did Forecasters contemplating the same situation hypothetically.</li><li>Study 2 tested an intervention modeled after a commonly proposed reform of consent searches, in which the experimenter explicitly advises participants that they have the right to withhold consent. We found that this advisory did not significantly reduce compliance rates or make Experiencers feel more free to say no. At the same time, the gap between Experiencers and Forecasters remained significant.</li></ol><p>These findings suggest that decision makers judging the voluntariness of consent consistently underestimate the pressure to comply with intrusive requests. This is problematic because it indicates that a key justification for suspicionless consent searches—that they are voluntary—relies on an assessment that is subject to bias. The results thus provide support to critics who would like to see consent searches banned or curtailed, as they have been in several states.</p><p>The results also suggest that a popular reform proposal—requiring police to advise citizens of their right to refuse consent—may have little effect. This corroborates previous observational studies that find negligible effects of <em>Miranda</em> warnings on confession rates among interrogees, and little change in rates of consent once police start notifying motorists of their right to refuse vehicle searches. We suggest that these warnings are ineffective because they fail to address the psychology of compliance. The reason people comply with police, we contend, is <em>social</em>, not informational. The social demands of police-citizen interactions persist even when people are informed of their rights. It is time to abandon the myth that notifying people of their rights makes them feel empowered to exercise those rights.</p>'
- - /docs/technology/2012-christin.pdf
  - ! 'It’s All about the Benjamins: An Empirical Study on Incentivizing Users to Ignore Security Advice'
  - Nicolas Christin, Serge Egelman, Timothy Vidas, Jens Grossklags
  - 2012-01-01
  - 10.1007/978-3-642-27576-0_2
  - ! '<p>We examine the cost for an attacker to pay users to execute arbitrary code—potentially malware. We asked users at home to download and run an executable we wrote without being told what it did and without any way of knowing it was harmless. Each week, we increased the payment amount. Our goal was to examine whether users would ignore common security advice—not to run untrusted executables—if there was a direct incentive, and how much this incentive would need to be. We observed that for payments as low as $0.01, 22% of the people who viewed the task ultimately ran our executable. Once increased to $1.00, this proportion increased to 43%. We show that as the price increased, more and more users who understood the risks ultimately ran the code. We conclude that users are generally unopposed to running programs of unknown provenance, so long as their incentives exceed their inconvenience.</p>'
- - /docs/iq/1997-gordon.pdf
  - ! 'Everyday Life as an Intelligence Test: Effects of Intelligence and Intelligence Context'
  - Robert A. Gordon
  - 1997-01-01
  - 10.1016/S0160-2896(97)90017-9
  - ! '<p>To show why the importance of intelligence is often misperceived, an analogy between single test items and single nontest actions in everyday life is drawn. 3 requirements of good test items are restated, and the analogy is employed to account for underrecognition of the importance of general intelligence in everyday actions, which often fail to meet the requirements and thus fail as intelligence measures for reasons that have little to do with their dependence on intelligence. A new perspective on the role of intelligence in nontest actions is introduced by considering its operation at 3 levels: that of the individual, that of the near context of the individual, and that of entire populations. Social scientists have misunderstood the operation and impact of IQ in populations by confining attention to the individual level. A population-IQ-outcome model is explained that tests for the pooled effects of intelligence at all 3 levels on differences between 2 populations in prevalences of certain outcomes. When the model fits, the difference between 2 populations in the outcome measured is found commensurate with the difference in their IQ or general intelligence distributions. The model is tested on and found to fit prevalences of juvenile delinquency, adult crime, single parenthood, <span class="smallcaps-auto">HIV</span> infection, poverty, belief in conspiracy rumors, and key opinions from polls about the O.J. Simpson trial and the earlier Tawana Brawley case. A deviance principle is extracted from empirical findings to indicate kinds of outcome the model will not fit. Implications for theories of practical and multiple intelligences are discussed. To understand the full policy implications of intelligence, such a fundamentally new perspective as that presented here will be needed.</p>'
- - /docs/iq/1997-gordon.pdf#page=47
  - ! 'Everyday Life as an Intelligence Test: Effects of Intelligence and Intelligence Context: Conspiracy Rumors in Everyday Life'
  - Robert A. Gordon
  - 1997-01-01
  - 10.1016/S0160-2896(97)90017-9
  - ! '<p>This major section extends the IQ model into the domain of public opinion concerning what is to be accepted as factual. The domain of factual opinion often lacks the constraints imposed on performance outcomes by real consequences, and it adds the element of irreducible uncertainty that characterizes events not personally witnessed by all. Such considerations can work for or against success of the model. Uncertainty calls forth judgment, but loosening of practical constraints can add unpredictability to outcomes. Surveys concerning belief in conspiracy rumors and key beliefs about the O.J. Simpson trial provide the main data.</p><p><strong>Conspiracy Rumors in Everyday Life</strong></p><p>Although conspiracy themes among Whites have long been studied (Cohn, 1966; Harrington, 1996; <a href="https://en.wikipedia.org/wiki/The_Paranoid_Style_in_American_Politics">Hofstadter, 1965</a>), the many rumors centered around conspiracies, some quite elaborate, that have been afloat in the African-American community at one time or another have just recently drawn scholarly attention (Turner, 1993). Often, those rumors concern consumer products manufactured by White corporations and their imagined sponsorship by the Ku Klux Klan (e.g., Kool cigarettes because of the K) or supposed adulteration of fast foods aimed at sterilizing Black males. Others target the government. Black celebrities, authority figures, academics, and media outlets sometimes lend credence to the rumors, and peers sometimes punish better informed individuals for defying the messages.</p><p>…Black organ donations are few because of distrust of the medical system and belief in myths (“Why More,” 1995), fostered, for example, by <a href="https://en.wikipedia.org/wiki/Nation_of_Islam">Nation of Islam</a> leader <a href="https://en.wikipedia.org/wiki/Louis_Farrakhan">Louis Farrakhan</a>…“Public-health workers say that the discussion of <a href="https://en.wikipedia.org/wiki/Operation_INFEKTION"><span class="smallcaps-auto">AIDS</span> as a plot against blacks</a> has eroded the credibility of <span class="smallcaps-auto">AIDS</span> prevention campaigns and has made some blacks suspicious of <span class="smallcaps-auto">AIDS</span> tests and treatments”…The director of a Black studies program stated that they diverted attention “from the resolution of pressing social problems” (Myers, 1990, p. A19). Andrew Cooper, publisher of a Black newspaper in Brooklyn, warned that the rumors were dysfunctional for all, observing, “It is a danger to America to have a large group of its citizens believe that its government is in a conspiracy to eliminate them”…Rumor experts offer no account for why, if a rumor is believed by a certain percentage of Blacks, it will also be believed by a certain, but smaller, percentage of Whites….What did account for the more than 40-point race split in public opinion over <a href="https://en.wikipedia.org/wiki/O._J._Simpson_murder_case">O.J. Simpson’s guilt</a>?…the <a href="https://en.wikipedia.org/wiki/Tawana_Brawley_rape_allegations">Brawley case</a> dominated the news…Finally, a 7-month grand jury investigation concluded that the entire affair was a hoax, originally contrived by Brawley and her mother to cover up the girl’s 4-day absence from home.</p>'
- - /docs/cs/2020-troise.pdf
  - ! 'The 1-Bit Instrument: The Fundamentals of 1-Bit Synthesis, Their Implementational Implications, and Instrumental Possibilities'
  - Blake Troise
  - 2020-01-01
  - 10.1525/jsmg.2020.1.1.44
  - ! '<p>The 1-bit sonic environment (perhaps most famously musically employed on the ZX Spectrum) is defined by extreme limitation. Yet, belying these restrictions, there is a surprisingly expressive instrumental versatility. This article explores the theory behind the primary, idiosyncratically 1-bit techniques available to the composer-programmer, those that are essential when designing “instruments” in 1-bit environments. These techniques include pulse width modulation for timbral manipulation and means of generating virtual polyphony in software, such as the pin pulse and pulse interleaving techniques. These methodologies are considered in respect to their compositional implications and instrumental applications. [Keywords: chiptune, 1-bit, one-bit, ZX Spectrum, pulse pin method, pulse interleaving, timbre, polyphony, history]</p>'
- - /docs/iq/1984-hunter.pdf
  - ! 'Validity and Utility of Alternative Predictors of Job Performance'
  - John Edward Hunter, Ronda F. Hunter
  - '1984'
  - 10.1037/0033-2909.96.1.72
  - ! '<p>Meta-analysis of the cumulative research on various predictors of job performance shows that for entry-level jobs there is no predictor with validity equal to that of ability, which has a mean validity of 0.53. For selection on the basis of current job performance, the work sample test, with mean validity of 0.54, is slightly better. For federal entry-level jobs, substitution of an alternative predictor would cost from $3.12 billion (job tryout) to $15.89 billion per year (age). Hiring on ability has a utility of $15.61 billion per year, but affects minority groups adversely. Hiring on ability by quotas would decrease this utility by 5%. A third strategy—using a low cutoff score—would decrease utility by 83%. Using other predictors in conjunction with ability tests might improve validity and reduce adverse impact, but there is as yet no data base for studying this possibility.</p>'
- - /docs/cs/2015-mcsherry.pdf
  - ! 'Scalability! But at what COST?'
  - Frank McSherry, Michael Isard, Derek G. Murray
  - 2015-05
  - ''
  - ! '<p>We offer a new metric for big data platforms, <span class="smallcaps-auto">COST</span>, or the Configuration that Outperforms a Single Thread. The <span class="smallcaps-auto">COST</span> of a given platform for a given problem is the hardware configuration required before the platform outperforms a competent single-threaded implementation. <span class="smallcaps-auto">COST</span> weighs a system’s scalability against the overheads introduced by the system, and indicates the actual performance gains of the system, without rewarding systems that bring substantial but parallelizable overheads.</p><p>We survey measurements of data-parallel systems [for graph processing] recently reported in <span class="smallcaps-auto">SOSP</span> and <span class="smallcaps-auto">OSDI</span>, and find that many systems have either a surprisingly large <span class="smallcaps-auto">COST</span>, often hundreds of cores, or simply underperform one thread for all of their reported configurations.</p>'
- - /docs/science/2014-ma.pdf
  - ! 'Quantification of Pizza Baking Properties of Different Cheeses, and Their Correlation with Cheese Functionality'
  - Xixiu Ma, Murat O. Balaban, Lu Zhang, Emma A.C. Emanuelsson-Patterson, Bryony James
  - 2014-07-21
  - 10.1111/1750-3841.12540
  - ! '<p>The aim of this study is to quantify the pizza baking properties and performance of different cheeses, including the browning and blistering, and to investigate the correlation to cheese properties (rheology, free oil, transition temperature, and water activity). The color, and color uniformity, of different cheeses (Mozzarella, Cheddar, Colby, Edam, Emmental, Gruyere, and Provolone) were quantified, using a machine vision system and image analysis techniques. The correlations between cheese appearance and attributes were also evaluated, to find that cheese properties including elasticity, free oil, and transition temperature influence the color uniformity of cheeses. [Keywords: color uniformity, machine vision, pizza baking, <span class="smallcaps-auto">PCA</span>]</p><p><em>Practical Application</em>: Different cheeses can be employed on “gourmet” style pizzas in combination with Mozzarella. Based on the findings, cheeses with some attributes can be used to cook pizzas to meet the specific preferences of consumers.</p>'
- - /docs/psychology/2020-danese.pdf
  - ! 'Objective and subjective experiences of child maltreatment and their relationships with psychopathology'
  - Andrea Danese, Cathy Spatz Widom
  - 2020-05-18
  - 10.1038/s41562-020-0880-3
  - ! '<p>Does psychopathology develop as a function of the objective or subjective experience of childhood maltreatment? To address this question, we studied a unique cohort of 1,196 children with both objective, court-documented evidence of maltreatment and subjective reports of their childhood maltreatment histories made once they reached adulthood, along with extensive psychiatric assessment. We found that, even for severe cases of childhood maltreatment identified through court records, risk of psychopathology linked to objective measures was minimal in the absence of subjective reports. In contrast, risk of psychopathology linked to subjective reports of childhood maltreatment was high, whether or not the reports were consistent with objective measures. These findings have important implications for how we study the mechanisms through which child maltreatment affects mental health and how we prevent or treat maltreatment-related psychopathology. Interventions for psychopathology associated with childhood maltreatment can benefit from deeper understanding of the subjective experience.</p>'
- - /docs/sociology/2020-shi.pdf
  - ! 'The public salience of crime, 1960–2014: Age–period–cohort and time–series analyses'
  - Luzi Shi, Yunmei Lu, Justin T. Pickett
  - 2020-05-18
  - 10.1111/1745-9125.12248
  - ! '<p>The public salience of crime has wide-ranging political and social implications; it influences public trust in the government and citizens’ everyday routines and interactions, and it may affect policy responsiveness to punitive attitudes. Identifying the sources of crime salience is thus important. Two competing theoretical models exist: the objectivist model and the social constructionist model. According to the first, crime salience is a function of the crime rate. According to the second, crime salience is a function of media coverage and political rhetoric, and trends in crime salience differ across population subgroups as a result of differences in their responsiveness to elite initiatives. In both theories, period‐level effects predominate. Variation in crime salience, however, may also reflect age and cohort effects. Using data from 422,504 respondents interviewed between 1960 and 2014, we first examine the nature of crime salience using hierarchical age–period–cohort (<span class="smallcaps-auto">HAPC</span>) models and then analyze period‐level predictors using first differences. We find that 1. crime salience varies mostly at the period level; 2. crime salience trends are parallel (cointegrated) across demographic, socioeconomic, and partisan groups; and 3. crime salience trends within every population subgroup are most consistent with the constructionist model. The crime rate does not exert a significant effect in any subgroup.</p>'
- - /docs/design/1980-knuth.pdf
  - ! 'The Letter S'
  - Donald E. Knuth
  - 1980-09-01
  - 10.1007/bf03023051
  - ! '<p>This expository paper explains how the problem of drawing the letter ‘S’ leads to interesting problems in elementary calculus and analytic geometry. It also gives a brief introduction to the author’s <span class="smallcaps-auto">METAFONT</span> language for alphabet design.</p>'
- - /docs/design/1982-knuth.pdf
  - ! 'The Concept of a Meta-Font'
  - Donald E. Knuth
  - 1982-01
  - ''
  - ! '<p>A single drawing of a single letter reveals only a small part of what was in the designer’s mind when that letter was drawn. But when precise instructions are given about how to make such a drawing, the intelligence of that letter can be captured in a way that permits us to obtain an infinite variety of related letters from the same specification. Instead of merely describing a single letter, such instructions explain how that letter would change its shape if other parameters of the design were changed. Thus an entire font of letters and other symbols can be specified so that each character adapts itself to varying conditions in an appropriate way. Initial experiments with a precise language for pen motions suggest strongly that the font designer of the future should not simply design isolated alphabets; the challenge will be to explain exactly how each design should adapt itself gracefully to a wide range of changes in the specification. This paper gives examples of a meta-font and explains the changeable parameters in its design.</p>'
- - /docs/design/2007-rhatigan.pdf
  - ! "The Monotype 4-Line System for Setting Mathematics"
  - Daniel Rhatigan
  - 2007-08-13
  - ''
  - ! '<p>[Description of the most advanced mechanical typesetting system for the challenging task of typesetting mathematics. To provide the typographic quality of hand-set math but at an affordable cost, the Monotype corporation made a huge investment post-<span class="smallcaps-auto">WWII</span> into a mechanical typesetting system which would encode every mathematical equation into 4 horizontal ‘lines’ into which could be slotted entries from a vast new family of fonts &amp; symbols, all tweaked to fit in various positions, which would then be spat out by the machine into a single solid lead piece which could be combined with the rest to form a single page, allowing a skilled operator to rapidly ‘type’ his way through a page of math to yield a beautiful custom output without endlessly tedious hand-arranging lots of little metal bits.]</p>'
- - /docs/statistics/bias/2020-botviniknezer.pdf
  - ! 'Variability in the analysis of a single neuroimaging dataset by many teams'
  - Rotem Botvinik-Nezer, Felix Holzmeister, Colin F. Camerer, Anna Dreber, Juergen Huber, Magnus Johannesson, Michael Kirchler, Roni Iwanir, Jeanette A. Mumford, R. Alison Adcock, Paolo Avesani, Blazej M. Baczkowski, Aahana Bajracharya, Leah Bakst, Sheryl Ball, Marco Barilari, Nadège Bault, Derek Beaton, Julia Beitner, Roland G. Benoit, Ruud M. W. J. Berkers, Jamil P. Bhanji, Bharat B. Biswal, Sebastian Bobadilla-Suarez, Tiago Bortolini, Katherine L. Bottenhorn, Alexander Bowring, Senne Braem, Hayley R. Brooks, Emily G. Brudner, Cristian B. Calderon, Julia A. Camilleri, Jaime J. Castrellon, Luca Cecchetti, Edna C. Cieslik, Zachary J. Cole, Olivier Collignon, Robert W. Cox, William A. Cunningham, Stefan Czoschke, Kamalaker Dadi, Charles P. Davis, Alberto De Luca, Mauricio R. Delgado, Lysia Demetriou, Jeffrey B. Dennison, Xin Di, Erin W. Dickie, Ekaterina Dobryakova, Claire L. Donnat, Juergen Dukart, Niall W. Duncan, Joke Durnez, Amr Eed, Simon B. Eickhoff, Andrew Erhart, Laura Fontanesi, G. Matthew Fricke, Shiguang Fu, Adriana Galván, Remi Gau, Sarah Genon, Tristan Glatard, Enrico Glerean, Jelle J. Goeman, Sergej A. E. Golowin, Carlos González-García, Krzysztof J. Gorgolewski, Cheryl L. Grady, Mikella A. Green, João F. Guassi Moreira, Olivia Guest, Shabnam Hakimi, J. Paul Hamilton, Roeland Hancock, Giacomo Handjaras, Bronson B. Harry, Colin Hawco, Peer Herholz, Gabrielle Herman, Stephan Heunis, Felix Hoffstaedter, Jeremy Hogeveen, Susan Holmes, Chuan-Peng Hu, Scott A. Huettel, Matthew E. Hughes, Vittorio Iacovella, Alexandru D. Iordan, Peder M. Isager, Ayse I. Isik, Andrew Jahn, Matthew R. Johnson, Tom Johnstone, Michael J. E. Joseph, Anthony C. Juliano, Joseph W. Kable, Michalis Kassinopoulos, Cemal Koba, Xiang-Zhen Kong, Timothy R. Koscik, Nuri Erkut Kucukboyaci, Brice A. Kuhl, Sebastian Kupek, Angela R. Laird, Claus Lamm, Robert Langner, Nina Lauharatanahirun, Hongmi Lee, Sangil Lee, Alexander Leemans, Andrea Leo, Elise Lesage, Flora Li, Monica Y. C. Li, Phui Cheng Lim, Evan N. Lintz, Schuyler W. Liphardt, Annabel B. Losecaat Vermeer, Bradley C. Love, Michael L. Mack, Norberto Malpica, Theo Marins, Camille Maumet, Kelsey McDonald, Joseph T. McGuire, Helena Melero, Adriana S. Méndez Leal, Benjamin Meyer, Kristin N. Meyer, Glad Mihai, Georgios D. Mitsis, Jorge Moll, Dylan M. Nielson, Gustav Nilsonne, Michael P. Notter, Emanuele Olivetti, Adrian I. Onicas, Paolo Papale, Kaustubh R. Patil, Jonathan E. Peelle, Alexandre Pérez, Doris Pischedda, Jean-Baptiste Poline, Yanina Prystauka, Shruti Ray, Patricia A. Reuter-Lorenz, Richard C. Reynolds, Emiliano Ricciardi, Jenny R. Rieck, Anais M. Rodriguez-Thompson, Anthony Romyn, Taylor Salo, Gregory R. Samanez-Larkin, Emilio Sanz-Morales, Margaret L. Schlichting, Douglas H. Schultz, Qiang Shen, Margaret A. Sheridan, Jennifer A. Silvers, Kenny Skagerlund, Alec Smith, David V. Smith, Peter Sokol-Hessner, Simon R. Steinkamp, Sarah M. Tashjian, Bertrand Thirion, John N. Thorp, Gustav Tinghög, Loreen Tisdall, Steven H. Tompson, Claudio Toro-Serey, Juan Jesus Torre Tresols, Leonardo Tozzi, Vuong Truong, Luca Turella, Anna E. van ‘t Veer, Tom Verguts, Jean M. Vettel, Sagana Vijayarajah, Khoi Vo, Matthew B. Wall, Wouter D. Weeda, Susanne Weis, David J. White, David Wisniewski, Alba Xifra-Porxas, Emily A. Yearling, Sangsuk Yoon, Rui Yuan, Kenneth S. L. Yuen, Lei Zhang, Xu Zhang, Joshua E. Zosky, Thomas E. Nichols, Russell A. Poldrack, Tom Schonberg
  - 2020-05-20
  - 10.1038/s41586-020-2314-9
  - ! '<p>Data analysis workflows in many scientific domains have become increasingly complex and flexible. Here we assess the effect of this flexibility on the results of functional magnetic resonance imaging by asking 70 independent teams to analyse the same dataset, testing the same 9 ex-ante hypotheses<sup>1</sup>. The flexibility of analytical approaches is exemplified by the fact that no two teams chose identical workflows to analyse the data. This flexibility resulted in sizeable variation in the results of hypothesis tests, even for teams whose statistical maps were highly correlated at intermediate stages of the analysis pipeline. Variation in reported results was related to several aspects of analysis methodology. Notably, a meta-analytical approach that aggregated information across teams yielded a significant consensus in activated regions. Furthermore, prediction markets of researchers in the field revealed an overestimation of the likelihood of significant findings, even by researchers with direct knowledge of the dataset<sup>2,3,4,5</sup>. Our findings show that analytical flexibility can have substantial effects on scientific conclusions, and identify factors that may be related to variability in the analysis of functional magnetic resonance imaging. The results emphasize the importance of validating and sharing complex analysis workflows, and demonstrate the need for performing and reporting multiple analyses of the same data. Potential approaches that could be used to mitigate issues related to analytical variability are discussed.</p>'
- - /docs/economics/2017-sacerdote.pdf
  - ! "Fifty Years Of Growth In American Consumption, Income, And Wages"
  - Bruce Sacerdote
  - 2017-05-16
  - 10.3386/w23292
  - ! '<p>Despite the large increase in U.S. income inequality, consumption for families at the 25<sup>th</sup> and 50<sup>th</sup> percentiles of income has grown steadily over the time period 1960–2015. The number of cars per household with below median income has doubled since 1980 and the number of bedrooms per household has grown 10% despite decreases in household size. The finding of zero growth in American real wages since the 1970s is driven in part by the choice of the <span class="smallcaps-auto">CPI</span>-U as the price deflator (Broda and Weinstein 2008, <em>Prices, Poverty, And Inequality: Why Americans Are Better Off Than You Think</em>). Small biases in any price deflator compound over long periods of time. Using a different deflator such as the Personal Consumption Expenditures index (<span class="smallcaps-auto">PCE</span>) yields modest growth in real wages and in median household incomes throughout the time period. Accounting for the <a href="/docs/economics/1998-hamilton.pdf" title="The True Cost of Living: 1974–1991">Hamilton (1998)</a> and <a href="/docs/economics/2001-costa.pdf" title="Estimating Real Income in the United States from 1888 to 1994: Correcting CPI Bias Using Engel Curves">Costa (2001)</a> estimates of <span class="smallcaps-auto">CPI</span> bias yields estimated wage growth of 1% per year during 1975–2015. Meaningful growth in consumption for below median income families has occurred even in a prolonged period of increasing income inequality, increasing consumption inequality and a decreasing share of national income accruing to labor.</p>'
- - /docs/economics/1998-hamilton.pdf
  - ! "The True Cost of Living: 1974–1991"
  - Bruce W. Hamilton
  - 1998-05-19
  - ''
  - ! '<p>This first purpose of this paper is to utilize the <span class="smallcaps-auto">PSID</span> to see whether the anomalies of Figures 1 and 2 can be attributed to some non-<span class="smallcaps-auto">CPI</span> cause such as demographics or changes in the distribution of income. The second purpose is to offer a more refined estimate of <span class="smallcaps-auto">CPI</span> bias. Third, I will present evidence of strikingly different inflation rates by race. Using the <span class="smallcaps-auto">PSID</span>, I estimate a demand function for food at home for 1974 through 1991. Using a standard measure of real income (total family income after federal taxes, the <span class="smallcaps-auto">PSID</span>’s best continuously available approximation of disposable income)<sup>10</sup> deflated by the <span class="smallcaps-auto">CPI</span>, this demand function has shown consistent drift over the sample period; I attribute this drift to unmeasured growth in real income, and in turn I attribute the mismeasurement of income to <span class="smallcaps-auto">CPI</span> bias.</p><p>In a nutshell, the results are as follows: On average, in 1974 the <span class="smallcaps-auto">PSID</span> sample<sup>11</sup> of white households spent 16.64% of its income on at-home food. By 1991 this share had fallen to 12.04%. Measured per-household income grew 7% over this time span, explaining just over half a point of the food-share decline. Decline in the relative <span class="smallcaps-auto">CPI</span> of food is sufficient to explain perhaps as much as 1 percentage point of decline in food’s share. Other regressors accounts for less than 0.1 point of additional decline; thus about 3 points of the food-share decline are left to be explained by <span class="smallcaps-auto">CPI</span> bias. I estimate that this bias is about 2.5% per year from 1974 through 1981, and slightly under 1% per year since then.</p><p>For blacks, food’s share fell from 21.17% to 12.44%. Approximately 0.8 point of the decline can be explained by measured income growth, and another point by movement in other regressors, and up to another 1 point by the decline in the food <span class="smallcaps-auto">CPI</span>. Thus the food-share decline left to be explained by measurement error is 5.9 points. I estimate the bias to be approximately 4% per year from 1974 through 1981 and about 3% per year since then.</p>'
- - /docs/economics/2001-costa.pdf
  - ! "Estimating Real Income in the United States from 1888 to 1994: Correcting CPI Bias Using Engel Curves"
  - Dora L. Costa
  - 2001-12
  - 10.1086/323279
  - ! '<p>This paper provides the first estimates of overall <span class="smallcaps-auto">CPI</span> bias prior to the 1970s and new estimates of bias since the 1970s. It finds that annual <span class="smallcaps-auto">CPI</span> bias was −0.1% between 1888 and 1919 and rose to 0.7% between 1919 and 1935. Annual <span class="smallcaps-auto">CPI</span> bias was 0.4% in the 1960s and then rose to 2.7% between 1972 and 1982 before falling to 0.6% between 1982 and 1994. The findings imply that we have underestimated growth rates in true income in the 1920s and 1930s and in the 1970s.</p>'
- - https://www.newyorker.com/magazine/2011/11/21/crunch
  - "Crunch: Building a better apple"
  - John Seabrook (New Yorker)
  - 2011-11-14
  - ''
  - ! '<p>Profile of the development &amp; launch of the <a href="https://en.wikipedia.org/wiki/SweeTango">SweeTango</a> apple, a successor to <a href="https://en.wikipedia.org/wiki/Honeycrisp">Honeycrisp</a> (via a hybridization with <a href="https://en.wikipedia.org/wiki/Zestar_apple">Zestar</a>), developed by the University of Minnesota apple breeding program, which has been running since 1878 and created 27 notable apples (earning its role as the state fruit).</p><p>Breeding programs like that are part of why Americans have historically shifted from consuming hard cider (made with inedible wild-types) to ‘eating apples’, but progress was set back by a drastic decrease in variety to the <a href="https://en.wikipedia.org/wiki/McIntosh_(apple)">McIntosh</a>/<a href="https://en.wikipedia.org/wiki/Golden_Delicious">Golden Delicious</a>/<a href="https://en.wikipedia.org/wiki/Red_Delicious">Red Delicious</a> triumvirate–Red Delicious degrading rapidly in quality. The apple revolution began in the 1970s when <a href="https://en.wikipedia.org/wiki/Granny_Smith">Granny Smith</a> proved US consumers would buy a better apple, and was followed by the <a href="https://en.wikipedia.org/wiki/Fuji_(apple)">Fuji</a>, <a href="https://en.wikipedia.org/wiki/Braeburn">Braeburn</a>, and <a href="https://en.wikipedia.org/wiki/Gala_(apple)">Gala</a>.</p><p>How does one breed a new apple? Apples do not breed true and every offspring is wildly different. Apple breeders use brute force and brutally stringent screening: an acre of thousands of saplings will be grown, and in all, the breeders will walk the row, grab 1 apple, chew it briefly, spit it out, and mark the tree if good. Any sapling which is marked several years in a row (a few score out of thousands) survives; clones of it will be transplanted elsewhere for further testing, and evaluated similarly for another decade. If and only a new apple tree &amp; clones pass all these tests, will it even be considered for commercialization.</p><blockquote><p>“I’d like to give a tree a couple chances, but I just don’t have the mouth time for that,” Bedford explained. “So it’s one strike and you’re out. With all these new trees coming on each year, you won’t have space unless you thin out the duds.” He sprayed another tree trunk with the mark of death. “But it is kind of nerve-racking, because you want to give the tree a chance to do its best. No one wants to be known as the guy who killed the next Honeycrisp.”</p></blockquote><p>The winner of such a process must be both brilliant and lucky, and Honeycrisp was both. But UMinn breeders watched with dismay as they felt the released Honeycrisp saplings were mistreated or poorly-raised by careless commercial growers, and decided the next apple, SweeTango, would be a “<a href="https://en.wikipedia.org/wiki/Club_good">club</a> <a href="https://www.npr.org/sections/thesalt/2014/11/10/358530280/want-to-grow-these-apples-youll-have-to-join-the-club" title="Want To Grow These Apples? You&#39;ll Have To Join The Club">apple</a>”: it would be fully patented &amp; controlled, and sold only to select apple growers who would be required to follow stringent rules.</p><p>The “club apple” business model has proven to be its own revolution by internalizing the costs &amp; benefits, incentivizing the creation of a dizzying variety of new apples reaching the American grocery market every year.</p>'
- - /docs/genetics/selection/2010-kean.pdf
  - "Besting Johnny Appleseed: With a few tricks, and a lot of patience, fruit geneticists are undoing the work of an American legend"
  - Sam Kean (Science)
  - 2010-04-16
  - 10.1126/science.328.5976.301
  - ! '<p>[Review of modern apple breeding techniques: genome sequencing enables selecting on seeds rather than trees by predicting taste &amp; robustness, saving years of delay; this also allows avoiding the ‘<span class="smallcaps-auto">GMO</span>’ stigma by crossbreeding (quickly moving genes into new apple trees without direct genetic editing using genomic selection), such as a “fast-flowering gene” to accelerate maturation during evaluation but then select it out for the final tree; the creation of “The Gauntlet”, a greenhouse deliberately stocked with as many pathogens as possible, provides a stress test to weed out weak sapling as quickly as possible; and buds can be cryogenically preserved to cut down storage costs by more than an order of magnitude.]</p><p>Until recently, geneticists, their skills honed on <em>Arabidopsis</em> and other quick-breeding flora, avoided fruit-tree research like a blight. Of the 11,000 U.S. field tests on plants with transgenic genes between 1987 and 2004, just 1% focused on fruit trees. That’s partly because of the slow pace. Whereas vegetables like corn might produce two harvests each summer, apple trees need eons—around 5 years—to produce their first fruit, most of which will be disregarded as ugly, bitter, or squishy. But everything in apple breeding is about to change. An Italian team plans to publish the decoded apple genome this summer, and scientists are starting to single out complex genetic markers for taste and heartiness. In some cases the scientists even plan, by inserting genes from other species, to eliminate the barren juvenile stage and push fruit trees to mature rapidly, greatly reducing generation times.</p>'
- - /docs/nicotine/2009-froeliger.pdf
  - ! "Effects of nicotine on novelty detection and memory recognition performance: double-blind, placebo-controlled studies of smokers and nonsmokers"
  - Brett Froeliger, David G. Gilbert, F. Joseph McClernon
  - 2009-06-02
  - 10.1007/s00213-009-1571-y
  - ! '<p><strong>Rationale</strong>: Dependent smokers exhibit deficits in attentional and memory processes when smoking abstinent as compared to when satiated. While nicotine replacement therapy improves attention during abstinence, it is unclear whether this is due to the alleviation of withdrawal-related deficits or inherent beneficial effects of nicotine.</p><p><strong>Objectives</strong>: The primary aim of these studies was to test whether nicotine exerts a beneficial effect on novelty detection and whether such effects occur in nonsmokers as well as habitual smokers.</p><p><strong>Materials and methods</strong>: In 2 parallel, double-blind, placebo-controlled studies, 24 smokers (study 1) and 24 nonsmokers (study 2) were tested in two counterbalanced sessions: once while wearing a nicotine patch (smokers = 14 mg; nonsmokers = 7 mg) and once while wearing a placebo patch. On each day, participants performed three content-specific oddball tasks (perceptual, semantic, and emotional) that required them to press a button whenever they saw a novel target (20% of stimuli) embedded in a stream of common nontarget stimuli (80% of stimuli). Recognition memory for targets was subsequently tested. Reports of mood, smoking withdrawal, patch side effects, and blind success were collected in each session.</p><p><strong>Results</strong>: Among smokers, compared to placebo, nicotine decreased target reaction time during all oddball tasks. Among nonsmokers, nicotine increased target detection accuracy and subsequent memory recognition. Nicotine’s enhancement on each respective measure was not task-content specific in either sample.</p><p><strong>Conclusions</strong>: These data suggest that acute nicotine administration may exert direct beneficial effects on novelty detection and subsequent memory recognition in both smokers and nonsmokers. Moreover, these effects are not content-specific.</p>'
- - /docs/ai/2020-bell.pdf#facebook
  - ! "GrokNet: Unified Computer Vision Model Trunk and Embeddings For Commerce"
  - Sean Bell, Yiqun Liu, Sami Alsheikh, Yina Tang, Ed Pizzi, M. Henning, Karun Singh, Omkar Parkhi, Fedor Borisyuk
  - 2020-08-22
  - ''
  - ! '<p>In this paper, we present GrokNet, a deployed image recognition system for commerce applications. GrokNet leverages a multi-task learning approach to train a single computer vision trunk. We achieve a 2.1× improvement in exact product match accuracy when compared to the previous state-of-the-art Facebook product recognition system. We achieve this by training on 7 datasets across several commerce verticals, using 80 categorical loss functions and 3 embedding losses. We share our experience of combining diverse sources with wide-ranging label semantics and image statistics, including learning from human annotations, user-generated tags, and noisy search engine interaction data. GrokNet has demonstrated gains in production applications and operates at Facebook scale.</p>'
- - https://ai.facebook.com/blog/powered-by-ai-advancing-product-understanding-and-building-new-shopping-experiences
  - 'Powered by AI: Advancing product understanding and building new shopping experiences'
  - 'Tamara Berg, Sean Bell, Manohar Paluri, Andrei Chtcherbatchenko, Harry Chen, Francis Ge, Bo Yin'
  - 2020-05-19
  - ''
  - ! '<p>Today we’re announcing:</p><ul><li>We’ve built and deployed GrokNet, a universal computer vision system designed for shopping. It can identify fine-grained product attributes across billions of photos—in different categories, such as fashion, auto, and home decor.</li><li>GrokNet is powering new Marketplace features for buyers and sellers today and we’re testing automatic product tagging on Facebook Pages to help make photos shoppable.</li><li>We’re also introducing Rotating View, a state-of-the-art 3D-like photo capability that allows anyone with a camera on their phone to capture multi-dimensional panoramic views of their listings on Marketplace.</li><li>And we’ve advanced research by creating a state of the art technique to predict occluded or layered objects in photos (like a shirt beneath a jacket).</li><li>These advancements are part of the foundation we’re building to develop an entirely new way to shop on our platforms—making it easier for individuals and small businesses to showcase their products to billions of people, and for buyers to find exactly what they’re looking for.</li></ul><p>…We built, trained, and deployed a model with 83 loss functions across seven data sets to combine multiple verticals into a single embedding space. This universal model allows us to leverage many more sources of information, which increases our accuracy and outperforms our single vertical-focused models… In the GrokNet training architecture, a major challenge is managing 7 datasets and 83 loss functions, so that they all perform well simultaneously. To solve this, we adjust the batch sizes and loss weights, using more images per batch and higher loss weights for the challenging tasks. We also use weakly supervised learning to automatically generate additional training data, further improving accuracy.</p><p>…Our long-term vision is to build an all-in-one AI lifestyle assistant that can accurately search and rank billions of products, while personalizing to individual tastes. That same system would make online shopping just as social as shopping with friends in real life. Going one step further, it would advance visual search to make your real-world environment shoppable. If you see something you like (clothing, furniture, electronics, etc.), you could snap a photo of it and the system would find that exact item, as well as several similar ones to purchase right then and there…While these systems are fragmented right now, incorporating everything into one system is the ambitious challenge we’ve set out to achieve. Building these systems across all Facebook platforms would enable shoppers to connect with their friends and family to get an opinion on an automatically generated 360-degree 3D view of an item. These friends can weigh in on which sneakers they like most or which size painting looks best in the shopper’s kitchen. By combining state-of-the-art computer vision with advancements in other AI domains, such as language understanding, personalization, and social-first experiences, we’re well positioned to transform online shopping for everyone.</p>'
- - https://www.bloomberg.com/news/articles/2020-05-18/softbank-vision-fund-books-17-7-billion-loss-on-wework-uber
  - "SoftBank Vision Fund Posts $17.7 Billion Loss on WeWork, Uber"
  - Pavel Alpeyev (Bloomberg)
  - 2020-05-18
  - ''
  - ! '<p><a href="https://en.wikipedia.org/wiki/SoftBank_Group">SoftBank Group Corp.</a> said its Vision Fund business lost 1.9 trillion yen ($17.7 billion) last fiscal year after writing down the value of investments, including <a href="https://en.wikipedia.org/wiki/WeWork">WeWork</a> and <a href="https://en.wikipedia.org/wiki/Uber">Uber</a> Technologies Inc.</p><p>The company posted an overall operating loss of 1.36 trillion yen in the 12 months ended March and a net loss of 961.6 billion yen, according to a statement on Monday. The Tokyo-based conglomerate released figures in two preliminary earnings statements last month. The losses are the worst ever in the company’s 39-year history. SoftBank founder Masayoshi Son’s $100 billion Vision Fund went from the group’s main contributor to profit a year ago to its biggest drag on earnings. Uber’s disappointing public debut last May was followed by the implosion of WeWork in September and its subsequent rescue by SoftBank. Now Son is struggling with the impact of the coronavirus on the portfolio of startups weighted heavily toward the sharing economy.</p><p>“The situation is exceedingly difficult,” Son said at a briefing discussing the results on Monday. “Our unicorns have fallen into this sudden coronavirus ravine. But some of them will use this crisis to grow wings.”</p><p>The drop in Uber’s share price was responsible for about $5.2 billion of Vision Fund’s losses in the period, while WeWork contributed $4.6 billion and another $7.5 billion came from the rest of the portfolio, SoftBank said. The $75 billion the Vision Fund has spent to invest in 88 companies as of March 31 is now worth $69.6 billion. SoftBank also recorded losses from its own investments, including WeWork and satellite operator <a href="https://en.wikipedia.org/wiki/OneWeb">OneWeb</a>, which filed for bankruptcy in March.</p>'
- - /docs/sociology/2020-okuyama.pdf
  - ! "Fast food outlets, physical activity facilities, and obesity among adults: a nationwide longitudinal study from Sweden"
  - Kenta Okuyama, Xinjun Li, Takafumi Abe, Tsuyoshi Hamano, Paul W. Franks, Toru Nabika, Kristina Sundquis
  - 2020-05-19
  - 10.1038/s41366-020-0588-5
  - ! '<p><strong>Background</strong>: While neighborhood deprivation is a well-known predictor of obesity, the mechanisms behind this association are unclear and these are important to clarify before designing interventions focusing on modifiable neighborhood environmental factors in order to reduce obesity risk.</p><p><strong>Objectives</strong>: This study examined the longitudinal association between availability of fast-food outlets and physical activity facilities and the risk of obesity among adults.</p><p><strong>Methods</strong>: This study used multiple national register data from Sweden. During the 11-year follow-up period between 2005 and 2015, data from 1,167,449 men and 542,606 women, aged 20–55 years, were accessible for inclusion in this analysis. Incidence of obesity was identified based on a diagnosis of obesity during the follow-up period derived from clinical register data. Neighborhood availability of fast-food outlets and physical activity facilities were assessed in 2005 and Cox regression was used in the statistical analysis. Individual socio-demographic factors and neighborhood deprivation were used as covariates.</p><p><strong>Results</strong>: There were no meaningful associations between neighborhood fast-food outlets or physical activity facilities and obesity in men or women. Neighborhood deprivation was, however, consistently and strongly associated with incidence of obesity in both men and women.</p><p><strong>Conclusions</strong>: Availability of fast-food outlets and lack of physical activity facilities appear unlikely to cause obesity in Swedish adults. Other potentially modifiable environmental factors within specific social and cultural settings that may influence obesity risk should be examined in future studies.</p>'
- - /docs/genetics/correlation/2020-takahashi.pdf
  - ! "Genetic and environmental influences on the developmental trajectory of callous-unemotional traits from childhood to adolescence"
  - Yusuke Takahashi, Christopher R. Pease, Jean-Baptiste Pingault, Essi Viding
  - 2020-05-17
  - 10.1111/jcpp.13259
  - ! '<p><strong>Background</strong>: This study examined the genetic and environmental influences underlying baseline level and developmental course of callous–unemotional (CU) traits across childhood and adolescence.</p><p><strong>Methods</strong>: The data on 8,958 twin pairs (3,108 MZ twin pairs and 5,850 DZ twin pairs) from the Twins Early Development Study were analysed. CU traits were assessed at ages 7, 9, 12 and 16 by mothers and analysed using a biometric latent growth model.</p><p><strong>Results</strong>: Individual differences in the baseline level of CU traits were highly heritable (76.5%), while the heritability of the developmental course of CU traits was moderate (43.6%). The genetic influences on baseline level and developmental course of CU traits were mostly non-overlapping. Nonshared environment made a modest contribution to the baseline level of CU traits (21.7%). Nonshared environmental influences on the developmental course of CU traits were moderate (43.2%), with nearly half of them being the same as those influencing the baseline level and just over half being specific. Shared environmental effects did not contribute to systematic change across childhood and adolescence but were rather age-specific.</p><p><strong>Conclusions</strong>: Our findings demonstrate that rather than only being conceptualized as factors of stability, genes also play a dynamic role in explaining systematic change in CU traits. Genetic effects for the initial risk and subsequent development of CU traits are not the same. In addition to genetic factors, nonshared environmental influences play an important role in explaining why some children will increase or maintain their CU traits over time, whereas other will desist. New genetic and environmental influences with age suggest that repeated, age-tailored interventions may be required throughout development to make a lasting difference in the presentation of CU traits and associated outcomes.</p>'
- - /docs/psychology/2020-muthukrishna.pdf
  - ! "Beyond Western, Educated, Industrial, Rich, and Democratic (WEIRD) Psychology: Measuring and Mapping Scales of Cultural and Psychological Distance"
  - Michael Muthukrishna, Adrian V. Bell, Joseph Henrich, Cameron M. Curtin, Alexander Gedranovich, Jason McInerney, sBraden Thue
  - 2020-05-21
  - 10.1177/0956797620916782
  - ! '<p>In this article, we present a tool and a method for measuring the psychological and cultural distance between societies and creating a distance scale with any population as the point of comparison. Because psychological data are dominated by samples drawn from Western, educated, industrialized, rich, and democratic (<span class="smallcaps-auto">WEIRD</span>) nations, and overwhelmingly, the United States, we focused on distance from the United States. We also present distance from China, the country with the largest population and second largest economy, which is a common cultural comparison. We applied the fixation index (<span class="smallcaps-auto">FST</span>), a meaningful statistic in evolutionary theory, to the World Values Survey of cultural beliefs and behaviors. As the extreme <span class="smallcaps-auto">WEIRD</span>ness of the literature begins to dissolve, our tool will become more useful for designing, planning, and justifying a wide range of comparative psychological projects. Our code and accompanying online application allow for comparisons between any two countries. Analyses of regional diversity reveal the relative homogeneity of the United States. Cultural distance predicts various psychological outcomes. [Keywords: <span class="smallcaps-auto">WEIRD</span> people, cultural psychology, cultural distance, cross-cultural differences, replication crisis]</p>'
- - /docs/genetics/heritable/2020-visscher.pdf
  - ! "Musings on Visscher et al. (2006)"
  - Peter M. Visscher
  - 2020-05-19
  - 10.1017/thg.2020.21
  - ! '<p>The classical twin design relies on a number of strong number of assumptions in order to yield unbiased estimates of heritability. This includes the equal environments assumption—that monozygotic and dizygotic twins experience similar degrees of environmental similarity—an assumption that is likely to be violated in practice for many traits of interest. An alternative method of estimating heritability that does not suffer from many of these limitations is to model trait similarity between sibling pairs as a function of their empirical genome-wide identity by descent sharing, estimated from genetic markers. In this review, I recount the story behind Nick Martin’s and my development of this method, our first attempts at applying it in a human population and more recent studies using the original and related methods to estimate trait heritability. [Keywords: Linkage; identity by descent; heritability; height; equal environments assumption]</p>'
- - https://www.nature.com/articles/436776a
  - Harry Potter and the recessive allele
  - Jeffrey M. Craig, Renee Dow, Mary-Anne Aitken
  - 2005-08-10
  - 10.1038/436776a
  - ! '<p>Wizards or witches can be of any race, and may be the offspring of a wizard and a witch, the offspring of two muggles (‘muggle-born’), or of mixed ancestry (‘half-blood’). This suggests that wizarding ability is inherited in a Mendelian fashion, with the wizard allele (W) being recessive to the muggle allele (M). According to this hypothesis, all wizards and witches therefore have two copies of the wizard allele (WW). Harry’s friends Ron Weasley and Neville Longbottom and his arch-enemy Draco Malfoy are ‘pure-blood’ wizards: WW with WW ancestors for generations back. Harry’s friend Hermione is a powerful muggle-born witch (WW with WM parents). Their classmate Seamus is a half-blood wizard, the son of a witch and a muggle (WW with one WW and one WM parent). Harry (WW with WW parents) is not considered a pure-blood, as his mother was muggle-born. There may even be examples of incomplete penetrance (Neville has poor wizarding skills) and possible mutations or questionable paternity: Filch, the caretaker, is a ‘squib’, someone born into a wizarding family but with no wizarding powers of their own.</p>'
- - https://www.bmj.com/content/335/7633/1299
  - 'Origins of magic: review of genetic and epigenetic effects'
  - Sreeram V Ramagopalan, Marian Knight, George C Ebers, Julian C Knight
  - 2007-12-20
  - 10.1136/bmj.39414.582639.BE
  - ! '<p><strong>Objective</strong>: To assess the evidence for a genetic basis to magic.</p><p><strong>Design</strong>: Literature review.</p><p><strong>Setting</strong>: <em>Harry Potter</em> novels of J. K. Rowling.</p><p><strong>Participants</strong>: Muggles, witches, wizards, and squibs.</p><p><strong>Interventions</strong>: Limited.</p><p><strong>Main outcome measures</strong>: Family and twin studies, magical ability, and specific magical skills.</p><p><strong>Results</strong>: Magic shows strong evidence of heritability, with familial aggregation and concordance in twins. Evidence suggests magical ability to be a quantitative trait. Specific magical skills, notably being able to speak to snakes, predict the future, and change hair colour, all seem heritable.</p><p><strong>Conclusions</strong>: A multi-locus model with a dominant gene for magic might exist, controlled epistatically by one or more loci, possibly recessive in nature. Magical enhancers regulating gene expression may be involved, combined with mutations at specific genes implicated in speech and hair colour such as <span class="smallcaps-auto">FOXP</span>2 and <span class="smallcaps-auto">MCR</span>1.</p>'
- - /docs/traffic/2019-aribarg.pdf
  - ! "Native Advertising in Online News: Trade-Offs Among Clicks, Brand Recognition, and Website Trustworthiness"
  - Anocha Aribarg, Eric M. Schwartz
  - 2019-11-10
  - 10.1177/0022243719879711
  - ! '<p>Native advertising is a type of online advertising that matches the form and function of the platform on which it appears. In practice, the choice between display and in-feed native advertising presents brand advertisers and online news publishers with conflicting objectives. Advertisers face a trade-off between ad clicks and brand recognition, whereas publishers need to strike a balance between ad clicks and the platform’s trustworthiness. For policy makers, concerns that native advertising confuses customers prompted the U.S. Federal Trade Commission to issue guidelines for disclosing native ads. This research aims to understand how consumers respond to native ads versus display ads and to different styles of native ad disclosures, using randomized online and field experiments combining behavioral clickstream, eye movement, and survey response data. The results show that when the position of an ad on a news page is controlled for, a native ad generates a higher click-through rate because it better resembles the surrounding editorial content. However, a display ad leads to more visual attention, brand recognition, and trustworthiness for the website than a native ad. [Keywords: native advertising, public policy, eye-tracking, field experiments, advertising disclosure]</p>'
- - /docs/traffic/2009-kaiser.pdf
  - ! "Do media consumers really dislike advertising? An empirical assessment of the role of advertising in print media markets"
  - Ulrich Kaiser; Minjae Song
  - 2009-03-01
  - 10.1016/j.ijindorg.2008.09.003
  - ! '<p>This paper uses data on German consumer magazines observed between 1992 and 2004 to analyze the extent to which consumers (dis-)like advertising. We estimate logit demand models separately for the six most important magazine segments in terms of circulation. We find little evidence for readers disliking advertising. On the contrary, we show that readers in many magazine segments appreciate advertising.</p><p>Readers of Women’s magazines, Business and politics magazines as well as Car magazines—market segments where advertisements are relatively more informative—appreciate advertising while advertising is nuisance to readers of Adult magazines, a segment where advertisements are particularly uninformative. Demand for interior design magazines is not well identified. Our logit demand estimates are confirmed by logit demand models with random coefficients and by magazine-specific monopoly demand models.</p><p>[Keywords: two-sided markets, advertising, mean group estimation, random coefficients model, media markets, nuisance]</p>'
- - /docs/genetics/selection/2020-hieber.pdf
  - ! "Inbreeding and Inbreeding Depression in Linebred Beef Cattle"
  - Jordan Hieber
  - 2020-04
  - 10.0000/proquest/aeefc400bb2f1d415c929720cd29607b
  - ! '<p>This research applied genomics and phenotypic information in three different beef cattle populations. The methods applied were association analyses, runs of homozygosity, and genetic correlations. This incorporated both genomic and phenotypic approaches to identify the results of linebreeding in two closed Hereford populations. Further work evaluated carcass and maternal traits from the American Simmental Association Carcass Merit Program using genomic and phenotypic information to identify how carcass-based selection decisions impact maternal performance of Simmental-based cattle. Line 4 pedigree inbreeding, genomic inbreeding, and genomic pedigree inbreeding ranges were 0–36%, 0–49%, and 0–29%, respectively, and average inbreeding was 12.6%, 12.3%, and 17.7%, respectively. Line 1 pedigree inbreeding, genomic inbreeding, and genomic pedigree inbreeding ranges were 0–71%, 0–46%, and 0–63%, respectively, and average inbreeding was 42.1%, 14.4%, and 31.0%, respectively. Average rate of change in inbreeding per year was 0.03% over 55 years for Line 4 and −0.03% over 83 years for Line 1. Identified for Line 4 were 45 <span class="smallcaps-auto">ROH</span> regions, 35 strongly significant single nucleotide polymorphisms, three strongly significant <span class="smallcaps-auto">SNP</span> within <span class="smallcaps-auto">ROH</span>, and some significant <span class="smallcaps-auto">SNP</span> within 12 previously identified genes. Identified for Line 1 were 50 <span class="smallcaps-auto">ROH</span> regions, 93 strongly significant <span class="smallcaps-auto">SNP</span>, three strongly significant <span class="smallcaps-auto">SNP</span> within <span class="smallcaps-auto">ROH</span>, and some significant <span class="smallcaps-auto">SNP</span> within 11 previously identified genes. Within the Simmental dataset, nine chromosomes had genome-wide significance, explaining 0.2142% of total phenotypic information. The single-locus model identified 365 novel regions and 251 novel positional candidate genes. The multi-locus model identified 393 novel regions and 283 novel positional candidate genes. Also, detrimental genetic correlations between carcass characteristics and maternal traits were less than previously reported. Analyses utilized in this study indicate <span class="smallcaps-auto">ROH</span> and significant <span class="smallcaps-auto">SNP</span> can be used to identify regions of the genome affected by inbreeding. Also, simultaneous selection for carcass and maternal traits reduced the negative impact seen with single-trait selection for carcass traits.</p>'
- - /docs/iq/2020-simonton.pdf
  - ! "Galton, Terman, Cox: The Distinctive Volume II in <em>Genetic Studies of Genius</em>"
  - Dean Keith Simonton
  - 2020-05-22
  - 10.1177/0016986220921360
  - ! '<p>With just one exception, all of the volumes in Terman’s Genetic Studies of Genius report the results of a longitudinal study of more than a thousand intellectually gifted children. That single exception is Volume II, Cox’s single-authored <em>The Early Mental Traits of Three Hundred Geniuses</em>, which instead was a retrospective study of 301 eminent creators and leaders, using historiometric methods to estimate their IQs (as well as to assess a subset of 100 on 67 character traits). This article discusses how this volume actually fits with the other four volumes in the set. After giving the historical background, discussion turns to the emergence of Cox’s doctoral dissertation. Then comes a narrative of the aftermath, including subsequent contributions by Cox, Terman, and numerous other researchers extending into the 21<sup>st</sup> century. The article closes by treating the ways that the intellectually gifted and the historic geniuses are not comparable, thus indicating the need for more recent replications and extensions of her work. [Keywords: archival, biographical, historical analysis, early childhood, gifted, intelligence]</p>'
- - /docs/iq/1957-mccurdy.pdf
  - ! "The Childhood Pattern Of Genius"
  - Harold G. McCurdy
  - 1957-11-01
  - 10.2307/24333195
  - ! '<p>In summary, the present survey of biographical information on a sample of 20 men of genius suggests that the typical developmental pattern includes as important aspects: (1) a high degree of attention focused upon the child by parents and other adults, expressed in intensive educational measures and, usually, abundant love; (2) isolation from other children, especially outside the family; and (3) a rich efflorescence of phantasy, as a reaction to the two preceding conditions. In stating these conclusions I by no means wish to imply that original endowment is an insignificant variable. On the contrary. Galton’s strong arguments on behalf of heredity appear to me to be well-founded; and in this particular sample the early promise of these very distinguished men cannot be dissociated from the unusual intellectual qualities evident in their parents and transmitted, one would suppose, genetically as well as socially to their offspring. It is upon a groundwork of inherited ability that I see the pattern operating. Whether the environmental phase of it summarized under (1) and (2) is actually causally important, and to what extent the environmental factors are related to the blossoming out of phantasy, are questions which could be examined experimentally, though obviously any thorough experiment would require both a great deal of money and a certain degree of audacity. It might be remarked that the mass education of our public school system is, in its way, a vast experiment on the effect of reducing all three of the above factors to minimal values, and should, accordingly, tend to suppress the occurrence of genius.</p>'
- - /docs/iq/1931-white.pdf
  - ! "The Versatility of Genius"
  - Ralph K. White
  - 1930-10-12
  - 10.1080/00224545.1931.9918987
  - ! '<p>The purpose of this study is twofold : (<em>a</em>) to estimate the versatility of 300 eminent men, as an indication of the extent to which specialization is favorable or unfavorable to the attainment of eminence; and (<em>b</em>) to discover what kinds of special ability are associated with certain kinds of genius, as an indication of the vocational types to be kept in mind in the education and guidance of gifted children.</p><p>…The first purpose of this study was “to estimate the versatility of three hundred eminent men, as an indication of the extent to which specialization is favorable or unfavorable to the attainment of eminence.” If bare figures told the whole story, the answer would be decisive. We could say, not only that these geniuses were not one-sided freaks, overdeveloped on one side of their natures and atrophied on all the rest, but that they were actually far more versatile than the average college graduate of today. They were judged superior to the average graduate in 2015 instances, and inferior in only 141. Even if 30% of the positive scores were disregarded because they represent abilities which contributed to eminence, and 40% more were disregarded because they represent activities which took up only a very small amount of time (these percentages are very unreliable), there would still remain 605 positive scores in contrast to the total of 141 negative scores. Positive scores would still be more than 80% of the total (746), and negative scores less than 20%.</p>'
- - /docs/iq/1978-walberg.pdf
  - ! "IQ Correlates With High Eminence"
  - Herbert J. Walberg, Sue Pinzur Rasher, Keiko Hase
  - 1978-06-01
  - 10.1177/001698627802200213
  - ! '<p>Indicators of eminence derived from word and citation counts in primary biographical articles in encyclopedias published at the turn of the century, in 1935, and 1974 correlate positively 0.33 overall with IQ estimates made from biographical sources on a select sample of 282 philosophers, scientists, non-fiction and fiction writers, musicians, artists, religious leaders, statesmen, revolutionaries, and soldiers. These results are striking since the sample is restricted to the higher end of the eminence distribution; the mean estimated IQ for the total group is 158.9. Indicators of eminence for some fields—philosophers, musicians, and artists—vary from one period to the next. Individuals also shift in estimated eminence during the three time periods examined.</p>'
- - /docs/iq/1999-rogers.pdf
  - ! "The Lifelong Productivity of the Female Researchers in Terman’s Genetic Studies of Genius Longitudinal Study"
  - Karen B. Rogers
  - 1999-07-01
  - 10.1177/001698629904300303
  - ! '<p>An analysis of information collected from historical archives reveals a wealth of data on 30 female researchers who worked in various capacities with Dr. Lewis Terman in conducting his classic longitudinal study, <em>Genetic Studies of Genius</em> (1925), on 1,528 gifted children in California. The published and unpublished papers, memoranda, and research field notes of these researchers, their respective correspondence With Terman and each other, and some contacts with a living member of the research team and family members were used for this analysis. Although the information is incomplete on some of the women, most of them appeared to have had satisfying personal lives in addition to productive professional careers. Not only did they each contribute greatly to the actual work of carrying out Terman’s research conception, they also represent a continuum of life-long productivity. Personal responsibilities nay have had more to do with their subsequent levels of productivity than societal expectations or conventions.</p>'
- - /docs/iq/1936-miles.pdf
  - ! "Childhood Physical and Mental Health Records of Historical Geniuses"
  - Catharine C. Miles, Lillian S. Wolfe
  - 1936-01-01
  - 10.1037/h0093425
  - ! '<p>The enigma of genius presents no more perplexing problems than those implied in the definition of its psychophysiological constitution. The health and more especially the mental health of men of genius has proved to be not only the most fascinating but also perhaps the most provocative question involved. Definitions of genius are generally of two kinds: in terms of intrinsic quality and in terms of extrinsic achievement. The question as to the qualifications for the highest human classification is still in the fascinatingly vague region of thought where subjective exploration attracts one to pleasant excursions without limiting effort in terms of a prescribed scientific goal. We perceive that the criterion of intrinsic quality is in an important sense more rigid than that of world recognition and we would prefer a definition which explicitly emphasizes both. Genius in the intrinsic sense demands not only “the highest conceivable form of original ability, something altogether extraordinary and beyond even supreme educational powers,” but also “inexplicable and unique endowment.” Genius in terms of achievement requires “the ability to create special values bearing a personal stamp; such values include novel ideas and forms of expression and the production of factors which initiate new historical efforts.” The studies of many investigators seem to show that a rigid definition of the intrinsic kind makes objective agreement regarding any considerable group of qualifying persons practically impossible. Results, in terms of the names of geniuses, selected with primary emphasis on qualitative divergences in endowment indicate that common agreement is not attainable for any very large number of persons in recent or in more remote centuries. It would perhaps prove more interesting and would seem to some also more profitable if there were in the qualitative sense of unique superiority a group of “certified geniuses” to whom study could be devoted. Because there is no recognized group of this kind, one must attempt either subjectively to select in terms of uniqueness of endowment as Lombroso, Lange-Eichbaum, and Nisbet have done, or else objectively to measure in terms of eminent achievement following the method of Galton, Ellis, and Cattell. For the present study we have followed the second course. This procedure implies what is perhaps a less rigorous definition of genius but it offers a more objective method, depending as it does upon the world’s cumulatively discriminating estimate with respect to eminence.</p><p>…It is not essential that our scale agree with Olson’s at every point. The significant finding in the comparison is, we believe? The evidence which it gives that the mental health of 50 geniuses was on the average no less satisfactory than is shown by unselected children today. If there is a subtle relationship between genius and insanity it is not shown in the childhood records of this group of 50.</p>'
- - /docs/nicotine/1989-petrie.pdf
  - ! "Smoking and human information processing"
  - Rachel X. A. Petrie, Ian J. Deary
  - 1989-11-01
  - 10.1007/BF00445565
  - ! '<p>There is much evidence which indicates that smoking improves various aspects of human information processing (Wesnes 1987). The aim of the present study was to elucidate the stages of human information processing which are improved after cigarette smoking. Twelve regular smokers were tested on three cognitive tasks using a repeated measures design. Tasks used were: rapid visual information processing (<span class="smallcaps-auto">RVIP</span>), digit symbol substitution (<span class="smallcaps-auto">DSST</span>), and inspection time (IT). Performance parameters derived from these were intended to index different stages of the information processing sequence. Only those measures which involved a motor component were improved after smoking: response time on the <span class="smallcaps-auto">RVIP</span> task (<em>p</em>&lt;0.025) and <span class="smallcaps-auto">DSST</span> performance (<em>p</em>&lt;0.1). These findings suggest that central cholinergic pathways are involved in the late, response-related stages of the processing sequence.</p>'
- - /docs/nicotine/1994-pickworth.pdf
  - ! "Transdermal nicotine: reduction of smoking with minimal abuse liability"
  - Wallace B. Pickworth, Edward B. Bunker, Jack E. Henningfield
  - 1994-01-01
  - 10.1007/bf02244745
  - ! '<p>Cigarette consumption as well as the physiologic, performance and subjective effects of the nicotine patch were evaluated in ten subjects who smoked ad libitum while residing on a residential research ward for 30 days. Nicotine transdermal systems (“patches”) delivering a total of 0, 22 or 44 mg per 24h were applied daily at a constant dose during each 7-day condition; the order of dosing conditions was varied according to a randomized, double-blind, crossover design. Nicotine patches significantly but modestly reduced spontaneous smoking and significantly increased venous plasma nicotine levels. Self ratings of patch liking, satisfaction with cigarettes and the ability to identify the patch condition did not change as a function of the nicotine dose, indicating minimal abuse liability. There were no consistent changes in the puffing pattern measures; however, in all patch conditions, subjects with extensive histories of illicit drug use smoked cigarettes faster than subjects with histories of occasional drug use. Small changes in resting heart rate, pulse and blood pressure occurred when the nicotine patch was worn. Thus large changes in venous plasma nicotine levels engender only modest changes in ad libitum cigarette consumption, measures of abuse liability and cardiovascular effects. These findings are consistent with the notion that the addictive and toxic effects of nicotine are partially determined by the rate of drug administration.</p>'
- - /docs/nicotine/1994-warburton.pdf
  - ! "Improvements in performance without nicotine withdrawal"
  - David M. Warburton, Cliff Arnall
  - 1994-01-01
  - 10.1007/bf02245578
  - ! '<p>Two tests were made of the withdrawal-relief explanation of the improvements in performance obtained with smoking. Study 1 examined the extent to which abstinence from smoking produced poorer performance in smokers in comparison with non-smokers. No evidence was obtained of differences in performance in smokers who were deprived of cigarettes for 10h and non-smokers. Study 2 tested smokers with a standard cigarette or sham smoking after one hour and 12h of deprivation. There was no difference in performance for the two deprivation intervals either in the sham smoking condition, or after smoking the lit cigarette. This study gave no evidence for withdrawal-relief being an explanation of the improvements in performance obtained with smoking.</p>'
- - /docs/ai/1962-kelley.pdf
  - ! "Method of Gradients"
  - Henry J. Kelley
  - 1962-01-01
  - 10.1016/S0076-5392(08)62094-9
  - ! '<p>The method of gradients also known as method of steepest descent is an elementary concept for the solution of minimum problems. In recent years the computational appeal of the method has led to its adoption in a variety of application such as multivariable minimum problems of ordinary calculus, solution of systems of algebraic equations, integral equations, and variational problems. This chapter begins with a discussion of the main features of the gradient method in the context of ordinary minimum problems subject to constraints. It also discusses the variational problems of flight performance, introducing Green’s functions in the role played by partial derivatives in ordinary minimum problems and attempting to preserve an analogy between the two classes of problems in the subsequent development. The close relationship between Green’s functions or influence functions and the error coefficients of guidance theory has drawn attention to the usefulness of the adjoint system technique in guidance analysis.</p>'
- - /docs/ai/1963-kelley.pdf
  - ! "Singular Extremals In Lawden's Problem Of Optimal Rocket Flight"
  - Henry J. Kelley
  - 1963-07-01
  - 10.2514/3.1859
  - ! '<p>The problem of optimal rocket flight in an inverse square law force field has been studied extensively by Lawden and Leitmann. Periods of zero thrust, intermediate thrust, and maximum thrust are possible subarcs of the solution according to analysis of the Euler-Lagrange equations and the Weierstrass necessary condition. Arcs of intermediate thrust have been examined recently by Lawden; however, the question of whether or not such arcs actually may furnish a minimum has been left unresolved. The present paper derives the singular extremals of Lawden’s problem by means of the Legendre-Clebsch necessary condition applied in a transformed system of state and control variables.</p><p>These are obtained as circular orbits along which the thrust is zero and intermediate thrust arcs are found in Lawden’s analysis.Since these solutions satisfy only the weak form of the Legendre-Clebsch condition, i.e., the extremals are singular in the transformed system of variables, the question of their minimality remains unanswered.</p>'
- - /docs/genetics/editing/2020-beying.pdf
  - ! "CRISPR–Cas9-mediated induction of heritable chromosomal translocations in Arabidopsis"
  - Natalja Beying, Carla Schmidt, Michael Pacher, Andreas Houben, Holger Puchta
  - 2020-05-25
  - 10.1038/s41477-020-0663-x
  - ! '<p>Clustered regularly interspaced short palindromic repeats (<span class="smallcaps-auto">CRISPR</span>)–<span class="smallcaps-auto">CRISPR</span>-associated protein (Cas) technology has been applied in plant breeding mainly on genes for improving single or multiple traits<sup>1,2,3,4</sup>. Here we show that this technology can also be used to restructure plant chromosomes. Using the Cas9 nuclease from Staphylococcus aureus<sup>5</sup>, we were able to induce reciprocal translocations in the Mbp range between heterologous chromosomes in <em>Arabidopsis thaliana</em>. Of note, translocation frequency was about five times more efficient in the absence of the classical non-homologous end-joining pathway. Using egg-cell-specific expression of the Cas9 nuclease and consecutive bulk screening, we were able to isolate heritable events and establish lines homozygous for the translocation, reaching frequencies up to 2.5% for individual lines. Using molecular and cytological analysis, we confirmed that the chromosome-arm exchanges we obtained between chromosomes 1 and 2 and between chromosomes 1 and 5 of <em>Arabidopsis</em> were conservative and reciprocal. The induction of chromosomal translocations enables mimicking of genome evolution or modification of chromosomes in a directed manner, fixing or breaking genetic linkages between traits on different chromosomes. Controlled restructuring of plant genomes has the potential to transform plant breeding.</p>'
- - /docs/iq/2020-zigerell.pdf
  - ! "US Public Perceptions of an Intelligence Quotient Test Score Gap Between Black Americans and White Americans"
  - LJ Zigerell
  - 2020-05-27
  - 10.1177/1478929920917843
  - ! '<p>Intelligence quotient (IQ) is a common measure of intelligence that associates with many important life outcomes. Research over several decades has indicated that the average IQ test score among Black Americans is lower than the average IQ test score among White Americans, but in weighted results from a national nonprobability survey, only about 41% of US adults indicated awareness of this IQ gap. Results from a follow-up convenience survey indicated that, in the aggregate, White participants’ rating of White Americans’ average IQ and average intelligence is higher than Blacks Americans’ average IQ test score and average intelligence and was not driven by White participants’ belief in a universal White intellectual superiority. These and other results could have implications regarding the US public’s perceptions about the reasons for Black/White inequality and implications for the use of intelligence stereotype scales as measures of racial prejudice. [Keywords: intelligence quotient, IQ, intelligence, stereotypes, race, perceptions, inequality]</p>'
- - /docs/economics/2015-bronnenberg.pdf
  - ! "Do Pharmacists Buy Bayer? Informed Shoppers and the Brand Premium"
  - Bart J. Bronnenberg, Jean-Pierre Dubé, Matthew Gentzkow, Jesse M. Shapiro
  - 2015-07-15
  - 10.1093/qje/qjv024
  - ! '<p>We estimate the effect of information and expertise on consumers’ willingness to pay for national brands in physically homogeneous product categories. In a detailed case study of headache remedies, we find that more informed or expert consumers are less likely to pay extra to buy national brands, with pharmacists choosing them over store brands only 9% of the time, compared to 26% of the time for the average consumer. In a similar case study of pantry staples such as salt and sugar, we show that chefs devote 12 percentage points less of their purchases to national brands than demographically similar non-chefs. We extend our analysis to cover 50 retail health categories and 241 food and drink categories. The results suggest that misinformation and related consumer mistakes explain a sizable share of the brand premium for health products, and a much smaller share for most food and drink products. We tie our estimates together using a stylized model of demand and pricing.</p>'
- - /docs/sociology/2020-ostling.pdf
  - ! "Association Between Lottery Prize Size and Self-reported Health Habits in Swedish Lottery Players"
  - Robert Östling, David Cesarini, Erik Lindqvist
  - 2020-03-19
  - 10.1001/jamanetworkopen.2019.19713
  - ! '<p><strong>Key Points</strong>:</p><ul><li><strong>Question</strong>: Is unearned wealth from lottery winnings associated with more healthy habits and better overall health?</li><li><strong>Findings</strong>: This quasi-experimental cohort study of 3344 individuals in 3 Swedish lotteries found no statistically significant differences in long-term (5–22 years) health behaviors or overall health among individuals who participated in the same lottery but who randomly won prizes of different magnitudes.</li><li><strong>Meaning</strong>: The findings suggest that large, random transfers of unearned wealth are unlikely to be associated with large, long-term changes in health habits or overall health.</li></ul><p><strong>Abstract</strong>:</p><ul><li><strong>Importance</strong>: Poor health and unhealthy lifestyles are substantially more prevalent among individuals with low income than among individuals with high income, but the underlying mechanisms are not well understood.</li><li><strong>Objective</strong>: To evaluate whether changes to unearned wealth from lotteries are associated with long-term health behaviors and overall health.</li><li><strong>Design, Setting, and Participants</strong>: In this quasi-experimental cohort study, 4820 participants (aged 18–70 years at the time of winning) in 3 Swedish lotteries were surveyed from September 1, 2016, to November 11, 2016, between 5 and 22 years after a lottery event. Outcomes of participants in the same lottery who were randomly assigned prizes of different magnitudes by the lotteries but were ex ante identical in terms of their probability of winning different prizes were compared. Data were analyzed from December 22, 2016, to November 21, 2019.</li><li><strong>Exposures</strong>: Lottery prizes ranged from $0 for nonwinning players to $1.6 million.</li><li><strong>Main Outcomes and Measures</strong>: 4 lifestyle factors (smoking, alcohol consumption, physical activity, and a healthy diet index) and 2 measures of overall health (subjective health and an index of total health derived from responses to questions about 35 health conditions).</li><li><strong>Results</strong>: The survey was returned by 3344 of 4820 individuals (69%; 1722 [51.5%] male), which corresponded to 3362 observations. The mean (SD) age was 48 (11.8) years in the year of the lottery win and 60 (11.0) years at the time of the survey. There were no statistically significant associations between prize amount won and any of the 6 long-term health outcomes. Estimated associations expressed in SD units per $100 000 won were as follows: smoking (−0.006, 95% CI, −0.038 to 0.026); alcohol consumption (0.003, 95% CI, −0.027 to 0.033); physical activity (0.001, 95% CI, −0.029 to 0.032); dietary quality (−0.007, 95% CI, −0.040 to 0.026); subjective health (0.013, 95% CI, −0.017 to 0.043); and index of total health (−0.003, 95% CI, −0.033 to 0.027).</li><li><strong>Conclusions and Relevance</strong>: In this study of Swedish lottery players, unearned wealth from random lottery prize winnings was not associated with subsequent healthy lifestyle factors or overall health. The findings suggest that large, random transfers of unearned wealth are unlikely to be associated with large, long-term changes in health habits or overall health.</li></ul>'
- - /docs/modafinil/2020-rohde.pdf
  - ! "The use of stimulants in depression: Results from a self-controlled register study"
  - Christopher Rohde, Philip Brink, Søren D. Østergaard, Jimmi Nielsen
  - 2020-05-23
  - 10.1177/0004867420924076
  - ! '<p><strong>Objective</strong>: To investigate the effectiveness of stimulants in patients with depression, by using naturalistic outcome measures, such as psychiatric admissions, psychiatric bed-days and incidents of intentional self-harm or suicide attempts.</p><p><strong>Methods</strong>: Via linkage of the Danish nationwide health registers, we identified all patients with a diagnosis of depression initiating stimulants, including methylphenidate, modafinil, amphetamine, dexamphetamine or lisdexamphetamine, from 1995 to 2012. We used a mirror-image model to test whether redemption of a stimulant prescription was associated with a reduction in psychiatric admissions, inpatient days and incidents of intentional self-harm or suicide attempts. Specifically, the number of these outcomes in the 2 years leading up to redemption of a stimulant prescription was compared to the two subsequent years. Similar outcomes were used in a reverse mirror-image model to investigate the effect of stimulant termination.</p><p><strong>Results</strong>: A total of 3354, 935 and 105 patients diagnosed with depression redeemed prescriptions for methylphenidate, modafinil or amphetamine/dexamphetamine/lisdexamphetamine, respectively. Initiation of methylphenidate was not associated with a significant change in psychiatric admissions (mean: −0.02 admissions, <em>p</em> = 0.11) or inpatient days (mean: 0.13  days, <em>p</em> = 0.74). Similar findings were made for modafinil and the amphetamines. In addition, no clinically relevant change in psychiatric admissions or inpatient days was found after termination of a stimulant. After initiation of methylphenidate, the incidents of self-harm or suicide attempts were reduced by 54%, from 68 to 31 events (<em>p</em> = 0.004). No significant change in incidents of self-harm or suicide attempts were found for modafinil or the amphetamines.</p><p><strong>Conclusion</strong>: This nationwide study, using naturalistic outcomes, does not support the use of stimulants in patients with depression. However, the use of methylphenidate was associated with a 54% reduction in incidents of self-harm or suicide attempts, indicating that methylphenidate may potentially be useful in patients with depression with suicidal- or self-harming behaviour. However, further studies are needed, before any firm conclusions can be made. [Keywords: Depression, methylphenidate, modafinil, amphetamines, self-injurious behaviour]</p>'
- - /docs/sociology/2020-oster.pdf
  - ! "Health Recommendations and Selection in Health Behaviors"
  - Emily Oster
  - 2020-06-01
  - 10.1257/aeri.20190355
  - ! '<p>Consider a case in which a new research finding links a health behavior with good health outcomes. A possible consequence is take-up of this behavior among individuals who engage in other positive health behaviors. If this occurs, later analyses of observational data may be biased by the change in selection. This paper evaluates these dynamic biases in empirical settings. Using data from vitamin supplementation and diet, I show that selection responds endogenously to health recommendations. These results highlight how spurious findings on health behaviors can be self-reinforcing.</p><p>[Examples: vitamin E, vitamin D, sugar consumption, fat consumption, and the Mediterranean diet.]'
- - /docs/psychology/2020-levitt.pdf
  - ! "Heads or Tails: The Impact of a Coin Toss on Major Life Decisions and Subsequent Happiness"
  - Steven D. Levitt
  - 2020-05-19
  - 10.1093/restud/rdaa016
  - ! '<p>Little is known about whether people make good choices when facing important decisions. This article reports on a large-scale randomized <a href="https://www.freakonomicsexperiments.com/">field experiment</a> in which research subjects having difficulty making a decision flipped a coin to help determine their choice. For important decisions (e.g. quitting a job or ending a relationship), individuals who are told by the coin toss to make a change are more likely to make a change, more satisfied with their decisions, and happier six months later than those whose coin toss instructed maintaining the status quo. This finding suggests that people may be excessively cautious when facing life-changing choices. [Keywords: quitting, happiness, decision biases.]</p>'
- - /docs/rl/2018-eslami.pdf#deepmind
  - ! "Neural scene representation and rendering"
  - S. M. Ali Eslami, Danilo Jimenez Rezende, Frederic Besse, Fabio Viola, Ari S. Morcos, Marta Garnelo, Avraham Ruderman, Andrei A. Rusu, Ivo Danihelka, Karol Gregor, David P. Reichert, Lars Buesing, Theophane Weber, Oriol Vinyals, Dan Rosenbaum, Neil Rabinowitz, Helen King, Chloe Hillier, Matt Botvinick, Daan Wierstra, Koray Kavukcuoglu, Demis Hassabis
  - 2018-06-15
  - 10.1126/science.aar6170
  - ! '<p><strong>A scene-internalizing computer program</strong>: To train a computer to “recognize” elements of a scene supplied by its visual sensors, computer scientists typically use millions of images painstakingly labeled by humans. Eslami et al. developed an artificial vision system, dubbed the Generative Query Network (<span class="smallcaps-auto">GQN</span>), that has no need for such labeled data. Instead, the <span class="smallcaps-auto">GQN</span> first uses images taken from different viewpoints and creates an abstract description of the scene, learning its essentials. Next, on the basis of this representation, the network predicts what the scene would look like from a new, arbitrary viewpoint.</p><p><strong>Abstract</strong>: Scene representation—the process of converting visual sensory data into concise descriptions—is a requirement for intelligent behavior. Recent work has shown that neural networks excel at this task when provided with large, labeled datasets. However, removing the reliance on human labeling remains an important open problem. To this end, we introduce the Generative Query Network (<span class="smallcaps-auto">GQN</span>), a framework within which machines learn to represent scenes using only their own sensors. The <span class="smallcaps-auto">GQN</span> takes as input images of a scene taken from different viewpoints, constructs an internal representation, and uses this representation to predict the appearance of that scene from previously unobserved viewpoints. The <span class="smallcaps-auto">GQN</span> demonstrates representation learning without human labels or domain knowledge, paving the way toward machines that autonomously learn to understand the world around them.</p>'
- - https://www.medrxiv.org/content/10.1101/2020.05.18.20100685v2
  - <span class=\"smallcaps-auto\">GWAS</span> of Depression Phenotypes in the Million Veteran Program and Meta-analysis in More than 1.2 Million Participants Yields 178 Independent Risk Loci
  - Daniel F. Levey, Murray B. Stein, Frank R. Wendt, Gita A. Pathak, Hang Zhou, Mihaela Aslan, Rachel Quaden, Kelly M. Harrington, Gerard Sanacora, Andrew M. McIntosh, John Concato, Renato Polimanti, Joel Gelernter, on behalf of the Million Veteran Program
  - 2020-05-22
  - 10.1101/2020.05.18.20100685
  - ! '<p>We report a large meta-analysis of depression using data from the Million Veteran Program (<span class="smallcaps-auto">MVP</span>), 23andMe Inc., UK Biobank, and FinnGen; including individuals of European ancestry (<em>n</em>=1,154,267; 340,591 cases) and African ancestry (<em>n</em>=59,600; 25,843 cases). We identified 223 and 233 independent <span class="smallcaps-auto">SNP</span>s associated with depression in European ancestry and transancestral analysis, respectively. Genetic correlations within the <span class="smallcaps-auto">MVP</span> cohort across electronic health records diagnosis, survey self-report of diagnosis, and a 2-item depression screen exceeded 0.81. Using transcriptome-wide association study (<span class="smallcaps-auto">TWAS</span>) we found significant associations for gene expression in several brain regions, including hypothalamus (<span class="smallcaps-auto">NEGR</span>1, <em>p</em>=3.19×10<sup>−25</sup>) and nucleus accumbens (<span class="smallcaps-auto">DRD</span>2, <em>p</em>=1.87×10<sup>−20</sup>). 178 genomic risk loci were fine-mapped to find likely causal variants. We identified likely pathogenicity in these variants and overlapping gene expression for 17 genes from our <span class="smallcaps-auto">TWAS</span>, including <span class="smallcaps-auto">TRAF</span>3. This study sheds light on the genetic architecture of depression and provides new insight into the interrelatedness of complex psychiatric traits.</p>'
- - https://www.nature.com/articles/ejhg2017105
  - Sexual dimorphism in the genetic influence on human childlessness
  - Renske M. Verweij, Melinda C. Mills, Felix C. Tropf, René Veenstra, Anastasia Nyman, Harold Snieder
  - 2017-07-05
  - 10.1038/ejhg.2017.105
  - ! '<p>Previous research has found a genetic component of human reproduction and childlessness. Others have argued that the heritability of reproduction is counterintuitive due to a frequent misinterpretation that additive genetic variance in reproductive fitness should be close to zero. Yet it is plausible that different genetic loci operate in male and female fertility in the form of sexual dimorphism and that these genes are passed on to the next generation. This study examines the extent to which genetic factors influence childlessness and provides an empirical test of genetic sexual dimorphism. Data from the Swedish Twin Register (<em>N</em>=9942) is used to estimate a classical twin model, a genomic-relatedness-matrix restricted maximum likelihood (<span class="smallcaps-auto">GREML</span>) model on twins and estimates polygenic scores of age at first birth on childlessness. Results show that the variation in individual differences in childlessness is explained by genetic differences for 47% in the twin model and 59% for women and 56% for men using the <span class="smallcaps-auto">GREML</span> model. Using a polygenic score (<span class="smallcaps-auto">PGS</span>) of age at first birth (<span class="smallcaps-auto">AFB</span>), the odds of remaining childless are around 1.25 higher for individuals with 1 SD higher score on the <span class="smallcaps-auto">AFB</span> <span class="smallcaps-auto">PGS</span>, but only for women. We find that different sets of genes influence childlessness in men and in women. These findings provide insight into why people remain childless and give evidence of genetic sexual dimorphism.</p>'
- - https://www.goodreads.com/review/show/3231032913
  - ! 'Review of <em>The Battle Between the Frogs and the Mice: A Tiny Homeric Epic</em>, Stallings 2019'
  - Gwern Branwen
  - 2020-05-30
  - ''
  - ! '<p>Review of new translation of a well-known but now-neglected <a href="https://en.wikipedia.org/wiki/Batrachomyomachia">ancient Greek satirical poem</a> parodying the Homeric epics. Stallings’s rhymed-couplet translation is winsome and charming, preserving the too-cute names and bathos, and pairs well with Grant Silverstein’s energetic pencil drawings. A light and enjoyable read.</p>'
- - https://slatestarcodex.com/2020/05/26/my-immortal-as-alchemical-allegory/
  - '<em>My Immortal</em> As Alchemical Allegory'
  - Scott Alexander (<span class=\"smallcaps-auto\">SSC</span>)
  - 2020-05-26
  - ''
  - ! '<p>[Mock-serious literary exegesis by the author of <a href="http://unsongbook.com/"><em>Unsong</em></a> of infamously-bad <em>Harry Potter</em> fanfiction <a href="https://en.wikipedia.org/wiki/My_Immortal_(fan_fiction)">“My Immortal”</a>; Alexander sets out to try to explain the plot as a cunningly-concealed allegory of a <a href="https://en.wikipedia.org/wiki/Rosicrucianism">Rosicrucian</a> initiate’s failure to carry through the great work of <a href="https://en.wikipedia.org/wiki/Alchemy">alchemy</a> and a revision of <a href="https://en.wikipedia.org/wiki/Johann_Wolfgang_von_Goethe">Goethe’s</a> <a href="https://en.wikipedia.org/wiki/Faust,_Part_Two"><em>Faust Part II</em></a>, drawing on <a href="https://en.wikipedia.org/wiki/Carl_Jung">Carl Jung’s</a> interpretation of alchemy as a metaphor for spiritual transformation. As such, this explains the heavy color symbolism, the protagonist’s failure to consummate her relationship with Draco Malfoy, the author’s inability to distinguish Harry Potter from Rubeus Hagrid, the fourth-wall-breaking towards the end, and the ending itself, in which the protagonist, a self-insert of the author, escapes death and is reborn as the author herself.]</p>'
- - https://rootsofprogress.org/draining-the-swamp
  - 'Draining the swamp: How sanitation conquered disease long before vaccines or antibiotics'
  - Jason Crawford
  - 2020-01-28
  - ''
  - ! '[Public health history review: as famous as vaccines and antibiotics were, deaths from infectious diseases had been declining for centuries before hand, and vaccines/antibiotics merely helped continue the decline without representing a major trend break. Such trends date back to long before the vindication of germ theory, as incorrect theories like miasmas nevertheless led to effective sanitation and cleanliness interventions which <em>did</em> reduce disease: "the mortality data points to a large and easy-to-underappreciate role of pest control, water sanitation, food handling, and general hygiene."]'
- - /docs/rl/2018-silver.pdf#deepmind
  - ! "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play"
  - David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis
  - 2018-12-07
  - 10.1126/science.aar6404
  - ! '<p>The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.</p>'
- - https://openai.com/blog/procgen-benchmark/
  - 'Procgen Benchmark: We’re releasing Procgen Benchmark, 16 simple-to-use procedurally-generated environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable skills'
  - Karl Cobbe, Christopher Hesse, Jacob Hilton, John Schulman
  - 2019-12-03
  - ''
  - ! '<p>Announcement of <a href="https://github.com/openai/procgen" title="Procgen Benchmark: Procedurally-Generated Game-Like Gym-Environments">Procgen</a>: <a href="https://arxiv.org/abs/1912.01588#openai">“Leveraging Procedural Generation to Benchmark Reinforcement Learning”</a>, Cobbe et al 2019:</p><blockquote><p>In this report, we introduce Procgen Benchmark, a suite of 16 procedurally generated game-like environments designed to benchmark both sample efficiency and generalization in reinforcement learning. We believe that the community will benefit from increased access to high quality training environments, and we provide detailed experimental protocols for using this benchmark. We empirically demonstrate that diverse environment distributions are essential to adequately train and evaluate RL agents, thereby motivating the extensive use of procedural content generation. We then use this benchmark to investigate the effects of scaling model size, finding that larger models significantly improve both sample efficiency and generalization.</p></blockquote><p>…We want the best of both worlds: a benchmark comprised of many diverse environments, each of which fundamentally requires generalization. To fulfill this need, we have created Procgen Benchmark. <a href="https://openai.com/blog/quantifying-generalization-in-reinforcement-learning/" title="Quantifying Generalization in Reinforcement Learning: We’re releasing CoinRun, a training environment which provides a metric for an agent’s ability to transfer its experience to novel situations and has already helped clarify a longstanding puzzle in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art algorithms.">CoinRun</a> [<a href="https://arxiv.org/abs/1812.02341#openai" title="Quantifying Generalization in Reinforcement Learning">Cobbe et al 2018</a>] now serves as the inaugural environment in Procgen Benchmark, contributing its diversity to a greater whole.</p><p>…We’ve found that all of the Procgen environments require training on 500–1000 different levels before they can generalize to new levels, which suggests that standard RL benchmarks need much more diversity within each environment. Procgen Benchmark has become the standard research platform used by the OpenAI RL team, and we hope that it accelerates the community in creating better RL algorithms.</p>'
- - https://www.nytimes.com/2020/04/09/us/politics/amish-coronavirus-ohio.html
  - "In Ohio, the Amish Take On the Coronavirus: A famously traditional community has mobilized to help hospitals with medical supplies, even as it struggles with reconciling its communal way of life with the dictates of social distancing."
  - Elizabeth Williamson (<span class=\"smallcaps-auto\">NYT</span>)
  - 2020-04-09
  - ''
  - ! '<p>On April 1, John Miller, a manufacturer here with deep connections to the close-knit Amish community of Central Ohio, got a call from Cleveland Clinic. The hospital system was struggling to find protective face masks for its 55,000 employees, plus visitors. Could his team sew 12,000 masks in two days?</p><p>He appealed to Abe Troyer with Keim, a local lumber mill and home goods business and a leader in the Amish community: “Abe, make a sewing frolic.” A frolic, Mr. Miller explained, “is a colloquial term here that means, ‘Get a bunch of people. Throw a bunch of people at this.’” A day later, Mr. Troyer had signed up 60 Amish home seamstresses, and the Cleveland Clinic sewing frolic was on.</p><p>…the pandemic has idled hundreds of Amish seamstresses, craftsmen and artisans, and Amish people do not apply for federal unemployment benefits…Almost overnight, a group of local industry, community and church leaders has mobilized to sustain Amish households by pivoting to work crafting thousands of face masks and shields, surgical gowns and protective garments from medical-grade materials. When those run scarce, they switch to using gaily printed quilting fabric and waterproof Tyvek house wrap.</p><p>…Berlin Gardens, which normally makes garden furniture from recycled plastic milk jugs, completed their first order of 20,000 plastic face shields for Yale New Haven Hospital last month. “We’re close to 100,000 a day,” Sam Yoder, the current owner of Berlin Gardens, said last Friday. “It almost covers our payroll. Not quite.”…Cleveland Clinic has since increased its order to 10,000 masks a day, Ms. Sandhu said, and has also ordered protective gowns…From her sunny sewing room outside Charm, Gladys Beachy will coordinate 9 women, including her widowed mother, who will sew 500 masks each. She can’t help thinking that holding “a quilting” would make the repetitive job more interesting for all of them.</p>'
- - https://nv-tlabs.github.io/gameGAN/
  - Learning to Simulate Dynamic Environments with Game<span class=\"smallcaps-auto\">GAN</span>
  - Seung Wook Kim, Yuhao Zhou, Jonah Philion, Antonio Torralba, Sanja Fidler (Nvidia)
  - 2020-05
  - ''
  - ! '[Project page for Game<span class=\"smallcaps-auto\">GAN</span>, a <span class=\"smallcaps-auto\">GAN</span> which can learn and model a playable arcade game such as <em>Pac-Man</em>. This landing page includes diagrams, videos demonstrating Game<span class=\"smallcaps-auto\">GAN</span> trained on the official version of <em>Pac-Man</em>, Game<span class=\"smallcaps-auto\">GAN</span> trained on a custom version of <em>Pac-Man</em> and VizDoom, Game<span class=\"smallcaps-auto\">GAN</span> trained with memory module & disentangling rendering engine, and swapping foreground / background.]'
- - https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html#openai
  - 'Meta-Learning: Learning to Learn Fast'
  - Lilian Weng
  - 2019-11-30
  - ''
  - ! '<p>Meta-learning, also known as “learning to learn”, intends to design models that can learn new skills or adapt to new environments rapidly with a few training examples. There are three common approaches: 1. learn an efficient distance metric (metric-based); 2. use (recurrent) network with external or internal memory (model-based); 3. optimize the model parameters explicitly for fast learning (optimization-based).</p><p>…We expect a good meta-learning model capable of well adapting or generalizing to new tasks and new environments that have never been encountered during training time. The adaptation process, essentially a mini learning session, happens during test but with a limited exposure to the new task configurations. Eventually, the adapted model can complete new tasks. This is why meta-learning is also known as <a href="https://science.sciencemag.org/content/350/6266/1332/" title="&#39;Human-level concept learning through probabilistic program induction&#39;, Lake et al 2015">learning to learn</a>.</p><p>Define the Meta-Learning Problem · A Simple View · Training in the Same Way as Testing · Learner and Meta-Learner · Common Approaches · Metric-Based · Convolutional Siamese Neural Network · Matching Networks · Simple Embedding · Full Context Embeddings · Relation Network · Prototypical Networks · Model-Based · Memory-Augmented Neural Networks · <span class="smallcaps-auto">MANN</span> for Meta-Learning · Addressing Mechanism for Meta-Learning · Meta Networks · Fast Weights · Model Components · Training Process · Optimization-Based · <span class="smallcaps-auto">LSTM</span> Meta-Learner · Why <span class="smallcaps-auto">LSTM</span>? · Model Setup · <span class="smallcaps-auto">MAML</span> · First-Order <span class="smallcaps-auto">MAML</span> · Reptile · The Optimization Assumption · Reptile vs <span class="smallcaps-auto">FOMAML</span> · Reference</p>'
- - https://distill.pub/2020/bayesian-optimization/
  - "Exploring Bayesian Optimization: Breaking Bayesian Optimization into small, sizeable chunks"
  - Apoorv Agnihotri, Nipun Batra (Distill.pub)
  - 2020-05-05
  - 10.23915/distill.00026
  - '<p>[Discussion of Bayesian optimization (BO), a decision-theoretic application of Bayesian statistics (typically using Gaussian processes for flexibility) which tries to model a set of variables to find the maximum or best in the fewest number of collected data points possible. This differs from normal experiment design which tries to simply maximize the overall information about all points given a fixed number of samples, not just the best point, or “active learning”, which tries to select data points which make the model as predictive as possible while collecting samples. The difference can be visualized by watching posterior distributions for simple 2D problems evolve as data is collected according to different BO or active learning or simple grid-search/random baseline strategies. The optimal strategy is usually infeasible to calculate, so various heuristics like “expected improvement” or “Thompson sampling” are used, and their different behavior can be visualized and compared. BO is heavily used in machine learning to find the best combinations of settings for machine learning models.]</p><p>In this article, we looked at Bayesian Optimization for optimizing a black-box function. Bayesian Optimization is well suited when the function evaluations are expensive, making grid or exhaustive search impractical. We looked at the key components of Bayesian Optimization. First, we looked at the notion of using a surrogate function (with a prior over the space of objective functions) to model our black-box function. Next, we looked at the “Bayes” in Bayesian Optimization — the function evaluations are used as data to obtain the surrogate posterior. We look at acquisition functions, which are functions of the surrogate posterior and are optimized sequentially. This new sequential optimization is inexpensive and thus of utility of us. We also looked at a few acquisition functions and showed how these different functions balance exploration and exploitation. Finally, we looked at some practical examples of Bayesian Optimization for optimizing hyper-parameters for machine learning models.</p>'
- - https://www.microsoft.com/en-us/research/blog/zero-2-deepspeed-shattering-barriers-of-deep-learning-speed-scale/
  - 'ZeRO-2 & DeepSpeed: Shattering barriers of deep learning speed & scale'
  - DeepSpeed Team (MS)
  - 2020-05-19
  - ''
  - ! '<p>Today, we are happy to share our new findings and results as we introduce the improved ZeRO-2 and further developments with DeepSpeed:</p><ul><li>An <em>order-of-magnitude larger and faster training</em> with ZeRO-2: ZeRO-2 expands the scope of memory optimizations in the original ZeRO by tackling the full spectrum of memory consumption during training. More specifically, ZeRO-2 introduces new technology to reduce the memory footprint of gradients, activation memory, and fragmented memory, in addition to optimizer state memory optimization in the original ZeRO. Altogether, the memory savings empower DeepSpeed to improve the scale and speed of deep learning training by an order of magnitude. More concretely, ZeRO-2 allows training models as large as 170 billion parameters up to 10× faster compared to state of the art.</li><li><em>Fastest <span class="smallcaps-auto">BERT</span> training</em>: While ZeRO-2 optimizes large models during distributed training, we also introduce new technology to accelerate single <span class="smallcaps-auto">GPU</span> performance via kernel optimizations. These optimizations not only create a strong foundation for scaling out large models, but also improve the single <span class="smallcaps-auto">GPU</span> performance of highly tuned and moderately sized models like <span class="smallcaps-auto">BERT</span> by more than 30%, reaching a staggering performance of 64 teraflops per V100 <span class="smallcaps-auto">GPU</span>, which is over 50% of the hardware peak. Using these optimizations as the building block, DeepSpeed achieves the fastest <span class="smallcaps-auto">BERT</span> training record: 44 minutes on 1,024 <span class="smallcaps-auto">NVIDIA</span> V100 <span class="smallcaps-auto">GPU</span>s, compared with the best published result of 67 minutes on the same number and generation of <span class="smallcaps-auto">GPU</span>s.</li></ul><p>…ZeRO-2: Training models with 100 billion parameters up to 10× faster:</p><ol type="1"><li><em>Model scale</em>: State-of-the-art large models (trained without using ZeRO) such as OpenAI <span class="smallcaps-auto">GPT</span>-2, <span class="smallcaps-auto">NVIDIA</span> Megatron-LM, and Google T5 have sizes of 1.5B, 8.3B, and 11B parameters respectively. ZeRO-2 provides system capability to efficiently run models of 170 billion parameters, an order-of-magnitude bigger than these largest models (Figure 2, top left). The tests were conducted using 400 <span class="smallcaps-auto">NVIDIA</span> V100 <span class="smallcaps-auto">GPU</span>s; with more devices (such as 1,000 <span class="smallcaps-auto">GPU</span>s), ZeRO-2 allows us to scale toward 200 billion parameters.</li><li><em>Speed</em>: Improved memory efficiency powers higher throughput and faster training. Figure 2 (bottom left) shows system throughput of ZeRO-2, ZeRO-1, and baseline model parallelism. Here we use a state-of-the-art model parallelism approach, <span class="smallcaps-auto">NVIDIA</span> Megatron-LM, as baseline-MP, while ZeRO-2 and ZeRO-1 both combine ZeRO-powered data parallelism with Megatron-LM model parallelism. ZeRO-2 runs 100-billion-parameter models with over 38 teraflops per <span class="smallcaps-auto">GPU</span>, 30% of hardware peak, and aggregated performance over 15 petaflops on the cluster with 400 <span class="smallcaps-auto">NVIDIA</span> V100 <span class="smallcaps-auto">GPU</span>s. For models of the same size, ZeRO-2 is up to 10× faster in training speed when compared to the baseline because model parallelism requires high communication bandwidth to be efficient, and models of these sizes require model parallelism across nodes where the communication bandwidth is limited. The memory savings of ZeRO-2 allows us to reduce model parallelism degree and fit the model without requiring inter-node model parallelism, drastically reducing communication cost. ZeRO-2 is also up to 5× faster than ZeRO-1 because its additional memory savings help reduce communication further and support even larger batch sizes.</li><li><em>Scalability</em>: We observe superlinear speedup (Figure 2, top right), where the performance more than doubles when the number of <span class="smallcaps-auto">NVIDIA</span> <span class="smallcaps-auto">GPU</span>s are doubled. ZeRO-2 reduces the memory footprint of the model states as we increase the data parallelism degree, allowing us to fit larger batch sizes per <span class="smallcaps-auto">GPU</span> and resulting in better performance.</li><li><em>Democratizing large model training</em>: ZeRO-2 empowers model scientists to train models up to 13 billion parameters efficiently without any model parallelism that typically requires model refactoring (Figure 2, bottom right). 13 billion parameters is larger than most of the largest state-of-the-art models (such as Google T5, with 11 billion parameters). With respect to throughput, we observe an average throughput of 37 teraflops (30% hardware peak) per V100 <span class="smallcaps-auto">GPU</span> for model sizes ranging from 2 billion to 13 billion parameters. Model scientists can therefore experiment freely with large models without worrying about model parallelism. In comparison, the implementations of classic data parallelism approaches (such as PyTorch Distributed Data Parallel) run out of memory with 1.4-billion-parameter models, while ZeRO-1 supports up to 6 billion parameters.</li></ol><p>For more details about ZeRO-2, please see the <a href="https://github.com/microsoft/DeepSpeed">DeepSpeed GitHub repository</a> and the updated <a href="https://arxiv.org/abs/1910.02054#microsoft" title="&#39;ZeRO: Memory Optimizations Toward Training Trillion Parameter Models&#39;, Rajbhandari et al 2019">ZeRO paper</a>.</p>'
- - https://www.gq.com/story/the-great-paper-caper
  - 'The Great Paper Caper: Years of running drugs and boosting cars left Frank Bourassa thinking: There’s got to be an easier way to earn a dishonest living. That’s when he nerved up the idea to make his fortune. (Literally.) Which is how Frank became the most prolific counterfeiter in American history—a guy with more than $200 million in nearly flawless fake twenties stuffed in a garage. How he got away with it all, well, that’s even crazier.'
  - Wells Tower (GQ)
  - 2014-11-01
  - ''
  - ! '<p>Finally, when he was fairly certain that the cops weren’t onto him, Frank says he called another friend of his who showed up with scanners and radio wands to check the shipment for bugs. The crew opened the truck. On five wooden pallets sat the future of Frank’s criminal enterprise. It was paper of a special kind, made with the same rare cotton-and-linen recipe used for printing American currency. It also bore watermarked images of Andrew Jackson’s face and security strips reading <span class="smallcaps-auto">USA</span> <span class="smallcaps-auto">TWENTY</span> in minuscule type. The paper was the essential ingredient for fabricating high-grade counterfeit bills that the Canadian police would later describe as “basically undetectable” from the real thing. As soon as the security sweep pronounced the shipment clean, Frank welled up with optimism. “There was no way to stop me from there. I knew I was rich,” Frank recalled. “It was the best day of my life.” Frank now had what he needed to print hundreds of millions of dollars’ worth of fake U.S. currency—and to soon become the most prolific counterfeiter in the history of the trade.</p><p>…The recipe for the rag paper U.S. notes are printed on is deceptively simple—75% cotton and 25% linen—a distinctive composition every American unconsciously knows by feel. Simple though it may be, the recipe is also so widely known that dialing a paper mill and asking for a batch of 75/25 is a speedy way to get raided by the Secret Service (which was created expressly to bust counterfeiters—<span class="smallcaps-auto">POTUS</span> tending came later). And even if you <em>could</em> somehow chef up a few reams of the cotton-linen blend, you’d still need to add to it a whole host of security elements: the watermark—the translucent face of Jackson, Franklin, et al.—which appears when you hold the bill up to the light; the security strip; the tiny red and blue fibers embedded throughout the paper; and so on.</p><p>…In the fall of 2008, Frank says he began reaching out to paper mills across Europe and Asia under the alias Thomas Moore, an employee of The Letter Shop, a fictitious Quebec stationery concern. He purported to have a special client who wanted some special paper manufactured. What kind of paper? Well, rag paper with cotton, maybe some linen thrown in there. “Cotton and linen? Like, for currency?” suspicious papermakers would often respond, and Thomas Moore would be heard from no more.</p><p>But Frank had faith that somewhere—maybe in Poland, Slovakia, or Bulgaria—his avatar could flush out a papermaker stupid or crooked enough to make his recipe. In January 2009, he says, his search ended at the Artoz paper company headquartered in Lenzburg, Switzerland. By now, Frank had adopted the <em>nom de plume</em> Jackson Maxwell, of the Keystone Investment and Trading Company, a securities firm whose letterhead, suspiciously, bore no street address.</p><p>In correspondence included in court documents that Frank shared with me, Maxwell told his mark that Keystone was looking to print bond certificates on secure rag paper—customized with one or two security measures designed to, um, foil counterfeiters. Frank says that after Artoz accepted the basics of his bond-brokerage story, he tweaked and refined his order over many months, nudging one felonious tidbit after another onto the papermaker’s plate. He got them to add linen to the recipe. He asked them to mix in chemicals to thwart security pens and black-light tests. He persuaded them to sew in a security strip reading, in near microscopic print, <span class="smallcaps-auto">USA</span> <span class="smallcaps-auto">TWENTY</span>. (“I told them it was, you know, for a $20 bond.”) Artoz, he says, also agreed to imprint his paper with a watermark, an image etched into a cylindrical printing drum and pressed into the paper while the pulp is still wet. To get the equipment Artoz would need to do this, Frank paid $15,000, routed under a surrogate’s name through a Swiss bank account, to a company in Düren, Germany, that manufactured a drum etched with the likenesses of Andrew Jackson’s face. How did he manage that, exactly? “It was easy,” said Frank. “To you, he’s Andrew Jackson. To some guy in Germany, who the fuck is it? Some guy’s face. He doesn’t know.”</p>'
- - https://www.gizmodo.com.au/2020/05/the-internet-furry-drama-raising-big-questions-about-artificial-intelligence/
  - The Internet Furry Drama Raising Big Questions About Artificial Intelligence
  - Whitney Kimball (Gizmodo)
  - 2020-05-17
  - ''
  - ! '<p>Much of the fun of internet drama comes from its frivolousness, but sometimes an online shitfest points to something bigger. Last week, the AI-powered furry art site <a href="https://www.thisfursonadoesnotexist.com/">This Fursona Does Not Exist</a> did just that, igniting a fandom firestorm while also highlighting an important debate about digital art. Trained on more than 55,000 images pulled (without permission) from a furry art forum, the algorithm was a simple case of art theft to some. For others, it was a chance to break out the popcorn. But legal scholars who spoke with Gizmodo said the conflict raises thorny questions about ownership in the age of AI—questions that may ultimately have to be answered in court.</p><p>…At least one person tried (and failed) to find proof that the algorithm was copying images from e621.net outright. And within days, the entire site was slapped with a <span class="smallcaps-auto">DMCA</span> copyright infringement complaint. (The company whose name the <span class="smallcaps-auto">DMCA</span> was issued in, according to Arfa, denied filing the notice and requested it be withdrawn.) Some degree of backlash is understandable. Furry fandom has long been a close-knit community of independent creators supported by individual commissions. A project aimed at mass-producing fursonas—using original art as training material, no less—could be seen as a threat to creators’ livelihood. Some commenters accused Arfa of disrespect and asked for the choice to opt out of the project. Others complained that their work had been uploaded to e621 without their permission in the first place.</p>'
- - https://fursona.app
  - 'This Fursona Does Not Exist—Fursona Editor (Tensorflow Version)'
  - Arfafax
  - 2020-06-01
  - ''
  - ! '[Google Colab notebook for interactive editing faces generated by the <span class="smallcaps-auto">TFDNE</span>.com furry face Style<span class="smallcaps-auto">GAN</span> 2 model, using <a href="https://github.com/harskish/ganspace">Ganspace</a> to reverse-engineer the latent encoding and allow control of specific visual attributes of faces.]'
- - https://intelligence.org/2017/10/13/fire-alarm/
  - "There’s No Fire Alarm for Artificial General Intelligence"
  - Eliezer Yudkowsky
  - 2017-10-13
  - ''
  - ! '<p>[Meditation on the problem of coordinating reaction to x-risks, and AI risks in particular. To quote Norbert Wiener:</p><blockquote><p>Again and again I have heard the statement that learning machines cannot subject us to any new dangers, because we can turn them off when we feel like it. But can we? To turn a machine off effectively, we must be in possession of information as to whether the danger point has come. The mere fact that we have made the machine does not guarantee we shall have the proper information to do this.</p></blockquote><p>A fire alarm, even if it is not 100% accurate, coordinates human reactions: it becomes permissible to leave the room and investigate, take precautions, and for everyone to evacuate the building. This is because we all agree that fires usually come with smoke and smoke can be objectively detected. But what is the fire alarm for AI? “AI is whatever we can’t do yet”, and whenever AI accomplishes a new feat, people will simply move the goalposts and say that that task turned out to be unexpectedly easy to solve. There is no agreement on what “imminent <span class="smallcaps-auto">AGI</span>” <em>looks like</em>. You can ask AI researchers, “how would the world look different if we were in fact heading towards <span class="smallcaps-auto">AGI</span> in the near future, the next decade or three?” and they are unable to answer. They do not know what is or is not a ringing alarm bell, the point at which everyone should start taking the prospect very seriously. It was not chess, it was not ImageNet classification, it was not Go…</p><p>AI so far resembles other technologies like airplanes or nuclear bombs where just years before, the physicists who would invent it, eminent physicists, and physicists in general, were highly uncertain or skeptical or outright convinced of their impossibility. This was because progress in nuclear physics looked much the same regardless of whether nuclear bombs were possible and impossible. There was large ineradicable uncertainty, which appears to have neutered any serious effort to prepare. And yet, these matters ought to be dealt with in advance. Things like nuclear bombs or AI should not just arrive with no one having done anything to prepare. Or consider pandemics. Those who tried to warn the world about coronavirus will find this essay eerily apt.]</p><p>Okay, let’s be blunt here. I don’t think most of the discourse about <span class="smallcaps-auto">AGI</span> being far away (<em>or</em> that it’s near) is being generated by models of future progress in machine learning. I don’t think we’re looking at wrong models; I think we’re looking at no models.</p><p>I was once at a conference…I got up in Q&amp;A and said, “Okay, you’ve all told us that progress won’t be all that fast. But let’s be more concrete and specific. I’d like to know what’s the <em>least</em> impressive accomplishment that you are very confident <em>cannot</em> be done in the next two years.”</p><p>There was a silence.</p><p>Eventually, 2 people on the panel ventured replies, spoken in a rather more tentative tone than they’d been using to pronounce that <span class="smallcaps-auto">AGI</span> was decades out. They named “A robot puts away the dishes from a dishwasher without breaking them”, and Winograd schemas….A few months after that panel, there was unexpectedly a big breakthrough on Winograd schemas. The breakthrough didn’t crack 80%, so three cheers for wide credibility intervals with error margin, but I expect the predictor might be feeling slightly more nervous now with one year left to go…</p><p>But that’s not the point. The point is the silence that fell after my question, and that eventually I only got 2 replies, spoken in tentative tones. When I asked for concrete feats that were impossible in the next two years, I think that that’s when the luminaries on that panel switched to trying to build a mental model of future progress in machine learning, asking themselves what they could or couldn’t predict, what they knew or didn’t know. And to their credit, most of them did know their profession well enough to realize that forecasting future boundaries around a rapidly moving field is actually <em>really hard</em>, that nobody knows what will appear on arXiv next month, and that they needed to put wide credibility intervals with very generous upper bounds on how much progress might take place 24 months’ worth of arXiv papers later. (Also, Demis Hassabis was present, so they all knew that if they named something insufficiently impossible, Demis would have DeepMind go and do it.)</p><p>…When I observe that there’s no fire alarm for <span class="smallcaps-auto">AGI</span>, I’m not saying that there’s no possible equivalent of smoke appearing from under a door. What I’m saying rather is that the smoke under the door is always going to be arguable; it is not going to be a clear and undeniable and absolute sign of fire; and so there is never going to be a fire alarm producing common knowledge that action is now due and socially acceptable…There is never going to be a time before the end when you can look around nervously, and see that it is now clearly common knowledge that you can talk about <span class="smallcaps-auto">AGI</span> being imminent, and take action and exit the building in an orderly fashion, without fear of looking stupid or frightened.</p>'
- - https://progressstudies.school/
  - "Progress Studies for Aspiring Young Scholars: An online summer program in the history of technology for high school students"
  - Progress Studies for Young Scholars
  - 2020-05
  - ''
  - ! '<p>[2020] Progress Studies for Young Scholars is an online program of guided self-study in the history of industrial civilization for high school students.</p><p>This program will explore: what problems, challenges and hardships in life and work were faced by people in earlier generations and centuries? And how did we solve those problems through science, technology, and invention?</p><p>Learn about manufacturing from blacksmiths to assembly lines; about power from water wheels to combustion to electricity; about food from famine to industrial agriculture and genetically modified crops; about disease from basic sanitation to scientific medicine—and the struggles and circumstances of the men and women who worked to bend the arc of humanity upward.</p><p>Your learning will be supported by instructors who will help you develop your reasoning and research skills. You’ll also have the chance to engage ideas with a community of like-minded peers…A six-week course with daily reading, audio or video content. Go through it on your own, or join a study group with an instructor for daily online discussions and Q&amp;A.</p><p>Speaker series: Danica Remy · Deirdre Nansen McCloskey · Adam Mossoff · Anton Howes · Joel Mokyr · Laura Mazer · Manjari Narayan · Matt Bateman · Max Roser · Sarah Constantin · Tyler Cowen · Jason Crawford · Jerry Neumann · Michael Dearing · Michael Strong · Noor Siddiqui · Patrick Collison · Samo Burja</p>'
- - http://www.thisworddoesnotexist.com/
  - This Word Does Not Exist
  - Thomas Dimson
  - 2020-05-13
  - ''
  - ! '<p>[<span class="smallcaps-auto">GPT</span>-2 samples generated after training on a dictionary and heavily filtered to try to remove existing words (<a href="https://github.com/turtlesoupy/this-word-does-not-exist">source</a>). Example:</p><blockquote><p><strong>pellum (noun)</strong></p><p>the highest or most important point or position</p><p><em>“he never shied from the pellum or the right to preach”</em></p></blockquote><p>Discussion: <a href="https://news.ycombinator.com/item?id=23169962">HN</a>, <a href="https://old.reddit.com/r/MachineLearning/comments/gj475j/project_this_word_does_not_exist/">/r/ML</a>]</p><p>…Most of the project was spent throwing a number of rejection tricks to make good samples, e.g.,</p><ul><li>Rejecting samples that contain words that are in the a training set / blacklist to force generation completely novel words</li><li>Rejecting samples without the use of the word in the example usage</li><li>Running a part of speech tagger on the example usage to ensure they use the word in the correct <span class="smallcaps-auto">POS</span></li></ul>'
- - /Faces#danbooru2019e621-256px-biggan
  - Danbooru2019+e621 256px BigGAN Model Release
  - Tensorfork (Gwern Branwen, Shawn Presser et al)
  - 2020-05-28
  - ''
  - ! '<p>Release of a 256px Big<span class="smallcaps-auto">GAN</span> model trained on Danbooru2019 &amp; e621. This is a prototype model testing our ability to train a Big<span class="smallcaps-auto">GAN</span> stably for hundreds of thousands of iterations on a <span class="smallcaps-auto">TPU</span>-256 pod on 3 million+ anime/illustration images. While the generated samples are far from ‘photorealistic’, they serve as proof of concept that—unlike our failed Style<span class="smallcaps-auto">GAN</span> 2 scaling experiments—Big<span class="smallcaps-auto">GAN</span> can successfully model anime images with great generality, and that we can potentially scale up to 512px or even 1024px and match the DeepMind ImageNet Big<span class="smallcaps-auto">GAN</span> for quality.</p><p><figure><img src="/images/gan/2020-05-15-biggan-256px-danbooruplus-run39-90randomemasamples.jpg" alt="" /><figcaption>90 random <span class="smallcaps-auto">EMA</span> samples (untruncated) from the 256px Big<span class="smallcaps-auto">GAN</span> trained on Danbooru2019/anime-portraits/e621/e621-portraits.</figcaption></figure></p>'
- - /Crops#danbooru2019-portraits
  - "Danbooru2019 Portraits"
  - Gwern Branwen
  - '2019'
  - ''
  - ! '<p>Danbooru2019 Portraits is a dataset of <em>n</em>=302,652 (16GB) 512px anime faces cropped from solo <span class="smallcaps-auto">SFW</span> Danbooru2019 images in a relatively broad ‘portrait’ style encompassing necklines/ears/hats/etc rather than tightly focused on the face, upscaled to 512px as necessary, and low-quality images deleted by manual review using <a href="./Faces#discriminator-ranking" class="docMetadata" data-popup-title="Generating Anime Faces with StyleGAN: Using a trained Discriminator to Rank and Clean Data" data-popup-author="Gwern Branwen" data-popup-date="2019-04-22" data-popup-abstract="The Discriminator of a GAN is trained to detect outliers or bad datapoints. So it can be used for cleaning the original dataset of aberrant samples. This works reasonably well and I obtained BigGAN/StyleGAN quality improvements by manually deleting the worst samples (typically badly-cropped or low-quality faces), but has peculiar behavior which indicates that the Discriminator is not learning anything equivalent to a &quot;quality&quot; score but may be doing some form of &lt;em&gt;memorization&lt;/em&gt; of specific real datapoints. What does this mean for how GANs work?">Discriminator ranking</a>, which has been used for creating <a href="https://www.thiswaifudoesnotexist.net"><span class="smallcaps-auto">TWDNE</span></a>.</p>'
- - /Crops#danbooru2019-figures
  - "Danbooru2019 Figures: A Large-Scale Anime Character Illustration Dataset"
  - Gwern Branwen
  - 2020-05-31
  - ''
  - ! '<p>The <a href="/Danbooru2019">Danbooru2019</a> Figures dataset is a large-scale character anime illustration dataset of <em>n</em>=855,880 images (248GB; minimum width 512px) cropped from Danbooru2019 using the <a href="https://github.com/jerryli27/AniSeg/">AniSeg</a> anime character detection model. The images are cropped to focus on a single character’s entire visible body, extending ‘portrait’ crops to ‘figure’ crops. This is useful for tasks focusing on individual characters, such as character classification or for generative tasks (a corpus for weak models like Style<span class="smallcaps-auto">GAN</span>, or data augmentation for Big<span class="smallcaps-auto">GAN</span>).</p><p><figure><img src="/images/gan/2020-05-30-danbooru2019-figures-randomsamples-40.jpg" alt="" /><figcaption>40 random figure crops from Danbooru2019 (4×10 grid, resized to 256px)</figcaption></figure></p>'
- - /Crops#hands
  - PALM Anime Locator Model
  - Gwern Branwen
  - 2020-06-12
  - ''
  - ! '<p>We create and release <strong><span class="smallcaps-auto">PALM</span></strong>: the <span class="smallcaps-auto">PALM</span> Anime Locator Model. <span class="smallcaps-auto">PALM</span> is a pretrained anime hand detector/localization neural network, and 3 sets of accompanying anime hand datasets:</p><ol type="1"><li><p>a dataset of 5,382 anime-style <a href="/Danbooru2019">Danbooru2019</a> images annotated with the locations of 14,394 hands</p><p>This labeled dataset is used to train a <span class="smallcaps-auto">YOLO</span>v3 model to detect hands in anime.</p></li><li><p>a second dataset of 96,534 hands cropped from the Danbooru2019 dataset using the <span class="smallcaps-auto">PALM</span> <span class="smallcaps-auto">YOLO</span> model</p></li><li><p>a cleaned version of #2, consisting of 58,536 hand crops upscaled to &gt;=512px</p></li></ol><p>Hand detection can be used to clean images (eg remove face images with any hands in the way), or to generate datasets of just hands (as a form of data augmentation for <span class="smallcaps-auto">GAN</span>s), to generate reference datasets for artists, or for other purposes.</p><p><figure><img src="/images/gan/2020-06-11-danbooru2019-palms-upscaledrealhandsamples.jpg" alt="" /><figcaption>Random sample of upscaled subset of Danbooru2019 hands</figcaption></figure></p>'
- - https://80000hours.org/podcast/episodes/danny-hernandez-forecasting-ai-progress/
  - "Danny Hernandez on forecasting and the drivers of AI progress"
  - Arden Koehler, Robert Wiblin, Keiran Harris (80,000 Hours)
  - 2020-05-22
  - ''
  - ! '<p>Companies use about 300,000 times more computation training the best AI systems today than they did in 2012 and algorithmic innovations have also made them 25 times more efficient at the same tasks.</p><p>These are the headline results of two recent papers—<a href="https://openai.com/blog/ai-and-compute/" title="&#39;We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year doubling period). Since 2012, this metric has grown by more than 300,000× (a 2-year doubling period would yield only a 7× increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it’s worth preparing for the implications of systems far outside today’s capabilities&#39;, Amodei et al 2018">“AI and Compute”</a> and <a href="https://openai.com/blog/ai-and-efficiency/" title="&#39;AI and Efficiency: We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s Law would yield an 11× cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware efficiency&#39;, Hernandez &amp; Brown 2020">“AI and Efficiency”</a>—from the Foresight Team at OpenAI. In today’s episode I spoke with one of the authors, Danny Hernandez, who joined OpenAI after helping develop better forecasting methods at Twitch and Open Philanthropy. Danny and I talk about how to understand his team’s results and what they mean (and don’t mean) for how we should think about progress in AI going forward.</p><p>Debates around the future of AI can sometimes be pretty abstract and theoretical. Danny hopes that providing rigorous measurements of some of the inputs to AI progress so far can help us better understand what causes that progress, as well as ground debates about the future of AI in a better shared understanding of the field…In the interview, Danny and I also discuss a range of other topics, including:</p><ul><li>The question of which experts to believe</li><li>Danny’s journey to working at OpenAI</li><li>The usefulness of “decision boundaries”</li><li>The importance of Moore’s law for people who care about the long-term future</li><li>What OpenAI’s Foresight Team’s findings might imply for policy</li><li>The question whether progress in the performance of AI systems is linear</li><li>The safety teams at OpenAI and who they’re looking to hire</li><li>One idea for finding someone to guide your learning</li><li>The importance of hardware expertise for making a positive impact</li></ul><blockquote><p>If you believe AI progress is fast, what would progress look like that would convince you it’s slow? Paint a picture of that five years from now. What does slow progress look like to you? And now you’re like, “Oh yeah, progress is actually slow”. And what could have happened that would convince you that it’s actually fast. But you can make what would update you clear to yourself and others and that for big decisions, this is generally worthwhile.</p></blockquote>'
- - /docs/ai/anime/2019-yu.pdf
  - ! "Generating Furry Face Art from Sketches using a GAN"
  - Andrew Yu
  - 2019-12-01
  - ''
  - ! '<p>I generate furry face artwork from color sketches. The sketches are procedurally generated from a data set of furry artwork. Sketches are translated back into artwork via a Generative Adversarial Network. I implement the <span class="smallcaps-auto">GAN</span> using a U-Net autoencoder with encoder-decoder skip connections and experiment with adding adaptive instance normalization into upsampling layers. The results show effective mapping of training and dev set sketches back to their input style. However, the model does not perform as effectively on novel user sketches and often fails to add stochastic textures like hair details.</p>'
- - https://osf.io/preprints/socarxiv/mbj9p/
  - Understanding the geography of cryptomarkets using administrative data on postal drug deliveries in Scotland
  - Ben Matthews, Ben Collier, Susan McVie, Chris Dibben
  - 2020-05-28
  - 10.31235/osf.io/mbj9p
  - ! '<p>Cryptomarkets may open up the drugs supply in remote areas where access to drugs was expensive or patchy. However, using cryptomarkets relies on risk-limiting techniques to avoid detection which may be easier in urban areas. However, little is known about the geographical patterning of cryptomarket use, in part because data sources on the locations of cryptomarket purchasers are hard to come by. We use a novel dataset of packages of drugs packages intercepted by Scottish law enforcement, likely reflecting cryptomarket use, to understand the flows of drugs through cryptomarkets at regional and neighbourhood levels. This gives previously unavailable insights into the geographical patterns of cryptomarket use at the sub-national level.</p><p>We use descriptive statistics, Bayesian hierarchical regression models, and exploratory analysis of spatial clustering to describe the relationship between neighbourhood characteristics and expected rate of drugs consignments identified across Scotland.</p><p>The majority of intercepted drug packages were destined for urban centres, but there was a higher than expected delivery rate to some of Scotland’s remote and rural locations. Increased rates of drug delivery within Scottish neighbourhoods was associated with higher levels of crime and deprivation, internet connectivity and with access to services, but not with higher rates of drug-related hospitalisation.</p><p>Analysis of spatial clustering showed that drug delivery to the most remote and rural locations was still associated with good access to services because the packages were typically delivered to addresses in larger settlements within remote locations.</p>'
- - /docs/xrisks/1993-gott.pdf
  - ! "Implications of the Copernican principle for our future prospects"
  - J. Richard Gott III
  - 1993-05-27
  - 10.1038/363315a0
  - ! '<p>Making only the assumption that you are a random intelligent observer, limits for the total longevity of our species of 0.2 million to 8 million years can be derived at the 95% confidence level. Further consideration indicates that we are unlikely to colonize the Galaxy, and that we are likely to have a higher population than the median for intelligent species.</p>'
- - /docs/psychology/writing/1953-taylor.pdf
  - ! "“Cloze Procedure”: A New Tool for Measuring Readability"
  - Wilson L. Taylor
  - 1953-09-01
  - 10.1177/107769905303000401
  - ! '<p>Here is the first comprehensive statement of a research method and its theory which were introduced briefly during a workshop at the 1953 <span class="smallcaps-auto">AEJ</span> convention. Included are findings from three pilot studies and two experiments in which “cloze procedure” results are compared with those of two readability formulas.</p><p>“Cloze Procedure” involves no formula or “element counting,” but consists of sampling all potential readability influences. Although similar to sentence-completion tests, the cloze method demands deletion of random words from a passage. After administration to a group the correctly identified omissions are tallied. Experimental results show: (1) the cloze method consistently ranked three selected passages in the same way as the Flesch and Dale-Chall formulas; (2) the method was reliable; (3) the cloze method seemed to handle specialized passages more adequately than other methods; (4) the same rankings of readability were obtained when words were deleted at random or every <em>n</em><sup>th</sup> word; (5) the cloze procedure could be used for comparing reading abilities of different individuals.</p>'
- - https://www.nature.com/articles/s41467-019-09311-w
  - Accelerating dynamics of collective attention
  - Philipp Lorenz-Spreen, Bjarke Mørch Mønsted, Philipp Hövel, Sune Lehmann
  - 2019-04-15
  - 10.1038/s41467-019-09311-w
  - ! '<p>With news pushed to smart phones in real time and social media reactions spreading across the globe in seconds, the public discussion can appear accelerated and temporally fragmented. In longitudinal datasets across various domains, covering multiple decades, we find increasing gradients and shortened periods in the trajectories of how cultural items receive collective attention. Is this the inevitable conclusion of the way information is disseminated and consumed? Our findings support this hypothesis. Using a simple mathematical model of topics competing for finite collective attention, we are able to explain the empirical data remarkably well. Our modeling suggests that the accelerating ups and downs of popular content are driven by increasing production and consumption of content, resulting in a more rapid exhaustion of limited attention resources. In the interplay with competition for novelty, this causes growing turnover rates and individual topics receiving shorter intervals of collective attention.</p>'
- - /docs/genetics/heritable/2020-armstrongcarter.pdf
  - ! "The Earliest Origins of Genetic Nurture: The Prenatal Environment Mediates the Association Between Maternal Genetics and Child Development"
  - Emma Armstrong-Carter, Sam Trejo, Liam J. B. Hill, Kirsty L. Crossley, Dan Mason, Benjamin W. Domingue
  - 2020-06-02
  - 10.1177/0956797620917209
  - ! '<p>Observed genetic associations with educational attainment may be due to direct or indirect genetic influences. Recent work highlights genetic nurture, the potential effect of parents’ genetics on their child’s educational outcomes via rearing environments. To date, few mediating childhood environments have been tested. We used a large sample of genotyped mother–child dyads (<em>n</em>=2,077) to investigate whether genetic nurture occurs via the prenatal environment. We found that mothers with more education-related genes are generally healthier and more financially stable during pregnancy. Further, measured prenatal conditions explain up to one third of the associations between maternal genetics and children’s academic and developmental outcomes at the ages of 4 to 7 years. By providing the first evidence of prenatal genetic nurture and showing that genetic nurture is detectable in early childhood, this study broadens our understanding of how parental genetics may influence children and illustrates the challenges of within-person interpretation of existing genetic associations.</p>'
- - /docs/genetics/selection/2020-moeinizade.pdf
  - ! "Multi-trait Genomic Selection Methods for Crop Improvement"
  - Saba Moeinizade, Aaron Kusmec, Guiping Hu, Lizhi Wang, Patrick S. Schnable
  - 2020-06-01
  - 10.1534/genetics.120.303305
  - ! '<p>Plant breeders make selection decisions based on multiple traits, such as yield, plant height, flowering time, and disease resistance. A commonly used approach in multi-trait genomic selection is index selection, which assigns weights to different traits relative to their economic importance. However, classical index selection only optimizes genetic gain in the next generation, requires some experimentation to find weights that lead to desired outcomes, and has difficulty optimizing non-linear breeding objectives. Multi-objective optimization has also been used to identify the Pareto frontier of selection decisions, which represents different trade-offs across multiple traits. We propose a new approach, which maximizes certain traits while keeping others within desirable ranges. Optimal selection decisions are made using a new version of the look-ahead selection algorithm, which was recently proposed for single trait genomic selection and achieved superior performance with respect to other state-of-the-art selection methods. To demonstrate the effectiveness of the new method a case study is developed using a realistic data set where our method is compared with conventional index selection. Results suggest that the multi-trait look-ahead selection is more effective at balancing multiple traits compared to index selection. [Keywords: multi-trait genomic selection, optimization, simulation]</p>'
- - /docs/genetics/selection/2020-borrenpohl.pdf
  - ! "The value of early-stage phenotyping for wheat breeding in the age of genomic selection"
  - Daniel Borrenpohl, Mao Huang, Eric Olson, Clay Sneller
  - 2020-06-01
  - 10.1007/s00122-020-03613-0
  - ! '<p><strong>Key message</strong>: Genomic selection using data from an on-going breeding program can improve gain from selection, relative to phenotypic selection, by significantly increasing the number of lines that can be evaluated.</p><p><strong>Abstract</strong>:The early stages of phenotyping involve few observations and can be quite inaccurate. Genomic selection (GS) could improve selection accuracy and alter resource allocation. Our objectives were (1) to compare the prediction accuracy of GS and phenotyping in stage-1 and stage-2 field evaluations and (2) to assess the value of stage-1 phenotyping for advancing lines to stage-2 testing. We built training populations from 1769 wheat breeding lines that were genotyped and phenotyped for yield, test weight, Fusarium head blight resistance, heading date, and height. The lines were in cohorts, and analyses were done by cohort. Phenotypes or GS estimated breeding values were used to determine the trait value of stage-1 lines, and these values were correlated with their phenotypes from stage-2 trials. This was repeated for stage-2 to stage-3 trials. The prediction accuracy of GS and phenotypes was similar to each other regardless of the amount (0, 50, 100%) of stage-1 data incorporated in the GS model. Ranking of stage-1 lines by GS predictions that used no stage-1 phenotypic data had marginally lower correspondence to stage-2 phenotypic rankings than rankings of stage-1 lines based on phenotypes. Stage-1 lines ranked high by GS had slightly inferior phenotypes in stage-2 trials than lines ranked high by phenotypes. Cost analysis indicated that replacing stage-1 phenotyping with GS would allow nearly three times more stage-1 candidates to be assessed and provide 0.84–2.23 times greater gain from selection. We conclude that GS can complement or replace phenotyping in early stages of phenotyping.</p>'
- - /docs/technology/2007-avidan.pdf
  - ! "Seam carving for content-aware image resizing"
  - Shai Avidan, Ariel Shamir
  - 2007-07-01
  - 10.1145/1275808.1276390
  - ! '<p>Effective resizing of images should not only use geometric constraints, but consider the image content as well. We present a simple image operator called <i>seam carving</i> that supports content-aware image resizing for both reduction and expansion. A seam is an optimal 8-connected path of pixels on a <i>single</i> image from top to bottom, or left to right, where optimality is defined by an image energy function. By repeatedly carving out or inserting seams in one direction we can change the aspect ratio of an image. By applying these operators in both directions we can retarget the image to a new size. The selection and order of seams protect the content of the image, as defined by the energy function. Seam carving can also be used for image content enhancement and object removal. We support various visual saliency measures for defining the energy of an image, and can also include user input to guide the process. By storing the order of seams in an image we create <i>multi-size</i> images, that are able to continuously change in real time to fit a given size.</p>'
- - /docs/iq/1965-walkup.pdf
  - ! "Creativity in Science through Visualization"
  - Lewis E. Walkup
  - 1965-08-01
  - 10.2466/pms.1965.21.1.35
  - ! '<p><strong>Editors’ note</strong>: Mr. Walkup, an electrical engineer by training but an applied physicist by experience, has worked 12 yr. in research on explosives and ballistics and 19 yr. in the technology of the graphic arts, especially on the electrostatic photographic process called xerography. In this latter field he has been a major contributor of inventive ideas; he holds 37 U. S. and 60 foreign patents. The present article is a result of his personal study of creativity in his co-workers in a large industrial research institute.</p><p><strong>Abstract</strong>: The fact that attempts to gain insight into the creative process have been so unsuccessful suggests that they have overlooked at least one basic ingredient in the process. This ingredient may lie in the nature or way the individual mind goes about remembering and manipulating data. The hypothesis is advanced that the creative persons appear to have stumbled onto and then developed to a high degree of perfection the ability to visualize—almost hallucinate—in the area in which they are creative. And their visualizations seem to be of a sort that lend themselves to easy manipulation in the thinking process. This is illustrated by reports from many of the great inventors of the past and it is easy to demonstrate that individuals differ enormously in the kind and degree of their ability to think in such manipulable visualizations. If correct, this aspect of creativity suggests many research attacks and many potential changes in education for creative activity.</p><p>…It is interesting to ask a number of persons to solve a simple problem in mental arithmetic, say, to subtract 46 from 100, and then to ask them what went on in their heads as they solved the problem. I have found the following gamut of processes used. Some persons simply grope around with words, perhaps dividing the problem up into subtracting 6 from 10 and 4 from 10, which they do simply by remembering the words associated with these operations and then somehow combining these results to give the final answer. Others mentally write out 100 with 46 beneath it and picture the process of writing down the answer below the two. Finally, some individuals have specialized equipment for just this operation. They visualize two juxtaposed scales from zero to 100, one starting at the right and one at the left. With this mnemonic gadget the required subtraction involves simply finding 46 on one of the scales and reading off 54 on the other!</p><p>…Another interesting example involves the ability to visualize combinations of cubes. Try asking a number of persons to visualize a large cube made up of 27 smaller cubes, that is, three on each edge of the composite cube. Then, ask him to imagine painting the entire outer surface of the large cube. Finally, ask him how many of the smaller cubes he has painted on zero, one, two, or three sides. After he gives the result, ask him to describe the mental process he used in arriving at the answer. A surprising variety of answers come from this simple test. Some persons, even some professionally engaged in science and art, simply are unable to solve this problem mentally because they cannot visualize a cube in any way! Others stumble around with crude visualizations of a cube and end up by guessing at the answer. Some can visualize an opaque cube fairly well but must infer from the one view what is on the other side. The most potent approach seems to be that of the person who can visualize a transparent cube and simply count the smaller cubes whose sides are covered with paint, a process something like counting one’s fingers with his hands held up in front of him.</p><p>In still another provocative problem, persons may be asked co give verbal directions for driving a car from one location to another, and then asked what they visualized mentally as they were giving the directions. Again, a wide variety of mental processes will be disclosed. Surprisingly, many persons report seeing the route as from a low-flying helicopter. The fact that different persons use vastly different visualizations in thinking is suggested by some other informal reports. One person has declared that he dreams only in words, that he does not use any form of visualization in dream states. It has been claimed by some semanticists that the human being thinks only in words. This seems an utterly absurd statement to many of us who spend a large part of our waking hours in visualizing and thinking in pictorial representations. This, of course, does not deny the fact that it is quite possible that semanticists do, in fact, think only in words; it would be logical that “word thinkers” would be drawn to this specialized field.</p><p>…This is well illustrated by the now famous visualization by Kekule, as reported by Beveridge, which led him to the discovery of the benzene ring through a vision of a series of linked atoms biting its tail like a snake. Michael Faraday was one of the first to “see” the electrical and magnetic lines of force that now are standard tools for physicists to visualize otherwise mysterious phenomena in this area. Albert Einstein apparently believed that thought consisted entirely of dealing with mechanical images and not at all of words. The mathematician Jacques Hadamard reported that he thought exclusively in visual pictures. However, these men did not seem to realize the uniqueness of their ability to visualize in manipulable images. They seemed to assume that all persons had much the same ability. Inventors with whom I have talked report thinking visually about complex mechanisms and organic chemical molecules combining with other molecules. So, it appears that ideas which can be grasped when drawn on paper can be visualized without being put onto paper, perhaps with many shorthand approximations for unimportant parts. Also, the nature of the <em>seeing</em> or sensing is peculiar. It is almost a <em>feeling like</em> the object being visualized. One can <em>feel</em> the pressure of contacting objects, or the erosion of material by friction, or the flow of heat from one point to another, or the swing of the oscillating electrical circuit, or the bending of light as it passes from one medium to another, or the appropriateness of a well-designed structure co hold a maximum load, with every part equally strained in the process, or the eternal bouncing about of the molecules of a gas, or the almost physical transfer of energy from the gasoline, through the motor, transmission, and to the driving wheels of the automobile. It is as though one’s own kinesthetic sensing mechanisms were associated with the physical object and that he thus sensed directly what was going on in the external system. In highly-developed visualizers, this process probably is carried over for other than physical phenomena. Thus, poverty can be seen and felt as a pervading vapor that penetrates a house with its odors and depression, and history might be strung out along an imaginary line extending back as far as one wishes.</p><p>…At least here is a positive lead that is so apparent to the creative persons with whom I am familiar that they never stopped to consider whether or not it is special. When asked if they use life-like visualizations when they are inventing, they are inclined to say, “Why yes. Doesn’t everybody?” [See also: typical mind fallacy]</p>'
- - /docs/xrisks/1940-sciam-harrington-nuclearweapons-dontworryitcanthappen.pdf
  - "Don't Worry—It Can't Happen"
  - Jean Harrington (Scientific American)
  - 1940-05-01
  - '10.2307/24988773'
  - ! '<p>…Early last summer, in the midst of all this research, a chilly sensation began tingling up and down the spines of the experimenters. These extra neutrons that were being erupted—could they not in turn become involuntary bullets, flying from one exploding uranium nucleus into the heart of another, causing another fission which would itself cause still others? Wasn’t there a dangerous possibility that the uranium would at last become explosive? That the samples being bombarded in the laboratories at Columbia University, for example, might blow up the whole of New York City? To make matters more ominous, news of fission research from Germany, plentiful in the early part of 1939, mysteriously and abruptly stopped for some months. Had government censorship been placed on what might be a secret of military importance? The press and populace, getting wind of these possibly lethal goings-on, raised a hue and cry. Nothing daunted, however, the physicists worked on to find out whether or not they would be blown up, and the rest of us along with them. Now, a year after the original discovery, word comes from Paris that we don’t have to worry.</p><p>…With typical French—and scientific—caution, they added that this was perhaps true only for the particular conditions of their own experiment, which was carried out on a large mass of uranium under water. But most scientists agreed that it was very likely true in general.</p><p>…Readers made insomnious by “newspaper talk” of terrific atomic war weapons held in reserve by dictators may now get sleep.</p>'
- - /docs/nicotine/2001-warburton.pdf
  - ! "Improved incidental memory with nicotine after semantic processing, but not after phonological processing"
  - David M. Warburton, Abigail Skinner, Christopher D. Martin
  - 2001-01-01
  - 10.1007/s002130000565
  - ! '<p><em>Rationale</em>: A number of lines of evidence suggest that a nicotinic cholinergic system is mediating attentional processing. However, the evidence is less clear for a nicotinic system being involved in mnemonic processing.</p><p><em>Objectives</em>: The present study investigated the effects of nicotine on memory using a depth of processing paradigm.</p><p><em>Methods</em>: A double-blind design was used with participants (<em>n</em>=40) smoking either a nicotine containing cigarette (<em>n</em>=20) and a denicotinized cigarette (<em>n</em>=20). After smoking, each set of these participants was further subdivided into two groups (<em>n</em>=10 for each). One group were presented with a series of trials each beginning with the presentation of a “decision word” which they had to say whether it represented something which was living or non-living (semantic-orienting). The second group had to say whether the word had one syllable or two syllables (phonological or non-semantic orienting condition). This decision was followed by a word in coloured ink whose colour participants were required to name as quickly as possible. On completion of the whole task the participants were given an unexpected free recall test.</p><p><em>Results</em>: The nicotine-containing cigarette reduced the latencies for decision-making and colour naming in comparison with the denicotinized cigarette. The free recall test showed that nicotine-containing cigarette increased the number of words remembered, but only for the semantic-orienting condition and not the non-semantic condition.</p><p><em>Conclusions</em>: There is a nicotinic cholinergic system that mediates effortful processing. It can be deployed for attentional processing, including the associative processing required for memory encoding.</p>'
- - https://old.reddit.com/r/reinforcementlearning/comments/9pwy2f/wbe_and_drl_a_middle_way_of_imitation_learning/
  - '<span class=\"smallcaps-auto\">WBE</span> and <span class=\"smallcaps-auto\">DRL</span>: a Middle Way of imitation learning from the human brain'
  - Gwern Branwen
  - 2018-10-20
  - ''
  - ! '<p>Description of emerging machine learning paradigm identified by commentator starspawn0: discussions of building artificial brains typically presume either learning a brain architecture &amp; parameters from scratch (<span class="smallcaps-auto">AGI</span>) or laboriously ‘scanning’ and reverse-engineering a biological brain in its entirety to get a functioning artificial brain.</p><p>However, the rise of deep learning’s transfer learning &amp; meta-learning shows a wide variety of intermediate approaches, where ‘side data’ from natural brains can be used as scaffolding to guide &amp; constrain standard deep learning methods. Such approaches do not seek to ‘upload’ or ‘emulate’ any specific brain, they merely seek to imitate an average brain. A simple example would be training a <span class="smallcaps-auto">CNN</span> to imitate <a href="https://en.wikipedia.org/wiki/Eye_tracking">eyetracking</a> saliency data: what a human looks at while playing a video game or driving is the important part of a scene, and the <span class="smallcaps-auto">CNN</span> doesn’t have to learn importance from scratch. A more complex example would be using <span class="smallcaps-auto">EEG</span> as a ‘description’ of music in addition to the music itself. f<span class="smallcaps-auto">MRI</span> data could be used to guide a NN to have a similar modularized architecture with similar activation patterns given a particular stimulus as a human brain, which presumably is related to human abilities to zero-shot/few-shot learn and generalize.</p><p>While a highly marginal approach at the moment compared to standard approaches like scaling up models &amp; datasets, it is largely untapped, and progress in VR <a href="https://en.wikipedia.org/wiki/Virtual_reality_headset">headsets</a> with eyetracking capabilities (intended for <a href="https://en.wikipedia.org/wiki/Foveated_rendering">foveated rendering</a> but usable for many other purposes), brain imaging methods &amp; <a href="https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface"><span class="smallcaps-auto">BCI</span>s</a> has been more rapid than generally appreciated—in part thanks to breakthroughs using DL itself, suggesting the potential for a positive feedback loop where a <span class="smallcaps-auto">BCI</span> breakthrough enables a better NN for <span class="smallcaps-auto">BCI</span>s and so on.</p>'
- - https://arxiv.org/pdf/1809.11096.pdf&org=deepmind#page=8
  - 'Big<span class=\"smallcaps-auto\">GAN</span>: Large Scale <span class=\"smallcaps-auto\">GAN</span> Training For High Fidelity Natural Image Synthesis: 5.2 Additional Evaluation On <span class=\"smallcaps-auto\">JFT</span>-300M'
  - "Andrew Brock, Jeff Donahue, Karen Simonyan"
  - "2019-08-26"
  - ''
  - '<p>…To confirm that our design choices are effective for even larger and more complex and diverse datasets, we also present results of our system on a subset of <span class="smallcaps-auto">JFT</span>-300M (<a href="https://arxiv.org/abs/1707.02968#google" title="Revisiting unreasonable effectiveness of data in deep learning era">Sun et al., 2017</a>). The full <span class="smallcaps-auto">JFT</span>-300M dataset contains 300M real-world images labeled with 18K categories. Since the category distribution is heavily long-tailed, we subsample the dataset to keep only images with the 8.5K most common labels. The resulting dataset contains 292M images—two orders of magnitude larger than ImageNet.</p><p>…Our results show that these techniques substantially improve performance even in the setting of this much larger dataset at the same model capacity (64 base channels). We further show that for a dataset of this scale, we see significant additional improvements from expanding the capacity of our models to 128 base channels, while for ImageNet <span class="smallcaps-auto">GAN</span>s that additional capacity was not beneficial. In <a href="https://arxiv.org/pdf/1809.11096.pdf&amp;org=deepmind#figure.caption.30" title="Figure 19: JFT-300M IS vs FID at 256×256px">Figure 19</a> (Appendix D), we present truncation plots for models trained on this dataset…Interestingly, unlike models trained on ImageNet, where training tends to collapse without heavy regularization ([Section 4])(https://arxiv.org/pdf/1809.11096.pdf&amp;org=deepmind#section.4 “Characterizing Instability: The Generator/Discriminator/Conclusions”), the models trained on <span class="smallcaps-auto">JFT</span>-300M remain stable over many hundreds of thousands of iterations. This suggests that moving beyond ImageNet to larger datasets may partially alleviate <span class="smallcaps-auto">GAN</span> stability issues.</p>'
- - /docs/genetics/heritable/2020-halpernmanners.pdf
  - ! "The intergenerational transmission of early educational advantages: New results based on an adoption design"
  - Andrew Halpern-Manners, Helge Marahrens, Jenae M. Neiderhiser, Misaki N. Natsuaki, Daniel S. Shaw, David Reiss, Leslie D. Leve
  - 2020-06-01
  - 10.1016/j.rssm.2020.100486
  - ! '<p>Sociological research has traditionally emphasized the importance of post-birth factors (i.e., social, economic, and cultural capital) in the intergenerational transmission of educational advantages, to the neglect of potentially consequential pre-birth endowments (e.g., heritable traits) that are passed from parent to child. In this study, we leverage an experiment of <em>nurture</em>—children who were adopted at birth into nonrelative families—in an effort to simultaneously model the effects associated with both pathways. To do so, we fit a series of simple linear regression models that relate the academic achievement of adopted children to the educational attainments of their adoptive and biological parents, using U.S. data from a recent nationwide sample of birth and adoptive families (the Early Growth and Development Study). Because our dataset includes both “genetic” and “environmental” relatives, but not “genetic-<em>and</em>-environmental” relatives, the separate contributions of each pathway can be identified, as well as possible interactions between the two. Our results show that children’s early achievements are influenced not only by the attainments of their adoptive parents, but also the attainments of their <em>birth</em> parents—suggesting the presence of environmental <em>and</em> genetically mediated effects. Supplementary analyses provide little evidence of effect moderation, using both distal and proximate measures of the childhood environment to model gene-by-environment interactions. These findings are robust to a variety of parameterizations, withstand a series of auxiliary checks, and remain intact even after controlling for intrauterine exposures and other measurable variables that could compromise our design. The implications of our results for theory and research in the stratification literature, and for those interested in educational mobility, are discussed.</p>'
- - /docs/biology/1976-sagan.pdf
  - ! "Particles, environments, and possible ecologies in the Jovian atmosphere"
  - Carl Sagan. E. E. Salpeter
  - 1976-10-01
  - 10.1086/190414
  - ! '<p>The possible existence of indigenous Jovian organisms is investigated by characterizing the relevant physical environment of Jupiter, discussing the chromophores responsible for the observed coloration of the planet, and analyzing some permissible ecological niches of hypothetical organisms. Values of the eddy diffusion coefficient are estimated separately for the convective troposphere and the more stable mesosphere, and equilibrium condensation is studied for compounds containing Na, Cl, or both. The photoproduction of chromophores and nonequilibrium organic molecules is analyzed, and the motion of hypothetical organisms is examined along with the diffusion of metabolites and the consequent growth of organisms. Four kinds of organisms are considered: primary photosynthetic autotrophs (‘sinkers’), larger autotrophs or heterotrophs that actively maintain their pressure level (‘floaters’), organisms that seek out others (‘hunters’), and organisms that live at almost pyrolytic depths (‘scavengers’). It is concluded that ecological niches for sinkers, floaters, and hunters appear to exist in the Jovian atmosphere.</p><p>… The eddy diffusion coefficient is estimated as a function of altitude, separately for the Jovian troposphere and mesosphere. The growth-rate and motion of particles is estimated for various substances: the water clouds are probably nucleated by NH<sub>4</sub>Cl and sodium compounds are likely to be absent at and above the levels of the water clouds. Complex organic molecules produced by the Lα photolysis of methane may possibly be the absorbers in the lower mesosphere which account for the low reflectivity of Jupiter in the near-ultraviolet. The optical frequency chromophores are localized at or just below the Jovian tropopause. Candidate chromophore molecules must satisfy the condition that they are produced sufficiently rapidly that convective pyrolysis maintains the observed chromophore optical depth. Organic molecules and polymeric sulfur produced through H<sub>2</sub>S photolysis at λ&gt;2300 Å probably fail this test, even if a slow, deep circulation pattern, driven by latent heat, is present. The condition may be satisfied if complex organic chromophores are produced with high quantum yield by NH<sub>3</sub> photolysis at λ&lt;2300 Å. However, Jovian photoautotrophs in the upper troposphere satisfy this condition well, even with fast circulation, only biochemical properties of comparable terrestrial organisms are assured. Unless buoyancy can be achieved, a hypothetical organism drifts downward and is pyrolyzed. An organism in the form of a thin, gas-filled balloon can grow fast enough to replicate if (i) it can survive at the low mesospheric temperatures, or if (ii) photosynthesis occurs in the troposphere. If hypothetical organisms are capable of slow, powered locomotion and coalescence, they can grow large enough to achieve buoyancy. Ecological niches for sinkers, floaters, and hunters appear to exist in the Jovian atmosphere.</p>'
- - /docs/modafinil/2020-mereu.pdf
  - ! "Modafinil potentiates cocaine self–administration by a dopamine–independent mechanism: possible involvement of gap junctions"
  - Maddalena Mereu, Takato Hiranita, Chloe J. Jordan, Lauren E. Chun, Jessica P. Lopez, Mark A. Coggiano, Juliana C. Quarterman, Guo-Hua Bi, Jacqueline D. Keighron, Zheng-Xiong Xi, Amy Hauck Newman, Jonathan L. Katz, Gianluigi Tanda
  - 2020-04-27
  - 10.1038/s41386-020-0680-5
  - ! '<p>Modafinil and methylphenidate are medications that inhibit the neuronal reuptake of dopamine, a mechanism shared with cocaine. Their use as “smart drugs” by healthy subjects poses health concerns and requires investigation. We show that methylphenidate, but not modafinil, maintained intravenous self-administration in Sprague-Dawley rats similar to cocaine. Both modafinil and methylphenidate pretreatments potentiated cocaine self-administration. Cocaine, at self-administered doses, stimulated mesolimbic dopamine levels. This effect was potentiated by methylphenidate, but not by modafinil pretreatments, indicating dopamine-dependent actions for methylphenidate, but not modafinil. Modafinil is known to facilitate electrotonic neuronal coupling by actions on gap junctions. Carbenoxolone, a gap junction inhibitor, antagonized modafinil, but not methylphenidate potentiation of cocaine self-administration. Our results indicate that modafinil shares mechanisms with cocaine and methylphenidate but has a unique pharmacological profile that includes facilitation of electrotonic coupling and lower abuse liability, which may be exploited in future therapeutic drug design for cocaine use disorder.</p>'
- - /docs/ai/anime/2020-koyama.pdf
  - ! "System for searching illustrations of anime characters focusing on degrees of character attributes"
  - Yuta Koyama, Tomohiro Fukuhara, Koichi Yamada, Hironobu Abe, Hidetaka Masuda
  - 2020-06-01
  - 10.1117/12.2566509
  - ! '<p>Keyword searches are generally used when searching for illustrations of anime characters. However, keyword searches require that the illustrations be tagged first. The illustration information that a tag can express is limited, and it is difficult to search for a specific illustration. We focus on character attributes that are difficult to express using tags. We propose a new search method using the vectorization degrees of character attributes. Accordingly, we first created a character illustration dataset limited to the hair length attribute and then trained a convolutional neural network (<span class="smallcaps-auto">CNN</span>) to extract the features. We obtained a [illustration2vec Danbooru] vector representation of the character attributes using <span class="smallcaps-auto">CNN</span> and confirmed that they could be used for new searches. [Keywords: Illustration search, Anime characters, Vectorization, <span class="smallcaps-auto">CNN</span>]</p>'
- - /docs/genetics/correlation/2020-quinn.pdf
  - ! "Need to Account for Familial Confounding in Systematic Review and Meta–analysis of Prenatal Tobacco Smoke Exposure and Schizophrenia"
  - "Patrick D. Quinn, Sandra M. Meier, Brian M. D'Onofrio"
  - 2020-04-02
  - 10.1093/ntr/ntaa058
  - ! '<p>In the context of continued uncertainty regarding the long-term mental health effects of prenatal exposure to maternal smoking during pregnancy, we read with great interest the recently published meta-analysis of smoking and schizophrenia by Hunter and colleagues.1 Although the meta-analysis found that “exposure to prenatal smoke increased the risk of schizophrenia by 29%” (p. 3), the authors noted that “familial confounding may explain some of the observed association” (p. 8). We agree with the importance of this alternative hypothesis. In fact, we were surprised that the review did not consider the results of sibling comparison studies that have directly addressed it, particularly given that the review had the opportunity to do so using data from articles included in the meta-analysis.</p><p>…The two studies of interest represented over 60% of the weighted sample. They yielded covariate-adjusted hazard ratios of 1.33 (95% confidence interval [CI], 1.23–1.45) and 1.13 (95% CI, 1.05–1.23). However, their sibling comparison results, which were excluded from the review, were weaker and not statistically significant (hazard ratios, 1.21 [95% CI, 0.96–1.52] and 1.09 [0.84–1.42], respectively). These results suggest that familial confounding, rather than a true casual effect, explains much of the observed associations. The weaker associations from the sibling comparisons may thus dampen enthusiasm regarding a potentially meaningful role of exposure to maternal smoking during pregnancy in offspring schizophrenia. An approximately 10%–20% relative difference in rates of what is a rare outcome would suggest that modifying maternal smoking would have only a limited impact on the incidence of offspring schizophrenia.</p>'
- - /docs/modafinil/2020-zager.pdf
  - ! "Modulating the immune response with the wake–promoting drug modafinil: A potential therapeutic approach for inflammatory disorders"
  - Adriano Zager
  - 2020-04-18
  - 10.1016/j.bbi.2020.04.038
  - ! '<p><strong>Highlights</strong>:</p><ul><li>Modafinil is a psychostimulant drug approved for the treatment of sleep disorders.</li><li>Recent preclinical findings point to a immunomodulatory property of modafinil.</li><li>Modafinil impairs immune cells infiltration and glial activation during neuroinflammation.</li><li>Modafinil decreases neuroinflammation in models of neurodegenerative diseases.</li><li>Modafinil may be useful as adjuvant treatment for neurodegenerative diseases.</li></ul><p><strong>Abstract</strong>: Modafinil is a psychostimulant drug approved by the <span class="smallcaps-auto"><span class="smallcaps-auto">FDA</span></span> primarily for the treatment of sleep disorders such as narcolepsy, excessive daytime sleepiness and sleep apnea. Several documented but not yet approved uses for modafinil have been described over the last 30 years, including alleviating fatigue in neurological and neurodegenerative disorders. Recent evidence has suggested that modafinil may have an immunomodulatory effect. Here, we review the different effects of modafinil treatment in animal models of brain inflammation and peripheral immune function. We conclude that there is unequivocal evidence of an anti-inflammatory effect of modafinil in experimental animal models of brain inflammation and neurodegenerative disorders, including systemic inflammation and methamphetamine-induced neuroinflammation, Parkinson’s disease, brain ischemia, and multiple sclerosis. Modafinil acts on resident glial cells and infiltrating immune cells, negatively affecting both innate and adaptive immune responses in the brain. We also review the outcomes of modafinil treatment on peripheral immune function. The results of studies on this subject are still controversial and far from conclusive, but point to a new avenue of research in relation to peripheral inflammation. The data reviewed here raise the possibility of modafinil being used as adjuvant treatment for neurological disorders in which inflammation plays an important role. [Keywords: modafinil, immunity, inflammation, dopamine, microglia, T cells, macrophages]</p>'
- - /docs/design/1954-chaundy-theprintingofmathematics.pdf
  - ! "The Printing of Mathematics: Aids for Authors and Editors and Rules for Compositors and Readers at the University Press, Oxford"
  - T. W. Chaundy, P. R. Barrett, Charles Batey
  - 1954-01-01
  - ''
  - ! '<p>Although mechanical composition had become firmly established in printing-houses long before 1930, no significant attempt had been made before that time to develop the resources of the machine, or adapt the technique of the machine compositor, to the exacting demands of mathematical printing. In that year the first serious approach to the problem was made at the University Press in Oxford. The early experiments were made in collaboration with Professor G. H. Hardy and Professor R. H. Fowler, and the editors of the Quarterly Journal of Mathematics (for which these first essays were designed) and with the Monotype Corporation. Much adaptation and recutting of type faces was necessary before the new system could be brought into use. These joint preparations included the drafting of an entirely new code of ‘Rules for the Composition of Mathematics’ which has been reserved hitherto for the use of compositors at the Press and those authors and editors whose work was produced under the Press imprints. It is now felt that these rules should have a wider circulation since, in the twenty years which have intervened, they have acquired a greater significance.</p><p>…The original ‘Rules’, themselves amended by continuous trial and rich experience, are here preceded by two new chapters. The first chapter is a simple explanation of the technique of printing and is addressed to those authors who are curious to know how their writings are transformed to the orderliness of the printed page; the second chapter, begun as the offering of a mathematical author and editor to his fellow-workers in this field, culled from notes gathered over many years, has ended in closest collaboration with the reader who for as many years has reconciled the demands of author, editor, and printer; the third chapter is the aforesaid collection of ‘Rules’ and is intended for compositors, readers, authors, and editors. Appendixes follow on Handwriting, Types available, and Abbreviations. It is not expected that anyone will read this book from cover to cover, but it is hoped that both author and printer will find it an acceptable and ready work of reference.</p><p>List Of Illustrations · I. The Mechanics Of Mathematical Printing · II. Recommendations To Mathematical Authors · 1. Introduction · 2. Fractions · 3. Surds · 4. Superiors And Inferiors · 5. Brackets · 6. Embellished Characters · 7. Displayed Formulae · 8. Notation (Miscellaneous) · 9. Headings And Numbering · 10. Footnotes And References · 11. Varieties Of Type · 12. Punctuation · 13. Wording · 14. Preparing Copy · 15. Corrections Of Proofs · 16. Final Queries And Offprints · <span class="smallcaps-auto">III</span>. Rules For The Composition Of Mathematics At The University Press, Oxford · Appendixes: · A. Legible Handwriting · B. Type Specimens And List Of Special Sorts · C. Abbreviations · Index</p>'
- - /docs/psychology/2020-haslam.pdf
  - ! "Dimensions over categories: a meta–analysis of taxometric research"
  - Nick Haslam, Melanie J. McGrath, Wolfgang Viechtbauer, Peter Kuppens
  - 2020-06-04
  - 10.1017/S003329172000183X
  - ! '<p>Taxometric procedures have been used extensively to investigate whether individual differences in personality and psychopathology are latently dimensional or categorical (‘taxonic’). We report the first meta-analysis of taxometric research, examining 317 findings drawn from 183 articles that employed an index of the comparative fit of observed data to dimensional and taxonic data simulations. Findings supporting dimensional models outnumbered those supporting taxonic models five to one. There were systematic differences among 17 construct domains in support for the two models, but psychopathology was no more likely to generate taxonic findings than normal variation (i.e. individual differences in personality, response styles, gender, and sexuality). No content domain showed aggregate support for the taxonic model. Six variables—alcohol use disorder, intermittent explosive disorder, problem gambling, autism, suicide risk, and pedophilia—emerged as the most plausible taxon candidates based on a preponderance of independently replicated findings. We also compared the 317 meta-analyzed findings to 185 additional taxometric findings from 96 articles that did not employ the comparative fit index. Studies that used the index were 4.88 times more likely to generate dimensional findings than those that did not after controlling for construct domain, implying that many taxonic findings obtained before the popularization of simulation-based techniques are spurious. The meta-analytic findings support the conclusion that the great majority of psychological differences between people are latently continuous, and that psychopathology is no exception.</p>'
- - https://srconstantin.wordpress.com/2016/10/20/ra/
  - Ra
  - Sarah Constantin
  - 2016-10-20
  - ''
  - ! '<p>[Speculative essay about a specific kind of groupthink and failure mode of institutions: a pursuit of prestige, legitimacy, and respectability detached from reality, a prizing of vagueness and inscrutability and superficial perfection and avoidance of anything that might seem absurd or daring or mockable.]</p><p>The Egyptian god Ra was a symbol of divine kingship, all-powerful and all-seeing. He’s a good metaphor for a certain kind of psychological phenomenon that involves thought distortions around authority and legitimacy…The idea of a malign Establishment is somewhat convergent:</p><ul><li>The Establishment (attributed to Henry Fairlie in 1950’s Britain, talking about an informal social network of power among prominent, well-connected people)</li><li>The Man (e.g. Yippies, Burning Man)</li><li>The Combine (Ken Kesey)</li><li>Moloch (Allen Ginsberg)</li><li>The Beige Dictatorship (Charles Stross)</li><li>The Cathedral (Mencius Moldbug)</li><li>The Mandarins (Megan McArdle)</li></ul><p>Not all of these ideas are coterminous with Ra, or identical to each other.</p><p>What they have in common is that the Establishment is primarily an upper-class phenomenon, that it is more about social and moral legitimacy than mere wealth or raw power, and that it is <em>boringly evil</em>—it produces respectable, normal, right-thinking, mild-mannered people who do things with very bad consequences.</p><p>…Ra is something more like a psychological mindset, that causes people to actually <i>seek</i> corruption and confusion, and to <i>prefer corruption for its own sake</i> — though, of course, it doesn’t feel quite like that from the inside.</p><p>Ra is a specific kind of glitch in intuition, which can roughly be summarized as the drive to <i>idealize vagueness and despise clarity. </i>I’m going to try to define it by extension, using examples from my and others’ personal experiences.</p><p><strong>Ra is about generic superlativity.</strong></p><p>You know how universal gods are praised with formulas that call them glorious, mighty, exalted, holy, righteous, and other suchlike adjectives, all of which are perfectly <i>generic </i>and involve no <i>specific characteristics</i> except wonderfulness? That’s what Ra is all about.</p><p>The worship of Ra involves a preference for stockpiling money, accolades, awards, or other resources, beyond what you can meaningfully consume or make practical use of; a felt sense of wanting to attain that abstract radiance of “bestness”.</p><p>…<strong>Ra defends itself with vagueness, confusion, incoherence — and then anger.</strong></p><p>“Respectability” turns out to be incoherent quite often — i.e. if you have <i>any </i>consistent model of the world you often have to take extreme or novel positions as a logical conclusion from your assumptions. To Ra, disrespectability is damnation, and thus consistent thought is suspect.</p><p>Vagueness, mental fog, “underconfidence”, avoidance, evasion, blanking out, etc. are hallmarks of Ra. If cornered, a person embodying Ra will abruptly switch from blurry vagueness to <i>anger </i>and <i>nihilism</i>…Ra causes persistent brain fog or confusion, especially around economic thinking or cost-benefit analysis or quantitative estimates.</p><p>…Ra promotes the idea that <i>optimal politeness conveys as little information as possible</i>. That you should actively try to hide preferences (because if you shared them, you’d inconvenience others by pressuring them to satisfy your preferences). That all compliments are empty pleasantries. There’s an interpretation of “politeness” that’s anti-cooperative, that avoids probing for opportunities for genuine mutual benefit or connection and just wants to make the mutual defection process go as smoothly as possible. Ra prefers this, because it’s less revealing, commits you less, doesn’t pin you down, allows you to keep all your options open and devote everything to the pursuit of Ra…I’ve had my writing criticized because “when you give your opinion, it sounds like you think you’re smart”.</p>'
- - /docs/xrisks/2020-kokotajlo.pdf
  - ! "Counterproductive Altruism: The Other Heavy Tail"
  - Daniel Kokotajlo, Alexandra Oprea
  - 2020-05-30
  - 10.1111/phpe.12133
  - ! '<p>First, we argue that the appeal of effective altruism (henceforth, EA) depends significantly on a certain empirical premise we call the Heavy Tail Hypothesis (<span class="smallcaps-auto">HTH</span>), which characterizes the probability distribution of opportunities for doing good. Roughly, the <span class="smallcaps-auto">HTH</span> implies that the best causes, interventions, or charities produce orders of magnitude greater good than the average ones, constituting a substantial portion of the total amount of good caused by altruistic interventions. Next, we canvass arguments EAs have given for the existence of a positive (or “right”) heavy tail and argue that they can also apply in support of a negative (or “left”) heavy tail where counterproductive interventions do orders of magnitude more harm than ineffective or moderately harmful ones. Incorporating the other heavy tail of the distribution has important implications for the core activities of EA: effectiveness research, cause prioritization, and the assessment of altruistic interventions. It also informs the debate surrounding the institutional critique of EA.</p>'
- - /docs/statistics/bayes/2020-miller.pdf
  - ! "Laplace’s Theories of Cognitive Illusions, Heuristics and Biases"
  - Joshua B. Miller, Andrew Gelman
  - 2020-06-03
  - 10.1214/19-STS696
  - ! '<p>In his book from the early 1800s, <em>Essai Philosophique sur les Probabilités</em>, the mathematician Pierre-Simon de Laplace anticipated many ideas developed within the past 50 years in cognitive psychology and behavioral economics, explaining human tendencies to deviate from norms of rationality in the presence of probability and uncertainty. A look at Laplace’s theories and reasoning is striking, both in how modern they seem, how much progress he made without the benefit of systematic experimentation, and the novelty of a few of his unexplored conjectures. We argue that this work points to these theories being more fundamental and less contingent on recent experimental findings than we might have thought.</p>'
- - /docs/psychology/2006-deady.pdf
  - ! "Height in women predicts maternal tendencies and career orientation"
  - Denis K. Deady, Miriam J. Law Smith
  - 2006-01-01
  - 10.1016/j.paid.2005.06.014
  - ! '<p>Previous research has shown that variation in sex-specific personality traits in women can be predicted by measures of physical masculinisation (second to fourth digit ratio and circulating testosterone). This study aimed to test the hypothesis that certain sex-specific traits in women (maternal tendencies and career orientation) could be predicted by one index of masculinisation, height. Data was collected via online questionnaires. In pre-reproductive women (aged 20–29, <em>n</em>=679), increasing height related to decreasing maternal personality (lower importance of having children, lower maternal/broodiness) and decreasing reproductive ambition (fewer ideal number of children, older ideal own age to have first child). Increasing height also related to increasing career orientation (higher importance of having a career, and higher career competitiveness). In post-reproductive women (aged over 45, <em>n</em>=541), increasing height related to decreased reproductive events (fewer children, had first child at older age) and increased career orientation. Results provide further support for previous studies that show physical masculinisation is associated with psychological masculinisation.</p>'
- - /docs/history/2011-connell.pdf
  - ! "The Eternity of the World and Renaissance Historical Thought"
  - William J. Connell
  - 2011-01-01
  - ''
  - ! '<p>This essay suggests that the Renaissance revolution in historical thought was encouraged by contemporary debates over the Aristotelian-<a href="https://en.wikipedia.org/wiki/Averroes">Averroistic</a> doctrine of <a href="https://en.wikipedia.org/wiki/Eternity_of_the_world">the eternity of the world</a>. In the early Renaissance eternalism came to be understood as a proposition with controversial consequences not only for the creation of matter <em>ex nihilo</em> but also for the record of historical time. Modern scholarship, following Momigliano, believes that understandings of time had little effect on the practice of ancient historians. But that was not the view of <a href="https://en.wikipedia.org/wiki/Orosius">Orosius</a>, the most widely read historian during the Middle Ages, who condemned the pagan historians for their eternalism. Nor was it the view of the Italian humanists who, after reading the Greek historians, abandoned the providentialism of Orosius and revived ancient ways of writing history.</p>'
- - /docs/nootropics/2017-carharttharris.pdf
  - ! "Serotonin and brain function: a tale of two receptors"
  - R. L. Carhart-Harris, D. J. Nutt
  - 2017-08-31
  - 10.1177/0269881117725915
  - ! '<p>Previous attempts to identify a unified theory of brain serotonin function have largely failed to achieve consensus. In this present synthesis, we integrate previous perspectives with new and older data to create a novel bipartite model centred on the view that serotonin neurotransmission enhances two distinct adaptive responses to adversity, mediated in large part by its two most prevalent and researched brain receptors: the 5-HT1A and 5-HT2A receptors. We propose that <em>passive coping</em> (i.e. tolerating a source of stress) is mediated by postsynaptic 5-HT1AR signalling and characterised by stress moderation. Conversely, we argue that <em>active coping</em> (i.e. actively addressing a source of stress) is mediated by 5-HT2AR signalling and characterised by enhanced plasticity (defined as capacity for change). We propose that 5-HT1AR-mediated stress moderation may be the brain’s default response to adversity but that an improved ability to change one’s situation and/or relationship to it via 5-HT2AR-mediated plasticity may also be important—and increasingly so as the level of adversity reaches a critical point. We propose that the 5-HT1AR pathway is enhanced by conventional 5-HT reuptake blocking antidepressants such as the selective serotonin reuptake inhibitors (<span class="smallcaps-auto">SSRI</span>s), whereas the 5-HT2AR pathway is enhanced by 5-HT2AR-agonist psychedelics. This bipartite model purports to explain how different drugs (<span class="smallcaps-auto">SSRI</span>s and psychedelics) that modulate the serotonergic system in different ways, can achieve complementary adaptive and potentially therapeutic outcomes.</p>'
- - /docs/technology/2005-shirky-agroupisitsownworstenemy.pdf
  - ! "A Group is Its Own Worst Enemy"
  - Clay Shirky
  - 2005-01-01
  - 10.1007/978-1-4302-0038-3_23
  - ! '<p>…We had new applications like the Web, email, instant messaging, and bulletin boards, all of which were about humans communicating with one another through software. Now, suddenly, when you create software, it isn’t sufficient to think about making it possible to communicate; you have to think about making communication socially successful. In the age of usability, technical design decisions had to be taken to make software easier for a mass audience to use; in the age of social software, design decisions must be taken to make social groups survive and thrive and meet the goals of the group even when they contradict the goals of the individual. A discussion group designed by a usability expert might be optimized to make it easy to post spam about Viagra. But in social software design it’s pretty obvious that the goal is to make certain things harder, not easier, and if you can make it downright impossible to post spam, you’ve done your job. Features need to be designed to make the group successful, not the individual.</p><p>Today, hardly anybody really studies how to design software for human-to-human interaction. The field of social software design is in its infancy. In fact, we’re not even at the point yet where the software developers developing social software realize that they need to think about the sociology and the anthropology of the group that will be using their software, so many of them just throw things together and allow themselves to be surprised by the social interactions that develop around their software. Clay Shirky has been a pioneer in this field, and his talk “A Group Is Its Own Worst Enemy” will be remembered as a watershed in the widespread realization that in this new era, sociology and anthropology are just as crucial to software design as usability was in the last. —Joel Spolsky</p><hr /><p>People who work on social software are closer in spirit to economists and political scientists than they are to people making compilers. They both look like programming, but when you’re dealing with groups of people as one of your run-time phenomena, that is an incredibly different practice. In the political realm, we would call these kinds of crises a constitutional crisis. It’s what happens when the tension between the individual and the group, and the rights and responsibilities of individuals and groups, gets so serious that something has to be done. And the worst crisis is the first crisis, because it’s not just “We need to have some rules.” It’s also “We need to have some rules for making some rules.” And this is what we see over and over again in large and long-lived social software systems. Constitutions are a necessary component of large, long-lived, heterogeneous groups. “The likelihood that any unmoderated group will eventually get into a flame-war about whether or not to have a moderator approaches one as time increases.” As a group commits to its existence as a group, and begins to think that the group is good or important, the chance that they will begin to call for additional structure, in order to defend themselves from themselves, gets very, very high.</p><ol type="1"><li>You cannot completely separate technical and social issues</li><li>Members [power users] are different than users.</li><li>The core group has rights that trump individual rights in some situations.</li></ol><p>…if you don’t accept them upfront, they’ll happen to you anyway. And then you’ll end up writing one of those documents that says “Oh, we launched this and we tried it, and then the users came along and did all these weird things. And now we’re documenting it so future ages won’t make this mistake.”</p><ol type="1"><li>…If you were going to build a piece of social software to support large and long-lived groups, what would you design for? The first thing you would design for is handles the user can invest in.</li><li>you have to design a way for there to be members in good standing. Have to design some way in which good works get recognized. The minimal way is, posts appear with identity. You can do more sophisticated things like having formal karma or “member since.”</li><li>Three, you need barriers to participation. This is one of the things that killed Usenet. You have to have some cost to either join or participate, if not at the lowest level, then at higher levels. There needs to be some kind of segmentation of capabilities.</li><li>And, finally, you have to find a way to spare the group from scale. Scale alone kills conversations, because conversations require dense two-way conversations.</li></ol>'
- - /docs/psychology/2020-gabay.pdf
  - ! "The tendency for interpersonal victimhood: The personality construct and its consequences"
  - Rahav Gabay, Boaz Hameiri, Tammy Rubel-Lifschitz, Arie Nadler
  - 2020-10-15
  - 10.1016/j.paid.2020.110134
  - ! '<p>In the present research, we introduce a conceptualization of the Tendency for Interpersonal Victimhood (<span class="smallcaps-auto">TIV</span>), which we define as an enduring feeling that the self is a victim across different kinds of interpersonal relationships. Then, in a comprehensive set of eight studies, we develop a measure for this novel personality trait, <span class="smallcaps-auto">TIV</span>, and examine its correlates, as well as its affective, cognitive, and behavioral consequences. In Part 1 (Studies 1A-1C) we establish the construct of <span class="smallcaps-auto">TIV</span>, with its four dimensions; i.e., need for recognition, moral elitism, lack of empathy, and rumination, and then assess <span class="smallcaps-auto">TIV</span>’s internal consistency, stability over time, and its effect on the interpretation of ambiguous situations. In Part 2 (Studies 2A-2C) we examine <span class="smallcaps-auto">TIV</span>’s convergent and discriminant validities, using several personality dimensions, and the role of attachment styles as conceptual antecedents. In Part 3 (Studies 3–4) we explore the cognitive and behavioral consequences of <span class="smallcaps-auto">TIV</span>. Specifically, we examine the relationships between <span class="smallcaps-auto">TIV</span>, negative attribution and recall biases, and the desire for revenge (Study 3), and the effects of <span class="smallcaps-auto">TIV</span> on behavioral revenge (Study 4). The findings highlight the importance of understanding, conceptualizing, and empirically testing <span class="smallcaps-auto">TIV</span>, and suggest that victimhood is a stable and meaningful personality tendency. [Keywords: victimhood, interpersonal relations, personality, cognitive biases, attachment styles]</p>'
- - https://justpaste.it/7eovk#javascript
  - 'GPT-3 random sample dump: JavaScript tutorial'
  - GPT-3
  - 2020-05-28
  - ''
  - ! '<p>[Sample from <span class="smallcaps-auto">GPT</span>-3; condensed paragraphs &amp; formatting added for legibility inside popups, as the original plain text dumps strip the original <span class="smallcaps-auto">HTML</span> formatting of tutorials etc.]</p><p>Working with an example—rotating through an array For a number of years, I’ve been fascinated by the idea of writing code that can rotate through an array. Let’s say I have the following array of numbers:</p><div class="sourceCode" id="cb1"><pre class="sourceCode JavaScript"><code class="sourceCode javascript"><span id="cb1-1"><a href="https://justpaste.it/7eovk#cb1-1"></a><span class="kw">var</span> myNumbers <span class="op">=</span> [ <span class="dv">1</span><span class="op">,</span> <span class="dv">2</span><span class="op">,</span> <span class="dv">3</span><span class="op">,</span> <span class="dv">4</span><span class="op">,</span> <span class="dv">5</span> ]<span class="op">;</span></span></code></pre></div><p>The following snippet of code would display the same numbers in reverse order:</p><div class="sourceCode" id="cb2"><pre class="sourceCode JavaScript"><code class="sourceCode javascript"><span id="cb2-1"><a href="https://justpaste.it/7eovk#cb2-1"></a><span class="cf">for</span> ( <span class="kw">var</span> i <span class="op">=</span> myNumbers<span class="op">.</span><span class="at">length</span> <span class="op">-</span> <span class="dv">1</span><span class="op">;</span> i <span class="op">&gt;=</span> <span class="dv">0</span><span class="op">;</span> i<span class="op">--</span> ) { <span class="bu">console</span><span class="op">.</span><span class="fu">log</span>( myNumbers[i] )<span class="op">;</span> }</span></code></pre></div><p>What’s going on here?</p><p>We know that the index of an array can be used as a “pointer” to the location in memory that contains a particular item in an array. If the array <code>myNumbers</code> has five items, then <code>myNumbers[0]</code> , <code>myNumbers[1]</code> , <code>myNumbers[2]</code> , <code>myNumbers[3]</code> and <code>myNumbers[4]</code> will point to the values 1 , 2 , 3 , 4 and 5 respectively.</p><p>In the previous example, the code starts with the length of the array (5) and subtracts one from it. As we know that index 0 in an array contains the first item in the array, the previous code will execute the following steps: Take the length of the array (5) Subtract 1 (so we now have 4) Start at the index that contains the first item in the array (<code>myNumbers[4]</code> = 3) and run down the array until we reach the last item in the array (<code>myNumbers[3]</code> = 5) So the above code will end up displaying the items in the array in reverse order, starting at index 4 and working backwards to index 0. At this point, we have a good idea of how we can access the values in an array in a specific order, but how do we go the other way?</p><p>It would be great if we could simply use the same code as above, but add a “–” operator before the last number. That way, we could add a simple parameter to the code to control the range of numbers it will use. Unfortunately, we can’t do that. While JavaScript will happily work with <code>--</code> , it will also happily take <code>--</code> in code and convert it to −1 , or the last number in an array. That’s not going to do us any good, as we want the code to be flexible enough that we can work with a number that we specify as the range of numbers.</p><p>So let’s look at a simple function that can give us the results we need.</p><div class="sourceCode" id="cb3"><pre class="sourceCode JavaScript"><code class="sourceCode javascript"><span id="cb3-1"><a href="https://justpaste.it/7eovk#cb3-1"></a><span class="kw">function</span> <span class="fu">rotate</span>(numbers<span class="op">,</span> direction<span class="op">,</span> number) { numbers<span class="op">.</span><span class="fu">reverse</span>()<span class="op">;</span> numbers<span class="op">.</span><span class="fu">push</span>(number)<span class="op">;</span> numbers<span class="op">.</span><span class="fu">unshift</span>(number)<span class="op">;</span> }<span class="op">;</span></span></code></pre></div><p>The <code>rotate</code> function above has three parameters, and will rotate the values in the numbers array. …</p>'
- - https://arxiv.org/pdf/2005.14165.pdf&org=openai#page=48
  - "GPT-3 paper: Figure F.1: Four uncurated completions from a context suggesting the model compose a poem in the style of Wallace Stevens with the title 'Shadows on the Way'"
  - GPT-3
  - 2020-05-28
  - ''
  - ! '<p>As an example, in Figure F.1, we show 4 uncurated samples from a prompt suggesting that the model write a poem, with a given title, in the style of Wallace Stevens. We first experimented with a few prompts, then generated 4 samples with no additional editing or selection (sampling at temperature 1 using <a href="https://arxiv.org/abs/1904.09751#allen" title="&#39;The Curious Case of Neural Text Degeneration&#39;, Holtzman et al 2020">nucleus sampling [HBFC19]</a> with P = 0.9). Completions were truncated when the model began to write a new title and author heading, or broke into prose commentary.</p><p>…“Shadows on the Way”, Wallace Stevens:</p><ol type="1"><li>I must have shadows on the way / If I am to walk I must have / Each step taken slowly and alone / To have it ready made // And I must think in lines of grey / To have dim thoughts to be my guide / Must look on blue and green / And never let my eye forget / That color is my friend / And purple must surround me too // The yellow of the sun is no more / Intrusive than the bluish snow / That falls on all of us. I must have / Grey thoughts and blue thoughts walk with me / If I am to go away at all.</li><li>There is a way in the world. / That way a man may live in a small town / His lifetime and see no man come, / Never the stir of men about a market, / Never the bobbing of covered carts, / Never the creak passed on the stair / Closing some other life; an old man / Can prosper in that town, can prosper / When his store is seen to close, his wife / Fades in his house, and the world shouts in vain / That no one comes to hear him / Where his small bell tolls. / In that small town / Everything is known. / The ways of the young men are known, / And the ways of the young women / As they walk to the Spring; / The rumors are all known, / The quarrels, the hurt, the envy / Of the men and the women. / Till a day comes / That way out of the world / That leads to a wood. / Young, the young man / Walks, a lover now, / Knows the streets as they are and is of them.</li><li>The sun was all we had. Now, in the shade / All is changed. The mind must dwell on those / White fields, that to its eyes were always old; / Those ancient gleams, convoluting / The way they lay among the huge roots, / The great dark tomes of reverie, / The plumed labyrinth of the sea. // When our own breath gone faint and fade / Up the long stairway of the dead / We shall remember well / The blindness of the light, the whiteness / Of that white land. The footsteps, and / The grasses in that light, and in the shade / The menacing life. // We played, too, once, in the warmest rooms. / To one content, there is one content / For all mankind. The forest glades/ Are all the more for being in fable, / And wood and town in legend shadowed- / Once more to return. The one content / Has in it every happiness, more brave / For being purposeless; and so / Those island gardens, deep in the mind, / Make of remoteness familiarity / And of the unspoken name a friend.</li><li>Nobody will come to this place. It is a road that leads nowhere. / The solitude is deep. The mountains are high. / But they are desolate, and they turn the traveler’s face / Towards the North. All the sounds of the world are far away. / When the wind rises above the trees, / The boughs bow to the ground. / Even the birds that inhabit the tangle of weeds / That is the roadside cover, are silent. One listens, / But hears no roar of the forest. One is alone. / One will be taken. / One will be taken. / There is no utterance, there is no conversation, / But one is uneasy all the same… / There is a thin blue mist, / A darkness rising like smoke, / And within that darkness / A possession of the heart. / One will be taken… It was here, and it will be here again- / Here, under this sky empty and full of light.</li></ol>'
- - /GPT-3#prompts-as-programming
  - "GPT-3: Prompts As Programming"
  - Gwern Branwen
  - 2020-06-23
  - ''
  - ! '<p>The <a href="/GPT-3"><span class="smallcaps-auto">GPT</span>-3</a> neural network is so large a model in terms of power and dataset that it exhibits qualitatively different behavior: you do not apply it to a fixed set of tasks which were in the training dataset, requiring retraining on additional data if one wants to handle a new task (as one would have to retrain <a href="/GPT-2"><span class="smallcaps-auto">GPT</span>-2</a>); instead, you interact with it, expressing any task in terms of natural language descriptions, requests, and examples, tweaking the prompt until it “understands” &amp; it meta-learns the new task based on the high-level abstractions it learned from the pretraining.</p><p>This is a rather different way of using a DL model, and it’s better to think of it as a new kind of programming, where the prompt is now a “program” which programs <span class="smallcaps-auto">GPT</span>-3 to do new things.</p>'
- - /docs/psychology/2020-jones.pdf
  - ! "Helping or Harming? The Effect of Trigger Warnings on Individuals With Trauma Histories"
  - Payton J. Jones, Benjamin W. Bellet, Richard J. McNally
  - 2020-06-01
  - 10.1177/2167702620921341
  - ! '<p>Trigger warnings alert trauma survivors about potentially disturbing forthcoming content. However, empirical studies on trigger warnings suggest that they are functionally inert or cause small adverse side effects. We conducted a preregistered replication and extension of a previous experiment. Trauma survivors (<em>n</em>=451) were randomly assigned to either receive or not to receive trigger warnings before reading passages from world literature. We found no evidence that trigger warnings were helpful for trauma survivors, for participants who self-reported a post-traumatic stress disorder (<span class="smallcaps-auto">PTSD</span>) diagnosis, or for participants who qualified for probable <span class="smallcaps-auto">PTSD</span>, even when survivors’ trauma matched the passages’ content. We found substantial evidence that trigger warnings counter-therapeutically reinforce survivors’ view of their trauma as central to their identity. Regarding replication hypotheses, the evidence was either ambiguous or substantially favored the hypothesis that trigger warnings have no effect. In summary, we found that trigger warnings are not helpful for trauma survivors. [Keywords: trigger warning, trauma, <span class="smallcaps-auto">PTSD</span>, resilience, replication, open data, open materials, preregistered]</p>'
- - /docs/genetics/heritable/2020-ishigaki.pdf
  - ! "Large–scale genome–wide association study in a Japanese population identifies novel susceptibility loci across different diseases"
  - Kazuyoshi Ishigaki, Masato Akiyama, Masahiro Kanai, Atsushi Takahashi, Eiryo Kawakami, Hiroki Sugishita, Saori Sakaue, Nana Matoba, Siew-Kee Low, Yukinori Okada, Chikashi Terao, Tiffany Amariuta, Steven Gazal, Yuta Kochi, Momoko Horikoshi, Ken Suzuki, Kaoru Ito, Satoshi Koyama, Kouichi Ozaki, Shumpei Niida, Yasushi Sakata, Yasuhiko Sakata, Takashi Kohno, Kouya Shiraishi, Yukihide Momozawa, Makoto Hirata, Koichi Matsuda, Masashi Ikeda, Nakao Iwata, Shiro Ikegawa, Ikuyo Kou, Toshihiro Tanaka, Hidewaki Nakagawa, Akari Suzuki, Tomomitsu Hirota, Mayumi Tamari, Kazuaki Chayama, Daiki Miki, Masaki Mori, Satoshi Nagayama, Yataro Daigo, Yoshio Miki, Toyomasa Katagiri, Osamu Ogawa, Wataru Obara, Hidemi Ito, Teruhiko Yoshida, Issei Imoto, Takashi Takahashi, Chizu Tanikawa, Takao Suzuki, Nobuaki Sinozaki, Shiro Minami, Hiroki Yamaguchi, Satoshi Asai, Yasuo Takahashi, Ken Yamaji, Kazuhisa Takahashi, Tomoaki Fujioka, Ryo Takata, Hideki Yanai, Akihide Masumoto, Yukihiro Koretsune, Hiromu Kutsumi, Masahiko Higashiyama, Shigeo Murayama, Naoko Minegishi, Kichiya Suzuki, Kozo Tanno, Atsushi Shimizu, Taiki Yamaji, Motoki Iwasaki, Norie Sawada, Hirokazu Uemura, Keitaro Tanaka, Mariko Naito, Makoto Sasaki, Kenji Wakai, Shoichiro Tsugane, Masayuki Yamamoto, Kazuhiko Yamamoto, Yoshinori Murakami, Yusuke Nakamura, Soumya Raychaudhuri, Johji Inazawa, Toshimasa Yamauchi, Takashi Kadowaki, Michiaki Kubo, Yoichiro Kamatani
  - 2020-06-08
  - 10.1038/s41588-020-0640-3
  - ! '<p>The overwhelming majority of participants in current genetic studies are of European ancestry. To elucidate disease biology in the East Asian population, we conducted a genome-wide association study (<span class="smallcaps-auto">GWAS</span>) with 212,453 Japanese individuals across 42 diseases. We detected 320 independent signals in 276 loci for 27 diseases, with 25 novel loci (<em>p</em>&lt; 9.58 × 10<sup>−9</sup>). East Asian–specific missense variants were identified as candidate causal variants for three novel loci, and we successfully replicated two of them by analyzing independent Japanese cohorts; p.R220W of <span class="smallcaps-auto">ATG</span>16L2 (associated with coronary artery disease) and p.V326A of <span class="smallcaps-auto">POT</span>1 (associated with lung cancer). We further investigated enrichment of heritability within 2,868 annotations of genome-wide transcription factor occupancy, and identified 378 significant enrichments across nine diseases (false discovery rate &lt; 0.05) (for example, <span class="smallcaps-auto">NKX</span>3-1 for prostate cancer). This large-scale <span class="smallcaps-auto">GWAS</span> in a Japanese population provides insights into the etiology of complex diseases and highlights the importance of performing <span class="smallcaps-auto">GWAS</span> in non-European populations.</p>'
- - https://www.nature.com/articles/s41598-019-55693-8
  - "Facial expressions of pain in cats: the development and validation of a Feline Grimace Scale"
  - Marina C. Evangelista, Ryota Watanabe, Vivian S. Y. Leung, Beatriz P. Monteiro, Elizabeth O’Toole, Daniel S. J. Pang. Paulo V. Steagall
  - 2019-12-13
  - 10.1038/s41598-019-55693-8
  - ! '<p>Grimace scales have been used for pain assessment in different species. This study aimed to develop and validate the Feline Grimace Scale (<span class="smallcaps-auto">FGS</span>) to detect naturally-occurring acute pain. Thirty-five client-owned and twenty control cats were video-recorded undisturbed in their cages in a prospective, case-control study. Painful cats received analgesic treatment and videos were repeated one hour later. Five action units (AU) were identified: ear position, orbital tightening, muzzle tension, whiskers change and head position. Four observers independently scored (0–2 for each AU) 110 images of control and painful cats. The <span class="smallcaps-auto">FGS</span> scores were higher in painful than in control cats; a very strong correlation with another validated instrument for pain assessment in cats was observed (rho = 0.86, <em>p</em>&lt;0.001) as well as good overall inter-rater reliability [<span class="smallcaps-auto">ICC</span> = 0.89 (95% CI: 0.85–0.92)], excellent intra-rater reliability (<span class="smallcaps-auto">ICC</span> &gt; 0.91), and excellent internal consistency (Cronbach’s alpha = 0.89). The <span class="smallcaps-auto">FGS</span> detected response to analgesic treatment (scores after analgesia were lower than before) and a cut-off score was determined (total pain score &gt; 0.39 out of 1.0). The <span class="smallcaps-auto">FGS</span> is a valid and reliable tool for acute pain assessment in cats.</p>'
- - /docs/ai/2020-bao.pdf
  - ! "A map of object space in primate inferotemporal cortex"
  - Pinglei Bao, Liang She, Mason McGill, Doris Y. Tsao
  - 2020-06-03
  - 10.1038/s41586-020-2350-5
  - ! '<p>The <a href="https://en.wikipedia.org/wiki/Inferior_temporal_gyrus">inferotemporal (IT) cortex</a> is responsible for object recognition, but it is unclear how the representation of visual objects is organized in this part of the brain. Areas that are selective for categories such as faces, bodies, and scenes have been found<sup>1,2,3,4,5</sup>, but large parts of IT cortex lack any known specialization, raising the question of what general principle governs IT organization. Here we used functional <span class="smallcaps-auto">MRI</span>, microstimulation, electrophysiology, and deep networks to investigate the organization of the macaque IT cortex. We built a low-dimensional object space to describe general objects using a feedforward deep neural network trained on object classification<sup>6</sup>. Responses of IT cells to a large set of objects revealed that single IT cells project incoming objects onto specific axes of this space. Anatomically, cells were clustered into four networks according to the first two components of their preferred axes, forming a map of object space. This map was repeated across three hierarchical stages of increasing view invariance, and cells that comprised these maps collectively harboured sufficient coding capacity to approximately reconstruct objects. These results provide a unified picture of IT organization in which category-selective regions are part of a coarse map of object space whose dimensions can be extracted from a deep network.</p>'
- - /docs/psychology/2020-matz.pdf
  - ! "Personality–Place Transactions: Mapping the Relationships Between Big Five Personality Traits, States, and Daily Places"
  - Sandra C. Matz, Gabriella M. Harari
  - 2020-06-04
  - 10.1037/pspp0000297
  - ! '<p>People actively select their environments, and the environments they select can alter their psychological characteristics in the moment and over time. Such dynamic person–environment transactions are likely to play out in the context of daily life via the places people spend time in (e.g., home, work, or public places like cafes and restaurants). This article investigates personality–place transactions at 3 conceptual levels: stable personality traits, momentary personality states, and short-term personality trait expressions. Three 2-week experience sampling studies (2 exploratory and 1 confirmatory with a total <em>n</em>=2,350 and more than 63,000 momentary assessments) were used to provide the first large-scale evidence showing that people’s stable Big Five traits are associated with the frequency with which they visit different places on a daily basis. For example, extraverted people reported spending less time at home and more time at cafés, bars, and friends’ houses. The findings also show that spending time in a particular place predicts people’s momentary personality states and their short-term trait expression over time. For example, people reported feeling more extraverted in the moment when spending time at bars/parties, cafés/restaurants, or friends’ houses, compared with when at home. People who showed preferences for spending more time in these places also showed higher levels of short-term trait extraversion over the course of 2 weeks. The findings make theoretical contributions to environmental psychology, personality dynamics, as well as the person–environment transactions literature, and highlight practical implications for a world in which the places people visit can be easily captured via <span class="smallcaps-auto">GPS</span> sensors.</p>'
- - /docs/ai/2019-dai.pdf
  - ! "SAN: Second–Order Attention Network for Single Image Super–Resolution"
  - Tao Dai, Jianrui Cai, Yongbing Zhang, Shu-Tao Xia, Lei Zhang
  - 2019-06-15
  - 10.1109/CVPR.2019.01132
  - ! '<p>Recently, deep convolutional neural networks (<span class="smallcaps-auto">CNN</span>s) have been widely explored in single image super-resolution (<span class="smallcaps-auto">SISR</span>) and obtained remarkable performance. However, most of the existing <span class="smallcaps-auto">CNN</span>-based <span class="smallcaps-auto">SISR</span> methods mainly focus on wider or deeper architecture design, neglecting to explore the feature correlations of intermediate layers, hence hindering the representational power of <span class="smallcaps-auto">CNN</span>s. To address this issue, in this paper, we propose a second-order attention network (<span class="smallcaps-auto">SAN</span>) for more powerful feature expression and feature correlation learning. Specifically, a novel train- able second-order channel attention (<span class="smallcaps-auto">SOCA</span>) module is developed to adaptively rescale the channel-wise features by using second-order feature statistics for more discriminative representations. Furthermore, we present a non-locally enhanced residual group (<span class="smallcaps-auto">NLRG</span>) structure, which not only incorporates non-local operations to capture long-distance spatial contextual information, but also contains repeated local-source residual attention groups (<span class="smallcaps-auto">LSRAG</span>) to learn increasingly abstract feature representations. Experimental results demonstrate the superiority of our <span class="smallcaps-auto">SAN</span> network over state-of-the-art <span class="smallcaps-auto">SISR</span> methods in terms of both quantitative metrics and visual quality.</p>'
- - /docs/zeo/2020-vaccaro.pdf
  - ! "Sleep Loss Can Cause Death through Accumulation of Reactive Oxygen Species in the Gut"
  - Alexandra Vaccaro, Yosef Kaplan Dor, Keishi Nambara, Elizabeth A. Pollina, Cindy Lin, Michael E. Greenberg, Dragana Rogulja
  - 2020-06-11
  - 10.1016/j.cell.2020.04.049
  - ! '<p><strong>Highlights</strong>:</p><ul><li>Sleep deprivation leads to <span class="smallcaps-auto">ROS</span> accumulation in the fly and mouse gut</li><li>Gut-accumulated <span class="smallcaps-auto">ROS</span> trigger oxidative stress in this organ</li><li>Preventing <span class="smallcaps-auto">ROS</span> accumulation in the gut allows survival without sleep in flies</li></ul><p><strong>Abstract</strong>: The view that sleep is essential for survival is supported by the ubiquity of this behavior, the apparent existence of sleep-like states in the earliest animals, and the fact that severe sleep loss can be lethal. The cause of this lethality is unknown. Here we show, using flies and mice, that sleep deprivation leads to accumulation of reactive oxygen species (<span class="smallcaps-auto">ROS</span>) and consequent oxidative stress, specifically in the gut. <span class="smallcaps-auto">ROS</span> are not just correlates of sleep deprivation but drivers of death: their neutralization prevents oxidative stress and allows flies to have a normal lifespan with little to no sleep. The rescue can be achieved with oral antioxidant compounds or with gut-targeted transgenic expression of antioxidant enzymes. We conclude that death upon severe sleep restriction can be caused by oxidative stress, that the gut is central in this process, and that survival without sleep is possible when <span class="smallcaps-auto">ROS</span> accumulation is prevented. [Keywords: sleep, sleep deprivation, reactive oxygen species, oxidative stress, free radicals, gut, survival, antioxidants]</p>'
- - /docs/statistics/bias/2020-cowan.pdf
  - ! "How Do Scientific Views Change? Notes From an Extended Adversarial Collaboration"
  - Nelson Cowan, Clément Belletier, Jason M. Doherty, Agnieszka J. Jaroslawska, Stephen Rhodes, Alicia Forsberg, Moshe Naveh-Benjamin, Pierre Barrouillet, Valérie Camos, Robert H. Logie
  - 2020-06-08
  - 10.1177/1745691620906415
  - ! '<p>There are few examples of an extended adversarial collaboration, in which investigators committed to different theoretical views collaborate to test opposing predictions. Whereas previous adversarial collaborations have produced single research articles, here, we share our experience in programmatic, extended adversarial collaboration involving three laboratories in different countries with different theoretical views regarding working memory, the limited information retained in mind, serving ongoing thought and action. We have focused on short-term memory retention of items (letters) during a distracting task (arithmetic), and effects of aging on these tasks. Over several years, we have conducted and published joint research with preregistered predictions, methods, and analysis plans, with replication of each study across two laboratories concurrently. We argue that, although an adversarial collaboration will not usually induce senior researchers to abandon favored theoretical views and adopt opposing views, it will necessitate varieties of their views that are more similar to one another, in that they must account for a growing, common corpus of evidence. This approach promotes understanding of others’ views and presents to the field research findings accepted as valid by researchers with opposing interpretations. We illustrate this process with our own research experiences and make recommendations applicable to diverse scientific areas. [Keywords: scientific method, adversarial collaboration, scientific views, changing views, working memory]</p>'
- - /docs/genetics/heritable/2020-berry.pdf
  - ! "Human postprandial responses to food and potential for precision nutrition"
  - Sarah E. Berry, Ana M. Valdes, David A. Drew, Francesco Asnicar, Mohsen Mazidi, Jonathan Wolf, Joan Capdevila, George Hadjigeorgiou, Richard Davies, Haya Al Khatib, Christopher Bonnett, Sajaysurya Ganesh, Elco Bakker, Deborah Hart, Massimo Mangino, Jordi Merino, Inbar Linenberg, Patrick Wyatt, Jose M. Ordovas, Christopher D. Gardner, Linda M. Delahanty, Andrew T. Chan, Nicola Segata, Paul W. Franks, Tim D. Spector
  - 2020-06-11
  - 10.1038/s41591-020-0934-0
  - ! '<p>Metabolic responses to food influence risk of cardiometabolic disease, but large-scale high-resolution studies are lacking. We recruited n = 1,002 twins and unrelated healthy adults in the United Kingdom to the <span class="smallcaps-auto">PREDICT</span> 1 study and assessed postprandial metabolic responses in a clinical setting and at home. We observed large inter-individual variability (as measured by the population coefficient of variation (s.d./mean, %)) in postprandial responses of blood triglyceride (103%), glucose (68%) and insulin (59%) following identical meals. Person-specific factors, such as gut microbiome, had a greater influence (7.1% of variance) than did meal macronutrients (3.6%) for postprandial lipemia, but not for postprandial glycemia (6.0% and 15.4%, respectively); genetic variants had a modest impact on predictions (9.5% for glucose, 0.8% for triglyceride, 0.2% for C-peptide). Findings were independently validated in a US cohort (n = 100 people). We developed a machine-learning model that predicted both triglyceride (<em>r</em>= 0.47) and glycemic (<em>r</em>= 0.77) responses to food intake. These findings may be informative for developing personalized diet strategies. The ClinicalTrials.gov registration identifier is <span class="smallcaps-auto">NCT</span>03479866.</p><p>…The heritability of postprandial responses in the UK cohort was examined using classical twin methods (variance components analyses) to establish the upper bound of what might be predicted by directly measured genetic variation. Two-thirds of the cohort was recruited from the TwinsUK registry<sup>16</sup>, of which 230 twin pairs (<em>n</em>=460; 183 monozygotic and 47 dizygotic) were studied for heritability. Additive genetic factors explained 48% of the variance in glucose<sub>i<span class="smallcaps-auto">AUC</span>0–2h</sub>, whereas 0% of the variance in triglyceride<sub>6h-rise</sub> and 9% of the variance in insulin<sub>2h-rise</sub> were explained in this way (Fig. 3b). The estimated genetic variances in insulin<sub>1h-rise</sub> and C-peptide<sub>1h-rise</sub> were close to 0 (Supplementary Table 4).</p>'
- - /docs/genetics/selection/2020-chen.pdf
  - ! "Evidence of Polygenic Adaptation in Sardinia at Height–Associated Loci Ascertained from the Biobank Japan"
  - Minhui Chen, Carlo Sidore, Masato Akiyama, Kazuyoshi Ishigaki, Yoichiro Kamatani, David Schlessinger, Francesco Cucca, Yukinori Okada, Charleston W. K. Chiang
  - 2020-06-12
  - 10.1016/j.ajhg.2020.05.014
  - ! '<p>Adult height is one of the earliest putative examples of polygenic adaptation in humans. However, this conclusion was recently challenged because residual uncorrected stratification from large-scale consortium studies was considered responsible for the previously noted genetic difference. It thus remains an open question whether height loci exhibit signals of polygenic adaptation in any human population. We re-examined this question, focusing on one of the shortest European populations, the Sardinians, in addition to mainland European populations. We utilized height-associated loci from the Biobank Japan (<span class="smallcaps-auto">BBJ</span>) dataset to further alleviate concerns of biased ascertainment of <span class="smallcaps-auto">GWAS</span> loci and showed that the Sardinians remain significantly shorter than expected under neutrality (∼0.22 standard deviation shorter than Utah residents with ancestry from northern and western Europe [<span class="smallcaps-auto">CEU</span>] on the basis of polygenic height scores, <em>p</em>=3.89 × 10<sup>−4</sup>). We also found the trajectory of polygenic height scores between the Sardinian and the British populations diverged over at least the last 10,000 years (<em>p</em>=0.0082), consistent with a signature of polygenic adaptation driven primarily by the Sardinian population. Although the polygenic score-based analysis showed a much subtler signature in mainland European populations, we found a clear and robust adaptive signature in the UK population by using a haplotype-based statistic, the trait singleton density score (t<span class="smallcaps-auto">SDS</span>), driven by the height-increasing alleles (<em>p</em>=9.1 × 10<sup>−4</sup>). In summary, by ascertaining height loci in a distant East Asian population, we further supported the evidence of polygenic adaptation at height-associated loci among the Sardinians. In mainland Europeans, the adaptive signature was detected in haplotype-based analysis but not in polygenic score-based analysis. [Keywords: height, polygenic adaptation, population stratification]</p>'
- - /docs/nicotine/1998-parkin.pdf
  - ! "The effects of cigarette smoking on overnight performance"
  - C. Parkin, D. B. Fairweather, Z. Shamsi, N. Stanley, I. Hindmarch
  - 1998-03-01
  - 10.1007/s002130050553
  - ! '<p>15 healthy smokers and 15 non-smokers were enrolled into this study investigating the effects of smoking on overnight performance. Subjects arrived at the test centre at 1930 hours and were assessed at baseline (2000 hours) and at 2200, 0000, 0200, 0400, 0600, and 0800 hours on a battery of tests (including Critical Flicker Fusion, <span class="smallcaps-auto">CFF</span>; Choice Reaction Time, <span class="smallcaps-auto">CRT</span>; Compensatory Tracking Task, <span class="smallcaps-auto">CTT</span>; Short Term Memory Task, <span class="smallcaps-auto">STM</span>; and the Line Analogue Rating Scale, <span class="smallcaps-auto">LARS</span>). Results showed that the performance of the smokers was more consistent with baseline measures than that of the non-smokers, which became more impaired throughout the night on a number of tasks [<span class="smallcaps-auto">CFF</span> (<em>p</em>&lt;0.005), Total Reaction Time (<span class="smallcaps-auto">TRT</span>, <em>p</em>&lt;0.05), <span class="smallcaps-auto">CTT</span> (<em>p</em>&lt;0.05) and the Reaction Time (RT) aspect of the <span class="smallcaps-auto">CTT</span> task (<em>p</em>&lt;0.0005)]. The Recognition Reaction Time (<span class="smallcaps-auto">RRT</span>) aspect of the <span class="smallcaps-auto">CRT</span> task showed that the performance of the non-smokers became more impaired from baseline (<em>p</em>&lt;0.005), while that of the smokers remained at baseline levels until 0400 hours, when it deteriorated to become comparable to that of the non-smoking controls. Subjective sedation ratings (<span class="smallcaps-auto">LARS</span>) resulted in comparable levels of impairment for both study groups (<em>p</em>&lt;0.00005). Findings from the <span class="smallcaps-auto">STM</span> task failed to reach significance. These data suggest that when performance is being measured overnight, smokers show little or no impairment, whilst the performance of non-smokers showed performance decrements.</p>'
- - /docs/iq/smpy/2020-cardador.pdf
  - ! "Does More Mean Less? Interest Surplus and the Gender Gap in STEM Careers"
  - M. Teresa Cardador, Rodica Ioana Damian, Justin P. Wiegand
  - 2020-06-08
  - 10.1177/1069072720930658
  - ! '<p>The persistent gender gap in <span class="smallcaps-auto">STEM</span> (Science, Technology, Engineering, and Math) career choice represents a perplexing problem for researchers and policy makers alike. We contribute to the body of research on the gender gap in <span class="smallcaps-auto">STEM</span> careers by testing a “surplus model” of vocational interests as a predictor of <span class="smallcaps-auto">STEM</span> career choice. The model suggests that, controlling for ability, female adolescents with strong <span class="smallcaps-auto">STEM</span>-related interest should be less likely to pursue <span class="smallcaps-auto">STEM</span> careers when they also have strong interests in other areas, due to wider career options. We tested the surplus model in a large national longitudinal data set and translated the results into differences in annual wages. Our findings illuminate the predictive validity of a surplus model of interests on <span class="smallcaps-auto">STEM</span> career choice across gender, provide insight into the gender gap in <span class="smallcaps-auto">STEM</span>, and suggest opportunities for future research. [Keywords: vocational interests, surplus model, stem gender gap, stem career choice]</p>'
- - /docs/history/2020-hassner.pdf
  - ! "The Cost of Torture: Evidence from the Spanish Inquisition"
  - Ron E. Hassner
  - 2020-05-13
  - 10.1080/09636412.2020.1761441
  - ! '<p>Empirical evidence on contemporary torture is sparse. The archives of the Spanish Inquisition provide a detailed historical source of quantitative and qualitative information about interrogational torture. The inquisition tortured brutally and systematically, willing to torment all who it deemed as withholding evidence. This torture yielded information that was often reliable: witnesses in the torture chamber and witnesses that were not tortured provided corresponding information about collaborators, locations, events, and practices. Nonetheless, inquisitors treated the results of interrogations in the torture chamber with skepticism. This bureaucratized torture stands in stark contrast to the “ticking bomb” philosophy that has motivated US torture policy in the aftermath of 9/11. Evidence from the archives of the Spanish Inquisition suggests torture affords no middle ground: one cannot improvise quick, amateurish, and half-hearted torture sessions, motivated by anger and fear, and hope to extract reliable intelligence.</p>'
- - https://arxiv.org/abs/2006.06676#nvidia
  - "ADA/StyleGAN3: Training Generative Adversarial Networks with Limited Data"
  - Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila (Nvidia)
  - 2020-06
  - ''
  - ! '<p>Training generative adversarial networks (<span class="smallcaps-auto">GAN</span>) using too little data typically leads to discriminator overfitting, causing training to diverge. We propose an adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes. The approach does not require changes to loss functions or network architectures, and is applicable both when training from scratch and when fine-tuning an existing <span class="smallcaps-auto">GAN</span> on another dataset. We demonstrate, on several datasets, that good results are now possible using only a few thousand training images, often matching Style<span class="smallcaps-auto">GAN</span>2 results with an order of magnitude fewer images. We expect this to open up new application domains for <span class="smallcaps-auto">GAN</span>s. We also find that the widely used <span class="smallcaps-auto">CIFAR</span>-10 is, in fact, a limited data benchmark, and improve the record <span class="smallcaps-auto">FID</span> from 5.59 to 2.67.</p>'
- - /docs/economics/2003-brynjolfsson.pdf
  - ! "Computing Productivity: Firm–Level Evidence"
  - Erik Brynjolfsson, Lorin M. Hitt
  - 2003-11-01
  - 10.1162/003465303772815736
  - ! '<p>We explore the effect of computerization on productivity and output growth using data from 527 large U.S. firms over 1987–1994. We find that computerization makes a contribution to measured productivity and output growth in the short term (using 1-year differences) that is consistent with normal returns to computer investments. However, the productivity and output contributions associated with computerization are up to 5 times greater over long periods (using 5- to 7-year differences). The results suggest that the observed contribution of computerization is accompanied by relatively large and time-consuming investments in complementary inputs, such as organizational capital, that may be omitted in conventional calculations of productivity. The large long-run contribution of computers and their associated complements that we uncover may partially explain the subsequent investment surge in computers in the late 1990s.</p>'
- - /docs/economics/1998-brynjolfsson.pdf
  - ! "Beyond the productivity paradox"
  - Erik Brynjolfsson, Lorin M. Hitt
  - 1998-08-01
  - 10.1145/280324.280332
  - ! '<p>…<strong>What We Now Know About Computers and Productivity</strong>: Research on computers and productivity is entering a new phase. While the first wave of studies sought to document the relationship between investments in computers and increases in productivity, new research is focusing on how to make more computerization effective. Computerization does not automatically increase productivity, but it is an essential component of a broader system of organizational changes which does increase productivity. As the impact of computers becomes greater and more pervasive, it is increasingly important to consider these organizational changes as an integral part of the computerization process.</p><p>This is not the first time that a major general purpose technology like computers required an expensive and time-consuming period of restructuring. Significant productivity improvement from electric motors did not emerge until almost 40 years after their introduction into factories <a href="https://www.gwern.net/docs/economics/1990-david.pdf" title="&#39;The Dynamo and the Computer: A Historical Perspective on the Modern Productivity Paradox&#39;, David 1990">[7]</a>. The first use involved swapping gargantuan motors for large steam engines with no redesign of work processes. The big productivity gains came when engineers realized that the factory layout no longer had to be dictated by the placement of power transmitting shafts and rods. They re-engineered the factory so that machines were distributed throughout the factory, each driven by a separate, small electric motor. This made it possible to arrange the machines in accordance with the logic of work flow instead of in proximity to the central power unit.</p><p>It has also taken some time for businesses to realize the transformative potential of information technology to revolutionize work. However, the statistical evidence suggests that revolution is occurring much more quickly this time.</p>'
- - /docs/economics/1990-david.pdf
  - ! "The Dynamo and the Computer: A Historical Perspective on the Modern Productivity Paradox"
  - Paul A. David
  - 1990-05-01
  - 10.2307/2006600
  - !  '<p>Many observers of recent trends in the industrialized economies of the West have been perplexed by the conjecture of rapid technological innovation with disappointingly slow gains in measured productivity. A generation of economists who were brought up to identify increases in total factor productivity indexes with “technical progress” has found it quite paradoxical for the growth accountants’ residual measure of “the advance of knowledge” to have vanished at the very same time that a wave of major innovations was appearing-in microelectronics, in communications technologies based on lasers and fiber optics, in composite materials, and in biotechnology…This latter aspect of the so-called “productivity paradox” attained popular currency in the succinct formulation attributed to Robert Solow: “We see the computers everywhere but in the productivity statistics.”</p><p>…If, however, we are prepared to approach the matter from the perspective afforded by the economic history of the large technical systems characteristic of network industries, and to keep in mind a time-scale appropriate for thinking about transitions from established technological regimes to their respective successor regimes, many features of the so-called productivity paradox will be found to be neither so unprecedented nor so puzzling as they might otherwise appear.</p><p>…Computer and dynamo each form the nodal elements of physically distributed (transmission) networks. Both occupy key positions in a web of strongly complementary technical relationships that give rise to “network externality effects” of various kinds, and so make issues of compatibility standardization important for business strategy and public policy (see my 1987 paper and my paper with Julie Bunn, 1988). In both instances, we can recognize the emergence of an extended trajectory of incremental technical improvements, the gradual and protracted process of diffusion into widespread use, and the confluence with other streams of technological innovation, all of which are interdependent features of the dynamic process through which a general purpose engine acquires a broad domain of specific applications (see Timothy Bresnahan and Manuel Trajtenberg, 1989). Moreover, each of the principal empirical phenomena that make up modem perceptions of a productivity paradox had its striking historical precedent in the conditions that obtained a little less than a century ago in the industrialized West, including the pronounced slowdown in industrial and aggregate productivity growth experienced during the 1890–1913 era by the two leading industrial countries, Britain and the United States (see my 1989 paper, pp. 12–15, for details). In 1900, contemporary observers well might have remarked that the electric dynamos were to be seen “everywhere but in the productivity statistics!”</p>'
- - https://www.mdpi.com/2075-1729/10/6/84/htm
  - On the Potential of Silicon as a Building Block for Life
  - Janusz Jurand Petkowski, William Bains, Sara Seager
  - 2020-06-10
  - 10.3390/life10060084
  - ! '<p>Despite more than one hundred years of work on organosilicon chemistry, the basis for the plausibility of <a href="https://en.wikipedia.org/wiki/Hypothetical_types_of_biochemistry#Silicon_biochemistry">silicon-based life</a> has never been systematically addressed nor objectively reviewed. We provide a comprehensive assessment of the possibility of silicon-based biochemistry, based on a review of what is known and what has been modeled, even including speculative work. We assess whether or not silicon chemistry meets the requirements for chemical diversity and reactivity as compared to carbon. To expand the possibility of plausible silicon biochemistry, we explore silicon’s chemical complexity in diverse solvents found in planetary environments, including water, cryosolvents, and <a href="https://en.wikipedia.org/wiki/Sulfuric_acid">sulfuric acid</a>. In no environment is a life based primarily around silicon chemistry a plausible option. We find that in a water-rich environment silicon’s chemical capacity is highly limited due to ubiquitous silica formation; silicon can likely only be used as a rare and specialized heteroatom. Cryosolvents (e.g., liquid N<sub>2</sub>) provide extremely low solubility of all molecules, including organosilicons. Sulfuric acid, surprisingly, appears to be able to support a much larger diversity of organosilicon chemistry than water. [Keywords: silicon-based life; alternative biochemistry; alternative solvents; sulfuric acid biochemistry]</p>'
- - /docs/psychology/2020-allen.pdf
  - ! "Personality and Sexual Orientation: New Data and Meta–analysis"
  - Mark S. Allen, Davina A. Robson
  - 2020-06-08
  - 10.1080/00224499.2020.1768204
  - ! '<p>This research explored associations between personality and sexual orientation. In Study 1, we explored whether the Big Five trait dimensions relate to sexual orientation in a nationally representative sample of Australian adults (<em>n</em>=13,351). Personality differences were observed between those who identified as heterosexual (straight), bisexual, and homosexual (gay/lesbian) on all five measured traits. In Study 2, we conducted an updated systematic review and meta-analysis of personality and sexual orientation. A total of 21 studies (35 independent samples, 262 effect sizes) comprising 377,951 men and women were identified that satisfied inclusion criteria. Results showed that bisexual individuals reported higher levels of openness than homosexual individuals, who in turn, reported higher levels of openness than heterosexual individuals. Bisexual individuals also report lower levels of conscientiousness than both heterosexual and homosexual individuals. Sex moderation effects showed that homosexual men scored higher than heterosexual men on neuroticism, agreeableness and conscientiousness, whereas homosexual women scored lower than heterosexual women on extraversion, agreeableness, and conscientiousness. There was also evidence that personality differences between sexual orientation categories tend to decline with age. These findings align with the gender-shift hypothesis and should be of interest to theorists working in personality science and sexual identity development.</p>'
- - /Holy-wars
  - "Technology Holy Wars are Coordination Problems: Flamewars over platforms & upgrades are so bitter not because people are jerks but because the choice will influence entire ecosystems, benefiting one platform through network effects & avoiding 'bitrot' while subtly sabotaging the rest through 'bitcreep'."
  - Gwern Branwen
  - 2020-06-15
  - ''
  - ! '<p>The enduring phenomenon of ‘holy wars’ in computing, such as the bitterness around the prolonged Python 2 to Python 3 migration, are not due to mere pettiness or love of conflict, but because they are a coordination problem: dominant platforms enjoy strong network effects, such as reduced ‘bitrot’ as it is regularly used &amp; maintained by many users, and can inflict a mirror-image ‘bitcreep’ on other platforms which gradually are neglected and begin to bitrot because of the dominant platform.</p><p>The outright negative effect of bitcreep mean that holdouts do not just cost early adopters the possible network effects, they also greatly reduce the value of a given thing, and may cause the early adopters to be actually worse off and more miserable on a daily basis. Given the extent to which holdouts have benefited from the community, holdout behavior is perceived as parasitic and immoral behavior by adopters, while holdouts in turn deny any moral obligation and resent the methods that adopters use to increase adoption (such as, in the absence of formal controls, informal ones like bullying).</p><p>Perhaps if we explicitly understand ‘holy wars’ as coordination problems, we can avoid the worst excesses and tap into knowledge about the topic to better manage things like language migrations. [Keywords: technology, sociology, Python]</p>'
- - /docs/history/2003-chambers.pdf
  - ! "S. L. A. Marshall&#39;s men against fire: New evidence regarding fire ratios"
  - John Whiteclay Chambers II
  - 2003-09-01
  - ''
  - ! '<p>Chambers II discusses the findings of journalist-soldier S. L. A. Marshall about combat fire ratios particularly that in World War II. Marshall claimed that his figures about the ratio of fire, the proportion of a rifle unit firing its weapons in battle was derived from his group after-action interviews, a method he developed as a field historian in world War II and which as a civilian journalist, Reserve officer, and military consultant. Although the ratio-of-fire figure was his most famous product, Marshall was proudest of his methodology.</p><p>[Chambers interviews Frank L. Brennan, an assistant of Marshall during his Korea War after-action interview work, who accompanied him to every interview. Brennan described Marshall’s methodology as follows: the group interviews typically lasted about 2 hours at most; Marshall took few notes; Marshall preferred to ask open-ended questions and listen to the discussions; he rarely asked questions specifically about the rate of fire or whether a soldier had fired his weapon; he did not seem to collect any of the statistics he would later report in his books; and Marshall was evasive when Brennan asked about his <span class="smallcaps-auto">WWII</span> statistics’ sources. Brennan noted that in Marshall’s autobiography, Marshall greatly inflated his importance &amp; the resources placed at his disposal in Korea, and the length of his interviews. Brennan also served in combat afterwards, and observed a high rate of fire in his own men.]</p>'
- - /docs/statistics/bias/2020-griggs.pdf
  - ! "New Revelations About Rosenhan’s Pseudopatient Study: Scientific Integrity in Remission"
  - Richard A. Griggs, Jenna Blyler, Sherri L. Jackson
  - 2020-06-11
  - 10.1037/stl0000202
  - ! '<p>David Rosenhan’s pseudopatient study is one of the most famous studies in psychology, but it is also one of the most criticized studies in psychology. Almost 50 years after its publication, it is still discussed in psychology textbooks, but the extensive body of criticism is not, likely leading teachers not to present the study as the contentious classic that it is. New revelations by Susannah Cahalan (2019), based on her years of investigation of the study and her analysis of the study’s archival materials, question the validity and veracity of both Rosenhan’s study and his reporting of it as well as Rosenhan’s scientific integrity. Because many (if not most) teachers are likely not aware of Cahalan’s findings, we provide a summary of her main findings so that if they still opt to cover Rosenhan’s study, they can do so more accurately. Because these findings are related to scientific integrity, we think that they are best discussed in the context of research ethics and methods. To aid teachers in this task, we provide some suggestions for such discussions.</p><p>[ToC: Rosenhan’s Misrepresentations of the Pseudopatient Script and His Medical Record · Selective Reporting of Data · Rosenhan’s Failure to Prepare and Protect Other Pseudopatients · Reporting Questionable Data and Possibly Pseudo-Pseudopatients · Concluding Remarks · Footnotes · References]</p>'
- - /docs/history/2008-engen.pdf
  - ! "Killing For Their Country: A New Look at &#39;Killology&#39;"
  - Robert Engen
  - 2008-12-01
  - ''
  - ! '<p>It would appear, then, that Lieutenant Colonel Grossman’s appeals to biology and psychology are flawed, and that the bulwark of his historical evidence—S.L.A. Marshall’s assertion that soldiers do not fire their weapons—can be verifiably disproven. The theory of an innate, biological resistance to killing has little support in either evolutionary biology or in what we know about psychology, and, discounting Marshall’s claims, there is little basis in military history for such a theory either. This is not to say that all people can or will kill, or even that all soldiers can or will kill. Combat is staggeringly complex, an environment where human beings are pushed beyond all tolerable limits. There is much that we do not know, and plenty that we should be doing more to learn about. Grossman is clearly leading the way in posing these questions. Much of his work on the processes of killing and the relevance of physical distance to killing is extremely insightful. There is material in On Combat about fear, heart rate, and combat effectiveness that might be groundbreaking, and it should be studied carefully by historians trying to understand human behaviour in war. No disrespect to Lieutenant-Colonel Grossman is intended by this article, and it is not meant to devalue his work. I personally believe that some of the elements of his books, particularly the physiology of combat, would actually be strengthened if they were not shackled to the idea that humans cannot kill one another. But there are still questions that need to be asked, and the subject should not be considered closed. Grossman’s overall picture of killing in war and society is heavily informed by a belief in an innate human resistance to killing that, as has been offered here, does not stand up well to scrutiny. More research on the processes of human killing is needed, and although <em>On Killing</em> and <em>On Combat</em> form an excellent starting point, there are too many problems with their interpretation for them to be considered the final word on the subject. I believe that, in the future, the Canadian Forces needs to take a more critical posture when it comes to incorporating Grossman’s studies into its own doctrine. It is imperative that our nation’s military culture remain one devoted to pursuing the best available evidence at all costs, rather than one merely following the most popular consensus.</p>'
- - /docs/sociology/1982-simoons.pdf
  - ! "Breast-Feeding of Animals by Women: Its Socio-Cultural Context and Geographic Occurrence"
  - Frederick J. Simoons, James A. Baldwin
  - '1982'
  - 10.2307/40460478
  - ! '<p>In this paper, the practice of women breast-feeding animals is viewed from a geographic and historical perspective. The principal aims are to establish where the practice has been commonplace, to determine its economic and socio-cultural context, to consider its possible role in animal domestication, and to weigh its significance in human ecology.—In many cases, the practice is an expression of affection for pets (among Polynesians, among forest peoples of tropical South America, and especially among aboriginal hunters and gatherers in Southeast Asia, Australia, and Tasmania). In other cases, affection is supplemented or supplanted by economic concerns, as among various Melanesian “pig complex” peoples. In some cases, breast-feeding of animals is linked to cult and ritual, an outstanding example being the nursing of cubs in connection with the Ainu bear cult. In a few cases, animals are breast-fed with the welfare of the human mother or child being of greatest concern. The conclusion is drawn that animal nursing may indeed have contributed to the domestication of such animals as the pig and dog, and that in some places, particularly lowland New Guinea, the practice can play an important role in human ecology. [Keywords: Breast-Feeding of Animals, Ecology, Animal Domestication, Animal Cult]</p> <p>…This initial survey of the practice of breast-feeding of animals by humans leads us to three general conclusions about the practice. First, we note that virtually all contemporary human groups reported as regularly nursing animals belong to cultures which either possess no dairy animals or, if they do, do not milk them. Second, we note the importance of animal-nursing as a taming mechanism used by some human groups who capture infant animals in the wild, and suggest that animal-nursing may have contributed to the full domestication of such often-captured pets as the dog and the pig, Sauer’s “household” animals. Finally and most tentatively, we conclude that the practice of animal-nursing, particularly in areas such as New Guinea where human breastmilk production is low, may at times pose a health threat to human infants who must compete with animals at the breast.</p>'
- - https://www.nature.com/articles/s41467-020-16829-x
  - Efficient polygenic risk scores for biobank scale data by exploiting phenotypes from inferred relatives
  - Buu Truong, Xuan Zhou, Jisu Shin, Jiuyong Li, Julius H. J. van der Werf, Thuc D. Le, S. Hong Lee
  - 2020-06-17
  - 10.1038/s41467-020-16829-x
  - ! '<p>Polygenic risk scores are emerging as a potentially powerful tool to predict future phenotypes of target individuals, typically using unrelated individuals, thereby devaluing information from relatives. Here, for 50 traits from the UK Biobank data, we show that a design of 5,000 individuals with first-degree relatives of target individuals can achieve a prediction accuracy similar to that of around 220,000 unrelated individuals (mean prediction accuracy = 0.26 vs. 0.24, mean fold-change = 1.06 (95% CI: 0.99–1.13), <em>p</em>=0.08), despite a 44-fold difference in sample size. For lifestyle traits, the prediction accuracy with 5,000 individuals including first-degree relatives of target individuals is significantly higher than that with 220,000 unrelated individuals (mean prediction accuracy = 0.22 vs. 0.16, mean fold-change = 1.40 (1.17–1.62), <em>p</em>=0.025). Our findings suggest that polygenic prediction integrating family information may help to accelerate precision health and clinical intervention.</p><p>…We demonstrated that the polygenic prediction utilising close relatives between reference and target samples outperformed the analyses with unrelated individuals only by using the small-scale design. Compared with the analyses with second- or third-degree relatives, or unrelated individuals, a higher prediction accuracy was observed from the analysis with first-degree relatives, which was because of a lower value of M<sub>e</sub> that required fewer independent parameters to be estimated<sup>25,26,27</sup>. Moreover, this higher prediction accuracy was also probably due to the fact that close relatives share some unknown (unmodeled) factors in addition to additive genetic effects, which may be dominance, gene-by-family interaction and familial environmental effects. It was also shown that the analyses with second- and third-degree relatives outperformed the analysis with unrelated individuals although they were less efficient to improve the prediction accuracy, compared to first-degree relatives.</p><p>The approach of including close relatives will be most useful in applications where accuracy matters more than delineating between causal genetic effects and other effects. It is known that family-based heritability estimates can be inflated if nonadditive genetic effects or common environmental effects shared between close relatives are confounded with additive genetic effects<sup>3</sup>, which can be considered biased according to the concept of narrow-sense heritability that includes the additive genetic effects only. However, this bias should not be an issue when predicting the future phenotypes of target sample (i.e., a new-born baby) because such nonadditive genetic and common environmental effects can be a valuable source to improve the prediction accuracy<sup>28,42</sup>. Indeed, family history has been widely used as a biomarker to predict disease risk<sup>43,44</sup>, and it can also be used to increase the power to identify causal variants in <span class="smallcaps-auto">GWAS</span><sup>45,46,47</sup>. We consider that our method is a more systematic approach to utilise information of family history as well as within-family segregation<sup>48</sup>.</p>'
- - /docs/genetics/heritable/2020-smeland.pdf
  - ! "The polygenic architecture of schizophrenia—rethinking pathogenesis and nosology"
  - Olav B. Smeland, Oleksandr Frei, Anders M. Dale, Ole A. Andreassen
  - 2020-06-11
  - 10.1038/s41582-020-0364-0
  - ! '<p><strong>Abstract</strong>: Schizophrenia is a severe psychiatric disorder with considerable morbidity and mortality. Although the past two decades have seen limited improvement in the treatment of schizophrenia, research into the genetic causes of this condition has made important advances that offer new insights into the aetiology of schizophrenia. This Review summarizes the evidence for a polygenic architecture of schizophrenia that involves a large number of risk alleles across the whole range of population frequencies. These genetic risk loci implicate biological processes related to neurodevelopment, neuronal excitability, synaptic function and the immune system in the pathogenesis of schizophrenia. Mathematical models also suggest a substantial overlap between schizophrenia and psychiatric, behavioural and cognitive traits, a situation that has implications for understanding its clinical epidemiology, psychiatric nosology and pathobiology. Looking ahead, further genetic discoveries are expected to lead to clinically relevant predictive approaches for identifying high-risk individuals, improved diagnostic accuracy, increased yield from drug development programmes and improved stratification strategies to address the heterogeneous disease course and treatment responses observed among affected patients.</p><p><strong>Key points</strong>:</p><ul><li>Schizophrenia is characterized by ‘positive’ psychotic symptoms (including hallucinations and delusions) and ‘negative’ symptoms (including blunted affect, apathy and social impairment); this disorder is associated with considerable morbidity and mortality.</li><li>In the past decade, important advances have been made in our understanding of the genetics of schizophrenia.</li><li>The polygenic architecture of schizophrenia is accounted for by thousands of common genetic variants with small effect sizes and a few rare variants with large effect sizes.</li><li>These genetic risk variants implicate dysregulation of biological processes linked to neurodevelopment, neuronal excitability, synaptic function and the immune system in schizophrenia.</li><li>Genetic risk factors associated with schizophrenia transcend diagnostic boundaries and form a continuum with normal psychosocial traits, which challenges current psychiatric nosology.</li><li>Although increasingly larger sample sizes will accelerate the discovery of genetic variants, novel statistical methodologies could also improve the efficiency of analyses, render discoveries clinically relevant and facilitate precision medicine approaches.</li></ul>'
- - /docs/spacedrepetition/1993-bahrick.pdf
  - ! "Maintenance of Foreign Language Vocabulary and the Spacing Effect"
  - Harry P. Bahrick, Lorraine E. Bahrick, Audrey S. Bahrick, Phyllis E. Bahrick
  - 1993-09-01
  - 10.1111/j.1467-9280.1993.tb00571.x
  - ! '<p>In a 9-year longitudinal investigation, 4 subjects learned and relearned 300 English-foreign language word pairs. Either 13 or 26 relearning sessions were administered at intervals of 14, 28, or 56 days. Retention was tested for 1, 2, 3, or 5 years after training terminated. The longer intersession intervals slowed down acquisition slightly, but this disadvantage during training was offset by substantially higher retention. 13 retraining sessions spaced at 56 days yielded retention comparable to 26 sessions spaced at 14 days. The retention benefit due to additional sessions was independent of the benefit due to spacing, and both variables facilitated retention of words regardless of difficulty level and of the consistency of retrieval during training. The benefits of spaced retrieval practice to long-term maintenance of access to academic knowledge areas are discussed.</p>'
- - /docs/iq/2020-marr.pdf
  - ! "The Creative Tripod: The Stitching and the Unstitching Revisited"
  - M. Jackson Marr
  - 2020-06-11
  - 10.1007/s40732-020-00410-5
  - ! '<p>There are no undebated definitions of “creativity,” and any definition will reflect how this rich topic is treated. Nearly 20 years ago I discussed how behavior analysis might contribute—or not—to an understanding of creativity. I revisit this topic, expanding on some issues and reconsidering others. As before, my focus is on scientific and mathematical accomplishments, which, though tied closely to Weisberg’s placement of creative achievements in the domains of problem posing and problem solving, places emphasis on the extraordinary and productive giftedness of certain individuals. From the massive empirical, theoretical, and historical literature at least three essential and dynamically interlocking dimensions of their creative achievements emerge: talent, expertise, and motivation. I emphasize “interlocking” because the productive expression of each of these elements depends on the others. The role of behavior analysis in these elements is modest at best. It has nothing to say about talent—and even in some cases might deny its role altogether. As for expertise, with some notable exceptions, behavior analysis has had little to say about the acquisition of truly complex performances; this has been left to other fields. As for motivation, one must go well beyond naïve “pleasure and pain” accounts to more elusive, yet more powerful behavior–consequence relations. Many challenges to understanding remain for all behavioral scientists.</p>'
- - https://files.eric.ed.gov/fulltext/EJ746056.pdf
  - "Giftedness and Genetics: The Emergenic-Epigenetic Model and Its Implications"
  - Dean Keith Simonton
  - 2005-05
  - 10.4219/jeg-2005-338
  - ! '<p>The genetic endowment underlying giftedness may operate in a far more complex manner than often expressed in most theoretical accounts of the phenomenon. First, an endowment may be emergenic. That is, a gift may consist of multiple traits (multidimensional) that are inherited in a multiplicative (configurational), rather than an additive (simple) fashion. Second, the endowment may not appear all at once but, rather, will more likely unfold via an epigenetic process. These 2 complications have consequences regarding such aspects of giftedness as the likelihood of early signs, the appearance of early versus late bloomers, the distribution of giftedness in the general population, and the stability and continuity of gifts over the course of childhood and adolescence. These complexities lead to a 4-fold typology of giftedness that has important practical implications.</p> <p>…To sum up, the consequences presented in Table 1 imply that the phenomenon of giftedness is far more complicated than often imagined. To the extent that the emergenic-epigenetic model describes the inheritance and development of giftedness, then a particular gift cannot be understood without first discovering if it is additive or multiplicative and if it is simple or complex. Naturally, the phenomenon of giftedness is even more intricate than even this model suggests. After all, I have only scrutinized the genetics of giftedness—on the developmental complexities of natural endowment. The analysis would become all the more complicated if I were to incorporate environmental factors explicitly into the developmental model. Nevertheless, it must be obvious that to the extent that a specific gift operates according to emergenic inheritance and epigenetic development, the complications are already far more prodigious than implied by most dictionary definitions.</p> <p>[Note that the content of this paper almost completely overlaps with the almost-identically-titled Simonton 2005, "Genetics of Giftedness: The Implications of an Emergenic–Epigenetic Model"; you need not read the other. (Simonton is notorious for self-plagiarizing.)]'
- - /docs/iq/1943-burt.pdf
  - ! "Ability and Income"
  - Cyril Burt
  - 1943-01-01
  - 10.1111/j.2044-8279.1943.tb02725.x
  - ! '<p>The distribution of intelligence as measured by recognized scales supplemented by other information conforms closely to the normal curve of error, while that of personal income presents a highly skewed J-shaped curve. Reconciliation of this apparent discrepancy can be made by regarding income as dependent mainly on output, which in turn is related to the contributing abilities by some special function. Confirmation of this theory appears in the fact that in many intellectual fields the distribution of output approaches the J-shaped curve. The inequality in personal income is largely, though not entirely, an indirect effect of the inequality in innate intelligence. Yet mental output and achievement are undoubtedly influenced by differences in social and economic conditions. This is instanced by the fact that in assessing the influence of innate ability and parental income upon entrance to the universities, it appears from statistical analysis that of the ex-elementary (non-fee-paying) group about 40% of those possessing the necessary intelligence fail to obtain a university education. On the other hand, an equal number of children whose parents pay for their early instruction receive a university education for which their innate abilities alone scarcely equip them.</p>'
- - /docs/genetics/heritable/2020-vujkovic.pdf
  - ! "Discovery of 318 new risk loci for type 2 diabetes and related vascular outcomes among 1.4 million participants in a multi–ancestry meta–analysis"
  - Marijana Vujkovic, Jacob M. Keaton, Julie A. Lynch, Donald R. Miller, Jin Zhou, Catherine Tcheandjieu, Jennifer E. Huffman, Themistocles L. Assimes, Kimberly Lorenz, Xiang Zhu, Austin T. Hilliard, Renae L. Judy, Jie Huang, Kyung M. Lee, Derek Klarin, Saiju Pyarajan, John Danesh, Olle Melander, Asif Rasheed, Nadeem H. Mallick, Shahid Hameed, Irshad H. Qureshi, Muhammad Naeem Afzal, Uzma Malik, Anjum Jalal, Shahid Abbas, Xin Sheng, Long Gao, Klaus H. Kaestner, Katalin Susztak, Yan V. Sun, Scott L. DuVall, Kelly Cho, Jennifer S. Lee, J. Michael Gaziano, Lawrence S. Phillips, James B. Meigs, Peter D. Reaven, Peter W. Wilson, Todd L. Edwards, Daniel J. Rader, Scott M. Damrauer, Christopher J. Oamp#x02019;Donnell, Philip S. Tsao, Mark A. Atkinson, Al C. Powers, Ali Naji, Klaus H. Kaestner, Goncalo R. Abecasis, Aris Baras, Michael N. Cantor, Giovanni Coppola, Aris N. Economides, Luca A. Lotta, John D. Overton, Jeffrey G. Reid, Alan R. Shuldiner, Christina Beechert, Caitlin Forsythe, Erin D. Fuller, Zhenhua Gu, Michael Lattari, Alexander E. Lopez, Thomas D. Schleicher, Maria Sotiropoulos Padilla, Karina Toledo, Louis Widom, Sarah E. Wolf, Manasi Pradhan, Kia Manoochehri, Ricardo H. Ulloa, Xiaodong Bai, Suganthi Balasubramanian, Leland Barnard, Andrew L. Blumenfeld, Gisu Eom, Lukas Habegger, Alicia Hawes, Shareef Khalid, Evan K. Maxwell, William J. Salerno, Jeffrey C. Staples, Ashish Yadav, Marcus B. Jones, Lyndon J. Mitnaul, Samuel M. Aguayo, Sunil K. Ahuja, Zuhair K. Ballas, Sujata Bhushan, Edward J. Boyko, David M. Cohen, John Concato, Joseph I. Constans, Louis J. Dellitalia, Joseph M. Fayad, Ronald S. Fernando, Hermes J. Florez, Melinda A. Gaddy, Saib S. Gappy, Gretchen Gibson, Michael Godschalk, Jennifer A. Greco, Samir Gupta, Salvador Gutierrez, Kimberly D. Hammer, Mark B. Hamner, John B. Harley, Adriana M. Hung, Mostaqul Huq, Robin A. Hurley, Pran R. Iruvanti, Douglas J. Ivins, Frank J. Jacono, Darshana N. Jhala, Laurence S. Kaminsky, Scott Kinlay, Jon B. Klein, Suthat Liangpunsakul, Jack H. Lichy, Stephen M. Mastorides, Roy O. Mathew, Kristin M. Mattocks, Rachel McArdle, Paul N. Meyer, Laurence J. Meyer, Jonathan P. Moorman, Timothy R. Morgan, Maureen Murdoch, Xuan-Mai T. Nguyen, Olaoluwa O. Okusaga, Kris-Ann K. Oursler, Nora R. Ratcliffe, Michael I. Rauchman, R. Brooks Robey, George W. Ross, Richard J. Servatius, Satish C. Sharma, Scott E. Sherman, Elif Sonel, Peruvemba Sriram, Todd Stapley, Robert T. Striker, Neeraj Tandon, Gerardo Villareal, Agnes S. Wallbom, John M. Wells, Jeffrey C. Whittle, Mary A. Whooley, Junzhe Xu, Shing-Shing Yeh, Michaela Aslan, Jessica V. Brewer, Mary T. Brophy, Todd Connor, Dean P. Argyres, Nhan V. Do, Elizabeth R. Hauser, Donald E. Humphries, Luis E. Selva, Shahpoor Shayan, Brady Stephens, Stacey B. Whitbourne, Hongyu Zhao, Jennifer Moser, Jean C. Beckham, Jim L. Breeling, J. P. Casas Romero, Grant D. Huang, Rachel B. Ramoni, Saiju Pyarajan, Yan V. Sun, Kelly Cho, Peter W. Wilson, Christopher J. Oamp#x02019;Donnell, Philip S. Tsao, Kyong-Mi Chang, J. Michael Gaziano, Sumitra Muralidhar, Kyong-Mi Chang, Benjamin F. Voight, Danish Saleheen
  - 2020-06-15
  - 10.1038/s41588-020-0637-y
  - ! '<p>We investigated type 2 diabetes (T2D) genetic susceptibility via multi-ancestry meta-analysis of 228,499 cases and 1,178,783 controls in the Million Veteran Program (<span class="smallcaps-auto">MVP</span>), <span class="smallcaps-auto">DIAMANTE</span>, Biobank Japan and other studies. We report 568 associations, including 286 autosomal, 7 X-chromosomal and 25 identified in ancestry-specific analyses that were previously unreported. Transcriptome-wide association analysis detected 3,568 T2D associations with genetically predicted gene expression in 687 novel genes; of these, 54 are known to interact with <span class="smallcaps-auto">FDA</span>-approved drugs. A polygenic risk score (<span class="smallcaps-auto">PRS</span>) was strongly associated with increased risk of T2D-related retinopathy and modestly associated with chronic kidney disease (<span class="smallcaps-auto">CKD</span>), peripheral artery disease (<span class="smallcaps-auto">PAD</span>) and neuropathy. We investigated the genetic etiology of T2D-related vascular outcomes in the <span class="smallcaps-auto">MVP</span> and observed statistical <span class="smallcaps-auto">SNP</span>–T2D interactions at 13 variants, including coronary heart disease (<span class="smallcaps-auto">CHD</span>), <span class="smallcaps-auto">CKD</span>, <span class="smallcaps-auto">PAD</span> and neuropathy. These findings may help to identify potential therapeutic targets for T2D and genomic pathways that link T2D to vascular outcomes.</p>'
- - /docs/traffic/2020-hsieh.pdf
  - ! "Do not allow pop–up ads to appear too early internet users’ browsing behaviour to pop–up ads"
  - Ai-Yun Hsieh, Shao-Kang Lo, Yu-Ping Chiu, Ting Lie
  - 2020-06-23
  - 10.1080/0144929X.2020.1784282
  - ! '<p>This study examines the timing of pop-up advertising appearance and its effect on perceived intrusiveness, advertising irritation and advertising avoidance. Experiment was designed to build a virtual Internet environment (including the main content on the webpage and a pop-up ad) and to manipulate the timing of the pop-up advertising appearance. Participants were invited to participate in two experiments, and then assigned to a specific target browsing task; their advertising browsing activities during the task were measured. In order to measure their cognitive advertising avoidance, an eye-tracking device was utilised to gain objective and accurate psychological information. Results showed that earlier pop-up advertising appearances are associated with a lower consumer fixation count and fixation length; in contrast, pop-up advertising that appears later is associated with a higher fixation count and fixation length. This study attempts to gain more objective and accurate psychological data by using an eye-tracking device to collect information about eye movements associated with the appearance of pop-up advertising to better analyse consumer behaviours towards them. These results offer insights to Internet advertisers and Internet platform companies on how to provide more efficient Internet advertising. [Keywords: Pop-up advertising, pop-up timing, advertising intrusiveness, advertising avoidance, eye tracking]</p>'
- - /docs/history/2006-lurz-thedubiousquickkill.html
  - "The Dubious Quick Kill, part 1/2: Sword wounds and the circulatory system"
  - Frank Lurz
  - '2006'
  - ''
  - ! '<p>In conclusion, fencing tempo is a vital element of swordsmanship, but clearly for the duelist hitting before being hit is not at all the same thing as hitting without being hit. Exsanguination is the principal mechanism of death caused by stabbing and incising wounds and death by this means is seldom instantaneous. Although stab wounds to the heart are generally imagined to be instantly incapacitating, numerous modern medical case histories indicate that while victims of such wounds may immediately collapse upon being wounded, rapid disability from this type of wound is by no means certain. Many present-day victims of penetrating wounds involving the lungs and the great vessels of the thorax have also demonstrated a remarkable ability to remain physically active minutes to hours after their wounds were inflicted. These cases are consistent with reports of duelists who, subsequent to having been grievously or even mortally wounded through the chest, neck, or abdomen, nevertheless remained actively engaged upon the terrain and fully able to continue long enough to dispatch those who had wounded them.</p><p>…Early American motion pictures have frequently misrepresented virtually every aspect of authentic swordplay. This seems to have been especially true of the industry’s depiction of the manner in which swordsmen fell before the blades of their opponents. While anecdotes of duels may have been biased by politics or personal vanity, modern forensic medicine provides ample evidence to support historical accounts of gravely wounded duelists continuing in combats for surprising lengths of time, sometimes killing those who had killed them.</p><p>In the first installment of this essay modern forensic evidence indicated that exsanguination is the principal mechanism of death caused by stabbing and incising wounds, but that death by this means is seldom instantaneous; victims frequently capable of continued physical activity, even after being stabbed in the heart. Similarly, victims of sharp force injuries to the lungs are not infrequently able to carry on for protracted periods of time. Wounds which result in the introduction of blood into the upper airway, on the other hand, are likely to incapacitate and kill an adversary quite rapidly.</p><p>Duels featuring penetrating wounds to the muscles of the sword arm appear in some cases to have left duelists fully capable of manipulating their weapons. Thrusts to the thigh and leg may have been even less efficacious. Strokes with the cutting edges of swords to the limbs may result in more serious wounds to the musculature than the penetrating variety, but historical accounts of duels demonstrate that immediate incapacitation of an adversary stricken with such wounds was by no means guaranteed. Incising wounds which sever tendons, however, can be expected to immediately incapacitate the muscles from which they arise. Recent medical reports of sharp force injuries to the brain suggest that even a sword-thrust penetrating the skull ought not to have been expected always to disable an opponent instantaneously. While severe pain is usually incapacitating, the stress of combat may mask the pain of gravely serious wounds, enabling the determined duelist to remain on the ground for a considerable length of time.</p><p>The immediate consequences to a duelist of wounds inflicted by thrusts or cuts from the rapier, dueling sabre or smallsword were unpredictable. While historical anecdotes of affairs of honor and twentieth century medical reports show that many stabbing victims collapsed immediately upon being wounded, others did not. While a swordsman certainly gained no advantage for having been wounded, it cannot be said that an unscathed adversary, after having delivered a fatal thrust or cut, had no further concern for his safety. Duelists receiving serious and even mortal wounds were sometimes able to continue effectively in the combat long enough to take the lives of those who had taken theirs…For the duelist, however, another form of tempo had to be considered. In the early history of affairs of honor, this “dueling tempo” spanned the period extending from the moment that a wound was inflicted until the instant that the adversary was no longer able to continue effectively. This span of time was unpredictable in length and could be expressed in terms ranging from a fraction of a second to minutes. Considering the number and severity of wounds that were sustained by combatants in the early days of the duel, it would not be surprising to find that many duelists of latter days secretly breathed a sigh of relief when interrupted by seconds rushing in to terminate affairs of honor immediately upon the delivery of a well placed cut or thrust.</p>'
- - https://www.cl.cam.ac.uk/~bjc63/tight_scrape.pdf
  - "A tight scrape: methodological approaches to cybercrime research data collection in adversarial environments"
  - Kieron Turk, Sergio Pastrana, Ben Collier
  - 2020-06-10
  - ''
  - ! '<p>We outline in this article a study of ‘adversarial scraping’ for academic research, which involves the collection of data from websites that implement defences against traditional web scraping tools. Although this is primarily a research methods article, it also constitutes a valuable systematic accounting of the different defensive techniques used by the administrators of illicit online services. Some of these administrators intentionally implement functionality which attempts to prevent web scrapers from gathering data from their site, and some will unintentionally design their sites in ways that make data gathering harder. This is of particular importance for criminological research, where websites such as cryptomarkets and underground forums are publicly available (and hence there is an ethical case for data collection), but the illicit activity involved means that the administrators of these services limit scraping. We classify different anti-crawling techniques taken by websites and outline our developed countermeasures. Based on this, we evaluate which of these methods do and do not succeed at preventing data gathering from a website, as well as those which impact the scraper but do not necessarily prevent the data from being obtained. We find that there are some defences that, if used together, might thwart scraping. There are also a series of defences that are successful at slowing down scrapers, making historical scraping more difficult. On the other hand, we show that many defences are easy to work around and do not impact scraping. [Keywords: web crawling, web scraping, underground forums, chat channels, cybercrime]</p>'
- - /docs/iq/1995-rowe.pdf
  - ! "Ethnic and Racial Similarity in Developmental Process: A Study of Academic Achievement"
  - David C. Rowe, Alexander T. Vazsonyi, Daniel J. Flannery
  - 1995-01-01
  - 10.1111/j.1467-9280.1995.tb00301.x
  - ! '<p>Correlation matrices were computed on academic achievement and family environment measures using longitudinal data on siblings. The 8 × 8 correlation matrices were computed on Hispanics, blacks, and whites separately. When compared employing a <span class="smallcaps-auto">LISREL</span> method, the matrices were equal across these ethnic-racial groups. Hence, developmental processes influencing academic achievement may be similar in Hispanics, blacks, and whites. A structural equation model with 4 free parameters was fitted successfully to a correlation matrix pooled across groups. As a single structural equation model fitted all groups, the existence of minority-specific developmental processes was not supported.</p>'
- - /docs/ai/anime/2020-akita.pdf
  - ! "Deep–Eyes: Fully Automatic Anime Character Colorization with Painting of Details on Empty Pupils"
  - Kenta Akita, Yuki Morimoto, Reiji Tsuruno
  - 2020-01-01
  - 10.2312/egs.20201023
  - ! 'Many studies have recently applied deep learning to the automatic colorization of line drawings. However, it is difficult to paint empty pupils using existing methods because the networks are trained with pupils that have edges, which are generated from color images using image processing. Most actual line drawings have empty pupils that artists must paint in. In this paper, we propose a novel network model that transfers the pupil details in a reference color image to input line drawings with empty pupils. We also propose a method for accurately and automatically coloring eyes. In this method, eye patches are extracted from a reference color image and automatically added to an input line drawing as color hints using our eye position estimation network.'
- - /docs/genetics/correlation/2020-ning.pdf
  - ! "High–definition likelihood inference of genetic correlations across human complex traits"
  - Zheng Ning
  - 2020-06-29
  - 10.1038/s41588-020-0653-y
  - ! '<p>Genetic correlation is a central parameter for understanding shared genetic architecture between complex traits. By using summary statistics from genome-wide association studies (<span class="smallcaps-auto">GWAS</span>), linkage disequilibrium score regression (<span class="smallcaps-auto">LDSC</span>) was developed for unbiased estimation of genetic correlations. Although easy to use, <span class="smallcaps-auto">LDSC</span> only partially utilizes LD information. By fully accounting for LD across the genome, we develop a high-definition likelihood (<span class="smallcaps-auto">HDL</span>) method to improve precision in genetic correlation estimation. Compared to <span class="smallcaps-auto">LDSC</span>, <span class="smallcaps-auto">HDL</span> reduces the variance of genetic correlation estimates by about 60%, equivalent to a 2.5-fold increase in sample size. We apply <span class="smallcaps-auto">HDL</span> and <span class="smallcaps-auto">LDSC</span> to estimate 435 genetic correlations among 30 behavioral and disease-related phenotypes measured in the UK Biobank (<span class="smallcaps-auto">UKBB</span>). In addition to 154 significant genetic correlations observed for both methods, <span class="smallcaps-auto">HDL</span> identified another 57 significant genetic correlations, compared to only another 2 significant genetic correlations identified by <span class="smallcaps-auto">LDSC</span>. <span class="smallcaps-auto">HDL</span> brings more power to genomic analyses and better reveals the underlying connections across human complex traits.</p>'
- - /docs/genetics/heritable/2020-richter.pdf
  - ! "Genomic analyses implicate noncoding de novo variants in congenital heart disease"
  - Felix Richter, Sarah U. Morton, Seong Won Kim, Alexander Kitaygorodsky, Lauren K. Wasson, Kathleen M. Chen, Jian Zhou, Hongjian Qi, Nihir Patel, Steven R. DePalma, Michael Parfenov, Jason Homsy, Joshua M. Gorham, Kathryn B. Manheimer, Matthew Velinder, Andrew Farrell, Gabor Marth, Eric E. Schadt, Jonathan R. Kaltman, Jane W. Newburger, Alessandro Giardini, Elizabeth Goldmuntz, Martina Brueckner, Richard Kim, George A. Porter, Daniel Bernstein, Wendy K. Chung, Deepak Srivastava, Martin Tristani-Firouzi, Olga G. Troyanskaya, Diane E. Dickel, Yufeng Shen, Jonathan G. Seidman, Christine E. Seidman, Bruce D. Gelb
  - 2020-06-29
  - 10.1038/s41588-020-0652-z
  - ! '<p>A genetic etiology is identified for one-third of patients with congenital heart disease (<span class="smallcaps-auto"><span class="smallcaps-auto">CHD</span></span>), with 8% of cases attributable to coding de novo variants (<span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s). To assess the contribution of noncoding <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s to <span class="smallcaps-auto"><span class="smallcaps-auto">CHD</span></span>, we compared genome sequences from 749 <span class="smallcaps-auto"><span class="smallcaps-auto">CHD</span></span> probands and their parents with those from 1,611 unaffected trios. Neural network prediction of noncoding <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span> transcriptional impact identified a burden of <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s in individuals with <span class="smallcaps-auto"><span class="smallcaps-auto">CHD</span></span> (n = 2,238 <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s) compared to controls (n = 4,177; <em>p</em>= 8.7 × 10<sup>−4</sup>). Independent analyses of enhancers showed an excess of <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s in associated genes (27 genes versus 3.7 expected, <em>p</em>= 1 × 10<sup>−5</sup>). We observed significant overlap between these transcription-based approaches (odds ratio (OR) = 2.5, 95% confidence interval (CI) 1.1–5.0, <em>p</em>= 5.4 × 10<sup>−3</sup>). <span class="smallcaps-auto"><span class="smallcaps-auto">CHD</span></span> <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s altered transcription levels in 5 of 31 enhancers assayed. Finally, we observed a <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span> burden in <span class="smallcaps-auto"><span class="smallcaps-auto">RNA</span></span>-binding-protein regulatory sites (OR = 1.13, 95% CI 1.1–1.2, <em>p</em>= 8.8 × 10<sup>−5</sup>). Our findings demonstrate an enrichment of potentially disruptive regulatory noncoding <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s in a fraction of <span class="smallcaps-auto"><span class="smallcaps-auto">CHD</span></span> at least as high as that observed for damaging coding <span class="smallcaps-auto"><span class="smallcaps-auto">DNV</span></span>s.</p>'
- - /docs/psychology/writing/1997-boice.pdf
  - ! "Which is more Productive, Writing in Binge Patterns of Creative Illness or in Moderation?"
  - Bob Boice
  - 1997-10-01
  - 10.1177/0741088397014004001
  - ! '<p>The author reviews traditional beliefs about creative illness and suggests that their endorsement of euphoric binging misleads writers. Productive creativity seems to occur more reliably with moderation of work duration and of emotions, not with the fatigue and ensuing depression of binge writing. The author compares binge writers to a matched sample of novice professors who wrote in brief, daily sessions and with generally mild emotions. Binge writers (a) accomplished far less writing overall, (b) got fewer editorial acceptances, (c) scored higher on the Beck Depression Inventory, and (d) listed fewer creative ideas for writing. These data suggest that creative illness, defined by its common emotional state for binge writers (i.e., hypomania and its rushed euphoria brought on by long, intense sessions of working—followed by depression), offers more problems (e.g., working in an emotional, rushed, fatiguing fashion) than magic. The example of Joseph Conrad supports these findings.</p>'
- - /docs/cs/1981-cohen.pdf
  - ! "On Holy Wars and a Plea for Peace"
  - Daniel Cohen
  - 1981-10-01
  - 10.1109/C-M.1981.220208
  - ! '<p>Which bit should travel first? The bit from the big end or the bit from the little end? Can a war between Big Endians and Little Endians be avoided?</p><p>This article was written in an attempt to stop a war. I hope it is not too late for peace to prevail again. Many believe that the central question of this war is, What is the proper byte order in messages? More specifically, the question is, Which bit should travel first-the bit from the little end of the word or the bit from the big end of the word? Followers of the former approach are called Little Endians, or Lilliputians; followers of the latter are called Big Endians, or Blefuscuians. I employ these Swiftian terms because this modern conflict is so reminiscent of the holy war described in Gulliver’s Travels.</p><p>…To sum it all up, there are two camps, each with its own language. These languages are as compatible with each other as any Semitic and Latin languages. All Big Endians can talk only to each other. So can all the Little Endians, although there are some differences among the dialects used by different tribes. There is no middle ground—only one end can go first. As in all the religious wars of the past, power—not logic—will be the decisive factor. This is not the first holy war, and will probably not be the last. The “Reasonable, do it my way” approach does not work. Neither does the Esperanto approach of switching to yet another new language. Lest our communications world split along theses lines, we should take note of a certain book (not mentioned in the references), which has an interesting story about a similar phenomenon: the Tower of Babel. Lilliput and Blefuscu will never come to terms of their own free will. We need some Gulliver between the two islands to force a unified communication regime on all of us.</p><p>Of course, I hope that my way will be chosen, but it is not really critical. Agreement upon an order is more important than the order agreed upon.</p><p>Shall we toss a coin?"</p>'
- - /docs/genetics/heritable/2020-latvala.pdf
  - ! "Association of parental substance misuse with offspring substance misuse and criminality: a genetically informed register–based study"
  - ! "Antti Latvala, Ralf Kuja-Halkola, Brian M. D'Onofrio, Nitya Jayaram-Lindström, Henrik Larsson, Paul Lichtenstein"
  - 2020-06-29
  - 10.1017/S0033291720002135
  - ! "<jats:title>Abstract</jats:title>\n\t  <jats:sec id=\"S0033291720002135_sec_a1\" sec-type=\"other\">\n\t    <jats:title>Background</jats:title>\n\t    <jats:p>Genetically informed studies have provided mixed findings as to what extent parental substance misuse is associated with offspring substance misuse and antisocial behavior due to shared environmental and genetic factors.</jats:p>\n\t  </jats:sec>\n\t  <jats:sec id=\"S0033291720002135_sec_a2\" sec-type=\"methods\">\n\t    <jats:title>Methods</jats:title>\n\t    <jats:p>We linked data from nationwide registries for a cohort of 2 476 198 offspring born in Sweden 1958–1995 and their parents. Substance misuse was defined as International Classification of Diseases diagnoses of alcohol/drug use disorders or alcohol/drug-related criminal convictions. Quantitative genetic offspring-of-siblings analyses in offspring of monozygotic and dizygotic twin, full-sibling, and half-sibling parents were conducted.</jats:p>\n\t  </jats:sec>\n\t  <jats:sec id=\"S0033291720002135_sec_a3\" sec-type=\"results\">\n\t    <jats:title>Results</jats:title>\n\t    <jats:p>Both maternal and paternal substance misuse were robustly associated with offspring substance misuse [maternal adjusted hazard ratio (aHR) = 1.83 (95% confidence interval (CI) 1.80–1.87); paternal aHR = 1.96 (1.94–1.98)] and criminal convictions [maternal aHR = 1.56 (1.54–1.58); paternal aHR = 1.66 (1.64–1.67)]. Additive genetic effects explained 42% (95% CI 25–56%) and 46% (36–55%) of the variance in maternal and paternal substance misuse, respectively, and between 36 and 44% of the variance in substance misuse and criminality in offspring. The associations between parental substance misuse and offspring outcomes were mostly due to additive genetic effects, which explained 54–85% of the parent-offspring covariance. However, both nuclear and extended family environmental factors also contributed to the associations, especially with offspring substance misuse.</jats:p>\n\t  </jats:sec>\n\t  <jats:sec id=\"S0033291720002135_sec_a4\" sec-type=\"conclusions\">\n\t    <jats:title>Conclusions</jats:title>\n\t    <jats:p>Our findings from a large offspring-of-siblings study indicate that shared genetic influences mostly explain the associations between parental substance misuse and both offspring substance misuse and criminality, but we also found evidence for the contribution of environmental factors shared by members of nuclear and extended families.</jats:p>\n\t  </jats:sec>"
- - /docs/iq/2020-schubert.pdf
  - ! "A chronometric model of the relationship between frontal midline theta functional connectivity and human intelligence"
  - Anna-Lena Schubert, Dirk Hagemann, Christoph Löffler, Jan Rummel, Stefan Arnau
  - 2020-06-25
  - 10.1037/xge0000865
  - ! '<p>Individual differences in cognitive control have been suggested to act as a domain-general bottleneck constraining performance in a variety of cognitive ability measures, including but not limited to fluid intelligence, working memory capacity, and processing speed. However, owing to psychometric problems associated with the measurement of individual differences in cognitive control, it has been challenging to empirically test the assumption that individual differences in cognitive control underlie individual differences in cognitive abilities. In the present study, we addressed these issues by analyzing the chronometry of intelligence-related differences in midfrontal global theta connectivity, which has been shown to reflect cognitive control functions. We demonstrate in a sample of 98 adults, who completed a cognitive control task while their electroencephalogram was recorded, that individual differences in midfrontal global theta connectivity during stages of higher-order information-processing explained 65% of the variance in fluid intelligence. In comparison, task-evoked theta connectivity during earlier stages of information processing was not related to fluid intelligence. These results suggest that more intelligent individuals benefit from an adaptive modulation of theta-band synchronization during the time-course of information processing. Moreover, they emphasize the role of interregional goal-directed information-processing for cognitive control processes in human intelligence and support theoretical accounts of intelligence, which propose that individual differences in cognitive control processes give rise to individual differences in cognitive abilities.</p>'
- - /docs/history/2005-strong.pdf
  - ! "Incest Laws and Absent Taboos in Roman Egypt"
  - Anise K. Strong
  - 2005-01-01
  - 10.2139/ssrn.1596967
  - ! '<p>For at least two hundred and fifty years, many men in the Roman province of Egypt married their full sisters and raised families with them. During the same era, Roman law firmly banned close-kin marriages and denounced them both as nefas, or sacrilegious, and against the ius gentium, the laws shared by all civilized peoples. In Egypt, however, Roman officials deliberately chose not to enforce the relevant marriage laws among the Greek metic, hybrid, and native Egyptian populations; the bureaucracy also created loopholes within new laws which tolerated the practice. This policy created a gap between the absolute theoretical ban in Roman law and the reality of common incestuous unions in Egypt. Since Roman Egypt was both an important and a dangerous province, Rome needed both to pacify its people and to weaken Egypt’s status with its neighbors. By permitting incestuous marriages among non-Romans in Egypt, the Roman governors simultaneously pleased the local population while causing Jews and North Africans to hold their neighbor in contempt.</p>'
- - https://openai.com/blog/openai-api/
  - OpenAI API
  - Greg Brockman, Mira Murati, Peter Welinder (OpenAI)
  - 2020-06-11
  - ''
  - ! '<p>We’re releasing an <span class="smallcaps-auto">API</span> for accessing new AI models developed by OpenAI. Unlike most AI systems which are designed for one use-case, the <span class="smallcaps-auto">API</span> today provides a general-purpose “text in, text out” interface, allowing users to try it on virtually any English language task. You can now request access in order to integrate the <span class="smallcaps-auto">API</span> into your product, develop an entirely new application, or help us explore the strengths and limits of this technology.</p><p>Given any text prompt, the <span class="smallcaps-auto">API</span> will return a text completion, attempting to match the pattern you gave it. You can “program” it by showing it just a few examples of what you’d like it to do; its success generally varies depending on how complex the task is. The <span class="smallcaps-auto">API</span> also allows you to hone performance on specific tasks by training on a dataset (small or large) of examples you provide, or by learning from human feedback provided by users or labelers.</p>'
- - https://openai.com/blog/image-gpt/
  - "Image GPT (iGPT): We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image completions and samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised setting."
  - Mark Chen, Alec Radford, Ilya Sutskever (OpenAI)
  - 2020-06-17
  - ''
  - ! '<p>Transformer models like <span class="smallcaps-auto">BERT</span> and <span class="smallcaps-auto">GPT</span>-2 are domain agnostic, meaning that they can be directly applied to 1-D sequences of any form. When we train <span class="smallcaps-auto">GPT</span>-2 on images unrolled into long sequences of pixels, which we call i<span class="smallcaps-auto">GPT</span>, we find that the model appears to understand 2-D image characteristics such as object appearance and category. This is evidenced by the diverse range of coherent image samples it generates, even without the guidance of human provided labels. As further proof, features from the model achieve state-of-the-art performance on a number of classification datasets and near state-of-the-art unsupervised accuracy on ImageNet…we deliberately use the same transformer architecture as <span class="smallcaps-auto">GPT</span>-2 in language. As a consequence, we require significantly more compute in order to produce features competitive with those from top unsupervised convolutional nets…Generative sequence modeling is a universal unsupervised learning algorithm: since all data types can be represented as sequences of bytes, a transformer can be directly applied to any data type without additional engineering. Our work tests the power of this generality by directly applying the architecture used to train <span class="smallcaps-auto">GPT</span>-2 on natural language to image generation. We deliberately chose to forgo hand coding any image specific knowledge in the form of convolutions<sup>38</sup> or techniques like relative attention,<sup>39</sup> sparse attention,<sup>40</sup> and 2-D position embeddings.<sup>27</sup></p><p>…We train i<span class="smallcaps-auto">GPT</span>-S, i<span class="smallcaps-auto">GPT</span>-M, and i<span class="smallcaps-auto">GPT</span>-L, transformers containing 76M, 455M, and 1.4B parameters respectively, on ImageNet. We also train i<span class="smallcaps-auto">GPT</span>-XL[4], a 6.8 billion parameter transformer, on a mix of ImageNet and images from the web. Due to the large computational cost of modeling long sequences with dense attention, we train at the low resolutions of 32×32, 48×48, and 64×64…Our next result establishes the link between generative performance and feature quality. We find that both increasing the scale of our models and training for more iterations result in better generative performance, which directly translates into better feature quality.</p><p>…When we evaluate our features using linear probes on <span class="smallcaps-auto">CIFAR</span>-10, <span class="smallcaps-auto">CIFAR</span>-100, and <span class="smallcaps-auto">STL</span>-10, we outperform features from all supervised and unsupervised transfer algorithms. Our results are also compelling in the full fine-tuning setting</p><p>…Because we use the generic sequence transformer used for <span class="smallcaps-auto">GPT</span>-2 in language, our method requires large amounts of compute: i<span class="smallcaps-auto">GPT</span>-L was trained for roughly 2500 V100-days while a similarly performing MoCo<sup>24</sup> model can be trained in roughly 70 V100-days…We have shown that by trading off 2-D knowledge for scale<sup><a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" title="&#39;The Bitter Lesson&#39;. Rich Sutton 2019">60</a></sup> and by choosing predictive features from the middle of the network, a sequence transformer can be competitive with top convolutional nets for unsupervised image classification. Notably, we achieved our results by directly applying the <span class="smallcaps-auto">GPT</span>-2 language model to image generation. Our results suggest that due to its simplicity and generality, a sequence transformer given sufficient compute might ultimately be an effective way to learn excellent features in many domains.</p>'
- - /docs/ai/2020-chen.pdf#openai
  - ! "iGPT: Generative Pretraining from Pixels"
  - Mark Chen, Alec Radford, Rewon Child, Jeff Wu, Heewoo Jun, Prafulla Dhariwal, David Luan, Ilya Sutskever (OpenAI)
  - 2020-06-17
  - ''
  - ! '<p>Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we find that a <span class="smallcaps-auto">GPT</span>-2 scale model learns strong image representations as measured by linear probing, fine-tuning, and low-data classification. On <span class="smallcaps-auto">CIFAR</span>-10, we achieve 96.3% accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0% accuracy with full fine-tuning, matching the top supervised pre-trained models. An even larger model trained on a mixture of ImageNet and web images is competitive with self-supervised benchmarks on ImageNet, achieving 72.0% top-1 accuracy on a linear probe of our features.</p>'
- - https://beta.openai.com/
  - OpenAI API Beta homepage
  - OpenAI
  - 2020-06-11
  - ''
  - ! '<p>OpenAI technology, just an <span class="smallcaps-auto">HTTPS</span> call away: Apply our <span class="smallcaps-auto">API</span> to any language task—semantic search, summarization, sentiment analysis, content generation, translation, and more—with only a few examples or by specifying your task in English. One simple integration gives you access to our constantly-improving AI technology. Explore how you integrate with the <span class="smallcaps-auto">API</span> with these sample completions.</p><ul><li><span class="smallcaps">Simple, yet flexible</span>: Our <span class="smallcaps-auto">API</span> is designed to be used by anyone, but meets the needs of our own cutting-edge research.</li><li><span class="smallcaps">Your data, your rules</span>: You retain ownership of your data, and control whether we can use it for training models.</li><li><span class="smallcaps">Ready to go</span>: Our infrastructure already serves millions of <span class="smallcaps-auto">API</span> calls per day.</li></ul><p>Demos:</p><ul><li><p><span class="smallcaps">Semantic Search</span>: The <span class="smallcaps-auto">API</span> allows searching over documents based on the natural-language meaning of queries rather than keyword matching.</p><p>Casetext/Algolia/Web Browser Search Plugin</p></li><li><p><span class="smallcaps">Chat</span>: The <span class="smallcaps-auto">API</span> can enable fast, complex and consistent natural language discussions. With a brief prompt, the <span class="smallcaps-auto">API</span> generates dialogues spanning a range of topics, from space travel to history.</p><p>AI Channels</p></li><li><p><span class="smallcaps">Customer Service</span>: Leveraging search and chat capabilities, the <span class="smallcaps-auto">API</span> generates natural dialogue to quickly give customers relevant information. Through semantic text comprehension, the <span class="smallcaps-auto">API</span> can offer a range of analytics and productivity tools to better serve customers.</p><p>MessageBird/Sapling Intelligence</p></li><li><p><span class="smallcaps">Generation</span>: The <span class="smallcaps-auto">API</span> can generate complex and consistent natural language, and enables use cases like creative writing.</p><p>AI Dungeon/AI Weirdness/Replika</p></li><li><p><span class="smallcaps">Productivity Tools</span>: The <span class="smallcaps-auto">API</span> allows for parsing text into spreadsheet tables, summarizing email discussions, expanding content from bullet points, and more.</p><p>Quizlet/Art of Problem Solving/Natural Language Shell/Spreadsheets/Code Completion</p></li><li><p><span class="smallcaps">Content Comprehension</span>: The <span class="smallcaps-auto">API</span> can be used to build tools to help individuals consume content more efficiently.</p><p>Koko/Ross Intelligence/Summarization</p></li><li><p><span class="smallcaps">Polyglot</span>: While the <span class="smallcaps-auto">API</span> today works best in English, it also works quite well in other languages. The <span class="smallcaps-auto">API</span> can be used for tasks such as translation or chat with users in their preferred language.</p><p>Translation</p></li></ul>'
- - /docs/sociology/2020-wasow.pdf
  - ! "Agenda Seeding: How 1960s Black Protests Moved Elites, Public Opinion and Voting"
  - Omar Wasow
  - 2020-05-21
  - ''
  - ! '<p>How do stigmatized minorities advance agendas when confronted with hostile majorities? Elite theories of influence posit marginal groups exert little power. I propose the concept of agenda seeding to describe how activists use methods like disruption to capture the attention of media and overcome political asymmetries. Further, I hypothesize protest tactics influence how news organizations frame demands. Evaluating black-led protests between 1960 and 1972, I find nonviolent activism, particularly when met with state or vigilante repression, drove media coverage, framing, Congressional speech and public opinion on civil rights. Counties proximate to nonviolent protests saw presidential Democratic vote share among whites increase 1.3–1.6%. Protester-initiated violence, by contrast, helped move news agendas, frames, elite discourse and public concern toward “social control.” In 1968, using rainfall as an instrument, I find violent protests likely caused a 1.6–7.9% shift among whites towards Republicans and tipped the election. Elites may dominate political communication but hold no monopoly.</p>'
- - /docs/economics/2019-scholl.pdf
  - ! "Testing the Automation Revolution Hypothesis"
  - Keller Scholl, Robin Hanson
  - 2019-12-27
  - 10.2139/ssrn.3496364
  - ! '<p>Recently, many have predicted an imminent automation revolution, and large resulting job losses. Others have created metrics to predict new patterns in job automation vulnerability. As context to such claims, we test basic theory, two vulnerability metrics, and 251 O*<span class="smallcaps-auto">NET</span> job features as predictors of 1505 expert reports regarding automation levels in 832 U.S. job types from 1999 to 2019.</p><p>We find that pay, employment, and vulnerability metrics are predictive (R<sup>2</sup>~0.15), but add little to the top 25 O*<span class="smallcaps-auto">NET</span> job features, which together predict far better (R<sup>2</sup>~0.55). These best predictors seem understandable in terms of traditional kinds of automation, and have not changed over our time period. Instead, it seems that jobs have changed their features to become more suitable for automation.</p><p>We thus find no evidence yet of a revolution in the patterns or quantity of automation. And since, over this period, automation increases have predicted neither changes in pay nor employment, this suggests that workers have little to fear if such a revolution does come. [Keywords: automation, wages, employment, occupations, artificial intelligence, technology]</p>'
- - /docs/economics/2012-gordon.pdf
  - ! "Is U.S. Economic Growth Over? Faltering Innovation Confronts the Six Headwinds"
  - Bob Gordon
  - 2012-08-01
  - 10.3386/w18315
  - ! '<p>This paper raises basic questions about the process of economic growth. It questions the assumption, nearly universal since Solow’s seminal contributions of the 1950s, that economic growth is a continuous process that will persist forever. There was virtually no growth before 1750, and thus there is no guarantee that growth will continue indefinitely. Rather, the paper suggests that the rapid progress made over the past 250 years could well turn out to be a unique episode in human history. The paper is only about the United States and views the future from 2007 while pretending that the financial crisis did not happen. Its point of departure is growth in per-capita real <span class="smallcaps-auto">GDP</span> in the frontier country since 1300, the U.K. until 1906 and the U.S. afterwards. Growth in this frontier gradually accelerated after 1750, reached a peak in the middle of the 20<sup>th</sup> century, and has been slowing down since. The paper is about “how much further could the frontier growth rate decline?”</p><p>The analysis links periods of slow and rapid growth to the timing of the three industrial revolutions (IR’s), that is, IR #1 (steam, railroads) from 1750 to 1830; IR #2 (electricity, internal combustion engine, running water, indoor toilets, communications, entertainment, chemicals, petroleum) from 1870 to 1900; and IR #3 (computers, the web, mobile phones) from 1960 to present. It provides evidence that IR #2 was more important than the others and was largely responsible for 80 years of relatively rapid productivity growth between 1890 and 1972. Once the spin-off inventions from IR #2 (airplanes, air conditioning, interstate highways) had run their course, productivity growth during 1972–96 was much slower than before. In contrast, IR #3 created only a short-lived growth revival between 1996 and 2004. Many of the original and spin-off inventions of IR #2 could happen only once—urbanization, transportation speed, the freedom of females from the drudgery of carrying tons of water per year, and the role of central heating and air conditioning in achieving a year-round constant temperature.</p><p>Even if innovation were to continue into the future at the rate of the two decades before 2007, the U.S. faces six headwinds that are in the process of dragging long-term growth to half or less of the 1.9% annual rate experienced between 1860 and 2007. These include demography, education, inequality, globalization, energy/environment, and the overhang of consumer and government debt. A provocative “exercise in subtraction” suggests that future growth in consumption per capita for the bottom 99% of the income distribution could fall below 0.5% per year for an extended period of decades.</p>'
- - /docs/economics/1989-david.pdf
  - ! "Computer and Dynamo: The Modern Productivity Paradox In A Not–Too Distant Mirror"
  - Paul A. David
  - 1989-07-01
  - 10.22004/ag.econ.268373
  - ! '<p>Many observers of contemporary economic trends have been perplexed by the contemporary conjuncture of rapid technological innovation with disappointingly slow gains in measured productivity. The purpose of this essay is to show modern economists, and others who share their puzzlement in this matter, the direct relevance to their concerns of historical studies that trace the evolution of techno-economic regimes formed around “general purpose engines”. For this purpose an explicit parallel is drawn between two such engines—the computer and the dynamo. Although the analogy between information technology and electrical technology would have many limitations were it to be interpreted very literally, it nevertheless proves illuminating. Each of the principal empirical phenomena that go to make up modern perceptions of a “productivity paradox”, had a striking historical precedent in the conditions that obtained a little less than a century ago in the industrialized West. In 1900 contemporaries might well have said that the electric dynamos were to be seen “everywhere but in the economic statistics”. Exploring the reasons for that state of affairs, and the features of commonality between computer and dynamo—particularly in the dynamics of their diffusion and their incremental improvement, and the problems of capturing their initial effects with conventional productivity measures—provides some clues to help understand our current situation. The paper stresses the importance of keeping an appropriately long time-frame in mind when discussing the connections between the information revolution and productivity growth, as well as appreciating the contingent, path-dependent nature of the process of transition between one techno-economic regime and the next. [Keywords: productivity slowdown; diffusion of innovations; economics of technology; information technology; electric power industry]</p>'
- - https://www.mdpi.com/2073-4425/11/6/648
  - 'Preimplantation Genetic Testing for Polygenic Disease Relative Risk Reduction: Evaluation of Genomic Index Performance in 11,883 Adult Sibling Pairs'
  - Nathan R. Treff, Jennifer Eccles, Diego Marin, Edward Messick, Louis Lello, Jessalyn Gerber, Jia Xu, Laurent C.A.M. Tellier
  - 2020-06-12
  - 10.3390/genes11060648
  - ! '<p>Preimplantation genetic testing for polygenic disease risk (<span class="smallcaps-auto">PGT</span>-P) represents a new tool to aid in embryo selection. Previous studies demonstrated the ability to obtain necessary genotypes in the embryo with accuracy equivalent to in adults. When applied to select adult siblings with known type I diabetes status, a reduction in disease incidence of 45–72% compared to random selection was achieved. This study extends analysis to 11,883 sibling pairs to evaluate clinical utility of embryo selection with <span class="smallcaps-auto">PGT</span>-P. Results demonstrate simultaneous relative risk reduction of all diseases tested in parallel, which included diabetes, cancer, and heart disease, and indicate applicability beyond patients with a known family history of disease. [Keywords: preimplantation genetic testing; <span class="smallcaps-auto">PGT</span>-P; polygenic risk scoring; genomic index; relative risk reduction]</p>'
- - https://www.nature.com/articles/s41436-020-0869-3
  - 'Genetic ancestry analysis on >93,000 individuals undergoing expanded carrier screening reveals limitations of ethnicity-based medical guidelines'
  - Kristjan E. Kaseniit, Imran S. Haque, James D. Goldberg, Lee P. Shulman, Dale Muzzey
  - 2020-06-29
  - 10.1038/s41436-020-0869-3
  - ! '<p><em>Purpose</em>: Carrier status associates strongly with genetic ancestry, yet current carrier screening guidelines recommend testing for a limited set of conditions based on a patient’s self-reported ethnicity. Ethnicity, which can reflect both genetic ancestry and cultural factors (e.g., religion), may be imperfectly known or communicated by patients. We sought to quantitatively assess the efficacy and equity with which ethnicity-based carrier screening captures recessive disease risk.</p><p><em>Methods</em>: For 93,419 individuals undergoing a 96-gene expanded carrier screen (<span class="smallcaps-auto">ECS</span>), correspondence was assessed among carrier status, self-reported ethnicity, and a dual-component genetic ancestry (e.g., 75% African/25% European) calculated from sequencing data.</p><p><em>Results</em>: Self-reported ethnicity was an imperfect indicator of genetic ancestry, with 9% of individuals having &gt;50% genetic ancestry from a lineage inconsistent with self-reported ethnicity. Limitations of self-reported ethnicity led to missed carriers in at-risk populations: for 10 <span class="smallcaps-auto">ECS</span> conditions, patients with intermediate genetic ancestry backgrounds—who did not self-report the associated ethnicity—had significantly elevated carrier risk. Finally, for 7 of the 16 conditions included in current screening guidelines, most carriers were not from the population the guideline aimed to serve.</p><p><em>Conclusion</em>: Substantial and disproportionate risk for recessive disease is not detected when carrier screening is based on ethnicity, leading to inequitable reproductive care.</p>'
- - https://www.nature.com/articles/s41598-020-66867-0
  - Germline mutation rates in young adults predict longevity and reproductive lifespan
  - Richard M. Cawthon, Huong D. Meeks, Thomas A. Sasani, Ken R. Smith, Richard A. Kerber, Elizabeth O’Brien, Lisa Baird, Melissa M. Dixon, Andreas P. Peiffer, Mark F. Leppert, Aaron R. Quinlan, Lynn B. Jorde
  - 2020-06-19
  - 10.1038/s41598-020-66867-0
  - ! '<p>Ageing may be due to mutation accumulation across the lifespan, leading to tissue dysfunction, disease, and death. We tested whether germline autosomal mutation rates in young adults predict their remaining survival, and, for women, their reproductive lifespans. Age-adjusted mutation rates (<span class="smallcaps-auto">AAMR</span>s) in 61 women and 61 men from the Utah <span class="smallcaps-auto">CEPH</span> (Centre d’Etude du Polymorphisme Humain) families were determined. Age at death, cause of death, all-site cancer incidence, and reproductive histories were provided by the Utah Population Database, Utah Cancer Registry, and Utah Genetic Reference Project. Higher <span class="smallcaps-auto">AAMR</span>s were significantly associated with higher all-cause mortality in both sexes combined. Subjects in the top quartile of <span class="smallcaps-auto">AAMR</span>s experienced more than twice the mortality of bottom quartile subjects (hazard ratio [HR], 2.07; 95% confidence interval [CI], 1.21–3.56; <em>p</em>= 0.008; median survival difference = 4.7 years). Fertility analyses were restricted to women whose age at last birth (<span class="smallcaps-auto">ALB</span>) was ≥ 30 years, the age when fertility begins to decline. Women with higher <span class="smallcaps-auto">AAMR</span>s had significantly fewer live births and a younger <span class="smallcaps-auto">ALB</span>. Adult germline mutation accumulation rates are established in adolescence, and later menarche in women is associated with delayed mutation accumulation. We conclude that germline mutation rates in healthy young adults may provide a measure of both reproductive and systemic ageing. Puberty may induce the establishment of adult mutation accumulation rates, just when <span class="smallcaps-auto">DNA</span> repair systems begin their lifelong decline.</p>'
- - https://www.newscientist.com/article/2246020-three-people-with-inherited-diseases-successfully-treated-with-crispr/
  - Three people with inherited diseases successfully treated with CRISPR
  - Michael Le Page (New Scientist)
  - 2020-06-12
  - ''
  - ! '<p>Two people with beta thalassaemia and one with sickle cell disease no longer require blood transfusions, which are normally used to treat severe forms of these inherited diseases, after their bone marrow stem cells were gene-edited with <span class="smallcaps-auto">CRISPR</span>.</p><p>Result of this ongoing trial, which is the first to use <span class="smallcaps-auto">CRISPR</span> to treat inherited genetic disorders, were announced today at a virtual meeting of the European Hematology Association. “The preliminary results… demonstrate, in essence, a functional cure for patients with beta thalassaemia and sickle cell disease,” team member Haydar Frangoul at Sarah Cannon Research Institute in Nashville, Tennessee, said in <a href="https://crisprtx.gcs-web.com/news-releases/news-release-details/crispr-therapeutics-and-vertex-announce-new-clinical-data">a statement</a>.</p><p>…In this trial, run by collaborating companies <span class="smallcaps-auto">CRISPR</span> Therapeutics and Vertex, bone marrow stem cells are removed from people and the gene that turns off fetal haemoglobin production is disabled with <span class="smallcaps-auto">CRISPR</span>. The remaining bone marrow cells are killed by chemotherapy, then replaced by edited cells. This is done to ensure that new blood cells are produced by the edited stem cells, but the chemotherapy can have serious side effects including infertility. The first two patients with beta thalassaemia no longer need blood transfusions since being treated 15 and five months ago. Nor does the patient with sickle cell disease, nine months after treatment. The results are excellent, says Marina Cavazzana at the Necker-Enfants Malades Hospital in Paris, France, whose team has treated a 13-year-old boy with sickle cell disease using a different approach.</p>'
- - https://www.overcomingbias.com/2019/12/automation-as-colonization-wave.html
  - Automation As Colonization Wave
  - Robin Hanson
  - 2019-12-13
  - ''
  - ! '<p>Our automation data analysis found a few surprising results…But the most interesting surprise, I think, is that while, over the last twenty years, we’ve seen no noticeable change in the factors that predict which jobs get more automated, we <em>have</em> seen job features change to become more suitable to automation. On average jobs have moved by about a third of a standard deviation, relative to the distribution of job automation across jobs. This is actually quite a lot. Why do jobs change this way?</p><p>Consider the example of a wave of human colonization moving over a big land area. Instead of all the land becoming colonized more densely at same rate everywhere, what you instead see is new colonization happening much more near old colonization. In the U.S., dense concentrations started in the east and slowly spread to the west. There was little point in clearing land to grow stuff if there weren’t enough other folks nearby to which to sell your crops, and from which to buy supplies.</p><p>…Now think about the space of job tasks as a similar sort of landscape. Two tasks are adjacent to other tasks when the same person tends to do both, when info or objects are passed from one to the other, when they take place close in place and time, and when their details gain from being coordinated. The ease of automating each task depends on how regular and standardized are its inputs, how easy it is to formalize the info on which key choices depend, how easy it is to evaluate and judge outputs, and how simple, stable, and mild are the physical environments in which this task is done. When the tasks near a particular task get more automated, those tasks tend more to happen in a more controlled stable environment, the relevant info tends to be more formalized, and related info and objects get simpler, more standardized, and more reliably available. And this all tends to make it easier to automate such tasks. Much like how land is easier to colonize when nearby land is more colonized.</p><p>…We have long been experiencing a wave of automation passing across the space of job tasks. Some of this increase in automation has been due to falling computer tech costs, improving algorithms and tools, etc. But much of it may simply be the general potential of this tech being realized via a slow steady process with a long delay: the automation of tasks near other recently automated tasks, slowly spreading across the landscape of tasks.</p>'
- - https://spectrum.ieee.org/robotics/robotics-software/economics-of-the-singularity
  - "Economics Of The Singularity: Stuffed into skyscrapers by the billion, brainy bugbots will be the knowledge workers of the future"
  - Robin Hanson
  - 2008-06-01
  - ''
  - ! '<p>So we have perhaps five eras during which the thing whose growth is at issue—the universe, brains, the hunting economy, the farming economy, and the industrial economy—doubled in size at fixed intervals. Each era of growth before now, however, has eventually switched suddenly to a new era having a growth rate that was between 60 and 250 times as fast. Each switch was completed in much less time than it had taken the previous regime to double—from a few millennia for the agricultural revolution to a few centuries for the industrial one. These switches constituted singularities…A few exceedingly rare innovations, however, do suddenly change everything. One such innovation led to agriculture; another led to industry.</p><p>…If current trends continue, we should have computer hardware and brain scans fast and cheap enough to support this scenario in a few decades…Though it might cost many billions of dollars to build one such machine, the first copy might cost only millions and the millionth copy perhaps thousands or less. Mass production could then supply what has so far been the one factor of production that has remained critically scarce throughout human history: intelligent, highly trained labor.</p><p>…The relative advantages of humans and machines vary from one task to the next. Imagine a chart resembling a topographic cross section, with the tasks that are “most human” forming a human advantage curve on the higher ground. Here you find chores best done by humans, like gourmet cooking or elite hairdressing. Then there is a “shore” consisting of tasks that humans and machines are equally able to perform and, beyond them an “ocean” of tasks best done by machines. When machines get cheaper or smarter or both, the water level rises, as it were, and the shore moves inland.</p><p>This sea change has two effects. First, machines will substitute for humans by taking over newly “flooded” tasks. Second, doing machine tasks better complements human tasks, raising the value of doing them well. Human wages may rise or fall, depending on which effect is stronger. Wages could fall so far that most humans could not live on them. For example, in the 1920s, when the mass-produced automobile came along, it was produced largely by machines, with human help. So machines dominated that function—the assembly of cars. The resulting proliferation of machine-assembled cars raised the value of related human tasks, such as designing those cars, because the financial stakes were now much higher. Sure enough, automobiles raised the wages of machinists and designers—in these cases, the complementary effect dominated. At the same time, the automobile industry lowered the pay of saddle makers and stable hands, an example of the substitution effect.</p><p>So far, machines have displaced relatively few human workers, and when they have done so, they have in most cases greatly raised the incomes of other workers. That is, the complementary effect has outweighed the substitution effect—but this trend need not continue. In our graph of machines and humans, imagine that the ocean of machine tasks reached a wide plateau. This would happen if, for instance, machines were almost capable enough to take on a vast array of human jobs. For example, it might occur if machines were on the very cusp of human-level cognition. In this situation, a small additional rise in sea level would flood that plateau and push the shoreline so far inland that a huge number of important tasks formerly in the human realm were now achievable with machines. We’d expect such a wide plateau if the cheapest smart machines were whole-brain emulations whose relative abilities on most tasks should be close to those of human beings.</p><p>…Together these effects seem quite capable of producing economic doubling times much shorter than anything the world has ever seen. And note that this forecast does not depend on the rate at which we achieve machine intelligence capabilities or the rate at which the intelligence of machines increases. Merely having computer-like machines able to do most important mental tasks as well as humans do seems sufficient to produce very rapid growth.</p>'
- - https://www.zdnet.com/article/startup-tenstorrent-and-competitors-show-how-computing-is-changing-ai-and-vice-versa/
  - "Startup Tenstorrent shows AI is changing computing and vice versa: Tenstorrent is one of the rush of AI chip makers founded in 2016 and finally showing product. The new wave of chips represent a substantial departure from how traditional computer chips work, but also point to ways that neural network design may change in the years to come"
  - Tiernan Ray (ZDNet)
  - 2020-04-10
  - ''
  - ! '<p>2016 was an amazing year in the history of computing. That year, numerous experienced computer chip designers set out on their own to design novel kinds of parts to improve the performance of artificial intelligence. It’s taken a few years, but the world is finally seeing what those young hopefuls have been working on.</p><p>…Bajic, and other chip teams, are responding to the explosion in the size of deep learning models, such as <span class="smallcaps-auto">BERT</span>, and OpenAI’s “<span class="smallcaps-auto">GPT</span>2,” but also even newer models such as Nvidia’s “Megatron,” Microsoft’s “Turing <span class="smallcaps-auto">NLG</span>,” and neural net models that Bajic said he couldn’t talk about publicly that will have on the order of one-trillion parameters.</p>'
- - https://huggingface.co/calculator/
  - "How Big Should My Language Model Be?"
  - Teven Le Scao (Hugging Face)
  - 2020-06-08
  - ''
  - ! '<p>[Discussion of DL scaling laws and how big = better, with interactive graphs to help visualize the multi-way relationship between dataset / model / validation-loss / <span class="smallcaps-auto">FLOPS</span>.]</p><p>Research at Hugging Face also leverages this phenomenon, and we’ve combined it with <span class="smallcaps-auto">GPU</span> speed estimations to ensure model size is just right for the compute budget of the experiment (when in doubt, it’s bigger than you think!). This blog post will show how this impacts architecture decisions on a standard language modeling benchmark: we replicate the 14-layer state-of-the-art result from Zhang et al.’s Transformer-XL paper without any hyper-parameter optimization and saving 25% of training time. We also estimate that the 18-layer model from the same paper trained for an order of magnitude too many training steps. Wanna play with our demo before reading? Just click here!</p><ol type="1"><li><p>There is an optimal time to stop training (and it’s earlier than you think)</p></li><li><p><span class="smallcaps-auto">GPU</span>s are optimized for large, wide models</p></li><li><p>Demonstration on a language modeling task: Wikitext-103</p></li><li><p>Takeaways</p><ul><li>Big models are surprisingly efficient!</li><li>Training until convergence is not efficient at all.</li><li>Benchmarking smaller-scale runs allows us to predict model performance and optimal stopping time for production-scale models.</li><li>Using larger models stopped earlier and optimizing model size for speed lowers training costs.</li></ul></li></ol>'
- - https://dianaverse.com/2020/06/15/evpsychandanimalethics/
  - "Animal Ethics and Evolutionary Psychology—10 ideas"
  - Diana Fleischman
  - 2020-06-15
  - ''
  - ! '<p><a href="https://www.dropbox.com/s/80gipfxwsh72grg/Animal%20Ethics%20and%20Evolutionary%20psychology%20June%20draft%20for%20website%20and%20blog.pdf?dl=0">“Animal Ethics and Evolutionary Psychology”</a> (read the whole chapter here) attempts to untangle some of the evolutionary reasons why we have such inconsistent attitudes towards animals. Below I quote parts of the chapter—for full references, check out the original.</p><ol type="1"><li>Wolf moms think dog puppies are cuter than wolf pups</li><li>Women are more willing than men to let a foreign stranger die for their dog</li><li>Animal abuse is common, and there isn’t good evidence that it predicts psychopathy and criminality</li><li>Maybe you should “Eat the Whales”</li><li>Slaughterhouse workers think the guy who kills the cow, the knocker, has serious psychological problems</li><li>Many different polls find that a lot of regular people have pretty extreme views on animal rights</li><li>People hate vegetarians more than almost any other group, but they’re more likely to hire them or rent to them than any other group</li><li>Across cultures- women nursing animals at the breast is pretty common</li><li>Consumers who say they care about animal welfare rarely buy products in accordance with those beliefs</li><li>Evolutionary explanations don’t excuse or normalize violence in the animal domain or any other.</li></ol>'
- - https://lilianweng.github.io/lil-log/2020/06/07/exploration-strategies-in-deep-reinforcement-learning.html
  - Exploration Strategies in Deep Reinforcement Learning
  - Lilian Weng
  - 2020-06-07
  - ''
  - ! '<p>Exploitation versus exploration is a critical topic in Reinforcement Learning. We’d like the RL agent to find the best solution as fast as possible. However, in the meantime, committing to solutions too quickly without enough exploration sounds pretty bad, as it could lead to local minima or total failure. Modern RL algorithms that optimize for the best returns can achieve good exploitation quite efficiently, while exploration remains more like an open topic.</p><p>I would like to discuss several common exploration strategies in Deep RL here. As this is a very big topic, my post by no means can cover all the important subtopics. I plan to update it periodically and keep further enriching the content gradually in time.</p><ul><li><p>Classic Exploration Strategies</p></li><li><p>Key Exploration Problems</p><ul><li>The Hard-Exploration Problem</li><li>The Noisy-TV Problem</li></ul></li><li><p>Intrinsic Rewards as Exploration Bonuses</p><ul><li><p>Count-based Exploration</p><ul><li>Counting by Density Model</li><li>Counting after Hashing</li></ul></li><li><p>Prediction-based Exploration</p><ul><li>Forward Dynamics</li><li>Random Networks</li><li>Physical Properties</li></ul></li></ul></li><li><p>Memory-based Exploration</p><ul><li>Episodic Memory</li><li>Direct Exploration</li></ul></li><li><p>Q-Value Exploration</p></li><li><p>Variational Options</p></li></ul>'
- - https://obscuritory.com/sim/when-simcity-got-serious/
  - 'When <em>SimCity</em> got serious: the story of Maxis Business Simulations and <em>SimRefinery</em>'
  - Phil Salvador
  - 2020-05-19
  - ''
  - ! '<p>[Account of little-known excursion of the <a href="https://en.wikipedia.org/wiki/SimCity">Sim</a> franchise’s owner <a href="https://en.wikipedia.org/wiki/Maxis">Maxis</a> into simulating oil refineries and national health care systems, which touched on the failed ’90s push of President Bill Clinton &amp; Hillary Clinton for a total healthcare system overhaul. The protagonist, John Hiles, is a tragic figure: someone who kept pushing cutting-edge new ideas which ought to revolutionize the world and yet, they never quite did, always launching ahead of their time or derailed by bad luck along the way.]</p><p>Maxis didn’t want to make professional simulation games. But for two brief, strange years, they did.</p><p>From 1992 to 1994, a division called Maxis Business Simulations was responsible for making serious professional simulations that looked and played like Maxis games. After Maxis cut the division loose, the company continued to operate independently, taking the simulation game genre in their own direction. Their games found their way into corporate training rooms and even went as far as the White House.</p><p>Almost nothing they developed was ever released to the public. But their software raises questions about the role we want games to play in society.</p><p>Over the past few years, I’ve spoken with employees from Maxis and the Business Simulations team to learn more about their company. For the first time, this is their story.</p>'
- - https://www.medrxiv.org/content/10.1101/2020.06.01.20119297v1
  - An integrated polygenic and clinical risk tool enhances coronary artery disease prediction
  - "Fernando Riveros-Mckay Aguilera, Michael E. Weale, Rachel Moore, Saskia Selzam, Eva Krapohl, R. Michael Sivley, William A Tarran, Peter Sørensen, Alexander S. Lachapelle, Jonathan A. Griffiths, Ayden Saffari, John Deanfield, Chris C. A. Spencer, Julia Hippisley-Cox, David J. Hunter, Jack W. O'Sullivan, Euan A. Ashley, Vincent Plagnol, Peter Donnelly"
  - 2020-06-03
  - 10.1101/2020.06.01.20119297
  - ! '<p><em>Background</em>: There is considerable interest in whether genetic data can be used to improve standard cardiovascular disease risk calculators, as the latter are routinely used in clinical practice to manage preventative treatment.</p><p><em>Methods</em>: This research has been conducted using the UK Biobank (<span class="smallcaps-auto">UKB</span>) resource. We developed our own polygenic risk score (<span class="smallcaps-auto">PRS</span>) for coronary artery disease (<span class="smallcaps-auto">CAD</span>), using novel and established methods to combine published genome-wide association study (<span class="smallcaps-auto">GWAS</span>) data with data from 114,196 UK Biobank individuals, also leveraging a large resource of other <span class="smallcaps-auto">GWAS</span> datasets along with functional information, to aid in the identification of causal variants, and thence define weights for &gt; 8M genetic variants. We utilised a further 60,000 <span class="smallcaps-auto">UKB</span> individuals to develop an integrated risk tool (<span class="smallcaps-auto">IRT</span>) that combined our <span class="smallcaps-auto">PRS</span> with established risk tools (either the American Heart Association/American College of Cardiology’s pooled cohort equations (<span class="smallcaps-auto">PCE</span>) or the UK’s <span class="smallcaps-auto">QRISK</span>3) which was then tested in an additional, independent, set of 212,563 <span class="smallcaps-auto">UKB</span> individuals. We evaluated prediction performance in individuals of European ancestry, both as a whole and stratified by age and sex.</p><p><em>Findings</em>: The novel <span class="smallcaps-auto">CAD</span> <span class="smallcaps-auto">PRS</span> showed superior predictive power for <span class="smallcaps-auto">CAD</span> events, compared to other published <span class="smallcaps-auto">PRS</span>s. As an individual risk factor, it has similar predictive power to each of systolic blood pressure, <span class="smallcaps-auto">HDL</span> cholesterol, and <span class="smallcaps-auto">LDL</span> cholesterol, but is more predictive than total cholesterol and smoking history. Our novel <span class="smallcaps-auto">CAD</span> <span class="smallcaps-auto">PRS</span> is largely uncorrelated with <span class="smallcaps-auto">PCE</span>, <span class="smallcaps-auto">QRISK</span>3, and family history, and, when combined with <span class="smallcaps-auto">PCE</span> into an integrated risk tool, had superior predictive accuracy. In individuals reclassified as high risk, <span class="smallcaps-auto">CAD</span> event rates were markedly and significantly higher compared to those reclassified as low risk. Overall, 9.7% of incident <span class="smallcaps-auto">CAD</span> cases were misclassified as low risk by <span class="smallcaps-auto">PCE</span> and correctly classified as high risk by the <span class="smallcaps-auto">IRT</span>, in contrast to 3.7% misclassified by the <span class="smallcaps-auto">IRT</span> and correctly classified by <span class="smallcaps-auto">PCE</span>. The overall net reclassification improvement for the <span class="smallcaps-auto">IRT</span> was 5.7% (95% CI 4.4–7.0), but when individuals were stratified into four age-by-sex subgroups the improvement was larger for all subgroups (range 7.7%-17.3%), with best performance in younger middle-aged men aged 40–54yo (17.3%, 95% CI 13.0–21.5). Broadly similar results were found using a different risk tool (<span class="smallcaps-auto">QRISK</span>3), and also for cardiovascular disease events defined more broadly.</p><p><em>Interpretation</em>: An integrated risk tool that includes polygenic risk outperforms current, clinical risk stratification tools, and offers greater opportunity for early interventions. Given the plummeting costs of genetic tests, future iterations of <span class="smallcaps-auto">CAD</span> risk tools would be enhanced with the addition of a person’s polygenic risk.</p>'
- - https://www.npr.org/sections/health-shots/2020/06/23/877543610/a-year-in-1st-patient-to-get-gene-editing-for-sickle-cell-disease-is-thriving
  - 'A Year In, 1<sup>st</sup> Patient To Get Gene Editing For Sickle Cell Disease Is Thriving'
  - Rob Stein (NPR)
  - 2020-06-23
  - ''
  - ! '<p>…as the one-year anniversary of her landmark treatment approaches, Gray has just received good news: The billions of genetically modified cells doctors infused into her body clearly appear to be alleviating virtually all the complications of her disorder, sickle cell disease. “It’s wonderful. It’s the change I’ve been waiting on my whole life,” Gray told <span class="smallcaps-auto">NPR</span>, which has had exclusive access to chronicle her experience over the past year.</p><p>…The last time <span class="smallcaps-auto">NPR</span> spoke with Gray—in November—her doctors had just gotten the first hints the treatment might be working. Now, after nine months of careful testing, the treatment shows no signs of waning, making her doctors more confident than ever the experiment has been a success.</p><p>…The researchers conducting the study Gray started caution that it’s too soon to reach any firm conclusions about the long-term safety and effectiveness of the approach. Gray is just one patient who has been followed for what is still a relatively short period of time, they noted. But Gray’s experience so far, along with two other patients who received the same treatment for a similar disorder, indicate the therapy has been effective for her and may work for other patients as well, they said…At a meeting of the European Hematology Association on June 12, Frangoul and other researchers presented the latest results of their latest testing of Gray as well as two study subjects with a related condition, beta thalassemia. The latter also appear to be benefiting…The researchers also reported that the first patient to receive the same treatment for beta thalassemia in Germany has now been able to live without blood transfusions for 15 months. Previously, the researchers had reported data for that patient for nine months. In addition, four other beta thalassemia patients have been treated, including one who has been transfusion-free for five months, the researchers reported. While Gray and the beta thalassemia patients experienced some health complications following their procedures, none appears to have been due to the gene-edited cells and all recovered, according to the researchers.</p><p><strong>“A huge change”</strong>: Perhaps most importantly, the changes appear to have translated into significant health benefits for Gray. She hasn’t had any severe pain attacks since the treatment and hasn’t required any emergency room treatments, hospitalizations or blood transfusions. In each of the previous two years, Gray had required an average of seven hospitalizations and emergency room visits due to severe pain episodes as well as requiring regular blood transfusions. She has also been able to reduce significantly her need for powerful narcotics to alleviate her pain.</p><p>“It’s a very big deal for me,” Gray said. “It’s a huge change.”</p>'
- - https://www.psychologytoday.com/us/blog/animals-and-us/201908/did-breast-feeding-play-role-in-the-evolution-pets
  - 'Did Breast-Feeding Play A Role In the Evolution of Pets? Like the dolphin who adopted a baby whale, humans have often breast-fed pets'
  - Hal Herzog
  - 2019-08-06
  - ! ''
  - ! '<p>…One of my Facebook friends did not agree. She responded that the big difference between human pet-keeping and this unusual dolphin/whale relationship was that human females never breast-feed members of other species. But she was wrong. The surprising fact is that in many parts of the world, there is a long history of women nursing animals. To modern sensibilities, the idea of a woman suckling an animal is, to say the least, weird, and even perverted.</p><p>And yet, both of the two most important books on the evolution of pets, James Serpell’s <em>In the Company of Animals</em> and Psychology Today blogger John Bradshaw’s <em>The Animals Among Us</em>, discuss the role of wet-nursing animals by women in the origins of pet-keeping. Indeed, Bradshaw writes, “Far from an aberration confined to one tribe, breast-feeding of pets used to occur all over the world…” The most extensive academic treatise on the geography and functions of women breastfeeding animals is a fascinating but little known 1982 article by Fredrick Simoons and James Baldwin titled <a href="https://www.gwern.net/docs/sociology/1982-simoons.pdf">“Breast-Feeding of Animals: Its Socio-Cultural Context and Geographic Occurrence.”</a> The authors were particularly interested in regional differences in the suckling of animals…<strong>Why Do Women Breast-feed Animals?</strong> Simoons and Baldwin reported that wet-nursing of young animals occurred in different societies for four reasons:</p><ul><li><span class="smallcaps">Affectionate Breast-feeding</span>: In affectionate breast-feeding, women elected to nurse baby animals out of “compassion, warmth, love.” These creatures were essentially pets treated like human babies. This form of nursing was most common among the hunter-gatherers of the Amazon and the Malay Peninsula.</li><li><span class="smallcaps">Economic Breast-feeding</span>: In economic breast-feeding, young animals were nursed primarily for utilitarian purposes, for example, the rearing of a hunting dog. On Polynesian islands where dogs were on the menu, puppies were breastfed in order to improve the flavor of their flesh when they were consumed as adults.</li><li><span class="smallcaps">Ceremonial Breast-feeding</span>: This rare form of animal nursing was practiced by the Ainu in Japan who raised bear cubs for sacrificial slaughter.</li><li><span class="smallcaps">Human Welfare Breast-feeding</span>: In these cases, animals were nursed for the benefit of the humans. The most common examples were in cultures in which lactating women breast-fed animals to relieve breast pain. And as Carys Williams and her colleagues pointed out, breast-feeding puppies in Polynesia may even have been used as a form of contraception by extending lactation.</li></ul><p>…<strong>Animal Breastfeeding and the Origins of Pet-keeping:</strong> Simoons and Baldwin argue that breast-feeding was an important step on the path to pet-keeping and the domestication of animals. John Bradshaw is not so sure. He writes, “Just because women in other cultures interacted with animals in ways that seen unfathomably intense to us does not mean they automatically considered them “pet” in the sense that we do.” His point is well-taken. However, I still don’t see much difference between the adoption of a baby melon-headed whale by a nurturing mother dolphin, and the modern penchant for adopting puppies and kittens, showering them with love, and calling them “our babies.”</p>'
- - https://www.thedrive.com/news/33645/the-incredible-story-of-the-us-armys-earth-shaking-off-road-land-trains
  - ! "The Incredible Story of the US Army's Earth-Shaking, Off-Road Land Trains: Oh, your pickup has a lift? That's cute"
  - Peter Holderith (The Drive)
  - 2020-05-25
  - ''
  - ! '<p>You need to get 500 tons of supplies from Fairbanks, Alaska to the Arctic Ocean—a journey of about 400 miles through pure wilderness. There are no roads, very few airstrips, and endless ice. You’re going to have to withstand −68° temperatures. Also, nuclear armageddon is on the menu if you’re not quick about it. You, my friend, need a LeTourneau land train.</p><p>…Born in 1888, Robert Gilmore LeTourneau was an inventor of heavy machinery. In <span class="smallcaps-auto">WWII</span>, 70% of the Allies’ earth-moving equipment was created by LeTourneau Technologies, Inc. Having very little formal education, LeTourneau began his working career as an ironmonger. By the time he died in 1969 he was tremendously wealthy and personally held nearly 300 patents. He is buried on the campus of the University he founded in his name, where his gravestone reads “<span class="smallcaps-auto">MOVER</span> OF <span class="smallcaps-auto">MEN</span> <span class="smallcaps-auto">AND</span> <span class="smallcaps-auto">MOUNTAINS</span>.” Just a little character development for you. LeTourneau had spent the early 1950s perfecting a sort of diesel-electric drivetrain for multi-wheeled heavy-machinery. The system—somewhat similar in concept to the sort used on many locomotives—used a combustion engine to spin an electric generator. This generator would send its power to hub motors mounted to each wheel of the vehicle, allowing for multi-wheel-drive without differentials, driveshafts, or the drivetrain losses associated with them…Developed to haul lumber out of forests over rough terrain, the VC-12 had a hauling capacity of 140 tons. A second version saw LeTourneau add three more cargo trailers and another control cab out back with a second Cummins diesel, much like a real train would be set up with multiple locomotives. <span class="smallcaps-auto">TRADCOM</span> caught wind of the project and asked for a demonstration.</p><p>…The VC-22 was quickly assembled in a little more than a month. This is impressive considering it was one of the longest (if not the longest) off-road vehicle ever built at the time, with its six cars (including the locomotive) measuring a total of 274 feet. Each car had four driven wheels, resulting in 24-wheel-drive courtesy of two 400 horsepower Cummins diesel engines and the now-familiar hub motor setup. It had a payload capacity of 150 tons. Thanks to its 7.3-foot-tall wheels and tires, it could traverse nearly any terrain. It had a very successful first season hauling freight to the <span class="smallcaps-auto">DEW</span> Line, but a year later it jackknifed and a fire started in the engine room that rendered it inoperable. Soon after, Alaska Freightlines’ contract with Western Electric ended and the VC-22 was hauled out of Canada and left on the side of a highway in central Alaska, where it remains to this day.</p><p>…It might not sound like it, but the Army was very impressed with the <span class="smallcaps-auto">LCC</span>-1’s capabilities. So in 1958, officials commissioned the construction of its successor, the longest off-road vehicle ever and LeTourneau’s final triumph: the TC-497 Overland Train Mark II. The TC-497 is a truly remarkable feat of engineering. Capable of hauling 150 tons at 20 mph for nearly 400 miles (this range could be extended by carrying extra fuel cars), it was powered by four 1,170-hp gas turbine engines. Only one of these engines was in the locomotive, with the other three were housed in their own separate cars. It retained the hub motor system from previous overland trains as well, meaning all 54 wheels on the vehicle were powered…The TC-497 was tested by the Army in 1962 at the Yuma Proving Grounds in Arizona. The results were once again impressive—but so were simultaneous advances in heavy-lift helicopters like the Sikorsky CH-54 Tarhe, a fleet of which could accomplish what the TC-497 promised with a fraction of the time and effort. The time of solving a problem like remote logistics with a massive, almost cartoonish machine like an overland train was over.</p>'
- - https://www.wired.com/story/why-humans-totally-freak-out-when-they-get-lost/
  - "Why Humans Totally Freak Out When They Get Lost: People really do circle past the same tree over and over again—it doesn't just happen in movies"
  - Michael Bond (Wired)
  - 2020-05-13
  - ''
  - ! '<p>She left a note for her would-be rescuers: “When you find my body please call my husband George and my daughter Kerry, it will be the greatest kindness for them to know that I am dead and where you found me—no matter how many years from now. Please find it in your heart to mail the contents of this bag to one of them.” She survived at least 19 days on her own in the wilderness before succumbing to the effects of exposure and starvation, longer than many experts believed possible. She did not know that a dog team had passed within 100 yards of her, that her campsite was only half a mile from the trail as the crow flies, or that if she had walked downhill she would have soon reached an old railroad track that would have taken her, in either direction, straight out of the woods.</p><p>…When the aviator Francis Chichester was teaching navigation to <span class="smallcaps-auto">RAF</span> pilots during the Second World War, two of his students went missing during an exercise. Chichester searched for them for days in his light aircraft in the Welsh hills, without success. Three months later, he heard that they were prisoners of war: They had misread their compass and flown 180° in the wrong direction, traveling southeast instead of northwest, and had crossed the English Channel thinking it was the Bristol Channel. “They were grateful when an airfield put up a cone of searchlights for them,” Chichester recounted in his autobiography, “and it was not until they had finished their landing run on the airstrip and a German soldier poked a tommy-gun into the cockpit that they realised that they were not on an English airfield.” This was the wartime equivalent of following a satnav into a river.</p><p>…Some years ago Kenneth Hill, a psychologist at St Mary’s University in Halifax, Canada, who has dedicated his career to studying how lost people behave, reviewed more than 800 search and rescue reports from his home province of Nova Scotia, which is 80% forest and is known as the “lost person capital of North America.” In Nova Scotia you can get lost by stepping away from your backyard. He found only two cases out of those 800-plus in which the lost person had stayed put: an 80-year-old woman out picking apples, and an 11-year-old boy who had taken a “Hug a Tree and Survive” course at school (as the name implies, it teaches kids to stay where they are). He says most lost people are stationary when they are found, but only because they have run themselves into the ground and are too tired or ill to continue…Circling happens where there are no prominent landmarks (a cell phone mast or a tall tree, for example) or spatial boundaries (a fence or a line of hills), and where all the vistas look similar. Without a fixed reference point, we drift. A view of the sun or the moon can help keep us grounded, though the sun is a dangerous guide if you’re not aware of how it moves across the sky. In an appendix to Canadian Crusoes, Catharine Traill relates the true story of a girl who, lost in the woods of Ontario for three weeks, believed the sun would lead her out and so followed it hopefully all day as it arced from east to west and thus, inevitably, found herself at night in almost the same place she had been that morning…In 2009, Jan Souman tracked volunteers using <span class="smallcaps-auto">GPS</span> monitors as they attempted to walk in a straight line through the Sahara Desert and Germany’s Bienwald forest. When the sun wasn’t visible, none of them managed it: Errors quickly accumulated, small deviations became large ones, and they ended up walking in circles. Souman concluded that with no external cues to help them, people will not travel more than around 100 meters from their starting position, regardless of how long they walk for.</p><p>…It is common for lost people to lose their head as well as their heading direction. Stories of people walking “trance-like” past search parties, or running off and having to be chased down and tackled, are part of search and rescue lore. Ed Cornell, the psychologist who studies lost person behavior, says it is very difficult to interview someone just after they’ve been found: “They are basically scrambled” and can remember little about what happened to them.</p>'
- - https://fqxi.org/community/forum/topic/3345
  - ! "Schrödinger’s Zombie: Adam Brown at the 6<sup>th</sup> FQXi Meeting"
  - George Musser (FQXi)
  - 2019-09-08
  - ''
  - ! '<p>Forget the cat: what if you put a computer into the Schrödinger thought experiment? You could make the computer both run and not run, at once, and that’s just a warm-up. You could, in fact, make it not run and nonetheless extract the answer to a computation. The computer will be sitting there waiting for someone to press “Run,” yet will have produced a result. It sounds impossible by definition, but that’s quantum physics for you. This idea of counterfactual computation is not just a thought experiment; there are computers in the physics labs of the world that have done this.</p><p>At the recently concluded <span class="smallcaps-auto">FQX</span>i meeting in Tuscany, Adam Brown of Stanford University grabbed hold of counterfactual computation and ran with it. What if the computer is set up to perform a brain simulation? You could ascertain what that brain would be thinking even if it is not, in fact, thinking. Whether a simulated brain is conscious is a contentious question, but suppose it is. Then you could create a mind that acts in the world, yet lacks first-person experience—a philosophical zombie. What is more, you can decide the circumstances under which the mind will be conscious or not; it might revel in happy sensations, but have no experience of sad ones. Brown’s talk put a new spin on old problems in the philosophy of mind and personal identity.</p><p>…Once you realize that you can interact without interacting, all manners of possibilities open up. Kwiat and his colleagues used the scheme to take microscope images of hairs, wires, and fibers without shining light on them (Physical Review A 58, 605–608, <a href="http://arxiv.org/abs/quant-ph/9803060">arXiv:quant-ph/9803060</a> (1998)). Vaidman suggested that biologists could take x-ray images of cells without causing radiation damage <a href="http://arxiv.org/abs/quant-ph/9610033">arXiv:quant-ph/9610033</a> (1996). Jian-Wei Pan of the University of Science and Technology of China and colleagues transmitted an image using hardly any photons. Roger Penrose of Oxford, in <em>Shadows of the Mind</em>, <a href="http://www.scientificamerican.com/article/nil-communication-how-to-send-a-message-without-sending-anything-at-all/">puckishly suggested</a> that Orthodox Jews could use the system on the Sabbath to turn on a light without touching its switch…In the most astounding proposal of all, Richard Jozsa of Cambridge proposed in 1998 that you could swap the bomb for a computer (<a href="http://arxiv.org/abs/quant-ph/9805086">arXiv:quant-ph/9805086</a> (1998)). The particle is its on/off switch. Just as you can detect a bomb without interacting with it, you can obtain the output of the computer without running it.</p><p>…Suppose you program a computer to simulate a conscious mind. By putting this computer into an interferometer, you can predict what the mind will do without running the simulation. “Using counterfactual cognition, you can simulate what somebody’s going to do—you can predict what they’re going to do—without simulating them,” Brown said…From the outside, the counterfactual mind seems identical to the original or simulated mind. Its output is the same. From the inside, though, the difference is profound. The counterfactual mind doesn’t have an inside. It is a philosophical zombie. In the taxonomy of zombies, it is even weirder than other breeds, because not only is it not conscious, it doesn’t even exist. It remains a potentiality inside the computer, awaiting an “on” signal that never came…But Brown—in what was the most remarkable part of an already remarkable talk—made a virtue of this defect. Suppose you are simulating a mind that is making some big life decision. Such decisions are hard; with all the variables involved, you can never be sure which choice will make you happy or sad. But you can arrange the counterfactual procedure to execute only the happy outcomes and leave the sad ones unimplemented. Thus you could guarantee that any minds you conjure up will be happy. Indeed, you could apply that insight to an entire virtual universe, so that only universes that maximize the happiness of their occupants (or some other desirable outcome) were brought into existence.</p><p>Brown speculated that such a scenario bears on the problem of evil in theology. Even an omniscient creator faces a problem of prediction. If it wants to create a universe where good outweighs evil, it must, in effect, run a simulation first. But such a simulation is a universe in its own right. It seems the creator cannot avoid creating creatures that suffer. But counterfactual creation allows God to create a universe where good is guaranteed to outweigh evil.</p>'
- - https://avikdas.com/2019/05/14/real-world-dynamic-programming-seam-carving.html
  - 'Real-world dynamic programming: seam carving'
  - Avik Das
  - 2019-05-14
  - ''
  - ! '<p>Dynamic programming has a reputation as a technique you learn in school, then only use to pass interviews at software companies. Indeed, most developers do not regularly work on problems where dynamic programming is needed. Ultimately, dynamic programming is a technique for efficiently solving problems that can be broken down into highly-repeated subproblems, and as a result, is useful in many situations.</p><p>In this article, I’ll work through an interesting real-world application of dynamic programming: <a href="https://en.wikipedia.org/wiki/Seam_carving">seam carving</a>. The problem and proposed technique is discussed in detail in the paper <a href="https://www.gwern.net/docs/technology/2007-avidan.pdf" title="Seam carving for content-aware image resizing">“Seam Carving for Content-Aware Image Resizing”</a> by Avidan and Shamir. (The paper is freely available if you search for the title.)</p><p>…What Avidan and Shamir show in their paper is a technique known as <em>seam carving</em>. The technique first identifies “low-energy” areas of the image that are less interesting, then finds the lowest-energy “seams” that weave through the image. In the case of reducing the width of an image, seam carving finds a vertical seam that stretches from the top of the image to the bottom, moving left or right by at most one pixel from one row to the next.</p><p>In the surfer image, the lowest-energy seam goes through the middle of the image, where the water is the calmest. This matches our intuition. By identifying the lowest-energy seam, then removing it, we reduce the width of the image by one pixel. Repeating this process again and again lets us reduce the width of the image substantially.</p><p><strong>Defining the energy of an image</strong>: The magic is in finding the lowest-energy seam. To do so, we first assign each pixel of the image an energy. Then, we apply dynamic programming to find the lowest-energy path through the image, an algorithm we’ll discuss in detail in the next section. First, let’s cover how energy values are assigned to the pixels of the image…To compute the energy of a single pixel, we look at the pixels to the left and right of that pixel. We find the squared component-wise distance between them, that is compute the squared difference between the red components, the squared difference between the green components and the squared difference between blue components, then add them up. We do the same for the pixels above and below the center pixel. Finally, we add up the horizontal and vertical distances…With the energy computed for each pixel, we can now look for the lowest-energy seam that goes from the top of the image down to the bottom.</p><p>…The problem with the greedy approach above is that, when deciding how to continue a seam, we don’t take into account the rest of the seam yet to come. We can’t look into the future, but we can capture everything we know up to this point in order to look at the past…Unlike the greedy approach, the above approach essentially tries all possible paths through the image. It’s just that, when trying all possible paths, the same subproblems are solved again and again, making this approach a perfect candidate for dynamic programming.</p>'
- - http://www.practicallyefficient.com/2017/10/13/from-boiling-lead-and-black-art.html
  - 'From boiling lead and black art: An essay on the history of mathematical typography'
  - Eddie Smith
  - 2017-10-13
  - ''
  - ! '<p>[History of typesetting mathematics: handset type using boiling lead for precise layout, then mechanized with the Monotype System, superior to typewriters or phototypesetting but too expensive, spurring Donald Knuth to create T<sub>e</sub>X to rescue the beautifully-printed math he loved and felt he &amp; every other mathematician deserved.]</p><p>…No matter how hard it’s ever been to create printed text, creating printed math has <em>always</em> been even harder. In pre-digital times, equation-laden texts were known as “penalty copy” because of the significant additional time and expense it took to set math notation for printing presses…I think it’s critically important for those of us that write math to have at least a basic awareness of the history of mathematical typesetting.</p><p>For me, knowing this history has had several practical benefits. It’s made me more grateful for the writing tools I have today—tools that I can use to simplify and improve the presentation of quantitative concepts to other actuaries. It’s also motivated me to continue to strive for elegance in the presentation of math—something I feel like my profession has largely neglected in the Microsoft Office era of the last twenty years.</p><p>Most importantly, it’s reminded me just how much of an art the presentation of <em>all</em> language has always been. Because pre-Internet printing required so many steps, so many different people, so much <em>physical</em> craftsmanship, and so much <em>waiting</em>, there were more artistic layers between the author’s original thoughts and the final arrangement of letters and figures on pages. More <em>thinking</em> occurred throughout the entire process.</p><p>To fully appreciate mathematical typography, we have to first appreciate the general history of typography, which is also a history of human civilization. No other art form has impacted our lives more than type.</p>'
- - /docs/sociology/1972-downs.pdf
  - ! "Up and down with ecology—the &#39;issue–attention cycle&#39;"
  - Anthony Downs
  - 1972-01-01
  - ''
  - ! '<p>American public attention rarely remains sharply focused upon any one domestic issue for very long—even if it involves a continuing problem of crucial importance to society. Instead, a systematic “issue-attention cycle” seems strongly to influence public attitudes and behavior concerning most key domestic problems. Each of these problems suddenly leaps into prominence, remains there for a short time, and then—though still largely unresolved—gradually fades from the center of public attention. A study of the way this cycle operates provides insights into how long public attention is likely to remain sufficiently focused upon any given issue to generate enough political pressure to cause effective change.</p><p>The shaping of American attitudes toward improving the quality of our environment provides both an example and a potential test of this “issue-attention cycle.” In the past few years, there has been a remarkably widespread upsurge of interest in the quality of our environment. This change in public attitudes has been much faster than any changes in the environment itself. What has caused this shift in public attention? Why did this issue suddenly assume so high a priority among our domestic concerns? And how long will the American public sustain high-intensity interest in ecological matters? I believe that answers to these questions analyzing the “issue-attention cycle.”</p><p><strong>The dynamics of the “issue-attention cycle”</strong></p><p>Public perception of most “crises” in American domestic life does not reflect changes in real conditions as much as it reflects the operation of a systematic cycle of heightening public interest and then increasing boredom with major issues. This “issue-attention cycle” is rooted both in the nature of certain domestic problems and in the way major communications media interact with the public. The cycle itself has five stages, which may vary in duration depending upon the particular issue involved, but which almost always occur in the following sequence:</p><ol type="1"><li>The pre-problem stage…</li><li>Alarmed discovery and euphoric enthusiasm…</li><li>Realizing the cost of significant progress…</li><li>Gradual decline of intense public interest…</li><li>The post-problem stage…</li></ol>'
- - /docs/science/1997-bowden-classicalcomputationcanbecounterfactual.html
  - "Classical Computation can be Counterfactual 9/2/96 V1.1 (or Can Schrodinger's Cat Collapse the Wavefunction?)"
  - Keith Bowden
  - 1997-03-15
  - ''
  - ! '<p>We show that at least some classes of classical computation can be carried out counterfactually in a particular sense. By counterfactually we mean that, given a set of quantum superpositions which include the possibility of the (classical) computation being carried out, then an observation can be made such that, even if the computation is not carried out, the result of the computation can be obtained. That is, on some observations, the output of a computer run can be obtained without the computer even being switched on and depends only on the existence of the computer and the possibility of the computation being carried out. As with all counterfactual measurements the proportion of “successful” trials (ie, those in which the computation does not occur, although the result of the computation is obtained) can be made arbitrarily large, but the time taken to get the output is the same as that which would be needed in order to carry out the computation. The interest is in circumstances where there is a reason not to carry out the computation (such as the likelihood that it would permanently change the computer) but we still wish to know the result.</p><p>Although the computation is classical, the overall setup including the measuring device constitutes a quantum computer, and our result is essentially a special case of Josza’s algorithm [Josza, 1995] which shows that all quantum computation [Deutsch, 1985] can be carried out counterfactually. However today’s technology is many years away from building a general quantum computer in Deutsch’s sense. Our paradigm demonstrates that by considering a quantum computer to consist of a combination of classical and nonclassical parts, and by restricting the quantum part to observation and the classical part to computation, we can build interesting devices now. We consider how we can widen the class of counterfactual classical computations and come across some unexpected results and interesting speculations.</p>'
- - https://www.sciencedirect.com/science/article/pii/S0091305720301118
  - "Differential effects of modafinil on performance of low-performing and high-performing individuals during total sleep deprivation"
  - J. Lynn Caldwell, Valarie M. Schroeder, Christina L. Kunkle, Henry G. Stephenson
  - 2020-09
  - 10.1016/j.pbb.2020.172968
  - ! '<p><strong>Highlights</strong>:</p><ul><li>Some people are more vulnerable to the effects of sleep loss than others.</li><li>Modafinil (200mg) administered to 22 men over 36 hours of continuous wakefulness.</li><li>Modafinil did not help the best performers compared to their performance with placebo.</li><li>The worst performers significantly improved after receiving modafinil compared to placebo.</li></ul><p><strong>Background</strong>: Individual responses to the effects of inadequate sleep have been well documented; some people are more vulnerable to the effects of sleep loss than others. Fatigue-vulnerable individuals generally require access to effective fatigue countermeasures; however, the question arises as to whether these fatigue-vulnerable individuals receive the same benefits shown in group efficacy data. The present study administered modafinil to individuals to determine its differential effects on performance of best and worst performers during sleep deprivation.</p><p><strong>Methods</strong>: A sample of 22 men, age 21–40 yrs., was tested on 2 separate occasions during which they were kept awake for 36 h. During one period they received 200 mg modafinil; during the other they received placebo. Participants were tested on a variety of tasks while rested and at 5-hr intervals across the continuous wakefulness period. Performance for each cognitive task and subjective measure of fatigue from the placebo period was used to group individuals into high (HP) or low performance (LP) groups to indicate fatigue vulnerability for each task.</p><p><strong>Results</strong>: Results indicated that on the <span class="smallcaps-auto">MTS</span> task, the HP group performed the same throughout the testing period, regardless of whether they received modafinil or not. However, the LP group significantly improved after receiving modafinil compared to placebo. Performance on the <span class="smallcaps-auto">PVT</span> showed the HP group had a small decrease in the number of lapses after receiving modafinil compared to placebo, whereas the LP group had a large decrease in lapses after receiving modafinil compared to placebo. Performance on the <span class="smallcaps-auto">RDM</span> showed no difference between groups, regardless of drug condition. Groups did not differ after receiving modafinil on subjective fatigue measured by the <span class="smallcaps-auto">POMS</span>.</p><p><strong>Conclusions</strong>: Depending on the task, HP individuals did not benefit substantially when administered modafinil compared to placebo. However, the LP individuals improved after receiving modafinil compared to placebo. [Keywords: Individual differences, Modafinil, Sleep deprivation]</p>'
- - /docs/biology/1983-gwynne.pdf
  - ! "Beetles On The Bottle: Male Buprestids Mistake Stubbies For Females (Coleoptera)"
  - D. T. Gwynne, D. C. F. Rentz
  - 1983-02-01
  - 10.1111/j.1440-6055.1983.tb01846.x
  - ! 'Male <em>Julodimorpha bakewelli White</em> were observed attempting to copulate with beer bottles. Colour and reflection of tubercles on the bottle glass are suggested as causes for attraction and release of sexual behaviour.'
- - https://journals.sagepub.com/doi/full/10.1177/1745691620919372
  - The Sisyphean Cycle of Technology Panics
  - Amy Orben
  - 2020-06-30
  - 10.1177/1745691620919372
  - ! '<p>Widespread concerns about new technologies—whether they be novels, radios, or smartphones—are repeatedly found throughout history. Although tales of past panics are often met with amusement today, current concerns routinely engender large research investments and policy debate. What we learn from studying past technological panics, however, is that these investments are often inefficient and ineffective. What causes technological panics to repeatedly reincarnate? And why does research routinely fail to address them? To answer such questions, I examined the network of political, population, and academic factors driving the <em>Sisyphean cycle of technology panics</em>. In this cycle, psychologists are encouraged to spend time investigating new technologies, and how they affect children and young people, to calm a worried population. Their endeavor, however, is rendered ineffective because of the lack of a theoretical baseline; researchers cannot build on what has been learned researching past technologies of concern. Thus, academic study seemingly restarts for each new technology of interest, which slows down the policy interventions necessary to ensure technologies are benefiting society. In this article, I highlight how the Sisyphean cycle of technology panics stymies psychology’s positive role in steering technological change and the pervasive need for improved research and policy approaches to new technologies. [Keywords: digital-technology use, social media, screen time, well-being, adolescents]</p>'
- - https://environhealthprevmed.biomedcentral.com/articles/10.1186/s12199-020-00865-6
  - Association between lithium in tap water and suicide mortality rates in Miyazaki Prefecture
  - Naomi Kozaka, Shouhei Takeuchi, Nobuyoshi Ishii, Takeshi Terao, Yoshiki Kuroda
  - 2020-06-27
  - 10.1186/s12199-020-00865-6
  - ! '<p><em>Background</em>: Most studies have reported that suicide mortality rates are negatively associated with lithium levels in tap water; however, a few studies showed either no association or a positive association. Thus, the association between suicide mortality and lithium levels in tap water remains controversial. To clarify the association, our study evaluated the association between lithium levels in tap water and suicide mortality rates in Miyazaki Prefecture of Japan, after adjusting for confounding factors.</p><p><em>Methods</em>: We measured lithium levels in tap water across the 26 municipalities of Miyazaki Prefecture in Japan. We examined the standardized mortality ratio (<span class="smallcaps-auto">SMR</span>) for suicide in each municipality and used the data as the average suicide <span class="smallcaps-auto">SMR</span>s over 5 years (2009–2013). Weighted least-squares regression analysis, adjusted for the size of each municipality’s population, was used to investigate the association between lithium levels in tap water and suicide <span class="smallcaps-auto">SMR</span>s. In addition to a crude model, in an adjusted model, potential confounding factors (proportion of elderly people, proportion of one-person households, annual marriage rate, annual mean income, unemployment rate, the density of medical doctors per 100,000 people, annual total rainfall, and proportion of people with a college education or higher) were added as covariates.</p><p><em>Results</em>: We showed that male and female suicide <span class="smallcaps-auto">SMR</span>s were not associated with lithium levels in tap water in Miyazaki Prefecture. After adjusting for confounders, male suicide <span class="smallcaps-auto">SMR</span>s were significantly and positively associated with the proportion of elderly people in the population and annual total rainfall, and female suicide <span class="smallcaps-auto">SMR</span>s were associated with the proportion of elderly people in the population.</p><p><em>Conclusions</em>: No association between lithium levels in tap water and suicide mortality rates was found in Miyazaki Prefecture.</p>'
- - /docs/psychology/2016-jussim.pdf
  - ! "Stereotype accuracy: One of the largest and most replicable effects in all of social psychology"
  - Lee Jussim, Jarret T. Crawford, Stephanie M. Anglin, John R. Chambers, Sean T. Stevens, Florette Cohen
  - '2016'
  - ''
  - ! '<p>Stereotype accuracy is one of the largest and most replicable effects in all of social psychology. It took social psychology nearly a century to recognize that not only had it been <em>declaring</em> stereotypes to be inaccurate on the basis of little data, but once the data started to come in, to accept that this data often (though not always) demonstrated moderate to high stereotype accuracy. This resistance to the data has constituted a significant impediment to understanding the existence, causes, and consequences of <em>both</em> stereotype accuracy and inaccuracy.</p><p>…This chapter discusses stereotype accuracy as one of the largest and most replicable effects in all of social psychology. This chapter is divided into three major sections. The first, “History of Obstacles to Social Psychology Accepting Its Own Data on Stereotype Accuracy”, reviews some of the obstacles social psychology has faced with respect to accepting that stereotype (in)accuracy is an empirical question, and that the empirical data do not justify assumptions, definitions, or declarations that stereotypes are inaccurate. The second, “The Empirical Assessment of Stereotype (In)Accuracy”, summarizes what is now an impressive body of literature assessing the (in)accuracy of racial, gender, age, national, ethnic, political, and other stereotypes. The third, “Stereotype (In)Accuracy: Knowns, Unknowns, and Emerging Controversies”, summarizes broad and emerging patterns in that body of literature, highlighting unresolved controversies, and identifying important directions for future research.</p>'
- - /docs/psychology/2020-ok.pdf
  - ! "Signaling virtuous victimhood as indicators of Dark Triad personalities"
  - Ekin Ok, Yi Qian, Brendan Strejcek, Karl Aquino
  - 2020-07-01
  - 10.1037/pspp0000329
  - ! '<p>We investigate the consequences and predictors of emitting signals of victimhood and virtue. In our first three studies, we show that the virtuous victim signal can facilitate nonreciprocal resource transfer from others to the signaler. Next, we develop and validate a victim signaling scale that we combine with an established measure of virtue signaling to operationalize the virtuous victim construct. We show that individuals with Dark Triad traits—Machiavellianism, Narcissism, Psychopathy—more frequently signal virtuous victimhood, controlling for demographic and socioeconomic variables that are commonly associated with victimization in Western societies. In Study 5, we show that a specific dimension of Machiavellianism—amoral manipulation—and a form of narcissism that reflects a person’s belief in their superior prosociality predict more frequent virtuous victim signaling. Studies 3, 4, and 6 test our hypothesis that the frequency of emitting virtuous victim signal predicts a person’s willingness to engage in and endorse ethically questionable behaviors, such as lying to earn a bonus, intention to purchase counterfeit products and moral judgments of counterfeiters, and making exaggerated claims about being harmed in an organizational context. [Keywords: dark triad, unethical behavior, victim-signaling, victimization, virtue-signaling]</p>'
- - https://www.aclweb.org/anthology/2020.acl-main.463.pdf
  - "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data"
  - Emily M. Bender, Alexander Koller
  - 2020-07
  - ''
  - ! '<p>The success of the large neural language models on many <span class="smallcaps-auto">NLP</span> tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as “understanding” language or capturing “meaning.” In this position paper, we argue that a system trained only on form has <em>a priori</em> no way to learn meaning. In keeping with the <span class="smallcaps-auto">ACL</span> 2020 theme of “Taking Stock of Where We’ve Been and Where We’re Going,” we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.</p><p>…In this paper, we have argued that in contrast to some current hype, meaning cannot be learned from form alone. This means that even large language models such as <span class="smallcaps-auto">BERT</span> do not learn “meaning”; they learn some reflection of meaning into the linguistic form which is very useful in applications. We have offered some thoughts on how to maintain a healthy, but not exaggerated, optimism with respect to research that builds upon these LMs. In particular, this paper can be seen as a call for precise language use when talking about the success of current models and for humility in dealing with natural language. With this we hope to encourage a top-down perspective on our field which we think will help us select the right hill to climb toward human-analogous <span class="smallcaps-auto">NLU</span>.</p>'
- - /docs/iq/smpy/2020-bernstein.pdf
  - ! "Academic Acceleration in Gifted Youth and Fruitless Concerns Regarding Psychological Well–Being: A 35–Year Longitudinal Study"
  - Brian O. Bernstein, David Lubinski, Camilla P. Benbow
  - 2020-07-02
  - 10.1037/edu0000500
  - ! '<p>Academic acceleration of intellectually precocious youth is believed to harm overall psychological well-being even though short-term studies do not support this belief. Here we examine the long-term effects. Study 1 involves three cohorts identified before age 13, then longitudinally tracked for over 35 years: Cohort 1 gifted (top 1% in ability, identified 1972–1974, <em>n</em>=1,020), Cohort 2 highly gifted (top 0.5% in ability, identified 1976–1979, <em>n</em>=396), and Cohort 3 profoundly gifted (top 0.01% in ability, identified 1980–1983, <em>n</em>=220). Two forms of educational acceleration were examined: (a) age at high school graduation and (b) quantity of advanced learning opportunities pursued prior to high school graduation. Participants were evaluated at age 50 on several well-known indicators of psychological well-being. Amount of acceleration did not covary with psychological well-being. Study 2, a constructive replication of Study 1, used a different high-potential sample—elite science, technology, engineering, and mathematics graduate students (<em>n</em>=478) identified in 1992. Their educational histories were assessed at age 25 and they were followed up at age 50 using the same psychological assessments. Again, the amount of educational acceleration did not covary with psychological well-being. Further, the psychological well-being of participants in both studies was above the average of national probability samples. Concerns about long-term social/emotional effects of acceleration for high-potential students appear to be unwarranted, as has been demonstrated for short-term effects. [Keywords: gifted, acceleration, replication, appropriate developmental placement, psychological well-being]</p><p><em>Impact Statement</em>: Best practices suggest that acceleration in one of its many forms is educationally efficacious for meeting the advanced learning needs of intellectually precocious youth. Yet, parents, teachers, academic administrators, and psychological theorists worry that this practice engenders negative psychological effects. A three-cohort study of intellectually precocious youth followed for 35 years suggests that there is no cause for concern. These findings were replicated on a sample of elite <span class="smallcaps-auto">STEM</span> graduates whose educational histories were assessed at age 25 and tracked for 25 years.</p>'
- - /docs/iq/2020-giofre.pdf
  - ! "A population level analysis of the gender gap in mathematics_ Results on over 13 million children using the INVALSI dataset"
  - D. Giofrè, C. Cornoldi, A. Martini, E. Toffalini
  - 2020-07-01
  - 10.1016/j.intell.2020.101467
  - ! '<p><strong>Highlights</strong>:</p><ul><li>Gender differences in mathematics are largely explained by a regional gradient in Italy.</li><li>Gender differences in reading are not influenced by a regional gradient and are stable across Italy.</li><li>A number of factors, could influence the gender gap in mathematics.</li></ul><p><strong>Abstract</strong>: Whether males outperform females in mathematics is still debated. Such a gender gap varies across countries, but the determinants of the differences are unclear and could be produced by heterogeneity in the instructional systems or cultures and may vary across school grades. To clarify this issue, we took advantage of the <span class="smallcaps-auto">INVALSI</span> dataset, that offered over 13 million observations covering one single instructional system (i.e., the Italian system) in grades 2, 5, and 8, in the period 2010–2018. Results showed that males outperformed females in mathematics (and vice versa in reading), with gaps widening from the 2<sup>nd</sup> through to the 8<sup>th</sup> grade. The gender gap in mathematics was larger in the richer northern Italian regions (also characterized by greater gender equality) than in southern regions. This was not explained by average performance or fully accounted for by economic factors. No such north-south difference of the gap emerged in reading. Results are discussed with reference to the literature showing that the gender gap varies across world regions. [Keywords: Gender differences, Mathematics, Reading, Achievement, Sociocultural factors]</p>'
- - /docs/technology/2020-beerling.pdf
  - ! "Potential for large-scale CO2 removal via enhanced rock weathering with croplands"
  - David J. Beerling, Euripides P. Kantzas, Mark R. Lomas, Peter Wade, Rafael M. Eufrasio, Phil Renforth, Binoy Sarkar, M. Grace Andrews, Rachael H. James, Christopher R. Pearce, Jean-Francois Mercure, Hector Pollitt, Philip B. Holden, Neil R. Edwards, Madhu Khanna, Lenny Koh, Shaun Quegan, Nick F. Pidgeon, Ivan A. Janssens, James Hansen, Steven A. Banwart
  - 2020-07-08
  - 10.1038/s41586-020-2448-9
  - ! '<p><a href="https://en.wikipedia.org/wiki/Enhanced_weathering">Enhanced</a> <a href="https://en.wikipedia.org/wiki/Carbonate%E2%80%93silicate_cycle">silicate rock</a> <a href="https://en.wikipedia.org/wiki/Weathering#Chemical_weathering">weathering</a> (<span class="smallcaps-auto">ERW</span>), deployable with croplands, has potential use for atmospheric carbon dioxide (CO<sub>2</sub>) removal (<span class="smallcaps-auto">CDR</span>), which is now necessary to mitigate anthropogenic climate change<sup>1</sup>. <span class="smallcaps-auto">ERW</span> also has possible co-benefits for improved food and soil security, and reduced ocean acidification<sup>2,3,4</sup>. Here we use an integrated performance modelling approach to make an initial techno-economic assessment for 2050, quantifying how <span class="smallcaps-auto">CDR</span> potential and costs vary among nations in relation to business-as-usual energy policies and policies consistent with limiting future warming to 2° Celsius<sup>5</sup>. China, India, the <span class="smallcaps-auto">USA</span> and Brazil have great potential to help achieve average global <span class="smallcaps-auto">CDR</span> goals of 0.5 to 2 gigatonnes of carbon dioxide (CO<sub>2</sub>) per year with extraction costs of approximately US$80–180 per tonne of CO<sub>2</sub>. These goals and costs are robust, regardless of future energy policies. Deployment within existing croplands offers opportunities to align agriculture and climate policy. However, success will depend upon overcoming political and social inertia to develop regulatory and incentive frameworks. We discuss the challenges and opportunities of <span class="smallcaps-auto">ERW</span> deployment, including the potential for excess industrial silicate materials (<a href="https://en.wikipedia.org/wiki/Basalt">basalt</a> mine overburden, concrete, and iron and steel slag) to obviate the need for new mining, as well as uncertainties in soil weathering rates and land–ocean transfer of weathered products.</p>'
- - /docs/genetics/editing/2020-mok.pdf
  - ! "A bacterial cytidine deaminase toxin enables CRISPR–free mitochondrial base editing"
  - Beverly Y. Mok, Marcos H. de Moraes, Jun Zeng, Dustin E. Bosch, Anna V. Kotrys, Aditya Raguram, FoSheng Hsu, Matthew C. Radey, S. Brook Peterson, Vamsi K. Mootha, Joseph D. Mougous, David R. Liu
  - 2020-07-08
  - 10.1038/s41586-020-2477-4
  - ! '<p>Bacterial toxins represent a vast reservoir of biochemical diversity that can be repurposed for biomedical applications. Such proteins include a group of predicted interbacterial toxins of the deaminase superfamily, members of which have found application in gene-editing techniques<sup>1,2</sup>. Because previously described cytidine deaminases operate on single-stranded nucleic acids<sup>3</sup>, their use in base editing requires the unwinding of double-stranded <span class="smallcaps-auto">DNA</span> (ds<span class="smallcaps-auto">DNA</span>)—for example by a <span class="smallcaps-auto">CRISPR</span>–Cas9 system. Base editing within mitochondrial <span class="smallcaps-auto">DNA</span> (mt<span class="smallcaps-auto">DNA</span>), however, has thus far been hindered by challenges associated with the delivery of guide <span class="smallcaps-auto">RNA</span> into the mitochondria<sup>4</sup>. As a consequence, manipulation of mt<span class="smallcaps-auto">DNA</span> to date has been limited to the targeted destruction of the mitochondrial genome by designer nucleases<sup>9,10</sup>.Here we describe an interbacterial toxin, which we name DddA, that catalyses the deamination of cytidines within ds<span class="smallcaps-auto">DNA</span>. We engineered split-DddA halves that are non-toxic and inactive until brought together on target <span class="smallcaps-auto">DNA</span> by adjacently bound programmable <span class="smallcaps-auto">DNA</span>-binding proteins. Fusions of the split-DddA halves, transcription activator-like effector array proteins, and a uracil glycosylase inhibitor resulted in <span class="smallcaps-auto">RNA</span>-free DddA-derived cytosine base editors (Dd<span class="smallcaps-auto">CBE</span>s) that catalyse C•G-to-T•A conversions in human mt<span class="smallcaps-auto">DNA</span> with high target specificity and product purity. We used Dd<span class="smallcaps-auto">CBE</span>s to model a disease-associated mt<span class="smallcaps-auto">DNA</span> mutation in human cells, resulting in changes in respiration rates and oxidative phosphorylation. <span class="smallcaps-auto">CRISPR</span>-free Dd<span class="smallcaps-auto">CBE</span>s enable the precise manipulation of mt<span class="smallcaps-auto">DNA</span>, rather than the elimination of mt<span class="smallcaps-auto">DNA</span> copies that results from its cleavage by targeted nucleases, with broad implications for the study and potential treatment of mitochondrial disorders.</p>'
- - /docs/genetics/correlation/2020-rosenstrom.pdf
  - ! "Specific Antisocial and Borderline Personality Disorder Criteria and General Substance Use: A Twin Study"
  - Tom Rosenström, Fartein Ask Torvik, Eivind Ystrom, Steven H. Aggen, Nathan A. Gillespie, Robert F. Krueger, Nikolai Olavi Czajkowski, Kenneth S. Kendler, Ted Reichborn-Kjennerud
  - 2020-06-25
  - 10.1037/per0000404
  - ! '<p>Antisocial (<span class="smallcaps-auto">ASPD</span>) and borderline (<span class="smallcaps-auto">BPD</span>) personality disorders (PDs) are associated with increased risk for substance use. They are “specific” risk factors among PDs in that they withstand adjusting for the other PDs, whereas the reverse does not hold. Specificity is a classic sign of causation. This empirical work addresses 3 further problems that can undermine causal inferences in personality and substance-use research: hierarchical nature of etiologic factors in psychiatry, imperfectly operationalized PD criteria, and possible genetic or environmental confounding, as seen in lack of “etiologic continuity.” We used exploratory structural equation bifactor modeling and biometric models to mitigate these problems. The participants were Norwegian adult twins of ages 19–36 years (<em>n</em>=2,801). Criteria for <em>Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (<span class="smallcaps-auto">DSM</span>–5)</em>, PDs were assessed using a structured interview. General substance-use risk was indicated by World Health Organization Composite International Diagnostic Interviewed alcohol use disorder and illicit drug use, and by self-reported regular smoking. A general risk factor for all criteria of both <span class="smallcaps-auto">ASPD</span> and <span class="smallcaps-auto">BPD</span> was the strongest individual correlate of general substance use and showed etiologic continuity, though just 3 specific PD criteria could predict substance use to the same extent. The findings indicate that a broad latent factor for both <span class="smallcaps-auto">ASPD</span> and <span class="smallcaps-auto">BPD</span> may be a specific and a genetically and environmentally unconfounded risk factor for substance use. Substance-use treatment research might benefit from attending to transdiagnostic models of <span class="smallcaps-auto">ASPD</span>, <span class="smallcaps-auto">BPD</span>, and related behavioral disinhibition.</p>'
- - https://www.sciencedirect.com/science/article/pii/S0092867418307141
  - Common Disease Is More Complex Than Implied by the Core Gene Omnigenic Model
  - Naomi R. Wray, Cisca Wijmenga, Patrick F. Sullivan, Jian Yang, Peter M. Visscher
  - 2018-06-14
  - 10.1016/j.cell.2018.05.051
  - ! '<p>The evidence that most adult-onset common diseases have a polygenic genetic architecture fully consistent with robust biological systems supported by multiple back-up mechanisms is now overwhelming. In this context, we consider the recent “omnigenic” or “core genes” model. A key assumption of the model is that there is a relatively small number of core genes relevant to any disease. While intuitively appealing, this model may underestimate the biological complexity of common disease, and therefore, the goal to discover core genes should not guide experimental design. We consider other implications of polygenicity, concluding that a focus on patient stratification is needed to achieve the goals of precision medicine.</p><p>…In conclusion, <a href="https://www.sciencedirect.com/science/article/pii/S0092867417306293" title="An Expanded View of Complex Traits: From Polygenic to Omnigenic">Boyle et al 2017</a> are congratulated for their synthesis of current data and for articulation of a biological framework that has prompted extensive constructive discussion. We agree that understanding the cell-specific role of disease-associated variants is a crucial step for advancing knowledge of common disease. However, whereas those authors extrapolate results of analyses of <span class="smallcaps-auto">GWAS</span> summary statistics to make fundamental assumptions that rare variants of large effect in a small number of genes play the most critical roles in clinical conditions that attract a common disease diagnosis, we believe it would be a major disservice to the field to allow these assumptions to guide the next steps of research. To assume that a limited number of core genes are key to our understanding of common disease may underestimate the true biological complexity, which is better represented by systems genetics and network approaches (Baliga et al., 2017, Parikshak et al., 2015). While Boyle et al. advocate for <span class="smallcaps-auto">WES</span> studies, they did not discuss the sample sizes needed for such discovery. We believe that in the short term, large samples recorded for key measures of phenotypic heterogeneity and genome-wide <span class="smallcaps-auto">SNP</span> data are the best next steps for research using human <span class="smallcaps-auto">DNA</span> samples in moving forward our understanding of complex genetic diseases. Large numbers of samples, biobanked for cellular reprogramming, will position us well for the next generation of sequencing and other new technologies. High-throughput phenotyping to characterize cellular properties associated with disease-associated genomes may be the key to penetrate the polygenic complexity of common disease and provide the data needed for patient stratification, as well as to progress toward the goal of new drug treatments. These are research paths that need to advance in parallel to advance the promise of precision medicine.</p>'
- - /docs/iq/2017-wongupparaj.pdf
  - ! "The Flynn effect for verbal and visuospatial short–term and working memory: A cross–temporal meta–analysis"
  - Peera Wongupparaj, Rangsirat Wongupparaj, Veena Kumari, Robin G. Morris
  - 2017-09
  - 10.1016/j.intell.2017.07.006
  - ! '<p><em>Highlights</em>:</p><ul><li>Analysis of Digit span and Corsi-block span data from 1754 independent samples (<em>n</em>=139,677), covering a period of 43 years</li><li>Verbal and visuospatial short-term memory (<span class="smallcaps-auto">STM</span>) were positively correlated with year of publication.</li><li>Verbal and visuospatial working memory (WM) were negatively correlated with year of publication.</li></ul><p><em>Abstract</em>: The Flynn effect has been investigated extensively for IQ, but few attempts have been made to study it in relation to working memory (WM). Based on the findings from a cross-temporal meta-analysis using 1754 independent samples (<em>n</em>=139,677), the Flynn effect was observed across a 43-year period, with changes here expressed in terms of correlations (coefficients) between year of publication and mean memory test scores. Specifically, the Flynn effect was found for forward digit span (<em>r</em>=0.12, <em>p</em>&lt;0.01) and forward Corsi block span (<em>r</em>=0.10, <em>p</em>&lt;0.01). Moreover, an anti-Flynn effect was found for backward digit span (<em>r</em>=−0.06, <em>p</em>&lt;0.01) and for backward Corsi block span (<em>r</em>=−0.17, <em>p</em>&lt;0.01). Overall, the results support co-occurrence theories that predict simultaneous secular gains in specialized abilities and declines in g. The causes of the differential trajectories are further discussed. [Keywords: Flynn effect, Short-term memory, Working memory, Forward and backward digit span, Forward and backward Corsi block span, Cross-temporal meta-analysis]</p>'
- - /docs/nicotine/1992-west.pdf
  - ! "Nicotine addiction: a re–analysis of the arguments"
  - Robert West
  - 1992-09-01
  - 10.1007/BF02247413
  - ! '<p>This paper evaluates the arguments put forward by Robinson and Pritchard (R&amp;P, this volume) that the conclusions of the US Surgeon General (<span class="smallcaps-auto">USDHHS</span> 1988) that nicotine is addictive were ill founded. R&amp;P state that nicotine does not cause intoxication, that many smokers do not exhibit compulsive use, that nicotine is not a euphoriant, that nicotine is a weak reinforcer in other species, that non-pharmacological aspects of smoking are important and that negative affect control accounts for more of the variance in questionnaire measures of smoking motives than does habit. This paper points out that intoxication and a euphoriant effect are not normally considered to be central to dependence potential, that no addictive drug results in compulsive use in all users in all situations, that animals do reliably self-administer nicotine, that evidence concerning the apparent importance of non-pharmacological components of smoking do not diminish the importance of pharmacological aspects and that “variance accounted for” of self-report measures of smoking motivation do not bear on the issue of the importance of those motives. The paper concludes with a summary of the essence of the argument that cigarettes are addictive and that nicotine is the primary focus of that addiction.</p>'
- - https://en.wikisource.org/wiki/Of_a_Happy_Life/Book_III
  - "Of a Happy Life: Book 3"
  - "Seneca (Bohn's Classical Library Edition of L. Annaeus Seneca, Minor Dialogs Together with the Dialog 'On Clemency')"
  - '1990'
  - ''
  - ! '<p>Let us seek for some blessing, which does not merely look fine, but is sound and good throughout alike, and most beautiful in the parts which are least seen…I follow nature, which is a point upon which every one of the Stoic philosophers are agreed: true wisdom consists in not departing from nature and in moulding our conduct according to her laws and model.</p><p>A happy life, therefore, is one which is in accordance with its own nature, and cannot be brought about unless in the first place the mind be sound and remain so without interruption, and next, be bold and vigorous, enduring all things with most admirable courage, suited to the times in which it lives, careful of the body and its appurtenances, yet not troublesomely careful. It must also set due value upon all the things which adorn our lives, without over-estimating any one of them, and must be able to enjoy the bounty of Fortune without becoming her slave.</p><p>You understand without my mentioning it that an unbroken calm and freedom ensue, when we have driven away all those things which either excite us or alarm us: for in the place of sensual pleasures and those slight perishable matters which are connected with the basest crimes, we thus gain an immense, unchangeable, equable joy, together with peace, calmness and greatness of mind, and kindliness: for all savageness is a sign of weakness.</p>'
- - http://www.catb.org/jargon/html/H/holy-wars.html
  - "The Jargon File (version 4.4.7): H: holy wars"
  - Eric S. Raymond
  - 2003-12-29
  - ''
  - ! '<b>holy wars</b>: <span class="grammar" data-xmlns="http://www.w3.org/1999/xhtml">n.</span></dt></dt><dd><p>[from <a href="http://www.catb.org/jargon/html/U/Usenet.html"><i class="glossterm">Usenet</i></a>, but may predate it; common] <span class="grammar">n.</span> <a href="http://www.catb.org/jargon/html/F/flame-war.html"><i class="glossterm">flame war</i></a>s over <a href="http://www.catb.org/jargon/html/R/religious-issues.html"><i class="glossterm">religious issues</i></a>. The paper by Danny Cohen that popularized the terms <a href="http://www.catb.org/jargon/html/B/big-endian.html"><i class="glossterm">big-endian</i></a> and <a href="http://www.catb.org/jargon/html/L/little-endian.html"><i class="glossterm">little-endian</i></a> in connection with the <span class="smallcaps-auto">LSB</span>-first/<span class="smallcaps-auto">MSB</span>-first controversy was entitled <i class="citetitle">On Holy Wars and a Plea for Peace</i>.</p><p>Great holy wars of the past have included <a href="http://www.catb.org/jargon/html/I/[ITS]{.smallcaps-auto}.html"><i class="glossterm"><span class="smallcaps-auto">ITS</span></i></a> vs.: <a href="http://www.catb.org/jargon/html/U/Unix.html"><i class="glossterm">Unix</i></a>, <a href="http://www.catb.org/jargon/html/U/Unix.html"><i class="glossterm">Unix</i></a> vs.: <a href="http://www.catb.org/jargon/html/V/[VMS]{.smallcaps-auto}.html"><i class="glossterm"><span class="smallcaps-auto">VMS</span></i></a>, <a href="http://www.catb.org/jargon/html/B/[BSD]{.smallcaps-auto}.html"><i class="glossterm"><span class="smallcaps-auto">BSD</span></i></a> Unix vs.: System V, <a href="http://www.catb.org/jargon/html/C/C.html"><i class="glossterm">C</i></a> vs.: <a href="http://www.catb.org/jargon/html/P/Pascal.html"><i class="glossterm">Pascal</i></a>, <a href="http://www.catb.org/jargon/html/C/C.html"><i class="glossterm">C</i></a> vs.: <span class="smallcaps-auto">FORTRAN</span>, etc. In the year 2003, popular favorites of the day are <span class="smallcaps-auto">KDE</span> vs, <span class="smallcaps-auto">GNOME</span>, vim vs. elvis, Linux vs. [Free|Net|Open][BSD]{.smallcaps-auto}. Hardy perennials include <a href="http://www.catb.org/jargon/html/E/[EMACS]{.smallcaps-auto}.html"><i class="glossterm"><span class="smallcaps-auto">EMACS</span></i></a> vs.: <a href="http://www.catb.org/jargon/html/V/vi.html"><i class="glossterm">vi</i></a>, my personal computer vs.: everyone else’s personal computer, ad nauseam. The characteristic that distinguishes holy wars from normal technical disputes is that in a holy war most of the participants spend their time trying to pass off personal value choices and cultural attachments as objective technical evaluations. This happens precisely because in a true holy war, the actual substantive differences between the sides are relatively minor. See also <a href="http://www.catb.org/jargon/html/T/theology.html"><i class="glossterm">theology</i></a>.</p>'
- - http://www.paulgraham.com/identity.html
  - "Keep Your Identity Small"
  - Paul Graham
  - 2009-02
  - ''
  - ! '<p>As a rule, any mention of religion on an online forum degenerates into a religious argument. Why? Why does this happen with religion and not with Javascript or baking or other topics people talk about on forums?</p><p>…I think what religion and politics have in common is that they become part of people’s identity, and people can never have a fruitful argument about something that’s part of their identity. By definition they’re partisan.</p><p>Which topics engage people’s identity depends on the people, not the topic. For example, a discussion about a battle that included citizens of one or more of the countries involved would probably degenerate into a political argument. But a discussion today about a battle that took place in the Bronze Age probably wouldn’t. No one would know what side to be on. So it’s not politics that’s the source of the trouble, but identity. When people say a discussion has degenerated into a religious war, what they really mean is that it has started to be driven mostly by people’s identities. [1: When that happens, it tends to happen fast, like a core going critical. The threshold for participating goes down to zero, which brings in more people. And they tend to say incendiary things, which draw more and angrier counterarguments.]</p><p>…More generally, you can have a fruitful discussion about a topic only if it doesn’t engage the identities of any of the participants. What makes politics and religion such minefields is that they engage so many people’s identities. But you could in principle have a useful conversation about them with some people. And there are other topics that might seem harmless, like the relative merits of Ford and Chevy pickup trucks, that you couldn’t safely talk about with others.</p><p>Most people reading this will already be fairly tolerant. But there is a step beyond thinking of yourself as <em>x</em> but tolerating <em>y</em>: not even to consider yourself an <em>x</em>. The more labels you have for yourself, the dumber they make you.</p>'
- - https://lucumr.pocoo.org/2019/12/28/open-source-migrates/
  - Open Source Migrates With Emotional Distress
  - Armin Ronacher
  - 2019-12-28
  - ''
  - ! '<p>“Legacy code is bad and if you keep using it, it’s really your own fault.” There are many variations of the same thing floating around in Open Source communities and it always comes down to the same thing: at one point something is being declared old and it has to be replaced by something newer which is better. That better typically has some really good arguments on its side: we learned from our mistakes, it was wrong to begin with or something along the lines of it being impure or that it propagated bad ideas…Some communities as a whole for instance are suffering from this a whole lot. Every few years a library or the entire ecosystem of that community is thrown away and replaced by something new and support for the old one ends abruptly and arbitrarily. This has happened to the packaging ecosystem, the interpreter itself, modules in the standard library etc.</p><p>…This largely works because the way open source communities are managing migrations is by cheating and the currency of payment is emotional distress. Since typically money is not involved (at least not in the sense that a user would pay for the product directly) there is no obvious monetary impact of people not migrating. So if you cause friction in the migration process it won’t hurt you as a library maintainer. If anything the churn of some users might actually be better in the long run because the ones that don’t migrate are likely also some of the ones that are the most annoying in the issue tracker…Since the migration causes a lot of emotional distress, the cheat is carried happily by the entire community…I have been a part of the Python 3 migration and I can tell you that it sucked out all my enjoyment of being a part of that community. No matter on which side you were during that migration I heard very little positive about that experience.</p><p>…A big reason why this all happens in the first place is because as an Open Source maintainer the standard response which works against almost all forms of criticism is “I’m not paid for this and I no longer want to maintain the old version of X”. And in fact this is a pretty good argument because it’s both true, and very few projects actually are large enough that a fork by some third party would actually survive. Python for instance currently has a fork of 2.7 called Tauthon which got very little traction.</p><p>There are projects which are clearly managing such forceful transitions, but I think what is often forgotten is that with that transition many people love the community who do not want to participate in it or can’t…I honestly believe a lot of Open Source projects would have an easier time existing if they would acknowledge that these painful migrations are painful for everybody involved.</p>'
- - https://tpdne.arfa.dev/
  - "This Pony Does Not Exist"
  - Arfafax
  - 2020-07
  - ''
  - ! '<p>“This Pony Does Not Exist” (<span class="smallcaps-auto">TPDNE</span>) is the followup to <a href="https://www.thisfursonadoesnotexist.com/">“This Fursona Does Not Exist”</a>, also by Arfafax. He scraped the Derpibooru <em>My Little Pony: Friendship is Magic</em> image booru, hand-annotated images and trained a pony face <a href="https://github.com/AlexeyAB/darknet"><span class="smallcaps-auto">YOLO</span>v3</a> cropper to <a href="https://github.com/arfafax/MLP-Face-Dataset" title="MLP Faces Dataset: A dataset of SFW cropped MLP faces from Derpibooru">create a pony face crop dataset</a>, and trained the <span class="smallcaps-auto">TFDNE</span> <a href="/Faces">Style<span class="smallcaps-auto">GAN</span> 2 model</a> to convergence on TensorFork <span class="smallcaps-auto">TPU</span> pods, with an upgrade to 1024px resolution via transfer learning/model surgery. The interface reuses Said Achmiz’s <a href="https://www.obormot.net/demos/these-waifus-do-not-exist-alt">These Waifus Do Not Exist</a> grid UI.</p><figure><img src="/images/gan/2020-07-09-arfafax-tpdne-10ponies.jpg" alt="A 5×2 grid of pastel-colored ponies in the style of the cartoon series _My Little Pony: Friendship is Magic_, as rendered by a deep learning StyleGAN 2 AI model, from the website This Pony Does Not Exist (TPDNE)." /><figcaption>10 random pony samples from <span class="smallcaps-auto">TPDNE</span></figcaption></figure>'
- - /docs/iq/smpy/1980-albert.pdf
  - ! "Exceptionally Gifted Boys and Their Parents"
  - Robert S. Albert
  - 1980-10-01
  - 10.1177/001698628002400409
  - ! '<p>In an effort to explore some of the possible early-experiential and family variables involved in the achievement of eminence we have developed a model of cognitive and personality development and have undertaken a longitudinal study of two distinct groups of exceptionally gifted boys and their families. In this report, early similarities and differences between two groups of exceptionally gifted boys and their families will be explored. <em>Methodology</em>: This is a longitudinal study of two samples of healthy, exceptionally gifted boys and their families. One group consisted of 26 of the highest scorers in the 1976 Math Talent Search conducted by Julian Stanley (1974, 1977); the second group of 26 boys living in southern California were selected only on the basis of IQ’s of 150 or higher.</p><p>…Factors included for study were parents’ and grand-parents’ educational attainment, parents’ and subjects’ birth-order, subjects’ and parents’ creative potential, and subjects’ cognitive giftedness.</p><ul><li>Both samples were well-educated and had attained significantly more formal education than the national norms.</li><li>The birth-orders of the two samples are what one would expect from the literature of gifted children and they are not significantly different from one another.</li><li>A surprisingly remarkable similarity exists between the two samples of cognitively gifted boys, although they were selected a year apart, a continent apart, and on the basis of distinctly different test performances. We expected them to perform better on the figural and the math/science subtests of the Wallach-Kogan and <span class="smallcaps-auto">BIC</span> measures, respectively, and the high-IQ sample to perform significantly better on the verbal and the art/writing subtests. Instead, the differences between the samples are slight and not statistically significant. At minimum, these results suggest that the two samples are each made of highly talented, cognitively gifted boys in the ares of art/writing and math/science as measured by standard instruments. Second, these results further indicate the versatility that accompanies exceptional giftedness…Table 1 shows that the parents of both groups of exceptionally gifted boys are themselves exceptionally creative. Parents of both groups outperformed Duke University subjects. Furthermore, the parents definitely showed more creative potential than their children. It is the parents of the high-IQ boys who have the highest creativity scores of all.</li></ul><p>…We believe the results of the present study and those of Milgram et al. show that cognitive giftedness and creative giftedness are very much related to one another and may be manifestations of the same complex, multi-faceted abilities. Therefore, it should not surprise us that there is a large degree of family cognitive and creative similarity.</p>'
- - https://arstechnica.com/gaming/2020/07/the-return-of-the-70-video-game-has-been-a-long-time-coming/
  - "The return of the $70 video game has been a long time coming: Top-end game pricing has never been lower when measured in constant dollars"
  - Kyle Orland (Ars Technica)
  - 2020-07-09
  - ''
  - ! '<p>Last week, 2K made waves by becoming the first publisher to set a $70 asking price for a big-budget game on the next generation of consoles. <span class="smallcaps-auto">NBA</span>2K21 will cost the now-standard $60 on the Xbox One and PlayStation 4, but 2K will ask $10 more for the upcoming Xbox Series X and PlayStation 5 versions of the game (a $100 “Mamba Forever Edition” gives players access to current-generation and next-generation versions in a single bundle).</p><p>It remains to be seen if other publishers will follow 2K’s lead and make $70 a new de facto standard for big-budget console game pricing. But while $70 would match the high-water mark for <em>nominal</em> game pricing, it wouldn’t be a historically high asking price in terms of <em>actual</em> value. Thanks to inflation and changes in game distribution, in fact, the current ceiling for game prices has never been lower.</p><p>…To measure how the actual asking price for console games has changed over time, we relied primarily on scanned catalogs and retail advertising fliers we found online. While this information was easier to find for some years than others, we were still able to gather data for 20 distinct years across the last four decades. We then adjusted those nominal prices to constant 2020 dollars using the Bureau of Labor Statistics’ <span class="smallcaps-auto">CPI</span> inflation calculator.</p><p>…While nominal cartridge game prices in the early ’80s topped out at $30 to $40, inflation makes that the equivalent of $80 to $100 per game these days. $34.99 for <em>Centipede</em> on the Atari 2600 might sound cheap, but that 1983 price is the equivalent of roughly $90 today…As the industry transitioned into 16-bit cartridges in the ’90s, though, nominal prices for top-end games rose quickly past $60 in nominal dollars and $110 in 2020 dollars. That’s in large part because of the expensive <span class="smallcaps-auto">ROM</span> storage and co-processors often included in games of the day. By 1997, late-era <span class="smallcaps-auto">SNES</span> and early-era N64 games were routinely selling for $69.99 at many retailers, the highest nominal prices the industry has generally seen and still the equivalent of over $110 in today’s dollars.</p><p>…Disc prices settled down to a more reasonable $49.99 soon after that, setting a functional nominal price ceiling that would remain until the mid ’00s. It wasn’t until the Xbox 360 and PlayStation 3 hit the scene that top asking prices started increasing to $59.99. And that’s the de facto ceiling that has remained in place to this day, even as digital downloads and the explosion of indie games has meant many titles now launch at well below this price.</p><p>Adjusting for inflation, we can see the actual (2020 dollar) value of top-end disc-based games plateaued right around $70 for almost a decade through in the ’00s and early ’10s. Inflation has slowly eroded that value in the last decade, though, to the point where a $10 increase like the one for <span class="smallcaps-auto">NBA</span>2K21 merely gets games to the same actual price point as they enjoyed earlier in the century…a bump to $70 would not be a historically unprecedented increase in console gaming’s price ceiling. Accounting for inflation, in fact, it would merely bring those prices back in line with the recent historical average—something to keep in mind as you prepare for a new, seemingly costlier generation of console hardware.</p>'
