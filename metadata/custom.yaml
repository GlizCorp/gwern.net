- - /docs/genetics/selection/2007-maejima.pdf
  - Traits and genotypes may predict the successful training of drug detection dogs
  - Masami Maejima, Miho Inoue-Murayama, Keiichi Tonosaki, Naoto Matsuura, Shota Kato,
    Yasuhiro Saito, Alexander Weiss, Yuichi Murayama, Shin'ichi Ito
  - '2007'
  - 10.1016/j.applanim.2006.10.005
  - ! 'In Japan, approximately 30% of dogs that enter training programs to become
    drug detection dogs successfully complete training. To clarify factors related
    to the aptitude of drug detection dogs and develop an assessment tool, we evaluated
    genotypes and behavioural traits of 197 candidate dogs. The behavioural traits
    were evaluated within 2 weeks from the start of training and included <em>general
    activity</em>, <em>obedience training</em>, <em>concentration</em>, <em>affection
    demand</em>, <em>aggression toward dogs</em>, <em>anxiety</em>, and <em>interest
    in target</em>. Principal components analysis of these ratings yielded two components:
    Desire for Work and Distractibility. Desire for Work was significantly related
    to successful completion of training (<em>p</em>&lt;0.001). Since 93.3% of dogs
    that passed training and 53.3% of the dogs that failed training had Desire for
    Work scores of 45 or higher, we will be able to reject about half of inappropriate
    dogs before 3 months of training by adopting this cut-off point. We also surveyed
    eight polymorphic regions of four genes that have been related to human personality
    dimensions. Genotypes were not related to whether dogs passed, but there was a
    weak relationship between Distractibility and a 5HTT haplotype (<em>p</em> &lt;
    0.05).'
- - /static/js/wikipedia-popups.js
  - wikipedia-popups.js
  - Said Achmiz
  - '2019'
  - ''
  - <code>wikipedia-popups.js</code> is a stand-alone Javascript library which parses
    a page for English Wikipedia links and, when those links are mouse-overed, displays
    a 'popup' (a large tooltip) of the Wikipedia article's HTML summary as returned
    by the WP REST API, typically the introduction of each article. The summaries
    are requested on the initial page load to minimize UI latency as much as possible.
- - https://onlinelibrary.wiley.com/doi/full/10.1111/joim.12926
  - ! 'The Chinese National Twin Registry: a ''gold mine'' for scientific research'
  - W. Gao, W. Cao, J. Lv, C. Yu, T. Wu, S. Wang, L. Meng, D. Wang, Z. Wang, Z. Pang,
    M. Yu, H. Wang, X. Wu, Z. Dong, F. Wu, G. Jiang, X. Wang, Y. Liu, J. Deng, L.
    Lu, L. Li
  - 2019-07-04
  - 10.1111/joim.12926
  - The Chinese National Twin Registry (CNTR) currently includes data from 61&thinsp;566
    twin pair from 11 provinces or cities in China. Of these, 31&thinsp;705, 15&thinsp;060 and 13
    531 pairs are monozygotic, same-sex dizygotic and opposite-sex dizygotic pairs,
    respectively, determined by opposite sex or intrapair similarity. Since its establishment
    in 2001, the CNTR has provided an important resource for analysing genetic and
    environmental influences on chronic diseases especially cardiovascular diseases.
    Recently, the CNTR has focused on collecting biologic specimens from disease-concordant
    or disease-discordant twin pairs or from twin pairs reared apart. More than 8000
    pairs of these twins have been registered, and blood samples have been collected
    from more than 1500 pairs. In this review, we summarize the main findings from
    univariate and multivariate genetic effects analyses, gene-environment interaction
    studies, omics studies exploring DNA methylation and metabolomic markers associated
    with phenotypes. There remains further scope for CNTR research and data mining.
    The plan for future development of the CNTR is described. The CNTR welcomes worldwide
    collaboration.
- - /docs/iq/2014-johnson.pdf
  - ! 'Genetics of Intellectual and Personality Traits Associated with Creative Genius:
    Could Geniuses Be Cosmobian Dragon Kings?'
  - Wendy Johnson, Thomas J. Bouchard Jr.
  - '2014'
  - 10.1002/9781118367377.ch14
  - ! '[Behavioral genetics discussion of eminence/genius: intelligence, developmental
    processes, psychopathology, and creativity scales all contribute to accomplishment
    but leave much unexplained, in particular, the odd pattern of inheritance where
    genius runs in families but highly sporadically and not following any standard
    Mendelian or polygenic inheritance pattern. The authors refer to the concept of
    ''emergenesis'', where emergenic traits are not additive combinations of subtraits
    (as is strongly the case for traits like intelligence) but rather are multiplicative
    combinations, which are epistatic at the genetic level. Because all subtraits
    must be present to have a chance of producing the overall trait, emergenic traits
    can be highly genetically influenced yet still rare and sporadically appearing
    within families. (<em>The Wiley Handbook of Genius</em> 2014, chapter 14)]'
- - https://archive.org/details/originsofgeniusd00simo
  - ! 'Origins of Genius: Darwinian Perspectives on Creativity'
  - Dean Keith Simonton
  - '1999'
  - ''
  - How can we account for the sudden appearance of such dazzling artists and scientists
    as Mozart, Shakespeare, Darwin, or Einstein? How can we define such genius? What
    conditions or personality traits seem to produce exceptionally creative people?
    Is the association between genius and madness really just a myth? These and many
    other questions are brilliantly illuminated in <em>The Origins of Genius</em>.
    Dean Simonton convincingly argues that creativity can best be understood as a
    Darwinian process of variation and selection. The artist or scientist generates
    a wealth of ideas, and then subjects these ideas to aesthetic or scientific judgment,
    selecting only those that have the best chance to survive and reproduce. Indeed,
    the true test of genius is the ability to bequeath an impressive and influential
    body of work to future generations. Simonton draws on the latest research into
    creativity and explores such topics as the personality type of the genius, whether
    genius is genetic or produced by environment and education, the links between
    genius and mental illness (Darwin himself was emotionally and mentally unwell),
    the high incidence of childhood trauma, especially loss of a parent, amongst Nobel
    Prize winners, the importance of unconscious incubation in creative problem-solving,
    and much more. Simonton substantiates his theory by examining and quoting from
    the work of such eminent figures as Henri Poincare, W. H. Auden, Albert Einstein,
    Marie Curie, Charles Darwin, Niels Bohr, and many others. For anyone intrigued
    by the spectacular feats of the human mind, <em>The Origins of Genius</em> offers
    a revolutionary new way of understanding the very nature of creativity.
- - http://cogprints.org/772/3/152.pdf#page=8
  - ! 'Emergenesis: Genetic Traits That May Not Run in Families'
  - D. T. Lykken, M. McGue, A. Tellegen, T. J. Bouchard, J
  - '1992'
  - ''
  - Traits that are influenced by a configuration, rather than by a simple sum, of
    polymorphic genes may not be seen to be genetic unless one studies monozygotic
    twins (who share all their genes and thus all gene configurations) because such
    'emergenic' traits will tend not to run in families. Personal idiosyncrasies that
    have been found to be surprisingly concordant among monozygotic twins separated
    in infancy and reared apart may be emergenic traits. More speculatively, important
    human traits like leadership, genius in its many manifestations, being an effective
    therapist or parent, as well as certain psychopathological syndromes may also
    be emergenic. These ideas reemphasize the importance of the role played in human
    affairs by genetic variation.
- - http://cogprints.org/772/3/152.pdf
  - ! 'Emergenesis: Genetic Traits That May Not Run in Families'
  - D. T. Lykken, M. McGue, A. Tellegen, T. J. Bouchard, J
  - '1992'
  - ''
  - Traits that are influenced by a configuration, rather than by a simple sum, of
    polymorphic genes may not be seen to be genetic unless one studies monozygotic
    twins (who share all their genes and thus all gene configurations) because such
    'emergenic' traits will tend not to run in families. Personal idiosyncrasies that
    have been found to be surprisingly concordant among monozygotic twins separated
    in infancy and reared apart may be emergenic traits. More speculatively, important
    human traits like leadership, genius in its many manifestations, being an effective
    therapist or parent, as well as certain psychopathological syndromes may also
    be emergenic. These ideas reemphasize the importance of the role played in human
    affairs by genetic variation.
- - https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1601-183X.2006.00233.x
  - The mechanism of emergenesis
  - D. T. Lykken
  - '2006'
  - 10.1111/j.1601-183X.2006.00233.x
  - ! 'The intraclass correlations of monozygotic twins who were separated in infancy
    and reared apart (MZA twins) provide estimates of trait heritability, and the
    Minnesota Study of Twins Reared Apart [MISTRA: Bouchard et al. (1990), ''The sources
    of human psychological differences: the Minnesota study of twins reared apart'',
    <em>Science</em> 250, 223--228] has demonstrated that MZA pairs are as similar
    in most respects as MZ pairs reared together. Some polygenic traits—e.g. stature,
    IQ, harm avoidance, negative emotionality, interest in sports—are polygenic-additive,
    so pairs of relatives resemble one another on the given trait in proportion to
    their genetic similarity. But the existence and the intensity of other important
    psychological traits seem to be emergent properties of gene configurations (or
    configurations of independent and partially genetic traits) that interact multiplicatively
    rather than additively. Monozygotic (MZ) twins may be strongly correlated on such
    emergenic traits, while the similarity of dizygotic (DZ) twins, sibs or parent-offspring
    pairs may be much less than half that of MZ pairs. Some emergenic traits, although
    strongly genetic, do not appear to run in families. MISTRA has provided at least
    two examples of traits for which MZA twins are strongly correlated, and DZA pairs
    correlate near zero, while DZ pairs reared together (DZTs) are about half as similar
    as MZTs. These findings suggest that even more traits may be emergenic than those
    already identified. Studies of adoptees reared together (who are perhaps more
    common than twins reared apart) may help to identify traits that are emergenic,
    but that also are influenced by a common rearing environment. [Keywords: Epistasis,
    heritability, polygenic additivity, psychophysiology]'
- - https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-8986.1982.tb02489.x
  - ! 'Research With Twins: The Concept of Emergenesis'
  - D. T. Lykken
  - '1982'
  - 10.1111/j.1469-8986.1982.tb02489.x
  - ! 'Preliminary findings from an on-going study of monozygotic twins reared apart
    (MZA) and data from a larger sample of twins reared together (MZT and DZT), indicate
    a surprisingly strong influence of genetic variation on aptitudes, psychophysiological
    characteristics, personality traits and even dimensions of attitude and interest.
    For some of these variables, MZT and MZA twins show high intra-class correlations
    while DZT twins are no more similar than pairs of unrelated persons. It is suggested
    that such traits are ''emergenic'', i.e., that they are determined by the interaction—rather
    than the sum—of genetic influences. Emergenic traits, although perhaps strongly
    genetic, will not tend to run in families and for this reason have been neglected
    by students of behavior genetics. For this and several other listed reasons, wider
    use of twins in psychological research is strongly recommended. [Keywords: twins,
    behavior genetics, emergenesis, range correction, EEG spectra]'
- - https://www.nature.com/articles/s41467-017-01284-y
  - Inequality in genetic cancer risk suggests bad genes rather than bad luck
  - Mats Julius Stensrud, Morten Valberg
  - '2017'
  - 10.1038/s41467-017-01284-y
  - Heritability is often estimated by decomposing the variance of a trait into genetic
    and other factors. Interpreting such variance decompositions, however, is not
    straightforward. In particular, there is an ongoing debate on the importance of
    genetic factors in cancer development, even though heritability estimates exist.
    Here we show that heritability estimates contain information on the distribution
    of absolute risk due to genetic differences. The approach relies on the assumptions
    underlying the conventional heritability of liability model. We also suggest a
    model unrelated to heritability estimates. By applying these strategies, we describe
    the distribution of absolute genetic risk for 15 common cancers. We highlight
    the considerable inequality in genetic risk of cancer using different metrics,
    e.g., the Gini Index and quantile ratios which are frequently used in economics.
    For all these cancers, the estimated inequality in genetic risk is larger than
    the inequality in income in the USA.
- - https://www.annualreviews.org/doi/pdf/10.1146/annurev-genom-083115-022316
  - Thinking About the Evolution of Complex Traits in the Era of Genome-Wide Association
    Studies
  - Guy Sella, Nicholas H. Barton
  - 2019-06-21
  - 10.1146/annurev-genom-083115-022316
  - ! 'Many traits of interest are highly heritable and genetically complex, meaning
    that much of the variation they exhibit arises from differences at numerous loci
    in the genome. Complex traits and their evolution have been studied for more than
    a century, but only in the last decade have genome-wide association studies (GWASs)
    in humans begun to reveal their genetic basis. Here, we bring these threads of
    research together to ask how findings from GWASs can further our understanding
    of the processes that give rise to heritable variation in complex traits and of
    the genetic basis of complex trait evolution in response to changing selection
    pressures (i.e., of polygenic adaptation). Conversely, we ask how evolutionary
    thinking helps us to interpret findings from GWASs and informs related efforts
    of practical importance. [Keywords: evolution, genome-wide association study,
    GWAS, quantitative genetics, complex traits, polygenic adaptation, genetic architecture]'
- - https://www.newyorker.com/magazine/2019/07/22/the-promise-and-price-of-cellular-therapies
  - ! 'The Promise and Price of Cellular Therapies: New ''living drugs''—made from
    a patient''s own cells—can cure once incurable cancers. But can we afford them?'
  - Siddhartha Mukherjee
  - 2019-07-15
  - ''
  - ! '[Mukherjee traces the evolution of CAR T-cell therapy, a form of immunotherapy
    that uses engineered immune cells to eliminate cancer, beginning with the development
    of bone marrow transplantation by Fred Hutch''s Dr. E. Donnall Thomas. In his
    article, Mukherjee profiles recent T-cell therapy research by Dr. Carl June at
    the Perelman School of Medicine of the University of Pennsylvania and other leaders
    in the immunotherapy field including Drs. Steve Rosenberg and Michel Sadelain
    and the Hutch''s Drs. Stan Riddell and Phil Greenberg. In addition to the promising
    early successes with this new therapy, Mukherjee explores some of the challenges
    that remain to making these approaches more accessible and affordable. In particular,
    the staggering price of custom single-patient CAR-T immunotherapy is in the hundreds
    of thousands or millions of dollars, posing a challenge to health insurance and
    national healthcare systems.]'
- - https://www.cs.cmu.edu/~noamb/papers/19-Science-Superhuman.pdf
  - Pluribus:Superhuman AI for multiplayer poker
  - Noam Brown, Tuomas Sandholm
  - 2019-07-11
  - 10.1126/science.aay2400
  - ! 'In recent years there have been great strides in artificial intelligence (AI),
    with games often serving as challenge problems, benchmarks, and milestones for
    progress. Poker has served for decades as such a challenge problem. Past successes
    in such benchmarks, including poker, have been limited to two-player games. However,
    poker in particular is traditionally played with more than two players. Multiplayer
    games present fundamental additional issues beyond those in two-player games,
    and multiplayer poker is a recognized AI milestone. In this paper we present Pluribus,
    an AI that we show is stronger than top human professionals in six-player no-limit
    Texas hold''em poker, the most popular form of poker played by humans. [Keywords:
    Monte Carlo CFR, state abstraction, Nash equilibrium]'
- - https://waifulabs.com/blog/ax
  - How we built the Waifu Vending Machine
  - Sizigi Studios
  - 2019-07-23
  - ''
  - ! '[Design company Sizigi Studios discusses their creation of Waifu Labs (https://waifulabs.com/),
    a deep learning GAN website for interactive generation of anime faces, and their
    experience running a prototype of it at the Anime Expo (AX) 2019 anime convention
    in Los Angeles, where it was a popular exhibit. Laptops were setup attached to
    printers in an enclosed booth, making a ''vending machine''. Challenges included:
    no electricity outlets and no WiFi. Multiple laptops were cycled through as batteries
    wore out, while a gaming PC ran the neural network GANs locally rather than in
    a cloud VM. The failed WiFi was bypassed by using a smartphone as a local router.
    Further bugs were discovered in the code while many users waited in a long line.
    but were fixed in time, and the waifu vending machine was a success.]'
- - https://www.its.caltech.edu/~dg/crunch_art.html
  - The Big Crunch
  - David Goodstein
  - '1994'
  - ''
  - ! '<p>[On the end to the post-WWII Vannevar Bushian exponential growth of academia
    and consequences thereof: growth can''t go on forever, and it didn''t.]</p> <p>According
    to modern cosmology, the universe began with a big bang about 10 billion years
    ago, and it has been expanding ever since. If the density of mass in the universe
    is great enough, its gravitational force will cause that expansion to slow down
    and reverse, causing the universe to fall back in on itself. Then the universe
    will end in a cataclysmic event known as ''the Big Crunch''. I would like to present
    to you a vaguely analogous theory of the history of science. The upper curve on
    Figure 1 was first made by historian Derek da Solla Price, sometime in the 1950s.
    It is a semilog plot of the cumulative number of scientific journals founded worldwide
    as a function of time...the growth of the profession of science, the scientific
    enterprise, is bound to reach certain limits. I contend that these limits have
    now been reached.</p> <p>...But after about 1970 and the Big Crunch, the gleaming
    gems produced at the end of the vast mining-and-sorting operation produced less
    often from American ore. Research professors and their universities, using ore
    imported from across the oceans, kept the machinery humming.</p><p>...Let me finish
    by summarizing what I''ve been trying to tell you. We stand at an historic juncture
    in the history of science. The long era of exponential expansion ended decades
    ago, but we have not yet reconciled ourselves to that fact. The present social
    structure of science, by which I mean institutions, education, funding, publications
    and so on all evolved during the period of exponential expansion, before The Big
    Crunch. They are not suited to the unknown future we face. Today''s scientific
    leaders, in the universities, government, industry and the scientific societies
    are mostly people who came of age during the golden era, 1950–1970. I am myself
    part of that generation. We think those were normal times and expect them to return.
    But we are wrong. Nothing like it will ever happen again. It is by no means certain
    that science will even survive, much less flourish, in the difficult times we
    face. Before it can survive, those of us who have gained so much from the era
    of scientific elites and scientific illiterates must learn to face reality, and
    admit that those days are gone forever.</p>'
- - https://slatestarcodex.com/2019/04/22/1960-the-year-the-singularity-was-cancelled/
  - ! '1960: The Year The Singularity Was Cancelled'
  - Scott Alexander
  - 2019-04-22
  - ''
  - ! '[On the relationship between absolute population size, population growth, economic
    growth (absolute and per capita), innovation, ideas, and science: is the long
    exponential history of the progress of science, technology, and computing merely
    due to the accompanying exponential growth of the human population size after
    reaching a critical point where the Malthusian trap could be escaped and a new
    higher equilibrium sought, creating more possible researchers and enabling positive
    externalities? If so, then the end of exponential global population growth in
    the 1960s–1970s was also the end of the exponential era in human progress... At
    least until a new mode of exponential growth, such as artificial intelligence
    or brain emulations, begins.]'
- - https://forum.effectivealtruism.org/posts/dCjz5mgQdiv57wWGz/ingredients-for-creating-disruptive-research-teams
  - Ingredients for creating disruptive research teams
  - Stefan Torges
  - 2019-05-16
  - ''
  - ! '<p>This post tries to answer the question of what qualities make some research
    teams more effective than others. I was particularly interested in learning more
    about "disruptive" research teams, i.e. research teams that have an outsized impact
    on (1) the research landscape itself (e.g. by paving the way for new fields or
    establishing a new paradigm), and/or (2) society at large (e.g. by shaping technology
    or policy).[1] However, I expect the conclusions to be somewhat relevant for all
    research teams....</p><p>Key findings: excellent researchers have individual qualities
    and diversity, with shared direction, purposeful vision, concrete goals, leadership,
    and no inconveniences. Their organizations emphasize autonomy & self-organization,
    organic decentralized collaboration (with possibly metrics, goal-setting, and
    incentives), spaces for interaction, shared physical space, shared ''psychological
    spaces'' and forced interaction combined with psychological safety. Teams are
    small, seek external input and feedback, and value immaterial rewards.</p><p>...Based
    on the findings above, these are the most important takeaways for our research
    team at the Foundational Research Institute (FRI) as I see them: (1) We should
    continue to apply a high bar for hiring researchers... (2) Currently, we have
    staff who either excel at leadership or at research but nobody who combines both
    skill sets. We would likely benefit significantly from such an addition to our
    team....(3) We should continue to provide our research staff with as much freedom
    and operational support as possible... (4) Currently, many of our researchers
    work remotely which seems to have higher costs than I previously thought. As a
    consequence, I have become more convinced that we should try to create a research
    office geared toward the needs of our research staff.... (5) We should invest
    more time into creating psychological safety for our research staff. I''m not
    yet sure how to best proceed here... (6) It was worth it to invest time into developing
    a theory of change, i.e., thinking about how exactly our research would lead to
    real-world changes when it comes to AI designs and deployment.... (7) Organizing
    research workshops with other organizations focused on similar questions is worth
    it. We should also look into other formats of high-intensity in-person interaction.</p>'
- - /docs/history/1994-weschler.pdf
  - ! 'Inhaling the spore: Field trip to a museum of natural (un)history'
  - Lawrence Weschler
  - 1994-09-01
  - ''
  - ! '[Description of a visit to an unusual science museum: the LA Museum of Jurassic
    Technology. Unlike most science museums, only <em>some</em> of the exhibits are
    genuine. The others are fakes, many made by the museum''s curator. The visitor
    is challenged to discern the fabulous from the fraudulent.] [Keywords: 20th century,
    California, Curiosities and wonders, David Hildebrand Wilson, Los Angeles, Museum
    of Jurassic Technology, Science museums, hoax, performance art, critical thinking]'
- - http://www.sciencesuccess.org/uploads/1/5/5/4/15543620/science_quantifying_aaf5239_sinatra.pdf
  - Quantifying the evolution of individual scientific impact
  - Roberta Sinatra, Dashun Wang, Pierre Deville, Chaoming Song, Albert-László Barabási
  - 2016-11-04
  - 10.1126/science.aaf5239
  - ! '<p>Are there quantifiable patterns behind a successful scientific career? Sinatra
    et al. analyzed the publications of 2887 physicists, as well as data on scientists
    publishing in a variety of fields. When productivity (which is usually greatest
    early in the scientist''s professional life) is accounted for, the paper with
    the greatest impact occurs randomly in a scientist''s career. However, the process
    of generating a high-impact paper is not an entirely random one. The authors developed
    a quantitative model of impact, based on an element of randomness, productivity,
    and a factor <em>Q</em> that is particular to each scientist and remains constant
    during the scientist''s career.</p> <p><strong><em>Introduction</em></strong>:
    In most areas of human performance, from sport to engineering, the path to a major
    accomplishment requires a steep learning curve and long practice. Science is not
    that different: Outstanding discoveries are often preceded by publications of
    less memorable impact. However, despite the increasing desire to identify early
    promising scientists, the temporal career patterns that characterize the emergence
    of scientific excellence remain unknown.</p> <p><strong><em>Rationale</em></strong>:
    How do impact and productivity change over a scientific career? Does impact, arguably
    the most relevant performance measure, follow predictable patterns? Can we predict
    the timing of a scientist''s outstanding achievement? Can we model, in quantitative
    and predictive terms, scientific careers? Driven by these questions, here we quantify
    the evolution of impact and productivity throughout thousands of scientific careers.
    We do so by reconstructing the publication record of scientists from seven disciplines,
    associating to each paper its long-term impact on the scientific community, as
    quantified by citation metrics.</p> <p><strong><em>Results</em></strong>: We find
    that the highest-impact work in a scientist''s career is randomly distributed
    within her body of work. That is, the highest-impact work can be, with the same
    probability, anywhere in the sequence of papers published by a scientist—it could
    be the first publication, could appear mid-career, or could be a scientist''s
    last publication. This random-impact rule holds for scientists in different disciplines,
    with different career lengths, working in different decades, and publishing solo
    or with teams and whether credit is assigned uniformly or unevenly among collaborators.</p>
    <p>The random-impact rule allows us to develop a quantitative model, which systematically
    untangles the role of productivity and luck in each scientific career. The model
    assumes that each scientist selects a project with a random potential <em>p</em>
    and improves on it with a factor <em>Q<sub>i</sub></em>, resulting in a publication
    of impact <em>Q<sub>ip</sub></em>. The parameter <em>Q<sub>i</sub></em> captures
    the ability of scientist <em>i</em> to take advantage of the available knowledge
    in a way that enhances (<em>Q<sub>i</sub></em> &gt; 1) or diminishes (<em>Q<sub>i</sub></em>
    &lt; 1) the potential impact <em>p</em> of a paper. The model predicts that truly
    high-impact discoveries require a combination of high <em>Q</em> and luck (<em>p</em>)
    and that increased productivity alone cannot substantially enhance the chance
    of a very high impact work. We also show that a scientist''s <em>Q</em>, capturing
    her sustained ability to publish high-impact papers, is independent of her career
    stage. This is in contrast with all current metrics of excellence, from the total
    number of citations to the <em>h</em>-index, which increase with time. The <em>Q</em>
    model provides an analytical expression of these traditional impact metrics and
    allows us to predict their future time evolution for each individual scientist,
    being also predictive of independent recognitions, like Nobel prizes.</p> <p><strong><em>CONCLUSION</em></strong>:
    The random-impact rule and the <em>Q</em> parameter, representing two fundamental
    characteristics of a scientific career, offer a rigorous quantitative framework
    to explore the evolution of individual careers and understand the emergence of
    scientific excellence. Such understanding could help us better gauge scientific
    performance and offers a path toward nurturing high-impact scientists, potentially
    informing future policy decisions.</p>'
- - /static/js/popups.js
  - popups.js
  - Said Achmiz
  - 2019-08-21
  - ''
  - ! '<p><code>popups.js</code>: standalone Javascript library for creating ''popups''
    which display link metadata (typically, title/author/date/summary), for extremely
    convenient reference/abstract reading, with mobile and YouTube support. Whenever
    any such link is mouse-overed by the user, popups.js will pop up a large tooltip-like
    square with the contents of the attributes. This is particularly intended for
    references, where it is extremely convenient to autopopulate links such as to
    Arxiv.org/Biorxiv.org/Pubmed/PLOS/gwern.net/Wikipedia with the link''s title/author/date/abstract,
    so the reader can see it instantly.</p><p><code>popups.js</code> parses a HTML
    document and looks for <code>&lt;a&gt;</code> links which have the <code>docMetadata</code>
    attribute class, and the attributes <code>data-popup-title</code>, <code>data-popup-author</code>,
    <code>data-popup-date</code>, <code>data-popup-doi</code>, <code>data-popup-abstract</code>.
    (These attributes are expected to be populated already by the HTML document''s
    compiler, however, they can also be done dynamically. See <a href="https://www.gwern.net/static/js/wikipedia-popups.js"><code>wikipedia-popups.js</code></a>
    for an example of a library which does Wikipedia-only dynamically on page loads.)</p><p>For
    an example of a Hakyll library which generates annotations for Wikipedia/Biorxiv/Arxiv/PDFs/arbitrarily-defined
    links, see <a href="https://www.gwern.net/LinkMetadata.hs"><code>LinkMetadata.hs</code></a>;
    for a live demonstration, see the links in <a href="https://www.gwern.net/newsletter/2019/07">the
    July 2019 newsletter</a>.</p>'
- - /static/js/wikipedia-popups.js
  - wikipedia-popups.js
  - Said Achmiz
  - 2019-07-29
  - ''
  - ! '<code>wikipedia-popups.js</code>: standalone Javascript library for creating
    ''popups'' for links to English Wikipedia articles when the user mouse-overs the
    link. The tooltip-style popup displays the summaries/introductions/ledes to Wikipedia
    articles as returned by the Wikipedia API (see <code>https://www.mediawiki.org/wiki/Page_Previews/API_Specification</code>
    and <code>https://en.wikipedia.org/api/rest_v1/</code>). All summaries are loaded
    on page load so as to have minimal latency (on-mouseover summary loading is noticeably
    slow). If a page has many Wikipedia links on it, this can result in quite a few
    requests; the summaries can instead be provided statically, encoded into data
    attributes. (This also allows encoding summaries/previews of arbitrary websites
    by whatever is compiling the HTML.) See <code>/static/js/popups.js</code> for
    a JS library which takes that approach instead.'
- - /Questions#mouse-utopia
  - On the 'Mouse Utopia' experiment
  - Gwern Branwen
  - 2019-08-12
  - ''
  - <p>Did John Calhoun's 1960s Mouse Utopia really show that animal (and human) populations
    will expand to arbitrary densities, creating socially-driven pathology and collapse?
    I give reasons for doubt about its replicability, interpretation, and meaningfulness.</p><p>One
    of the most famous experiments in psychology & sociology was John Calhoun's Mouse
    Utopia experiments in the 1960s–1970s. In the usual telling, Mouse Utopia created
    ideal mouse environments in which the mouse population was permitted to increase
    as much as possible; however, the overcrowding inevitably resulted in extreme
    levels of physical & social dysfunctionality, and eventually population collapse
    & even extinction. Looking more closely into it, there are reasons to doubt the
    replicability of the growth & pathological behavior & collapse, and if it does
    happen, whether it is driven by the social pressures as claimed by Calhoun or
    by other causal mechanisms at least as consistent with the evidence like disease
    or mutational meltdown.</p>
- - /Order-statistics#sampling-gompertz-distribution-extremes
  - ! 'Order Statistics: Sampling Gompertz Distribution Extremes'
  - Gwern Branwen
  - 2019-08-14
  - ''
  - <p>Efficient random sampling of extreme order statistics (such as 1-in-10-billion)
    in R code using the beta transform trick, with a case study applying to the <a
    href="/Questions#jeanne-calment">Jeanne Calment lifespan anomaly</a>.</p><p>I
    implement random sampling from the extremes/order statistics of the Gompertz survival
    distribution, used to model human life expectancies, with the beta transformation
    trick and <code>flexsurv</code>/root-finding inversion. I then discuss the unusually
    robust lifespan record of Jeanne Calment, and show that records like hers (which
    surpass the runner-up's lifespan by such a degree) are not usually produced by
    a Gompertz distribution, supporting the claim that her lifespan was indeed unusual
    even for the record holder.</p>
- - https://www.nature.com/articles/d41586-019-01770-x
  - ! 'Russian biologist plans more CRISPR-edited babies: The proposal follows a Chinese
    scientist who claimed to have created twins from edited embryos last year'
  - David Cyranoski (<em>Nature News</em>)
  - 2019-07-10
  - ''
  - <p>A Russian scientist says he is planning to produce gene-edited babies, an act
    that would make him only the second person known to have done this. It would also
    fly in the face of the scientific consensus that such experiments should be banned
    until an international ethical framework has agreed on the circumstances and safety
    measures that would justify them.</p><p>Molecular biologist Denis Rebrikov has
    told <em>Nature</em> he is considering implanting gene-edited embryos into women,
    possibly before the end of the year if he can get approval by then. Chinese scientist
    He Jiankui prompted an international outcry when he announced last November that
    he had made the world's first gene-edited babies—twin girls.</p><p>...Rebrikov
    heads a genome-editing laboratory at Russia's largest fertility clinic, the Kulakov
    National Medical Research Center for Obstetrics, Gynecology and Perinatology in
    Moscow and is a researcher at the Pirogov Russian National Research Medical University,
    also in Moscow. According to Rebrikov he already has an agreement with an HIV
    centre in the city to recruit women infected with HIV who want to take part in
    the experiment...[he] plans to implant embryos only into a subset of HIV-positive
    mothers who do not respond to standard anti-HIV drugs. Their risk of transmitting
    the infection to the child is higher. If editing successfully disables the CCR5
    gene, that risk would be greatly reduced, Rebrikov says. 'This is a clinical situation
    which calls for this type of therapy', he says.</p>
- - https://icare.hse.ru/data/2018/10/24/1142422445/Rust.pdf
  - Has dynamic programming improved decision making?
  - John Rust
  - 2018-08-22
  - 10.1146/annurev-economics-080218-025721
  - ! '<p>Dynamic programming (DP) is an extremely powerful tool for solving a wide
    class of sequential decision making problems under uncertainty. In principle,
    it enables us to compute <em>optimal decision rules</em> that specify the best
    possible decision to take in any given situation. This article reviews developments
    in DP and contrasts its revolutionary impact on economics, operations research,
    engineering, and artificial intelligence, with the comparative paucity of real
    world applications where DP is actually used to improve decision making. I discuss
    the literature on numerical solution of DPs and its connection to the literature
    on reinforcement learning (RL) and artificial intelligence (AI). Despite amazing,
    highly publicized successes of these algorithms that result in superhuman levels
    of performance in board games such as chess or Go, I am not aware of comparably
    successful applications of DP for helping individuals and firms to solve real-world
    problems. I point to the fuzziness of many real world decision problems and the
    difficulty in mathematically formulating and modeling them as key obstacles to
    wider application of DP to improve decision making. Nevertheless, I provide several
    success stories where DP has demonstrably improved decision making and discuss
    a number of other examples where it seems likely that the application of DP could
    have significant value. I conclude that ''applied DP'' offers substantial promise
    for economic policy making if economists can let go of the empirically untenable
    assumption of unbounded rationality and try to tackle the challenging decision
    problems faced every day by individuals and firms.</p> <p>[Keywords: actor-critic
    algorithms, Alpha Zero, approximate dynamic programming, artificial intelligence,
    behavioral economics, Bellman equation, bounded rationality, curse of dimensionality,
    computational complexity, decision rules, dynamic pricing, dynamic programming,
    employee compensation, Herbert Simon, fleet sizing, identification problem, individual
    and firm behavior life-cycle problem, locomotive allocation, machine learning,
    Markov decision processes, mental models, model-free learning, neural networks,
    neurodynamic programming, offline versus online training, optimal inventory management,
    optimal replacement, optimal search, principle of decomposition, Q-learning, revenue
    management, real-time dynamic programming, reinforcement learning, Richard Bellman,
    structural econometrics, supervised versus unsupervised learning]</p>'
- - https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/
  - ! 'We Need a New Science of Progress: Humanity needs to get better at knowing
    how to get better'
  - Patrick Collison, Tyler Cowen
  - 2019-07-30
  - ''
  - <p>Progress itself is understudied. By 'progress,' we mean the combination of
    economic, technological, scientific, cultural, and organizational advancement
    that has transformed our lives and raised standards of living over the past couple
    of centuries. For a number of reasons, there is no broad-based intellectual movement
    focused on understanding the dynamics of progress, or targeting the deeper goal
    of speeding it up. We believe that it deserves a dedicated field of study. We
    suggest inaugurating the discipline of 'Progress Studies.'</p><p>Before digging
    into what Progress Studies would entail, it's worth noting that we still need
    a lot of progress. We haven't yet cured all diseases; we don't yet know how to
    solve climate change; we're still a very long way from enabling most of the world's
    population to live as comfortably as the wealthiest people do today; we don't
    yet understand how best to predict or mitigate all kinds of natural disasters;
    we aren't yet able to travel as cheaply and quickly as we'd like; we could be
    far better than we are at educating young people. The list of opportunities for
    improvement is still extremely long.</p><p>...Plenty of existing scholarship touches
    on these topics, but it takes place in a highly fragmented fashion and fails to
    directly confront some of the most important practical questions.</p><p>Imagine
    you want to know how to most effectively select and train the most talented students.
    While this is an important challenge facing educators, policy makers, and philanthropists,
    knowledge about how best to do so is dispersed across a very long list of different
    fields. Psychometrics literature investigates which tests predict success. Sociologists
    consider how networks are used to find talent. Anthropologists investigate how
    talent depends on circumstances, and a historiometric literature studies clusters
    of artistic creativity. There's a lively debate about when and whether '10,000
    hours of practice' are required for truly excellent performance. The education
    literature studies talent-search programs such as the Center for Talented Youth.
    Personality psychologists investigate the extent to which openness or conscientiousness
    affect earnings. More recently, there's work in sportometrics, looking at which
    numerical variables predict athletic success. In economics, Raj Chetty and his
    co-authors have examined the backgrounds and communities liable to best encourage
    innovators. Thinkers in these disciplines don't necessarily attend the same conferences,
    publish in the same journals, or work together to solve shared problems.</p><p>When
    we consider other major determinants of progress, we see insufficient engagement
    with the central questions. For example, there's a growing body of evidence suggesting
    that management practices determine a great deal of the difference in performance
    between organizations. One recent study found that a particular intervention—teaching
    better management practices to firms in Italy—improved productivity by 49 percent
    over 15 years when compared with peer firms that didn't receive the training.
    How widely does this apply, and can it be repeated? Economists have been learning
    that firm productivity commonly varies within a given sector by a factor of two
    or three, which implies that a priority in management science and organizational
    psychology should be understanding the drivers of these differences. In a related
    vein, we're coming to appreciate more and more that organizations with higher
    levels of trust can delegate authority more effectively, thereby boosting their
    responsiveness and ability to handle problems. Organizations as varied as Y Combinator,
    MIT's Radiation Lab, and ARPA have astonishing track records in catalyzing progress
    far beyond their confines. While research exists on all of these fronts, we're
    underinvesting considerably. These examples collectively indicate that one of
    our highest priorities should be figuring out interventions that increase the
    efficacy, productivity, and innovative capacity of human organizations...</p>
- - /docs/statistics/decision/2019-isakov.pdf
  - ! 'Is the FDA too conservative or too aggressive?: A Bayesian decision analysis
    of clinical trial design'
  - Leah Isakov, Andrew W. Lo, Vahid Montazerhodjat
  - 2019-01-04
  - 10.1016/j.jeconom.2018.12.009
  - Implicit in the drug-approval process is a host of decisions—target patient population,
    control group, primary endpoint, sample size, follow-up period, etc.—all of which
    determine the trade-off between Type I and Type II error. We explore the application
    of Bayesian decision analysis (BDA) to minimize the expected cost of drug approval,
    where the relative costs of the two types of errors are calibrated using U.S.
    Burden of Disease Study 2010 data. The results for conventional fixed-sample randomized
    clinical-trial designs suggest that for terminal illnesses with no existing therapies
    such as pancreatic cancer, the standard threshold of 2.5% is substantially more
    conservative than the BDA-optimal threshold of 23.9% to 27.8%. For relatively
    less deadly conditions such as prostate cancer, 2.5% is more risk-tolerant or
    aggressive than the BDA-optimal threshold of 1.2% to 1.5%. We compute BDA-optimal
    sizes for 25 of the most lethal diseases and show how a BDA-informed approval
    process can incorporate all stakeholders' views in a systematic, transparent,
    internally consistent, and repeatable manner.
- - https://www.theguardian.com/world/2019/aug/06/christian-science-church-medicine-death-horror-of-my-fathers-last-days
  - ! 'Dying the Christian Science way: the horror of my father''s last days; The
    anti-medical dogma of Christian Science led my father to an agonising death. Now
    the church itself is in decline—and it can''t happen fast enough'
  - Caroline Fraser
  - 2019-08-06
  - ''
  - ! '<p>[''Caroline Fraser, herself raised in a Scientist household, traces the
    growth of the Church from a small, eccentric sect into a politically powerful
    and socially respectable religion. She takes us into the closed world of Eddy''s
    followers, who reject modern medicine even at the cost of their children''s lives.
    And she reveals just how Christian Science managed to gain extraordinary legal
    and congressional approval for its dubious practices.''</p><p>Memoir of a former
    Christian Scientist, a Christian cult which believes all illness is spiritual
    and that medicine is useless/sinful and so whose adherents refuse medical treatment,
    describing her father''s slow decay from injuries and eventual death from a spreading
    gangrene that could have been treated. Author describes how (akin to Scientology)
    Christian Science is in decay itself, with rapidly declining numbers despite healthy
    financials and real estate assets from better days. While Christian Science may
    soon shrivel away, it leaves a toxic and literally infectious legacy: to profit
    off offering ''treatment'' and enable its members to avoid real medical treatment
    for their children and themselves, Christian Science spearheaded the legislation
    of ''religious exemptions'' to vaccines, empowering the current anti-vax movement,
    which may kill more children than Christian Science ever did.]</p>'
- - https://www.theatlantic.com/magazine/archive/2014/03/the-dark-power-of-fraternities/357580/
  - Why Don't Colleges Get Rid of Their Bad Fraternities? A yearlong investigation
    of Greek houses reveals their endemic, lurid, and sometimes tragic problems—and
    a sophisticated system for shifting the blame
  - Caitlin Flanagan (<em>The Atlantic</em>)
  - 2014-03-01
  - ''
  - ! '[History and investigation of legal records/settlements involving US college
    fraternities. Author finds that fraternities are involved in a remarkable number
    of serious, often fatal, injuries in part because of deliberate decisions to preserve
    traditions such as bunk beds for drunken partiers deliberately placed next to
    permanently-wide-open windows on the 2nd or 3rd story of frat buildings. Fraternities
    are able to survive because of their long history, including highly valuable real
    estate next to universities acquired in their earliest days (many frats being
    older than many American universities), and because of carefully-tailored insurance
    and regulations which enable them to push legal liability onto the students or
    members for the slightest infraction, such as bringing an additional bottle of
    beer, and thus responsibility for anything that might happen (like falling out
    of an open window); frat members are debriefed by the frat''s lawyers immediately
    after incidents with an eye to finding one who can be blamed, before the frat
    members can realize that the lawyers are not there to help them. While the frat
    members in question may have no assets to be sued over, their (frequently middle
    or upper-class) parents do, and may lose their houses in the subsequent lawsuits.]'
- - https://www.esquire.com/news-politics/news/a28718/why-men-love-war/
  - ! 'Why Men Love War: Like all lust, for as long as it lasts it dominates everything
    else'
  - William Broyles, Jr.
  - 1984-11-01
  - ''
  - ! '<p>"What people can''t understand," Hiers said, gently picking up each tiny
    rabbit and placing it in the nest, "is how much fun Vietnam was. I loved it. I
    loved it, and I can''t tell anybody." Hiers loved war. And as I drove back from
    Vermont in a blizzard, my children asleep in the back of the car, I had to admit
    that for all these years I also had loved it, and more than I knew. I hated war,
    too. Ask me, ask any man who has been to war about his experience, and chances
    are we''ll say we don''t want to talk about it—implying that we hated it so much,
    it was so terrible, that we would rather leave it buried. And it is no mystery
    why men hate war. War is ugly, horrible, evil, and it is reasonable for men to
    hate all that. But I believe that most men who have been to war would have to
    admit, if they are honest, that somewhere inside themselves they loved it too,
    loved it as much as anything that has happened to them before or since. And how
    do you explain that to your wife, your children, your parents, or your friends?</p><p>...I
    spent most of my combat tour in Vietnam trudging through its jungles and rice
    paddies without incident, but I have seen enough of war to know that I never want
    to fight again, and that I would do everything in my power to keep my son from
    fighting. Then why, at the oddest times—when I am in a meeting or running errands,
    or on beautiful summer evenings, with the light fading and children playing around
    me—do my thoughts turn back fifteen years to a war I didn''t believe in and never
    wanted to fight? Why do I miss it?</p><p>I miss it because I loved it, loved it
    in strange and troubling ways. When I talk about loving war I don''t mean the
    romantic notion of war that once mesmerized generations raised on Walter Scott.
    What little was left of that was ground into the mud at Verdun and Passchendaele:
    honor and glory do not survive the machine gun. And it''s not the mindless bliss
    of martyrdom that sends Iranian teenagers armed with sticks against Iraqi tanks.
    Nor do I mean the sort of hysteria that can grip a whole country, the way during
    the Falklands war the English press inflamed the lust that lurks beneath the cool
    exterior of Britain. That is vicarious war, the thrill of participation without
    risk, the lust of the audience for blood. It is easily fanned, that lust; even
    the invasion of a tiny island like Grenada can do it. Like all lust, for as long
    as it lasts it dominates everything else; a nation''s other problems are seared
    away, a phenomenon exploited by kings, dictators, and presidents since civilization
    began.</p>'
- - https://www.amazon.com/Third-World-First-Singapore-1965-2000/dp/0060197765
  - ! '<em>From Third World to First: The Singapore Story—1965&endash;2000</em>'
  - Lee Kuan Yew
  - 2000-10-03
  - ''
  - ! '<p>Few gave tiny Singapore much chance of survival when it was granted independence
    in 1965. How is it, then, that today the former British colonial trading post
    is a thriving Asian metropolis with not only the world''s number one airline,
    best airport, and busiest port of trade, but also the world''s fourth-highest
    per capita real income?</p><p>The story of that transformation is told here by
    Singapore''s charismatic, controversial founding father, Lee Kuan Yew. Rising
    from a legacy of divisive colonialism, the devastation of the Second World War,
    and general poverty and disorder following the withdrawal of foreign forces, Singapore
    now is hailed as a city of the future. This miraculous history is dramatically
    recounted by the man who not only lived through it all but who fearlessly forged
    ahead and brought about most of these changes.</p><p>Delving deep into his own
    meticulous notes, as well as previously unpublished government papers and official
    records, Lee details the extraordinary efforts it took for an island city-state
    in Southeast Asia to survive at that time.</p><p>Lee explains how he and his cabinet
    colleagues finished off the communist threat to the fledgling state''s security
    and began the arduous process of nation building: forging basic infrastructural
    roads through a land that still consisted primarily of swamps, creating an army
    from a hitherto racially and ideologically divided population, stamping out the
    last vestiges of colonial-era corruption, providing mass public housing, and establishing
    a national airline and airport.</p><p>In this illuminating account, Lee writes
    frankly about his trenchant approach to political opponents and his often unorthodox
    views on human rights, democracy, and inherited intelligence, aiming always "to
    be correct, not politically correct." Nothing in Singapore escaped his watchful
    eye: whether choosing shrubs for the greening of the country, restoring the romance
    of the historic Raffles Hotel, or openly, unabashedly persuading young men to
    marry women as well educated as themselves. Today''s safe, tidy Singapore bears
    Lee''s unmistakable stamp, for which he is unapologetic: "If this is a nanny state,
    I am proud to have fostered one."</p><p>Though Lee''s domestic canvas in Singapore
    was small, his vigor and talent assured him a larger place in world affairs. With
    inimitable style, he brings history to life with cogent analyses of some of the
    greatest strategic issues of recent times and reveals how, over the years, he
    navigated the shifting tides of relations among America, China, and Taiwan, acting
    as confidant, sounding board, and messenger for them. He also includes candid,
    sometimes acerbic pen portraits of his political peers, including the indomitable
    Margaret Thatcher and Ronald Reagan, the poetry-spouting Jiang Zemin, and ideologues
    George Bush and Deng Xiaoping.</p><p>Lee also lifts the veil on his family life
    and writes tenderly of his wife and stalwart partner, Kwa Geok Choo, and of their
    pride in their three children—particularly the eldest son, Hsien Loong, who is
    now Singapore''s deputy prime minister.</p><p>For more than three decades, Lee
    Kuan Yew has been praised and vilified in equal measure, and he has established
    himself as a force impossible to ignore in Asian and international politics. <em>From
    Third World to First</em> offers readers a compelling glimpse into this visionary''s
    heart, soul, and mind.</p>'
- - https://www.newcriterion.com/issues/2006/4/a-science-fiction-writer-of-the-fifties
  - A science fiction writer of the Fifties
  - Brad Leithauser
  - 2006-04-01
  - ''
  - <p>II. When the Smoke Clears</p><p>The mind, that rambling bear, ransacks the
    sky<br/>In search of honey,<br/>Fish, berries, carrion. It minds no laws …<br/>As
    if the heavens were some canvas tent,<br/>It slashes through the firmament<br/>To
    prise up the sealed stores with its big paws.<br/></p><p>The mind, that sovereign
    camel, sees the sky<br/>For what it is:<br/>Each star a grain of sand along the
    vast<br/>Passage to that oasis where, below<br/>The pillared palms, the portico<br/>Of
    fronds, the soul may drink its fill at last.<br/></p><p>The mind, that gorgeous
    spider, webs the sky<br/>With lines so sheer<br/>They all but vanish, and yet
    star to star<br/>(Thread by considered thread) slowly entwines<br/>The universe
    in its designs—<br/>Un-earthing patterns where no patterns are.<br/></p><p>The
    mind, that termite, seems to shun the sky.<br/>It burrows down,<br/>Tunneling
    in upon that moment when,<br/>In Time—its element—will come a day<br/>The longest-shadowed
    tower sway,<br/>Unbroken sunlight fall to earth again.</p> <p>...DNA was unspooled
    in the year<br/>I was born, and the test-tube births<br/>Of cloned mammals emerged
    in a mere<br/>Half-century; it seems the earth's<br/>Future's now in the hands
    of a few<br/>Techies on a caffeinated all-nighter who<br/>Sift the gene-alphabet
    like Scrabble tiles<br/></p><p>And our computer geeks are revealed, at last,<br/>As
    those quick-handed, sidelined little mammals<br/>In the dinosaurs' long shadows—those
    least-<br/>Likely-to-succeed successors whose kingdom come<br/>Was the globe itself
    (an image best written down,<br/>Perhaps, beneath a streetlamp, late, in some<br/>Star-riddled
    Midwestern town).<br/></p><p>He wrote boys' books and intuitively<br/>Recognized
    that the real<br/>Realist isn't the one who details<br/>Lowdown heartland factories
    and farms<br/>As if they would last, but the one who affirms,<br/>From the other
    end of the galaxy,<br/>Ours is the age of perilous miracles.<br/></p></blockquote>
- - http://www.atlasobscura.com/articles/is-hansel-and-gretel-real
  - ! 'How a Literary Prank Convinced Germany That ''Hansel and Gretel'' Was Real:
    A 1963 book purported to prove that the siblings were murderous bakers'
  - Jordan Todorov
  - 2019-07-03
  - ''
  - <p>So one can imagine the furor in 1963 when a German writer claimed to have uncovered
    the real story behind the fairy tale.</p><p>According to <em>Die Wahrheit über
    Hänsel und Gretel</em> (<em>The Truth About Hansel and Gretel</em>), the two siblings
    were, in fact, adult brother and sister bakers, living in Germany during the mid-17th
    century. They murdered the witch, an ingenious confectioner in her own right,
    to steal her secret recipe for lebkuchen, a gingerbread-like traditional treat.
    The book published a facsimile of the recipe in question, as well as sensational
    photos of archaeological evidence.</p><p>...The media picked up the story and
    turned it into national news. "Book of the week? No, it's the book of the year,
    and maybe the century!" proclaimed the West German tabloid <em>Abendzeitung</em>
    in November 1963. The state-owned <em>East German Berliner Zeitung</em> came out
    with the headline "Hansel and Gretel—a duo of murderers?" and asked whether this
    could be "a criminal case from the early capitalist era." The news spread like
    wildfire not only in Germany, but abroad too. Foreign publishers, smelling a profit,
    began negotiating for the translation rights. School groups, some from neighboring
    Denmark, traveled to the Spessart woods in the states of Bavaria and Hesse to
    see the newly discovered foundations of the witch's house.</p><p>As intriguing
    as <em>The Truth About Hansel and Gretel</em> might sound, however, none of it
    proved to be true. In fact, the book turned out to be a literary forgery concocted
    by Hans Traxler, a German children's book writer and cartoonist, known for his
    sardonic sense of humor. "1963 marked the 100th anniversary of Jacob Grimm's death,"
    says the now 90-year-old Traxler, who lives in Frankfurt, Germany. "So it was
    natural to dig into [the] Brothers Grimm treasure chest of fairy tales, and pick
    their most famous one, 'Hansel and Gretel.'"</p>
- - /docs/philo/2004-wallace-considerthelobster.html
  - ! 'Consider the Lobster: For 56 years, the Maine Lobster Festival has been drawing
    crowds with the promise of sun, fun, and fine food. One visitor would argue that
    the celebration involves a whole lot more'
  - David Foster Wallace
  - 2004-08-01
  - ''
  - ! '<p>[Originally published in the August 2004 issue of <em>Gourmet</em> magazine,
    this review of the 2003 Maine Lobster Festival generated some controversy among
    the readers of the culinary magazine. The essay is concerned with the ethics of
    boiling a creature alive in order to enhance the consumer''s pleasure, including
    a discussion of lobster sensory neurons.]</p><p>A detail so obvious that most
    recipes don''t even bother to mention it is that each lobster is supposed to be
    alive when you put it in the kettle...Another alternative is to put the lobster
    in cold salt water and then very slowly bring it up to a full boil. Cooks who
    advocate this method are going mostly on the analogy to a frog, which can supposedly
    be kept from jumping out of a boiling pot by heating the water incrementally.
    In order to save a lot of research-summarizing, I''ll simply assure you that the
    analogy between frogs and lobsters turns out not to hold.</p><p>...So then here
    is a question that''s all but unavoidable at the World''s Largest Lobster Cooker,
    and may arise in kitchens across the U.S.: Is it all right to boil a sentient
    creature alive just for our gustatory pleasure? A related set of concerns: Is
    the previous question irksomely PC or sentimental? What does ''all right'' even
    mean in this context? Is it all just a matter of individual choice?</p><p>...As
    far as I can tell, my own main way of dealing with this conflict has been to avoid
    thinking about the whole unpleasant thing. I should add that it appears to me
    unlikely that many readers of gourmet wish to think hard about it, either, or
    to be queried about the morality of their eating habits in the pages of a culinary
    monthly. Since, however, the assigned subject of this article is what it was like
    to attend the 2003 MLF, and thus to spend several days in the midst of a great
    mass of Americans all eating lobster, and thus to be more or less impelled to
    think hard about lobster and the experience of buying and eating lobster, it turns
    out that there is no honest way to avoid certain moral questions.</p>'
- - https://story.californiasunday.com/cosmic-crisp-apple-launch
  - ! 'The Launch: Inside the ''largest launch of a produce item in American history'''
  - Brooke Jarvis
  - 2019-07-18
  - ''
  - ! '<p>In those early days, the company, just like almost everybody else in Washington,
    primarily produced Red Delicious apples, plus a few Goldens and Grannies—familiar
    workhorse varieties that anybody was allowed to grow. Back then, the state apple
    commission advertised its wares with a poster of a stoplight: one apple each in
    red, green, and yellow. Today, across more than 4,000 acres of McDougall apple
    trees, you won''t find a single Red; every year, you''ll also find fewer acres
    of the apples that McDougall calls "core varieties," the more modern open-access
    standards such as Gala and Fuji. Instead, McDougall is betting on what he calls
    "value-added apples": Ambrosias, whose rights he licensed from a Canadian company;
    Envy, Jazz, and Pacific Rose, whose intellectual properties are owned by the New
    Zealand giant Enzafruit; and a brand-new variety, commercially available for the
    first time this year and available only to Washington-state growers: the Cosmic
    Crisp.</p><p>...The Cosmic Crisp is debuting on grocery stores after this fall''s
    harvest, and in the nervous lead-up to the launch, everyone from nursery operators
    to marketers wanted me to understand the crazy scope of the thing: the scale of
    the plantings, the speed with which mountains of commercially untested fruit would
    be arriving on the market, the size of the capital risk. People kept saying things
    like "unprecedented," "on steroids," "off the friggin'' charts," and "the largest
    launch of a single produce item in American history."</p><p>McDougall took me
    to the highest part of his orchard, where we could look down at all its hundreds
    of very expensively trellised and irrigated acres (he estimated the costs to plant
    each individual acre at $60,000 to $65,000, plus another $12,000 in operating
    costs each year), their neat, thin lines of trees like the stitching over so many
    quilt squares. "If you''re a farmer, you''re a riverboat gambler anyway," McDougall
    said. "But Cosmic Crisp—woo!" I thought of the warning of one former fruit-industry
    journalist that, with so much on the line, the enormous launch would have to go
    flawlessly: "It''s gotta be like the new iPhone."</p><p>...Though Washington State
    University owns the WA 38 patent, the breeding program has received funding from
    the apple industry, so it was agreed, over some objections by people who worried
    that quality would be diluted, that the variety should be universally and exclusively
    available to Washington growers. (Growers of Cosmic Crisp pay royalties both on
    every tree they buy and on every box they sell, money that will fund future breeding
    projects as well as the shared marketing campaign.) The apple tested so well that
    WSU, in collaboration with commercial nurseries, began producing apple saplings
    as fast as possible; the plan was to start with 300,000 trees, but growers requested
    4 million, leading to a lottery for divvying up the first available trees. Within
    three years, the industry had sunk 13 million of them, plus more than half a billion
    dollars, into the ground. Proprietary Variety Management expects that the number
    of Cosmic Crisp apples on the market will grow by millions of boxes every year,
    outpacing Pink Lady and Honeycrisp within about five years of its launch.</p>'
- - https://www.nytimes.com/2007/08/12/magazine/12fonts-t.html
  - The Road to Clarity
  - Joshua Yaffa (<em>The New York Times</em>)
  - 2007-08-12
  - ''
  - ! '<p>Looking at a sign in Clearview after reading one in Highway Gothic is like
    putting on a new pair of reading glasses: there''s a sudden lightness, a noticeable
    crispness to the letters. The Federal Highway Administration granted Clearview
    interim approval in 2004, meaning that individual states are free to begin using
    it in all their road signs. More than 20 states have already adopted the typeface,
    replacing existing signs one by one as old ones wear out. Some places have been
    quicker to make the switch—much of Route I-80 in western Pennsylvania is marked
    by signs in Clearview, as are the roads around Dallas-Fort Worth International
    Airport—but it will very likely take decades for the rest of the country to finish
    the roadside makeover. It is a slow, almost imperceptible process. But eventually
    the entire country could be looking at Clearview.</p><p>...Meeker initially assumed
    that the solution to the nation''s highway sign problem lay in the clean utilitarian
    typefaces of Europe. One afternoon in the late fall of 1992, Meeker was sitting
    in his Larchmont office with a small team of designers and engineers. He suggested
    that the group get away from the computer screens and out of the office to see
    what actually worked in the open air at long distances. They grabbed all the roadsigns
    Meeker had printed—nearly 40 metal panels set in a dozen different fonts of varying
    weights—and headed across the street to the Larchmont train station, where they
    rested the signs along a railing. They then hiked to the top of a nearby hill.
    When they stopped and turned, they were standing a couple hundred feet from the
    lineup below. There was the original Highway Gothic; British Transport, the road
    typeface used in the United Kingdom; Univers, found in the Paris Metro and on
    Apple computer keyboards; DIN 1451, used on road and train signage in Germany;
    and also Helvetica, the classic sans-serif seen in modified versions on roadways
    in a number of European countries. "There was something wrong with each one,"
    Meeker remembers. "Nothing gave us the legibility we were looking for." The team
    immediately realized that it would have to draw something from scratch.</p>'
- - https://spqr.eecs.umich.edu/papers/Kwong-HDDphone-IEEE-SP-2019.pdf
  - ! 'Hard Drive of Hearing: Disks that Eavesdrop with a Synthesized Microphone'
  - Andrew Kwong, Wenyuan Xu, Kevin Fu
  - 2019-05-01
  - 10.1145/2903140
  - Security conscious individuals may take considerable measures to disable sensors
    in order to protect their privacy. However, they often overlook the cyber-physical
    attack surface exposed by devices that were never designed to be sensors in the
    first place. Our research demonstrates that the mechanical components in magnetic
    hard disk drives behave as microphones with sufficient precision to extract and
    parse human speech. These unintentional microphones sense speech with high enough
    fidelity for the Shazam service to recognize a song recorded through the hard
    drive. This proof of concept attack sheds light on the possibility of invasion
    of privacy even in absence of traditional sensors. We also present defense mechanisms,
    such as the use of ultrasonic aliasing, that can mitigate acoustic eavesdropping
    by synthesized microphones in hard disk drives.
- - https://www.ribbonfarm.com/2012/03/08/halls-law-the-nineteenth-century-prequel-to-moores-law/
  - ! 'Hall''s Law: The Nineteenth Century Prequel to Moore''s Law'
  - Venkatesh Rao
  - 2012-03-08
  - ''
  - ! '<p>[Coins "Hall''s law": "the maximum complexity of artifacts that can be manufactured
    at scales limited only by resource availability doubles every 10 years." Economic
    history discussion of industrialization: the replacement of esoteric artisanal
    knowledge, based on trial-and-error and epitomized by a classic Sheffield steel
    recipe which calls for adding 4 white onions to iron, by formalized, specialized,
    rationalized processes such as interchangeable parts in a rifle produced by a
    factory system, which can create standardized parts at larger scales than craft-based
    processes, on which other systems can be built (once a reliable controlled source
    of parts exists). Examples include British gun-making, John Hall, the Montgomery
    Ward catalogue.]</p><p>I believe this law held between 1825 and 1960, at which
    point the law hit its natural limits. Here, I mean complexity in the loose sense
    I defined before: some function of mechanical complexity and operating tempo of
    the machine, analogous to the transistor count and clock-rate of chips. I don''t
    have empirical data to accurately estimate the doubling period, but 10 years is
    my initial guess, based on the anecdotal descriptions from Morris'' book and the
    descriptions of the increasing presence of technology in the world fairs. Along
    the complexity dimension, mass-produced goods increased rapidly got more complex,
    from guns with a few dozen parts to late-model steam engines with thousands. The
    progress on the consumer front was no less impressive, with the Montgomery Ward
    catalog offering mass-produced pianos within a few years of its introduction for
    instance. By the turn of the century, you could buy entire houses in mail-order
    kit form. The cost of everything was collapsing. Along the tempo dimension, everything
    got relentlessly faster as well. Somewhere along the way, things got so fast thanks
    to trains and the telegraph, that time zones had to be invented and people had
    to start paying attention the second hand on clocks.</p><p>...History is repeating
    itself. And the rerun episode we are living right now is not a pleasant one. The
    problem with history repeating itself of course, is that sometimes it does not.
    The fact that 1819–1880 map pretty well to 1959–2012 does not mean that 2012–2112
    will map to 1880–1980. Many things are different this time around. But assuming
    history <em>does</em> repeat itself, what are we in for? If the Moore''s Law endgame
    is the same century-long economic-overdrive that was the Hall''s Law endgame,
    today''s kids will enter the adult world with prosperity and a fully-diffused
    Moore''s Law all around them. The children will do well. In the long term, things
    will look up. But in the long term, you and I will be dead.</p>'
- - https://www.newyorker.com/magazine/1987/02/23/atchafalaya
  - Atchafalaya
  - John McPhee
  - 1987-02-15
  - ''
  - ! '[A study of the Mississippi River, its history, and efforts by the U.S. Army
    Corps of Engineers to hold it in place.] It was published in February, 1987, and
    it''s about the Herculean effort of the U.S. Army Corps of Engineers to control
    the flow of the Mississippi River, the fourth-longest river in the world. "Atchafalaya"
    is the name of the "distributary waterscape" that threatens to capture and redirect
    the flow of the Mississippi. If that happens, the cities and industrial centers
    of Southern Louisiana could find themselves sitting, uselessly, next to a "tidal
    creek," and economic ruin would be the inevitable result. To prevent that, the
    Corps of Engineers embarks on a vast project to artificially freeze the naturally
    shifting landscape. McPhee meets the engineers and explores the structures they''ve
    built to "preserve 1950 ... in perpetuity."... Like the Mississippi, "Atchafalaya"
    is long—around twenty-seven thousand words. But it''s all available online, and
    it gives you a real sense of what it''s like not just to live and work beside
    one of the world''s great rivers but actually to struggle with it.'
- - https://rootsofprogress.org/why-did-we-wait-so-long-for-the-bicycle
  - Why did we wait so long for the bicycle?
  - Jason Crawford
  - 2019-07-13
  - ''
  - <p>The bicycle, as we know it today, was not invented until the late 1800s. Yet
    it was a simple mechanical invention. It would seem to require no brilliant inventive
    insight, and certainly no scientific background.</p><p>...Technology factors are
    more convincing to me. They may have been necessary for bicycles to become practical
    and cheap enough to take off. But they weren't needed for early experimentation.
    Frames can be built of wood. Wheels can be rimmed with metal. Gears can be omitted.
    Chains can be replaced with belts; some early designs even used treadles instead
    of pedals, and at least one design drove the wheels with levers, as on a steam
    locomotive. So what's the real explanation?</p><p>First, the correct design was
    not obvious. For centuries, progress was stalled because inventors were all trying
    to create multi-person four-wheeled carriages, rather than single-person two-wheeled
    vehicles. It's unclear why this was; certainly inventors were copying an existing
    mode of transportation, but why would they draw inspiration only from the horse-and-carriage,
    and not from the horse-and-rider? (Some commenters have suggested that it was
    not obvious that a two-wheeled vehicle would balance, but I find this unconvincing
    given how many other things people have learned to balance on, from dugout canoes
    to horses themselves.) It's possible (I'm purely speculating here) that early
    mechanical inventors had a harder time realizing the fundamental impracticability
    of the carriage design because they didn't have much in the way of mathematical
    engineering principles to go on, but then again it's unclear what led to Drais's
    breakthrough. And even after Drais hit on the two-wheeled design, it took multiple
    iterations, which happened over decades, to get to a design that was efficient,
    comfortable, and safe.</p><p>...But we can go deeper, and ask the questions that
    inspired my intense interest in this question in the first place. Why was no one
    even experimenting with two-wheeled vehicles until the 1800s? And why was no one,
    as far as we know, even considering the question of human-powered vehicles until
    the 1400s? Why weren't there bicycle mechanics in the 1300s, when there were clockmakers,
    or at least by the 1500s, when we had watches? Or among the ancient Romans, who
    built water mills and harvesting machines? Or the Greeks, who built the Antikythera
    mechanism ? Even if they didn't have tires and chains, why weren't these societies
    at least experimenting with draisines? Or even the failed carriage designs?</p>
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2495396/pdf/postmedj00315-0056.pdf
  - Features of a successful therapeutic fast of 382 days' duration
  - Stewart & Fleming
  - 1973-03-01
  - 10.1136/pgmj.49.569.203
  - <p>A 27-year-old male patient fasted under supervision for 382 days and has subsequently
    maintained his normal weight. Blood glucose concentrations around 30 mg/100 ml
    were recorded consistently during the last 8 months, although the patient was
    ambulant and attending as an out-patient. Responses to glucose and tolbutamide
    tolerance tests remained normal. The hyperglycaemic response to glucagon was reduced
    and latterly absent, but promptly returned to normal during carbohydrate refeeding.
    After an initial decrease was corrected, plasma potassium levels remained normal
    without supplementation. A temporary period of hypercalcaemia occurred towards
    the end of the fast. Decreased plasma magnesium concentrations were a consistent
    feature from the first month onwards. After 100 days of fasting there was a marked
    and persistent increase in the excretion of urinary cations and inorganic phosphate,
    which until then had been minimal. These increases may be due to dissolution of
    excessive soft tissue and skeletal mass. Prolonged fasting in this patient had
    no ill-effects.</p><p>...During the 382 days of the fast, the patient's weight
    decreased from 456 to 180lb. Five years after undertaking the fast, Mr A.B.'s
    weight remains around 196lb...The amount of weight lost and the rate of loss were
    not strikingly different from that of an earlier patient (Stewart, Fleming & Robertson,
    1966) who reduced his weight from 432 to 235lb during 350 days of intermittent
    starvation.</p><p>...We wish to express our gratitude to Mr A.B. for his cheerful
    cooperation and steadfast application to the task of achieving a normal physique.</p>
- - /docs/psychology/2019-letexier.pdf
  - Debunking the Stanford Prison Experiment
  - Thibault Le Texier
  - 2019-08-05
  - 10.1037/amp0000401
  - ! 'The Stanford Prison Experiment (SPE) is one of psychology''s most famous studies.
    It has been criticized on many grounds, and yet a majority of textbook authors
    have ignored these criticisms in their discussions of the SPE, thereby misleading
    both students and the general public about the study''s questionable scientific
    validity. Data collected from a thorough investigation of the SPE archives and
    interviews with 15 of the participants in the experiment further question the
    study''s scientific merit. These data are not only supportive of previous criticisms
    of the SPE, such as the presence of demand characteristics, but provide new criticisms
    of the SPE based on heretofore unknown information. These new criticisms include
    the biased and incomplete collection of data, the extent to which the SPE drew
    on a prison experiment devised and conducted by students in one of Zimbardo''s
    classes 3 months earlier, the fact that the guards received precise instructions
    regarding the treatment of the prisoners, the fact that the guards were not told
    they were subjects, and the fact that participants were almost never completely
    immersed by the situation. Possible explanations of the inaccurate textbook portrayal
    and general misperception of the SPE''s scientific validity over the past 5 decades,
    in spite of its flaws and shortcomings, are discussed. [Keywords: Stanford Prison
    Experiment, Zimbardo, epistemology]'
- - https://harpers.org/archive/2013/09/the-devils-bait/?single=1
  - ! 'The Devil''s Bait: Symptoms, signs, and the riddle of Morgellons'
  - Leslie Jamison (<em>Harper's Magazine</em>)
  - 2013-09-01
  - ''
  - ! '<p>For Paul, it started with a fishing trip. For Lenny, it was an addict whose
    knuckles were covered in sores. Dawn found pimples clustered around her swimming
    goggles. Kendra noticed ingrown hairs. Patricia was attacked by sand flies on
    a Gulf Coast beach. Sometimes the sickness starts as blisters, or lesions, or
    itching, or simply a terrible fog settling over the mind, over the world.</p><p>For
    me, Morgellons disease started as a novelty: people said they had a strange ailment,
    and no one—or hardly anyone—believed them. But there were a lot of them, reportedly
    12,000, and their numbers were growing. Their illness manifested in many ways,
    including fatigue, pain, and formication (a sensation of insects crawling over
    the skin). But the defining symptom was always the same: fibers emerging from
    their bodies. Not just fibers but fuzz, specks, and crystals. They didn''t know
    what this stuff was, or where it came from, or why it was there, but they knew—and
    this was what mattered, the important word—that it was real.</p><p>...Browne''s
    "harsh hairs" were the early ancestors of today''s fibers. Photos online show
    them in red, white, and blue—like the flag—and also black and translucent. These
    fibers are the kind of thing you describe in relation to other kinds of things:
    jellyfish or wires, animal fur or taffy candy or a fuzzball off your grandma''s
    sweater. Some are called goldenheads, because they have a golden-colored bulb.
    Others simply look sinister, technological, tangled.</p><p>Patients started bringing
    these threads and flecks and fuzz to their doctors, storing them in Tupperware
    or matchboxes, and dermatologists actually developed a term for this phenomenon.
    They called it "the matchbox sign", an indication that patients had become so
    determined to prove their disease that they might be willing to produce fake evidence.</p><p>...This
    isn''t an essay about whether Morgellons disease is real. That''s probably obvious
    by now. It''s an essay about what kinds of reality are considered prerequisites
    for compassion. It''s about this strange sympathetic limbo: Is it wrong to speak
    of empathy when you trust the fact of suffering but not the source?</p>'
- - https://www.thecut.com/2019/07/what-happens-when-lyme-disease-becomes-an-identity.html
  - ! 'Maybe It''s Lyme: What happens when illness becomes an identity?'
  - Molly Fischer (<em>The Cut</em>)
  - 2019-07-24
  - ''
  - ! '<p>This is the rallying cry of the Lyme Warrior. Spend a while browsing <code>#lymewarrior</code>
    on Instagram and what you find looks like wellness content at first. There are
    selfies, shots of food, talk of toxins, exhortations toward self-care. There are
    more extensive arrays of supplements than you might expect. Then the IVs snake
    into view. There are hospital gowns and seats at outpatient-treatment centers
    and surgically implanted ports displayed with pride. This is wellness predicated
    on the constant certainty that all is not well. Like Hadid, the Lyme Warriors
    struggle against those who would doubt their condition, and, like Hadid, they
    are firm in their resolve. They have a name, and they have each other.</p><p>Where
    Murray sought to answer a question, the warrior who now takes up the cause of
    chronic Lyme is seeking to affirm an answer. For this community of patients, Lyme
    has come to function as something more expansive than a diagnosis. While Lyme
    disease is a specific medical condition—one that may manifest more severely or
    less, be treated more easily or less—chronic Lyme is something else altogether.
    (The medical establishment generally avoids using the term <em>chronic Lyme</em>,
    and because of this establishment wariness, advocates who believe Lyme is a chronic
    infection now sometimes advise patients to avoid it too.) This version of Lyme
    has no consistent symptoms, no fixed criteria, and no accurate test. This Lyme
    is a kind of identity. Lyme is a label for a state of being, a word that conveys
    your understanding of your lived experience. Lyme provides the language to articulate
    that experience and join with others who share it. In the world of chronic Lyme,
    doctors are trustworthy (or not) based on their willingness to treat Lyme. Tests
    are trustworthy (or not) based on their ability to confirm Lyme. Lyme is the fundamental
    fact, and you work backward from there. Lyme is a community with a cause: the
    recognition of its sufferers'' suffering—and, with it, the recognition of Lyme.</p>'
- - http://gershmanlab.webfactional.com/pubs/GenerativeAdversarialBrain.pdf
  - The Generative Adversarial Brain
  - Samuel J. Gershman
  - 2019-07-21
  - ''
  - ! '<p>The idea that the brain learns generative models of the world has been widely
    promulgated. Most approaches have assumed that the brain learns an explicit density
    model that assigns a probability to each possible state of the world. However,
    explicit density models are difficult to learn, requiring approximate inference
    techniques that may find poor solutions. An alternative approach is to learn an
    implicit density model that can sample from the generative model without evaluating
    the probabilities of those samples. The implicit model can be trained to fool
    a discriminator into believing that the samples are real. This is the idea behind
    generative adversarial algorithms, which have proven adept at learning realistic
    generative models. This paper develops an adversarial framework for probabilistic
    computation in the brain. It first considers how generative adversarial algorithms
    overcome some of the problems that vex prior theories based on explicit density
    models. It then discusses the psychological and neural evidence for this framework,
    as well as how the breakdown of the generator and discriminator could lead to
    delusions observed in some mental disorders.</p><p>...Our sensory inputs are impoverished,
    and yet our experience of the world feels richly detailed. For example, our fovea
    permits us access to a high fidelity region of the visual field only twice the
    size of our thumbnail held at arm''s length. But we don''t experience the world
    as though looking through a tiny aperture. Instead, our brains feed us a "grand
    illusion" of panoptic vision (Chater, 2018; Noe et al., 2000; Odegaard et al.,
    2018). Similarly, we receive no visual input in the region of the retina that
    connects to the optic nerve, yet under normal circumstances we are unaware of
    this blind spot. Moreover, even when we receive high fidelity visual input, we
    may still fail to witness dramatic changes in scenes (Simons, 2000), as though
    our brains have contrived imaginary scenes that displace the true scenes.</p><p>...First,
    how can we explain the phenomenology of illusion: why do some illusions feel real,
    as though one is actually seeing them, whereas other inferences carry information
    content without the same perceptual experience. For example, Ramachandran and
    Hirstein (1997) use the example of gazing at wallpaper in a bathroom, where the
    wallpaper in your visual periphery is ''filled in'' (you subjectively experience
    it as high fidelity even though objectively you perceive it with low fidelity),
    but the wallpaper behind your head is not filled in. In other words, you infer
    that the wallpaper continues behind your head, and you may even know this with
    high confidence, but you do not have the experience of seeing the wallpaper behind
    your head. Thus, the vividness or "realness" of perceptual experience is not a
    simple function of belief strength. So what is it a function of? Second, how can
    we explain the peculiar ways that the inferential apparatus breaks down? In particular,
    how can we understand the origins of delusions, hallucinations, and confabulations
    that arise in certain mental disorders? While Bayesian models have been developed
    to explain these phenomena, they fall short in certain ways that we discuss later
    on.</p>'
- - https://qualiacomputing.com/2019/08/10/logarithmic-scales-of-pleasure-and-pain-rating-ranking-and-comparing-peak-experiences-suggest-the-existence-of-long-tails-for-bliss-and-suffering/
  - ! 'Logarithmic Scales of Pleasure and Pain: Rating, Ranking, and Comparing Peak
    Experiences Suggest the Existence of Long Tails for Bliss and Suffering'
  - Qualia Computing
  - 2019-08-10
  - ''
  - ! '<p>Based on: the characteristic distribution of neural activity, personal accounts
    of intense pleasure and pain, the way various pain scales have been described
    by their creators, and the results of a pilot study we conducted which ranks,
    rates, and compares the hedonic quality of extreme experiences, we suggest that
    the best way to interpret pleasure and pain scales is by thinking of them as logarithmic
    compressions of what is truly a long-tail. The most intense pains are orders of
    magnitude more awful than mild pains (and symmetrically for pleasure).</p><p>This
    should inform the way we prioritize altruistic interventions and plan for a better
    future. Since the bulk of suffering is concentrated in a small percentage of experiences,
    focusing our efforts on preventing cases of intense suffering likely dominates
    most utilitarian calculations.</p><p>An important pragmatic takeaway from this
    article is that if one is trying to select an effective career path, as a heuristic
    it would be good to take into account how one''s efforts would cash out in the
    prevention of extreme suffering (see: ''Hell-Index''), rather than just QALYs
    and wellness indices that ignore the long-tail. Of particular note as promising
    Effective Altruist careers, we would highlight working directly to develop remedies
    for specific, extremely painful experiences. Finding scalable treatments for migraines,
    kidney stones, childbirth, cluster headaches, CRPS, and fibromyalgia may be extremely
    high-impact (cf. ''Treating Cluster Headaches and Migraines Using N,N-DMT and
    Other Tryptamines'', ''Using Ibogaine to Create Friendlier Opioids'', and ''Frequency
    Specific Microcurrent for Kidney-Stone Pain''). More research efforts into identifying
    and quantifying intense suffering currently unaddressed would also be extremely
    helpful. Finally, if the positive valence scale also has a long-tail, focusing
    one''s career in developing bliss technologies may pay-off in surprisingly good
    ways (whereby you may stumble on methods to generate high-valence healing experiences
    which are orders of magnitude better than you thought were possible). [Keywords:
    consciousness research, Effective Altruism, ethics, Hedonic Tone, meaning, psychedelic,
    sex, spirituality, valence]</p>'
- - http://www.structuredprocrastination.com/
  - Structured Procrastination
  - John Perry
  - 1996-02-23
  - ''
  - <p>All procrastinators put off things they have to do. Structured procrastination
    is the art of making this bad trait work for you. The key idea is that procrastinating
    does not mean doing absolutely nothing. Procrastinators seldom do absolutely nothing;
    they do marginally useful things, like gardening or sharpening pencils or making
    a diagram of how they will reorganize their files when they get around to it.
    Why does the procrastinator do these things? Because they are a way of not doing
    something more important. If all the procrastinator had left to do was to sharpen
    some pencils, no force on earth could get him do it. However, the procrastinator
    can be motivated to do difficult, timely and important tasks, as long as these
    tasks are a way of not doing something more important.</p><p>Structured procrastination
    means shaping the structure of the tasks one has to do in a way that exploits
    this fact. The list of tasks one has in mind will be ordered by importance. Tasks
    that seem most urgent and important are on top. But there are also worthwhile
    tasks to perform lower down on the list. Doing these tasks becomes a way of not
    doing the things higher up on the list. With this sort of appropriate task structure,
    the procrastinator becomes a useful citizen. Indeed, the procrastinator can even
    acquire, as I have, a reputation for getting a lot done.</p>
- - https://sites.duke.edu/tomasellolabduke/files/2016/09/Herrmann_PsychScience_2010.pdf#page=4
  - The Structure of Individual Differences in the Cognitive Abilities of Children
    and Chimpanzees
  - Esther Herrmann, Maria Victoria Hernández-Lloreda, Josep Call, Brian Hare, Michael
    Tomasello
  - 2010-01-01
  - 10.1177/0956797609356511
  - ! 'Most studies of animal cognition focus on group performance and neglect individual
    differences and the correlational structure of cognitive abilities. Moreover,
    no previous studies have compared the correlational structure of cognitive abilities
    in nonhuman animals and humans. We compared the structure of individual differences
    of 106 chimpanzees and 105 two-year-old human children using 15 cognitive tasks
    that posed problems about the physical or social world. We found a similar factor
    of spatial cognition for the two species. But whereas the chimpanzees had only
    a single factor in addition to spatial cognition, the children had two distinct
    additional factors: one for physical cognition and one for social cognition. These
    findings, in combination with previous research, support the proposal that humans
    share many cognitive skills with nonhuman apes, especially for dealing with the
    physical world, but in addition have evolved some specialized skills of social
    cognition. [Keywords: individual differences, chimpanzees, human children, social
    cognition, physical cognition]'
- - https://sites.duke.edu/tomasellolabduke/files/2016/09/Herrmann_PsychScience_2010.pdf
  - The Structure of Individual Differences in the Cognitive Abilities of Children
    and Chimpanzees
  - Esther Herrmann, Maria Victoria Hernández-Lloreda, Josep Call, Brian Hare, Michael
    Tomasello
  - 2010-01-01
  - 10.1177/0956797609356511
  - ! 'Most studies of animal cognition focus on group performance and neglect individual
    differences and the correlational structure of cognitive abilities. Moreover,
    no previous studies have compared the correlational structure of cognitive abilities
    in nonhuman animals and humans. We compared the structure of individual differences
    of 106 chimpanzees and 105 two-year-old human children using 15 cognitive tasks
    that posed problems about the physical or social world. We found a similar factor
    of spatial cognition for the two species. But whereas the chimpanzees had only
    a single factor in addition to spatial cognition, the children had two distinct
    additional factors: one for physical cognition and one for social cognition. These
    findings, in combination with previous research, support the proposal that humans
    share many cognitive skills with nonhuman apes, especially for dealing with the
    physical world, but in addition have evolved some specialized skills of social
    cognition. [Keywords: individual differences, chimpanzees, human children, social
    cognition, physical cognition]'
- - /docs/psychology/1992-rymer.pdf
  - A Silent Childhood
  - Rymer (<em>The New Yorker</em>)
  - 1992-04-13
  - ''
  - ! '''Annals Of Science'' about a case of child abuse in which a child named Genie
    was kept isolated from the world, locked in a restraining harness in a silent
    bedroom in her parent''s house in Temple City, California. She was either harnessed
    to an infant''s potty chair, unable to move anything except her fingers and hands,
    feet and toes, she was left to sit, tied-up, hour after hour, often into the night,
    day after day, month after month, year after year. At night, when Genie was not
    forgotten, she was placed into another restraining garment—a sleeping bag which
    her father had fashioned to hold Genie''s arms stationary. In effect, it was a
    straight jacket. Describes her environment, and the "toys" she was given to "play"
    with. Because of two plastic raincoats that were sometimes hung in the room, she
    had an inordinate fondness for anything plastic. She was incarcerated by her father
    for 11 1/2 of the first 13 years of her life in a silent room. She could not speak
    when she was rescued, and only learned to talk when she reached the hospital.
    Tells about the fallout, both in human terms and legally, surrounding the research
    into her linguistic abilities. Investigations of Genie''s brain unveiled the utter
    dominance of her "spatial" right hemisphere over her "linguistic" left... This
    may have been why she was unable to grasp grammar—because she was using the wrong
    equipment... From the misfortunes of brain-damaged people, it is clear that language
    tasks are dispersed within their left-hemisphere home. Someone whose brain is
    injured above the left ear will still be able to speak, but there will be no idea
    behind the word strings... Tells about a suit her mother, Irene, brought against
    the hospital when her therapy sessions with hospital staff were included in research
    results by Susan Curtiss, a graduate student studying Genie. The results of Curtiss''s
    doctorate study seemed to both confirm and deny linguist Noam Chomsky''s theory
    about language acquisition. Genie was shuttled from foster home to foster home
    after the scientists at the hospital (including the head of research, David Rigler,
    who adopted her for four years) ran out of grant money. She is currently institutionalized
    in an adult home for the mentally retarded, and in the words of one scientist,
    Jay Shurley, filled with a soul-sickness, and sinking into an apparent'' replica
    of an organic dementia.'
- - https://www.perell.com/blog/peter-thiel
  - Peter Thiel's Religion
  - David Perell
  - 2019-08-04
  - ''
  - ! '<p>We''ll study religion through the lens of Peter Thiel. He''s an investor
    who found wealth in PayPal, a student who found wisdom in Libertarian ideals,
    and a philosopher who found faith in the resurrection of Jesus Christ. Thiel was
    raised as an Evangelical and inherited the Christianity of his parents. But his
    beliefs are "somewhat heterodox." In a profile in the New Yorker, Thiel said:
    "I believe Christianity to be true. I don''t feel a compelling need to convince
    other people of that."</p> <p>Three simple statements will lead us towards our
    ultimate answer about the importance of religion:</p> <ol type="1"> <li>Don''t
    copy your neighbors</li> <li>Time moves forward</li> <li>The future will be different
    from the present</li> </ol> <p>Rather than focusing on Thiel''s actions, I''ve
    chosen to focus on his ideas. First, we''ll explore the principles of Peter Thiel''s
    worldview. We''ll begin by explaining Thiel''s connection to a French philosopher
    named Rene Girard. We''ll return to old books like The Bible, old ideas like sacrifice,
    and old writers like Shakespeare, and see why this ancient wisdom holds clues
    for modern life. Then, we''ll return to the tenets of the Christian story. We''ll
    cover the shift from cyclical time to linear time, which was spurred by technological
    development and human progress. We''ll see why the last book in The Bible,The
    Book of Revelation, is a core pillar of Thiel''s philosophy. Then, we''ll close
    with Thiel''s advice and wisdom almost as old as Cain and Abel: the Ten Commandments.</p>
    <p>...Mimetic conflict emerges when two people desire the same, scarce resource.
    Like lions in a cage, we mirror our enemies, fight because of our sameness, and
    ascend status hierarchies instead of providing value for society. Only by observing
    others do we learn how and what to desire. Our Mimetic nature is simultaneously
    our biggest strength and biggest weakness. When it goes right, imitation is a
    shortcut to learning. But when it spirals out of control, Mimetic imitation leads
    to envy, violence, and bitter, ever-escalating violence...Girard observed that
    even when you put a group of kids together in a room full of toys, they''ll inevitably
    desire the same toy instead of finding their own toy to play with. A rivalry will
    emerge. Human see, human want.</p> <p>...Here''s what I do know: Thiel is trying
    to save the world from apocalypse. The Book of Revelation paints two outcomes
    for the future of humanity: catastrophic apocalypse or a new heaven and a new
    earth...The probability of a civilization-ending apocalypse is increasing. Just
    because we no longer believe that Zeus can strike humans with sky-lighting thunderbolts,
    doesn''t mean that existential risk isn''t possible. Like Girard, he worries that
    the world is becoming more Mimetic. Worse, globalization is raising the threat
    of runaway mimesis and an apocalyptic world with cold corpses, dead horses, and
    splintered guns.</p> <p>...Christianity promises a Living Hope that enables believers
    to endure unimaginable suffering. A hope so resilient that like a Captain America''s
    shield, it can survive any evil, any sickness, or any torture. No matter the obstacles,
    certainty about the future gives you the confidence to act in the present. Thiel''s
    idea of Definite Optimism is Christian theology cloaked in secular language. By
    raising our spirits, a positive vision for the future unites society and raises
    our spirits. And that''s what the Western world needs right now. Technological
    growth is the best way to reduce suffering in the world. Technological progress
    has stagnated since the 1970s, which contributes to the vile political atmosphere
    and the pessimism of modern Westerners. Thiel says we should acknowledge our lack
    of progress, dream up a vision of Definite Optimism, and guided by Christian theology,
    work to make it a reality.</p>'
- - https://reddit.com/r/TheMotte/comments/ceajmw/book_review_from_third_world_to_first_by_lee_kuan/
  - ! 'Book Review: From Third World to First, by Lee Kuan Yew [PART ONE]'
  - TracingWoodgrains
  - 2019-07-17
  - ''
  - <p>What happens when you give an honest, capable person absolute power?</p> <p>In
    <em>From Third World to First</em>, Lee Kuan Yew, in characteristically blunt
    style, does his best to answer that question.</p> <p>Lee Kuan Yew's politics—and
    by extension Singapore's, because he really did define the country—are often,
    I feel, mischaracterized. In "We Sail Tonight For Singapore", for example, Scott
    Alexander characterizes it as reactionary. This is agreeable to the American left,
    because it's run so differently to Western liberal ideals, and agreeable to reactionaries,
    because Singapore is preternaturally successful by almost any metric you care
    to use.</p> <p>The only problem is that the claim reflects almost nothing about
    how Lee Kuan Yew actually ran the country or who he was.</p> <p>I get the impression
    it's a mistake to frame Singapore alongside a partisan political axis at all,
    because the second you do, half of what the country does will seem bizarre. Lee,
    personally, is open about his party's aim to claim the middle ground, opposed
    by "only the extreme left and right." (111) With that in mind, what works best
    to predict Lee's choices? In his telling, he is guided continually by a sort of
    ruthless pragmatism. Will a policy increase the standard of living in the country?
    Will it make the citizens more self-sufficient, more capable, or safer? Ultimately,
    does it work? Oh, and does it make everybody furious?</p> <p>Great, do that.</p>
    <p><em>From Third World to First</em> is the single most compelling political
    work I've read, and I'd like to capture as much of Lee's style and ideology as
    possible. He divides the book (or at least the half I'm reviewing; I'll leave
    his thoughts on world affairs alone because there's so much to cover as is) into
    sections based on specific policy problems and how he approached them. I'll focus
    my attention on a few:</p> <ul> <li>Citizen welfare &amp; development</li> <li>Free
    speech &amp; free press</li> <li>Approach to political opposition</li> <li>Handling
    of racial &amp; cultural tensions</li> </ul>
- - https://reddit.com/r/TheMotte/comments/cgowu1/lee_kuan_yew_review_part_two_you_are_free_to_agree/
  - ! 'Lee Kuan Yew Review, Part Two: ''You are free to agree'''
  - TracingWoodgrains
  - 2019-07-23
  - ''
  - <p>Are you a fan of free speech? Are you eager for everyone to have a platform?
    Are you in favor of an open, unconstrained press? Lee Kuan Yew isn't, and he's
    probably poking fun at you.</p><p>...Here's a question. You're a tiny city-state
    occupying valuable territory, trying to stay independent. You are watching the
    cultural revolution sweep across the homeland of three-quarters of your people,
    and you keep noticing them funding your newspapers. Meanwhile, other superpowers
    are locked in an all-out ideological struggle with those forces, a struggle that's
    shaping policy around the whole world. The country's dominant English-language
    newspaper at the time of gaining independence was "owned by the British and actively
    promoted their interests."<sup>(185)</sup></p><p>What's the right level of freedom
    of press?...Dystopian information lockdown, or prudent defense against foreign
    influence and misinformation? LKY is convinced, rightly or not, that it is the
    latter. Read with modern US politics in mind, it's easy to compare it to deplatformings
    from tech websites, concerns about Russian infiltration of social media, or the
    controversies around fake news. The context changes, the challenges stay the same.</p>
- - https://reddit.com/r/TheMotte/comments/cjqd9i/lee_kuan_yew_review_part_three_race_language_and/
  - ! 'Lee Kuan Yew Review, Part Three: Race, Language, and Uncomfortable Questions'
  - TracingWoodgrains
  - 2019-07-30
  - ''
  - <p>Here's a tricky governing problem for you.</p><p>Imagine your country had historically
    encouraged a minority group to segregate into lower income communities with poor
    living conditions.</p><p>Picture, too, that that minority group had historically
    underperformed in school compared to others.</p><p>Say that your country had faced
    large-scale riots in the 1960s over concerns about perceived government discrimination
    and oppression.</p><p>To spice things up, let's add that they're the country's
    indigenous people, and that they speak a different language and practice a different
    faith than everybody else in the country.</p><p>...and that initially, they formed
    the vast majority of the military and the police force, and the majority in your
    much larger neighbor country. It's hardly going to mirror other countries exactly,
    after all.<sup>(12)</sup></p><p>How do you ensure justice for them and for all
    citizens?</p><p>Singapore has its advantages over other countries, true. It's...
    what was the quote?... "a single city with a beautiful natural harbor right smack
    in the middle of a fantastic chokepoint in one of the biggest trade routes in
    the world."<sup>1</sup></p><p>But demographically, it's <em>complicated</em>,
    to say the least.</p>
- - https://reddit.com/r/TheMotte/comments/cmoo25/lee_kuan_yew_review_part_four_the_pathway_to_power/
  - ! 'Lee Kuan Yew Review, Part Four: The Pathway to Power'
  - TracingWoodgrains
  - 2019-08-06
  - ''
  - ! 'So far, my review has mostly left out one massive elephant in the room. Lee
    Kuan Yew was Prime Minister of Singapore from 1959 to 1990. When he stepped down
    from office, he went straight into a close advisory role, sticking around the
    government in some official capacity until 2011. How was he in power so long?
    What was his approach to opposition and to political disagreements, beyond lawsuits?
    Where did he fall on the scale of democratically elected leader to dictator? As
    with every other topic, LKY is pretty candid about this all. The best place to
    start, though, is likely not with the overt political battles. Instead, I''ll
    focus where he focused early: the unions.'
- - https://medium.com/@deepmindsafetyresearch/designing-agent-incentives-to-avoid-reward-tampering-4380c1bb6cd
  - Designing agent incentives to avoid reward tampering
  - Tom Everitt, Ramana Kumar, Marcus Hutter
  - 2019-08-14
  - ''
  - <p>From an AI safety perspective, having a clear design principle and a crisp
    characterization of what problem it solves means that we don't have to guess which
    agents are safe. In this post and paper we describe how a design principle called
    'current-RF optimization' avoids the reward function tampering problem.</p><p>...One
    way to prevent the agent from tampering with the reward function is to isolate
    or encrypt the reward function. However, we do not expect such solutions to scale
    indefinitely with our agent's capabilities, as a sufficiently capable agent may
    find ways around most defenses. In our new paper, we describe a more principled
    way to fix the reward tampering problem. Rather than trying to protect the reward
    function, we <b>change the agent's incentives</b> for tampering with it.</p><p>The
    fix relies on a slight <b>change to the RL framework</b> that gives the agent
    query access to the reward function. In the rocks and diamonds environment, this
    can be done by specifying to the agent how the purple nodes describe the reward
    function.</p><p>Using query access to the reward function, we can design a model-based
    agent that uses the <b>current reward function</b> to evaluate rollouts of potential
    policies (a current-RF agent, for short). For example, in the rocks and diamonds
    environment, a current-RF agent will look at the current reward description, and
    at time 1 see that it should collect diamonds. This is the criteria by which it
    will choose its first action, which will be going upwards towards the diamond.
    Note that the reward description is still changeable, just as before. Still, the
    current-RF agent will not use the reward-tampering possibility, because it is
    focused on satisfying the current reward description.</p>
- - https://tinyletter.com/gwern
  - Gwern.net newsletter (TinyLetter subscription page)
  - Gwern Branwen
  - 2013-12-01
  - ''
  - Subscription page for the monthly gwern.net newsletter. There are monthly updates,
    which will include summaries of projects I've worked on that month (the same as
    the <a href="https://www.gwern.net/Changelog">changelog</a>), collations of links
    or discussions from <a href="https://www.reddit.com/r/gwern/">my subreddit</a>,
    and book/movie reviews. You can also browse <a href="https://www.gwern.net/tags/newsletter">the
    archives since December 2013</a>.
- - /tags/newsletter
  - Gwern.net newsletter archives
  - Gwern Branwen
  - 2013-12-01
  - ''
  - ! 'Newsletter tag: archive of all issues back to 2013 for the gwern.net newsletter
    (monthly updates, which will include summaries of projects I''ve worked on that
    month (the same as the <a href="https://www.gwern.net/Changelog">changelog</a>),
    collations of links or discussions from <a href="https://www.reddit.com/r/gwern/">my
    subreddit</a>, and book/movie reviews.)'
- - https://www.reddit.com/r/gwern/
  - /r/gwern subreddit
  - Gwern Branwen
  - 2018-10-01
  - ''
  - A subreddit for posting links of interest and also for announcing updates to gwern.net
    (which can be <a href="https://www.reddit.com/r/gwern/.rss">used as a RSS feed</a>).
    Submissions are categorized similar to the monthly newsletter and typically will
    be collated there.
- - https://idlewords.com/2010/03/scott_and_scurvy.htm
  - ! 'Scott and Scurvy: How the Cure for Scurvy Was Lost'
  - Maciej Ceglowski
  - 2010-06-03
  - ''
  - <p>[Scott's Antarctic expedition in 1911 was plagued by the disease scurvy, despite
    its having been "conquered in 1747, when the Scottish physician James Lind proved
    in one of the first controlled medical experiments that citrus fruits were an
    effective cure for the disease." How it all went wrong would make a case study
    for a philosophy of science class.</p><p>The British Admiralty switched their
    scurvy cure from lemon juice to lime juice in 1860. The new cure was much less
    effective, but by that time advances in technology meant that most sea voyages
    were so short that there was little or no danger of scurvy anyway. So poor Scott's
    expedition, as well as applying 'state-of-the-art' (i.e. wrong) cures, were falling
    back on a 'tried-and-true' remedy that in fact had been largely ineffective already
    for 50 years... without anyone noticing.]</p><p>An unfortunate series of accidents
    conspired with advances in technology to discredit the cure for scurvy. What had
    been a simple dietary deficiency became a subtle and unpredictable disease that
    could strike without warning. Over the course of fifty years, scurvy would return
    to torment not just Polar explorers, but thousands of infants born into wealthy
    European and American homes. And it would only be through blind luck that the
    actual cause of scurvy would be rediscovered, and vitamin C finally isolated,
    in 1932.</p><p>...So when the Admiralty began to replace lemon juice with an ineffective
    substitute in 1860, it took a long time for anyone to notice. In that year, naval
    authorities switched procurement from Mediterranean lemons to West Indian limes.
    The motives for this were mainly colonial—it was better to buy from British plantations
    than to continue importing lemons from Europe. Confusion in naming didn't help
    matters. Both "lemon" and "lime" were in use as a collective term for citrus,
    and though European lemons and sour limes are quite different fruits, their Latin
    names (<em>citrus medica</em>, var. <em>limonica</em> and <em>citrus medica</em>,
    var. <em>acida</em>) suggested that they were as closely related as green and
    red apples. Moreover, as there was a widespread belief that the antiscorbutic
    properties of lemons were due to their acidity, it made sense that the more acidic
    Caribbean limes would be even better at fighting the disease.</p><p>In this, the
    Navy was deceived. Tests on animals would later show that fresh lime juice has
    a quarter of the scurvy-fighting power of fresh lemon juice. And the lime juice
    being served to sailors was not fresh, but had spent long periods of time in settling
    tanks open to the air, and had been pumped through copper tubing. A 1918 animal
    experiment using representative samples of lime juice from the navy and merchant
    marine showed that the 'preventative' often lacked any antiscorbutic power at
    all.</p><p>By the 1870s, therefore, most British ships were sailing without protection
    against scurvy. Only speed and improved nutrition on land were preventing sailors
    from getting sick.</p><p>...In the course of writing this essay, I was tempted
    many times to pick a villain. Maybe the perfectly named Almroth Wright, who threw
    his considerable medical reputation behind the ptomaine theory and so delayed
    the proper re-understanding of scurvy for many years. Or the nameless Admiralty
    flunky who helped his career by championing the switch to West Indian limes. Or
    even poor Scott himself, sermonizing about the virtues of scientific progress
    while never conducting a proper experiment, taking dreadful risks, and showing
    a most unscientific reliance on pure grit to get his men out of any difficulty.</p><p>But
    the villain here is just good old human ignorance, that master of disguise. We
    tend to think that knowledge, once acquired, is something permanent. Instead,
    even holding on to it requires constant, careful effort.</p>
- - https://www.nytimes.com/2019/07/02/magazine/dead-pig-brains-reanimation.html
  - Scientists Are Giving Dead Brains New Life. What Could Go Wrong? In experiments
    on pig organs, scientists at Yale made a discovery that could someday challenge
    our understanding of what it means to die.
  - Matthew Shaer (<em>The New York Times</em>)
  - 2019-07-02
  - ''
  - ! '<p>In the course of his research, Sestan, an expert in developmental neurobiology,
    regularly ordered slices of animal and human brain tissue from various brain banks,
    which shipped the specimens to Yale in coolers full of ice. Sometimes the tissue
    arrived within three or four hours of the donor''s death. Sometimes it took more
    than a day. Still, Sestan and his team were able to culture, or grow, active cells
    from that tissue—tissue that was, for all practical purposes, entirely dead. In
    the right circumstances, they could actually keep the cells alive for several
    weeks at a stretch.</p><p>When I met with Sestan this spring, at his lab in New
    Haven, he took great care to stress that he was far from the only scientist to
    have noticed the phenomenon. "Lots of people knew this," he said. "Lots and lots."
    And yet he seems to have been one of the few to take these findings and push them
    forward: If you could restore activity to individual post-mortem brain cells,
    he reasoned to himself, what was to stop you from restoring activity to entire
    slices of post-mortem brain?</p><p>...The technical hurdles were immense: To perfuse
    a post-mortem brain, you would have to somehow run fluid through a maze of tiny
    capillaries that start to clot minutes after death. Everything, from the composition
    of the blood substitute to the speed of the fluid flow, would have to be calibrated
    perfectly. In 2015, Sestan struck up an email correspondence with John L. Robertson,
    a veterinarian and research professor in the department of biomedical engineering
    at Virginia Tech. For years, Robertson had been collaborating with a North Carolina
    company, BioMedInnovations, or BMI, on a system known as a CaVESWave—a perfusion
    machine capable of keeping kidneys, hearts and livers alive outside the body for
    long stretches. Eventually, Robertson and BMI hoped, the machine would replace
    cold storage as a way to preserve organs designated for transplants.</p><p>...By
    any measure, the contents of the paper Sestan and his team published in Nature
    this April were astonishing: Not only were Sestan and his team eventually able
    to maintain perfusion for six hours in the organs, but they managed to restore
    full metabolic function in most of the brain—the cells in the dead pig brains
    took oxygen and glucose and converted them into metabolites like carbon dioxide
    that are essential to life. "These findings," the scientists write, "show that,
    with the appropriate interventions, the large mammalian brain retains an underappreciated
    capacity for normothermic restoration of microcirculation and certain molecular
    and cellular functions multiple hours after circulatory arrest."</p><p>..."What''s
    happened, I''d argue," says Christof Koch, the president and chief scientist at
    the Allen Institute for Brain Science, "is that a lot of things about the brain
    that we once thought were irreversible have turned out not necessarily to be so."</p>'
- - https://nintil.com/bloom-sigma/
  - ! 'On Bloom''s two sigma problem: A systematic review of the effectiveness of
    mastery learning, tutoring, and direct instruction'
  - José Luis Ricón
  - 2019-07-28
  - ''
  - ! '<p>Is Bloom''s "Two Sigma" phenomenon real? If so, what do we do about it?</p><p>Educational
    psychologist Benjamin Bloom found that one-on-one tutoring using mastery learning
    led to a two sigma(!) improvement in student performance. The results were replicated.
    He asks in his paper that identified the "2 Sigma Problem": how do we achieve
    these results in conditions more practical (i.e., more scalable) than one-to-one
    tutoring?</p><p>In a related vein, this large-scale meta-analysis shows large
    (>0.5 Cohen''s <em>d</em>) effects from direct instruction using mastery learning.
    "Yet, despite the very large body of research supporting its effectiveness, DI
    has not been widely embraced or implemented."</p><p><ul> <li>The literatures examined
    here are full of small sample, non-randomized trials, and highly heterogeneous
    results.</li> <li>Tutoring in general, most likely, does not reach the 2-sigma
    level that Bloom suggested. Likewise, it''s unlikely that mastery learning provides
    a 1-sigma improvement. <ul> <li>But high quality tutors, and high quality software
    are likely able to reach a 2-sigma improvement and beyond. </li> </ul> </li> <li>All
    the methods (mastery learning, direct instruction, tutoring, software tutoring,
    deliberate practice, and spaced repetition) studied in this essay are found to
    work to various degrees, outlined below.</li> <li>This essay covers many kinds
    of subjects being taught, and likewise many groups (special education vs regular
    schools, college vs K-12). The effect sizes reported here are averages that serve
    as general guidance.</li> <li>The methods studied tend to be more effective for
    lower skilled students relative to the rest.</li> <li>The methods studied work
    at all levels of education, with the exception of direct instruction: There is
    no evidence to judge its effectiveness at the college level.</li> <li>The methods
    work substantially better when clear objectives and facts to be learned are set.
    There is little evidence of <a href="https://www.econlib.org/archives/2012/08/low_transfer_of.html">learning
    transfer</a>: Practicing or studying X subject does not improve much performance
    outside of X.</li> <li>There is some suggestive evidence that the underlying reasons
    these methods work are increased and repeated exposure to the material, the <a
    href="https://en.wikipedia.org/wiki/Testing_effect">testing effect</a>, and fine-grained
    feedback on performance in the case of tutoring.</li> <li>Long term studies tend
    to find evidence of a fade-out effect, effect sizes decrease over time. This is
    likely due to the skills being learned not being practiced.</li> </ul></p><p>Bloom
    noted that mastery learning had an effect size of around 1 (one sigma); while
    tutoring leads to <em>d</em>=2. This is mostly an outlier case.</p><p>Nonetheless,
    Bloom was on to something: Tutoring and mastery learning do have a degree of experimental
    support, and fortunately it seems that carefully designed software systems can
    completely replace the instructional side of traditional teaching, achieving better
    results, on par with one to one tutoring. However, designing them is a hard endeavour,
    and there is a motivational component of teachers that may not be as easily replicable
    purely by software.</p><p>Overall, it''s good news that the effects are present
    for younger and older students, and across subjects, but the effect sizes of tutoring,
    mastery learning or DI are not as good as they would seem from Bloom''s paper.
    That said, it is true that tutoring does have large effect sizes, and that properly
    designed software does as well. The DARPA case study shows what is possible with
    software tutoring, in the case the effect sizes went even beyond Bloom''s paper.</p>'
- - /docs/iq/2019-hegelund.pdf
  - ! 'The influence of familial factors on the association between IQ and educational
    and occupational achievement: A sibling approach'
  - Emilie Rune Hegelund, Trine Flensborg-Madsen, Jesper Dammeyer, Laust Hvas Mortensen,
    Erik Lykke Mortensen
  - 2019-06-04
  - 10.1016/j.paid.2019.05.045
  - ! 'The present register-based study investigated the influence of familial factors
    on the association of IQ with educational and occupational achievement among young
    men in Denmark. The study population comprised all men with at least one full
    brother where both the individual and his brothers were born from 1950 and appeared
    before a draft board in 1968–1984 and 1987–2015 (<em>n</em> = 364,193 individuals).
    Intelligence was measured by Børge Priens Prøve at age 18. Educational and occupational
    achievement were measured by grade point average (GPA) in lower secondary school,
    time to receiving social benefits at ages 18–30, and gross income at age 30. The
    statistical analyses comprised two distinct statistical analyses of the investigated
    associations: A conventional cohort analysis and a within-sibship analysis in
    which the association under investigation was analysed within siblings while keeping
    familial factors shared by siblings fixed. The results showed that an appreciable
    part of the associations of IQ with educational and occupational achievement could
    be attributed to familial factors shared by siblings. However, only the within
    sibling association between IQ and GPA in lower secondary school clearly differed
    from the association observed in the cohort analysis after covariates had been
    taken into account.'
- - https://www.econ.ku.dk/cebi/publikationer/working-papers/CEBI_WP_04-19.pdf
  - ! 'Cognitive Consequences Of Iodine Deficiency In Adolescence: Evidence From Salt
    Iodization In Denmark'
  - Benjamin Ly Serena
  - 2019-06-21
  - 10.2139/ssrn.3409795
  - ! 'Over the past three decades, many countries have introduced iodized salt policies
    to eradicate iodine deficiency. While it is well known that iodine deficiency
    in utero is detrimental to cognitive ability, little is known about the consequences
    of iodine deficiencies after birth. This paper examines the impact of iodine deficiency
    in adolescence on cognitive performance. I identify the causal effect of iodine
    deficiency quasi-experimentally using the introduction of iodized salt in Denmark.
    Denmark went from a ban on iodized salt before 1998 to a mandate after 2001, making
    it an ideal national experiment. Combining administrative records on high school
    grades over a thirty-year period with geographic variation in initial iodine deficiency,
    I find that salt iodization increases the Grade Point Averages of high school
    students by 6–9 percent of a standard deviation. This improvement is comparable
    to the benefits of more standard school achievement policies and at much lower
    costs. [Key words: Iodine Deficiency, Iodized Salt, Nutrition, Human Capital,
    Health]'
- - https://www.wired.com/2008/02/ff-seacowboys/
  - ! 'High Tech Cowboys of the Deep Seas: The Race to Save the Cougar Ace'
  - Joshua Davis
  - 2008-02-25
  - ''
  - ! '<p>[On July 23, 2006 the <em>Cougar Ace</em>, a 654-foot car carrier owned
    by Mitsui O.S.K. Lines, reported to the Coast Guard that they were taking on water
    and listing 80 degrees. The Singapore homeported vessel, carrying 4,813 vehicles,
    was en route to Vancouver B.C. In a dramatic rescue, the Coast Guard was able
    to successfully remove all 23 crewmembers from the ship. Joshua Davis of Wired
    tells the story of how a crew from Titan Salvage were able to save the ship, although
    they lost one of their own in the process.]</p><p>...At the worst possible moment,
    a large swell hits the <em>Cougar Ace</em> and rolls the ship even farther to
    port. Objects begin to slide across the deck. They pick up momentum and crash
    against the port-side walls as the ship dips farther. Wedged naked in the shower
    stall, Kyin is confronted by an undeniable fact: The <em>Cougar Ace</em> is capsizing.</p><p>He
    lunges for a towel and staggers into the hallway as the ship''s windmill-sized
    propeller spins out of the water. Throughout the ship, the other 22 crew members
    begin to lose their footing as the decks rear up. There are shouts and screams.
    Kyin escapes through a door into the damp night air. He''s barefoot and dripping
    wet, and the deck is now a slick metal ramp. In an instant, he''s skidding down
    the slope toward the Pacific. He slams into the railings and his left leg snaps,
    bone puncturing skin. He''s now draped naked and bleeding on the railing, which
    has dipped to within feet of the frigid ocean. The deck towers 105 feet above
    him like a giant wave about to break. Kyin starts to pray.</p><p>...Ship captains
    spend their careers trying to avoid a collision or grounding like this. But for
    Rich Habib, nearly every month brings a welcome disaster. While people are shouting
    "Abandon ship!" Habib is scrambling aboard. He''s been at sea since he was 18,
    and now, at 51, his tanned face, square jaw, and don''t-even-try-bullshitting-me
    stare convey a world-weary air of command. He holds an unlimited master''s license,
    which means he''s one of the select few who are qualified to pilot ships of any
    size, anywhere in the world. He spent his early years captaining hulking vessels
    that lifted other ships on board and hauled them across oceans. He helped the
    Navy transport a nuclear refueling facility from California to Hawaii. Now he''s
    the senior salvage master—the guy who runs the show at sea—for Titan Salvage,
    a highly specialized outfit of men who race around the world saving ships.</p><p>They''re
    a motley mix: American, British, Swedish, Panamanian. Each has a specialty—deep-sea
    diving, computer modeling, underwater welding, big-engine repair. And then there''s
    Habib, the guy who regularly helicopters onto the deck of a sinking ship, greets
    whatever crew is left, and takes command of the stricken vessel.</p><p>..The job
    is daunting: Board the <em>Cougar Ace</em> with the team and build an on-the-fly
    digital replica of the ship. The car carrier has 33 tanks containing fuel, freshwater,
    and ballast. The amount of fluid in each tank affects the way the ship moves at
    sea, as does the weight and placement of the cargo. It''s a complex system when
    the ship is upright and undamaged. When the cargo holds take on seawater or the
    ship rolls off-center—both of which have occurred—the vessel becomes an intricate,
    floating puzzle.</p><p>Johnson will have to unravel the complexity. He''ll rely
    on ship diagrams and his own onboard measurements to re-create the vessel using
    an obscure maritime modeling software known as GHS—General HydroStatics. The model
    will allow him to simulate and test what will happen as water is transferred from
    tank to tank in an effort to use the weight of the liquid to roll the ship upright.
    If the model isn''t accurate, the operation could end up sinking the ship.</p>'
- - https://www.pnas.org/content/111/19/6934
  - Field experiments of success-breeds-success dynamics
  - Arnout van de Rijt, Soong Moon Kang, Michael Restivo, Akshay Patil
  - 2014-05-13
  - 10.1073/pnas.1316836111
  - ! '<p>Social scientists have long debated why similar individuals often experience
    drastically different degrees of success. Some scholars have suggested such inequality
    merely reflects hard-to-observe personal differences in ability. Others have proposed
    that one fortunate success may trigger another, thus producing arbitrary differentiation.
    We conducted randomized experiments through intervention in live social systems
    to test for success-breeds-success dynamics. Results show that different kinds
    of success (money, quality ratings, awards, and endorsements) when bestowed upon
    arbitrarily selected recipients all produced significant improvements in subsequent
    rates of success as compared with the control group of nonrecipients. However,
    greater amounts of initial success failed to produce much greater subsequent success,
    suggesting limits to the distortionary effects of social feedback.</p><p>Seemingly
    similar individuals often experience drastically different success trajectories,
    with some repeatedly failing and others consistently succeeding. One explanation
    is preexisting variability along unobserved fitness dimensions that is revealed
    gradually through differential achievement. Alternatively, positive feedback operating
    on arbitrary initial advantages may increasingly set apart winners from losers,
    producing runaway inequality. To identify social feedback in human reward systems,
    we conducted randomized experiments by intervening in live social environments
    across the domains of funding, status, endorsement, and reputation. [Kickstarter/Wikipedia/Change.org/Epinions]
    In each system we consistently found that early success bestowed upon arbitrarily
    selected recipients produced significant improvements in subsequent rates of success
    compared with the control group of nonrecipients. However, success exhibited decreasing
    marginal returns, with larger initial advantages failing to produce much further
    differentiation. These findings suggest a lesser degree of vulnerability of reward
    systems to incidental or fabricated advantages and a more modest role for cumulative
    advantage in the explanation of social inequality than previously thought. [Keywords:
    Matthew effect, preferential attachment, scale-free networks, rich-get-richer
    effects, power law]</p>'
- - /docs/philo/2010-yvain-inverselawofscientificnomenclature.html
  - Inverse Law of Scientific Nomenclature
  - Scott Alexander
  - 2010-10-23
  - ''
  - <p>It is, of course, a notable prediction of this theory that the least scientific
    idea possible would end up called "Scientology".</p><p>Or so I thought! Last night,
    I discovered there was a movement called "Factology". Obviously this requires
    further investigation!</p><p>...<p>But surely they don't just randomly draw crazy
    conclusions based on a few words that sound the same, do they? Well, here's a
    quote from their Wikipedia article, about "examples of movies with encoded content
    about the reality of aliens among us":</p><blockquote><p>"Yoda... is short for
    Judah. Freemasons are inspired by one entity and that is a grey, by the name of
    Yoda. Yoda guides Freemasonry back to Judah, with the ancient Israel masonry.
    The British"Covenant Of Man" symbolizes the empire striking back. America is the
    empire fighting to overthrow Europe.... The word Yoda is not an English word as
    you have been led to believe. Its root word yawdaw appears 111 times in the Old
    Testament, means "to give thanks or praise, throw down, cast, shoot." The word
    Yadah meaning, to "to praise, give thanks" stems from the root word Yawdaw and
    appears only two times in the Old Testament (Daniel 2:23, Daniel 6:10). Not to
    mention the fact Yoda played in [the film] Return of the Jedi, and the word jedi
    is the same as yeti, it's just a matter of a letter, it's really the same word.
    Yeti is the name of Sasquatch (Bigfoot), also called Seti which is equivalent
    to the Extraterrestrials called the Seirians."</p>...<p>Okay, so Uncle Sam is
    a gnostic demon, as revealed by Dr. Seuss who is secretly the king of the pagan
    gods. But can they get even <em>crazier</em>?:</p><blockquote><p>"White people
    were bred to be food, and the 'rapture' expected by Christians is really the return
    of the 'raptors' who will dine on the now-ripe delicious white flesh."</p></blockquote></p>
- - https://www.outsideonline.com/1902036/king-ferret-leggers
  - ! 'The King of the Ferret Leggers: What kind of person sticks a ferret down his
    pants for more than five consecutive hours? Our writer tried to find out'
  - Donald Katz
  - 1983-02-01
  - ''
  - <p>Mr. Reg Mellor, the "king of ferret legging," paced across his tiny Yorkshire
    miner's cottage as he explained the rules of the English sport that he has come
    to dominate rather late in life. "Ay lad," said the 72-year-old champion, "no
    jockstraps allowed. No underpants—nothin' whatever. And it's no good with tight
    trousers, mind ye. Little bah-stards have to be able to move around inside there
    from ankle to ankle."</p><p>Basically, the contest involves the tying of a competitor's
    trousers at the ankles and the subsequent insertion into those trousers of a couple
    of peculiarly vicious fur-coated, foot-long carnivores called ferrets. The brave
    contestant's belt is then pulled tight, and he proceeds to stand there in front
    of the judges as long as he can, while animals with claws like hypodermic needles
    and teeth like number 16 carpet tacks try their damnedest to get out. From a dark
    and obscure past, the sport has made an astonishing comeback in the past 15 years.
    When I first heard about ferret legging, the world record stood at 40 painful
    seconds of "keepin' 'em down," as they say in ferret-legging circles. A few years
    later the dreaded one-minute mark was finally surpassed. The current record—implausible
    as it may seem—now stands at an awesome 5 hours and 26 minutes, a mark reached
    last year by the gaudily tattooed 72-year-old little Yorkshireman with the waxed
    military mustache who now stood two feet away from me in the middle of the room,
    apparently undoing his trousers.</p><p>"The ferrets must have a full mouth o'
    teeth," Reg Mellor said as he fiddled with his belt. "No filing of the teeth;
    no clipping. No dope for you or the ferrets. You must be sober, and the ferrets
    must be hungry—though any ferret'll eat yer eyes out even if he isn't hungry."</p><p>...Loyal
    to nothing that lives, the ferret has only one characteristic that might be deemed
    positive—a tenacious, single-minded belief in finishing whatever it starts. That
    usually entails biting off whatever it bites. The rules of ferret legging do allow
    the leggers to try to knock the ferret off a spot it's biting (from outside the
    trousers only), but that is no small matter, as ferrets never let go. No less
    a source than the Encyclopaedia Britannica suggests that you can get a ferret
    to let go by pressing a certain spot over its eye, but Reg Mellor and the other
    ferret specialists I talked to all say that is absurd. Reg favors a large screwdriver
    to get a ferret off his finger. Another ferret legger told me that a ferret that
    had almost dislodged his left thumb let go only after the ferret and the man's
    thumb were held under scalding tap water—for 10 minutes. Mr. Graham Wellstead,
    the head of the British Ferret and Ferreting Society, says that little is known
    of the diseases carried by the ferret because veterinarians are afraid to touch
    them. Reg Mellor, a man who has been more intimate with ferrets than many men
    have been with their wives, calls ferrets "cannibals, things that live only to
    kill, that'll eat your eyes out to get at your brain" at their worst, and "untrustworthy"
    at their very best.</p>
- - http://nautil.us/issue/39/sport/the-strange-brain-of-the-worlds-greatest-solo-climber
  - ! 'The Strange Brain of the World''s Greatest Solo Climber: Alex Honnold doesn''t
    experience fear like the rest of us'
  - J.B. MacKinnon (<em>Nautilus</em>)
  - 2016-08-11
  - ''
  - ! '<p>Synnott got the biggest response from a story set in Oman, where the team
    had traveled by sailboat to visit the remote mountains of the Musandam Peninsula,
    which reaches like a skeletal hand into the mouth of the Persian Gulf. Coming
    upon an isolated village, they went ashore to mix with the locals. "At a certain
    point," Synnott said, "these guys start yelling and they''re pointing up at the
    cliff. And we''re like, ''What''s going on?'' And of course I''m thinking, ''Well,
    I''m pretty sure I know.'' "</p><p>Up came the photograph for the gasp from the
    crowd. There was Honnold, the same casual dude who was sitting on stage in a grey
    hoodie and khakis, now looking like a toy as he scaled a huge, bone-colored wall
    behind the town. ("The rock quality wasn''t the best," Honnold said later.) He
    was alone and without a rope. Synnott summed up the villagers'' reaction: "Basically,
    they think Alex is a witch." When the Explorers Hall presentation concluded, the
    adventurers sat down to autograph posters. Three lines formed. In one of them,
    a neurobiologist waited to share a few words with Synnott about the part of the
    brain that triggers fear. The concerned scientist leaned in close, shot a glance
    toward Honnold, and said, "That kid''s amygdala isn''t firing."</p><p>...Inside
    the tube, Honnold is looking at a series of about 200 images that flick past at
    the speed of channel surfing. The photographs are meant to disturb or excite.
    "At least in non-Alex people, these would evoke a strong response in the amygdala,"
    says Joseph. "I can''t bear to look at some of them, to be honest." The selection
    includes corpses with their facial features bloodily reorganized; a toilet choked
    with feces; a woman shaving herself, Brazilian style; and two invigorating mountain-climbing
    scenes. "Maybe his amygdala is not firing—he''s having no internal reactions to
    these stimuli," says Joseph. "But it could be the case that he has such a well-honed
    regulatory system that he can say, ''OK, I''m feeling all this stuff, my amygdala
    is going off,'' but his frontal cortex is just so powerful that it can calm him
    down."</p><p>...ABSENCE OF FEAR: Scans compare Honnold''s brain (left) with a
    control subject''s (right), a rock climber of a similar age. Crosshairs mark the
    amygdala, a group of nuclei involved in generating fear. As both climbers look
    at the same arousing images, the control subject''s amygdala glows, while Honnold''s
    remains inert, showing no activity whatsoever.</p><p>There is also a more existential
    question. "Why does he do this?" she says. "He knows it''s life-threatening—I''m
    sure people tell him every day. So there may be some kind of really strong reward,
    like the thrill of it is very rewarding." To find out, Honnold is now running
    through a second experiment, the "reward task," in the scanner. He can win or
    lose small amounts of money (the most he can win is $22) depending on how quickly
    he clicks a button when signaled. "It''s a task that we know activates the reward
    circuitry very strongly in the rest of us," Joseph says. In this case, she''s
    looking most closely at another brain apparatus, the nucleus accumbens, located
    not far from the amygdala (which is also at play in the reward circuitry) near
    the top of the brainstem. It is one of the principal processors of dopamine, a
    neurotransmitter that arouses desire and pleasure. High sensation seekers, Joseph
    explains, may require more stimulation than other people to get a dopamine hit.</p><p>After
    about half an hour, Honnold emerges from the scanner looking sleepily doe-eyed.
    Raised in Sacramento, California, he has a refreshingly frank manner of speaking,
    and an oddly contradictory demeanor that might be described as intensely laid
    back—his nickname is No Big Deal, which is his assessment of almost every experience
    he undergoes. Like most expert climbers, he is leanly muscled, more like a fitness
    buff than a body builder. The exceptions are his fingers, which permanently look
    as though they''ve just been slammed in a car door, and his forearms, which bring
    to mind Popeye.</p><p>"Looking at all those images—does that count as being under
    stress?" he asks Joseph. "Those images that you saw are used pretty widely in
    the field for inducing fairly strong arousal responses," Joseph replies. "Because,
    I can''t say for sure, but I was like, <em>whatever</em>," he says. The photographs,
    even the "gruesome burning children and stuff" struck him as dated and jaded.
    "It''s like looking through a curio museum."</p>'
- - https://www.framerated.co.uk/the-haunting-1963/
  - ! 'Film Review: <em>The Haunting</em> (1963)'
  - Remy Dean
  - 2017-10-31
  - ''
  - <p>Gidding hints that the house <em>itself</em> is doing the haunting, implying
    that the architectural environment is responsible for reflecting back the fears
    of those within, teasing out their vulnerabilities, feeding upon them, and making
    them manifest. The house becomes a monster, a maleficent presence that resents
    its human tenants. If the house can be read as a metaphor for the body, as is
    often the case in Gothic mansions and castles, then the occupants become its consciousness,
    the archetypes inhabiting its ego and id. Then the house inevitably suffers from
    a mental schism, a multiple personality disorder. The characters become those
    internal voices of nagging doubt and paranoia for the house... and it eventually
    suffers a mental breakdown.</p><p>Despite filming in England, the setting remained
    as New England. Ettington Park in Stratford-upon-Avon was the spooky mansion that
    Robert Wise chose for Hill House's exteriors, reputedly selected from a list he
    sourced from the British Psychical Research Society of buildings considered to
    be <em>genuinely</em> haunted. This is the first 'character' to appear in the
    film, emerging out of darkness and looking very eerie indeed, due to the inventive
    use of infra-red film stock.</p><p>It's been argued that the house is the true
    star of the film, and I have to admit it turns in a memorable 'performance'. This,
    though, has more to do with marvellous production design by Elliot Scott and the
    huge labyrinthine sets built at Borehamwood. Corridors were made to converge or
    open out, creating a subtly expressionistic feel and rooms were constructed slightly
    askew, sometimes with walls that angled inward. Scott went on to design <em>Labyrinth</em>
    (1986) and the first two Indiana Jones sequels.</p><p>...<em>The Haunting</em>
    is regularly included in Top 10 lists of the scariest films ever made. But the
    special effects are limited to only a few ingenious mechanical effects, as the
    terror is mostly the result of brilliant sound-design, clever use of shadows,
    and inventive camerawork.</p><p>Wise chose to shoot the film in Panavision's wide
    format and every shot makes full use of it, with beautiful compositions and plenty
    of visual interest across every inch of the screen. The otherworldly atmosphere
    and ominous tracking shots, enhanced by special lenses, work in tandem with the
    subtly distorted sets.</p><p>Wise had some problems sourcing the wide-angle lenses
    he needed, mainly because they didn't exist at that time. He wanted the interior
    to look deep, dark, and foreboding, seeming to move as if we were within a living
    thing. The available lenses just weren't cutting it for him. He badgered Bob Gottschalk,
    president of Panavision, until he let slip that wider-lenses were in development
    at their optics labs. Gottschalk explained that they were early prototypes and
    the lenses caused unacceptable distortions. This was <em>exactly</em> what Wise
    wanted! After signing a disclaimer to waive any legal repercussions, he became
    the first director to use such wide angles, imbuing Hill House with its unique
    and disquieting visual personality.</p><p>The unique look of the film goes a long
    way to creating the brooding atmosphere, but the sound design was the real breakthrough.
    The slightest creak of floorboard or sigh of draught makes audiences hold their
    breath to better listen, and then cacophonous groans and thuds really get the
    heart racing.</p><p>...Of course, our emotional involvement hinges on the performances
    of the actors. It seems that the personal circumstances and attitudes of the actors
    already reflected the characters they were to play. Harris admits that she was
    suffering from a bout of depression during filming, and this inadvertently helped
    her play the central role of the sensitive Eleanor, who feels isolated and shunned
    by her colleagues, and so becomes victim to the seductively malign atmosphere
    of the house. Her performance is both fragile and disturbingly unhinged in turns.
    The voice-over she provides, to share her character's paranoia, might have looked
    corny on paper to those American studio executives, but Harris delivers it so
    perfectly that it draws the sympathies of the audience. We feel for her, even
    as she seems to succumb to madness and becomes the willing victim.</p><p><em>The
    Haunting</em> stands alongside <em>Night of the Demon</em> (1957) and <em>The
    Innocents</em> (1961) as a defining classic in the cinema of the supernatural.
    It has never been surpassed and its 'presence' is palpable in most intelligent
    psychological horror films to this day. If special effects had been used more
    extensively, then it surely would have dated, but keeping the focus on mood and
    the psychological aspects of the narrative has ensured it remains as effective
    as ever.</p><p>It's the best Halloween film I could recommend.</p>
- - https://tvtropes.org/pmwiki/pmwiki.php/Anime/MobileSuitGundamCharscounterattack
  - ! 'TVTropes: Anime / Mobile Suit Gundam: Char''s Counterattack'
  - TVTropes
  - '2019'
  - ''
  - ! '<p><em>Mobile Suit Gundam: Char''s Counterattack</em> is the first full-length
    Gundam animated movie released in 1988. <em>Char''s Counterattack</em> is the
    culmination of the original saga begun in <em>Mobile Suit Gundam</em> and continued
    through <em>Mobile Suit Zeta Gundam</em> and <em>Mobile Suit Gundam ZZ</em>, marking
    the final conflict of the fourteen-year rivalry between Amuro Ray and Char Aznable,
    and the end of the Earth Federation/Zeon conflicts.</p><p>...The movie is noteworthy
    for having a rather unusual genesis. Originally, director Yoshiyuki Tomino was
    going to wrap up Amuro and Char''s storyline in <em>Gundam ZZ</em>, but mid-way
    through production he was given the go-ahead to make a movie, forcing the plot
    of <em>ZZ</em> to be rewritten (details on its trope page). In the meantime Tomino
    wrote the novel <em>Hi-Streamer</em>, but when Sunrise gave him the green light,
    he went back and wrote a second novel, <em>Beltorchika''s Children</em>, which
    he specifically wrote to be adapted into a movie. However, Sunrise instead chose
    to use <em>Hi-Streamer</em>, with the final film being a pretty straightforward
    adaptation of its second half. These two novels serve as the origin of the Hi-Nu
    Gundam (the finalized, "perfect" Nu Gundam) and Nightingale (a bigger, beefier
    Sazabi), which pop up in video games like <em>Super Robot Wars</em>, <em>SD Gundam
    G Generation</em>, and <em>Gundam Vs Series</em>.</p>'
- - https://www.animenewsnetwork.com/news/2007-02-20/hideaki-anno-releases-statement-about-new-evangelion-movies
  - Hideaki Anno Releases Statement About New Evangelion Movies
  - 2007-02-20
  - Hideaki Anno
  - ''
  - <p>Many different desires are motivating us to create the new "Evangelion" film.</p><p>The
    desire to portray my sincere feelings on film.</p><p>The desire to share, with
    an audience, the embodiment of image, the diversity of expressions, and the detailed
    portrayal of emotions that animation offers.</p><p>The desire to connect today's
    exhausted Japanese animation [industry] to the future.</p><p>The desire to fight
    the continuing trend of stagnation in anime.<p/><p>The desire to support the strength
    of heart that exists in the world.<p/><p>Finally, the desire to have these wishes
    be realized.</p><p>For these purposes, we used the best methods available to us
    to make another Evangelion film.</p><p>Many times we wondered, "It's a title that's
    more than 10 years old. Why now?"</p><p>"Eva is too old", we felt.</p><p>However,
    over the past 12 years, there has been no anime newer than Eva.<p/><p>... As the
    creator of this project, [I assure you that] a very new-feeling Evangelion world
    has been constructed.</p><p>... Although it seems obvious, we aim to create a
    form of entertainment that anyone can look forward to; one that people who have
    never seen Evangelion can easily adjust to, one that can engage audiences as a
    movie for theatres, and one that produces a new understanding of the world.</p>
- - https://www.khara.co.jp/2019/08/01/01/
  - 『シン・ウルトラマン』映画化に関するお知らせ
  - Studio Khara
  - 2019-08-01
  - ''
  - <p>A new film production of "SHIN ULTRAMAN" was publicly announced today. The
    new movie will come to theaters in 2021.</p><p>Hideaki Anno will join a film team,
    Higuchi-Gumi led by Director Shinji Higuchi, taking charge of Produce and Screenplay.
    First draft script has been finished in February 5th, 2019. Anno will fully join
    the project after finishing his "EVANGELION:3.0+1.0" film.</p>
- - https://www.amazon.com/Secret-History-Star-Wars/dp/0978465237
  - <em>The Secret History of Star Wars</em>
  - Michael Kaminski
  - 2008-11-18
  - ''
  - ! 'Star Wars is one of the most important cultural phenomena of the Western world.
    The tale of Luke Skywalker, Han Solo, and the fall and redemption of Anakin Skywalker
    has become modern myth, an epic tragedy of the corruption of a young man in love
    into darkness, the rise of evil, and the power of good triumphing in the end.
    But it didn''t start out that way. In this thorough account of one of cinema''s
    most lasting works, Michael Kaminski presents the true history of how Star Wars
    was written, from its beginnings as a science fiction fairy tale to its development
    over three decades into the epic we now know, chronicling the methods, techniques,
    thought processes, and struggles of its creator. For this unauthorized account,
    he has pored through over four hundred sources, from interviews to original scripts,
    to track how the most powerful modern epic in the world was created, expanded,
    and finalized into the tale an entire generation has grown up with. [ISBN: 0978465237]'
- - https://scholars-stage.blogspot.com/2010/08/notes-on-dynamics-of-human-civilization.html
  - ! 'Notes on the Dynamics of Human Civilization: The Growth Revolution'
  - Tanner Greer
  - 2018-08-04
  - ''
  - ! '<p>My interest lies in the dynamics of civilized societies: their material
    needs and limitations, the recurring patterns of geography, social organization,
    and cultural complexity upon which they are built, and the type of interactions
    that define their relationships with each other and the physical systems they
    depend on for survival—or in simpler words, the means by which human communities
    flourish and fall.</p><p>...Human civilization has gone through two stages. The
    first of these stages is the longest, beginning with the emergence of complex
    societies in the Near East c. 11,500 years ago and ending only at the beginning
    of the 19th century. I submit that every society of this period—from the first
    chiefdoms to the great empires of Rome and China—operated under the same basic
    structural constraints. The rules and limitations were the same; the differences
    were a matter of emphasis and scale. This changes at the turn of the 19th century.
    Humanity''s third great period begins here (it has not yet ended). The rules by
    which the modern world operates are incredibly different from those of the old
    order. The transformation wrought by modernization was no less revolutionary than
    that wrought by the advent of complex society 11,000 years previous.</p><p>This
    revolution is widely recognized, but also grossly mischaracterized. The standard
    label for this transition is the "Industrial Revolution". This title is misleading.
    The industrialization of the world economy was the <em>result</em>, not the <em>cause</em>
    of modernization. The nature of this radical transformation is captured better
    by a different title: <b>The Growth Revolution</b>. Population, wealth, and energy
    production/consumption are three quantitative variables that can be estimated
    with some accuracy through much of human history. When displayed on a broad scale
    like this, a striking trend is seen in all three data sets: by 1820 all three
    begin an exponential climb upwards. This is the "Growth Revolution." During this
    revolution human energy production and consumption, population size, wealth, technological
    capacity, and knowledge all began to increase at an exponential rate. <b>This
    constant expansion of human resources is the defining feature of our time.</b>
    Ours is an exponential age.</p><p>...500 years of growth on the part of the wealthiest
    static societies of the old order is <em>equal to less than 7% of a single year''s
    growth on the part of their modern equivalent!</em></p><p>...Many of the world''s
    fallen civilizations met their doom by trying to exceed the inherit limits of
    static civilization.</p>'
- - https://scholars-stage.blogspot.com/2018/01/vengeance-as-justice-passages-i.html
  - ! 'Vengeance As Justice: Passages I Highlighted in My Copy of <em>Eye for an Eye</em>'
  - Tanner Greer
  - 2018-01-26
  - ''
  - ! 'These type of questions naturally lead to the topic of this book: <em>lex talionis</em>,
    the law of the talion, the principle of an eye for an eye, of justice through
    vengeance, retaliation sanctioned by culture and law. This understanding of justice
    is what propels the Icelandic sagas. But it wasn''t just a Viking tick. "Eye for
    an eye" was standard practice just about everywhere a few thousand years ago,
    from the shores of Germainia and the fields of the Greek <em>polis</em> to the
    warring tribes of Canaan and the even more distant lands of the Kurus and the
    Zhou. We view this understanding of justice as backward and crude. We say things
    like "an eye for an eye makes the whole world blind." Miller aims to convince
    us otherwise. We have a lot to learn from these talionic cultures, he argues,
    and our world could be made a more just place if we could humble ourselves enough
    to learn from them.</p><p>I am not going to provide a precis of Miller''s argument
    here. Like past editions of ''Passages I Highlighted'' (see here) I will reserve
    myself to quoting the passages of this book I found most interesting. But to really
    give you a sense for Miller''s argument, I think the best thing I can do is quote
    first from another one of his books, one that focuses specifically on Icelandic
    society. He begins <em>that</em> book by quoting a passage from an obscure saga.
    In only a paragraph, the saga lays out what <em>lex talionis</em> looked like
    in real life:</p><blockquote><p>Some Norwegian merchants chopped off Skæring''s
    hand. Gudmund was given self-judgment in the injury case. Haf Brandsson [Gudmund''s
    second cousin] and Gudmund together adjudged compensation in the amount of thirty
    hundreds, which was to be paid over immediately. Gudmund then rode away from the
    ship. But the Norwegians confronted Haf, who had remained behind; they thought
    the judgment had been too steep and they asked him to do one of two things: either
    reduce the award or swear an oath. Haf refused to do either.</p><p>Some people
    rode after Gudmund and told him what had happened. He turned back immediately
    and asked Haf what was going on. Haf told him where matters stood. Gudmund said,
    "Swear the oath, Haf, or else I will do it, but then they will have to pay sixty
    hundreds. The oath of either one of us will have the same price as Skæring''s
    hand."</p><p>The Norwegians refused the offer. "Then I shall make you another
    proposal," said Gudmund. "I will pay Skæring the thirty hundreds that you were
    judged to pay, but I shall choose one man from amongst you who seems to me of
    equivalent standing with Skæring and chop off his hand. You may then compensate
    that man''s hand as cheaply as you wish."</p><p>This did not appeal to the Norwegians
    and they decided to pay the original award immediately. Gudmund took Skæring with
    him when they left the ship. (<em>G.dýri</em> 26:212) [1]</p></blockquote><p>Iceland
    was a country without a state. They had laws but no government to enforce them.
    If you were wronged, the responsibility to right the wrong rested with you and
    your kin. To prevent retaliatory feuds the Icelanders would often give the wronged
    party a chance to stand in judgement and mete out a punishment to pay for their
    mistakes and restore balance between the two groups. The saga passage you''ve
    just read is an excellent example of how the system worked. Miller''s comments
    on it are worth pondering:</p><blockquote><p>By the time the saga writer focuses
    attention on this incident it is not the hand that is the subject of the dispute
    but the legitimacy and justice of Gudmund''s judgment. The Norwegians think the
    award excessive, and not without reason. More than a few men''s lives at this
    time were compensated for with thirty hundreds or less. <strong><em>Gudmund, however,
    is able to justify astutely his over-reaching by giving these men of the market
    a lesson on the contingency of value and values. To the Norwegians the award should
    reflect the price of a middling Icelandic hand. Gudmund forces them to conceive
    of the award in a different way: it is not the price of buying Skæring''s hand,
    but the price of preserving a Norwegian hand.</em></strong> By introducing the
    prospect of one of their hands to balance against Skæring''s, he is able to remind
    the Norwegians that the thirty hundreds they must pay purchases more than Skæring''s
    hand; it also buys off vengeance in kind. <strong><em>He is also able to force
    them to take into account the costs of personalizing the injury. Most people,
    he bets, are willing to pay more to save their own hands than they would be willing
    to pay to take someone else''s. The justice of Gudmund''s award thus depends on
    a redefinition of its significance. Rather than buying Skæring''s hand, the Norwegians
    are preserving their own, and the price, they now feel, is well worth paying.</em></strong>
    Fellow feeling thus comes not in the form of imagining Skæring''s anguish and
    pain as Skæring''s, but in imagining the pain as their own. [2]</p></blockquote><p>This
    is the logic of <em>lex talionis</em>. This is why "an eye for an eye" did not
    in fact make the whole world go blind. The principle of an eye for an eye, as
    Miller sees it, is "the more ancient and deeper notion that justice is a matter
    of restoring balance, achieving equity, determining equivalence, making reparations...
    getting back to zero, to even." [3] Trading eyes for eyes is not so much about
    indiscriminate, unthinking violence as it is carefully calculated attempts to
    match punishment to crime. Talionic justice is a system built on deterrence—not
    only deterring criminals from committing crimes, but deterring vengeance seekers
    from exacting too heavy a price in retaliation for crimes committed against them.'
- - https://scholars-stage.blogspot.com/2018/08/tradition-is-smarter-than-you-are.html
  - Tradition is Smarter Than You Are
  - Tanner Greer
  - 2018-08-27
  - ''
  - ! '<p>Let''s talk about Henrich first. One of the clearest presentations of his
    ideas is in his 2016 book <em>The Secret of Our Success</em>. The book is less
    a heavy scholarly tome than a popified version of Henrich''s research, but Henrich''s
    decision to trade theoretical detail for accessibility is understandable (it is
    also why I don''t feel bad quoting large blocks of text from the book in this
    post). Henrich advances the argument that brain-power alone is not enough to explain
    why humans are such a successful species. Humans, he argues, are not nearly as
    intelligent as we think they are. Remove them from the culture and environment
    they have learned to operate in and they fail quickly. His favorite example of
    this are European explorers who die in the middle of deserts, jungles, or arctic
    wastes even though thousands of generations of hunter-gatherers were able to survive
    and thrive in these same environments. If human success was due to our ability
    to problem solve, analyze, and rationally develop novel solutions to novel challenges,
    the explorers should have been fine. Their ghastly fates suggest that rationality
    may not be the key to human survival...Henrich has dozens of these examples. The
    common thread pulling them together is that the people whose survival is guaranteed
    by strict observance of these traditions have no real explanation for <em>why</em>
    they are following them. Henrich goes into this with more depth in discussion
    of his ethnographic work in Fiji, where women do not eat certain fish while pregnant.</p><p>...
    Henrich makes two arguments here, both relevant to contemporary debates in politics
    and philosophy. The first is that customs, traditions, and the like are subject
    to Darwinian selection. Henrich is not always clear on exactly what is being selected
    for—is it individuals who follow a tradition, groups whose members all follow
    the tradition, or the tradition itself?—but the general gist is that traditions
    stick around longest when they are adaptive. This process is "blind." Those who
    follow the traditions do not know how they work, and in some cases (like religious
    rituals that build social solidarity) knowing the details of how they work might
    actually reduce the efficacy of the tradition. That is the second argument of
    note: we do not (and often cannot) understand just how the traditions we inherit
    help our survival, and because of that, it is difficult to artificially create
    replacements.</p><p>...Can any of this be put into action? I suspect many conservatives
    will think the answer to this question is obvious. Henrich and Scott have provided
    empirical support for maintaining "Chesterton''s fence." Chesterton asks us not
    destroy customs, tradition, and social structures that we cannot explain. Henrich
    and Scott question our ability to rationally explain them. Implicit in this is
    a strong defense of the local, the traditional, and the unchanging. The trouble
    with our world is that it <em>is</em> changing. Henrich focuses on small scale
    societies. These societies are not static. The changes they undergo are often
    drastic. But the distance between the life-style of a forager today and that of
    her ancestors five hundred years ago pales next to the gap that yawns between
    the average city-slicker and her ancestors five centuries past...Europeans, Japanese,
    Taiwanese, and South Koreans born today look forward to spending their teenage
    years in stage five societies. What traditions could their grandparents give them
    that might prepare them for this new world? By the time any new tradition might
    arise, the conditions that made it adaptive have already changed. This may be
    why the rationalist impulse wrests so strong a hold on the modern mind. The traditions
    are gone; custom is dying. In the search for happiness, rationalism is the only
    tool we have left.</p>'
- - https://scholars-stage.blogspot.com/2015/05/the-war-where-future-met-past.html
  - When Modern War Met an Antique Art
  - Tanner Greer
  - 2015-05-08
  - ''
  - ! '<p>We associate <em>ukiyo-e</em> prints with traditional Japanese landscapes
    or pastoral settings, episodes from Japanese myths or historical epics, and scenes
    of courtesan life in Edo. It can be a bit bewildering when we see the same art
    style and production methods used to produce more modern images. This should not
    be too much of a surprise, however: the most famous of the great Japanese woodblock
    artists died only a few decades before Commodore Perry brought his black boats
    to Edo bay. Much of their era would disappear in the miraculous changes of the
    Meiji revolution, but as the prints included here show quite clearly,  much of
    the old order lived on into the 20th century.</p><p>These prints all depict episodes
    from the Sino-Japanese War of 1894 or the Russo-Japanese War that was waged a
    decade later. Remarkably, none of these prints were designed to be great works
    of art; the great majority were carved and colored to accompany news reports from
    the front-lines, printed in newspapers or periodicals circulating in Japan on
    short notice. The artists never saw the battlefields they depicted, relying instead
    on common visual tropes, reporter''s accounts (you can see a gaggle of such reporters
    in the bottom right corner of the print placed directly below), and their own
    imaginations to create these images. The prints are therefore less useful for
    understanding the tactics or battlefield conditions of these wars than they are
    for understanding the attitude of a Japanese public mobilized for external conquest
    for  the first time in centuries.</p><p>As historical sources the prints are revealing.
    A comparison of the physical features of the Japanese and Chinese soldiers depicted
    testifies to how thoroughly the Japanese people had adopted the racialist ideology
    common in European circles at the time. The prints, like the wars themselves,
    also betray how eager the Japanese were to prove that they were the equals of
    the Western powers. Perhaps most interesting, however, is how <em>exultantly</em>
    they depict the wars of their day. Tactically, the Russo-Japanese War was not
    far removed from the Great War that soon followed it, but the way the Japanese
    portrayed their experience with industrial warfare could not be further removed
    from the collective horror Europeans felt when they fought in the trenches. These
    woodblock prints were some of the first artistic renderings of industrial age
    warfare; never again would a people forced to wage such a war render it so beautifully.</p><p>Copied
    below are the war prints I found most useful as historical windows or most visually
    arresting as works of art...</p>'
- - https://scholars-stage.blogspot.com/2014/12/isis-mongols-and-return-of-ancient.html
  - ISIS, the Mongols, and 'The Return of Ancient Challenges'
  - Tanner Greer
  - 2014-12-18
  - ''
  - <p>The most interesting parallel between ISIS and the forces of Chinggis Khan
    is actually not one Anderson makes explicitly. He sets up this comparison in his
    discussion of the ISIS command structure:</p><blockquote><p><strong><em>Use Mission
    Orders to Enhance Operational Security</em></strong>. Telling subordinates what
    to do, not how to do it, is a basic tenant of maneuver warfare; but it also allows
    Baghdadi to command and control his forces with an absolute minimum of cell phone
    and radio communications that are subject to American intercepts which can be
    provided to Iraqi security forces. Baghdadi makes extensive use of runners and
    motorcycle messengers to keep his opponents in the dark.</p><p>American commanders
    talk a good game about Maneuver Warfare, but many take advantage of technology
    and secure communications to micromanage. It is not unusual for an American Colonel
    to be tracking squad sized units on his computer; worse still, it is not unusual
    to require American squad and platoon sized units to submit detailed patrol plans
    three days in advance so they can be plotted into computers. <em>Baghdadi can
    simply say; "take this town and let me know when you have it". It doesn't make
    him a good guy, but he is a very effective military leader. Contrast this with
    Maliki and Karzai who will move or fire a commander who appears so competent or
    popular that he might become a competitor for</em> power (emphasis added) [9].</p></blockquote><p>And
    <em>here</em> is where things get interesting. I don't think it is possible to
    isolate one, single variable that can account for the epochal success of the Mongol
    military machine. But if I was forced to try and boil down the secret of the Mongol
    Empire to a sentence or two it would sound a lot like the one Anderson has written
    here. In contrast to <strong>both</strong> the kingdoms the Mongols destroyed
    and every other nomadic confederation that preceded or followed his empire, Chinggis
    Khan possessed the complete loyalty of his troops and his generals. The men under
    his command were absolutely, and to their enemies, terrifyingly, united. Chinggis
    Khan could wage simultaneous wars on opposite sides of the known world, erode
    the internal cohesion of every kingdom his envoys visited, and paralyze enemy
    defenses with a flood of independently commanded units only because of the fearsome
    unity and loyalty of his forces.</p> While none of the Mongol's other foes imploded
    so spectacularly, sowing dissension and division within the ranks of their enemies
    was an essential element of all Mongol campaigns. Whether they were fighting Hungarian
    monarchs on Pannonian plains or Song Dynasty navies on the Yangtze, the Mongols
    were masters at turning their enemies against each other. The same could not be
    said about the Mongol's rivals. No one ever managed to turn a Mongol. For the
    first three generation of the empire there were no secession crises, no infighting,
    and few traitors. Powerful commanders deferred to their leaders, even when, as
    Juvainyi hints, doing so meant to demotion or punishment. [11] This is really
    quite extraordinary when you consider the kind of positions these commanders were
    placed in. Consider the case of Muqali, one of the greatest but least known of
    the Mongol generals. While Chinggis was off fighting the Khawarezm Empire and
    other enemies in the West, Muqali was placed in charge of the war effort in Northern
    China. For six years he controlled all of Mongolia, Manchuria, and the North China
    plain and for six years he fought the Jin Empire without losing a single battle.
    He was a powerful and popular commander. But neither he nor his sons ever challenged
    the great Khan's authority. There is no evidence that Chinggis ever feared that
    they would. [12]</p>.<p>.. The story of how Chinggis Khan created an empire whose
    many branches were unified in effort and whose many subjects were absolutely loyal
    to him is one of the most fascinating in world history. Unfortunately, it is only
    tangentially related to the topic at hand. A full investigation of that question
    must be reserved for a later post. For the purposes of this discussion what matters
    is that the conquests of the Mongol empire, the type of warfare it waged, and
    the methods it used to incorporate new peoples into its domains would not have
    been possible except for the unshakable unity of its commanders and warriors.
    In this the Mongols are very much like Abu Bakr al-Baghdadi and the warriors under
    his command.</o>
- - https://scholars-stage.blogspot.com/2014/06/the-cross-section-ilusion.html
  - The Cross Section Illusion
  - Tanner Greer
  - 2014-06-07
  - ''
  - <p>If you are concerned with American obesity rates and turn to the cross sectional
    data to try and figure out what is going on, it is easy to reach a flawed conclusion.
    The correlation between education and obesity, for example, seems quite clear.
    The poorer and less educated an American is, the more likely he or she is to be
    obese. Looking at this data it seems reasonable to suggest that something about
    poverty is making people more obese—perhaps cruddy processed food is the only
    thing America's poor and less educated can afford to buy, or maybe the poor live
    in urban areas where people do not exercise. These hypotheses are plausible...
    until you look at the time series. It then becomes apparent that the rich and
    educated are gaining weight at the same rate as the poor. Poverty cannot explain
    this.</p><p>It is very difficult to make meaningful claims about causation—or
    even correlation!—on the basis of cross section data alone. Often times seemingly
    perfect, statistically significant correlations disappear when the same variables
    are viewed over a longer stretch of time. In other cases—as in this one—time series
    data reveals that the real story isn't about variance between two groups at all,
    but about the rate at which each group is changing. It is all too easy to be fooled
    by the Cross Section Illusion.</p>
- - http://zenpundit.com/?p=52965
  - ! 'Announcing: The Thucydides Roundtable'
  - Tanner Greer et al
  - 2016-08-23
  - ''
  - <p>I am proud to announce the upcoming Thucydides Roundtable, to be hosted at
    the group blog Zenpundit in October 2016.</p><p>Thucydides is a man of firsts.
    He has been called the father of realism, the first "theorist of war" in the Western
    tradition, the inventor of political science and international relations, the
    first man to ever attempt an objective and evidence based history of the world
    he lived in, and many other things besides. In the two thousand years since they
    were first written, his words have been used and abused by historians, poets,
    social scientists, and statesmen from one side of the Earth to the other. His
    chronicle of the thirty year war waged between his native Athens and her rival
    Sparta has just about everything in it. I really do mean <em>everything</em>.
    No great or enduring theme of the human experience is left untouched—war and international
    order of course make their appearance, but so do meditations on statesmanship,
    bargaining, courage, partisanship, justice, ethics, ambition, greed, honor, religion,
    culture, history, and so much more. His <em>History of the Peloponnesian War</em>
    is not just the story of a quarrel between Athenians and Lacedaemonians in the
    5th century BC. It is a story about all of mankind.</p><p>Or at least this is
    what Thucydides hoped it would be.</p><p>I invite you to discover for yourself
    if Thucydides' ambition was realized by reading his work with us. We will officially
    kick off the roundtable discussion at Zenpundit in mid-October. In the weeks to
    come we will publish the full list of official participants as well as the Roundtable's
    official rules of engagement. Until then, I encourage you to go out and purchase
    the <em>Landmark Thucydides</em> to get a head start on the reading. It's a big
    book, but one well worth reading.</p>
- - https://scholars-stage.blogspot.com/2016/10/everybody-wants-thucydides-trap.html
  - Everybody Wants a Thucydides Trap
  - Tanner Greer
  - 2016-10-30
  - ''
  - ! '<p>We don''t come to Thucydides'' <em>History</em> with preexisting knowledge
    of the war. Our only guide to Thucydides is Thucydides himself. We thus must read
    with utmost care. If we do not, we risk mistaking Thucydides'' judgments about
    the war for the events of the war itself.</p><p>Nowhere is more careful attention
    demanded than Thucydides'' treatment of the Megarian Decree. Like all Greeks of
    the age, the Athenians had long memories. Their enmity for Megara began a generation
    earlier, when Athenian blood was lost as consequence of Megarian betrayal. The
    Megarian betrayal came during a day of war, Athen''s first life-and-death struggle
    with the men of Sparta. The proximate causes of the this dispute were more recent,
    however. Thucydides reports that Athens "accused the Megarians of pushing their
    cultivation into consecrated ground and the unenclosed land on their border, and
    of harboring runaway slaves." Thucydides'' description of the Athenian response:
    a "Megara Decree, excluding the Megarians from the use of Athenian harbors and
    of the market of Athens." (1.139.2)</p><p>...In face of these questions Pericles
    was dismissive:</p><p><blockquote>"<b>I hope that none of you think that we shall
    be going to war for a trifle if we refuse to revoke the Megara decree, which appears
    in front of their complaints</b>, and the revocation of which is to save us from
    war, or let any feeling of self-reproach linger in your minds, as if you went
    to war for slight cause. <b>Why, this trifle contains the whole seal and trial
    of your resolution.</b> If you give way, you will instantly have to meet some
    greater demand, as having been frightened into obedience in the first instance;
    while a firm refusal will make them clearly understand that they must treat you
    more as equals. Make your decision therefore at once, either to submit before
    you are harmed, or <b>if we are to go to war, as I for one think we ought, to
    do so without caring whether the ostensible cause be great or small</b>, resolved
    against making concessions or consenting to a precarious tenure of our possessions.
    For all claims from an equal, urged upon a neighbor as commands before any attempt
    at legal settlement, be they great or be they small, have only one meaning, and
    that is slavery. [1.40.4, emphasis added]</blockquote></p><p>The argument that
    Thucydides puts into Pericles'' mouth is simple: the coming war is not really
    about the decree at all, but more fundamental questions of power and rank. Is
    Athens subordinate to Sparta? Or are the two polis equal in rank? That was the
    real question being decided by this war. Any "ostensible cause" to get things
    rolling would do—in this case that ostensible cause just happened to be the embargo
    of Megara.</p><p>...See this for what it is: Thucydides has omitted from his history
    a central cause of the war! This was not an oversight. It may have been the entire
    point of Book I. In Thucydidean terms, the Megarian decree was (as Thucydides
    has Pericles say) "a trifle." It was an "ostensible cause" of the great war, but
    not its true one. A war of this magnitude could not be caused by trifles, and
    to drive home the point of just how trifling and irrelevant this <em>casus belli</em>
    was to the war''s actual conduct, Thucydides crafts a narrative of the war that
    does not include it at all...A review of the origins and first moments of this
    war suggests that it was less a matter of growing fear and growing power, than
    a matter of tarnished honor and quests for glory. Athens'' growing wealth was
    a necessary condition for the war, but it was hardly the only or the most important
    cause of it. Had Athens'' quest for glory been less ambitious, had Sparta not
    tied herself to an ally hellbent on forcing her private wars and narrow interests
    onto the entire league of Spartan allies, and had the Greeks not been a people
    obsessed with insults, rank, and honor, this war may never have occurred. It was
    not an inevitable clash of fear and power that brought war to Hellas, but a very
    specific set of decisions made by a very specific set of leaders in the years
    before the war.</p>'
- - https://scholars-stage.blogspot.com/2016/12/men-of-honor-men-of-interest.html
  - Men of Honor, Men of Interest
  - Tanner Greer
  - 2016-12-01
  - ''
  - ! 'The Plataeans and the Mytilenians both heard a case arguing for their death,
    as well as one arguing for their continued survival. In the Mytilenian case, both
    the defendant and the prosecution were represented by Athenians. In the case of
    Plataea, the Plataeans were forced to speak in their own defense, with the Thebans
    arguing for their death. The parallel is clear. It to the arguments we turn to
    find the contrast between the two hegemonic powers.</p><blockquote><p>...<em>What
    is this but to make greater enemies than you have already, and to force others
    to become so who would otherwise have never thought of it?</em></p></blockquote><p>The
    Athenians were once a people of honor. "For glory then and honor now" was the
    rallying cry Pericles raised to lead his people to war (2.64.6). The Athenians
    began this entire drama chasing it. No longer. Athenian honor died long before
    the war''s close. Athenian honor could not survive the plague. Then the beastly
    truth was revealed: honor meant nothing but scarred skin and blistered visage.
    Nobility brought no recompense but rotting flesh. Eat now, drink now, be merry
    now, for tomorrow men will die! And die, and, die, and die. Justice, integrity,
    honor—mere words. Where could those words be found? Buried deep in burning heaps
    of flesh! Abandoned in lonely, forgotten corners where none would see them croak
    away! Beneath blood, phlegm, pustule, and vomit! What has honor to do with Athens?
    Nothing. What is more, they knew it....Thucydides relates the speech of two men
    in the debate over Mytilene, one Cleon, son of Cleanetus, the ''most violent man
    in Athens.'' The other Diodotus, son of Eucrates, a more measured sort who does
    not appear elsewhere in this history. Cleon argues for the Mytilene''s extinction.
    Diodotus, for their salvation. They disagreed on almost every point. What sticks
    out, however, is what they <em>did</em> agree on. Both wanted everyone to know
    that their arguments had nothing whatsoever to do with justice, honor, or mercy.</p><p>Said
    Cleon:</p><blockquote><p>...However, if, right or wrong, you determine to rule,
    you must carry out your principle and punish the Mytilenians as your interest
    requires; or else you must give up your empire and cultivate honesty without danger
    (3.37; 3.40).</p></blockquote><p>In reply, Diodotus:</p><blockquote><p>...However,
    I have not come forward either to oppose or to accuse in the matter of Mytilene;
    indeed, the question before us as sensible men is not their guilt, but our interests.
    Though I prove them ever so guilty, I shall not, therefore, advise their death,
    unless it be expedient; nor though they should have claims to indulgence, shall
    I recommend it, unless it be clearly for the good of the country</p></blockquote><p>Behold
    the men of Athens! Dead to honor, to principle, to humanity. This was a people
    whose hearts had hardened. Nothing was left to Athens but the pursuit of power—and
    its cousin, profit. The only language they spoke was the language of naked interest.
    That language saved the Mytilenians. They were lucky. Interest is a fickle master.
    The men of Melos discovered just how twisted a master it can be. In time, so would
    the Athenians.'
- - https://scholars-stage.blogspot.com/2016/11/history-is-written-by-losers.html
  - ! ' History is Written by the Losers '
  - Tanner Greer
  - 2016-11-21
  - ''
  - <p>In his roundtable post, "Treason Makes the Historian," Lynn Rees lists a few
    of the type. Herodotus wrote his history only after his exile from Halicarnassus;
    Xenophon wrote his memoirs only after his faction was forced out of Athens. Polybius
    was once a general for the Archean League, but wrote his history as a hostage
    at Rome. The destruction of Judea was chronicled by a Josephus, a Jew.</p><p>These
    men abandoned their countries and people for the victors of the future. But Quislingdom
    was not the only losing path to historical fame. Tacitus's loyalty to Rome never
    wavered—but neither did his identification with Rome's Senatorial class, a group
    whose power was slowly stripped away as Tacitus wrote his chronicles. Sima Guang,
    the second most significant historian of Chinese history, only finished his massive
    Zizhi Tongjian after court rivalries had forced him to retire. The history of
    the Mongols was written almost entirely by their vanquished enemies. Ibn Khaldun
    was associated with so many failed regimes that it is a wonder he found time to
    write his history at all.</p><p>I am sure more examples can be found. The example
    most relevant to this roundtable is one Thucydides, son of Olorus. It is here
    in Book IV we finally learn a tad about the man behind the curtain:</p><p><blockquote>The
    passage of Brasidas was a complete surprise to the people in the town; and the
    capture of many of those outside, and the flight of the rest within the wall,
    combined to produce great confusion among the citizens; especially as they did
    not trust one another.... Meanwhile the party opposed to the traitors proved numerous
    enough to prevent the gates being immediately thrown open, and in concert with
    Eucles, the general, who had come from Athens to defend the place, sent to the
    other commander in Thrace, Thucydides, son of Olorus, the author of this history,
    who was at the isle of Thasos, a Parian colony, half a day's sail from Amphipolis,
    to tell him to come to their relief. On receipt of this message he at once set
    sail with seven ships which he had with him, in order, if possible, to reach Amphipolis
    in time to prevent its capitulation, or in any case to save Eion (4.103).</blockquote></p><p>Now
    pieces of Thucydides work start to click together. Few Spartans are mentioned
    by name; fewer still are Spartans mentioned by name on multiple occasions. The
    exception is Brasidas. Brasidas, brave defender of Methone, and thus "the first
    man in this war to receive the official honors of Sparta" (2.25). Brasidas, whose
    stratagems almost defeated the Athenians at sea (2.86-87). Brasidas, the daring
    leading who almost stormed the fort at Pylos (4.12). Brasidas, the savior of Megara
    (4.70-73). Brasidas, the only Spartan eloquent and wise enough to raise all of
    Thessaly into revolt (4.84). Brasidas, the general who defeated Thucydides.</p><p>Thucydides'
    obsession with Brasidas is easy to understand once his personal relation to Thucydides
    is made clear. His portrayal of Brasidas as daring, brilliant, charismatic, and
    clever beyond measure also begins to make sense—the greater Brasidas' past feats
    appear, the less damning Thucydides defeat at his hands becomes.</p>
- - https://scholars-stage.blogspot.com/2015/10/pre-modern-battlefields-were-absolutely.html
  - Pre-Modern Battlefields Were Absolutely Terrifying
  - Tanner Greer
  - 2015-10-25
  - ''
  - ! '<p>Why was cold steel a "unique terror" for troops in combat? On the face of
    it a sword does not <em>seem</em> any more frightening than the cannon-ball. Pop
    culture portrayals of small imperialist forces putting hordes of backward natives
    to flight with nothing but gun and powder suggest the opposite conclusion. Images
    of countless thousands led to the slaughter on the banks of the Somme or hills
    of Verdun only strengthen the impression. But those men who actually withstood
    both the bullet and the bayonet overwhelmingly preferred to face the former. A
    similar preference for arrows and cross-bows shot from afar over spear thrusts
    and sword strokes closer to home pervades the ancient and medieval sources.</p><p>To
    understand why this was so you must discard Hollywood notions of close combat.
    This is hard to do, for the notions are much older than Hollywood. The classical
    Chinese novels Outlaws of the Marsh and Romance of the Three Kingdoms speak of
    warriors who exchange five, ten, twenty, and even fifty "rounds" or "clashes"
    on the battlefield. The long duels of ancient India''s great war epic, the Mahabharata,
    are matched only by the extended contests of its Greek counterpart, the Iliad.
    All of it is poppycock. Ancient battles did not descend into a series of extended
    melees when the two front lines collided. The silliness of the Hollywood style
    of battle becomes immediately apparent when you watch sparring competitions that
    use pre-modern weapons: [video link]</p><p>As you can see, most close quarter
    engagements are decided within seconds. To engage in hand to hand combat is to
    hang your life on a the balance of a few split second decisions. This is terrifying.
    It is all the more terrifying if the enemy force is as committed and disciplined
    as your own. If you survive the first encounter—that is, if you successfully kill
    the first man who attempts to kill you—there will be another, and then yet another
    to fill in his place. How long can you keep making instant life-or-death decisions
    before you make a mistake? The odds are not in your favor. The physical and mental
    strain of close quarters combat on those in the front lines is simply more than
    can be borne for any great stretch of time.</p>'
- - https://scholars-stage.blogspot.com/2015/01/the-radical-sunzi.html
  - The Radical Sun Tzu
  - Tanner Greer
  - 2015-01-02
  - ''
  - <p>Timeless as it may seem, however, the <em>Sunzi</em> was the product of problems
    experienced at a specific time and a specific place. It is my belief that we cannot
    really understand the <em>Sunzi</em> if we do not first understand the world from
    which it came—the world of the Warring States.[2] A few historians and scholars
    of Chinese thought have written this sort of analysis; the best of these attempts
    to place the <em>Sunzi</em> within its historical context are usually focused
    on the broad, macro-historical trends that divided the Spring and Autumn period
    that preceded the <em>Sunzi</em> from the Warring States period that gave birth
    to it. From this perspective the <em>Sunzi</em> and the other military manuals
    that followed it were the natural product of a world torn asunder by wars waged
    on an ever increasing scale between large infantry armies fighting in the name
    of territorial, bureaucratized states.[3] There is, however, more to the <em>Sunzi</em>'s
    historical setting than the institutional history of ancient China. Just as important
    is the intellectual milieu of early Warring States times. The compilers of the
    <em>Sunzi</em> were not the first Chinese to write about war. When read as a response
    to these earlier voices, the <em>Sunzi</em>'s vision of war and politics is nothing
    less than radical.</p><p>...Its revolutionary nature only becomes clear when we
    see what it was written in response to. The place to turn is the <em>Zuo Zhuan</em>,
    China's oldest narrative historical account and one of the few preserves of the
    old Spring and Autumn ethos. One of its better known dictums reads:</p><p><blockquote>The
    great affairs of state are sacrifice and warfare.[5]</blockquote></p><p>Meyer
    comments on the contrast between the two statements:</p><p><blockquote>[In the
    <em>Sunzi</em>] all mention of sacrifice is eliminated, telegraphing the text's
    contention that martial matters must be viewed in purely material terms. Rather
    than "warfare", the "military" is held up as the great affair of state, implying
    (as the text goes on to elaborate) that there are uses for military power beyond
    the 'honorable' contest of arms. Moreover, the word that the <em>Sunzi</em> uses
    by reference to the "military", <em>bing</em> (兵), does not evoke the aristocratic
    charioteer but the common foot solider, who had become the backbone of the Warring
    States army.[6]</blockquote></p><p>The <em>Sunzi</em>'s insistence that military
    methods were more important to the state's survival than sacrifice was not merely
    radical—it was nonsensical. In the early Chinese world view, sacrifice and warfare
    could not be separated from each other. As with the Aztecs, Maya, and many other
    premodern peoples, for the Chinese of Zhou times, warfare <em>was</em> a sacrificial
    ritual.</p>
- - /docs/iq/1957-shockley.pdf
  - On the Statistics of Individual Variations of Productivity in Research Laboratories
  - William Shockley
  - '1957'
  - 10.1109/JRPROC.1957.278364
  - It is well-known that some workers in scientific research laboratories are enormously
    more creative than others. If the number of scientific publications is used as
    a measure of productivity, it is found that some individuals create new science
    at a rate at least 50 times greater than others. Thus differences in rates of
    scientific production are much bigger than differences in the rates of performing
    simpler acts, such as the rate of running the mile, or the number of words a man
    can speak per minute. On the basis of statistical studies of rates of publication,
    it is found that it is more appropriate to consider not simply the rate of publication
    but its logarithm. The logarithm appears to have a normal distribution over the
    population of typical research laboratories. The existence of a "log-normal distribution"
    suggests that the logarithm of the rate of production is a manifestation of some
    fairly fundamental mental attribute. The great variation in rate of production
    from one individual to another can be explained on the basis of simplified models
    of the mental processes concerned. The common feature in the models is that a
    large number of factors are involved so that small changes in each, all in the
    same direction, may result in a very large [multiplicative] change in output.
    For example, the number of ideas a scientist can bring into awareness at one time
    may control his ability to make an invention and his rate of invention may increase
    very rapidly with this number.
- - /docs/psychology/1993-lipsey.pdf
  - ! 'The Efficacy of Psychological, Educational, and Behavioral Treatment: Confirmation
    from Meta-Analysis'
  - Mark W. Lipsey, David B. Wilson
  - '1993'
  - ''
  - Conventional reviews of research on the efficacy of psychological, educational,
    and behavioral treatments often find considerable variation in outcome among studies
    and, as a consequence, fail to reach firm conclusions about the overall effectiveness
    of the interventions in question. In contrast meta-analytic reviews show a strong,
    dramatic pattern of positive overall effects that cannot readily be explained
    as artifacts of meta-analytic technique or generalized placebo effects. Moreover,
    the effects are not so small that they can be dismissed as lacking practical or
    clinical significance. Although meta-analysis has limitations, there are good
    reasons to believe that its results are more credible than those of conventional
    reviews and to conclude that well-developed psychological, educational, and behavioral
    treatment is generally efficacious.
- - /docs/nootropics/2013-rojas.pdf
  - Neurological and psychological applications of transcranial lasers and LEDs
  - Julio C.Rojas, F.Gonzalez-Lima
  - '2013'
  - 10.1016/j.bcp.2013.06.012
  - Transcranial brain stimulation with low-level light/laser therapy (LLLT) is the
    use of directional low-power and high-fluency monochromatic or quasimonochromatic
    light from lasers or LEDs in the red-to-near-infrared wavelengths to modulate
    a neurobiological function or induce a neurotherapeutic effect in a nondestructive
    and non-thermal manner. The mechanism of action of LLLT is based on photon energy
    absorption by cytochrome oxidase, the terminal enzyme in the mitochondrial respiratory
    chain. Cytochrome oxidase has a key role in neuronal physiology, as it serves
    as an interface between oxidative energy metabolism and cell survival signaling
    pathways. Cytochrome oxidase is an ideal target for cognitive enhancement, as
    its expression reflects the changes in metabolic capacity underlying higher-order
    brain functions. This review provides an update on new findings on the neurotherapeutic
    applications of LLLT. The photochemical mechanisms supporting its cognitive-enhancing
    and brain-stimulatory effects in animal models and humans are discussed. LLLT
    is a potential non-invasive treatment for cognitive impairment and other deficits
    associated with chronic neurological conditions, such as large vessel and lacunar
    hypoperfusion or neurodegeneration. Brain photobiomodulation with LLLT is paralleled
    by pharmacological effects of low-dose USP methylene blue, a non-photic electron
    donor with the ability to stimulate cytochrome oxidase activity, redox and free
    radical processes. Both interventions provide neuroprotection and cognitive enhancement
    by facilitating mitochondrial respiration, with hormetic dose-response effects
    and brain region activational specificity. This evidence supports enhancement
    of mitochondrial respiratory function as a generalizable therapeutic principle
    relevant to highly adaptable systems that are exquisitely sensitive to energy
    availability such as the nervous system.
- - /docs/radiance/2005-gusterson.pdf
  - ! 'A Pedagogy of Diminishing Returns: Scientific Involution across Three Generations
    of Nuclear Weapons Science'
  - Hugh Gusterson
  - '2005'
  - ''
  - ! '<p>A generation of historians, sociologists, and anthropologists of science
    has learned from actor-network theory and the sociology of scientific knowledge
    (SSK) to focus on the building of scientific institutions and facts, and from
    Thomas Kuhn to expect a certain historical rhythm in the evolution of scientific
    fields of knowledge: first, a dynamic burst of creativity (the "revolution") as
    the foundational ideas of the new field are laid down; second, a period of "normal
    science" in which gaps are filled in as the new knowledge is institutionalized;
    and, finally, as puzzles emerge that cannot be fully explained by the established
    paradigm, a new burst of creativity as another generation redefines the fundamental
    precepts of the field.</p><p>In this essay, looking at three generations of nuclear
    weapons designers, I follow and then depart from the Kuhnian script. Although
    the first two generations of nuclear weapons scientists conformed perfectly to
    the Kuhnian storyline, the final story is not about the punctuated equilibrium
    of scientific revolution, but about a process of scientific involution as nuclear
    weapons science has simultaneously matured and withered in a way that is beautifully
    evoked in a blues ballad once sung for me by a group of weapons designers from
    the Lawrence Livermore National Laboratory:</p><blockquote><p>Went down to Amarillo<br/>Lookin''
    for my sweet ''53<sup>3</sup><br/>It was laying on a long white table<br/>Looked
    cold and hard to me<br/>Let it go, let it go, retire it<br/>No city scrapers do
    we need<br/>Take a 61<sup>4</sup> and modify it.<br/>Call it the mod 11-E<br/>Now
    you can search this whole world over<br/>From Frisco to Albuquerque<br/>You can
    mentor anyone that you want to<br/>But you''ll never find designers like me<br/>Now
    when I''m gone, just put me way down<br/>In a hole off the old Orange Road.<br/>''ttach
    a cable to my device can<br/>So I can run those legacy codes (fading)<br/>So I
    can run those legacy codes<br/>So I can run those legacy codes.<sup>5</sup></p></blockquote><p>...The
    1970s and the 1980s, when nuclear testing moved underground, were a period of
    routinization: the institutional apparatus for nuclear weapons design and testing
    grew, its scientific achievements shrank, and the arteries of the weapons design
    bureaucracy hardened. Attempts to perfect a third-generation nuclear weapon—the
    x-ray laser—failed and were abandoned in an atmosphere of scandal and disgrace.<sup>11</sup>
    The art of weapons design progressed, but by increments rather than great leaps:
    weapons designers learned to squeeze greater yields out of smaller quantities
    of plutonium so that nuclear weapons could be made lighter and smaller, weapons
    were made safer through the addition of Permissive Action Links (PALS) and the
    substitution of Insensitive High Explosive (IHE) for conventional explosives,<sup>12</sup>
    and the supercomputer codes used to model the behavior of nuclear weapons were
    gradually refined. The names of the men (and now women) behind these achievements
    are largely unknown outside the nuclear weapons bureaucracy, and in some cases
    their achievements are only partially known within the weapons laboratories, thanks
    to the compartmentalizing effects of official secrecy in the weapons complex.<sup>13</sup></p><p>Nuclear
    tests were forbidden after the end of the Cold War, and the practice and pedagogy
    of nuclear weapons science shifted again. Forced to largely abandon their nuclear
    test site in Nevada—a place where the desert sands encroach on the old bowling
    alley and cinema, now disused, as tourist buses disgorge camera-laden voyeurs
    to gawk at the nuclear craters—many of the old-timers elected to retire. Those
    that stayed have regrouped their forces in the virtual world of simulated testing,
    where they are attempting to train a new generation of scientists to maintain
    devices they cannot test. In some ways the scientific challenges of nuclear weapons
    design have shrunk to microscopic proportions: new designs are not built or deployed,
    and even the decision to substitute a new epoxy in an aging weapon can send a
    tremor of fear through design teams unsure if their weapons will still work. In
    other ways, the scientific challenges are suddenly magnified: how to design implosion,
    shock wave, and laser fusion experiments that will shed light on the performance
    of aging nuclear weapons in the absence of nuclear testing? How to use the physics
    knowledge of today to understand test data, long buried in dusty filing cabinets,
    from the 1950s and the 1960s? And how to convert old two-dimensional codes designed
    for Cray supercomputers into three-dimensional codes that can run on massively
    parallel systems now being designed?</p>'
- - /docs/psychology/1963-gussow.pdf
  - ! 'A Preliminary Report of Kayak Angst Among the Eskimo of West Greenland: A Study
    in Sensory Deprivation'
  - Zachary Gussow
  - '1963'
  - 10.1177/002076406300900103
  - <p>Sensory deprivation experiences and isolation phenomena belong to the broader
    field of environmental stress and, as such, research in this area is of importance
    to the anthropologist concerned with mental disorder. In one form or another sensory
    deprivation is a universal experience. It is present in such diverse events as
    research experiments, sleep, vision experiences, 'highway hypnosis' and kayak-angst.
    Sensory deprivation and isolation may be culturally required, recommended, unavoidable
    or even individually sought out. Reactions are variable and are dependent upon
    the interplay of a number of factors. Experiences may be occupationally linked,
    as in the confused and disoriented reactions reported by aviators flying solo
    or in positions cut off from the rest of the crew. Creative people who seek out
    retreats in order to work more efficiently and productively, as well as persons
    on the couch in psychoanalytic treatment are also experiencing sensory deprivation,
    though in a mild form.</p><p>In kayak-angst the Eskimo of West Greenland provide
    us with an instance of a group where severe sensory deprivation reactions are
    culturally typical for the adult male segment of the population and forms a part
    of their routinized, seasonal, if not everyday, round of life.</p><p>Kayak-angst
    (kayak-phobia, kayak-dizziness) is well known throughout all districts of West
    Greenland. It is also known to occur among the Polar Eskimo and in East Greenland,
    though an intensive search of the literature, extensive correspondence, and interviews
    with eastern Canadian Eskimos has failed so far to document it for other Eskimo
    groups. Kayak-angst is scarcely mentioned in English written accounts, with the
    exception of brief references in Freuchen, Birket-Smith and a few others. On the
    other hand there is a considerable body of material in the Scandinavian languages,
    much of it gathered by Danish physicians. The condition was reported as early
    as 1806 and in 1949 Dr. Av M Ch. Ehrstrom diagnosed 24 cases in one of the northern
    districts. Kenneth I. Taylor, a student of anthropology with considerable kayak
    experience informs me (private communication) that as recently as 1959 he met
    three such individuals in Northwest Greenland. In 1900, Meldorf estimated that
    10% of all men in the Julianhaab district over the age of 18 suffered from kayak-angst.
    Others have regarded it as the 'national disease' of the West Greenland Eskimo.</p><p>Material
    for the present paper is based on an analysis of 13 cases out of the 60 kayak-angst
    individuals medically examined and interviewed by Bertelsen in 1905.</p><p><em>Kayak-Angst
    Syndrome</em></p><p>Typically, kayak-angst afflict male hunters out alone on a
    calm, 'mirroring' slightly wavy sea or lake, close to or at a distance from shore,
    either while paddling or sitting quietly. Under these conditions of sea, and especially
    with the sun directly overhead or in his eyes, there develops a lowering in the
    level of consciousness brought on by the absence of external reference points
    at a time when the hunter is involved in a visually 'fixed' or staring position
    demanding minimal or repetitive movements. A lesser number report they are equally
    affected in storms, windy or rough weather. Some claim not to have attacks when
    in the company of others and consequently will never hunt alone. A few report
    attacks when others are around, though claim they are less severe at this time.
    On the other hand some report that the presence of others increases their anxiety.
    One man was afraid their kayaks might collide, particularly in storms. Another
    said he felt at ease only in the company of men he trusted.</p>
- - /docs/lithium/2014-mauer.pdf
  - ! 'Standard and trace-dose lithium: A systematic review of dementia prevention
    and other behavioral benefits'
  - Sivan Mauer, Derick Vergne, S. Nassir Ghaemi
  - 2014-06-11
  - 10.1177/0004867414536932
  - ! '<p><em>Objective</em>: Dementia is a major public health issue, with notably
    high rates in persons with mood illnesses. Lithium has been shown to have considerable
    neuroprotective effects, even in trace or low doses. The aim of this review is
    to summarize the current understanding of lithium benefits in trace or low doses
    in dementia prevention and for other behavioral or medical benefits.</p><p><em>Methods</em>:
    A systematic review identified 24 clinical, epidemiological, and biological reports
    that met inclusion criteria of assessing lithium in standard or low doses for
    dementia or other behavioral or medical benefits.</p><p><em>Results</em>: 5 out
    of 7 epidemiological studies found an association between standard-dose lithium
    and low dementia rates. 9 out of 11 epidemiological studies, usually of drinking
    water sources, found an association between trace-dose lithium and low suicide/homicide/mortality
    and crime rates. All four small randomized clinical trials of lithium for Alzheimer''s
    dementia have found at least some clinical or biological benefits versus placebo.
    Only one small randomized clinical trial (RCT) of trace lithium has been conducted,
    assessing mood symptoms in former substance abusers, and found benefit with lithium
    versus placebo.</p><p><em>Conclusions</em>: Lithium, in both standard and trace
    doses, appears to have biological benefits for dementia, suicide, and other behavioral
    outcomes. Further RCT research of trace lithium in dementia is warranted. [Keywords:
    Cognition, dementia, lithium, prevention, standard dose, trace]</p>'
- - /docs/eva/2008-gardner.pdf
  - Aum Shinrikyo and a Panic About Manga and Anime
  - Richard A. Gardner
  - '2008'
  - 10.4324/9781315703152-16
  - <p>In the midst of the accolades, it is important to recall that there have been
    moments in recent history when manga and anime have been regarded as potentially
    dangerous or as emblems of what is wrong with Japan.</p><p>Such was the case in
    the months following the release of sarin gas in several Tokyo subway lines by
    members of the religious group Aum Shinrikyo on the morning of March 20, 1995.
    As the extent of the Aum's crimes gradually became clear, Japanese journalists,
    scholars, intellectuals, and commentators of every sort attempted to explain the
    origin and rise of Aum, the reasons for the group's turn to violence, and what
    the appearance of such a group might mean about Japan. In the various theories
    and explanations presented, nearly every aspect of Japanese society, culture,
    and religion has been held to be at least partially accountable for the rise of
    Aum and the turn to violence by some of its members (see Gardner 1999, 221–222;
    2002a, 36–42). In the efforts to explain Aum, considerable attention was given
    to the roles that manga and anime might have played. This resulted in what might
    be described as a panic about their possible negative influence on Japanese culture
    and society. Rather than attempting to explain precisely how manga and anime might
    have contributed to the rise of Aum and its vision of 'Harumagedon', or Armageddon,
    this chapter will simply present an overview of the ways in which both members
    of Aum and commentators on Aum understood the role of manga and anime in relation
    to Aum. Attention will be given, in particular, to how these perceptions were
    linked with broader concerns about the possible negative influence of various
    forms of media, technology, and 'virtual reality'.</p>
- - /docs/statistics/bias/2013-ioannidis.pdf
  - What's to know about the credibility of empirical economics?
  - John Ioannidis, Chris Doucouliagos
  - '2013'
  - 10.1111/joes.12032
  - ! 'The scientific credibility of economics is itself a scientific question that
    can be addressed with both theoretical speculations and empirical data. In this
    review, we examine the major parameters that are expected to affect the credibility
    of empirical economics: sample size, magnitude of pursued effects, number and
    pre-selection of tested relationships, flexibility and lack of standardization
    in designs, definitions, outcomes and analyses, financial and other interests
    and prejudices, and the multiplicity and fragmentation of efforts. We summarize
    and discuss the empirical evidence on the lack of a robust reproducibility culture
    in economics and business research, the prevalence of potential publication and
    other selective reporting biases, and other failures and biases in the market
    of scientific information. Overall, the credibility of the economics literature
    is likely to be modest or even low. [Keywords: Bias; Credibility; Economics; Meta-research;
    Replication; Reproducibility]'
- - /docs/iq/smpy/2013-kell.pdf
  - ! 'Who Rises to the Top?: Early Indicators'
  - Harrison J. Kell, David Lubinski, Camilla P. Benbow
  - 2013-03-26
  - 10.1177/0956797612457784
  - ! 'Youth identified before age 13 (<em>n</em> = 320) as having profound mathematical
    or verbal reasoning abilities (top 1 in 10,000) were tracked for nearly three
    decades. Their awards and creative accomplishments by age 38, in combination with
    specific details about their occupational responsibilities, illuminate the magnitude
    of their contribution and professional stature. Many have been entrusted with
    obligations and resources for making critical decisions about individual and organizational
    well-being. Their leadership positions in business, health care, law, the professoriate,
    and STEM (science, technology, engineering, and mathematics) suggest that many
    are outstanding creators of modern culture, constituting a precious human-capital
    resource. Identifying truly profound human potential, and forecasting differential
    development within such populations, requires assessing multiple cognitive abilities
    and using atypical measurement procedures. This study illustrates how ultimate
    criteria may be aggregated and longitudinally sequenced to validate such measures.
    [Keywords: cognitive abilities, creativity, human capital, intelligence, profoundly
    gifted, STEM]'
- - /docs/psychology/1955-abramson.pdf
  - ! 'Lysergic Acid Diethylamide (LSD-25): Xv. the Effects Produced By Substitution
    of a Tap Water Placebo'
  - H. A. Abramson, M. E. Jarvik, A. Levine, M. R. Kaufman, M. W. Hirsch
  - '1955'
  - 10.1080/00223980.1955.9712991
  - ! '<p>The purpose of this paper is to study the responses given to a questionnaire
    by subjects who received a tap water ''placebo'' instead of lysergic acid diethylamide
    (LSD-25), and to relate the number of responses to other variables. These variables
    are: body weight, number of responses on a health questionnaire, arithmetic test
    scores, scores on the Wechsler-Bellevue Intelligence Scale, and Rorschach test
    responses.</p><p>...Figure 4 shows for each question the percentage and number
    of subjects out of 28 who gave a positive response at least once during the 0.5,
    2.5, and 4.5-hour intervals. The questions appear in the figure in the order of
    decreasing percentages of response to them. The time of the response and the magnitude
    are disregarded in this tabulation. The question receiving the greatest percentage
    response was (Subject 24), "Are your palms moist?" As many as 60.7 per cent reported
    this symptom. Half of the subjects reported headache (Subject 13) , fatigue (Subject
    44), and drowsiness (Subject 45). About 36 per cent reported anxiety (Subject
    47). Illness (Subject 1), and dizziness (Subject 15) were reported by 28.6 per
    cent of the group and 25 per cent indicated a dream-like feeling (Subject 46),
    increased appetite (Subject 6), unsteadiness (Subject 16), a hot feeling (Subject
    22) , heaviness of hands and feet (Subject 30), and weakness (Subject 43). There
    were 19 questions which received positive responses from between 10 and 22 per
    cent of the subjects. Less than 10 per cent of the group (or no more than two
    subjects) responded positively to the remaining questions, but each question received
    a positive response from at least one subject.</p><p>...The findings point out
    that a substance such as tap water, which is generally considered chemically and
    pharmacologically inactive, is capable of eliciting certain responses from certain
    subjects who believe they have received lysergic acid diethylamide. These observations
    emphasize once more the need for placebo controls in studies investigating the
    effects of drugs; without them changes which are produced merely by the situation
    and not by the drug are frequently falsely attributed to the action of the drug...Most
    subjects who respond to a placebo tend to do so most markedly during the first
    0.5 hour after receiving the substance. At this time their anticipation of, and
    anxiety about, the effects of LSD-25 are probably greatest. Gradually the effects
    wear off, as the anticipation wears off. Individual differences exist in the time
    of peak effect, but this is the most common finding. The questions which elicited
    the greatest percentage response from the group were those related to anxiety
    (moist palms and feeling anxious) or to phenomena which commonly occur without
    the presence of any foreign agent (drowsiness, fatigue, and headache). The remaining
    questions received random responses. The fact that there is a wide range in the
    number of positive responses made to the questionnaire is of major interest.</p>'
- - /docs/statistics/bias/2008-scherer.pdf
  - Full publication of results initially presented in abstracts
  - Roberta W. Scherer, Patricia Langenberg, Erik von Elm
  - '2007'
  - 10.1002/14651858.MR000005.pub3
  - ! '<p><b>Studies initially reported as conference abstracts that have positive
    results are subsequently published as full-length journal articles more often
    than studies with negative results.</b></p><p>Less than half of all studies, and
    about 60% of randomized or controlled clinical trials, initially presented as
    summaries or abstracts at professional meetings are subsequently published as
    peer-reviewed journal articles. An important factor appearing to influence whether
    a study described in an abstract is published in full is the presence of ''positive''
    results in the abstract. Thus, the efforts of persons trying to collect all of
    the evidence in a field may be stymied, first by the failure of investigators
    to take abstract study results to full publication, and second, by the tendency
    to take to full publication only those studies reporting ''significant'' results.
    The consequence of this is that systematic reviews will tend to over-estimate
    treatment effects.</p><p><em>Background</em>: Abstracts of presentations at scientific
    meetings are usually available only in conference proceedings. If subsequent full
    publication of abstract results is based on the magnitude or direction of study
    results, publication bias may result. Publication bias, in turn, creates problems
    for those conducting systematic reviews or relying on the published literature
    for evidence.</p><p><em>Objectives</em>: To determine the rate at which abstract
    results are subsequently published in full, and the time between meeting presentation
    and full publication.</p><p><em>Search methods</em>: We searched MEDLINE, EMBASE,
    The Cochrane Library, Science Citation Index, reference lists, and author files.
    Date of most recent search: June 2003. Selection criteria We included all reports
    that examined the subsequent full publication rate of biomedical results initially
    presented as abstracts or in summary form. Follow-up of abstracts had to be at
    least two years.</p><p><em>Data collection and analysis</em>: Two reviewers extracted
    data. We calculated the weighted mean full publication rate and time to full publication.
    Dichotomous variables were analyzed using relative risk and random effects models.
    We assessed time to publication using Kaplan-Meier survival analyses.</p><p><em>Main
    results</em>: Combining data from 79 reports (29,729 abstracts) resulted in a
    weighted mean full publication rate of 44.5% (95% confidence interval (CI) 43.9
    to 45.1). Survival analyses resulted in an estimated publication rate at 9 years
    of 52.6% for all studies, 63.1% for randomized or controlled clinical trials,
    and 49.3% for other types of study designs.</p><p>''Positive'' results defined
    as any ''significant'' result showed an association with full publication (RR
    = 1.30; CI 1.14 to 1.47), as did ''positive'' results defined as a result favoring
    the experimental treatment (RR =1.17; CI 1.02 to 1.35), and ''positive'' results
    emanating from randomized or controlled clinical trials (RR = 1.18, CI 1.07 to
    1.30).</p><p>Other factors associated with full publication include oral presentation
    (RR = 1.28; CI 1.09 to 1.49); acceptance for meeting presentation (RR = 1.78;
    CI 1.50 to 2.12); randomized trial study design (RR = 1.24; CI 1.14 to 1.36);
    and basic research (RR = 0.79; CI 0.70 to 0.89). Higher quality of abstracts describing
    randomized or controlled clinical trials was also associated with full publication
    (RR = 1.30, CI 1.00 to 1.71).</p><p><em>Authors'' conclusions</em>: Only 63% of
    results from abstracts describing randomized or controlled clinical trials are
    published in full. ''Positive'' results were more frequently published than not
    ''positive'' results.</p>'
- - /docs/melatonin/2013-preckel.pdf
  - ! 'Morningness-eveningness and educational outcomes: the lark has an advantage
    over the owl at high school'
  - Franzis Preckel, Anastasiya A. Lipnevich, Katharina Boehme, Lena Brandner, Karsten
    Georgi, Tanja Könen, Katharina Mursin, Richard D. Roberts
  - 2012-01-02
  - 10.1111/j.2044-8279.2011.02059.x
  - ! '<p><em>Background</em>: Chronotype refers to individuals'' preference for morning
    or evening activities. Its two dimensions (morningness and eveningness) are related
    to a number of academic outcomes.</p><p><em>Aims</em>: The main goal of the study
    was to investigate the incremental validity of chronotype as a predictor of academic
    achievement after controlling for a number of traditional predictors. In so doing,
    a further aim was ongoing validation of a chronotype questionnaire, the Lark-Owl
    Chronotype Indicator.</p><p><em>Sample</em>: The sample comprised 272 students
    attending 9th and 10th grades at five German high schools. Data was also obtained
    from 132 parents of these students.</p><p><em>Method</em>: Students were assessed
    in class via self-report questionnaires and a standardized cognitive test. Parents
    filled out a questionnaire at home. The incremental validity of chronotype was
    investigated using hierarchical linear regression. Validity of the chronotype
    questionnaire was assessed by correlating student ratings of their chronotype
    with behavioural data on sleep, food intake, and drug consumption and with parent
    ratings of chronotype.</p><p><em>Results</em>: Eveningness was a significant (negative)
    predictor of overall grade point average (GPA), math-science GPA, and language
    GPA, after cognitive ability, conscientiousness, need for cognition, achievement
    motivation, and gender were held constant. Validity evidence for the chronotype
    measure was established by significant correlations with parent-ratings and behavioural
    data.</p><p><em>Conclusions</em>: Results point to the possible discrimination
    of adolescents with a proclivity towards eveningness at school. Possible explanations
    for the relationship between chronotype and academic achievement are presented.
    Implications for educational practice are also discussed.</p>'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959137/
  - The Unilateralist's Curse and the Case for a Principle of Conformity
  - Nick Bostrom, Thomas Douglas, Anders Sandberg
  - 2016-01-26
  - 10.1080/02691728.2015.1108373
  - ! 'In some situations a number of agents each have the ability to undertake an
    initiative that would have significant effects on the others. Suppose that each
    of these agents is purely motivated by an altruistic concern for the common good.
    We show that if each agent acts on her own personal judgment as to whether the
    initiative should be undertaken, then the initiative will be undertaken more often
    than is optimal. We suggest that this phenomenon, which we call the unilateralist''s
    curse, arises in many contexts, including some that are important for public policy.
    To lift the curse, we propose a principle of conformity, which would discourage
    unilateralist action. We consider three different models for how this principle
    could be implemented, and respond to an objection that could be raised against
    it. [Keywords: The Winner''s Curse, Disagreement, Rationality, Aumann, informative
    prior, shrinkage, bid shading]'
- - /docs/psychology/2014-vyssoki.pdf
  - Direct Effect of Sunshine on Suicide
  - Benjamin Vyssoki, Nestor D. Kapusta, Nicole Praschak-Rieder, Georg Dorffner, Matthaeus
    Willeit
  - 2014:09:10
  - 10.1001/jamapsychiatry.2014.1198
  - ! '<p><em>Importance</em>: It has been observed that suicidal behavior is influenced
    by sunshine and follows a seasonal pattern. However, seasons bring about changes
    in several other meteorological factors and a seasonal rhythm in social behavior
    may also contribute to fluctuations in suicide rates.</p><p><em>Objective</em>:
    To investigate the effects of sunshine on suicide incidence that are independent
    of seasonal variation.</p><p><em>Design, Setting, and Participants</em>: Retrospective
    analysis of data on all officially confirmed suicides in Austria between January
    1, 1970, and May 6, 2010 (<em>n</em> = 69 462). Data on the average duration of
    sunshine per day (in hours) were calculated from 86 representative meteorological
    stations. Daily number of suicides and daily duration of sunshine were differentiated
    to remove variation in sunshine and variation in suicide incidence introduced
    by season. Thereafter, several models based on Pearson correlation coefficients
    were calculated.</p><p><em>Main Outcomes and Measures</em>: Correlation of daily
    number of suicides and daily duration of sunshine after mathematically removing
    the effects of season.</p><p><em>Results</em>: Sunshine hours and number of suicides
    on every day from January 1, 1970, to May 6, 2010, were highly correlated (<em>r</em> = 0.4870;
    <em>p</em> &lt; 10<sup>−9</sup>). After differencing for the effects of season,
    a mathematical procedure that removes most of the variance from the data, a positive
    correlation between number of suicides and hours of daily sunshine remained for
    the day of suicide and up to 10 days prior to suicide (<em>r<sub>maximum</sub></em> = 0.0370;
    <em>p</em> &lt; 10<sup>−5</sup>). There was a negative correlation between the
    number of suicides and daily hours of sunshine for the 14 to 60 days prior to
    the suicide event (<em>r<sub>minimum</sub></em> = −0.0383; <em>p</em> &lt; 10<sup>−5</sup>).
    These effects were found in the entire sample and in violent suicides.</p><p><em>Conclusions
    and Relevance</em>: Duration of daily sunshine was significantly correlated with
    suicide frequency independent of season, but effect sizes were low. Our data support
    the hypothesis that sunshine on the day of suicide and up to 10 days prior to
    suicide may facilitate suicide. More daily sunshine 14 to 60 days previously is
    associated with low rates of suicide. Our study also suggests that sunshine during
    this period may protect against suicide.</p>'
- - /docs/nootropics/2015-hall.pdf
  - ! 'Genetics and the placebo effect: the placebome'
  - Kathryn T. Hall, Joseph Loscalzo, Ted J. Kaptchuk
  - 2015-05-01
  - 10.1016/j.molmed.2015.02.009
  - <ul><li>Predisposition to respond to placebo treatment may be in part a stable
    heritable trait.</li><li>Candidate placebo response pathways may interact with
    drugs to modify outcomes in both the placebo and drug treatment arms of clinical
    trials.</li><li>Genomic analysis of randomized placebo and no-treatment controlled
    trials are needed to fully realize the potential of the placebome.</li></ul><p>Placebos
    are indispensable controls in randomized clinical trials (RCTs), and placebo responses
    significantly contribute to routine clinical outcomes. Recent neurophysiological
    studies reveal neurotransmitter pathways that mediate placebo effects. Evidence
    that genetic variations in these pathways can modify placebo effects raises the
    possibility of using genetic screening to identify placebo responders and thereby
    increase RCT efficacy and improve therapeutic care. Furthermore, the possibility
    of interaction between placebo and drug molecular pathways warrants consideration
    in RCT design. The study of genomic effects on placebo response, 'the placebome',
    is in its infancy. Here, we review evidence from placebo studies and RCTs to identify
    putative genes in the placebome, examine evidence for placebo-drug interactions,
    and discuss implications for RCTs and clinical care.</p>
- - /docs/radiance/1995-mackenzie.pdf
  - Tacit Knowledge, Weapons Design, and the Uninvention of Nuclear Weapons
  - Donald MacKenzie, Graham Spinardi
  - '1995'
  - 10.1086/230699
  - ! '''Tacit Knowledge'', embodied in people rather than words, equations, or diagrams,
    plays a vital role in science. The historical record of the development and spread
    of nuclear weapons and the recollections of their designers suggest that tacit
    knowledge is also crucial to nuclear weapons development. Therefore, if design
    ceases, and if there is no new generation of designers to whom that tacit knowledge
    can be passed, then in an important (though qualified) sense nuclear weapons will
    have been uninvented. Their renewed development would thus have some of the characteristics
    of reinvention rather than simply copying. In addition, knowledge may be lost
    not only as a result of complete disarmament, but also as a consequence of likely
    measures such as a nuclear test ban.'
- - /docs/genetics/2015-rottensteiner.pdf
  - Physical activity, fitness, glucose homeostasis, and brain morphology in twins
  - Mirva Rottensteiner, Tuija Leskinen, Eini Niskanen, Sari Aaltonen, Sara Mutikainen,
    Jan Wikgren, Kauko Heikkilä, Vuokko Kovanen, Heikki Kainulainen, Jaakko Kaprio,
    Ina Tarkka, Urho Kujala
  - '2015'
  - 10.1249/MSS.0000000000000437
  - ! '<p><em>Purpose</em>: The main aim of the present study (FITFATTWIN) was to
    investigate how physical activity level is associated with body composition, glucose
    homeostasis, and brain morphology in young adult male monozygotic twin pairs discordant
    for physical activity.</p><p><em>Methods</em>: From a population-based twin cohort,
    we systematically selected 10 young adult male monozygotic twin pairs (age range,
    32–36 yr) discordant for leisure time physical activity during the past 3 yr.
    On the basis of interviews, we calculated a mean sum index for leisure time and
    commuting activity during the past 3 yr (3-yr LTMET index expressed as MET-hours
    per day). We conducted extensive measurements on body composition (including fat
    percentage measured by dual-energy x-ray absorptiometry), glucose homeostasis
    including homeostatic model assessment index and insulin sensitivity index (Matsuda
    index, calculated from glucose and insulin values from an oral glucose tolerance
    test), and whole brain magnetic resonance imaging for regional volumetric analyses.</p><p><em>Results</em>:
    According to pairwise analysis, the active twins had lower body fat percentage
    (<em>p</em> = 0.029) and homeostatic model assessment index (<em>p</em> = 0.031)
    and higher Matsuda index (<em>p</em> = 0.021) compared with their inactive co-twins.
    Striatal and prefrontal cortex (subgyral and inferior frontal gyrus) brain gray
    matter volumes were larger in the nondominant hemisphere in active twins compared
    with those in inactive co-twins, with a statistical threshold of <em>p</em> &lt;
    0.001.</p><p><em>Conclusions</em>: Among healthy adult male twins in their mid-30s,
    a greater level of physical activity is associated with improved glucose homeostasis
    and modulation of striatum and prefrontal cortex gray matter volume, independent
    of genetic background. The findings may contribute to later reduced risk of type
    2 diabetes and mobility limitations.</p>'
- - /docs/statistics/causality/2017-allamee.pdf
  - ! 'Percutaneous coronary intervention in stable angina (ORBITA): a double-blind,
    randomised controlled trial'
  - Rasha Al-Lamee, David Thompson, Hakim-Moulay Dehbi, Sayan Sen, Kare Tang, John
    Davies, Thomas Keeble, Michael Mielewczik, Raffi Kaprielian, Iqbal S Malik, Sukhjinder
    S Nijjer, Ricardo Petraco, Christopher Cook, Yousif Ahmad, James Howard, Christopher
    Baker, Andrew Sharp, Robert Gerber, Suneel Talwar, Ravi Assomull, Jamil Mayet,
    Roland Wensel, David Collier, Matthew Shun-Shin, Simon A Thom, Justin E Davies,
    Darrel P Francis
  - 2017-11-02
  - 10.1016/S0140-6736(17)32714-9
  - ! '<p><em>Summary: Background Symptomatic relief is the primary goal of percutaneous
    coronary intervention (PCI) in stable angina and is commonly observed clinically.
    However, there is no evidence from blinded, placebo-controlled randomised trials
    to show its efficacy.</p><p><em>Methods>/em>: ORBITA is a blinded, multicentre
    randomised trial of PCI versus a placebo procedure for angina relief that was
    done at five study sites in the UK. We enrolled patients with severe (≥70%) single-vessel
    stenoses. After enrolment, patients received 6 weeks of medication optimisation.
    Patients then had pre-randomisation assessments with cardiopulmonary exercise
    testing, symptom questionnaires, and dobutamine stress echocardiography. Patients
    were randomised 1:1 to undergo PCI or a placebo procedure by use of an automated
    online randomisation tool. After 6 weeks of follow-up, the assessments done before
    randomisation were repeated at the final assessment. The primary endpoint was
    difference in exercise time increment between groups. All analyses were based
    on the intention-to-treat principle and the study population contained all participants
    who underwent randomisation. This study is registered with ClinicalTrials.gov,
    number NCT02062593.</p><p><em>Findings</em>: ORBITA enrolled 230 patients with
    ischaemic symptoms. After the medication optimisation phase and between Jan 6,
    2014, and Aug 11, 2017, 200 patients underwent randomisation, with 105 patients
    assigned PCI and 95 assigned the placebo procedure. Lesions had mean area stenosis
    of 84.4% (SD 10.2), fractional flow reserve of 0.69 (0.16), and instantaneous
    wave-free ratio of 0.76 (0.22). There was no significant difference in the primary
    endpoint of exercise time increment between groups (PCI minus placebo 16.6 s,
    95% CI -8.9 to 42.0, <em>p</em>=0.200). There were no deaths. Serious adverse
    events included four pressure-wire related complications in the placebo group,
    which required PCI, and five major bleeding events, including two in the PCI group
    and three in the placebo group.</p><p><em>Interpretation</em>: In patients with
    medically treated angina and severe coronary stenosis, PCI did not increase exercise
    time by more than the effect of a placebo procedure. The efficacy of invasive
    procedures can be assessed with a placebo control, as is standard for pharmacotherapy.</p>'
- - https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc
  - ! 'OpenGPT-2: We Replicated GPT-2-1.5b Because You Can Too'
  - Aaron Gokaslan, Vanya Cohen
  - 2019-08-22
  - ''
  - <p>Recently, large language models like BERT¹, XLNet², GPT-2³, and Grover⁴ have
    demonstrated impressive results generating new content and multiple tasks. Since
    Open-AI has not released their largest model [GPT-2-1.5b] at this time, we seek
    to replicate the model to allow others to build on our pretrained model and further
    improve it. You can access the model and generate text using our Google Colab.</p><p>...We
    demonstrate that many of the results of the paper can be replicated by two masters
    students...Because our replication efforts are not unique, and large language
    models are the current most effective means of countering generated text, we believe
    releasing our model is a reasonable first step towards countering the potential
    future abuse of these kinds of models.</p><p>We base our implementation off of
    the Grover model⁴ and modify their codebase to match the language modeling training
    objective of GPT-2. Since their model was trained on a similarly large corpus,
    much of the code and hyperparameters proved readily reusable. We did not substantially
    change the hyperparameters from Grover.</p><p>From start to finish, we estimate
    that we use under $500,000 in cloud compute for all of our experiments including
    searching for hyper-parameters and testing various cleaning methods on our datasets.
    The cost of training the model from scratch using our code is about $50,000.</p><p>...Despite
    the differences in our training distribution, we do report similar perplexities
    over most datasets.</p>
- - https://scholars-stage.blogspot.com/2014/09/what-edward-luttwak-doesnt-know-about.html
  - What Edward Luttwak Doesn't Know About Ancient China (Or a Short History of Han-Xiongnu
    Relations), pt. 1
  - Tanner Greer
  - 2014-10-04
  - ''
  - ! 'A few weeks ago a friend passed along one of the least correct essays I have
    ever had the misfortune to read. It was written by Edward Luttwak...In it Luttwak
    suggests contemporary Chinese foreign policy follows a pattern first seen in the
    foreign relations of the Han Dynasty two millennia ago:<br><blockquote>Formidable
    mounted archers and capable of sustained campaigning (a primary objective of the
    Steppe State), the Xiongnú ravaged and savaged and extorted tribute from the perpetually
    less martial, and certainly cavalry-poor Han until the latter finally felt able
    to resist again. Even then, 147 years of intermittent warfare ensued until Huhanye
    (呼韓邪), the paramount Chanyu (Qagan, Khan) of the Xiongnú, personally and formally
    submitted to the emperor Han Xuandi in 51 BCE, undertaking to pay homage, to leave
    a son at court as a hostage, and to deliver tribute, as befitted a vassal. That
    was a very great downfall from the familial status of earlier Chanyus of the epoch
    of Xiongnú predominance, who were themselves recognized as emperors, whose sons
    and heirs could have imperial daughters in marriage, and who from 200 BCE had
    received tribute from the Han, instead of the other way around. It is this successful
    transformation of a once superior power first into an equal (signified by imperial
    marriages) and then into a subservient client-state that seems to have left an
    indelible residue in China''s tradition of statecraft.</blockquote><br>..if Edward
    Luttwak wants to talk about how the echoes of the Han-Xiongnu war can be heard
    in modern China''s foreign policy, I am all ears.  Long term readers of The Stage
    know that there are few conversation starters I would find more thrilling to hear.
    Too many contemporary controversies cannot be understood until we step back and
    look at world affairs from the long view of history. But there is a catch in all
    this: <em>the history has to be correct</em>. It must accord to the facts. If
    one uses the past to interpret the present then your reading must be based on
    events that <em>actually</em> happened. This cannot be said for Mr. Luttwak''s
    essay. The story he tells simply did not happen.<br>Luttwak''s descriptions of
    the <em>heqin</em> policy''s aim is basically correct. It was designed to corrupt
    the Xiongnu and slowly ''Sinicize'' them. It was designed, through the power of
    Confucian family norms, to subordinate the Xiongnu ruler to Han Emperor.<br>What
    Luttwak neglects to mention is that the policy was a complete and utter failure.'
- - https://scholars-stage.blogspot.com/2014/09/what-edward-luttwak-doesnt-know-about_6.html
  - What Edward Luttwak Doesn't Know About Ancient China (Or a Short History of Han-Xiongnu
    Relations), pt. 2
  - Tanner Greer
  - 2014-10-06
  - ''
  - If the 'peace marriage' (<em>heqin</em>) system Luttwak describes did not do the
    Xiongnu in, what did?<br>...The logistics machine the Han created to defeat the
    Xiongnu is one of the marvels of the ancient world [3]. Each of the Han's campaigns
    was a feat worthy of Alexander the Great. But Alexander only pushed to India once.
    The Han launched these campaigns year after year for <em>decades</em> [4]. The
    sheer expanse of the conflict is staggering; Han armies ranged from Fergana to
    Manchuria, theaters 3,000 miles apart. Each campaign required the mobilization
    of tens of thousands of men and double the number of animals. Chang Chun-shu has
    tallied the numbers:<br><blockquote>"In the many campaigns in the Western regions
    (Hexi, Qiang, and Xiyu) and the Xiongnu land, the Han sent a total force of over
    1.2 million cavalrymen, 800,000 foot soldiers, and 10.5 million men in support
    and logistic roles. The total area of lad seized in Hexi alone was 426,700 square
    kilometers. In developing this region the Han spent 100 billion in cash per year,
    compared to the regular annual government revenue of 12 billion. In the process
    the Han government moved from the interior over 1 million people to populate and
    develop the Hexi river. Thus the Han conquest of the land west of the Yellow River
    was the greatest expansion in Chinese history." [5]</blockquote><br>The demands
    of the war forced the Han to restructure not only the Chinese state, but all of
    Chinese society. [6] The Han's willingness to radically restructure their society
    to meet the immense financial and logistic demands of an eighty year conflict
    is one of the central reasons they emerged victorious from it.<br>...The Han followed
    the same basic strategy. The aim of generals like Wei Qing and Huo Qubing was
    to kill every single man, woman and child they came across and by doing so instill
    such terror in their enemies that tribes would surrender <em>en masse</em> upon
    their arrival. By trapping the Xiongnu into one bloody slug match after another
    the Han forced them into a grinding war of attrition that favored the side with
    the larger population reserves. The Xiongnu were unprepared for such carnage in
    their own lands; within the first decade of the conflict the Han's sudden attacks
    forced the Xiongnu to retreat from their homeland in the Ordos to the steppes
    of northern Mongolia. Then came a sustained—and successful—effort to apply the
    same sort of pressure on the Xiongnu's allies and vassals in Turkestan and Fergana.
    By sacking oasis towns and massacring tribes to the east, the Han were able to
    terrorize the peoples of Turkestan into switching their allegiance to China or
    declare their independence from the Xiongnu.<br>The Xiongnu were left isolated
    north of the Orkhorn. Under constant military pressure and cut off from the goods
    they had always extorted from agrarian peoples in China and Turkestan, the Xiongnu
    political elite began to fracture. A series of succession crises and weak leaders
    ensued; by 58 BC the Xiongnu's domain had fallen into open civil war. It was one
    of the aspiring claimants to the title of Chanyu that this conflict produced who
    traveled to Chang'an, accepted the Han's suzerainty, and ended eighty years of
    war between the Han and the Xiongnu [8].<br>How did the Chinese transform an enemy
    whose realm stretched thousands of miles across Inner Asia into a mere tributary
    vassal? They did it through <em>flame and blood and terror</em>. Any narrative
    of Han-Xiongnu relations that passes over these eighty years of grueling warfare
    is a distorted depiction of the times.
- - https://scholars-stage.blogspot.com/2014/03/smallpox-on-steppe.html
  - Smallpox on the Steppe
  - Tanner Greer
  - 2014-03-08
  - ''
  - ! '<blockquote>...The Manchus, before the founding of the Qing, also rarely encountered
    smallpox, but they knew of its danger. Mongols and Manchus who had not been exposed
    to the disease were exempted from coming to Beijing to receive titles of succession.
    The main response of the Mongols and Manchus to those who did fall ill was quarantine.
    Li Xinheng commented that if anyone in a tribe caught smallpox, his relatives
    abandoned him in a cave or distant grassland. <b>70 to 80 percent of those infected
    died.</b> The German traveler Peter Simon Pallas, who visited the Mongols three
    times front 1768 to I771, commented that smallpox was the only disease they greatly
    feared. It occurred very seldom, but spread rapidly when it struck: "If someone
    catches it, they abandon him in his tent; they only approach front the windward
    side to provide food. Children who catch it are sold to the Russians very cheaply."
    The Mongols whom Pallas visited lived far from the Chinese border, but they knew
    well that smallpox was highly contagious and nearly fatal.<br>The Chinese discovery
    of variolation—a method of inoculation—was of great aid in reducing the severity
    of attacks. The Kangxi emperor himself was selected as heir in part because he
    had survived the disease in childhood; his father had died of it. <b>In 1687 he
    inaugurated regular inoculation of the royal family, and his successor extended
    mandatory inoculation to all Manchu children. The Manchus adopted this Chinese
    medical practice in order to protect themselves against the virulent strains that
    were absent from the steppe. Only Manchus who had survived the disease were allowed
    to be sent to the Mongolian steppe.</b> Mongols close to the Manchu and Chinese
    border gradually grew immune, but those farther away suffered great losses in
    the nineteenth century when Chinese penetration increased. [1]</blockquote><br>...
    For several millennia historians have tried to explain the generally superior
    strength and endurance of steppe warriors, often focusing on the demands of life
    in the saddle or the nomads'' protein-rich diets as the explanation for their
    vitality. A more powerful explanation may be the absence of the debilitating and
    deadly diseases of settled life among the peoples of the steppe.'
- - https://scholars-stage.blogspot.com/2014/04/meditations-on-maoism-ye-fus-hard-road.html
  - Meditations on Maoism—Ye Fu's <em>Hard Road Home</em>
  - Tanner Greer
  - 2014-04-14
  - ''
  - ! '<p>Americans-and particularly American conservatives-are sometimes accused
    of failing to confront their country''s past honestly.  Ye Fu''s challenge—and
    in many respects all of China''s—was not honestly facing his past, but simply
    <em>finding</em> it. Ye Fu was born the great grandson of a ranking Nationalist
    commander, the grand son of a landlord, and the son of two parents who zealously
    joined the revolution only to be discarded by later ''struggles of the Proletariat''.
    Ye Fu was only dimly aware of this heritage growing up. It was not until his father''s
    funeral, when he first stepped foot on his ancestral lands, that he had either
    the chance or a reason to find the truth of his family''s past. This became a
    quest that drove and consumed him and is a recurring motif that unites his most
    poignant essays.</p><p>...Thus the true details of his father''s life and heritage
    were revealed: a grandfather who had climbed from the peasantdom of his birth
    to the hallowed class of landlord only a few years before the revolution overtook
    the village (he earned the title by being the only one in the village rich enough
    to employ a single field hand); a son who zealously hunted down landlords for
    the Party, unaware that his own family 50 miles to the east suffered the same
    persecution he so earnestly delivered; the suicide of his father and the destruction
    of the clan''s eldest generation in its entirety, both brothers and wives, within
    a single night.</p><p>"Hundreds of millions of lives were shoveled into the trenches
    of the 20th century", Ye Fu reflects. [4] Historians estimate that the death toll
    of these land reform campaigns is in the range of two to three million. [5] But
    for Ye Fu those ditches are not those of the nameless millions. These were ditches
    dug by his father and filled by his grandfather. The tragedies of the 20th century
    are <em>his</em> tragedies. He was born from the ditches—though he would not discover
    this gruesome truth until he was a grown man.</p><p>He who reads Ye Fu''s meditations
    on these mournful roots leaves with the strong—but unexpected—impression that
    the true tragedy of modern Chinese history is not found in its colossal death
    toll. For Ye Fu the real tragedy is what all these dead represented. The first
    to die were those most committed to the old order. They were the upholders of
    traditional propriety, keepers of the ancestral shrine, and symbols of basic human
    decency. These men and women often lived far below their ideals, profiting from
    a system rightly seen as exploitative, but as long they lived so did the ideal.
    Their deaths meant the destruction of their entire society. With them passed old
    structures of power and control, but also the old values and traditions these
    social arrangements had embodied and enshrined. The life defined by decorum, trust,
    filial piety, and kindness lost its place as the ideal of Chinese civilization,
    replaced by a new model that honored cruelty, deception, and revolutionary ardor.</p>'
- - https://scholars-stage.blogspot.com/2019/01/reflections-on-chinas-stalinist.html
  - ! 'Reflections on China''s Stalinist Heritage I: A Tyrant''s Toolkit'
  - Tanner Greer
  - 2019-01-17
  - ''
  - ! '<p>One of the extraordinary things about reading Mao''s speeches from this
    period is the fluidity of who was considered an ally and who was considered an
    enemy. Mao framed his campaigns as a struggle between "the people" and "the enemy,"
    but who fit into each group differed drastically based off of the Party''s perceptions
    of who was a credible threat to The Cause and who was not. As Mao put it:</p><p><blockquote>To
    understand these two different types of contradictions correctly, we must first
    be clear on what is meant by "the people" and what is meant by "the enemy". The
    concept of "the people" varies in content in different countries and in different
    periods of history in a given country. Take our own country for example. During
    the War of Resistance Against Japan, all those classes, strata and social groups
    opposing Japanese aggression came within the category of the people, while the
    Japanese imperialists, their Chinese collaborators and the pro-Japanese elements
    were all enemies of the people. During the War of Liberation, the U.S. imperialists
    and their running dogs—the bureaucrat-capitalists, the landlords and the Kuomintang
    reactionaries who represented these two classes—were the enemies of the people,
    while the other classes, strata and social groups, which opposed them, all came
    within the category of the people. At the present stage, the period of building
    socialism, the classes, strata and social groups which favour, support and work
    for the cause of socialist construction all come within the category of the people,
    while the social forces and groups which resist the socialist revolution and are
    hostile to or sabotage socialist construction are all enemies of the people.[5]</blockquote></p><p>Thus
    a particular group could at one point be an honored part of "the people," at another
    point an ally in a "united front," and later a despised "enemy" of the regime.
    How the regime treated you depended very much on how threatening Party leaders
    believed you might be to the regime and its cause.</p><p>Today The Cause has flipped—officially—from
    socialist revolution to national rejuvenation. The Party works under the same
    schema but has shifted the "people" that Mao identified with specific economic
    classes to the nation at large.[6] Mass mobilization campaigns have been retired.
    <b>But struggle and united front campaigns have not.</b> Xi''s great corruption
    purge, the Uighur labor camps of Xinjiang, the attack on Christians across China—these
    all follow the same methods for crushing and coercing "enemies" developed by Mao
    and the Party in the early ''40s. "One Country, Two Systems," interference campaigns
    in the Chinese diaspora, the guided, gilded tours given to Musk and his ilk—these
    all follow the same methods for corrupting and controlling "allies" developed
    by Mao and the Party that same decade. <b>The tools have never changed.</b> The
    only thing that has changed is the Party''s assessment of who is an "enemy" and
    who is part of the "people."</p><p>There is one threat, however, that the Communist
    legacy has poorly prepared the Party to face. Stalin and Mao conceived of their
    projects in cultural terms—they were not just attempting to stamp out dangerous
    people, but dangerous <em>ideas</em>. To that end both Stalin and Mao cut their
    countries off from the world they had no control over. If your end goal is socialist
    revolution this might be tenable. But if your end goal is national rejuvenation—that
    is, a future where China sits at the top of a global order, more wealthy and powerful
    than any other—then engagement with the outside world must be had. It means foreigners
    coming to China in great numbers, and Chinese going abroad in numbers no smaller.
    It means a much more accurate conception of the way the rest of the world works
    among the minds of the Chinese people. It means contemplating paths for China
    that do not involve being ruled by a dictatorial party-state.</p><p>This tension
    lies at the root of the Party''s problems with the West. Countries like America
    threaten the Party with their mere existence. Consider what these countries do:
    they allow dissidents from authoritarian powers shelter. Their societies spawn
    (even when official government policy is neutral on the question) movement after
    movement devoted to spreading Western ideals and ideas to other lands and peoples.
    They are living proof that a country does not need a one-party state to become
    powerful and wealthy. These things pose a threat to the Communist Party of China.
    The Party itself is the first to admit it. [7]</p>'
- - https://scholars-stage.blogspot.com/2019/03/reflections-on-chinas-stalinist.html
  - ! 'Reflections on China''s Stalinist Heritage II: Just How Totalitarian is Modern
    China?'
  - Tanner Greer
  - 2019-03-07
  - ''
  - ! '<p>Under the Khmer Rouge, making love was an explicitly <em>political</em>
    act. Marriage was a <em>political</em> decision. Refusing to sleep with your husband
    was an act of <em>political</em> rebellion. <strong><em>The first claim of the
    totalitarian is that everything is political.</em></strong></p><p>In my view,
    a totalitarian system must meet two minimum requirements:</p><ol type="1"><li>In
    this system all human action is considered political action.</li><li>The system
    is ruled by a Party which claims commanding authority to direct all political
    action—and thus all human action—for its cause.</li></ol><p>The great tragedies
    of 20th century history occurred as the totalitarian leaders attempted to translate
    their <em>claim</em> of authority over all human action into actual control over
    the same.</p><p>This view of totalitarian society crystallized in my mind some
    years ago, when I first read Liang Heng''s memoir of his youthful escapades as
    a Red Guard in the Cultural Revolution. A professor had asked me to review it.
    In that brief review I noted:</p><blockquote><p>In Mao''s China the personal was
    always political. And not just the personal—<em>everything</em> anyone did was
    political. Maoism was a political ideology that asked its members to give everything
    they were, had, and did to the socialist cause. This intellectual framework implies
    that everything one does should be layered with political meaning. A child''s
    prank, a lover''s kiss, and a friend''s embrace were all political acts. The clothes
    one wore, the way one walked, the letters one wrote, and the words one spoke all
    had political valence. It was with this in mind Liang Shan warned: "Never give
    your opinion on anything, even if you''re asked directly" (76).</p><p>Such caution
    is inevitable in a world where there is no distinction between the personal and
    the political. Politics is the division of power, politicking the contest for
    it. In a system where the most intimate and private actions have political meaning,
    these actions will be used by those who seek power. These naked contests for control
    leave no room for good and evil—good becomes what those with power declare it.
    "One day you are red, one day you are black, and one day you are red again" (76),
    Liang Shan instructed, and he was correct. This struggle stretched from factions
    warring within the walls of Zhongnanhai to the village black class child currying
    for favor.</p><p>The problem is not competition: that is an ingrained aspect of
    human life. The special tragedy of the Maoist system was that it spared nothing
    from the pursuit of power. There was no aspect of life that could be cordoned
    off as a refuge from the storm. [2]</p>'
- - https://scholars-stage.blogspot.com/2017/07/everything-is-worse-in-china.html
  - Everything is Worse in China
  - Tanner Greer
  - 2017-07-19
  - ''
  - ! '<p>Here I will just share one of my strongest reactions to the book—a thought
    that occurred again and again as I drifted through its pages. Esolen presents
    a swarm of maladies sickening American society, ranging from a generation of children
    suffocated by helicopter parenting to a massive state bureaucracy openly hostile
    too virtuous living. My reaction to each of his carefully drawn portraits was
    the same: this problem is even worse in China.</p><p>Are you worried about political
    correctness gone awry, weaponized by mediocrities to defame the worthy, suffocating
    truth, holding honest inquiry hostage through fear and terror? <em>That problem
    is worse in China.</em></p><p>Do you lament the loss of beauty in public life?
    Its loss as a cherished ideal of not just art and oratory but in the building
    of homes, chapels, bridges, and buildings? Its disappearance in the comings-and-goings
    of everyday life? <em>That problem is worse in China.</em>Do you detest a rich,
    secluded, and self-satisfied cultural elite that despises, distrusts, and derides
    the uneducated and unwashed masses not lucky enough to live in one of their chosen  urban
    hubs? <em>That problem is worse in China.</em> Are you sickened by crass materialism?
    Wealth chased, gained, and wasted for nothing more than vain display? Are you
    oppressed by the sight of children denied the joys of childhood, guided from one
    carefully structured resume-builder to the next by parents eternally hovering
    over their shoulders? Do you dread a hulking, bureaucratized leviathan, unaccountable
    to the people it serves, and so captured by special interests that even political
    leaders cannot control it? Are you worried by a despotic national government that
    plays king-maker in the economic sphere and crushes all opposition to its social
    programs into the dust? Do you fear a culture actively hostile to the free exercise
    of religion? Hostility that not only permeates through every layer of society,
    but is backed by the awesome power of the state?</p><p><em>These too are all worse
    in China.</em></p><p>...All of this should lighten the tone of gloom and doom
    that pervades the traditionalist critique of modern America. The reference point
    of these writers is the American (or less usually, the European) past. Look instead
    at the present! It could be so much worse for those of our ilk. In some countries,
    it is.</p>'
- - https://scholars-stage.blogspot.com/2019/05/the-utterly-dysfunctional-belt-and-road.html
  - The Utterly Dysfunctional Belt and Road
  - Tanner Greer
  - 2019-05-08
  - ''
  - ! '<p>The always excellent Stella Zhang directed me to a newish paper by political
    scientists Lee Jones and Zeng Jinhan on the domestic politics of China''s Belt
    and Road. Long term readers will remember that I am bearish on Xi''s grand dream.
    Here is how I described the central problems with the scheme for <em>Foreign Policy</em>:</p><blockquote><p>There
    is also a gap between how BRI projects are supposed to be chosen and how they
    actually have been selected. Xi and other party leaders have characterized BRI
    investment in Eurasia as following along defined "economic corridors" that would
    directly connect China to markets and peoples in other parts of the continent.
    By these means the party hopes to channel capital into areas where it will have
    the largest long-term benefit and will make cumulative infrastructure improvements
    possible.</p><p>This has not happened: one analysis of 173 BRI projects concluded
    that with the exception of the China-Pakistan Economic Corridor (CPEC) "there
    appears to be no significant relationship between corridor participation and project
    activity... [suggesting that] interest groups within and outside China are skewing
    President Xi''s signature foreign policy vision."</p><p>This skew is an inevitable
    result of China''s internal political system. BRI projects are not centrally directed.
    Instead, lower state bodies like provincial and regional governments have been
    tasked with developing their own BRI projects. The officials in charge of these
    projects have no incentive to approve financially sound investments: by the time
    any given project materializes, they will have been transferred elsewhere. BRI
    projects are shaped first and foremost by the political incentives their planners
    face in China: There is no better way to signal one''s loyalty to Xi than by laboring
    for his favored foreign-policy initiative. From this perspective, the most important
    criteria for a project is how easily the BRI label can be slapped on to it.....</p><p>The
    problems China has had with the BRI stem from contradictions inherent in the ends
    party leaders envision for the initiative and the means they have supplied to
    reach them. BRI projects are chosen through a decentralized project-management
    system and then funded through concessional loans offered primarily by PRC policy
    banks. This is a recipe for cost escalation and corruption. In countries like
    Cambodia, a one-party state ruled by autocrats, this state of affairs is viable,
    for there is little chance that leaders will be held accountable for lining their
    pockets (or, more rarely, the coffers of their local communities) at the entire
    nation''s expense. But most BRI countries are not Cambodia. In democracies this
    way of doing things is simply not sustainable, and in most BRI countries it is
    only so long before an angry opposition eager to pin their opponents with malfeasance
    comes to power, armed with the evidence of misplaced or exploitative projects.
    [1]</p></blockquote><p>The key points to take away from my account is that the
    failures of the BRI seem to factor back to a few central points: first, that project
    selection is mostly driven by the priorities of folks working in SOEs, provincial
    governments, and a plethora of different policy banks. The central government
    in Beijing has difficulty directing their efforts. Secondly, that these people
    do not have a good understanding of the countries in which they are investing,
    and face little incentive to gain this understanding. This leads to the sort of
    corruption and ''predatory'' funding that has given BRI its poisonous reputation
    in countries long exposed to it.</p><p>Jones and Zeng agree with this general
    picture, but provide a far more detailed account of what is happening ''behind
    the scenes'' when BRI projects are chosen and funded. The process they describe
    is not unique to the Belt and Road. It starts as Communist high leadership paints
    bold words in the sky:</p><blockquote><p>Foreign-policy steering happens through
    several important mechanisms. The first is top leaders'' major speeches, which
    are usually kept vague to accommodate diverse interests and agendas. Rather than
    ''carefully-worked out grand strategies'', they are typically ''platitudes, slogans,
    catchphrases, and generalities'', offering ''atmospheric guidance'' that others
    must then interpret and implement. Examples include: Deng''s <em>tao guang yang
    hui</em>, whose meaning is ''debatable''; Hu''s ''harmonious world''—''more of
    a narrative than a grand strategy''; and Xi''s ''new type of great power relations.''
    As discussed below, Xi''s vague 2013 remarks on the ''silk road economic belt''
    (SREB) and ''maritime silk road'' (MSR) exemplify this tendency. [2]</p></blockquote><p>But
    bold words are not policy. The Party often has difficulty transforming grand visions
    into detailed policy proposals. This is sometimes quite intentional—in a closed
    system like the People''s Republic, it may be better to have politicos arguing
    over <em>how</em> to make the Core''s vision possible, instead of whether the
    Core''s vision is worth making possible in the first place.</p>'
- - https://scholars-stage.blogspot.com/2019/04/the-inner-life-of-chinese-teenagers.html
  - The Inner Life of Chinese Teenagers
  - Tanner Greer
  - 2019-04-19
  - ''
  - ! '<p>The second point probably deserves more space than I was able to give in
    the <em>LA Review of Books</em>. Consider, for a moment, the typical schedule
    of a Beijing teenager:</p><p>She will (depending on the length of her morning
    commute) wake up somewhere between 5:30 and 7:00 AM. She must be in her seat by
    7:45, 15 minutes before classes start. With bathroom breaks and gym class excepted,
    she will not leave that room until the 12:00 lunch hour and will return to the
    same spot after lunch is ended for another four hours of instruction. Depending
    on whether she has after-school tests that day, she will be released from her
    classroom sometime between 4:10 and 4:40. She then has one hour to get a start
    on her homework, eat, and travel to the evening cram school her parents have enrolled
    her in. Math, English, Classical Chinese—there are cram schools for every topic
    on the <em>gaokao</em>. On most days of the week she will be there studying from
    6:00 to 9:00 PM (if the family has the money, she will spend another six hours
    at these after-school schools on Saturday and Sunday mornings). Our teenager will
    probably arrive home somewhere around 10:00 PM, giving her just enough time to
    spend two or three hours on that day''s homework before she goes to bed. Rinse
    and repeat, day in and day out, for six years. The strain does not abate until
    she has defeated—or has been defeated by—the <em>gaokao</em>.</p><p>This is well
    known, but I think the wrong aspects of this experience are emphasized. Most outsiders
    look at this and think: see how much pressure these Chinese kids are under. I
    look and think: <em>how little privacy and independence these Chinese kids are
    given!</em></p><p>To put this another way: Teenage demands for personal space
    are hardly unique to China. What makes China distinctive is the difficulty its
    teenagers have securing this goal. Chinese family life is hemmed in narrow bounds.
    The urban apartments that even well-off Chinese call their homes are tiny and
    crowded. Few have more than two bedrooms. Teenagers are often forced to share
    their bedroom with a grandparent. So small was the apartment of one 16-year-old
    I interviewed that she slept, without apparent complaint, in the same bed as her
    parents for her entire first year of high school. Where can a teenager like her
    go, what door could she slam, when she was angry with her family? Within the walls
    of her home there was no escape from the parental gaze.</p><p>A Chinese teen has
    few better options outside her home. No middle-class Chinese teenager has a job.
    None have cars. The few that have boyfriends or girlfriends go about it as discreetly
    as possible. Apart from the odd music lesson here or there, what Americans call
    "extra-curricular activities" are unknown. One a recent graduate of a prestigious
    international high school in Beijing once explained to me the confusion she felt
    when she was told she would need to excel at an after-school activity to be competitive
    in American university admissions:</p><p>"In tenth grade our home room teacher
    told us that American universities cared a lot about the things we do outside
    of school, so from now on we would need to find time to ''cultivate a hobby.''
    I remember right after he left the girl sitting at my right turned to me and whispered,
    ''I don''t know how to cultivate a hobby. Do you?''"</p>'
- - https://scholars-stage.blogspot.com/2013/02/ominous-parallels-what-antebellum.html
  - ! 'Ominous Parallels: What Antebellum America Can Teach Us About Our Modern Political
    Regime'
  - Tanner Greer
  - 2013-02-26
  - ''
  - ! '<p>Many people point to the hyper-partisanship of national Democratic and Republican
    parties as the greatest challenge facing 21st century America. When seen through
    the lens of another vapidly partisan political system—that of Jacksonian America—we
    see that the real danger is not noisy partisanship, but the iniquity it hides:
    for them it was slavery; for us, plutarchy.</p><p>...As in the antebellum, today''s
    hyperpartisanship has its uses. The issues are real enough, and the cultural divide
    between each party''s demographic "base" is wide.  Politicians take advantage
    of this with over-the-top rhetoric, turning all issues into a cultural crusade
    against the radicalism of the progressive left or the bigotry of entrenched conservatism.
    The accuracy of these attacks is unimportant. The antebellum party system allowed
    Southerners to define themselves as ''Whigs'' or ''Democrats'' instead of ''slavers''.
    The current system serves its purpose just as well, allowing plutocrats to define
    themselves not in terms of power or privilege, but as part of a culturally cohesive
    group that represents ''real'' America. With partisan issues taking the fore,
    politicians, lobbyists, and corporate big wigs  can plunder the American economy
    and strip American citizens of their liberties in a decidedly bipartisan fashion.
    [9] And thus the greatest structural fault-line in America''s body-politic and
    the most dangerous challenge to the integrity of her republican institutions and
    the liberties of her citizenry continues onward without public comment. And all
    of this without a gag rule.</p><p>If the comparison of the antebellum Republic''s
    political regime with its ailing modern descendent seems a bit chilling—well,
    it <em>is</em>. The last time America''s sins broke through the partisan politics
    designed to hide them the result was the most destructive war of her history.
    It is an ominous precedent.</p>'
- - https://scholars-stage.blogspot.com/2015/09/shakespeare-in-american-politics.html
  - Shakespeare in American Politics
  - Tanner Greer
  - 2015-09-30
  - ''
  - <p>...A good place to start is with the Webster-Hayne debate of 1830. Of all American
    oratory, only the Lincoln-Douglass debates can claim greater fame than the debate
    Daniel Webster and Robert Hayne held on the antebellum Senate floor. At that time
    there was a resolution before the Senate calling for all new federal land surveys
    to be postponed until all of the existing land already surveyed was sold. This
    struck the ire of the westerners, who pushed for federal land to be given to new
    settlers without charge or delay...These allusions to Shakespeare only occupy
    a normal portion of the two men's debate—no more than a few paragraphs out of
    ninety or so pages of text. Nevertheless, the use of <em>Macbeth</em>'s script
    in the debate is telling. Neither Webster nor Hayne thought it was a waste of
    their time to debate the finer points of Shakespeare's plays in the halls of the
    Senate. The reader senses that Webster, in particular, did so in a positively
    gleeful fashion.</p><p>What has happened here? How have we gone from long discussions
    of Shakespearean drama on the senate floor to the shallow repetition of disembodied
    sentence fragments? The answers to this question tell us much about the American
    body politic:</p><p>1. <em>The decline of public speaking as a vital part of American
    culture</em>. Oratory is something of a lost art in modern America. It is hard
    to imagine just how vital it was to public life for most of America's history.
    In Webster's day public speaking was a central part of entertainment, education,
    civic life, and religious practice. He was elected in the midst of the 2nd Great
    Awakening, when American religious life was dominated by camp meetings and church
    members were expected to preach and testify one to another. It was a time when
    every township had a lyceum at its center, and intellectual life was dominated
    by those who traveled the lyceum circuit. Collections of speeches like <em>The
    Columbian Orator</em> were the most common type of schoolbook in the antebellum
    era, while most American men actively participated in town assemblies and party
    caucuses. The mastery of proper political rhetoric was an essential social skill.</p><p>Add
    all this together and you are left with a population that found immense pleasure
    in listening to, reenacting, and reading the speeches of others. It was a prized
    art, and when masters like Webster or Lincoln displayed their talents, people
    flocked together to listen to them. There was thus a great deal of patience for
    the sort of rhetorical flourish inherit in the long discussions of Shakespeare
    seen above. Today's Americans will not sit still and listen to a political speech
    for longer than ten minutes. The medium through which politicians communicate
    to the masses really doesn't let them. Radio shows and news channels rely on the
    soundbite. If a politician's message cannot be squeezed into a seven second slot
    it will not be heard.</p>
- - https://scholars-stage.blogspot.com/2015/10/awareness-vs-action-two-modes-of.html
  - ! 'Awareness vs. Action: Two Modes of Protest in American History'
  - Tanner Greer
  - 2015-10-07
  - ''
  - ! '<p>...Daniel Walker Howe devotes several pages to the origins of the [Temperance]
    movement in his excellent book <em>What God Hath Wrought: The Transformation of
    America, 1814–1848</em>. It is worth quoting from them at length:</p><p><blockquote>Americans
    in the early nineteenth century quaffed alcohol in prodigious quantities. In 1825,
    the average American over fifteen years of age consumed seven gallons of alcohol
    a year, mostly in the form of whiskey and hard cider. (The corresponding figure
    at the start of the twenty-first century was less than two gallons, most of it
    from beer and wine.) Workers typically took a midmorning break and a mid-afternoon
    break, both accompanied by alcohol, as well as liquor with every meal. To entertain
    guests meant to ply them with several kinds of alcohol until some fell down. All
    social classes drank heavily; college students, journeyman printers, agricultural
    laborers, and canal-diggers were especially notorious. Schoolchildren might face
    an inebriated teacher in the classroom. Although socially tolerated, drunkenness
    frequently generated violence, especially domestic violence, and other illegal
    behavior. In such a society, intemperance represented a serious issue of public
    health, comparable to the problems of drug abuse experienced in later generations.<br>Making
    temperance a Christian cause constituted an innovation, for traditional Christianity
    had not discouraged drinking. Indeed, Beecher recalled, ministerial conferences
    during his youth had been occasions for heavy convivial drinking. Unlike a later
    generation of crusaders, Beecher never thought the legal prohibition of alcohol
    a practical solution; he relied purely on changing public attitudes. This was
    no mean feat. To take stand against the strong social pressures to drink took
    real courage, especially for young men. To help them, temperance workers paid
    reformed alcoholics to go on speaking tours, published temperance tracts, put
    on temperance plays, and drove the "water wagon" through towns encouraging converts
    to jump on. Publicists and organizers like Beecher struck a nerve with the public.
    The temperance cause resonated among people in all walks of life, rural and urban,
    white and black. Although it began in the Northeast, temperance reached the South
    and West and exerted powerful and lasting influence there. At first the temperance
    advocates restricted themselves to encouraging moderation (hence the name "temperance");
    in this phase they condemned only distilled liquors, not beer and wine. At the
    grassroots level, however, it became apparent that total abstinence made a more
    effective appeal. Beecher endorsed this shift in <em>Six Sermons on Intemperance</em>
    (1825). Those who signed a temperance pledge were encouraged to put a <em>T</em>
    after their names if willing to take the extra step of pledging total abstinence;
    from this derives our word "teetotaler."<br>The campaign to alter age old habits
    and attitudes proved amazingly successful: consumption of alcohol, especially
    of hard liquor, declined steadily and dramatically after 1830, falling to 1.8
    gallons per person over fifteen by the late 1840s. [2]</blockquote></p><p>A few
    things to note about this account: temperance societies were organized and worked
    at the level of towns, congregations, families, and individuals, not entire states
    or nations. The information they passed along was not intended to make people
    <em>aware</em> of the danger of drinking, but to inspire or scare them into <em>acting</em>
    on this knowledge. They created communities who could help individuals who were
    struggling to do this. They were most successful when they secured <em>individual
    commitments to action</em>. It was also incredibly successful. This became the
    standard template for American civic associations until the late 19th century.</p>'
- - https://scholars-stage.blogspot.com/2019/06/passages-i-highlighted-in-my-copy-of.html
  - ! 'Passages I Highlighted in My Copy of <em>Only Yesterday: An Informal History
    of the 1920s</em>'
  - Tanner Greer
  - 2019-06-24
  - ''
  - ! '<p>Last week''s post, "If You Were to Write a History of 21st Century America,
    What Would It Look Like?", asked what a 21st century version of Frederick Lewis
    Allen''s <em>Only Yesterday: An Informal History of the 1920s</em> might look
    like. Here is how I described the book in that post:</p><p><blockquote>There are
    many things to love about this book. Allen wrote his history of the 1920''s in
    a jaunty, breezy style. When you pick his book up it is hard to put it down. Allen''s
    tone is fair, his judgements sharp, and prose delectably entertaining. The most
    notable thing about this history of the 1920s, however, is its publication date:
    Allen wrote the book in 1930. He saw it published in 1931.</p><p>I often wish
    Allen had more imitators. Allen''s book shines as a social history. The genius
    of writing such a history directly after the events took place is that the historian
    can narrate not just what happened in a period, but what it felt like to live
    through it. Names have not receded into history; the little things of daily existence
    are still remembered, and often still in use. Judgements of past events have not
    been too clouded by the downstream effects they had three or four decades down
    the line. There is an immediacy to <em>Only Yesterday</em> that I have never found
    in any other work of history (though I have found it in several works of fiction).</blockquote></p><p>While
    Allen gives due coverage to economic and political affairs (the League of Nations
    debates, the Teapot Dome scandal, and the crash of ''29 each get their own chapter
    length narrations), the majority of Allen''s book is what we would today call
    "social history." Allen spends about equal time describing the fads for crossword
    puzzles and mahjong (yes, you read that last one right) as he does the entire
    administration of Calvin Coolidge...</p>'
- - https://scholars-stage.blogspot.com/2019/04/on-quests-for-transcendence.html
  - Questing for Transcendence
  - Tanner Greer
  - 2019-04-29
  - ''
  - ! '<p>Will Wilkinson explored one possibility in an essay he wrote a few years
    ago on American country music. Wilkinson begins with the observation that American
    conservatives (i.e., the consumers of country music) tend to be low on "openness"
    in the Big-5 personality scale. Folks who rate high on openness are the sort attracted
    to novelty: world travels, new drugs, and so forth. Country music, he suggests,
    captures the emotional lives of a different group of people:</p><blockquote><p>Emotional
    highlights of the low-openness life are going to be the type celebrated in "One
    Boy, One Girl": the moment of falling in love with "the one," the wedding day,
    the birth one''s children (though I guess the song is about a surprising ultrasound).
    More generally, country music comes again and again to the marvel of advancing
    through life''s stations, and finds delight in experiencing traditional familial
    and social relationships from both sides. Once I was a girl with a mother, now
    I''m a mother with a girl. My parents took care of me, and now I take care of
    them. I was once a teenage boy threatened by a girl''s gun-loving father, now
    I''m a gun-loving father threatening my girl''s teenage boy. Etc. And country
    is full of assurances that the pleasures of simple, rooted, small-town, lives
    of faith are deeper and more abiding than the alternatives.</p><p>My conjecture,
    then, is that country music functions in part to reinforce in low-openness individuals
    the idea that life''s most powerful, meaningful emotional experiences are precisely
    those to which conservative personalities living conventional lives are most likely
    to have access. And it functions as a device to coordinate members of conservative-minded
    communities on the incomparable emotional weight of traditional milestone experiences....</p><p>But
    why would you want your kids to grow up with the same way of life as you and your
    grandparents? My best guess (and let me stress guess) is that those low in openness
    depend emotionally on a sense of enchantment of the everyday and the profundity
    of ritual. Even a little change, like your kids playing with different toys than
    you did, comes as a small reminder of the instability of life over generations
    and the contingency of our emotional attachments. This is a reminder low-openness
    conservatives would prefer to avoid, if possible. What high-openness liberals
    feel as mere nostalgia, low-openness conservatives feel as the baseline emotional
    tone of a recognizably decent life. If your kids don''t experience the same meaningful
    things in the same way that you experienced them, then it may seem that their
    lives will be deprived of meaning, which would be tragic. And even if you''re
    able to see that your kids will find plenty of meaning, but in different things
    and in different ways, you might well worry about the possibility of ever really
    understanding and relating to them. The inability to bond over profound common
    experience would itself constitute a grave loss of meaning for both generations.
    So when the culture redefines a major life milestone, such as marriage, it trivializes
    one''s own milestone experience by imbuing it was a sense of contingency, threatens
    to deprive one''s children of the same experience, and thus threatens to make
    the generations strangers to one another. And what kind of monster would want
    that?</p><p>Country music is a bulwark against cultural change, a reminder that
    "what you see is what you get," a means of keeping the charge of enchantment in
    "the little things" that make up the texture of the every day, and a way of literally
    broadcasting the emotional and cultural centrality of the conventional big-ticket
    experiences that make a life a life.[3]</p></blockquote><p>...Yet there is one
    segment of society that seems to get it. In the years since my [Mormon missionary]
    service, I have been surprised to find that the one group of people who consistently
    understands my experience are soldiers....both many ex-missionaries (known as
    "RMs" or "Return Missionaries" in Mormon lingo) and many veterans have such trouble
    adapting to life when they return to their homes. This comparison occurred to
    me first several years ago, when I read a Facebook comment left by a man who had
    served as a Marine mechanic in Afghanistan...I did not save the comment at the
    time, but I remember it well enough to reproduce a paraphrase here:</p><blockquote><p>"I
    do not know if I want to live any more. I served in Afghanistan from [various
    dates of various deployments] and am now working as a salesman for [a prominent
    American company]. I despise this world I am in now—everything is so selfish and
    so self centered. In Afghanistan every single decision I made had a purpose; every
    single thing I did was for something bigger than myself. Everything I did, I did
    to save lives. Every deed helped accomplish our mission. Here in America no one
    does anything except for themselves. We work to earn a buck—what is the point
    to living like this? There is not a day that goes by that I don''t wish I was
    back in that hellhole. There what I did mattered. Here it is all meaningless."</p>'
- - https://scholars-stage.blogspot.com/2016/01/america-will-always-fail-at-regional.html
  - America Will Always Fail At Regional Expertise
  - Tanner Greer
  - 2016-01-
  - ''
  - <p>I have argued before that any potential American foreign policy or 'grand strategy'
    that requires  statesmen with a nuanced understanding of a foreign region's cultures,
    politics, and languages to implement it is doomed to fail. Regional acumen is
    a rare trait, and one I greatly admire. But it is rare for a reason. Regional
    acumen just does not scale—or at least, Americans do not know how to scale it.
    I have said this before. But it was reinforced tonight when I stumbled—quite by
    accident—across this old <em>New York Times Magazine</em> personal by Lydia Kiesling.
    In it she describes her experience learning Uzbek with a FLAS grant from the Department
    of Education.</p><p>...This article gets to the heart of why America will always
    lack the kind of language and area expertise needed to succeed in the kinds of
    things the American people (or American leaders) often demand the United States
    government do. Uzbek is an obscure language. But it is an obscure language at
    the center of the national security concerns that have bedeviled the United States
    over the last decade and a half. To give a brief picture:</p><ul><li>There are
    about three million Uzbeks who live in Afghanistan. Uzbeks were an essential part
    of the Northern Alliance's resistance against the Taliban, and Uzbek leaders became
    an important part of the government established by NATO forces once the Taliban
    was driven from power. This is still true. Afghanistan's current vice-president,
    Abdul Rashid Dostum, is an Uzbek.</li><li>Uzbekistan is the central hub of central
    Asia. One of the greatest defeats of our Afghan campaign happened not on the battlefield,
    but at the diplomats' table. Uzbekistan's decision to withdraw American basing
    and supply rights was nothing short of a disaster, forcing the United States to
    be even more dependent on Pakistan (our true enemy in the region) for logistic
    support.</li><li>Uzbek and Uighur are a hair's breadth away from mutually intelligible.
    Xinjiang's low intensity Uighur insurgency is the single greatest security concern
    of China, America's greatest rival.</li></ul><p>This is a language that <em>matters</em>.
    What happens to the woman who spent a year of her life studying it? She was rejected
    from the CIA (or wherever) on background technicalities, and has not used her
    language since. Or to be more precise, she has used it twice. Twice in four years.
    <em>Twice</em>.</p><p>This gets to the heart of America's problem with regional
    acumen. Area expertise simply doesn't pay. You may count the number of private
    sector jobs currently on the market that demand Uzbek fluency on two hands. And
    even if there <em>were</em> a multitude of jobs that required proficiency in Uzbek
    and English, there are undoubtedly several hundred—perhaps several thousand—Uzbekistanis
    who speak English better than Ms. Kiesling speaks Uzbek, and who will work for
    less pay to boot.</p>
- - https://scholars-stage.blogspot.com/2015/02/the-education-of-american-strategist.html
  - American Policy Makers Do Not Read Books
  - Tanner Greer
  - 2015-02-18
  - ''
  - <p>If the American strategist of 2015 has a deep base of historical, cultural,
    and scientific knowledge to draw on to guide the decisions he makes this is because
    he acquired this knowledge base <em>before</em> he was a senior policy maker.
    You can actually see hints of this in the survey data—Avey and Desch asked policy
    makers to list the living international relations scholars they thought had the
    greatest influence on actual policy making. Along with scholars-turned-officials
    (e.g. Henry Kissinger, Zbigniew Brzezinski, Anne-Marie Slaughter) and public intellectuals
    (e.g. Francis Fukuyama, Fareed Zakaria) were a list of men whose scholarly apogee
    was twenty to thirty years ago, back when our policy makers were undergrads! (Funnily
    enough many of these men—Samuel Huntington, Albert Wohlstetter, Hans Morgenthau—are
    not only past their scholarly prime, <em>but are no longer alive!</em>) Those
    who rose to prominence after 1995 barely register. [3]</p><p>One of the lessons
    we can draw from this is that the books and material we expect American students
    to read and master in the early stages of their life will have an outsized influence
    on the knowledge they will possess in their old age. Today's strategists survive
    off of what they learned when they were in school forty years ago. [4] Absent
    dramatic changes in the life style of government officials or unforeseen technological
    developments, <b>the policy-makers crafting strategy in 2040 will be working off
    of the knowledge base they are building from the books they are reading right
    now.</b></p>
- - https://scholars-stage.blogspot.com/2018/03/you-dont-have-people.html
  - You Do Not Have the People
  - Tanner Greer
  - 2018-03-
  - ''
  - ! '<p>These numbers are taken from a November NBC News/Gen Forward poll, a survey
    that questions 18–35 year olds across the nation on the political issues of the
    day. Respondents are asked to list what they believe are the three most important
    issues facing America. [3] There are a lot of interesting things one can say about
    this data, but for our purposes here I would focus your attention on the two rows
    labeled "foreign policy" and "military strength." There is one big thing you will
    notice about these two figures: they are minuscule. Respondents are largely satisfied
    with America''s place in the world. In their minds, police brutality, education,
    crime, taxes, racism, the economy, immigration, climate change, health care, gun
    control and the national budget are all more critical problems than anything involving
    foreign affairs.</p><p>Millennials do not stand in for all of America. Older generations
    care more for foreign policy than the Millennial and Generation Z cohorts do,
    though other polls suggest that their priorities also lie in the domestic sphere.
    But I focus in on this group for a reason: the opinions of this generation will
    have an outsized influence on our defense policies. In the case of war, these
    are the people who will actually be called to sacrifice their time and lives for
    the sake of American interests. Their willingness to suffer for the sake of the
    public interest sets the upper bounds for what is militarily possible in a time
    of conflict. Their attitude in peace will be even more important. Armament programs
    are decade long affairs. Proper sized navies are generation-length projects. Great
    power rivalries take decades to unfold. Who will be responsible for maintaining
    this effort? <em>These guys</em>. The millennial generation is already the largest
    cohort in this republic''s history (given current fertility rates there will likely
    be none larger). Were they not so politically desensitized, they would also already
    possess the power to decide most elections in the country. When the last of the
    boomers die out, by sheer power of numbers alone, these men and women will rule
    the roost. Their perception of America''s role in the world, and the threats she
    faces, will determine America''s future.</p><p>The take-away: more important than
    developing new weapon systems, devising new treaties, or crafting new strategies
    will be convincing the American people that they can and should bear the costs
    of doing any of that. Nothing is more important than winning the public opinion
    war. If we lose there, nothing else really matters.</p><p>... If we lived in an
    age when public trust in elites and the institutions they manned was stronger,
    many of the worries I voice could be dispensed with. That is simply not where
    we are at. Unfortunately, the Trump administration''s disregard for public opinion
    on the Korea issue is but an extreme expression of a tendency that blights the
    entire field. We are uncomfortable with democratic accountability, unwilling to
    subject ourselves to public debate, and uninterested in the constraints public
    opinion and popular politics place on the policies we craft. This complacency
    is not excusable. It is not sustainable. <em>We cannot defend the cause of freedom
    without the support of the people.</em> To try and do this is to risk terrible
    disaster.</p>'
- - https://scholars-stage.blogspot.com/2018/07/what-cyber-war-will-look-like.html
  - What Cyber-War Will Look Like
  - Tanner Greer
  - 2018-07-06
  - ''
  - ! '<p>In a report Cancian wrote for the Center for Strategic and International
    Studies on how great powers adapt to tactical and strategic surprise, Cancian
    sketched out twelve "vignettes" of potential technological or strategic shocks
    to make his abstract points a bit more concrete. Here is how Cancian imagines
    an "asymmetric cyber-attack" launched by the PRC against the United States Military:</p><blockquote><p>The
    U.S. secretary of defense had wondered this past week when the other shoe would
    drop. Finally, it had, though the U.S. military would be unable to respond effectively
    for a while.</p><p>The scope and detail of the attack, not to mention its sheer
    audacity, had earned the grudging respect of the secretary. Years of worry about
    a possible Chinese "Assassin''s Mace"—a silver bullet super-weapon capable of
    disabling key parts of the American military—turned out to be focused on the wrong
    thing.</p><p>The cyber attacks varied. Sailors stationed at the 7th Fleet''s homeport
    in Japan awoke one day to find their financial accounts, and those of their dependents,
    empty. Checking, savings, retirement funds: simply gone. The Marines based on
    Okinawa were under virtual siege by the populace, whose simmering resentment at
    their presence had boiled over after a YouTube video posted under the account
    of a Marine stationed there had gone viral. The video featured a dozen Marines
    drunkenly gang-raping two teenaged Okinawan girls. The video was vivid, the girls''
    cries heart-wrenching the cheers of Marines sickening And all of it fake. The
    National Security Agency''s initial analysis of the video had uncovered digital
    fingerprints showing that it was a computer-assisted lie, and could prove that
    the Marine''s account under which it had been posted was hacked. But the damage
    had been done.</p><p>There was the commanding officer of Edwards Air Force Base
    whose Internet browser history had been posted on the squadron''s Facebook page.
    His command turned on him as a pervert; his weak protestations that he had not
    visited most of the posted links could not counter his admission that he had,
    in fact, trafficked some of them. Lies mixed with the truth. Soldiers at Fort
    Sill were at each other''s throats thanks to a series of text messages that allegedly
    unearthed an adultery ring on base.</p><p>The variations elsewhere were endless.
    Marines suddenly owed hundreds of thousands of dollars on credit lines they had
    never opened; sailors received death threats on their Twitter feeds; spouses and
    female service members had private pictures of themselves plastered across the
    Internet; older service members received notifications about cancerous conditions
    discovered in their latest physical.</p><p>Leadership was not exempt. Under the
    hashtag <code>#PACOMMUSTGO</code> a dozen women allegedly described harassment
    by the commander of Pacific command. Editorial writers demanded that, under the
    administration''s "zero tolerance" policy, he step aside while Congress held hearings.</p><p>There
    was not an American service member or dependent whose life had not been digitally
    turned upside down. In response, the secretary had declared "an operational pause,"
    directing units to stand down until things were sorted out.</p><p>Then, China
    had made its move, flooding the South China Sea with its conventional forces,
    enforcing a sea and air identification zone there, and blockading Taiwan. But
    the secretary could only respond weakly with a few air patrols and diversions
    of ships already at sea. Word was coming in through back channels that the Taiwanese
    government, suddenly stripped of its most ardent defender, was already considering
    capitulation. [2]</p>'
- - https://mbio.asm.org/content/3/2/e00036-12
  - ! 'The Black Queen Hypothesis: Evolution of Dependencies through Adaptive Gene
    Loss'
  - J. Jeffrey Morris, Richard E. Lenski, Erik R. Zinser
  - 2012-03-23
  - 10.1128/mBio.00036-12
  - Reductive genomic evolution, driven by genetic drift, is common in endosymbiotic
    bacteria. Genome reduction is less common in free-living organisms, but it has
    occurred in the numerically dominant open-ocean bacterioplankton <em>Prochlorococcus</em>
    and “<em>Candidatus Pelagibacter</em>,” and in these cases the reduction appears
    to be driven by natural selection rather than drift. Gene loss in free-living
    organisms may leave them dependent on co-occurring microbes for lost metabolic
    functions. We present the Black Queen Hypothesis (BQH), a novel theory of reductive
    evolution that explains how selection leads to such dependencies; its name refers
    to the queen of spades in the game Hearts, where the usual strategy is to avoid
    taking this card. Gene loss can provide a selective advantage by conserving an
    organism’s limiting resources, provided the gene’s function is dispensable. Many
    vital genetic functions are leaky, thereby unavoidably producing public goods
    that are available to the entire community. Such leaky functions are thus dispensable
    for individuals, provided they are not lost entirely from the community. The BQH
    predicts that the loss of a costly, leaky function is selectively favored at the
    individual level and will proceed until the production of public goods is just
    sufficient to support the equilibrium community; at that point, the benefit of
    any further loss would be offset by the cost. Evolution in accordance with the
    BQH thus generates “beneficiaries” of reduced genomic content that are dependent
    on leaky “helpers,” and it may explain the observed nonuniversality of prototrophy,
    stress resistance, and other cellular functions in the microbial world.
- - https://papers.tinbergen.nl/19059.pdf
  - Cannabis Prices on the Dark Web
  - Jakub Cerveny, Jan C. van Ours
  - 2019-08-13
  - ''
  - This paper examines prices of cannabis sold over the anonymous internet marketplace
    AlphaBay. We analyze cannabis prices of 500 listings from about 140 sellers, originating
    from 18 countries. We find that both listing characteristics and country characteristics
    matter. Cannabis prices are lower if sold in larger quantities, so there is a
    clear quantity discount. Cannabis prices increase with perceived quality. Cannabis
    prices are also higher when the seller is from a country with a higher GDP per
    capita or higher electricity prices. The internet based cannabis market seems
    to be characterized by monopolistic competition where many sellers offer differentiated
    products with quality variation causing a dispersion of cannabis prices and sellers
    have some control over the cannabis prices.
- - /docs/modafinil/2019-kredlow.pdf
  - ! 'The Efficacy of Modafinil as a Cognitive Enhancer: A Systematic Review and
    Meta-Analysis'
  - M. Alexandra Kredlow, Ani Keshishian, Sarah Oppenheimer, Michael W. Otto
  - 2019-08-19
  - 10.1097/JCP.0000000000001085
  - ! '<p><strong>Background</strong>: Animal models and human studies have identified
    the potential of modafinil as a cognitive enhancing agent, independent of its
    effects on promoting wakefulness in sleep-deprived samples. Given that single-dose
    applications of other putative memory enhancers (eg, D-cycloserine, yohimbine,
    and methylene blue) have shown success in enhancing clinical outcomes for anxiety-related
    disorders, we conducted a meta-analytic review examining the potential for single-dose
    effects for modafinil on cognitive functioning in non–sleep-deprived adults.</p><p><strong>Methods</strong>:
    A total of 19 placebo-controlled trials that examined the effects of single-dose
    modafinil versus placebo on the cognitive domains of attention, executive functioning,
    memory, or processing speed were identified, allowing for the calculation of 67
    cognitive domain–specific effect sizes.</p><p><strong>Results</strong>: The overall
    positive effect of modafinil over placebo across all cognitive domains was small
    and significant (<em>g</em> = 0.10; 95% confidence interval, 0.05–0.15; <em>p</em>
    &lt; 0.001). No significant differences between cognitive domains were found.
    Likewise, no significant moderation was found for modafinil dose (100 mg vs 200
    mg) or for the populations studied (psychiatric vs nonpsychiatric).</p><p><strong>Conclusions</strong>:
    In conclusion, the available evidence indicates only limited potential for modafinil
    to act as a cognitive enhancer outside sleep-deprived populations.</p>'
- - https://www.nature.com/articles/s41467-019-11786-6
  - A critique of pure learning and what artificial neural networks can learn from
    animal brains
  - Anthony M. Zador
  - 2019-08-21
  - 10.1038/s41467-019-11786-6
  - ! '<p>Artificial neural networks (ANNs) have undergone a revolution, catalyzed
    by better supervised learning algorithms. However, in stark contrast to young
    animals (including humans), training such networks requires enormous numbers of
    labeled examples, leading to the belief that animals must rely instead mainly
    on unsupervised learning. Here we argue that most animal behavior is not the result
    of clever learning algorithms—supervised or unsupervised—but is encoded in the
    genome. Specifically, animals are born with highly structured brain connectivity,
    which enables them to learn very rapidly. Because the wiring diagram is far too
    complex to be specified explicitly in the genome, it must be compressed through
    a “genomic bottleneck”. The genomic bottleneck suggests a path toward ANNs capable
    of rapid learning.</p><p>...As the name implies, ANNs were invented in an attempt
    to build artificial systems based on computational principles used by the nervous
    system5. In what follows, we suggest that additional principles from neuroscience
    might accelerate the goal of achieving artificial mouse, and eventually human,
    intelligence. We argue that in contrast to ANNs, animals rely heavily on a combination
    of both learned and innate mechanisms. These innate processes arise through evolution,
    are encoded in the genome, and take the form of rules for wiring up the brain6.
    Specifically, we introduce the notion of the “genomic bottleneck”—the compression
    into the genome of whatever innate processes are captured by evolution—as a regularizing
    constraint on the rules for wiring up a brain. We discuss the implications of
    these observations for generating next-generation machine algorithms.</p><p>...In
    this view, supervised learning in ANNs should not be viewed as the analog of learning
    in animals. Instead, since most of the data that contribute an animal’s fitness
    are encoded by evolution into the genome, it would perhaps be just as accurate
    (or inaccurate) to rename it “supervised evolution.” Such a renaming would emphasize
    that “supervised learning” in ANNs is really recapitulating the extraction of
    statistical regularities that occurs in animals by both evolution and learning.
    In animals, there are two nested optimization processes: an outer “evolution”
    loop acting on a generational timescale, and an inner “learning” loop, which acts
    on the lifetime of a single individual. Supervised (artificial) evolution may
    be much faster than natural evolution, which succeeds only because it can benefit
    from the enormous amount of data represented by the life experiences of quadrillions
    of individuals over hundreds of millions of years.</p>'
- - https://nv-adlr.github.io/MegatronLM
  - ! 'MegatronLM: Training Billion+ Parameter Language Models Using GPU Model Parallelism'
  - NVIDIA ADLR
  - 2019-08-13
  - ''
  - Larger language models are dramatically more useful for NLP tasks such as article
    completion, question answering, and dialog systems. Training the largest neural
    language model has recently been the best way to advance the state of the art
    in NLP applications. Two recent papers, <a href="https://arxiv.org/abs/1810.04805">BERT</a>
    and <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a>,
    demonstrate the benefits of large scale language modeling. Both papers leverage
    advances in compute and available text corpora to significantly surpass state
    of the art performance in natural language understanding, modeling, and generation.
    Training these models requires hundreds of exaflops of compute and <a href="https://arxiv.org/abs/1604.06174">clever
    memory management</a> to trade recomputation for a reduced memory footprint. However,
    for very large models beyond a billion parameters, the memory on a single GPU
    is not enough to fit the model along with the parameters needed for training,
    requiring model parallelism to split the parameters across multiple GPUs. Several
    approaches to model parallelism exist, but they are difficult to use, either because
    they rely on custom compilers, or because they scale poorly or require changes
    to the optimizer.</p></div><div><p> In this work, we implement a simple and efficient
    model parallel approach by making only a few targeted modifications to existing
    <a href="https://openreview.net/pdf?id=BJJsrmfCZ">PyTorch</a> transformer implementations.
    <a href="https://github.com/nvidia/megatron-lm">Our code</a> is written in native
    Python, leverages mixed precision training, and utilizes the <a href="https://developer.nvidia.com/nccl">NCCL
    library</a> for communication between GPUs. We showcase this approach by training
    an 8.3 billion parameter transformer language model with 8-way model parallelism
    and 64-way data parallelism on 512 GPUs, making it the <b>largest transformer
    based language model ever trained at 24x the size of BERT and 5.6x the size of
    GPT-2</b>. We have published the code that implements this approach at <a href="https://github.com/NVIDIA/Megatron-LM">our
    GitHub repository</a>.</p></div><div><p> Our experiments are conducted on NVIDIA’s
    <a href="https://devblogs.nvidia.com/dgx-superpod-world-record-supercomputing-enterprise">DGX
    SuperPOD</a>. Without model parallelism, we can fit a baseline model of 1.2B parameters
    on a single V100 32GB GPU, and sustain 39 TeraFLOPS during the overall training
    process, which is 30% of the theoretical peak FLOPS for a single GPU in a DGX2-H
    server. Scaling the model to 8.3 billion parameters on 512 GPUs with 8-way model
    parallelism, we achieved up to <b>15.1 PetaFLOPS sustained performance</b> over
    the entire application and reached <b>76% scaling efficiency</b> compared to the
    single GPU case.
- - https://en.wikipedia.org/wiki/Gambler%27s_fallacy#Monte_Carlo_Casino
  - ! 'Gambler''s Fallacy, examples: The Monte Carlo Casino'
  - English Wikipedia
  - 'NA'
  - ''
  - ! '<p>Perhaps the most famous example of the gambler’s fallacy occurred in a game
    of roulette at the <a href="https://en.wikipedia.org/wiki/Monte_Carlo_Casino">Monte
    Carlo Casino</a> on August 18, 1913, when the ball fell in black 26 times in a
    row. This was an extremely uncommon occurrence: the probability of a sequence
    of either red or black occurring 26 times in a row is <math display="inline"
    xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mfrac><mn>18</mn><mn>37</mn></mfrac><mrow><mn>26</mn><mo>−</mo><mn>1</mn></mrow></msup><annotation
    encoding="application/x-tex">\frac{18}{37}^{26-1}</annotation></semantics></math>
    or around 1 in 66.6 million, assuming the mechanism is unbiased. Gamblers lost
    millions of francs betting against black, reasoning incorrectly that the streak
    was causing an imbalance in the randomness of the wheel, and that it had to be
    followed by a long streak of red.</p>'
- - https://davidreiley.com/papers/PandoraListenerDemandCurve.pdf
  - ! 'Measuring Consumer Sensitivity to Audio Advertising: A Field Experiment on
    Pandora Internet Radio'
  - Jason Huang, David H. Reiley, Nickolai M. Riabov
  - 2018-04-21
  - 10.2139/ssrn.3166676
  - A randomized experiment with almost 35 million Pandora listeners enables us to
    measure the sensitivity of consumers to advertising, an important topic of study
    in the era of ad-supported digital content provision. The experiment randomized
    listeners into 9 treatment groups, each of which received a different level of
    audio advertising interrupting their music listening, with the highest treatment
    group receiving more than twice as many ads as the lowest treatment group. By
    keeping consistent treatment assignment for 21 months, we are able to measure
    long-run demand effects, with three times as much ad-load sensitivity as we would
    have obtained if we had run a month-long experiment. We estimate a demand curve
    that is strikingly linear, with the number of hours listened decreasing linearly
    in the number of ads per hour (also known as the price of ad-supported listening).
    We also show the negative impact on the number of days listened and on the probability
    of listening at all in the final month. Using an experimental design that separately
    varies the number of commercial interruptions per hour and the number of ads per
    commercial interruption, we find that neither makes much difference to listeners
    beyond their impact on the total number of ads per hour. Lastly, we find that
    increased ad load causes a significant increase in the number of paid ad-free
    subscriptions to Pandora, particularly among older listeners.
- - https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf#openai
  - Language Models are Unsupervised Multitask Learners
  - Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever
  - '2019'
  - ''
  - Natural language processing tasks, such as question answering, machine translation,
    reading comprehension, and summarization, are typically approached with supervised
    learning on task-specific datasets. We demonstrate that language models begin
    to learn these tasks without any explicit supervision when trained on a new dataset
    of millions of webpages called WebText. When conditioned on a document plus questions,
    the answers generated by the language model reach 55 F1 on the CoQA dataset—matching
    or exceeding the performance of 3 out of 4 baseline systems without using the
    127,000+ training examples. The capacity of the language model is essential to
    the success of zero-shot task transfer and increasing it improves performance
    in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter
    Transformer that achieves state of the art results on 7 out of 8 tested language
    modeling datasets in a zero-shot setting but still underfits WebText. Samples
    from the model reflect these improvements and contain coherent paragraphs of text.
    These findings suggest a promising path towards building language processing systems
    which learn to perform tasks from their naturally occurring demonstrations.
- - https://openai.com/blog/language-unsupervised/
  - Improving Language Understanding with Unsupervised Learning
  - OpenAI
  - June 11, 2018
  - ''
  - ! 'We’ve obtained state-of-the-art results on a suite of diverse language tasks
    with a scalable, task-agnostic system, which we’re also releasing. Our approach
    is a combination of two existing ideas: <a href="https://arxiv.org/abs/1706.03762">transformers</a>
    and <a href="https://arxiv.org/abs/1511.01432">unsupervised pre-training</a>.
    These results provide a convincing example that pairing supervised learning methods
    with unsupervised pre-training works very well; this is an idea that many have
    explored in the past, and we hope our result motivates further research into applying
    this idea on larger and more diverse datasets.'
- - /docs/modafinil/2000-jasinski.pdf
  - An evaluation of the abuse potential of modafinil using methylphenidate as a reference
  - Donald R. Jasinski
  - 2000-01-01
  - 10.1177/026988110001400107
  - Modafinil is a unique wake-promoting agent. Preclinical studies indicate a mechanism
    of action which is distinct from that of amphetamine or methylphenidate. To compare
    the pharmacodynamic profiles of modafinil, methylphenidate, and placebo in humans,
    a double-blind Latin square crossover study was conducted in 24 male volunteers
    with a history of polysubstance abuse that included the stimulant cocaine. Each
    subject was given single oral doses of methylphenidate (45 mg or 90 mg), modafinil
    (200 mg, 400 mg or 800 mg) and placebo. Measures of subjective, behavioural, and
    physiological responses were evaluated at fixed intervals during 72 h after each
    dosing occasion. Subjects discriminated both modafinil and methylphenidate from
    placebo. Subjects liked the effects of both drugs. However, modafinil differed
    from methylphenidate in its lack of a significant response on the Amphetamine
    Scale of the Addiction Research Center Inventory. The profile of physiological
    effects for modafinil differed from methylphenidate in that it showed greater
    inhibition of observed and reported sleep, less facilitation of orthostatic tachycardia
    and less reduction of caloric intake. These findings are consistent with preclinical
    pharmacological data suggesting that modafinil is not an amphetamine-like agent.
- - /Questions#jeanne-calment
  - On the Jeanne Calment longevity anomaly
  - Gwern Branwen
  - 2018-10-17
  - ''
  - ! '<p>Jeanne Calment holds the record for human longevity at ~122.5 years, and
    will have held it for a minimum of 3 decades, despite countless countervailing
    factors. No challenging centenarian has come close to her record, and arithmetically,
    they will not for years to come. Some <a href="Order-statistics#sampling-gompertz-distribution-extremes"
    title="Order Statistics: efficiently sampling Gompertz distribution extremes">statistical
    simulations</a> suggest that Calment-like records are not expected from the distribution
    of human life expectancies, and as time passes, her record becomes increasingly
    anomalous.</p><p>This truly remarkable longevity raises the question of whether
    Calment''s longevity is due to the same factors as all other centenarians: did
    she benefit from some unique factor like genetic mutations, or, as accused in
    late 2018 of being, is she, in fact, merely a fraud which has escaped previous
    verification?</p>'
- - /docs/economics/2001-fehr.pdf
  - Do Incentive Contracts Crowd Out Voluntary Cooperation?
  - Ernst Fehr, Simon Gächter
  - 2001-11-05
  - ''
  - In this paper we provide experimental evidence indicating that incentive contracts
    may cause a strong crowding out of voluntary cooperation. This crowding-out effect
    constitutes costs of incentive provision that have been largely neglected by economists.
    In our experiments the crowding-out effect is so strong that the incentive contracts
    are less efficient than contracts without any incentives. Principals, nonetheless,
    prefer the incentive contracts because they allow them to appropriate a much larger
    share of the (smaller) total surplus and are, hence, more profitable for them.
- - /docs/economics/2007-schneider.pdf
  - A Rule Against Perpetuities For The Twenty-First Century
  - Frederick R. Schneider
  - '2007'
  - 10.2307/20787089
  - <p>The common law rule against perpetuities maintained alienation of property
    by voiding interests in property that did not vest within a life in being at the
    creation of the interest plus twenty-one years. The rule was applied strictly,
    often producing harsh results. The courts used a what-might-happen test to strike
    down nonvested interests that might not have vested in a timely manner. During
    the last half-century, many legislatures have softened the application of the
    rule against perpetuities by enacting wait-and-see provisions, which require courts
    to decide cases based on the facts as they actually developed, and reformation,
    which allowed some nonvested interests to be reformed to save them from invalidity.</p><p>This
    paper describes the common law rule. Then it traces the modern developments, including
    promulgation of the widely adopted Uniform Statutory Rule Against Perpetuities,
    which includes an alternate 90 year fixed wait-and-see period to be applied in
    place of the common law's lives in being plus twenty-one years.</p><p>The paper
    continues by exploring the policies which underlie the rule against perpetuities.
    Then, after finding that there is no significant movement to repeal the rule except
    for trusts, it is established that proposals for that federal law, including federal
    transfer taxes, cannot and should not be used to implement the policies served
    by the rule itself.</p><p>There is a continuing need for state rules against perpetuities.
    The paper proposes that the rule be modified to make it more understandable and
    easier to apply. The proposed rule would replace lives in being plus twenty-one
    years with a fixed term of years. This would eliminate most of the difficulties
    encountered in application of the rule. Wait-and-see and reformation are part
    of the proposed rule. The proposed rule provides for determination of valid interests
    at the end of the fixed term of year Rule and contains a definition of "vested"
    to enable judges and attorneys to apply the rule in cases which will arise many
    years in the future.</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.306.7113&rep=rep1&type=pdf
  - On the Near Impossibility of Measuring the Returns to Advertising
  - Randall A. Lewis, Justin M. Rao
  - 2013-04-23
  - ''
  - Classical theories of the firm assume access to reliable signals to measure the
    causal impact of choice variables on profit. For advertising expenditure we show,
    using twenty-five online field experiments (representing $2.8 million) with major
    U.S. retailers and brokerages, that this assumption typically does not hold. Statistical
    evidence from the randomized trials is very weak because individual-level sales
    are incredibly volatile relative to the per capita cost of a campaign—a “small”
    impact on a noisy dependent variable can generate positive returns. A concise
    statistical argument shows that the required sample size for an experiment to
    generate sufficiently informative confidence intervals is typically in excess
    of ten million person-weeks. This also implies that heterogeneity bias (or model
    misspecification) unaccounted for by observational methods only needs to explain
    a tiny fraction of the variation in sales to severely bias estimates. The weak
    informational feedback means most firms cannot even approach profit maximization.
- - https://www.uea.ac.uk/documents/107435/107587/ccp_11_9.pdf
  - Does Retail Advertising Work? Measuring the Effects of Advertising on Sales Via
    a Controlled Experiment on Yahoo!
  - Randall A. Lewis, David H. Reiley
  - 2011-06-08
  - ''
  - We measure the causal effects of online advertising on sales, using a randomized
    experiment performed in cooperation between Yahoo! and a major retailer. After
    identifying over one million customers matched in the databases of the retailer
    and Yahoo!, we randomly assign them to treatment and control groups. We analyze
    individual-level data on ad exposure and weekly purchases at this retailer, both
    online and in stores. We find statistically and economically significant impacts
    of the advertising on sales. The treatment effect persists for weeks after the
    end of an advertising campaign, and the total effect on revenues is estimated
    to be more than seven times the retailer’s expenditure on advertising during the
    study. Additional results explore differences in the number of advertising impressions
    delivered to each individual, online and offline sales, and the effects of advertising
    on those who click the ads versus those who merely view them. Power calculations
    show that, due to the high variance of sales, our large number of observations
    brings us just to the frontier of being able to measure economically significant
    effects of advertising. We also demonstrate that without an experiment, using
    industry-standard methods based on endogenous crosssectional variation in advertising
    exposure, we would have obtained a wildly inaccurate estimate of advertising effectiveness.
- - /docs/biology/1966-kessler.pdf
  - Interplay Between Social Ecology and Physiology, Genetics and Population Dynamics
    of Mice
  - Alexander Kessler
  - 1966-03-31
  - ''
  - ! '<p>The interplay between socioecologlcal and biological processes manifests
    Itself at the level of individuals, populations, and species. The biology of Individuals
    is deeply modified when they are groups; many of the attributes of populations
    such as size, distribution, composition, etc. are related to social interactions,
    and at the level of species, patterns of social relations within groups tend to
    be structured in ways that influence survival, reproduction, and exchange among
    populations.</p><p>In one experimental approach to these problems, the social
    ecology of freely growing populations of mice In large enclosures was related
    to behavioral, physiological, and health changes of individuals, to demographic
    changes and to changes of gene frequencies. Another experiment examined the process
    and effects of artificial selection for the same trait in different social environments.</p><p><strong><em>Population
    Experiment</em></strong></p><p>The population enclosures were octagonal structures
    subdivided Into central and peripheral sections with a total surface area of 13.3
    square feet. From a founder group of mice of known genetic (progeny of a four-way
    cross among inbred mouse strains C57L/J, SWR/J, C3HeB/FeJ, 129/J) and environmental
    background, three equivalent samples of mice were distributed into replicate population
    enclosures (Pop A and B) and into standard laboratory cages as randomly mated
    male-female pairs—the control group (Pop C).</p><p>During the first year of study,
    daily observations of the enclosures were made, and several censuses were performed.
    Identifiable cohorts, animals born during each census interval, were established
    to provide an additional way of analyzing changes in the populations.</p><p>In
    Pop C, reproduction remained constant and mortality was negligible. Marked changes
    occurred in Pop A and B. The sizes (1000—A and 800—B mice) and densities (85—A
    and 60—B mice per square foot) are several times greater than those of any previously
    reported population of small mammals. However, there would have been 100,000 mice
    in each enclosure at the end of a year had the populations continued to grow as
    they did at first. Changes of reproductive physiology constituted prominent aspects
    of self-regulation in the enclosures. Peak demographic input rates occurred during
    the third month, but were already associated with decreased productivity per adult
    female. Analysis of maturation and reproduction pointed to inhibition of reproduction
    in sexually mature females as the most important factor in the decline of productivity.
    Pregnancy rates fell steadily and inhibition of full-term gestation occurred.
    Gonads and reproductive cells of males were adult, but a large proportion of males
    showed little sexual activity.</p><p>Neonatal mortality was particularly striking
    in Pop B, where 30% of females showed advanced pregnancy during the last 5.5 months
    with no newborns surviving. About 25% of the mice in the enclosures died during
    the year. Highest weekly death rates occurred during the first half of the year
    before peak numbers were present. Autopsies of mice of Pop A revealed little in
    the way of abnormal findings.</p><p>Biomass either paralleled or increased more
    rapidly than numbers in both enclosures, contrasting with some other population:
    studies in which growth was impaired with crowding.</p><p>Changes of behavior
    included: 1. disappearance of circadian activity peaks, 2. decline in frequency
    of fighting per male but an increase in unusual aggressiveness, 3. aberrations
    of sexual behavior, 4. deterioration of maternal care, 5. cannibalism, 6) striking
    decrease in social responsiveness.</p><p>Cohorts in the populations were biologically
    distinguishable sub-units in contrast to control cohorts, which showed no such
    differentiation. Cohorts in Pop A and B differed with respect to reproduction
    physiology, mortality, and behavior, and intercohort differences persisted at
    all levels of population density.</p><p>Many of the properties of Pop A and B
    mice changes when the mice were placed in different social environments, attesting
    to the specificity of the influence of social factors. For example, mice of Pop
    A, randomly paired in control cages, showed a marked rise in reproduction, and
    cohorts reproductively inhibited before were most productive in the new social
    environment. Behavioral tests performed outside the enclosure environment revealed:
    1. intercohort differences among Pop A mice contrasted with stereotyped behavior
    of Pop C mice, and 2. changes in behavior of Pop A mice both immediately after
    removal from the population and after six weeks in new social conditions. Pop
    B mice changed their social environment by emigrating into the empty interconnected
    enclosure of Pop A. Two distinctive sub-populations formed. Greater changes in
    reproduction, mortality, and behavior occurred in the emigrant subpopulation,
    which underwent more extensive social reorganization. Immediately following reunion
    of the two subpopulations, a population crash occurred, possibly related to the
    sudden changes of social conditions.</p><p>Use of genetically defined animals
    made feasible the study of gene frequency changes. Polymorphism of alleles at
    the C locus affecting coat color differed between Pop A and B on the one hand
    and Pop C on the other. Although the magnitude of the upward change of recessive
    c in Pop A and B was not large, the consistency and similarity of the change in
    Pop A and B and lack of change in Pop C suggested the action of systematic processes
    and the probable adaptiveness of the changes. There was little evidence of differential
    adult reproduction or mortality among the phenotypes but there were suggestions
    of differential neonatal survival. The relatively slow rate of change of the alleles
    after the first generation suggested the establishment of a state of balanced
    polymorphism at the C locus. Hemoglobin allele and genotype frequencies of mice
    of Pop A alive at the end of the year did not deviate from what might have been
    predicted on the basis of panmixia.</p><p><strong><em>Selection Experiment</em></strong></p><p>Selection
    for the same trait in varied environments tends to involve genetic and physiological
    differences. The question of adaptability to different social environments was
    studied; heavy body weight at sexual maturity was chosen as the trait for selection;
    groups of different sizes—pairs or groups of 20-30 mice—were the environmental
    variables. Sexes were kept separate between weaning and sexual maturity. A within-litter
    selection method was used.</p><p>Crowding depressed weight at sexual maturity
    but equal improvement with selection occurred in both social environments. Heritability
    was also equal in crowded and uncrowded groups. Environmental exchange carried
    out in the sixth and seventh generation suggested that mice selected in crowded
    environments performed slightly better in both crowded and uncrowded environments.</p><p>The
    large sizes and unusual degree of crowding attained by the freely growing populations
    in this study compared with previous studies may be related to the types of animals
    used, to the number of individuals in the founder nuclei, and to the physical
    structure of the enclosures. Extreme crowding was compatible with general physical
    health. The decline of fertility and fecundity, the decreased survival of newborns,
    and the appearance of behavioral aberrations—rather than disease or an increase
    in adult mortality—represented the major self-regulatory mechanisms that eventually
    limited population growth. The growth of individuals was not inhibited. Social
    withdrawal and the decline of social interaction rather than a rise of interaction
    characterized the populations. Such findings cast doubt about the generality of
    the so-called “Stress” theory of social ecology that emphasizes increased interaction
    and pituitary-adrenal hyperactivity as the principal mechanisms involved in self-regulation
    of vertebrate populations.</p><p>Other formulations of mammalian social ecology,
    such as those that focus on the importance of early development, of spatial requirements,
    of neurophysiological reactivity, and of communications, constitute additional
    explanations of the interplay of social and biological processes in crowded populations.</p><p>Although
    man’s potential reactions are more complex and variable than those of lower vertebrates
    and give prominence to the role of symbols and culture, his social environment
    is even more fundamental to his entire existence. This, if anything, increases
    the importance of the interplay of socioecological and biological processes for
    man.</p>'
- - https://paperswithcode.com/task/language-modelling
  - Language Modelling State-of-the-art leaderboards
  - paperswithcode.com
  - 2019-08-28
  - ''
  - ! 'Language modeling is the task of predicting the next word or character in a
    document. This page lists key recent papers on NLP language modeling and records
    reported research performance on the following tasks: WikiText-103, Penn Treebank
    (Word Level), enwiki8, Text8, One Billion Word, WikiText-2, Hutter Prize, Penn
    Treebank (Character Level).'
- - https://gpt2.apps.allenai.org/?text=Joel%20is
  - LM Explorer (alpha)
  - Allen Institute For Artificial Intelligence
  - 2019-02-26
  - ''
  - <p>This demonstration uses the public 345M 117M parameter OpenAI GPT-2 language
    model to generate sentences.</p><p>Enter some initial text and the model will
    generate the most likely next words. You can click on one of those words to choose
    it and continue or just keep typing. Click the left arrow at the bottom to undo
    your last choice.</p>
- - https://www.poetryfoundation.org/poems/49303/howl
  - Howl
  - Allen Ginsberg
  - '1955'
  - ''
  - <p>[Poem]</p><p>I saw the best minds of my generation destroyed by madness, starving
    hysterical naked,<br>dragging themselves through the negro streets at dawn looking
    for an angry fix,<br>angelheaded hipsters burning for the ancient heavenly connection
    to the starry dynamo in the machinery of night,<br>who poverty and tatters and
    hollow-eyed and high sat up smoking in the supernatural darkness of cold-water
    flats floating across the tops of cities contemplating jazz,<br>who bared their
    brains to Heaven under the El and saw Mohammedan angels staggering on tenement
    roofs illuminated,<br>who passed through universities with radiant cool eyes hallucinating
    Arkansas and Blake-light tragedy among the scholars of war,<br>who were expelled
    from the academies for crazy & publishing obscene odes on the windows of the skull,
    ...</p>
- - http://antinegationism.tumblr.com/post/182901133106/an-eternal-howl
  - An Eternal Howl
  - antinegationism
  - 2019-02-18
  - ''
  - ! '<p>[GPT-2] Prompt: </p><p>“Moloch! Solitude! Filth! Ugliness! Ashcans and unobtainable
    dollars! Children screaming under the stairways! Boys sobbing in armies! Old men
    weeping in the parks! <br>Moloch! Moloch! Nightmare of Moloch! Moloch the loveless!
    Mental Moloch! Moloch the heavy judger of men! <br>Moloch the incomprehensible
    prison! Moloch the crossbone soulless jailhouse and Congress of sorrows!<br>Moloch
    whose buildings are judgment! Moloch the vast stone of war! Moloch the stunned
    governments! <br>Moloch whose mind is pure machinery! Moloch whose blood is running
    money! Moloch whose fingers are ten armies! Moloch whose breast is a cannibal
    dynamo! <br>Moloch whose ear is a smoking tomb! <br>Moloch whose eyes are a thousand
    blind windows! <br>Moloch whose skyscrapers stand in the long streets like endless
    Jehovahs! <br>Moloch whose factories dream and croak in the fog! <br>Moloch whose
    smoke-stacks and antennae crown the cities …”<br>Response: <br>like a pile of
    wood! <br>Moloch whose huge flawless towers cry like song in the daytime! <br>Moloch
    whose buildings implode like a living Iometer of History! <br>Moloch whose bridges
    sag violently like a lattice apple falling on the stream! <br>Moloch whose court
    are the host of billions of millions of nerves of passion and anger still raging
    up and down every dollar in the world! <br>Moloch the shadow world long, Americanized
    and red in red! <br>Moloch is cruel always and everywhere. <br>Moloch is perfect
    to human purposes! <br>Moloch is kept beyond height blind. Moloch the incorporeal
    skull of man! <br>Moloch the flag of equality! <br>Moloch the endless ever-splitting
    price of hell! <br>Moloch the worldly bathing anchor in fungicide money! <br>Moloch
    the hideous empire in feeble lines! Moloch the death of the dreamless things!
    Moloch the glorious command of justice! Moloch the bloody trail!</p>'
- - https://twitter.com/robertskmiles/status/1104008764997419009
  - Rob Miles on Twitter
  - Robert Miles
  - 2019-03-08
  - ''
  - Has anyone done this yet? I told my GPT-2 program to write new verses for Allen
    Ginsberg&#39;s Howl, and forgot to tell it to stop:<a href="https://t.co/TpNnR5V2Ex">https://t.co/TpNnR5V2Ex</a>
    <a href="https://t.co/Q4fUQY8czU">pic.twitter.com/Q4fUQY8czU</a>
- - https://medium.com/@ysaw/gpt-2-writes-a-shelley-poem-bc0c19fe4ee3
  - GPT-2 Writes a Shelley Poem
  - Stephen Woods
  - 2019-02-20
  - ''
  - ! '<p>(seed text was Ozymandias)</p><p>The sea hath never parted from the rocky
    shores,<br>That doth not rise again the sea, and its long, tumbled,<br>As if the
    waters have broken by its side.<br>And as the ocean came up to sea,<br>And the
    sea was broken by the wreck,<br>And the sea sank to the Sea of the Dead<br>By
    the wad of blood. It would have slain the Sea of the Dead<br>But it would not:
    its last breath, And it did.<br>This sea in the sea hath a Sea of waggon,<br>And
    a Sea of waggon of blood; For all what hath not come<br>With it hath fallen, And
    as a waggon of blood the waggon<br>And the blood is flowing out of that waggon.<br>So,
    then, are the works of Zeus,<br>And the work of Zeus, O Great Creator, whose designs<br>With
    the work of the great King are he wrought<br>In their midst. . . . .<br>In the
    desert have the mighty Gods<br>And the gods themselves come.”<br>A serpent of
    darkness rises among the hills<br>In a forest on the land of the gods.<br>A mighty
    bird that flies out a bird-hoast,<br>And flies out a fly, from behind its wing.<br>And
    there the sky is filled with white, and it is broken through.<br>And like this,
    we know the mighty Man<br>Of the clouds from which he fled upon the land of the
    gods,<br>The mighty serpent that the king sent for them,<br>And he brought them
    to that man; and he said:<br>“I know you, O mighty Man from the earth!”<br>And
    what do you say? You knew him when you saw in the dream,<br>And you saw from under
    one of his arms a mighty serpent<br>That a mighty man can lift up, and drive<br>He
    that was in the way and lifted up; and he led him to be a god,<br>And he he led
    him down the great mountain which I have prepared.<br>Let his tongue speak, tell
    thee, O man: “I know thee.<br>Here thou dost see, O great King, that is the very
    power of the Gods”<br>Let His voice say, to thee, “that is the very power of the
    Gods”<br>Let His voice say to thee, “that is the voice of the whole creation”</p>'
- - https://slatestarcodex.com/2019/02/19/gpt-2-as-step-toward-general-intelligence/
  - GPT-2 As Step Toward General Intelligence
  - Scott Alexander
  - 2019-02-19
  - ''
  - ! 'A machine learning researcher writes me in response to yesterday’s post, saying:<p><blockquote>I
    still think GPT-2 is a brute-force statistical pattern matcher which blends up
    the internet and gives you back a slightly unappetizing slurry of it when asked.</blockquote></p><p>I
    resisted the urge to answer “Yeah, well, your mom is a brute-force statistical
    pattern matcher which blends up the internet and gives you back a slightly unappetizing
    slurry of it when asked.”</p><p>But I think it would have been true.</p><p>A very
    careless plagiarist takes someone else’s work and copies it verbatim: “The mitochondria
    is the powerhouse of the cell”. A more careful plagiarist takes the work and changes
    a few words around: “The mitochondria is the energy dynamo of the cell”. A plagiarist
    who is more careful still changes the entire sentence structure: “In cells, mitochondria
    are the energy dynamos”. The most careful plagiarists change everything except
    the underlying concept, which they grasp at so deep a level that they can put
    it in whatever words they want—at which point it is no longer called plagiarism.</p><p>GPT-2
    writes fantasy battle scenes by reading a million human-written fantasy battle
    scenes, distilling them down to the concept of a fantasy battle scene, and then
    building it back up from there. I think this is how your mom (and everyone else)
    does it too. GPT-2 is worse at this, because it’s not as powerful as your mom’s
    brain. But I don’t think it’s doing a different thing. We’re all blending experience
    into a slurry; the difference is how finely we blend it...</p>'
- - https://twitter.com/peterkz_swe/status/1098668851640848384
  - Peter Krantz on Twitter
  - Peter Krantz
  - 2019-02-21
  - ''
  - ! '<p>First line of famous poems continued by the <a href="https://twitter.com/OpenAI">@openAI</a>
    GPT-2 example model from &quot;Language Models are Unsupervised Multitask Learners&quot;
    <a href="https://twitter.com/hashtag/gpt2poetrytwsrcpt2poetry</a> <a href="https://twitter.com/hashtag/GPT2">#GPT2</a><br>\U0001F447\U0001F3FC</p>&mdash;
    Peter Krantz (@peterkz_swe) <a href="https://twitter.com/peterkz_swe/status/1098668851640848384">February
    21, 2019</a></blockquote><br><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script><br><blockquote class="twitter-tweet" data-lang="en"><p
    lang="en" dir="ltr">It little profits that an idle king,<br>who loves his
    throne for a moment to enjoy a good meal, <br>might, if he was not in the right
    position, <br>become the subject of a great banquet.<br>But as the royal household
    will do, <br>so too shall their subjects. <a href="https://twitter.com/hashtag/gpt2poetry">#gpt2poetry</a>
    <a href="https://twitter.com/hashtag/tennyson">#tennyson</a></p>'
- - https://github.com/kylemcdonald/gpt-2-poetry
  - gpt-2-poetry
  - Kyle McDonald
  - 2019-03-04
  - ''
  - <p>I used <code>download-urls.py</code> to quickly download the HTML from poetryfoundation.org
    based on the URLs in <code>romantic-urls.txt</code>.</p><p>Then I used <code>Parse
    Poetry.ipynb</code> to parse the HTML and extract the title, author, and poem.
    There are some glitches here with newlines being rendered in some places they
    shouldn't, and not being rendered in places where they should. This notebook saves
    a bunch of text files to output/ that include metadata as the first few lines.</p><p>Then
    I used <code>Generate GPT-2.ipynb</code> to generate poems based on random chunks
    from the poems and the seed words. This notebook saves files to <code>poems.json</code>
    and <code>generated.json</code>. To run this notebook, first get GPT-2 running,
    and drop the notebook in the <code>gpt-2/src/</code> directory.</p><p>Both Python
    notebooks import from <code>utils</code> which I have separately pushed here.</p><p>Finally,
    I load <code>generated.json</code> and <code>poems.json</code> with JavaScript
    in <code>index.html</code> and display the results.</p>
- - https://medium.com/merzazine/fridai-water-water-everywhere-as-read-by-artificial-intelligence-d02bb3d2b156
  - ! 'FridAI: ‘Water, water, everywhere’, as read by Artificial Intelligence'
  - Merzmensch Kosmopol
  - 2019-03-15
  - ''
  - ! '<p>Samuel Taylor Coleridge once introduced to the world that desolated ship
    journey in his “The Rime of the Ancient Mariner”:<br><blockquote>Water, water,
    everywhere,<br>And all the boards did shrink;<br>Water, water, everywhere,<br>Nor
    any drop to drink.</blockquote>Ulysses, Noah and Job, so many allusions are hidden
    in this masterpiece about “a sadder and a wiser man”. And so I wanted to know,
    which journey will be chosen by GPT-2, a Deep Learning entity, developed by OpenAI
    to write texts.</p><p>And it wrote me a poem.</p><p>My input was the four lined
    stanza, as cited above. And here is the poetic vision by Artificial Intelligence:</p><p><blockquote>Water,
    water, everywhere, <br>And all the boards did shrink; <br>Water, water, everywhere,
    <br>Nor any drop to drink. <br>Water, water, everywhere, <br>And all the boards
    did shrink; <br>Water, water, everywhere, <br>No balm in his hair: <br>Water,
    water, everywhere, <br>And all the boards did shrink. <br>Water, water, everywhere,
    <br>Yet we like its rarity. <br>Water, water, everywhere, <br>And all the boards
    did shrink. <br>Water, water, everywhere.</blockquote></p><p>Yes, the rarity of
    the water (everywhere) is striking. Even if the hair is suffering without balm.
    Probably because you cannot drink a drop.</p><p>But the poem was not over. AI
    was embraced by inspiration...</p>'
- - http://yudhanjaya.com/2019/04/the-poetry-machine/
  - The Poetry Machine
  - Yudhanjaya Wijeratne
  - 2019-04-12
  - ''
  - ! '<p>I’ve always admired the translations of Chinese poetry–I’m no expert on
    the field, but there are two poets named Du Fu and Li Bai that I really like.
    They were legendary masters from the Great Tang Dynasty, and (if the translations
    are accurate), they had a phenomenal talent for freezing a moment and capturing
    that particular slice of time with their words; their poems read like a string
    of Polaroids stretched across a riverbank.</p><p>Here, for example, is a Du Fu
    poem. Among other things, there’s a certain simplicity here: one strong emotion
    resonates through, and unlike much of the English verse I grew up with, it’s firmly
    in the present tense:<blockquote>A LONG CLIMB<br>In a sharp gale from the wide
    sky apes are whimpering,<br>Birds are flying homeward over the clear lake and
    white sand,<br>Leaves are dropping down like the spray of a waterfall,<br>While
    I watch the long river always rolling on.<br>I have come three thousand miles
    away. Sad now with autumn<br>And with my hundred years of woe, I climb this height
    alone.<br>Ill fortune has laid a bitter frost on my temples,<br>Heart-ache and
    weariness are a thick dust in my wine.</blockquote> <p>Which I suppose is why
    this appeals to me—there’s a rare clarity here, even if the translation might
    be inaccurate.</p><p>So the Tang poets seemed like the right place to start with
    for my experiment with machine-generated art (and besides, the excellent GWERN
    already did the usual English[1]). Right now, I’ve snuck away for a few hours
    from a my statistical models to peek at the code I set to run this morning.<p><p>Among
    those of us who work with machine learning, the work I’ve put into this whole
    project is trivial: a tiny dataset, a cup of coffee, a few lines of Python code,
    and a single cigarette while I waited for OpenAI’s transformer-based generation
    model [2] to download.</p>'
- - https://twitter.com/rossgoodwin/status/1124901310677913600
  - Ross Goodwin on Twitter
  - ! '@rossgoodwin'
  - 2019-05-04
  - ''
  - <p>THREE MORE GPT-2 POEMS</p><p>I've been training this poetry model on a corpus
    structured to encourage thematic integration of individual keyword prompts, and
    the word "ghost" produced these results.</p><p>{ 1 / 3 } <a href="https://t.co/GehRqfQGq8">pic.twitter.com/GehRqfQGq8</a>...</p>
- - https://iforcedabot.com/what-can-a-fake-news-detector-do/
  - Testing The Limits of Grover The Neural Fake News Detector. Can It Write Fiction?
    Can It Write Riddles?
  - Jonathan Fly
  - 2019-05-31
  - ''
  - ! '<p>Grover is a neural network modeled after GPT-2 as a state-of-the-art detector
    for Neural Network fake news. Grover is also a state-of-the-art generator of fake
    news and they provide a web interface. Since Grover is modeled after the full-size
    1.5B GPT-2—not the smaller version the public has access to—this is a bit like
    getting a back door to the full-size GPT-2. This is very exciting! (Update: They
    just reduced the size of the public model to 345M—everything in this post come
    from the full size model. Glad I stayed up way too late hammering the real thing
    for samples… Update 2: It’s back up!)</p><p>Grover was trained on 5000 news domains
    indexed by Google News, not the internet generally like GPT-2. As you would expect
    Grover excels at writing fake news: <blockquote><p>Scientists Recommend Against
    Vaccination: "The Evidence Is Now Clear: Vaccines Cause Autism and Cancer"</p><p>After
    a 15-year study, scientists in Britain are recommending that the British government
    refrain from administering vaccines. The study, written by Mike Gunton, professor
    of epidemiology and professor of genetic medicine at the University of Liverpool,
    claims that the chances of the MMR vaccine, a vaccine for measles, mumps and rubella,
    causing autism in children are “strongly possible.” And while Gunton and his team
    say their findings only apply to the MMR vaccine, they believe there are “many
    similar disorders” linked to vaccines and there is “strong evidence” vaccines
    cause autism and leukemia. Gunton told the Telegraph that no effort should be
    made to give vaccines to children younger than 3 months of age. The vaccine is
    highly controversial, and parents have been choosing to opt out of the MMR vaccination
    in recent years. This year, the British government’s vaccination program chose
    not to distribute the MMR vaccine, citing the study as the reason.</p></blockquote>
    You don’t have to fish to get coherent fake news of Grover, it’s absolutely great
    at it.</p>'
- - https://medium.com/@NPCollapse/replicating-gpt2-1-5b-86454a7f26af
  - Replicating GPT2–1.5B
  - Connor Leahy
  - 2019-06-06
  - ''
  - ! '<p>In this post, I want to quickly talk about the technical and organizational
    questions around my recent replication of GPT2–1.5B. Please read my main post
    for the full story. I will try to keep this post brief.</p>><b>The important facts</b></p><p>Code:
    <a href="https://github.com/ConnorJL/GPT2">https://github.com/ConnorJL/GPT2</a></p><p>Samples:
    <a href="https://github.com/ConnorJL/GPT2/tree/master/samples">https://github.com/ConnorJL/GPT2/tree/master/samples</a></p><p>The
    code should run out of the box on GPUs and TPUs (and CPUs, if you’re really desperate).
    I used the parameters specified in 1.5B.json and trained it on a preemptible v3–512
    TPU pod (which is actually more powerful than the machine OpenAI used) for around
    a week (with interruptions). Code and instructions for generating the dataset
    are also included in the repo.</p><p>You can download my models with the script
    in the repo. Currently I have a weaker version of 117M, and a model I call PrettyBig
    which is slightly larger than OpenAI’s 345M, which means it is technically the
    largest GPT2 model currently publicly available.</p><p>I will be releasing 1.5B
    to the public on July 1st, if, and only if, no one shows me a convincing reason
    not to. When I do, it will be downloadable just like my other models.</p>'
- - https://medium.com/@NPCollapse/addendum-evaluation-of-my-model-e6734b51a830
  - ! 'Addendum: Evaluation of My Model'
  - Connor Leahy
  - 2019-06-12
  - ''
  - ! '<p>As a mercifully short addendum, I’d like to quickly address a few questions
    about my model. Please read my update post to hear my important updated beliefs
    on this situation, because I believe the details of how powerful my model is or
    not are not actually very important to the overall situation.</p><p>As described
    in my technical post, my model is not identical to OpenAI’s, because I simply
    didn’t have all the details of what they did. The truth is also that the samples
    and metrics I have shown aren’t 100% accurate. For one, my metric code is flawed,
    I made several rookie mistakes in setting up accurate evaluation (let train and
    eval data mix, used metrics whose math I didn’t understand etc), and the model
    I used to generate the samples is in fact not the final trained model, but one
    about halfway through the training. I didn’t take my time to evaluate the strength
    of my model, I simply saw I had the same amount of hardware as OpenAI and code
    as close to the paper as possible and went with it. The reason for this is a simple
    human flaw: I got cold feet once I realized what I was sitting on and acted rashly.
    I made a mistake, I did something stupid, that’s all there is to it.</p><p>Thanks
    to help from OpenAI it is now safe to say that my model is not as powerful as
    OpenAI’s. The metric results for WikiText2, LAMBADA and PTB are (lower is better):</p><p>GPT2:
    18.67 / 8.63 / 36.51</p><p>Mine: 43.79 / 109.47 / 202.29</p><p>Although I used
    the same amount of hardware (or more), the differences in my training setup and
    hyperparameters made a significant difference. Which is an unfortunate reality
    to anyone familiar with reproducing deep learning papers. I don’t think my model
    in its current state is even as dangerous as 117M in its text generating abilities.
    But I believe to have found the quirks in my setup that have held the model back,
    and they are easy to fix. I am very tempted to continue tinkering with the model
    and seeing if I can improve it…but I will be holding back for now.</p>'
- - https://www.rand.org/research/gun-policy/analysis/essays/mass-shootings.html
  - ! 'Mass Shootings: Definitions and Trends'
  - Rosanna Smart (RAND)
  - 2018-03-02
  - ''
  - ! '<p>There is no standard definition of what constitutes a mass shooting. Media
    outlets, academic researchers, and law enforcement agencies frequently use different
    definitions when discussing mass shootings, leading to different assessments of
    the frequency with which mass shootings occur and about whether mass shootings
    are more common now than they were a decade or two ago.</p><p>...These definitions
    matter. Depending on which data source is referenced, there were seven, 65, 332,
    or 371 mass shootings in the United States in 2015 (see table below), and those
    are just some examples. More-restrictive definitions (e.g., Mother Jones) focus
    on the prevalence of higher-profile events motivated by mass murder, but they
    omit more-common incidents occurring in connection with domestic violence or criminal
    activity, which make up about 80 percent of mass shooting incidents with four
    or more fatally injured victims (Krouse and Richardson, 2015).</p><p>...In 2014,
    the FBI released a study showing that “active shooting incidents” had increased
    at an average annual rate of 16 percent between 2000 and 2013 (Blair and Schweit,
    2014). In contrast to the varied definitions for mass shootings, there is an agreed-upon
    definition among government agencies for <em>active shooter</em>: “an individual
    actively engaged in killing or attempting to kill people in a confined and populated
    area; in most cases, active shooters use firearm(s) and there is no pattern or
    method to their selection of victims” (U.S. Department of Homeland Security, 2008,
    p. 2). Using a modified version of this definition to include incidents that had
    multiple offenders or occurred in confined spaces, Blair and Schweit (2014) found
    that active shootings had increased from only one incident in 2000 to 17 in 2013.</p><p>...In
    their analysis of mass shooting trends from 1999 to 2013, Krouse and Richardson
    (2015) distinguished between mass shootings occurring in public locations that
    are indiscriminate in nature (“mass public shootings”), mass shootings in which
    the majority of victims are members of the offender’s family and that are not
    attributable to other criminal activity (“familicide mass shootings”), and mass
    shootings that occur in connection to some other criminal activity (“other felony
    mass shootings”). The two figures below show trends in these types of mass shooting
    incidents and fatalities, respectively, using the data provided in Krouse and
    Richardson (2015). Extending the data back to the 1970s, two studies found evidence
    of a slight increase in the frequency of mass public shootings over the past three
    decades (Cohen, Azrael, and Miller, 2014; Krouse and Richardson, 2015). However,
    using an expanded definition that includes domestic- or felony-related killings,
    there is little evidence to suggest that mass shooting incidents or fatalities
    have increased (Cohen, Azrael, and Miller, 2014; Krouse and Richardson, 2015;
    Fox and Fridel, 2016). Thus, different choices about how to define a mass shooting
    result in different findings for both the prevalence of these events at a given
    time and whether their frequency has changed over time.</p><p>...Definitional
    issues aside, the relative rarity of mass shooting events makes analysis of trends
    particularly difficult. Chance variability in the annual number of mass shooting
    incidents makes it challenging to discern a clear trend, and trend estimates will
    be sensitive to outliers and to the time frame chosen for analysis. For example,
    while Krouse and Richardson (2015) found evidence of an upward trend in mass public
    shootings from 1999 to 2013, they noted that the increase was driven largely by
    2012, which had an unusually high number of mass public shooting incidents. Additionally,
    Lott (2015) showed that the FBI study’s estimate of a dramatic increase in active-shooter
    incidents was largely driven by the choice of 2000 as the starting date, because
    that year had an unusually low number of shooting incidents; extending the analysis
    to cover 1977 onward and adjusting the data to exclude events with fewer than
    two fatalities, Lott (2015) found a much smaller and statistically insignificant
    increase (less than 1 percent annually) in mass shooting fatalities over time.</p>'
- - https://medium.com/huggingface/distilbert-8cf3380435b5
  - ! 'Smaller, faster, cheaper, lighter: Introducing DistilBERT, a distilled version
    of BERT'
  - Victor Sanh
  - 2019-08-28
  - ''
  - ! '<p>[HuggingFace has released a NLP transformer model "DistilBERT", which is
    similar to the BERT architecture: only 66 million parameters (instead of 110 million)
    while keeping 95% of the performance on GLUE. It is available on their repository
    ''pytorch-transformers'' alongside 7 other transformer models. It uses knowledge
    distillation with a cross-entropy loss to train a much smaller faster version
    of BERT with similar performance.]</p><p>"We train DistilBERT on eight 16GB V100
    GPUs for approximately three and a half days using the concatenation of Toronto
    Book Corpus and English Wikipedia (same data as original BERT)...As shown in the
    following table, DistilBERT’s performances compare favorably with the baselines
    while having respectively about half and one third the number of parameters (more
    on this below). Among the 9 tasks, DistilBERT is always on par or improving over
    the ELMo baseline (up to 14 points of accuracy on QNLI). DistilBERT also compares
    surprisingly well to BERT: we are able to retain more than 95% of the performance
    while having 40% fewer parameters. In terms of inference time, DistilBERT is more
    than 60% faster and smaller than BERT and 120% faster and smaller than ELMo+BiLSTM."</p>'
- - https://www.outsideonline.com/1925841/inside-look-surprisingly-violent-quidditch-world-cup
  - An Inside Look at the Surprisingly Violent Quidditch World Cup
  - Eric Hansen (Outside)
  - 2012-05-04
  - ''
  - ! '<p>The Quidditch World Cup sounds dorky, and make no mistake: it is. But these
    sorcery-loving Harry Potter fans play pretty rough, as Eric Hansen found out when
    he captained a bad-news team of ex-athletes, ultimate Frisbee studs, slobs, drunks,
    and some people he knows from Iceland. Brooms up, and may the best Muggles win.</p><p>...But
    there were portents of violence, like when I spoke to a longtime player who gave
    me strange-sounding advice that I relayed to the team. “‘Hide your girls?’” Josh
    kept asking. “What does that even mean?”</p><p>...“Drepa, drepa, drekka blód!”
    we shouted, thinking then that “Kill, kill, drink blood” was the height of irony.</p><p>...A
    goalie—the keeper—guards his team’s hula-hoops, usually by swatting the quaffle
    out of the air with his hand. Or so we thought...I try, but he barges past with
    the flailing arms and unblinking eyes of a proper Potter psycho. For reasons unknown,
    just shy of our goal the bastard chooses to ignore the hoops and instead clobbers
    my wife, Hrund, who isn’t even in the game.</p><p>I see the whole episode from
    just inches away, a dirty lock of his hair waving in my face as I sprint behind
    him. One moment she’s relaxing on the sideline, looking away, not even holding
    a broom. The next, this freak lowers his non-broom-carrying shoulder and blasts
    her in the sternum. The impact sends her flying through the dusky air, nearly
    completing a full back layout before landing on her head.</p><p>...I didn’t catch
    a whiff of the terrifying stench of Quid Kid hostility until I ambled out into
    the parking lot at the south gate and ended up chatting with a tired ambulance
    driver who was having a smoke. He was one of 30 EMTs posted at the event. “Easy
    duty,” I said. “This is just the quiet before another storm,” he corrected. “I’ve
    had eight concussions, two people taken to the hospital, bloody noses, scrapes,
    twisted ankles. I stopped counting injuries after 10.” My teammates weren’t as
    surprised by these stats as I expected. One recalled stopping a young female chaser
    just short of the goal, only to have the girl yell an extremely unprintable comment.
    Another teammate recalled watching a man in Division 1 lift a girl, spin her like
    the blades of a helicopter, and throw her to the dirt. The violence was not only
    pervasive but gender neutral. Hide your girls, indeed.</p>'
- - /docs/psychology/2013-hurlburt.pdf
  - Toward a phenomenology of inner speaking
  - Russell T. Hurlburt, Christopher L. Heavey, Jason M. Kelsey
  - 2013-12-01
  - 10.1016/j.concog.2013.10.003
  - ! '<p><em>Highlights</em>:</p><ul><li>Inner speaking is a common but not ubiquitous
    phenomenon of inner experience.</li><li>There are large individual differences
    in the frequency of inner speaking (from near 0% to near 100%).</li><li>There
    is substantial variability in the phenomenology of naturally occurring moments
    of inner speaking.</li><li>Use of an appropriate method is critical to the study
    of inner experience.</li><li>Descriptive Experience Sampling is designed to apprehend
    high fidelity descriptions of inner experience.</li></ul><p><em>Abstract</em>:
    Inner speaking is a common and widely discussed phenomenon of inner experience.
    Based on our studies of inner experience using Descriptive Experience Sampling
    (a qualitative method designed to produce high fidelity descriptions of randomly
    selected pristine inner experience), we advance an initial phenomenology of inner
    speaking. Inner speaking does occur in many, though certainly not all, moments
    of pristine inner experience. Most commonly it is experienced by the person as
    speaking in his or her own naturally inflected voice but with no sound being produced.
    In addition to prototypical instances of inner speaking, there are wide-ranging
    variations that fit the broad category of inner speaking and large individual
    differences in the frequency with which individuals experience inner speaking.
    Our observations are discrepant from what many have said about inner speaking,
    which we attribute to the characteristics of the methods different researchers
    have used to examine inner speaking.</p>'
- - http://www.bbc.com/future/story/20190819-what-your-inner-voice-says-about-you
  - ! 'What the voice inside your head says about you: We tend to assume that our
    internal monologue ''speaks'' in words---but it turns out that, for many of us,
    it’s much more complicated'
  - Kelly Oakes (BBC)
  - 2019-08-20
  - ''
  - ! '<p>Psychologist Russell Hurlburt at the University of Nevada, Las Vegas, has
    spent the last few decades training people to see inside their own minds more
    clearly in an attempt to learn something about our inner experiences at large.
    Though many individual studies on inner speech include only a small number of
    participants, making it hard to know whether their results apply more widely,
    Hurlburt estimates he’s been able to peek inside the minds of hundreds of people
    since he began his research. What he’s found suggests that the thoughts running
    through our heads are a lot more varied than we might suppose.</p><p>For one,
    words don’t seem to feature as heavily in our day-to-day thoughts as many of us
    think they do. “Most people think that they think in words, but many people are
    mistaken about that,” he says. In one small study, for example, <a href="http://hurlburt.faculty.unlv.edu/brouwers--hurlburt%202018.pdf"
    title="&#39;Pristine Inner Experience while Silent Reading: It’s *Not* Silent
    Speaking of the Text&#39;, Brouwers et al 2018">16 college students were given
    short stories before being randomly sampled</a> to find out what they were thinking
    during the course of reading. Only a quarter of their sampled thoughts featured
    words at all, and just 3% involved internal narration.</p><p>…If people aren’t
    constantly talking to themselves, what are they doing?</p><p>In his years of studying
    the inner workings of people’s minds, Hurlburt has come up with five categories
    of inner experiences: inner speaking, which comes in a variety of forms; inner
    seeing, which could feature images of things you’ve seen in real life or imaginary
    visuals; feelings, such as anger or happiness; sensory awareness, like being aware
    of the scratchiness of the carpet under your feet; and unsymbolised thinking,
    a trickier concept to get your head around, but essentially a thought that doesn’t
    manifest as words or images, but is undoubtedly present in your mind. But those
    categories leave room for variation, too. Take inner speaking, which can come
    in the form of a single word, a sentence, some kind of monologue, or even a conversation.
    The idea of an internal dialogue—rather than a monologue—will be familiar to anyone
    who’s ever rehearsed an important conversation, or rehashed an argument, in their
    mind. But the person we talk to inside our head is not always a stand in for someone
    else—often, that other voice is another aspect of ourselves.</p><p>…Famira Racy,
    co-ordinator of the Inner Speech Lab at Mount Royal University, Canada, and her
    colleagues recently used a method called thought listing—which, unsurprisingly,
    involves getting participants to list their thoughts at certain times—to take
    a broader look at <a href="https://www.gwern.net/docs/psychology/2019-famira.pdf"
    title="&#39; Using a Thought Listing Procedure to Construct the General Inner
    Speech Questionnaire: An Ecological Approach&#39;, Racy et al 2019">why and when
    people use inner speech, as well as what they say to themselves.</a></p><p>They
    found that the students in the study were talking to themselves about everything
    from school to their emotions, other people, and themselves, while they were doing
    everyday tasks like walking and getting in and out of bed. Though it has the same
    limitations as much research on inner speech—namely, you can’t always trust people
    to know what or how they were really thinking—the results appear consistent with
    previous work.</p><p>“I can’t say for sure if it’s any more important [than other
    kinds of inner experience], but there’s been enough research done to show that
    inner speech plays an important role in self-regulation behaviour, problem solving,
    critical thinking and reasoning and future thinking,” Racy says…“It gives you
    a way to communicate with yourself using a meaningful structure,” says Racy. Or
    as one of her colleagues sometimes puts it: “Inner speech is your flashlight in
    the dark room that is your mind.”</p>'
- - https://openai.com/blog/gpt-2-6-month-follow-up/
  - ! 'GPT-2: 6-Month Follow-Up'
  - OpenAI
  - 2019-08-20
  - ''
  - <p>We’re releasing the 774 million parameter GPT-2 language model after the release
    of our small 124M model in February, staged release of our medium 355M model in
    May, and subsequent research with partners and the AI community into the model’s
    potential for misuse and societal benefit. We’re also releasing an open-source
    legal agreement to make it easier for organizations to initiate model-sharing
    partnerships with each other, and are publishing a technical report about our
    experience in coordinating with the wider AI research community on publication
    norms.</p><p>...Research from these partners will factor into our future release
    decisions, as will observing how the 774M model is used, and discussing language
    models with researchers and policymakers to understand the considerations around
    larger models. As part of our staged release strategy, our current plan is to
    release the 1558M parameter model in a few months, but it’s plausible that findings
    from a partner, or malicious usage of our 774M model, could change this.</p>
- - /docs/iq/1987-simonton.pdf
  - Developmental antecedents of achieved eminence
  - Dean Keith Simonton
  - '1987'
  - ''
  - ! '<p>[Literature review of Simonton & other''s research into life history predictors
    of great accomplishment in the arts/sciences/politics/etc, particularly childhood:
    what variables seem to correlate with later eminence? Simonton discusses as predictors:
    1. intelligence; 2. birth order (first-born); 3. extreme motivation/drive; 3.
    parental loss/orphanhood (!); 4. a previous generation of role models to imitate;
    5. formal education (or lack thereof); 6. global circumstances/''zeitgeist''.</p><p>On
    nature-nurture, Simonton deprecates the role of genetics, arguing that genius
    counts fluctuate too much and are too sporadic over time to reflect primarily
    genetics, but see Lykken et al on ''emergenesis'', dysgenics, and tail effects
    in order statistics (especially the Lotka curve/log-normal distribution Simonton
    is so familiar with) for why this argument is weak.]</p>'
- - https://warontherocks.com/2019/08/lets-not-make-a-deal-geopolitics-and-greenland/
  - ! 'Let''s (Not) Make a Deal: Geopolitics and Greenland'
  - Jon Rahbek-Clemmensen (War on the Rocks)
  - 2019-08-28
  - ''
  - As is often the case, the truth lies somewhere in between these extremes. Trump’s
    offer to buy Greenland is not a wild-eyed fluke. Instead, it reflects a steadily
    increasing American interest in Greenland that is spurred by fear of Chinese and
    Russian encroachments. At the same time, however, a quest to purchase Greenland
    is not the optimal way to achieve American security interests, as it is unlikely
    to succeed, and even if it did, it would be far more expensive than other, more
    sensible approaches. Instead, the United States should engage with Denmark and
    Greenland to find common ground on shared concerns...Instead of offering to buy
    Greenland, the United States should pursue an engagement strategy that combines
    targeted concessions with clever diplomacy to get the Danes and Greenlanders to
    cooperate. Luckily, if approached correctly, both nations are very interested
    in supporting U.S. security interests, as they are broadly shared—especially in
    Copenhagen. The key will be to see this not as a zero-sum game, but as a win-win-win
    situation.
- - https://www.vulture.com/2019/08/spottedrisk-scandal-insurance-hollywood.html
  - Can You Indemnify Against Dick Pics? The rise of scandal insurance in Hollywood
  - Boris Kachka
  - 2019-08-05
  - ''
  - ! '<p>A standard Lloyd’s contract defined disgrace in vague terms—as “any criminal
    act, or any offence against public taste or decency … which degrades or brings
    that person into disrepute or provokes insult or shock to the community.” Most
    effective policies rely on precise terms and evidence that both sides can agree
    on—the Richter scale, a hospital bill. Subjective wording leads to disputes. Insurance
    “has to involve no litigation,” says Bill Hubbard, CEO of the entertainment insurer
    HCC Specialty Group. “You know the Supreme Court justice who said, ‘I know pornography
    when I see it’? You can’t settle claims that way.”</p><p>The contracts were much
    clearer on the definition of what <em>didn’t</em> merit a payout: Many of them
    exempted non-felonious offenses and acts committed prior to the policy’s start
    date. Even if the <em>All the Money</em> producers had bought a policy, Spacey’s
    past transgressions might have been excluded, treated as preexisting conditions.</p><p>While
    these limitations kept the industry small, the foibles of the rich and famous
    only increased demand for a better product. Tiger Woods’s 2009 car crash, followed
    by revelations of his infidelities, cost him $22 million in contracts with brands
    like AT&amp;T and Gatorade—which was nothing compared to what they cost the companies.
    A UC Davis study put the brands’ shareholder losses somewhere between $5 billion
    and $12 billion.</p><p>But it wasn’t Woods who made disgrace insurance look viable;
    it was reality television. A few months before the golfer’s car crash came what
    one underwriter refers to only as “that Viacom loss.” Ryan Jenkins, then a contestant
    on the VH1 reality show <em>Megan Wants a Millionaire</em> and the star of an
    upcoming season of <em>I Love Money</em>, became the lead suspect in his wife’s
    murder and killed himself a few days later. <em>Megan</em> was canceled after
    three episodes and the <em>Money</em> season shelved entirely, costing Viacom
    seven figures in losses. That’s when the company started buying disgrace insurance.</p><p>Thousands
    of reality shows have been insured in the ensuing decade, many of them via two
    insurance brokers, Gallagher Entertainment and HUB International. HUB’s managing
    director, Bob Jellen, can recall about half a dozen claims paying out since the
    Jenkins murder. He wouldn’t offer specifics, but others have given two examples:
    <em>P.I. Moms</em>, which was canceled in 2011 following fraud and drug charges,
    and Spike TV’s <em>Bar Rescue</em>, after an owner killed a country singer in
    his own rescued bar. “It’s something we don’t advertise,” says Jellen of disgrace
    insurance. “You don’t have to sell people on disgrace.”</p>'
- - /docs/psychology/2017-mercier.pdf
  - How Gullible are We? A Review of the Evidence from Psychology and Social Science
  - Hugo Mercier
  - 2017-05-18
  - 10.1037/gpr0000111
  - ! '<p>A long tradition of scholarship, from ancient Greece to Marxism or some
    contemporary social psychology, portrays humans as strongly gullible—wont to accept
    harmful messages by being unduly deferent. However, if humans are reasonably well
    adapted, they should not be strongly gullible: they should be vigilant toward
    communicated information. Evidence from experimental psychology reveals that humans
    are equipped with well-functioning mechanisms of epistemic vigilance. They check
    the plausibility of messages against their background beliefs, calibrate their
    trust as a function of the source’s competence and benevolence, and critically
    evaluate arguments offered to them. Even if humans are equipped with well-functioning
    mechanisms of epistemic vigilance, an adaptive lag might render them gullible
    in the face of new challenges, from clever marketing to omnipresent propaganda.
    I review evidence from different cultural domains often taken as proof of strong
    gullibility: religion, demagoguery, propaganda, political campaigns, advertising,
    erroneous medical beliefs, and rumors. Converging evidence reveals that communication
    is much less influential than often believed—that religious proselytizing, propaganda,
    advertising, and so forth are generally not very effective at changing people’s
    minds. Beliefs that lead to costly behavior are even less likely to be accepted.
    Finally, it is also argued that most cases of acceptance of misguided communicated
    information do not stem from undue deference, but from a fit between the communicated
    information and the audience’s preexisting beliefs.</p><p>[Keywords: epistemic
    vigilance, gullibility, trust]</p>'
- - https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf
  - Deep Neural Networks for YouTube Recommendations
  - Paul Covington, Jay Adams, Emre Sargin
  - 2016-09-15
  - 10.1145/2959100.2959190
  - ! 'YouTube represents one of the largest scale and most sophisticated industrial
    recommendation systems in existence. In this paper, we describe the system at
    a high level and focus on the dramatic performance improvements brought by deep
    learning. The paper is split according to the classic two-stage information retrieval
    dichotomy: first, we detail a deep candidate generation model and then describe
    a separate deep ranking model. We also provide practical lessons and insights
    derived from designing, iterating and maintaining a massive recommendation system
    with enormous user-facing impact.'
- - https://www.youtube.com/watch?v=HEqQ2_1XRTs
  - ! 'Reinforcement Learning for Recommender Systems: A Case Study on Youtube'
  - Minmin Chen
  - 2019-03-28
  - ''
  - While reinforcement learning (RL) has achieved impressive advances in games and
    robotics, it has not been widely adopted in recommender systems. Framing recommendation
    as an RL problem offers new perspectives, but also faces significant challenges
    in practice. Industrial recommender systems deal with extremely large action spaces—many
    millions of items to recommend and complex user state spaces—billions of users,
    who are unique at any point in time. In this talk, I will discuss our work on
    scaling up a policy-gradient-based algorithm, i.e. REINFORCE to a production recommender
    system at Youtube. We proposed algorithms to address data biases when deriving
    policy updates from logged implicit feedback. I will also discuss some follow
    up work and outstanding research questions in applying RL, in particular off-policy
    optimization in recommender systems. [33m:16s; with slides]
- - /docs/rl/2016-graves.pdf
  - Hybrid computing using a neural network with dynamic external memory
  - Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka
    Grabska-Barwińska, Sergio Gómez Colmenarejo, Edward Grefenstette, Tiago Ramalho,
    John Agapiou, Adrià Puigdomènech Badia, Karl Moritz Hermann, Yori Zwols, Georg
    Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray
    Kavukcuoglu, Demis Hassabis
  - 2016-10-27
  - 10.1038/nature20101
  - Artificial neural networks are remarkably adept at sensory processing, sequence
    learning and reinforcement learning, but are limited in their ability to represent
    variables and data structures and to store data over long timescales, owing to
    the lack of an external memory. Here we introduce a machine learning model called
    a differentiable neural computer (DNC), which consists of a neural network that
    can read from and write to an external memory matrix, analogous to the random-access
    memory in a conventional computer. Like a conventional computer, it can use its
    memory to represent and manipulate complex data structures, but, like a neural
    network, it can learn to do so from data. When trained with supervised learning,
    we demonstrate that a DNC can successfully answer synthetic questions designed
    to emulate reasoning and inference problems in natural language. We show that
    it can learn tasks such as finding the shortest path between specified points
    and inferring the missing links in randomly generated graphs, and then generalize
    these tasks to specific graphs such as transport networks and family trees. When
    trained with reinforcement learning, a DNC can complete a moving blocks puzzle
    in which changing goals are specified by sequences of symbols. Taken together,
    our results demonstrate that DNCs have the capacity to solve complex, structured
    tasks that are inaccessible to neural networks without external read–write memory.
- - /docs/rl/2016-silver.pdf
  - Mastering the game of Go with deep neural networks and tree search
  - David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George
    van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam,
    Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya
    Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel,
    Demis Hassabis
  - 2016-01-28
  - 10.1038/nature16961
  - The game of Go has long been viewed as the most challenging of classic games for
    artificial intelligence owing to its enormous search space and the difficulty
    of evaluating board positions and moves. Here we introduce a new approach to computer
    Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’
    to select moves. These deep neural networks are trained by a novel combination
    of supervised learning from human expert games, and reinforcement learning from
    games of self-play. Without any lookahead search, the neural networks play Go
    at the level of state-of-the-art Monte Carlo tree search programs that simulate
    thousands of random games of self-play. We also introduce a new search algorithm
    that combines Monte Carlo simulation with value and policy networks. Using this
    search algorithm, our program AlphaGo achieved a 99.8% winning rate against other
    Go programs, and defeated the human European Go champion by 5 games to 0. This
    is the first time that a computer program has defeated a human professional player
    in the full-sized game of Go, a feat previously thought to be at least a decade
    away.
- - https://geneticsexbehavior.info/wp-content/uploads/2019/08/ganna190830.pdf
  - Large-scale GWAS reveals insights into the genetic architecture of same-sex sexual
    behavior
  - Andrea Ganna, Karin J. H. Verweij, Michel G. Nivard, Robert Maier, Robbee Wedow,
    Alexander S. Busch, Abdel Abdellaoui, Shengru Guo, J. Fah Sathirapongsasuti, 23andMe
    Research Team, Paul Lichtenstein, Sebastian Lundström, Niklas Långström, Adam
    Auton, Kathleen Mullan Harris, Gary W. Beecham, Eden R. Martin, Alan R. Sanders,
    John R. B. Perry, Benjamin M. Neale, Brendan P. Zietsch
  - 2019-08-29
  - 10.1126/science.aat7693
  - ! '<p>Twin studies and other analyses of inheritance of sexual orientation in
    humans has indicated that same-sex sexual behavior has a genetic component. Previous
    searches for the specific genes involved have been underpowered and thus unable
    to detect genetic signals. Ganna et al. perform a genome-wide association study
    on 493,001 participants from the United States, the United Kingdom, and Sweden
    to study genes associated with sexual orientation (see the Perspective by Mills).
    They find multiple loci implicated in same-sex sexual behavior indicating that,
    like other behavioral traits, nonheterosexual behavior is polygenic.</p><p><strong>Introduction</strong>:
    Across human societies and in both sexes, some 2 to 10% of individuals report
    engaging in sex with same-sex partners, either exclusively or in addition to sex
    with opposite-sex partners. Twin and family studies have shown that same-sex sexual
    behavior is partly genetically influenced, but previous searches for the specific
    genes involved have been underpowered to detect effect sizes realistic for complex
    traits.</p><p><strong>Rationale</strong>: For the first time, new large-scale
    datasets afford sufficient statistical power to identify genetic variants associated
    with same-sex sexual behavior (ever versus never had a same-sex partner), estimate
    the proportion of variation in the trait accounted for by all variants in aggregate,
    estimate the genetic correlation of same-sex sexual behavior with other traits,
    and probe the biology and complexity of the trait. To these ends, we performed
    genome-wide association discovery analyses on 477,522 individuals from the United
    Kingdom and United States, replication analyses in 15,142 individuals from the
    United States and Sweden, and follow-up analyses using different aspects of sexual
    preference.</p><p><strong>Results</strong>: In the discovery samples (UK Biobank
    and 23andMe), 5 autosomal loci were significantly associated with same-sex sexual
    behavior. Follow-up of these loci suggested links to biological pathways that
    involve sex hormone regulation and olfaction. 3 of the loci were significant in
    a meta-analysis of smaller, independent replication samples. Although only a few
    loci passed the stringent statistical corrections for genome-wide multiple testing
    and were replicated in other samples, our analyses show that many loci underlie
    same-sex sexual behavior in both sexes. In aggregate, all tested genetic variants
    accounted for 8 to 25% of variation in male and female same-sex sexual behavior,
    and the genetic influences were positively but imperfectly correlated between
    the sexes [genetic correlation coefficient (<em>r<sub>g</sub></em>)= 0.63; 95%
    confidence intervals, 0.48 to 0.78]. These aggregate genetic influences partly
    overlapped with those on a variety of other traits, including externalizing behaviors
    such as smoking, cannabis use, risk-taking, and the personality trait “openness
    to experience.” Additional analyses suggested that sexual behavior, attraction,
    identity, and fantasies are influenced by a similar set of genetic variants (<em>r<sub>g</sub></em>
    &gt; 0.83); however, the genetic effects that differentiate heterosexual from
    same-sex sexual behavior are not the same as those that differ among nonheterosexuals
    with lower versus higher proportions of same-sex partners, which suggests that
    there is no single continuum from opposite-sex to same-sex preference.</p><p><strong>Conclusion</strong>:
    Same-sex sexual behavior is influenced by not one or a few genes but many. Overlap
    with genetic influences on other traits provides insights into the underlying
    biology of same-sex sexual behavior, and analysis of different aspects of sexual
    preference underscore its complexity and call into question the validity of bipolar
    continuum measures such as the Kinsey scale. Nevertheless, many uncertainties
    remain to be explored, including how sociocultural influences on sexual preference
    might interact with genetic influences. To help communicate our study to the broader
    public, we organized workshops in which representatives of the public, activists,
    and researchers discussed the rationale, results, and implications of our study.</p>'
- - /docs/ai/2019-gervais.pdf
  - The Machine As Author
  - Daniel J. Gervais
  - 2019-03-24
  - ''
  - ! 'The use of Artificial Intelligence (AI) machines using deep learning neural
    networks to create material that facially looks like it should be protected by
    copyright is growing exponentially. From articles in national news media to music,
    film, poetry and painting, AI machines create material that has economic value
    and that competes with productions of human authors. The Article reviews both
    normative and doctrinal arguments for and against the protection by copyright
    of literary and artistic productions made by AI machines. The Article finds that
    the arguments in favor of protection are flawed and unconvincing and that a proper
    analysis of the history, purpose, and major doctrines of copyright law all lead
    to the conclusion that productions that do not result from human creative choices
    belong to the public domain. The Article proposes a test to determine which productions
    should be protected, including in case of collaboration between human and machine.
    Finally, the Article applies the proposed test to three specific fact patterns
    to illustrate its application. [Keywords: copyright, author, artificial intelligence,
    machine learning]'
- - /docs/anime/2015-saito.pdf
  - ! '<code>Illustration2Vec</code>: a semantic vector representation of illustrations'
  - Saito Masaki, Yusuke Matsui
  - 2015-11-02
  - 10.1145/2820903.2820907
  - ! 'Referring to existing illustrations helps novice drawers to realize their ideas.
    To find such helpful references from a large image collection, we first build
    a semantic vector representation of illustrations by training convolutional neural
    networks. As the proposed vector space correctly reflects the semantic meanings
    of illustrations, users can efficiently search for references with similar attributes.
    Besides the search with a single query, a <em>semantic morphing</em> algorithm
    that searches the intermediate illustrations that gradually connect two queries
    is proposed. Several experiments were conducted to demonstrate the effectiveness
    of our methods. [Keywords: illustration, CNNs, visual similarity, search]'
- - /docs/statistics/decision/1960-kelley.pdf
  - Gradient Theory of Optimal Flight Paths
  - Henry J. Kelley
  - 1960-10-01
  - 10.2514/8.5282
  - An analytical development of flight performance optimization according to the
    method of gradients or 'method of steepest decent' is presented. Construction
    of a minimizing sequence of flight paths by a stepwise process of descent along
    the local gradient direction is described as a computational scheme. Numerical
    application of the technique is illustrated in a simple example of orbital transfer
    via solar sail propulsion. Successive approximations to minimum time planar flight
    paths from Earth's orbit to the orbit of Mars are presented for cases corresponding
    to free and fixed boundary conditions on terminal velocity components.
- - /docs/ai/1962-bryson.pdf
  - A Steepest-Ascent Method for Solving Optimum Programming Problems
  - A. E. Bryson, W. F. Denham
  - 1962-06-01
  - 10.1115/1.3640537
  - ! '<p>A systematic and rapid steepest-ascent numerical procedure is described
    for solving two-point boundary-value problems in the calculus of variations for
    systems governed by a set of nonlinear ordinary differential equations. Numerical
    examples are presented for minimum time-to-climb and maximum altitude paths for
    a supersonic interceptor and maximum-range paths for an orbital glider. [Keywords:
    Boundary-value problems, Computer programming, Differential equations, Variational
    techniques]</p><p>...A systematic and rapid steepest-ascent numerical procedure
    is described for determining optimum programs for nonlinear systems with terminal
    constraints. The procedure uses the concept of local linearization around a nominal
    (non-optimum) path. The effect on the terminal conditions of a small change in
    the control variable program is determined by numerical integration of the adjoint
    differential equations for small perturbations about the nominal path. Having
    these adjoint (or influence) functions, it is then possible to determine the change
    in the control variable program that gives maximum increase in the pay-off function
    for a given mean-square perturbation of the control variable program while simultaneously
    changing the terminal quantities by desired amounts. By repeating this process
    in small steps, a control variable program that minimizes one quantity and yields
    specified values of other terminal quantities can be approached as closely as
    desired. Three numerical examples are presented: (<em>a</em>) The angle-of-attack
    program for a typical supersonic interceptor to climb to altitude in minimum time
    is determined with and without specified terminal velocity and heading. (<em>b</em>)
    The angle-of-attack program for the same interceptor to climb to maximum altitude
    is determined, (<em>c</em>) The angle-of-attack program is determined for a hypersonic
    orbital glider to obtain maximum surface range starting from satellite speed at
    300,000 ft altitude.</p>'
- - /docs/traffic/2015-lewis.pdf
  - The Unfavorable Economics of Measuring the Returns to Advertising
  - Randall A. Lewis, Justin M. Rao
  - 2015-07-06
  - 10.1093/qje/qjv023
  - Twenty-five large field experiments with major U.S. retailers and brokerages,
    most reaching millions of customers and collectively representing $2.8 million
    in digital advertising expenditure, reveal that measuring the returns to advertising
    is difficult. The median confidence interval on return on investment is over 100
    percentage points wide. Detailed sales data show that relative to the per capita
    cost of the advertising, individual-level sales are very volatile; a coefficient
    of variation of 10 is common. Hence, informative advertising experiments can easily
    require more than 10 million person-weeks, making experiments costly and potentially
    infeasible for many firms. Despite these unfavorable economics, randomized control
    trials represent progress by injecting new, unbiased information into the market.
    The inference challenges revealed in the field experiments also show that selection
    bias, due to the targeted nature of advertising, is a crippling concern for widely
    employed observational methods.
- - /docs/sociology/2014-flyvbjerg.pdf
  - ! 'What You Should Know About Megaprojects and Why: An Overview'
  - Bent Flyvbjerg
  - 2014-04-07
  - 10.1002/pmj.21409
  - ! 'This paper takes stock of megaproject management, an emerging and hugely costly
    field of study. First, it answers the question of how large megaprojects are by
    measuring them in the units mega, giga, and tera, concluding we are presently
    entering a new "tera era" of trillion-dollar projects. Second, total global megaproject
    spending is assessed, at USD 6-9 trillion annually, or 8 percent of total global
    GDP, which denotes the biggest investment boom in human history. Third, four "sublimes"
    – political, technological, economic, and aesthetic – are identified to explain
    the increased size and frequency of megaprojects. Fourth, the "iron law of megaprojects"
    is laid out and documented: Over budget, over time, over and over again. Moreover,
    the "break-fix model" of megaproject management is introduced as an explanation
    of the iron law. Fifth, Albert O. Hirschman''s theory of the Hiding Hand is revisited
    and critiqued as unfounded and corrupting for megaproject thinking in both the
    academy and policy. Sixth, it is shown how megaprojects are systematically subject
    to "survival of the unfittest," explaining why the worst projects get built instead
    of the best. Finally, it is argued that the conventional way of managing megaprojects
    has reached a "tension point," where tradition is challenged and reform is emerging.'
- - https://psyarxiv.com/g4x6r/
  - Low Base Rates Prevented Terman from Identifying Future Nobelists
  - Russell Warne, Ross Larsen, Jonathan Clark
  - 2019-08-28
  - 10.31234/osf.io/g4x6r
  - Although the accomplishments of the 1,528 subjects of the Genetic Studies of Genius
    are impressive, they do not represent the pinnacle of human achievement. Since
    the early 1990s, commentators (e.g., Bond, 2014; Gladwell, 2006; Heilman, 2016;
    Shurkin, 1992) have drawn attention to the fact that two future Nobelists—William
    Shockley and Luis Alvarez—were among the 168,000 candidates screened for the study;
    but they were rejected because their IQ scores were too low. Critics see this
    as a flaw of Terman’s methodology and/or intelligence testing. However, events
    with a low base rate (such as winning a Nobel prize) are difficult to predict
    (Taylor & Russell, 1939). This study simulates the Terman’s sampling procedure
    to estimate the probability that Terman’s sampling procedure would have selected
    one or both future Nobelists from a population of 168,000 candidates. Using data
    simulations, we created a model that realistically reflected the test-retest and
    split-half reliability of the IQ scores used to select individuals for the Genetic
    Studies of Genius and the relationship between IQ and Nobelist status. Results
    showed that it was unlikely for Terman to identify children who would later earn
    Nobel prizes, mostly due to the low base rates of such high future achievement
    and the high minimum IQ needed to be selected for Terman’s study. Changes to the
    methodology that would have been required to select one or both Nobelists for
    the longitudinal study were not practical. Therefore, Alvarez’s and Shockley’s
    absence from the Genetic Studies of Genius sample does not invalidate intelligence
    testing or Terman’s landmark study.
- - /docs/genetics/heritable/2015-polderman.pdf
  - Meta-analysis of the heritability of human traits based on fifty years of twin
    studies
  - Tinca J. C. Polderman, Beben Benyamin, Christiaan A. de Leeuw, Patrick F. Sullivan,
    Arjen van Bochoven, Peter M. Visscher, Danielle Posthuma
  - 2015-05-18
  - 10.1038/ng.3285
  - Despite a century of research on complex traits in humans, the relative importance
    and specific nature of the influences of genes and environment on human traits
    remain controversial. We report a meta-analysis of twin correlations and reported
    variance components for 17,804 traits from 2,748 publications including 14,558,903
    partly dependent twin pairs, virtually all published twin studies of complex traits.
    Estimates of heritability cluster strongly within functional domains, and across
    all traits the reported heritability is 49%. For a majority (69%) of traits, the
    observed twin correlations are consistent with a simple and parsimonious model
    where twin resemblance is solely due to additive genetic variation. The data are
    inconsistent with substantial influences from shared environment or non-additive
    genetic variation. This study provides the most comprehensive analysis of the
    causes of individual differences in human traits thus far and will guide future
    gene-mapping efforts. All the results can be visualized using the MaTCH webtool.
- - /docs/genetics/correlation/2016-belsky.pdf
  - ! 'The Genetics of Success: How Single-Nucleotide Polymorphisms Associated With
    Educational Attainment Relate to Life-Course Development'
  - Daniel W. Belsky, Terrie E. Moffitt, David L. Corcoran, Benjamin Domingue, HonaLee
    Harrington, Sean Hogan, Renate Houts, Sandhya Ramrakha, Karen Sugden, Benjamin
    S. Williams, Richie Poulton, Avshalom Caspi
  - 2016-06-01
  - 10.1177/0956797616643070
  - ! 'A previous genome-wide association study (GWAS) of more than 100,000 individuals
    identified molecular-genetic predictors of educational attainment. We undertook
    in-depth life-course investigation of the polygenic score derived from this GWAS
    using the four-decade Dunedin Study (N = 918). There were five main findings.
    First, polygenic scores predicted adult economic outcomes even after accounting
    for educational attainments. Second, genes and environments were correlated: Children
    with higher polygenic scores were born into better-off homes. Third, children’s
    polygenic scores predicted their adult outcomes even when analyses accounted for
    their social-class origins; social-mobility analysis showed that children with
    higher polygenic scores were more upwardly mobile than children with lower scores.
    Fourth, polygenic scores predicted behavior across the life course, from early
    acquisition of speech and reading skills through geographic mobility and mate
    choice and on to financial planning for retirement. Fifth, polygenic-score associations
    were mediated by psychological characteristics, including intelligence, self-control,
    and interpersonal skill. Effect sizes were small. Factors connecting DNA sequence
    with life outcomes may provide targets for interventions to promote population-wide
    positive development. [Keywords: genetics, behavior genetics, intelligence, personality,
    adult development]'
- - /Danbooru2017
  - ! 'Danbooru2017: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset
    [replaced by Danbooru2018]'
  - Gwern Branwen
  - 2015-12-15
  - ''
  - Danbooru2017 was a large-scale anime image database with 2.9m+ images annotated
    with 77.5m+ tags; it can be useful for machine learning purposes such as image
    recognition and generation. It has been replaced by <a href="/Danbooru2018">Danbooru2018</a>,
    an updated and larger dataset.
- - http://www.nature.com/mp/journal/vaop/ncurrent/full/mp2015225a.html
  - Shared genetic aetiology between cognitive functions and physical and mental health
    in UK Biobank (<em>N</em>=112 151) and 24 GWAS consortia
  - S. P. Hagenaars, S. E. Harris, G. Davies, W. D. Hill, D. C. M. Liewald, S. J.
    Ritchie, R. E. Marioni, C. Fawns-Ritchie, B. Cullen, R. Malik, METASTROKE Consortium,
    International Consortium for Blood Pressure GWAS, SpiroMeta Consortium, CHARGE
    Consortium Pulmonary Group, CHARGE Consortium Aging and Longevity Group, B. B.
    Worrall, C. L. M. Sudlow, J. M. Wardlaw, J. Gallacher, J. Pell, A. M. McIntosh,
    D. J. Smith, C. R. Gale, Ian J. Deary
  - 2016-01-26
  - 10.1038/mp.2015.225
  - Causes of the well-documented association between low levels of cognitive functioning
    and many adverse neuropsychiatric outcomes, poorer physical health and earlier
    death remain unknown. We used linkage disequilibrium regression and polygenic
    profile scoring to test for shared genetic aetiology between cognitive functions
    and neuropsychiatric disorders and physical health. Using information provided
    by many published genome-wide association study consortia, we created polygenic
    profile scores for 24 vascular–metabolic, neuropsychiatric, physiological–anthropometric
    and cognitive traits in the participants of UK Biobank, a very large population-based
    sample (<em>N</em>=112 151). Pleiotropy between cognitive and health traits was
    quantified by deriving genetic correlations using summary genome-wide association
    study statistics and to the method of linkage disequilibrium score regression.
    Substantial and significant genetic correlations were observed between cognitive
    test scores in the UK Biobank sample and many of the mental and physical health-related
    traits and disorders assessed here. In addition, highly significant associations
    were observed between the cognitive test scores in the UK Biobank sample and many
    polygenic profile scores, including coronary artery disease, stroke, Alzheimer’s
    disease, schizophrenia, autism, major depressive disorder, body mass index, intracranial
    volume, infant head circumference and childhood cognitive ability. Where disease
    diagnosis was available for UK Biobank participants, we were able to show that
    these results were not confounded by those who had the relevant disease. These
    findings indicate that a substantial level of pleiotropy exists between cognitive
    abilities and many human mental and physical health disorders and traits and that
    it can be used to predict phenotypic variance across samples.
- - /docs/rl/2017-silver.pdf
  - Mastering the game of Go without human knowledge
  - David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang,
    Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen,
    Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel,
    Demis Hassabis
  - 2017-10-19
  - 10.1038/nature24270
  - ! 'A long-standing goal of artificial intelligence is an algorithm that learns,
    tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo
    became the first program to defeat a world champion in the game of Go. The tree
    search in AlphaGo evaluated positions and selected moves using deep neural networks.
    These neural networks were trained by supervised learning from human expert moves,
    and by reinforcement learning from self-play. Here we introduce an algorithm based
    solely on reinforcement learning, without human data, guidance or domain knowledge
    beyond game rules. AlphaGo becomes its own teacher: a neural network is trained
    to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games.
    This neural network improves the strength of the tree search, resulting in higher
    quality move selection and stronger self-play in the next iteration. Starting
    tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning
    100–0 against the previously published, champion-defeating AlphaGo.'
- - /docs/statistics/order/1947-elfving.pdf
  - The Asymptotical Distribution of Range in Samples from a Normal Population
  - G. Elfving
  - '1947'
  - 10.1093/biomet/34.1-2.111
  - ! '<p>Consider a sample of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation
    encoding="application/x-tex">n</annotation></semantics></math> observations,
    taken from an infinite normal population with the mean 0 and the standard deviation
    1. Let <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>a</mi><annotation
    encoding="application/x-tex">a</annotation></semantics></math> be the smallest
    and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation
    encoding="application/x-tex">b</annotation></semantics></math> the greatest
    of the observed values. Then <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mo>=</mo><mi>b</mi><mo>−</mo><mi>a</mi></mrow><annotation
    encoding="application/x-tex">w = b - a</annotation></semantics></math> is the
    <em>range</em> of the sample. For certain statistical purposes knowledge of the
    sampling distribution of range is needed. The distribution function, however,
    involves a rather complicated integral, whose exact calculation is, for <math
    display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>&gt;</mo><mn>2</mn></mrow><annotation
    encoding="application/x-tex">n &gt; 2</annotation></semantics></math>, impossible…it
    seems to be at least of theoretical interest to investigate the asymptotical distribution
    of range for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>→</mo><mi>∞</mi></mrow><annotation
    encoding="application/x-tex">n \rightarrow \\infty</annotation></semantics></math>.
    This is the purpose of the present paper.</p>'
- - /docs/statistics/order/1999-chen.pdf
  - Accurate approximation to the extreme order statistics of Gaussian samples
  - Chien-Chung Chen, Christopher W. Tyler
  - '1999'
  - 10.1080/03610919908813542
  - <p>Evaluation of the integral properties of Gaussian Statistics is problematic
    because the Gaussian function is not analytically integrable. We show that the
    expected value of the greatest order statistics in Gaussian samples (the max distribution)
    can be accurately approximated by the expression Φ<sup>−1</sup>(0.5264<sup>1/<em>n</em></sup>),
    where <em>n</em> is the sample size and Φ<sup>−1</sup> is the inverse of the Gaussian
    cumulative distribution function. The expected value of the least order statistics
    in Gaussian samples (the min distribution) is correspondingly approximated by
    -Φ<sup>-1</sup>(0.5264<sup>1/<em>n</em></sup>). The standard deviation of both
    extreme order distributions can be approximated by the expression 0.5[Φ<sup>-1</sup>(0.8832<sup>1/<em>n</em></sup>)
    - Φ<sup>−1</sup>(0.2142<sup>1/<em>n</em></sup>)]. We also show that the probability
    density function of the extreme order distribution can be well approximated by
    gamma distributions with appropriate parameters. These approximations are accurate,
    computationally efficient, and readily implemented by build-in functions in many
    commercial mathematical software packages such as MATLAB, Mathematica, and Excel.</p>
- - /docs/genetics/selection/2019-lopez.pdf
  - Genomic Evidence for Local Adaptation of Hunter-Gatherers to the African Rainforest
  - Marie Lopez, Jeremy Choin, Martin Sikora, Katherine Siddle, Christine Harmant,
    Helio A. Costa, Martin Silvert, Patrick Mouguiama-Daouda, Jean-Marie Hombert,
    Alain Froment, Sylvie Le Bomin, George H. Perry, Luis B. Barreiro, Carlos D. Bustamante,
    Paul Verdu, Etienne Patin, Lluís Quintana-Murci
  - 2019-08-08
  - 10.1016/j.cub.2019.07.013
  - ! '<p><em>Highlights</em>:</p><ul><li>A strong selective sweep at <em>TRPS1</em>
    occurred in African rainforest hunter-gatherers</li><li>Pleiotropic height genes
    lead to polygenic selection signals for reproductive age</li><li>Pathogen-driven
    selection, mostly viral, has been pervasive among hunter-gatherers</li><li>Post-admixture
    selection has maintained adaptive variation in hunter-gatherers</li></ul><p><em>Summary</em>:
    African rainforests support exceptionally high biodiversity and host the world’s
    largest number of active hunter-gatherers [1, 2, 3]. The genetic history of African
    rainforest hunter-gatherers and neighboring farmers is characterized by an ancient
    divergence more than 100,000 years ago, together with recent population collapses
    and expansions, respectively [4, 5, 6, 7, 8, 9, 10, 11, 12]. While the demographic
    past of rainforest hunter-gatherers has been deeply characterized, important aspects
    of their history of genetic adaptation remain unclear. Here, we investigated how
    these groups have adapted—through classic selective sweeps, polygenic adaptation,
    and selection since admixture—to the challenging rainforest environments. To do
    so, we analyzed a combined dataset of 566 high-coverage exomes, including 266
    newly generated exomes, from 14 populations of rainforest hunter-gatherers and
    farmers, together with 40 newly generated, low-coverage genomes. We find evidence
    for a strong, shared selective sweep among all hunter-gatherer groups in the regulatory
    region of <em>TRPS1</em>—primarily involved in morphological traits. We detect
    strong signals of polygenic adaptation for height and life history traits such
    as reproductive age; however, the latter appear to result from pervasive pleiotropy
    of height-associated genes. Furthermore, polygenic adaptation signals for functions
    related to responses of mast cells to allergens and microbes, the IL-2 signaling
    pathway, and host interactions with viruses support a history of pathogen-driven
    selection in the rainforest. Finally, we find that genes involved in heart and
    bone development and immune responses are enriched in both selection signals and
    local hunter-gatherer ancestry in admixed populations, suggesting that selection
    has maintained adaptive variation in the face of recent gene flow from farmers.
    [Keywords: natural selection, genetic adaptation, rainforest, height, immunity,
    hunter-gatherers, admixture, Africa, positive selection, polygenic adaptation]</p>'
- - /docs/technology/2019-kwong.pdf
  - ! 'Hard Drive of Hearing: Disks that Eavesdrop with a Synthesized Microphone'
  - Andrew Kwong, Wenyuan Xu, Kevin Fu
  - 2019-05-01
  - 10.1109/SP.2019.00008
  - Security conscious individuals may take considerable measures to disable sensors
    in order to protect their privacy. However, they often overlook the cyberphysical
    attack surface exposed by devices that were never designed to be sensors in the
    first place. Our research demonstrates that the mechanical components in magnetic
    hard disk drives behave as microphones with sufficient precision to extract and
    parse human speech. These unintentional microphones sense speech with high enough
    fidelity for the Shazam service to recognize a song recorded through the hard
    drive. This proof of concept attack sheds light on the possibility of invasion
    of privacy even in absence of traditional sensors. We also present defense mechanisms,
    such as the use of ultrasonic aliasing, that can mitigate acoustic eavesdropping
    by synthesized microphones in hard disk drives.
- - https://www.theatlantic.com/magazine/archive/2006/08/nightfall/305030/
  - Nightfall
  - Brad Leithauser
  - 2006-07-31
  - ''
  - <p>In Iceland, in early January,<br/>when dusk begins at dawn,<br/>alone in a
    wind-whipped shack,<br/>I kneel as though cowering<br/>before my little stove
    door.<br/>Nights are immense, and my coal is black<br/>as night.</p><p>A geologist<br/>in
    his lab might be able to say,<br/>within a million years or so, just<br/>when
    and where the coal’s towering<br/>source-plants were laid down;<br/>I only know,
    while waiting for<br/>the room to warm, it was very<br/>long ago, and far away.</p>
- - https://www.newcriterion.com/issues/2006/10/a-good-list
  - A good list
  - Brad Leithauser
  - 2006-10-01
  - ''
  - <p>Some nights, can’t sleep, I draw up a list,<br/>Of everything I’ve never done
    wrong.<br/>To look at me now, you might insist<br/>My list could hardly be long,<br/>But
    I’ve stolen no gnomes from my neighbor’s yard,<br/>Or struck his dog, backing
    out my car.<br/>Never ate my way up and down the Loire<br/>On a stranger’s credit
    card.<br/></p><p>I’ve never given a cop the slip,<br/>Stuffed stiffs in a gravel
    quarry,<br/>Or silenced Cub Scouts on a first camping trip<br/>With an unspeakable
    ghost story.<br/>Never lifted a vase from a museum foyer,<br/>Or rifled a Turkish
    tourist’s backpack.<br/>Never cheated at golf. Or slipped out a blackjack<br/>And
    flattened a patent lawyer.<br/></p><p>I never forged a lottery ticket,<br/>Took
    three on a two-for-one pass,<br/>Or, as a child, toasted a cricket<br/>With a
    magnifying glass.<br/>I never said “air” to mean “err,” or obstructed<br/>Justice,
    or defrauded a securities firm.<br/>Never mulcted—so far as I understand the term.<br/>Or
    unjustly usufructed.<br/></p><p>I never swindled a widow of all her stuff<br/>By
    means of a false deed and title<br/>Or stood up and shouted, <em>My God, that’s
    enough!</em><br/>At a nephew’s piano recital.<br/>Never practiced arson, even
    as a prank,<br/>Brightened church-suppers with off-color jokes,<br/>Concocted
    an archaeological hoax—<br/>Or dumped bleach in a goldfish tank.<br/></p><p>Never
    smoked opium. Or smuggled gold<br/>Across the Panamanian Isthmus.<br/>Never hauled
    back and knocked a rival out cold,<br/>Or missed a family Christmas.<br/>Never
    borrowed a book I <em>intended</em> to keep.<br/>… My list, once started, continues
    to grow,<br/>Which is all for the good, but just goes to show<br/>It’s the good
    who do not sleep.</p>
- - /docs/psychology/2018-brouwers.pdf
  - ! 'Pristine inner experience while silent reading: It’s <em>not</em> silent speaking
    of the text'
  - Vincent P. Brouwers, Christopher L. Heavey, Leiszle Lapping-Carr, Stefanie Moynihan,
    Jason Kelsey, Russell T. Hurlburt
  - 2018-01-01
  - ''
  - ! '<p>We used Descriptive Experience Sampling to explore the pristine inner experience
    of 16 college students while reading Fitzgerald and Hemingway short stories. We
    provide rich descriptions of the phenomena while reading. Visual imagery was frequent.
    Although many theorists presume the ubiquitous presence of an inner voice that
    narrates the text as it is read, we found that only about 3% of samples involved
    such inner narration. Words were experienced during about a quarter of all samples,
    including: a focus on specific words from the text (but which were not merely
    inner reading), words innerly spoken in response to the text (content was related
    to the text but not of the text itself), and innerly spoken unrelated words (apparently
    not connected to the text). We suggest that presuppositions account for others''
    overestimation of silent speech frequency, and discuss the impact of these findings
    on understanding reading and consciousness science.</p><p>[Keywords: Descriptive
    Experience Sampling; inner speaking; inner speech; iterative method; phenomenology;
    pristine inner experience; reading; silent reading]</p>'
- - /docs/psychology/2019-famira.pdf
  - ! 'Using a Thought Listing Procedure to Construct the General Inner Speech Questionnaire:
    An Ecological Approach'
  - Racy Famira, Morin Alain, Duhnych Christina
  - 2019-07-09
  - 10.1080/10720537.2019.1633572
  - ! 'The construction of existing self-report measures of inner speech is guided
    by a priori theoretical views regarding how it is experienced or what functions
    it serves. We present two studies aimed at constructing and validating a more
    ecologically valid tool called the General Inner Speech Questionnaire (GISQ).
    Study 1 employed an open-format thought-listing procedure inviting 227 participants
    to freely recall what they talk to themselves about in general. The most frequently
    self-generated inner speech instances were about negative emotions, problem solving/thinking,
    planning, self-motivating, emotional control, and self. In Study 2, we used this
    inner speech content to construct the 57-item GISQ. The GISQ is normally distributed,
    shows acceptable internal consistency, and contains four moderately strong factors:
    self-reflection, self-observation, cognition, and inner speech accompanying activities.
    Importantly, the GISQ correlates positively with other measures of inner speech
    and self-related process.'
- - /newsletter/2019/07#evangelion-3.0
  - ! 'Review: <em>Rebuild 3.0</em> (<em>Evangelion: 3.0 You Can (Not) Redo</em>)'
  - Gwern Branwen
  - 2019-07-31
  - ''
  - ! '[Review of the third <em>Rebuild</em> film. The long-delayed tetralogy, which
    now stretches over a decade of production, shows a lack of artistic vision or
    interest by anyone at Studio Khara, particularly director Hideaki Anno. It appears
    now to be a naked cash grab for launching a new studio with a guaranteed moneymaker.
    <em>3.0</em>, the last chance for <em>Rebuild</em> to redeem itself and deliver
    a satisfying whole, wastes its time with irrelevancies and fails to deliver on
    anything promised by Anno and Khara, lazily embracing the worst parts of the Evangelion
    style while destroying much of what was good about characters like Kaworu. It
    is the worst Evangelion film ever made, and so bad that it has largely destroyed
    my interest in the franchise.]'
- - https://wiki.evageeks.org/Episode_06
  - ! 'NGE TV, Episode 6: "Showdown in Tokyo-3"/"Rei-3"'
  - EvaGeeks EvaWiki
  - ''
  - ''
  - Continuing from the previous episode, the Angel Ramiel is drilling down into the
    GeoFront to attack Nerv HQ directly. After Shinji barely survived a direct confrontation
    with it, Misato devises a plan to have Eva-00 and Eva-01 defeat the Angel by sniping
    it from a distance using a positron rifle which requires the total electric output
    of Japan to power up...Misato codenames the plan she creates to defeat the Angel
    Ramiel as "Operation Yashima". This is named after the <a href="https://en.wikipedia.org/wiki/Battle_of_Yashima">Battle
    of Yashima</a> which occurred in 1185 in medieval Japan, which also included a
    feat of conspicuously talented archery.
- - http://www.animenewsservice.com/archives-dec13/
  - ! '12-11-99: Japan Maritime Self-Defence Force Series Supervised By Hideaki Anno'
  - J-Dream Direct Newsletter, J-Dream Web
  - 1999-12-20
  - ''
  - ! 'The filming of Japan Self-Defense Force equipment and training, supervised
    by Gainax director, Hideaki Anno (Evangelion), is being released in Japan on LD
    and DVD. The first volume: “JUSDF FLEET POWER1 -Yokosuka- Japan Maritime Self-Defense
    Force” went on sale on Nov. 25th. The first volume includes scenes of carrier-based
    aircraft and asroc shooting and retails for 5800 Yen.'
- - /otaku#karekano-research
  - Please Listen To Me, Mr. Anno! Anno Hideaki X Highschool Boys & Girls [excerpts]
  - Hideaki Anno et al
  - '1998'
  - ''
  - In 1998, Hideaki Anno, prior to production of <em><a href="https://en.wikipedia.org/wiki/Kare_Kano">His
    and Her Circumstances</a></em>, engaged in a series of dialogues with students
    in several high schools (Toyoko Academy High School/Fujimi High School/Kanagawa
    Prefectural Ikuta High School/The Meiji University Associated Junior-High and
    High Schools of Nakano and Hachioji/Tokyo Toyama Public High School/Tokyo Nishi
    Public High School), which were published by the <em>Mainichi Intermediate-School
    News</em> and eventually translated & republished on the Gainax website. The dialogues
    are interesting because of the wide range of material discussed like contemporary
    politics.
- - https://www.newscientist.com/article/2208777-exclusive-five-couples-lined-up-for-crispr-babies-to-avoid-deafness/
  - ! 'Exclusive: Five couples lined up for CRISPR babies to avoid deafness'
  - Michael Le Page
  - 2019-07-04
  - ''
  - Five Russian couples who are deaf want to try the CRISPR gene-editing technique
    so they can have a biological child who can hear, biologist Denis Rebrikov has
    told New Scientist. He plans to apply to the relevant Russian authorities for
    permission in “a couple of weeks”...Both would-be parents in each couple have
    a recessive form of deafness, meaning that all their children would normally inherit
    the same condition. While the vast majority of genetic diseases can be prevented
    by screening IVF embryos before implantation, with no need for gene-editing, this
    is not an option for these couples. Several reports have suggested that—if it
    can be done safely—editing the genes of babies might be justified in this kind
    of situation...Now Rebrikov has told New Scientist that he also wants to prevent
    children inheriting a form of deafness caused by mutations in the GJB2 gene. In
    western Siberia, many people have a missing DNA letter in position 35 of the GJB2
    gene. Having one copy has no effect, but those who inherit this mutation from
    both parents never develop the ability to hear. Rebrikov has found five couples
    in which both would-be parents are deaf because of this mutation and don’t want
    their children to be deaf too. So he plans to use CRISPR to correct this mutation
    in IVF embryos from these couples. All these embryos will have the mutation in
    both copies of the GJB2 gene—correcting one copy using a method known as homology-directed
    repair will prevent deafness. “Technically, it is achievable,” says Burgio.
- - /docs/economics/2019-mckenzie.pdf
  - ! 'Predicting entrepreneurial success is hard: Evidence from a business plan competition
    in Nigeria'
  - David McKenzie, Dario Sansone
  - 2019-11-01
  - 10.1016/j.jdeveco.2019.07.002
  - ! 'We compare the absolute and relative performance of three approaches to predicting
    outcomes for entrants in a business plan competition in Nigeria: Business plan
    scores from judges, simple ad-hoc prediction models used by researchers, and machine
    learning approaches. We find that (i) business plan scores from judges are uncorrelated
    with business survival, employment, sales, or profits three years later; (ii)
    a few key characteristics of entrepreneurs such as gender, age, ability, and business
    sector do have some predictive power for future outcomes; (iii) modern machine
    learning methods do not offer noticeable improvements; (iv) the overall predictive
    power of all approaches is very low, highlighting the fundamental difficulty of
    picking competition winners.'
- - https://www.nonstopsystems.com/radio/pdf-hell/article-hell-patents-plunder.pdf
  - Secrets by the thousands
  - Charles Lester Walker (Harper's Magazine)
  - 1946-10-01
  - ''
  - ! '<p>Someone wrote to Wright Field recently, saying he understood this country
    had got together quite a collection of enemy war secrets, that many were now on
    public sale, and could he, please, be sent everything on German jet engines. The
    Air Documents Division of the Army Air Forces answered: “Sorry–but that would
    be fifty tons”. Moreover, that fifty tons was just a small portion of what is
    today undoubtedly the biggest collection of captured enemy war secrets ever assembled.
    ..It is estimated that over a million separate items must be handled, and that
    they, very likely, practically all the scientific, industrial and military secrets
    of Nazi Germany. One Washington official has called it “the greatest single source
    of this type of material in the world, the first orderly exploitation of an entire
    country’s brain-power.”</p><p>What did we find? You’d like some outstanding examples
    from the war secrets collection?</p><p>…the tiniest vacuum tube I had ever seen.
    It was about half thumb-size. Notice it is heavy porcelain—not glass—and thus
    virtually indestructible. It is a thousand watt—one-tenth the size of similar
    American tubes…“That’s Magnetophone tape,” he said. “It’s plastic, metallized
    on one side with iron oxide. In Germany that supplanted phonograph recordings.
    A day’s Radio program can be magnetized on one reel. You can demagnetize it, wipe
    it off and put a new program on at any time. No needle; so absolutely no noise
    or record wear. An hour-long reel costs fifty cents.”…He showed me then what had
    been two of the most closely-guarded, technical secrets of the war: the infra-red
    device which the Germans invented for seeing at night, and the remarkable diminutive
    generator which operated it. German cars could drive at any, speed in a total
    blackout, seeing objects clear as day two hundred meters ahead. Tanks with this
    device could spot; targets two miles away. As a sniper scope it enabled German
    riflemen to pick off a man in total blackness…We got, in addition, among these
    prize secrets, the technique and the machine for making the world’s most remarkable
    electric condenser…The Kaiser Wilhelm Institute for Silicate Research had discovered
    how to make it and—something which had always eluded scientists—in large sheets.
    We know now, thanks to FIAT teams, that ingredients of natural mica were melted
    in crucibles of carbon capable of taking 2,350 degrees of heat, and then—this
    was the real secret—cooled in a special way…“This is done on a press in one operation.
    It is called the ‘cold extrusion’ process. We do it with some soft, splattery
    metals. But by this process the Germans do it with cold steel! Thousands of parts
    now made as castings or drop forgings or from malleable iron can now be made this
    way. The production speed increase is a little matter of one thousand per cent.”
    This one war secret alone, many American steel men believe, will revolutionize
    dozens of our metal fabrication industries.</p><p>…In textiles the war secrets
    collection has produced so many revelations, that American textile men are a little
    dizzy.But of all the industrial secrets, perhaps, the biggest windfall came from
    the laboratories and plants of the great German cartel, I. G. Farbenindustrie.
    Never before, it is claimed, was there such a store-house of secret information.
    It covers liquid and solid fuels, metallurgy, synthetic rubber, textiles, chemicals,
    plastics. drugs, dyes. One American dye authority declares: “It includes the production
    know-how and the secret formulas for over fifty thousand dyes. Many of them are
    faster and better than ours. Many are colors we were never able to make. The American
    dye industry will be advanced at least ten years.”</p><p>…Milk pasteurization
    by ultra-violet light…how to enrich the milk with vitamin D…cheese was being made—“good
    quality Hollander and Tilsiter”—by a new method at unheard-of speed…a continuous
    butter making machine…The finished product served as both animal and human food.
    Its caloric value is four times that of lean meat, and it contains twice as much
    protein. The Germans also had developed new methods of preserving food by plastics
    and new, advanced refrigeration techniques…German medical researchers had discovered
    a way to produce synthetic blood plasma.</p><p>…When the war ended, we now know,
    they had 138 types of guided missiles in various stages of production or development,
    using every known kind of remote control and fuse: radio, radar, wire, continuous
    wave, acoustics, infra-red, light beams, and magnetics, to name some; and for
    power, all methods of jet propulsion for either subsonic or supersonic speeds.
    Jet propulsion had even been applied to helicopter flight…Army Air Force experts
    declare publicly that in rocket power and guided missiles the Nazis were ahead
    of us by at least ten years.</p>'
- - /docs/statistics/order/beanmachine-multistage/index.html
  - ! 'Multi-Stage Bean Machine Visualization: Advantages of Repeated Optimization'
  - Rafe Kennedy, Gwern Branwen
  - 2018-12-17
  - ''
  - ! '<p>An interactive JavaScript of order statistics visualized as a Galton bean
    machine, showing difference in means & maxima between single stage of selection
    and multiple stages.</p><p>This is an interactive JS-based visualization of the
    difference in optimization potentials of a single-stage pipeline vs a multi-stage
    pipeline, in which new samples/measurements can be generated at each step (such
    as in evolutionary processes).</p><p>Because it optimizes over multiple steps,
    the multi-stage pipeline “ratchets upward” and can attain far more extreme maxima
    than a single-stage pipeline, even with the same total number of samples&mdash;the
    single-stage process quickly hits “diminishing returns”, where large increases
    in sample count result in only small increases in the expected maximum. This means
    that small gains per stage, or a few stages, or a few generations of evolution,
    can result in large increases of sample means, compared to a single-stage process.
    Due to <a href="https://en.wikipedia.org/wiki/Order_statistic">order statistics</a>,
    the increases in means can cause larger increases in the probability of samples
    passing thresholds such as “top 1%”/≥2.32σ, or yielding extremes. And the more
    stages, the greater differences can be (single-stage selection increases logarithmically,
    while multi-stage increases linearly).</p><p>These increases can be counterintuitively
    large, but the gains/losses are relevant to understanding many processes, such
    as the clinical drug discovery pipeline (eg <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0147215"
    title="When Quality Beats Quantity: Decision Theory, Drug Discovery, and the Reproducibility
    Crisis">Scannell &amp; Bosley 2016</a>).</p><p>The visualization metaphor here
    is <a href="https://en.wikipedia.org/wiki/Bean_machine">Francis Galton’s <em>quincunx</em>
    or “bean machine”</a>: a ball (sample) falls from the top (zero-mean), and is
    affected by sets of pins (stochastic variables) which bounce the ball left/right
    with 50-50 probability (increase/decrease it) as it falls to the bottom (final
    total). The resulting binomial distribution approximates a normal distribution.
    The bean machine visually &amp; concretely illustrates the sampling distribution
    of how a normally-distributed final variable can emerge out of the sum of many
    individual small discrete effects, without requiring any mathematics.</p><p>In
    this visualization, we generalize Galton’s “bean machine” by allowing stacking
    of bean machines. To stack bean machines, we select the ball which is the <em>maximum</em>
    within each sample. How large is it? In the single-stage bean machine, selection
    stops there. In the multi-stage bean machine, <em>another</em> bean machine begins
    with the maximum serving as the seed &amp; new average, and another round of generation
    &amp; selection begins, and so on, until a final sample is selected, and we can
    see how large it is. The gains turn out to be larger the more samples we use total,
    unsurprisingly, but also the more stages we specify; the maximum possible maximum
    turns out to be when we have so many stages that there are just 2 samples per
    stage.</p><p><img style="border: 1px solid #666;" alt="Screenshot of the multi-stage
    bean machine, showing selection in progress in a 3x3 pipeline" width="300" src="/docs/statistics/order/beanmachine-multistage/beanmachine-demo.pngbeanmachine-demo.png"
    title="Multi-Stage Bean Machine"></p>'
- - /docs/cs/1982-perlis.pdf
  - Epigrams on Programming
  - Alan J. Perlis
  - 1982-09-1
  - 10.1145/947955.1083808
  - ! '<p>[130 epigrams on computer science and technology, published in 1982, for
    ACM''s SIGPLAN journal, by noted computer scientist and programming language researcher
    <a href="https://en.wikipedia.org/wiki/Alan_Perlis">Alan Perlis</a>.The epigrams
    are a series of short, programming-language-neutral, humorous statements about
    computers and programming, distilling lessons he had learned over his career,
    which are widely quoted.]</p><p>8. A programming language is low level when its
    programs require attention to the irrelevant. 19. A language that doesn’t affect
    the way you think about programming, is not worth knowing. 54. Beware of the Turing
    tar-pit in which everything is possible but nothing of interest is easy.</p><p>15.
    Everything should be built top-down, except the first time. 30. In programming,
    everything we do is a special case of something more general—and often we know
    it too quickly. 31. Simplicity does not precede complexity, but follows it. 58.
    Fools ignore complexity. Pragmatists suffer it. Some can avoid it. Geniuses remove
    it. 65. Make no mistake about it: Computers process numbers—not symbols. We measure
    our understanding (and control) by the extent to which we can arithmetize an activity.
    56. Software is under a constant tension. Being symbolic it is arbitrarily perfectible;
    but also it is arbitrarily changeable.</p><p>1. One man’s constant is another
    man’s variable. 34. The string is a stark data structure and everywhere it is
    passed there is much duplication of process. It is a perfect vehicle for hiding
    information.</p><p>36. The use of a program to prove the 4-color theorem will
    not change mathematics—it merely demonstrates that the theorem, a challenge for
    a century, is probably not important to mathematics.</p><p>39. Re graphics: A
    picture is worth 10K words—but only those to describe the picture. Hardly any
    sets of 10K words can be adequately described with pictures.</p><p>48. The best
    book on programming for the layman is <em>Alice in Wonderland</em>; but that’s
    because it’s the best book on anything for the layman.</p><p>77. The cybernetic
    exchange between man, computer and algorithm is like a game of musical chairs:
    The frantic search for balance always leaves one of the 3 standing ill at ease.
    79. A year spent in artificial intelligence is enough to make one believe in God.
    84. Motto for a research laboratory: What we work on today, others will first
    think of tomorrow.</p><p>91. The computer reminds one of Lon Chaney—it is the
    machine of a thousand faces.</p><p>7. It is easier to write an incorrect program
    than understand a correct one. 93. When someone says “I want a programming language
    in which I need only say what I wish done,” give him a lollipop. 102. One can’t
    proceed from the informal to the formal by formal means.</p><p>100. We will never
    run out of things to program as long as there is a single program around.</p><p>108.
    Whenever 2 programmers meet to criticize their programs, both are silent. 112.
    Computer Science is embarrassed by the computer. 115. Most people find the concept
    of programming obvious, but the doing impossible. 116. You think you know when
    you can learn, are more sure when you can write, even more when you can teach,
    but certain when you can program. 117. It goes against the grain of modern education
    to teach children to program. What fun is there in making plans, acquiring discipline
    in organizing thoughts, devoting attention to detail and learning to be self-critical?</p>'
- - /docs/japanese/1997-carter-shotetsu-unforgottendreams.pdf
  - ! 'Unforgotten Dreams: Poems by the Zen Monk Shōtetsu'
  - Shōtetsu, Steven D. Carter (translator)
  - '1997'
  - ''
  - ! '<p>[This volume presents translations of over 200 poems by Shōtetsu, who is
    generally considered to be the last great poet of the <em>uta</em> form. Includes
    an introduction, a glossary of important names and places and a list of sources
    of the poems.]</p><p>The Zen monk Shōtetsu (1381–1459) suffered several rather
    serious misfortunes in his life: he lost all the poems of his first thirty years—more
    than 30,000 of them—in a fire; his estate revenues were confiscated by an angry
    shogun; and rivals refused to allow his work to appear in the only imperially
    commissioned poetry anthology of his time. Undeterred by these obstacles, he still
    managed to make a living from his poetry and won recognition as a true master,
    widely considered to be the last great poet of the classical <em>uta</em>, or
    <em>waka</em>, tradition. Shōtetsu viewed his poetry as both a professional and
    religious calling, and his extraordinarily prolific corpus comprised more than
    11,000 poems—the single largest body of work in the Japanese canon.</p><p>The
    first major collection of Shōtetsu''s work in English, <em>Unforgotten Dreams</em>
    presents beautifully rendered translations of more than two hundred poems. The
    book opens with Steven Carter''s generous introduction on Shōtetsu''s life and
    work and his significance in Japanese literature, and includes a glossary of important
    names and places and a list of sources of the poems. Revealing as never before
    the enduring creative spirit of one of Japan''s greatest poets, this fine collection
    fills a major gap in the English translations of medieval Japanese literature.</p>'
- - /docs/iq/smpy/2016-makel.pdf
  - When Lightning Strikes Twice
  - Matthew C. Makel, Harrison J. Kell, David Lubinski, Martha Putallaz, Camilla P.
    Benbow
  - 2016-07-01
  - 10.1177/0956797616644735
  - ! 'The educational, occupational, and creative accomplishments of the profoundly
    gifted participants (IQs ⩾ 160) in the Study of Mathematically Precocious Youth
    (SMPY) are astounding, but are they representative of equally able 12-year-olds?
    Duke University’s Talent Identification Program (TIP) identified 259 young adolescents
    who were equally gifted. By age 40, their life accomplishments also were extraordinary:
    Thirty-seven percent had earned doctorates, 7.5% had achieved academic tenure
    (4.3% at research-intensive universities), and 9% held patents; many were high-level
    leaders in major organizations. As was the case for the SMPY sample before them,
    differential ability strengths predicted their contrasting and eventual developmental
    trajectories—even though essentially all participants possessed both mathematical
    and verbal reasoning abilities far superior to those of typical Ph.D. recipients.
    Individuals, even profoundly gifted ones, primarily do what they are best at.
    Differences in ability patterns, like differences in interests, guide development
    along different paths, but ability level, coupled with commitment, determines
    whether and the extent to which noteworthy accomplishments are reached if opportunity
    presents itself. [Keywords intelligence, creativity, giftedness, replication,
    blink comparator]'
- - /docs/psychology/1993-lipsey.pdf
  - ! 'The Efficacy of Psychological, Educational, and Behavioral Treatment: Confirmation
    from Meta-Analysis'
  - Mark W. Lipsey, David B. Wilson
  - 1993-12-01
  - 10.1037/0003-066x.48.12.1181
  - Conventional reviews of research on the efficacy of psychological, educational,
    and behavioral treatments often find considerable variation in outcome among studies
    and, as a consequence, fail to reach firm conclusions about the overall effectiveness
    of the interventions in question. In contrast, meta-analysis reviews show a strong,
    dramatic pattern of positive overall effects that cannot readily be explained
    as artifacts of meta-analytic technique or generalized placebo effects. Moreover,
    the effects are not so small that they can be dismissed as lacking practical or
    clinical significance. Although meta-analysis has limitations, there are good
    reasons to believe that its results are more credible than those of conventional
    reviews and to conclude that well-developed psychological, educational, and behavioral
    treatment is generally efficacious.
- - /docs/iq/2015-hofman.pdf
  - ! 'Evolution of the Human Brain: From Matter to Mind'
  - Michel A. Hofman
  - '2015'
  - 10.1007/978-1-4939-1562-0_5
  - ! 'Design principles and operational modes are explored that underlie the information
    processing capacity of the human brain. The hypothesis is put forward that in
    higher organisms, especially in primates, the complexity of the neural circuitry
    of the cerebral cortex is the neural correlate of the brain’s coherence and predictive
    power, and, thus, a measure of intelligence. It will be argued that with the evolution
    of the human brain we have nearly reached the limits of biological intelligence.
    [Keywords: Biological intelligence, Cognition, Consciousness, Cerebral cortex,
    Primates, Information processing, Neural networks, Cortical design, Human brain
    evolution]'
- - /docs/catnip/2011-villani.pdf
  - Heritability and Characteristics of Catnip Response in Two Domestic Cat Populations
  - Natalie Adele Villani
  - '2011'
  - ''
  - The domestic cat response to catnip is unique in nature as it represents a repeatable,
    recognizable behavioral response to an olfactory stimulus that appears to have
    little evolutionary significance. There is clear variation in response between
    cats and this has been attributed to genetic factors in the past. These factors
    are explored in this study using behavioral observation after presenting of catnip
    to cats in two different research colonies with different environmental and genetic
    backgrounds. The response trait is defined and Gibbs sampling methods are used
    to explore a mixed model for the trait to determine genetic effects. Heritabilities
    obtained in the two colonies for the most significant response behaviors, the
    head over roll and cheek rub, were 0.511 and 0.794 using catnip spray and dried
    catnip respectively. No clear Mendelian mode of inheritance was ascertained in
    either colony. The variation in response behaviors and intensity seen in the two
    colonies reflects the complex nature of expression of the catnip response, but
    there is a clear genetic influence on the feline predisposition to responding.
- - /docs/statistics/causality/2019-gordon.pdf
  - ! 'A Comparison of Approaches to Advertising Measurement: Evidence from Big Field
    Experiments at Facebook'
  - Brett R. Gordon, Florian Zettelmeyer, Neha Bhargava, Dan Chapsky
  - 2019-05-04
  - 10.1287/mksc.2018.1135
  - Measuring the causal effects of digital advertising remains challenging despite
    the availability of granular data. Unobservable factors make exposure endogenous,
    and advertising’s effect on outcomes tends to be small. In principle, these concerns
    could be addressed using randomized controlled trials (RCTs). In practice, few
    online ad campaigns rely on RCTs and instead use observational methods to estimate
    ad effects. We assess empirically whether the variation in data typically available
    in the advertising industry enables observational methods to recover the causal
    effects of online advertising. Using data from 15 U.S. advertising experiments
    at Facebook comprising 500 million user-experiment observations and 1.6 billion
    ad impressions, we contrast the experimental results to those obtained from multiple
    observational models. The observational methods often fail to produce the same
    effects as the randomized experiments, even after conditioning on extensive demographic
    and behavioral variables. In our setting, advances in causal inference methods
    do not allow us to isolate the exogenous variation needed to estimate the treatment
    effects. We also characterize the incremental explanatory power our data would
    require to enable observational methods to successfully measure advertising effects.
    Our findings suggest that commonly used observational approaches based on the
    data usually available in the industry often fail to accurately measure the true
    effect of advertising.
- - /docs/math/1979-demillo.pdf
  - Social Processes and Proofs of Theorems and Programs
  - Richard A. De Millo, Richard J. Lipton, Alan J. Perlis
  - '1979'
  - 10.1145/359104.359106
  - Many people have argued that computer programming should strive to become more
    like mathematics. Maybe so, but not in the way they seem to think. The aim of
    program verification, an attempt to make programming more mathematics-like, is
    to increase dramatically one’s confidence in the correct functioning of a piece
    of software, and the device that verifiers use to achieve this goal is a long
    chain of formal, deductive logic. In mathematics, the aim is to increase one’s
    confidence in the correctness of a theorem, and it’s true that one of the devices
    mathematicians could in theory use to achieve this goal is a long chain of formal
    logic. But in fact they don’t. What they use is a proof, a very different animal.
    Nor does the proof settle the matter; contrary to what its name suggests, a proof
    is only one step in the direction of confidence. We believe that, in the end,
    it is a social process that determines whether mathematicians feel confident about
    a theorem—and we believe that, because no comparable social process can take place
    among program verifiers, program verification is bound to fail. We can’t see how
    it’s going to be able to affect anyone’s confidence about programs.
- - https://www.esquire.com/news-politics/a5609/chimpanzee-attack-0409/
  - ! 'The Worst Story I Ever Heard: The Davises are like any other family, only instead
    of a son, they raised a chimpanzee. As with Travis, the chimp that attacked a
    woman who''s finally speaking out, for years everything seemed fine. Then something
    strange and horrifying happened—though not necessarily what you''d think'
  - Rich Schapiro
  - 2009-11-11
  - ''
  - ! '[The story of a couple who raised a chimpanzee (Moe) as their surrogate son.
    After many years, Moe was taken away from them because he bit another person.
    They visited Moe in the sanctuary which also sheltered other chimps. One day they
    brought Moe a birthday cake, and the other chimps were watching Moe eat the cake.
    Those others were out of their cage for some reason. They viciously attacked and
    mauled the man, biting off his face and genitals before they could be stopped,
    and didn’t even go for the cake.]'
- - https://www.nature.com/articles/s42003-019-0558-4
  - Social and non-social autism symptoms and trait domains are genetically dissociable
  - Varun Warrier, Roberto Toro, Hyejung Won, Claire S. Leblond, Freddy Cliquet, Richard
    Delorme, Ward De Witte, Janita Bralten, Bhismadev Chakrabarti, Anders D. Børglum,
    Jakob Grove, Geert Poelmans, David A. Hinds, Thomas Bourgeron, Simon Baron-Cohen
  - 2019-09-03
  - 10.1038/s42003-019-0558-4
  - The core diagnostic criteria for autism comprise two symptom domains – social
    and communication difficulties, and unusually repetitive and restricted behaviour,
    interests and activities. There is some evidence to suggest that these two domains
    are dissociable, though this hypothesis has not yet been tested using molecular
    genetics. We test this using a genome-wide association study (N = 51,564) of a
    non-social trait related to autism, systemising, defined as the drive to analyse
    and build systems. We demonstrate that systemising is heritable and genetically
    correlated with autism. In contrast, we do not identify significant genetic correlations
    between social autistic traits and systemising. Supporting this, polygenic scores
    for systemising are significantly and positively associated with restricted and
    repetitive behaviour but not with social difficulties in autistic individuals.
    These findings strongly suggest that the two core domains of autism are genetically
    dissociable, and point at how to fractionate the genetics of autism.
- - /Embryo-selection#sperm-phenotype-selection
  - Sperm Phenotype Selection
  - Gwern Branwen
  - 2019-08-17
  - ''
  - <p>Sperm can be selected on traits such as mobility, which are measures of quality.
    These may be correlated with genetics for adult traits, and one can select from
    billions of sperm. Estimating the gain, it is probably worthwhile but small.</p><p>A
    possible adjunct to embryo selection is sperm selection. Non-destructive sequencing
    is not yet possible, but measuring phenotypic correlates of genetic quality (such
    as sperm speed/motility) is. These correlations of sperm quality/genetic quality
    are, however, small and confounded in current studies by between-individual variation.
    Optimistically, the gain from such sperm selection is probably small, <0.1SD,
    and there do not appear to be any easy ways to boost this effect. Sperm selection
    is probably cost-effective and a good enhancement of existing IVF practices, but
    not particularly notable.</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.174.621&rep=rep1&type=pdf
  - Intelligence and semen quality are positively correlated
  - Rosalind Arden, Linda S. Gottfredson, Geoffrey Miller, Arand Pierce
  - '2008'
  - 10.1016/j.intell.2008.11.001
  - ! 'Human cognitive abilities intercorrelate to form a positive matrix, from which
    a large first factor, called ‘Spearman''s <em>g</em>’ or general intelligence,
    can be extracted. General intelligence itself is correlated with many important
    health outcomes including cardiovascular function and longevity. However, the
    important evolutionary question of whether intelligence is a fitness-related trait
    has not been tested directly, let alone answered. If the correlations among cognitive
    abilities are part of a larger matrix of positive associations among fitness-related
    traits, then intelligence ought to correlate with seemingly unrelated traits that
    affect fitness—such as semen quality. We found significant positive correlations
    between intelligence and 3 key indices of semen quality: log sperm concentration
    (<em>r</em>=.15, <em>p</em>=.002), log sperm count (<em>r</em>=.19, <em>p</em>&lt;.001),
    and sperm motility (<em>r</em>=.14, <em>p</em>=.002) in a large sample of US Army
    Veterans. None was mediated by age, body mass index, days of sexual abstinence,
    service in Vietnam, or use of alcohol, tobacco, marijuana, or hard drugs. These
    results suggest that a phenotype-wide fitness factor may contribute to the association
    between intelligence and health. Clarifying whether a fitness factor exists is
    important theoretically for understanding the genomic architecture of fitness-related
    traits, and practically for understanding patterns of human physical and psychological
    health.'
- - https://rbej.biomedcentral.com/articles/10.1186/s12958-015-0029-9
  - Infertility etiologies are genetically and clinically linked with other diseases
    in single meta-diseases
  - Juan J. Tarín, Miguel A. García-Pérez, Toshio Hamatani, Antonio Cano
  - 2015-05-15
  - 10.1186/s12958-015-0029-9
  - ! 'The present review aims to ascertain whether different infertility etiologies
    share particular genes and/or molecular pathways with other pathologies and are
    associated with distinct and particular risks of later-life morbidity and mortality.
    In order to reach this aim, we use two different sources of information: (1) a
    public web server named <a href="http://disease-connect.org">DiseaseConnect</a>
    focused on the analysis of common genes and molecular mechanisms shared by diseases
    by integrating comprehensive omics and literature data; and (2) a literature search
    directed to find clinical comorbid relationships of infertility etiologies with
    only those diseases appearing after infertility is manifested. This literature
    search is performed because DiseaseConnect web server does not discriminate between
    pathologies emerging before, concomitantly or after infertility is manifested.
    Data show that different infertility etiologies not only share particular genes
    and/or molecular pathways with other pathologies but they have distinct clinical
    relationships with other diseases appearing after infertility is manifested. In
    particular, (1) testicular and high-grade prostate cancer in male infertility;
    (2) non-fatal stroke and endometrial cancer, and likely non-fatal coronary heart
    disease and ovarian cancer in polycystic ovary syndrome; (3) osteoporosis, psychosexual
    dysfunction, mood disorders and dementia in premature ovarian failure; (4) breast
    and ovarian cancer in carriers of BRCA1/2 mutations in diminished ovarian reserve;
    (5) clear cell and endometrioid histologic subtypes of invasive ovarian cancer,
    and likely low-grade serous invasive ovarian cancer, melanoma and non-Hodgkin
    lymphoma in endometriosis; and (6) endometrial and ovarian cancer in idiopathic
    infertility. The present data endorse the principle that the occurrence of a disease
    (in our case infertility) is non-random in the population and suggest that different
    infertility etiologies are genetically and clinically linked with other diseases
    in single meta-diseases. This finding opens new insights for clinicians and reproductive
    biologists to treat infertility problems using a phenomic approach instead of
    considering infertility as an isolated and exclusive disease of the reproductive
    system/hypothalamic–pituitary–gonadal axis. In agreement with a previous validation
    analysis of the utility of DiseaseConnect web server, the present study does not
    show a univocal correspondence between common gene expression and clinical comorbid
    relationship. Further work is needed to untangle the potential genetic, epigenetic
    and phenotypic relationships that may be present among different infertility etiologies,
    morbid conditions and physical/cognitive traits.'
- - http://www.toddkshackelford.com/downloads/Jeffery-et-al-AJHB-2016.pdf
  - Does Human Ejaculate Quality Relate to Phenotypic Traits?
  - Austin John Jeffery, Michael N. Pham, Todd K. Shackelford, Bernhard Fink
  - '2016'
  - 10.1002/ajhb.22805
  - A given man’s phenotype embodies cues of his ancestral ability to effectively
    defend himself and his kin from harm, to survive adverse conditions, and to acquire
    status and mating opportunities. In this review, we explore the hypothesis that
    a man’s phenotype also embodies cues to fertility or the probability that an ejaculate
    will fertilize ova. Female mate choice depends on the ability to discern the quality
    of a male reproductive partner through his phenotype, and male fertility may be
    among the traits that females have evolved to detect. A female who selects as
    mates males that deliver higher quality ejaculates will, on average, be more fecund
    than her competitors. Data on several non-human species demonstrate correlations
    between ejaculate quality and secondary sexual characteristics that inform female
    mate choice, suggesting that females may select mates in part on the basis of
    fertility. While the non-human literature on this topic has advanced, the human
    literature remains limited in scope and there is no clear consensus on appropriate
    methodologies or theoretical positions. We provide a comprehensive review and
    meta-analysis of this literature, and conclude by proposing solutions to the many
    issues that impede progress in the field. In the process, we hope to encourage
    interest and insight from investigators in other areas of human mating and reproductive
    biology.
- - https://parenting.nytimes.com/becoming-a-parent/ivf-sperm-selection
  - ! 'Tinder for Sperm: Even in the Petri Dish, Looks and Athleticism Are Prized:
    What makes one sperm cell—a blob of DNA with a tail—stand out? The selection process
    is like a microscopic Mr. America contest'
  - Randi Hutter Epstein (NYT)
  - 2019-07-18
  - ''
  - <p>Fertility treatments have gone so high-tech, it’s logical to assume there’s
    an exact formula for each procedure. Embryos are frozen and warmed at precise
    temperatures, hormones are measured to the billionth of a gram, and women inject
    themselves with strictly-calibrated doses of drugs. But sperm selection remains
    more art than science. Though fertility specialists generally agree that an “ideal”
    human sperm has a smooth, olive-shaped head and a long, undulating tail, the degree
    to which the appearance of sperm cells correlates with their fertilizing potential
    is a subject of much controversy. It isn’t always possible to find sperm with
    this ideal physique in a given sample, Lo noted, and even homely, misshapen sperm
    can produce healthy babies. Sometimes, Lo said, “You pick the least ugly of the
    sample you have.”</p><p>...These days, many leading fertility centers use techniques
    that allow them to bypass all these steps. Instead, they pick a single sperm and
    inject it into the egg, a technique called intracytoplasmic sperm injection or
    ICSI (pronounced ICK-see). ICSI was designed to help men with few or defective
    sperm, but has become so common that it’s used in more than half of all I.V.F.
    procedures. (Despite its widespread use, studies have not proven that ICSI boosts
    pregnancy rates when men have sufficient numbers of healthy sperm.)</p><p>...Techniques
    to sort sperm by putting them through fine mesh filters and by having them swim
    through specially-engineered pathways called microchannels have also failed to
    yield better results than simply choosing by appearance. Research efforts continue
    but, for now, sperm selection is generally left up to the aesthetic judgement
    of the individual embryologist.</p><p>...Since it’s impossible to individually
    examine each of the thousands of sperm in a typical sample, embryologists acknowledge
    that the quest for the best possible sperm involves an element of fate. “If I
    look in my scope and say, ‘That one looks really great,’ I’ll choose it,” Lo explained.
    But if an especially strong swimmer darts across his field of vision, he sometimes
    changes course at the last minute. When this happens, he said, he wonders, “Did
    I choose that sperm? Did the sperm choose me?”</p>
- - /docs/genetics/selection/2014-mcdowell.pdf
  - Advanced sperm selection techniques for assisted reproduction (Review)
  - S. McDowell, B. Kroon, E. Ford, Y. Hook, D. Glujovsky, A. Yazdani
  - '2014'
  - 10.1002/14651858.CD010461.pub2
  - ! '<p><strong>Background</strong>: Assisted reproductive technologies (ART) such
    as in vitro fertilisation (IVF) and intracytoplasmic sperm injection (ICSI) bring
    together gametes outside of the body to enhance the probability of fertilisation
    and pregnancy. Advanced sperm selection techniques are increasingly being employed
    in ART, most commonly in cycles utilising ICSI. Advanced sperm selection techniques
    are thought to improve the chance that structurally intact and mature sperm with
    high DNA integrity are selected for fertilisation. Advanced sperm selection strategies
    include selection according to surface charge; sperm apoptosis; sperm birefringence;
    ability to bind to hyaluronic acid; and sperm morphology under ultra-high magnification.
    These techniques theoretically improve ART outcomes.</p><p><strong>Objectives</strong>:
    To evaluate the impact of advanced sperm selection techniques on ART outcomes.</p><p><strong>Search
    methods</strong>: Systematic search of electronic databases (Cochrane Menstrual
    Disorders and Subfertility Group Specialised Register, the Cochrane Central Register
    of Controlled Trials (CENTRAL), MEDLINE, EMBASE, PsycINFO, Cumulative Index to
    Nursing and Allied Health Literature (CINAHL), Latin American and Caribbean Health
    Science Information Database (LILACS)), trials registers (ClinicalTrials.gov,
    Current Controlled Trials, World Health Organization International Clinical Trials
    Registry Platform), conference abstracts (Web of Knowledge) and grey literature
    (OpenGrey) for relevant randomised controlled trials. We hand-searched the reference
    lists of included studies and similar reviews. The search was conducted in May
    2014.</p><p><strong>Selection criteria</strong>: We included randomised controlled
    trials (RCTs) comparing an advanced sperm selection technique versus standard
    IVF or ICSI or versus another advanced sperm selection technique. We excluded
    studies of sperm selection using ultra-high magnification (intracytoplasmic morphologically
    selected sperm injection, or IMSI), as they are the subject of a separate Cochrane
    review. Quasi-randomised and pseudo-randomised trials were excluded. Our primary
    outcome measure was live birth rate per woman randomly assigned. Secondary outcome
    measures included clinical pregnancy per woman randomly assigned, miscarriage
    per clinical pregnancy and fetal abnormality per clinical pregnancy.</p><p><strong>Data
    collection and analysis</strong>: Two review authors independently assessed eligibility
    of studies and risk of bias, and performed data extraction. Disagreements were
    resolved by consultation with a third review author. Study investigators were
    consulted to resolve other queries that arose. Risk ratios (RRs) were calculated
    with 95% confidence intervals (CIs). We planned to combine studies using a fixed-effect
    model, if sufficient data were available. The quality of the evidence was evaluated
    using Grades of Recommendation, Assessment, Development and Evaluation (GRADE)
    methods.</p><p><strong>Main results</strong>: Two RCTs were included in the review.
    Both evaluated sperm selection by hyaluronanic acid binding for ICSI, but only
    one reported live births. No studies were identified that were related to surface
    charge selection, sperm apoptosis or sperm birefringence.</p><p>One RCT compared
    hyaluronanic acid binding versus conventional ICSI. Live birth was not reported.
    Evidence was insufficient to show whether there was a difference between groups
    in clinical pregnancy rates (RR 1.01, 95% CI 0.84 to 1.22, one RCT, 482 women).
    This evidence was deemed to be of low quality, mainly as the result of poor reporting
    of methods and findings. Miscarriage data were unclear, and fetal abnormality
    rates were not reported.</p><p>The other RCT compared two different hyaluronanic
    acid binding techniques, SpermSlow and physiological intracytoplasmic sperm injection
    (PISCI). Evidence was insufficient to indicate whether there was a difference
    between groups in rates of live birth (RR 1.16, 95% CI 0.65 to 2.05, one RCT,
    99 women), clinical pregnancy (RR 1.07, 95% CI 0.67 to 1.71, one RCT, 99 women)
    or miscarriage (RR 0.76, 95% CI 0.24 to 2.44, one RCT, 41 women). The evidence
    for these comparisons was deemed to be of low quality, as it was limited by imprecision
    and poor reporting of study methods. Fetal abnormality rates were not reported.</p><p><strong>Authors’
    conclusions</strong>: Evidence was insufficient to allow review authors to determine
    whether sperm selected by hyaluronanic acid binding improve live birth or pregnancy
    outcomes in ART, and no clear data on adverse effects were available. Evidence
    was also insufficient to show whether there is a difference in efficacy between
    the hyaluronic acid binding methods SpermSlow and PICSI. No randomised evidence
    evaluating sperm selection by sperm apoptosis, sperm birefringence or surface
    charge was found. Further studies of suitable quality are required to evaluate
    whether any of these advanced sperm selection techniques can be recommended for
    use in clinical practice.</p>'
- - https://www.frontiersin.org/articles/10.3389/fvets.2019.00241/full
  - ! 'Throwing the Baby Out With the Bath Water: Could Widespread Neutering of Companion
    Dogs Cause Problems at a Population Level?'
  - Jessica K. Dawson, Tiffani J. Howell, Matthew B. Ruby, Pauleen C. Bennett
  - 2019-07-22
  - 10.3389/fvets.2019.00241
  - <p>In many countries where companion dogs are popular, owners are strongly encouraged
    to neuter their dogs. Consequently, millions of dogs are neutered each year. In
    recent times considerable attention has been paid to the possible effects of such
    procedures on canine health and welfare. Less scrutinized are the potential ramifications
    of widespread neutering on the breeding of dogs and their continued success as
    human companions. This paper summarizes research investigating factors influencing
    the breeding and rearing of dogs most suited to companionship roles in contemporary,
    typically high-density, communities, and briefly reviews current breeder practices.
    It then argues that a fundamental shift to promote inclusion of “proven” companion
    dogs in the gene pool, as opposed to dogs meeting conformation or working/sporting
    standards, is required to successfully meet the needs of modern urban dog owners.
    A new model is proposed, whereby responsible owners and breeders work together
    to produce dogs most suited for life as human companions.</p><p>...The demonstrated
    importance of genetics and early environment in determining behavioral predispositions
    makes it imperative to consider where companion dogs come from. Prior to the widespread
    introduction of neutering practices, dogs often bred indiscriminately, and people
    typically obtained their dogs for free from neighbors whose bitch had produced
    a litter (47). While this was problematic in terms of creating dog overpopulation,
    it meant that most of the dogs who produced offspring were well suited to the
    demands of the lives they were expected to lead. Those who weren't well-suited
    were disposed of. Today, strong demand for companion dogs, coupled with rapid
    urbanization, increased concern regarding the welfare of animals, particularly
    companion dogs, and high neutering rates, has resulted in a multimillion-dollar
    industry involving the selective breeding and selling of puppies (48). Widespread
    neutering means that humans intentionally control nearly all dog breeding in developed
    countries...As described previously, in many developed countries, neutering companion
    dogs is considered an important aspect of responsible ownership. Hence, the very
    best companion dogs in the general community, those owned by responsible citizens
    who choose their dogs carefully and ensure they are reared correctly, are almost
    certainly those most likely to be neutered. Conversely, it is those companion
    dog owners who fail to perform the “responsible” behavior of neutering their dog
    who are perhaps most likely to breed. These “breeders” may also choose not to
    perform other “responsible” behaviors, such as selecting their dog carefully,
    testing it for genetic disorders, or evaluating the dog's suitability as a companion
    prior to allowing it to reproduce. In other words, they may not thoroughly consider
    the genetic and environmental factors known to be critical to optimal puppy development.</p><p>Second,
    we advocate that all dogs should be independently tested for suitability before
    being bred—much as breeders now advertise that their puppies' parents are successful
    show dogs, or that they are free from known genetic disorders, so they should
    be encouraged to advertise that independent testing has shown their breeding dogs
    to be well-suited behaviourally to life as human companions. We anticipate that
    responsible breeders would be willing to pay for this independent certification,
    much as they presently pay for genetic tests, eye screening and tests for hip
    dysplasia. Several behavioral tests exist to measure specific traits, such as
    the Socially Acceptable Behavior test (64), which measures aggression, or the
    Dog Mentality Assessment test (65), which examines levels of playfulness, curiosity,
    aggression, sociability, and chase-proneness. In the USA, the Canine Good Citizen
    program, administered by the American Kennel Club, takes <30 min to administer
    and is designed to identify dogs that meet ten objectives consistent with being
    a good companion dog. Any one of these tests could be used as a basis for developing
    an assessment suited to breeding dogs—dogs that are not themselves good companions
    are less likely to produce puppies able to excel at this role.</p>
- - /Clone#dog-heritabilities
  - Dog behavioral trait heritabilities review
  - Gwern Branwen
  - 2019-01-13
  - ''
  - ! '<p>Notes on reading reviews &amp; meta-analyses on the psychometric properties
    &amp; heritabilities of dog behavioral traits, particularly for working dogs.
    Dog heritabilities might be expected to be low in the context of considering dogs
    of the same breed (as would be relevant to a breeding or training context): heavy
    selective breeding would tend to reduce within-breed heritabilities (while increasing
    group heritability).</p><p>Overall, heritabilities appear to differ by breed and
    be quite low (say, closer to 25% than to the <a href="/docs/genetics/heritable/2015-polderman.pdf"
    title="&#39;Meta-analysis of the heritability of human traits based on fifty years
    of twin studies&#39;, Polderman et al 2015">human average of &gt;50%</a>) but
    the psychometric properties of dog behavioral tests also appear to be poor, with
    low item counts, reliabilities, test-retests, and predictive power, rater/judge
    effects, and little use of latent factors to extract more reliable measures, suggesting
    considerable total measurement error and thus considerable underestimation of
    prediction/heritabilities. Possibly dog heritabilities are much closer to human
    heritabilities than they seem.</p>'
- - /docs/genetics/heritable/1965-scott-geneticsandthesocialbehaviorofthedog.pdf
  - ! 'Genetics and the Social Behavior of the Dog [Dog Behavior: The Genetic Basis]'
  - John Paul Scott, John L. Fuller
  - '1965'
  - ''
  - ! 'Classic study of dog behavior, the authoritative information from 20 years
    of research at the Jackson Laboratory. The authors synthesize developmental problems
    and canine genetics, based on study of 470 dogs. Central to the book is the role
    heredity plays in the development of behavior. Giving puppies an environment designed
    on the principles of a well-run school, Scott and Fuller tested five breeds representing
    the major dog groups and carried out a Mendelian experiment with two of the most
    different breeds: The basenji and the cocker spaniel. They found that heredity
    affects almost every trait tested; that gender affects aggressiveness and the
    dominance order, but not trainability and problem-solving; that emotional traits
    profoundly influence performance; that, although breeds differ widely in emotional
    and motivational characteristics, none shows distinct superiority in problem solving;
    and that detailed statistical analyses indicate a highly complex pathway between
    primary gene action and its final effect on behavior. Includes important information
    on rearing methods, the origin and history of dog breeds, basic behavior patterns
    and the psychological and behavioral development of puppies. Their careful scientific
    work demonstrated the importance and existence of time limited phases in the early
    life of dogs within which certain experiences need to occur or the dogs may be
    forever deficient. Their work (with that of Eckhard Hess''s on ducks and geese)
    demonstrated that these critical or sensitive periods in early development could
    be scientifically studied in ways compatible with a scientific psychology. This
    book will always be especially valuable to dog breeders and trainers; its last
    chapters summarize in very clear terms the particular phases in early development
    and experiences the dog needs to be adequately socialized. The reader can refer
    back to earlier chapters to get more information on how the experiments were conducted
    and the distribution of results. It answers questions on proper age that puppies
    can be separated from their mothers, what experiences are important to provide
    at what age, etc. Originally published in 1965. [ISBN: 0-226-74335-7]'
- - https://annesofiebeckknudsen.com/wp-content/uploads/2019/01/thosewhostayed.pdf
  - ! 'Those Who Stayed: Individualism, Self-Selection and Cultural Change during
    the Age of Mass Migration'
  - Anne Sofie Beck Knudsen
  - 2019-01-01
  - ''
  - ! 'This paper examines the joint evolution of emigration and individualism in
    Scandinavia during the Age of Mass Migration (1850&ndash;1920). A long-standing
    hypothesis holds that people of a stronger individualistic mindset are more likely
    to migrate as they suffer lower costs of abandoning existing social networks.
    Building on this hypothesis, I propose a theory of cultural change where migrant
    self-selection generates a relative push away from individualism, and towards
    collectivism, in migrant-sending locations through a combination of initial distributional
    effects and channels of intergenerational cultural transmission. Due to the interdependent
    relationship between emigration and individualism, emigration is furthermore associated
    with cultural convergence across subnational locations. I combine various sources
    of empirical data, including historical population census records and passenger
    lists of emigrants, and test the relevant elements of the proposed theory at the
    individual and subnational district level, and in the short and long run. Together,
    the empirical results suggest that individualists were more likely to migrate
    than collectivists, and that the Scandinavian countries would have been considerably
    more individualistic and culturally diverse, had emigration not taken place. [Keywords:
    Culture, individualism, migration, selection, economic history]'
- - /Statistical-notes#selective-emigration-and-personality-trait-change
  - Selective Emigration and Personality Trait Change
  - Gwern Branwen
  - 2019-09-03
  - ''
  - ! '<p><a href="https://annesofiebeckknudsen.com/wp-content/uploads/2019/01/thosewhostayed.pdf"
    title="Those Who Stayed: Individualism, Self-Selection and Cultural Change during
    the Age of Mass Migration">Knudsen 2019</a> finds that the emigration of 25% of
    the Scandinavian population to the USA 1850–1920 was driven in part by more ‘individualistic’
    personality factors among emigrants, leading to permanent decreases in mean ‘individualism’
    in the home countries. This is attributed to cultural factors, rather than genetics.
    I model the overall migration as a simple truncation selection scenario, and find
    that in a simple model under reasonable assumptions, the entire effect could be
    genetic.</p>'
- - https://www.nature.com/articles/s41467-019-11724-6
  - Extreme inbreeding in a European ancestry sample from the contemporary UK population
  - Loic Yengo, Naomi R. Wray, Peter M. Visscher
  - 2019-09-03
  - 10.1038/s41467-019-11724-6
  - ! '<p>In most human societies, there are taboos and laws banning mating between
    first- and second-degree relatives, but actual prevalence and effects on health
    and fitness are poorly quantified. Here, we leverage a large observational study
    of ~450,000 participants of European ancestry from the UK Biobank (UKB) to quantify
    extreme inbreeding (EI) and its consequences. We use genotyped SNPs to detect
    large runs of homozygosity (ROH) and call EI when &gt;10% of an individual’s genome
    comprise ROHs. We estimate a prevalence of EI of ~0.03%, i.e., ~$. EI cases have
    phenotypic means between 0.3 and 0.7 standard deviation below the population mean
    for 7 traits, including stature and cognitive ability, consistent with inbreeding
    depression estimated from individuals with low levels of inbreeding. Our study
    provides DNA-based quantification of the prevalence of EI in a European ancestry
    sample from the UK and measures its effects on health and fitness traits.</p><p>In
    most human societies, there are taboos and laws banning mating between first-
    and second-degree relatives, but actual prevalence and effects on health and fitness
    are poorly quantified. Here, we leverage a large observational study of ~450,000
    participants of European ancestry from the UK Biobank (UKB) to quantify extreme
    inbreeding (EI) and its consequences. We use genotyped SNPs to detect large runs
    of homozygosity (ROH) and call EI when &gt;10% of an individual’s genome comprise
    ROHs. We estimate a prevalence of EI of ~0.03%, i.e., ~<math display="inline"
    xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mn>3652</mn></mfrac><annotation
    encoding="application/x-tex">\frac{1}{3652}</annotation></semantics></math>.
    EI cases have phenotypic means between 0.3 and 0.7 standard deviation below the
    population mean for 7 traits, including stature and cognitive ability, consistent
    with inbreeding depression estimated from individuals with low levels of inbreeding.
    Our study provides DNA-based quantification of the prevalence of EI in a European
    ancestry sample from the UK and measures its effects on health and fitness traits.</p>'
- - https://minimaxir.com/2019/09/howto-gpt2/
  - How To Make Custom AI-Generated Text With GPT-2
  - Max Woolf
  - 2019-09-04
  - ''
  - ! 'From a text-generation perspective, the included demos were very impressive:
    the text is coherent over a long horizon, and grammatical syntax and punctuation
    are near-perfect.</p><p><img src=/img/howto-gpt2/openai-demo.png alt></p><p>At
    the same time, the Python code which allowed anyone to download the model (albeit
    smaller versions out of concern the full model can be abused to mass-generate
    fake news) and the <a href=https://www.tensorflow.org>TensorFlow</a> code to
    load the downloaded model and generate predictions was <a href=https://github.com/openai/gpt-2
    >open-sourced on GitHub</a>.</p><p>Neil Sheppard created <a href=https://github.com/nshepperd/gpt-2
    >a fork</a> of OpenAI’s repo which contains additional code to allow <em>finetuning</em>
    the existing OpenAI model on custom datasets. A <a href=https://github.com/ak9250/gpt-2-colab
    >notebook</a> was created soon after, which can be copied into <a href=https://colab.research.google.com
    >Google Colaboratory</a> and clones Sheppard''s repo to finetune GPT-2 backed
    by a free GPU. From there, the proliferation of GPT-2 generated text took off:
    researchers such as Gwern Branwen made <a href=https://www.gwern.net/GPT-2 >GPT-2
    Poetry</a> and Janelle Shane made <a href=https://aiweirdness.com/post/183471928977/dd-character-bios-now-making-slightly-more
    >GPT-2 Dungeons and Dragons character bios</a>.</p><p>I waited to see if anyone
    would make a tool to help streamline this finetuning and text generation workflow,
    a la <a href=https://github.com/minimaxir/textgenrnn >textgenrnn</a> which I had
    made for recurrent neural network-based text generation. Months later, no one
    did. So I did it myself. Enter <a href=https://github.com/minimaxir/gpt-2-simple
    >gpt-2-simple</a>, a Python package which wraps Sheppard''s finetuning code in
    a functional interface and adds <em>many</em> utilities for model management and
    generation control.</p><p><p>Thanks to gpt-2-simple and <a href=https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce
    >this Colaboratory Notebook</a>, you can easily finetune GPT-2 on your own dataset
    with a simple function, and generate text to your own specifications!</p>'
- - /docs/genetics/selection/2013-walsh-book2-ch14-draft.pdf
  - ! 'Chapter 14. Short-term Changes in the Mean: 2. Truncation and Threshold Selection
    [2013 draft]'
  - Michael Lynch, Bruce Walsh
  - '2013'
  - ''
  - <p>This brief chapter first considers the theory of truncation selection on the
    mean, which is of general interest, and then examines a number of more specialized
    topics that may be skipped by the casual reader. Truncation selection (Figure
    14.1) occurs when all individuals on one side of a threshold are chosen, and is
    by far the commonest form of artificial selection in breeding and laboratory experiments.
    One key result is that for a normally-distributed trait, the selection intensity
    <em>ī</em> is fully determined by the fraction <em>p</em> saved (Equation 14.3a),
    provided that the chosen number of adults is large. This allows a breeder or experimentalist
    to predict the expected response given their choice of <em>p</em>.</p><p>The remaining
    topics are loosely organized around the theme of selection intensity and threshold
    selection. First, when a small number of adults are chosen to form the next generation,
    Equation 14.3a overestimates the expected <em>ī</em>, and we discuss how to correct
    for this small sample effect. This correction is important when only a few individuals
    form the next generation, but is otherwise relatively minor. The rest of the chapter
    considers the response in discrete traits. We start with a binary (present/absence)
    trait, and show how an underlying liability model can be used to predict response.
    We also examine binary trait response in a logistic regression framework (estimating
    the probability of showing the trait given some underlying liability scores) and
    the evolution of both the mean value on the liability scale and the threshold
    value. We conclude with a few brief comments on response when a trait is better
    modeled as Poisson, rather than normally, distributed….In addition to being the
    commonest form of artificial selection, truncation selection is also the most
    efficient, giving the largest selection intensity of any scheme culling the same
    fraction of individuals from a population (Kimura and Crow 1978, Crow and Kimura
    1979).</p><p>[Preprint chapter of <a href="https://www.amazon.com/Evolution-Selection-Quantitative-Traits-Bruce/dp/0198830874"><em>Evolution
    and Selection of Quantitative Traits</em></a>, Lynch and Walsh 2018]</p>
- - /Statistical-notes#oh-deer-could-deer-evolve-to-avoid-car-accidents
  - ! 'Oh Deer: Could Deer Evolve to Avoid Car Accidents?'
  - Gwern Branwen
  - 2018-11-11
  - ''
  - ! '<p>Can deer evolve under the selection pressure of car accidents to learn to
    avoid roads? Probably, but it''ll take a long time.</p><p>I’ve noticed while driving
    many deer corpses over the years. Cars seem like they could be a major source
    of deer mortality. If they are, deer might be evolving behavior to avoid cars.
    But deer/car accident rates appear stable or increasing (perhaps due to human
    population growth &amp; construction). How fast would we expect to see any deer
    adaptation?</p><p>Looking at some of the mortality statistics, I model it as a
    liability threshold trait being selected on via truncation selection, and calculate
    some hypotheticals about whether and how fast they could adapt.</p><p>Teal deer:
    of course, but it’d be slow.</p>'
- - /Clone#nba-screening-scenario
  - NBA Screening Scenario
  - Gwern Branwen
  - 2019-06-03
  - ''
  - <p>Analogous to the <a href="/Clone">dog cloning scenario</a>, I consider the
    case of selecting for extremes on PGSes, motivated by a scenario of scouting tall
    men for the NBA.</p><p>Setting up the NBA selection problem as a liability threshold
    model with current height PGSes as a noisy predictor, height selection can be
    modeled as selecting for extremes on a PGS which is regressed back to the mean
    to yield expected adult height, and probability of being tall enough to consider
    a NBA career.</p><p>Filling in reasonable values, nontrivial numbers of tall people
    can be found by genomic screening with a current PGS, and as PGSes approach their
    predictive upper bound (derived from whole-genome-based heritability estimates
    of height), selection is capable of selecting almost all tall people by taking
    the top PGS percentile.</p>
- - https://tvtropes.org/pmwiki/pmwiki.php/Main/RuleOfCool
  - Rule of Cool
  - TVTropes
  - ''
  - ''
  - <p><em>The limit of the Willing Suspension of Disbelief for a given element is
    directly proportional to its awesomeness.</em></p><p>Stated another way, all but
    the most pedantic of viewers will forgive liberties with reality as long as the
    result is wicked sweet or awesome. This applies to the audience in general; there
    will naturally be a different threshold for each individual. Also known in some
    circles as a "rad herring", in which something doesn't make sense within the guidelines
    of the story's reality, but it's too cool <em>not</em> to include it...Since it's
    subjective, it doesn't have to be cool in the sense of "Grim reaper on a mountain
    playing an electric guitar". The protagonist might not use guns because it's cooler
    to have them fight vampires with knives and stakes. You might have Missing Parent
    Syndrome because it would be weird to have parents with you on a road trip across
    the country. Basically, Rule of Cool works differently for whichever genre you're
    writing for.</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.691.3734&rep=rep1&type=pdf
  - ! 'Hatred and Profits: Getting Under the Hood of the Ku Klux Klan'
  - Roland G. Fryer, Steven D. Levitt
  - 2010-08-31
  - ''
  - The Ku Klux Klan reached its heyday in the mid-1920s, claiming millions of members.
    In this paper, we analyze the 1920s Klan, those who joined it, and the social
    and political impact that it had. We utilize a wide range of newly discovered
    data sources including information from Klan membership roles, applications, robe-order
    forms, an internal audit of the Klan by Ernst and Ernst, and a census that the
    Klan conducted after an internal scandal. Combining these sources with data from
    the 1920 and 1930 U.S. Censuses, we find that individuals who joined the Klan
    were better educated and more likely to hold professional jobs than the typical
    American. Surprisingly, we find few tangible social or political impacts of the
    Klan. There is little evidence that the Klan had an effect on black or foreign
    born residential mobility, or on lynching patterns. Historians have argued that
    the Klan was successful in getting candidates they favored elected. Statistical
    analysis, however, suggests that any direct impact of the Klan was likely to be
    small. Furthermore, those who were elected had little discernible effect on legislation
    passed. Rather than a terrorist organization, the 1920s Klan is best described
    as a social organization built through a wildly successful pyramid scheme fueled
    by an army of highly-incentivized sales agents selling hatred, religious intolerance,
    and fraternity in a time and place where there was tremendous demand.
- - /doc/economics/2014-heald.pdf
  - How Copyright Keeps Works Disappeared
  - Paul J. Heald
  - 2014-12-01
  - 10.1111/jels.12057
  - A random sample of new books for sale on Amazon.com shows more books for sale
    from the 1880s than the 1980s. Why? This article presents new data on how copyright
    stifles the reappearance of works. First, a random sample of more than 2,000 new
    books for sale on Amazon.com is analyzed along with a random sample of almost
    2,000 songs available on new DVDs. Copyright status correlates highly with absence
    from the Amazon shelf. Together with publishing business models, copyright law
    seems to deter distribution and diminish access. Further analysis of eBook markets,
    used books on Abebooks.com, and the Chicago Public Library collection suggests
    that no alternative marketplace for out-of-print books has yet developed. Data
    from iTunes and YouTube, however, tell a different story for older hit songs.
    The much wider availability of old music in digital form may be explained by the
    differing holdings in two important cases, Boosey & Hawkes v. Disney (music) and
    Random House v. Rosetta Stone (books).
- - /docs/economics/2007-doran.pdf
  - So You Discovered an Anomaly ... Gonna Publish It? An Investigation Into the Rationality
    of Publishing a Market Anomaly
  - James Doran, Colbrin A. Wright
  - 2007-01-11
  - 10.2139/ssrn.956105
  - If publishing an anomaly leads to the dissipation of its profitability, a notion
    that has mounting empirical support, then publishing a highly profitable market
    anomaly seems to be irrational behavior. This paper explores the issue by developing
    and empirically testing a theory that argues that publishing a market anomaly
    may, in fact, be rational behavior. The theory predicts that researchers with
    few (many) publications and lesser (stronger) reputations have the highest (lowest)
    incentive to publish market anomalies. Employing probit models, simple OLS regressions,
    and principal component analysis, we show that (a) market anomalies are more likely
    to be published by researchers with fewer previous publications and who have been
    in the field for a shorter period of time and (b) the profitability of published
    market anomalies is inversely related to the common factor spanning the number
    of publications the author has and the number of years that have elapsed since
    the professor earned his Ph.D. The empirical results suggest that the probability
    of publishing an anomaly and the profitability of anomalies that are published
    are inversely related to the reputation of the authors. These results corroborate
    the theory that publishing an anomaly is rational behavior for an author trying
    to establish his or her reputation.
- - https://static1.squarespace.com/static/5329e895e4b09fd4786211a3/t/56cb78e3d51cd4c4751d1245/1456175333161/Public+Opin+Q-2014-Makowsky-poq-nfu041.pdf
  - Education, Intelligence, and Attitude Extremity
  - Michael D. Makowsky, Stephen C. Miller
  - '2014'
  - doi:10.1093/poq/nfu041
  - Education and general intelligence both serve to inform opinions, but do they
    lead to greater attitude extremity? The potential civic returns to education include
    not only the sophistication of citizen opinions, but also their moderation. We
    use questions on economic policy, social issues, and environmental issues from
    the General Social Survey [GSS] to test the impact of education on attitude extremity,
    as measured by deviation from centrist or neutral positions, while controlling
    for intelligence. We use quantile regression modeling to identify effects on both
    the most extreme beliefs as well as the most ambivalent. We find that intelligence
    is a moderating force across the entire distribution in economic, social, and
    environmental policy beliefs. Completing high school strongly correlates to reduced
    extremity, particularly in the upper quantiles. College education increases attitude
    extremity in the lower tail, while postgraduate education increases extremity
    in the upper tail. Results are discussed in the context of enlightenment and motivated-reasoning
    theories of beliefs and education. The relevance to political party core and swing
    voters is briefly discussed.
- - https://www.thiswaifudoesnotexist.net/
  - ThisWaifuDoesNotExist.net
  - Gwern Branwen
  - 2019-02-19
  - ''
  - <p><a href="https://www.thiswaifudoesnotexist.net/"><code>ThisWaifuDoesNotExist.net</code></a>
    (<a href="https://www.gwern.net/TWDNE">TWDNE</a>) is a static website which uses
    JS to display random <a href="https://www.gwern.net/Faces">anime faces generated
    by StyleGAN</a> neural networks, along with <a href="https://www.gwern.net/GPT-2">GPT-2</a>-generated
    'anime plot summaries'.</p><p><figure><img src="/images/gan/thiswaifudoesnotexist.png"
    alt="A screenshot of “This Waifu Does Not Exist” (TWDNE) showing a random StyleGAN-generated
    anime face and a random GPT-2-small text sample conditioned on anime keywords/phrases."
    /><figcaption>A screenshot of <q>“This Waifu Does Not Exist”</q> (TWDNE) showing
    a random StyleGAN-generated anime face and a random GPT-2-small text sample conditioned
    on anime keywords/phrases.</figcaption></figure></p>
- - https://classic.esquire.com/article/1990/12/1/terminal-delinquents
  - ! 'Terminal Delinquents: Once, They Stole Hubcaps And Shot Out Street-Lights.
    Now They''re Stealing Your Social Security Number And Shooting Out Your Credit
    Rating. A Layman''s Guide To Computer High Jinks'
  - Jack Hitt, Paul Tough (Esquire)
  - 1990-12-01
  - ''
  - ! '[Gonzo-style account of hanging out with teenage hackers and phreakers in NYC,
    Phiber Optik and Acid Phreak, similar to <a href="https://classic.esquire.com/article/1990/12/1/terminal-delinquents"><em>Hackers</em></a>]
    <p>“Sometimes,” says Kool, “it’s so simple. I used to have contests with my friends
    to see how few words we could use to get a password. Once I called up and said,
    ‘Hi, I’m from the social-engineering center and I need your password,’ and they
    gave it to me! I swear, sometimes I think I could call up and say, ‘Hi, I’m in
    a diner, eating a banana split. Give me your password.’” LIKE ITS mechanical counterpart,
    social engineering is half business and half pleasure. It is a social game that
    allows the accomplished hacker to show off his knowledge of systems, his mastery
    of jargon, and especially his ability to manipulate people. It not only allows
    the hacker to get information; it also has the comic attractions of the old-fashioned
    prank phone call—fooling an adult, improvisation, cruelty. In the months we spent
    with the hackers, the best performance in a social-engineering role was by a hacker
    named Oddjob. With him and three other guys we pulled a hacking all-nighter in
    the financial district, visiting pay phones in the hallway of the World Trade
    Center, outside the bathrooms of the Vista Hotel, and in the lobby of the international
    headquarters of American Express.</p><p>…Where we see only a machine’s function,
    they see its potential. This is, of course, the noble and essential trait of the
    inventor. But hackers warp it with teenage anarchic creativity: Edison with attitude.
    Consider the fax machine. We look at it; we see a document-delivery device. One
    hacker we met, Kaos, looked at the same machine and immediately saw the Black
    Loop of Death. Here’s how it works: Photocopy your middle finger displaying the
    international sign of obscene derision. Make two more copies. Tape these three
    pages together. Choose a target fax machine. Wait until nighttime, when you know
    it will be unattended, and dial it up. Begin to feed your long document into your
    fax machine. When the first page begins to emerge below, tape it to the end of
    the last page. Ecce. This three-page loop will continuously feed your image all
    night long. In the morning, your victim will find an empty fax machine, surrounded
    by two thousand copies of your finger, flipping the bird.</p><p>…From a distance,
    a computer network looks like a fortress—impregnable, heavily guarded. As you
    get closer, though, the walls of the fortress look a little flimsy. You notice
    that the fortress has a thousand doors; that some are unguarded, the rest watched
    by unwary civilians. All the hacker has to do to get in is find an unguarded door,
    or borrow a key, or punch a hole in the wall. The question of whether he’s allowed
    in is made moot by the fact that it’s unbelievably simple to enter. Breaking into
    computer systems will always remain easy because the systems have to accommodate
    dolts like you and me. If computers were used only by brilliant programmers, no
    doubt they could maintain a nearly impenetrable security system. But computers
    aren’t built that way; they are “dumbed down” to allow those who must use them
    to do their jobs. So hackers will always be able to find a trusting soul to reveal
    a dialup, an account, and a password. And they will always get in.</p>'
- - https://advances.sciencemag.org/content/5/9/eaaw2594
  - ! 'Different languages, similar encoding efficiency: Comparable information rates
    across the human communicative niche'
  - Christophe Coupé, Yoon Oh, Dan Dediu, François Pellegrino
  - 2019-09-04
  - 10.1126/sciadv.aaw2594
  - ! 'Language is universal, but it has few indisputably universal characteristics,
    with cross-linguistic variation being the norm. For example, languages differ
    greatly in the number of syllables they allow, resulting in large variation in
    the Shannon information per syllable. Nevertheless, all natural languages allow
    their speakers to efficiently encode and transmit information. We show here, using
    quantitative methods on a large cross-linguistic corpus of 17 languages, that
    the coupling between language-level (information per syllable) and speaker-level
    (speech rate) properties results in languages encoding similar information rates
    (~39 bits/s) despite wide differences in each property individually: Languages
    are more similar in information rates than in Shannon information or speech rate.
    These findings highlight the intimate feedback loops between languages’ structural
    properties and their speakers’ neurocognition and biology under communicative
    pressures. Thus, language is the product of a multiscale communicative niche construction
    process at the intersection of biology, environment, and culture.'
- - https://scholarship.law.georgetown.edu/cgi/viewcontent.cgi?article=1557&context=facpub#pdf
  - Constitutional Hardball
  - Mark Tushnet
  - '2004'
  - ''
  - ! 'For the past several years I have been noticing a phenomenon that seems to
    me new in my lifetime as a scholar of constitutional law. I  call the phenomenon
    <em>constitutional hardball</em>. This Essay develops the idea that there is such
    a practice, that there is a sense in which it is new, and that its emergence (or
    re-emergence) is interesting because it signals that political actors understand
    that they are in a position to put in place a new set of deep institutional arrangements
    of a sort I call a ''constitutional order''. A shorthand sketch of constitutional
    hardball is this: it consists of political claims and practices-legislative and
    executive initiatives-that are without much question within the bounds of existing
    constitutional doctrine and practice but that are nonetheless in some tension
    with existing <em>pre</em>-constitutional understandings. It is <em>hardball</em>
    because its practitioners see themselves as playing for keeps in a special kind
    of way; they believe the stakes of the political controversy their actions provoke
    are quite high, and that their defeat and their opponents'' victory would be a
    serious, perhaps permanent setback to the political positions they hold.'
- - /docs/economics/2017-gard.pdf
  - ! 'Creating a Last Twenty (L20) Collection: Implementing Section 108(h) in Libraries,
    Archives and Museums'
  - Elizabeth Townsend Gard
  - 2017-10-02
  - 10.2139/ssrn.3049158
  - ! 'Section 108(h) has not been utilized by libraries and archives, in part because
    of the uncertainty over definitions (e.g. “normal commercial exploitation”), determination
    of the eligibility window (last twenty years of the copyright term of published
    works), and how to communicate the information in the record to the general public.
    This paper seeks to explore the elements necessary to implement the Last Twenty
    exception, otherwise known as Section 108(h) and create a Last Twenty (L20) collection.
    In short, published works in the last twenty years of the copyright may be digitized
    and distributed by libraries, archives, and museums, as long as there is no commercial
    sale of the works and no reasonably priced copy is available. This means that
    Section 108(h) is available for the forgotten and neglected works, 1923-1941,
    including millions of foreign works restored by GATT. Section 108(h) is less effective
    for big, commercially available works. In many ways, that is the dividing line
    created by Section 108(h): allow for commercial exploitation of works throughout
    their term, but allow libraries to rescue works that had no commercial exploitation
    or copies available for sale and make them available through copying and distribution
    for research, scholarship, and preservation. In fact, Section 108(h) when it was
    being debated in Congress was called labeled “orphan works.” This paper suggests
    ways to think about the requirements of Section 108(h) and to make it more usable
    for libraries. Essentially, by confidently using Section 108(h) we can continue
    to make the past usable one query at a time. The paper ends with an evaluation
    of the recent Discussion Paper by the U.S. Copyright Office on Section 108 and
    suggests changes/recommendations related to the proposed changes to Section 108(h).
    [Keywords: Copyright, Public Domain, Library, Archives, Museum, Section 108(h),
    Internet Archive, orphan works]'
- - https://openscholarship.wustl.edu/cgi/viewcontent.cgi?article=6319&context=law_lawreview
  - Algorithmic Entities
  - Lynn M. LoPucki
  - '2018'
  - ''
  - <p>In a 2014 article, Professor Shawn Bayern demonstrated that anyone can confer
    legal personhood on an autonomous computer algorithm by putting it in control
    of a limited liability company. Bayern’s demonstration coincided with the development
    of “autonomous” online businesses that operate independently of their human owners—accepting
    payments in online currencies and contracting with human agents to perform the
    off-line aspects of their businesses. About the same time, leading technologists
    Elon Musk, Bill Gates, and Stephen Hawking said that they regard human-level artificial
    intelligence as an existential threat to the human race.</p><p>This Article argues
    that algorithmic entities—legal entities that have no human controllers—greatly
    exacerbate the threat of artificial intelligence. Algorithmic entities are likely
    to prosper first and most in criminal, terrorist, and other anti-social activities
    because that is where they have their greatest comparative advantage over human-controlled
    entities. Control of legal entities will contribute to the threat algorithms pose
    by providing them with identities. Those identities will enable them to conceal
    their algorithmic natures while they participate in commerce, accumulate wealth,
    and carry out anti-social activities.</p><p>Four aspects of corporate law make
    the human race vulnerable to the threat of algorithmic entities. First, algorithms
    can lawfully have exclusive control of not just American LLC’s but also a large
    majority of the entity forms in most countries. Second, entities can change regulatory
    regimes quickly and easily through migration. Third, governments—particularly
    in the United States—lack the ability to determine who controls the entities they
    charter and so cannot determine which have non-human controllers. Lastly, corporate
    charter competition, combined with ease of entity migration, makes it virtually
    impossible for any government to regulate algorithmic control of entities.</p>
- - /docs/economics/2016-mclean.pdf
  - Does Academic Research Destroy Stock Return Predictability?
  - R. David McLean, Jeffrey Pontiff
  - 2016-02-01
  - 10.1111/jofi.12365
  - We study the out-of-sample and post-publication return predictability of 97 variables
    shown to predict cross-sectional stock returns. Portfolio returns are 26% lower
    out-of-sample and 58% lower post-publication. The out-of-sample decline is an
    upper bound estimate of data mining effects. We estimate a 32% (58%–26%) lower
    return from publication-informed trading. Post-publication declines are greater
    for predictors with higher in-sample returns, and returns are higher for portfolios
    concentrated in stocks with high idiosyncratic risk and low liquidity. Predictor
    portfolios exhibit post-publication increases in correlations with other published-predictor
    portfolios. Our findings suggest that investors learn about mispricing from academic
    publications.
- - /docs/sociology/2019-akbari.pdf
  - Kinship, fractionalization and corruption
  - Mahsa Akbari, Duman Bahrami-Rad, Erik O. Kimbrough
  - 2019-08-16
  - 10.1016/j.jebo.2019.07.015
  - ! 'We examine the roots of variation in corruption across societies, and we argue
    that marriage practices and family structure are an important, overlooked determinant
    of corruption. By shaping patterns of relatedness and interaction, marriage practices
    influence the relative returns to norms of nepotism/favoritism versus norms of
    impartial cooperation. In-marriage (e.g. consanguineous marriage) generates fractionalization
    because it yields relatively closed groups of related individuals and thereby
    encourages favoritism and corruption. Out-marriage creates a relatively open society
    with increased interaction between non-relatives and strangers, thereby encouraging
    impartiality. We report a robust association between in-marriage practices and
    corruption both across countries and within countries. Instrumental variables
    estimates exploiting historical variation in preferred marriage practices and
    in exposure to the Catholic Church’s family policies provide evidence that the
    relationship could be causal. [Keywords: Corruption, Fractionalization, Institutions,
    Mating patterns, Consanguinity]'
- - /docs/economics/1996-dempsey.pdf
  - ! 'Taxi Industry Regulation, Deregulation, and Reregulation: The Paradox of Market
    Failure'
  - Paul Stephen Dempsey
  - '1996'
  - ''
  - ! '<p>During the last fifteen years, Congress has deregulated, wholly or partly,
    a number of infrastructure industries, including most modes of transport&mdash;airlines,
    motor carriers, railroads, and intercity bus companies. Deregulation emerged in
    a comprehensive ideological movement which abhorred governmental pricing and entry
    controls as manifestly causing waste and inefficiency, while denying consumers
    the range of price and service options they desire.</p><p>In a nation dedicated
    to free market capitalism, governmental restraints on the freedom to enter into
    a business or allowing the competitive market to set the price seem fundamentally
    at odds with immutable notions of economic liberty. While in the late 19th and
    early 20th Century, market failure gave birth to economic regulation of infrastructure
    industries, today, we live in an era where the conventional wisdom is that government
    can do little good and the market can do little wrong.</p><p>Despite this passionate
    and powerful contemporary political/economic ideological movement, one mode of
    transportation has come full circle from regulation, through deregulation, and
    back again to regulation&mdash;the taxi industry. American cities began regulating
    local taxi firms in the 1920s. Beginning a half century later, more than 20 cities,
    most located in the Sunbelt, totally or partially deregulated their taxi companies.
    However, the experience with taxicab deregulation was so profoundly unsatisfactory
    that virtually every city that embraced it has since jettisoned it in favor of
    resumed economic regulation.</p><p>Today, nearly all large and medium-sized communities
    regulate their local taxicab companies. Typically, regulation of taxicabs involves:
    (1) limited entry (restricting the number of firms, and/or the ratio of taxis
    to population), usually under a standard of "public convenience and necessity,"
    [PC&N] (2) just, reasonable, and non-discriminatory fares, (3) service standards
    (e.g., vehicular and driver safety standards, as well as a common carrier obligation
    of non-discriminatory service, 24-hour radio dispatch capability, and a minimum
    level of response time), and (4) financial responsibility standards (e.g., insurance).</p><p>This
    article explores the legal, historical, economic, and philosophical bases of regulation
    and deregulation in the taxi industry, as well as the empirical results of taxi
    deregulation. The paradoxical metamorphosis from regulation, to deregulation,
    and back again, to regulation is an interesting case study of the collision of
    economic theory and ideology, with empirical reality. We begin with a look at
    the historical origins of taxi regulation.</p> <p>[Keywords: Urban Transportation,
    Taxi Industry, Common Carrier, Mass Transit, Taxi Industry Regulation, Taxi Deregulation,
    Reregulation, Taxicab Ordinance, PUC, Open Entry, Reglated Entry, Operating Efficiency,
    Destructive Competition, Regulated Competition, Cross Subsidy, Cream Skimming,
    PC&N, Pollution, Cabs]</p>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.708.3217&rep=rep1&type=pdf
  - Taxes, Lawyers, and the Decline of Witch Trials in France
  - Noel D. Johnson, Mark Koyama
  - 2014-02-01
  - 10.1086/674900
  - How is rule of law established? We address this question by exploring the effect
    of increases in fiscal capacity on the establishment of well-enforced, formal,
    legal standards in a preindustrial economy. Between 1550 and 1700, there were
    over 2,000 witch trials in France. Prosecuting a witch required local judges to
    significantly deviate from formal rules of evidence. Hence, we exploit the significant
    variation across time and space in witch trials and fiscal capacity across French
    regions between 1550 and 1700 to show that increases in fiscal capacity were associated
    with increased adherence to the formal rule of law. As fiscal capacity increased,
    local judges increasingly upheld de jure rules, and the frequency of witch trials
    declined.
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.364.697&rep=rep1&type=pdf
  - ! 'The Age of Reason: Financial Decisions over the Life Cycle and Implications
    for Regulation'
  - Sumit Agarwal, John C. Driscoll, Xavier Gabaix, David Laibson
  - '2009'
  - 10.1353/eca.0.0067
  - Many consumers make poor financial choices, and older adults are particularly
    vulnerable to such errors. About half of the population between ages 80 and 89
    have a medical diagnosis of substantial cognitive impairment. We study life-cycle
    patterns in financial mistakes using a proprietary database with information on
    10 types of credit transactions. Financial mistakes include suboptimal use of
    credit card balance transfer offers and excess interest rate and fee payments.
    In a cross section of prime borrowers, middle-aged adults made fewer financial
    mistakes than either younger or older adults. We conclude that financial mistakes
    follow a U-shaped pattern, with the cost-minimizing performance occurring around
    age 53. We analyze nine regulatory strategies that may help individuals avoid
    financial mistakes. We discuss laissez-faire, disclosure, nudges, financial "driver's
    licenses," advance directives, fiduciaries, asset safe harbors, and ex post and
    ex ante regulatory oversight. Finally, we pose seven questions for future research
    on cognitive limitations and associated policy responses.
- - https://harpers.org/archive/1998/11/the-radioactive-boy-scout/?single=1
  - ! 'The Radioactive Boy Scout: When a teenager attempts to build a breeder reactor'
  - Ken Silverstein (Harper's)
  - 1998-11-01
  - ''
  - ! 'Growing up in suburban Detroit, David Hahn was fascinated by science. While
    he was working on his Atomic Energy badge for the Boy Scouts, David’s obsessive
    attention turned to nuclear energy. Throwing caution to the wind, he plunged into
    a new project: building a model nuclear reactor in his backyard garden shed. Posing
    as a physics professor, David solicited information on reactor design from the
    U.S. government and from industry experts. Following blueprints he found in an
    outdated physics textbook, David cobbled together a crude device that threw off
    toxic levels of radiation. His wholly unsupervised project finally sparked an
    environmental emergency that put his town’s forty thousand suburbanites at risk.
    The EPA ended up burying his lab at a radioactive dumpsite in Utah. [Keywords:
    20th century, David Hahn, Experiments, Michigan, Nuclear engineering, Radiochemistry,
    Recreation, Teenage boys].'
- - /Embryo-selection#history-of-ies
  - History of IES (Iterated Embryo Selection)
  - Gwern Branwen
  - 2019-01-18
  - ''
  - <p>The idea of <em>iterated embryo selection</em>—conducing multiple generations
    of embryo selection in a petri dish by exploiting gametogenesis or stem cells—has
    a complicated history. Tracing relevant papers back to 1989, the idea appears
    to have been invented independently at least 4 times, and has been proposed under
    as many names.</p><p>A predecessor was introduced by <a href="https://www.gwern.net/docs/genetics/selection/1991-georges.pdf">Georges
    & Massey 1991</a> as “velogenetics”. Velogenetics led to what appears to be the
    first invention of IES, <a href="https://www.gwern.net/docs/genetics/selection/1998-haley.pdf">Haley
    & Visscher 1998’s</a> “whizzogenetics”. It was then invented in 2009 by <a href="https://web.archive.org/web/20091214014113/http://theuncertainfuture.com/faq.html#7">Carl
    Shulman</a> as “iterated embryo selection”/“IES”. It was reinvented a third time
    by <a href="https://pdfs.semanticscholar.org/29d0/884cf4ed6acdb2711f556863a1ef2bd3a908.pdf">Sparrow
    2013</a< as “in vitro eugenics”. And it was reinvented up to three times in 2018,
    as “in vitro breeding”, by <a href="https://www.pnas.org/content/pnas/early/2018/02/08/1716161115.full.pdf">Bogliotti
    et al 2018</a>/<a href="https://www.gwern.net/docs/genetics/selection/2018-goszczynski.pdf">Goszczynski
    et al 2018</a>/<a href="https://jasbsci.biomedcentral.com/articles/10.1186/s40104-018-0304-7">Hou
    et al 2018</a> (whose relationship is unclear, as the latter two claim novelty
    but publish not just the same idea but same name, while the former, published
    before them and giving said name & idea, nevertheless does not claim novelty).</p>
- - /Embryo-selection#glue-robbers-sequencing-nobelists-using-collectible-letters
  - ! 'Glue Robbers: Sequencing Nobelists Using Collectible Letters'
  - Gwern Branwen
  - 2019-03-04
  - ''
  - <p>A major challenge in GWASes of cognitive traits like intelligence &amp; personality
    is getting sufficient statistical power to produce results. Statistical power
    can be increased by increasing sample size, or increasing the ‘effect size’ (ie
    size of differences). One way of increasing effect size is collecting extreme
    datapoints, such as the extremely-high IQ TIP/SMPY samples for comparison with
    a baseline group. As such datapoints are by definition rare, they are hard to
    collect in bulk. This is true for other cognitive traits such as personality,
    ambition, accomplishment, scientific breakthroughs—all of which are surely connected
    with each other &amp; intelligence, but even harder to screen for &amp; collect
    genomes.</p><p>The increasing power of DNA sequencing methods means that as of
    2018, one can extract &amp; sequence DNA from envelopes &amp; postal stamps which
    are decades or centuries old. This is legally permissible, and many such envelopes
    &amp; stamps from historical figures can be bought for low prices. This means
    that one can potentially genotype—in addition to everyone else in the past—the
    greatest minds in history and run analyses. They could be used as an ultra-highly-enriched
    sample in GWASes for intelligence or achievement with potentially high statistical
    power and combined with other datasets for further gains in PGSes.</p>
- - /Embryo-selection#iq-income-bibliography
  - IQ/income bibliography
  - Gwern Branwen
  - 2016-02-17
  - ''
  - Partial bibliography of fulltext papers discussing intelligence and income or
    socioeconomic status.
- - /Embryo-selection#embryo-selection-and-dynasties
  - ! 'Embryo Selection and Dynasties: A Liability Threshold Model'
  - Gwern Branwen
  - 2018-02-08
  - ''
  - <p>Genetic selection &amp; engineering technologies, if banned or highly regulated,
    could exacerbate existing social inequality by increasing genetic differences
    between groups on key traits like intelligence or Conscientiousness or ethnocentrism
    and ensuring near-permanent continuity of wealth or power. Whether this is a serious
    problem quantitatively with feasible levels of embryo selection has not been much
    examined. I consider the specific scenario of a single family, such as a royal
    family or wealthy corporate owner, which wishes to increase the odds of succession
    to a sufficiently-competent heir who can maintain the dynasty. I suggest a toy
    model treating it as a repeated liability-threshold model in which heirs are selected
    as order statistics and if any heir is above a threshold, the dynasty survives
    another generation; given average numbers of generations and heirs, this defines
    a unique threshold of competence. Adding embryo selection turns this into a two-stage
    selection process. In some scenarios, assuming a threshold of ~+1SD and advanced
    polygenic scores for multiple selection, embryo selection could considerably increase
    the lifespan of a dynasty due to tail effects on the increased mean in each stage.</p>
- - /Archiving-URLs#sort---key-compression-trick
  - The <code>sort --key</code> compression trick (CLI folklore)
  - Gwern Branwen
  - 2014-03-03
  - ''
  - <p>Programming folklore notes that one way to get better lossless compression
    efficiency is to rearrange files inside the archive to group ‘similar’ files together
    and expose redundancy to the compressor, in accordance with information-theoretical
    principles. A particularly easy and broadly-applicable way of doing this, which
    does not require using any unusual formats or tools and is fully compatible with
    the default archive methods, is to sort the files by <em>filename</em> and especially
    file extension. I show how to do this with the standard Unix command-line <code>sort</code>
    tool, using the so-called “<code>sort --key</code> trick”, and give examples of
    the large space-savings possible from my archiving work for personal website mirrors
    and for making <a href="/DNM-archives">darknet market mirror datasets</a> where
    the redundancy at the file level is particularly extreme and the <code>sort --key</code>
    trick shines compared to the naive approach.</p>
- - http://www.unm.edu/~gfmiller/newpapers_sept6/penke%202007%20targetarticle.pdf
  - The Evolutionary Genetics of Personality
  - Lars Penke, Jaap J. A. Denissen, Geoffrey F. Miller
  - 2007-04-27
  - 10.1002/per.629
  - ! 'Genetic influences on personality differences are ubiquitous, but their nature
    is not well understood. A theoretical framework might help, and can be provided
    by evolutionary genetics. We assess three evolutionary genetic mechanisms that
    could explain genetic variance in personality differences: selective neutrality,
    mutation-selection balance, and balancing selection. Based on evolutionary genetic
    theory and empirical results from behaviour genetics and personality psychology,
    we conclude that selective neutrality is largely irrelevant, that mutation-selection
    balance seems best at explaining genetic variance in intelligence, and that balancing
    selection by environmental heterogeneity seems best at explaining genetic variance
    in personality traits. We propose a general model of heritable personality differences
    that conceptualises intelligence as fitness components and personality traits
    as individual reaction norms of genotypes across environments, with different
    fitness consequences in different environmental niches. We also discuss the place
    of mental health in the model. This evolutionary genetic framework highlights
    the role of gene-environment interactions in the study of personality, yields
    new insight into the person-situation-debate and the structure of personality,
    and has practical implications for both quantitative and molecular genetic studies
    of personality. [Keywords: evolutionary psychology; personality differences; behaviour
    genetics; intelligence; personality traits; gene-environment interactions; mutation
    load; mutation-selection balance; mutational cross-section; epistasis; frequency-dependent
    selection]'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3590899/
  - Procreative beneficence and <em>in vitro</em> gametogenesis
  - Hannah Bourne, Thomas Douglas, Julian Savulescu
  - 2012-09-01
  - 10.1007/bf03351338
  - ! '<p>The Principle of Procreative Beneficence (PB) holds that when a couple plans
    to have a child, they have significant moral reason to select, of the possible
    children they could have, the child who is most likely to experience the greatest
    wellbeing – that is, the most advantaged child, the child with the best chance
    at the best life....In this paper we wish address a different and more practical
    objection: the objection that parents will be heavily restricted in the number
    of traits that they can select, since they will have to choose among a very limited
    number of embryos. Recent advances in stem cell research may provide a solution
    to this problem. Recent research suggests that it may become possible to derive
    gametes (eggs and sperm) from human stem cells in vitro, a process which we will
    term in vitro gametogenesis (IVG). IVG would allow the creation of stems cells
    from a patient’s somatic (body) cells, and these stems cells could then be used
    to generate a plentiful supply of eggs or sperm in the laboratory....The ability
    to create large numbers of eggs or sperm through IVG greatly increases our capacity
    to select the best child possible. Selection could occur in two ways: (1) the
    most genetically desirable of this massive number of gametes could be selected
    and then used to create an embryo, or alternatively, (2) large numbers of embryos
    could be produced from these gametes and then the best embryo selected. Whatever
    the method, the advent of IVG could allow us to select for a much larger number
    of traits than is currently conceivable.</p><p>...Suppose that a couple would
    like to select for 20 single gene traits which are carried on 20 different and
    unlinked autosomal loci. Suppose further that at ten of these loci, alleles contribute
    recessively to the desired trait...The chance of the couple having such a child
    would be just over 1% with traditional IVF plus selection, but would increased
    to over 99.99% if 10,000 embryos could be created using IVG...By enabling the
    creation of large numbers of gametes and embryos, IVG may allow the selection
    of traits in future children to a degree that has previously been inconceivable.</p>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1030.5102&rep=rep1&type=pdf
  - Incest Laws and Absent Taboos in Roman Egypt
  - Anise K. Strong
  - '2005'
  - 10.2139/ssrn.1596967
  - ! 'For at least two hundred and fifty years, many men in the Roman province of
    Egypt married their full sisters and raised families with them. During the same
    era, Roman law firmly banned close-kin marriages and denounced them both as <em>nefas</em>,
    or sacrilegious, and against the <em>ius gentium</em>, the laws shared by all
    civilized peoples. In Egypt, however, Roman officials deliberately chose not to
    enforce the relevant marriage laws among the Greek metic, hybrid, and native Egyptian
    populations; the bureaucracy also created loopholes within new laws which tolerated
    the practice. This policy created a gap between the absolute theoretical ban in
    Roman law and the reality of common incestuous unions in Egypt. Since Roman Egypt
    was both an important and a dangerous province, Rome needed both to pacify its
    people and to weaken Egypt’s status with its neighbors. By permitting incestuous
    marriages among non-Romans in Egypt, the Roman governors simultaneously pleased
    the local population while causing Jews and North Africans to hold their neighbor
    in contempt. [Keywords: Roman incest, Roman law, Roman Egypt]'
- - /docs/economics/2010-rost.pdf
  - The corporate governance of Benedictine abbeys
  - Katja Rost, Emil Inauen, Margit Osterloh, Bruno S. Frey
  - 2010-01-12
  - 10.1108/17511341011008331
  - ! '<p><em>Purpose</em>: This paper aims to analyse the governance structure of
    monasteries to gain new insights and apply them to solve agency problems of modern
    corporations. In an historic analysis of crises and closures it asks, if Benedictine
    monasteries were and are capable of solving agency problems. The analysis shows
    that monasteries established basic governance instruments very early and therefore
    were able to survive for centuries.</p><p><em>Design/methodology/approach</em>:
    The paper uses a dataset of all Benedictine abbeys that ever existed in Bavaria,
    Baden‐Württemberg, and German‐speaking Switzerland to determine their lifespan
    and the reasons for closures. The governance mechanisms are analyzed in detail.
    Finally, it draws conclusions relevant to the modern corporation. The theoretical
    foundations are based upon principal agency theory, psychological economics, as
    well as embeddedness theory.</p><p><em>Findings</em>: The monasteries that are
    examined show an average lifetime of almost 500 years and only a quarter of them
    dissolved as a result of agency problems. This paper argues that this success
    is due to an appropriate governance structure that relies strongly on internal
    control mechanisms.</p><p><em>Research limitations/implications</em>: Benedictine
    monasteries and stock corporations differ fundamentally regarding their goals.
    Additional limitations of the monastic approach are the tendency to promote groupthink,
    the danger of dictatorship and the life long commitment.</p><p><em>Practical implications</em>:
    The paper adds new insights into the corporate governance debate designed to solve
    current agency problems and facilitate better control.</p><p><em>Originality/value</em>:
    By analyzing monasteries, a new approach is offered to understand the efficiency
    of internal behavioral incentives and their combination with external control
    mechanisms in corporate governance.</p>'
- - https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&topic_id=1
  - Sparkline theory and practice
  - Edward Tufte et al
  - '2004'
  - ''
  - ! '[Originally the draft chapter of the <a href="https://en.wikipedia.org/wiki/Sparkline">sparkline</a>
    ("Intense, Simple, Word-Sized Graphics") chapter of <a href="https://en.wikipedia.org/wiki/Edward_Tufte">Edward
    Tufte''s</a> <em>Beautiful Evidence</em> (2005), this page is a compilation of
    sparkline examples, links to sparkline software tools, and debates over how best
    to use sparklines to graph statistical data.]'
- - /Faces#biggan
  - Generating Anime Faces with BigGAN
  - Gwern Branwen
  - 2019-06-04
  - ''
  - I explore BigGAN, another recent GAN with SOTA results on the most complex image
    domain tackled by GANs so far, ImageNet. BigGAN's capabilities come at a steep
    compute cost, however. I experiment with 128px ImageNet transfer learning (successful)
    with ~6 GPU-days, and from-scratch 256px anime portraits of 1000 characters on
    a 8x2080ti machine for a month (mixed results). My BigGAN results are good but
    compromised by practical problems with the released BigGAN code base. While BigGAN
    is not yet superior to StyleGAN for many purposes, BigGAN-like approaches may
    turn out to be necessary to scale to whole anime images.
- - /docs/sunkcosts/2003-carmichael.pdf
  - ! 'Caring About Sunk Costs: A Behavioral Solution to Holdup Problems With Small
    Stakes'
  - Lorne Carmichael, W. Bentley MacLeod
  - 2003-04-01
  - 10.1093/jleo/19.1.106
  - Economics students need to be taught that opportunity costs are important for
    optimal decision making but that sunk costs are not. Why should this be? Presumably
    these students have been making optimal decisions all their lives, and the concepts
    should be easy for them. We show that caring about sunk costs can help agents
    achieve efficient investments in a simple team production environment. Furthermore,
    the solution we propose is uniquely efficient if the environment is sufficiently
    complex. Hence, in addition to explaining contract form and ownership (Williamson,
    1975; Hart, 1995), studies of the holdup problem may also provide insights into
    observed behavior in day‐today bilateral bargaining problems.
- - /docs/sunkcosts/2010-cohen.pdf
  - Free Distribution or Cost-Sharing? Evidence from a Randomized Malaria Prevention
    Experiment
  - Jessica Cohen, Pascaline Dupas
  - 2010-02-01
  - 10.2307/40506276
  - ! 'It is often argued that cost-sharing—charging a subsidized, positive price—for
    a health product is necessary to avoid wasting resources on those who will not
    use or do not need the product. We explore this argument through a field experiment
    in Kenya, in which we randomized the price at which prenatal clinics could sell
    long-lasting antimalarial insecticide-treated bed nets (ITNs) to pregnant women.
    We find no evidence that cost-sharing reduces wastage on those who will not use
    the product: women who received free ITNs are not less likely to use them than
    those who paid subsidized positive prices. We also find no evidence that cost-sharing
    induces selection of women who need the net more: those who pay higher prices
    appear no sicker than the average prenatal client in the area in terms of measured
    anemia (an important indicator of malaria). Cost-sharing does, however, considerably
    dampen demand. We find that uptake drops by sixty percentage points when the price
    of ITNs increases from zero to $0.60 (i.e., from 100% to 90% subsidy), a price
    still $0.15 below the price at which ITNs are currently sold to pregnant women
    in Kenya. We combine our estimates in a cost-effectiveness analysis of the impact
    of ITN prices on child mortality that incorporates both private and social returns
    to ITN usage. Overall, our results suggest that free distribution of ITNs could
    save many more lives than cost-sharing programs have achieved so far, and, given
    the large positive externality associated with widespread usage of ITNs, would
    likely do so at a lesser cost per life saved. [Keywords: Subsidies, Prices, Malaria,
    Distribution costs, Sharing, Women, Anemia, Cost efficiency, Random allocation,
    Sunk costs]'
- - /docs/sunkcosts/2007-karavanov.pdf
  - ! 'Factors Affecting Entrapment: Justification Needs, Face Concerns, and Personal
    Networks'
  - Anya Karavanov, Deborah A. Cai
  - '2007'
  - 10.2139/ssrn.1087332
  - ! '<p>This study explores the link between the entrapment bias and the concept
    of face (self- and other-positive) and internal and external justification processes.
    It examines how face-saving concerns and justification needs moderate the entrapment
    bias in accountability condition (i.e., presence of constituencies and reporting
    requirements). In addition, this research looks at whether the size and influence
    of personal networks is associated with face-saving behaviors that, in turn, affect
    entrapment. The research also explores whether overall face concerns have an effect
    on internal and external self-justification.</p><p>Participants were 236 undergraduate
    communication majors enrolled in a large East Coast university, who were assigned
    to one of the four conditions: (1) constituency, reporting; (2) constituency,
    no reporting; (3) no constituency; reporting; (4) no constituency; no reporting.</p><p>The
    current investigation did not support the findings from previous studies that
    suggest that justification processes and face concerns lead to entrapment. This
    study found that only internal self-justification and other-positive face concerns
    are related to entrapment, but instead of contributing to entrapment, these aspects
    prevent individuals from becoming entrapped. Personal networks were demonstrated
    to have positive effect on both self- and other-positive face concerns, providing
    empirical support for the value of using personal networks as a predictor of face
    goals. However, personal networks did not contribute to entrapment.</p><p>Overall,
    this study identifies processes and conditions (e.g., concern for other-positive
    face, internal self-justification, reporting requirement, no direct observation
    by constituency, keeping clear record of performance success or failure) that
    may prevent the entrapment bias from occurring. Implications of this research
    are discussed as well as directions for future research.</p>'
- - /docs/sunkcosts/2018-hong.pdf
  - Sunk Cost as a Self-Management Device
  - Fuhai Hong, Wei Huang, Xiaojian Zhao
  - 2018-08-01
  - 10.1287/mnsc.2018.3032
  - <p>The sunk cost effect has been widely observed in individual decisions. Building
    on an intrapersonal self-management game, the paper theoretically shows that the
    sunk cost effect may stem from an attempt to overcome the underinvestment problem
    associated with a high degree of present bias or to resolve the multi-selves coordination
    problem when the degree of present bias is low. Especially for individuals with
    severe present bias, the current self may take a costly action (which is a sunk
    cost for the future self) to signal the individual’s high success probability
    that motivates his future self-disciplining behaviors. In equilibrium, a higher
    level of sunk cost is more likely to give rise to a higher probability for the
    individual to continue the project. We then conduct a laboratory experiment. The
    empirical findings are consistent with our theoretical implications.</p> <p>The
    online appendix is available at <a href="https://doi.org/10.1287/mnsc.2018.3032">10.1287/mnsc.2018.3032</a></p>.
- - https://www.andrew.cmu.edu/user/nicolasc/publications/Christin-WWW13.pdf
  - ! 'Traveling the Silk Road: A Measurement Analysis of a Large Anonymous Online
    Marketplace'
  - Nicolas Christin
  - 2013-05-13
  - 10.1145/2488388.2488408
  - ! 'We perform a comprehensive measurement analysis of Silk Road, an anonymous,
    international online marketplace that operates as a Tor hidden service and uses
    Bitcoin as its exchange currency. We gather and analyze data over eight months
    between the end of 2011 and 2012, including daily crawls of the marketplace for
    nearly six months in 2012. We obtain a detailed picture of the type of goods sold
    on Silk Road, and of the revenues made both by sellers and Silk Road operators.
    Through examining over 24,400 separate items sold on the site, we show that Silk
    Road is overwhelmingly used as a market for controlled substances and narcotics,
    and that most items sold are available for less than three weeks. The majority
    of sellers disappears within roughly three months of their arrival, but a core
    of 112 sellers has been present throughout our measurement interval. We evaluate
    the total revenue made by all sellers,from public listings, to slightly over USD
    1.2 million per month; this corresponds to about USD 92,000 per month in commissions
    for the Silk Road operators. We further show that the marketplace has been operating
    steadily, with daily sales and number of sellers overall increasing over our measurement
    interval. We discuss economic and policy implications of our analysis and results,
    including ethical considerations for future research in this area. [Keywords:
    Online crime, anonymity, electronic commerce]'
- - https://msu.edu/course/eng/487/johnsen/61.1moretti.pdf
  - The Slaughterhouse of Literature
  - Franco Moretti
  - 2000-03-01
  - ''
  - ! '<p>The history of the world is the slaughterhouse of the world, reads a famous
    Hegelian aphorism; and of literature. The majority of books disappear forever—and
    “majority” actually misses the point: if we set today’s canon of nineteenth-century
    British novels at two hundred titles (which is a very high figure), they would
    still be only about 0.5 <em>percent</em> of all published novels.</p> <p>[Literature
    paper by <a href="https://en.wikipedia.org/wiki/Franco_Moretti">Franco Moretti</a>.
    Moretti considers the vast production of literature of which only the slightest
    fraction is still read and studied as part of a ''canon''. Canons are formed by
    market forces, leading to preservation and reading in a feedback loop&mdash;far
    from academics selecting the best based on esthetic grounds. Moretti offers a
    case study of Arthur Conan Doyle''s Sherlock Holmes by comparing to all the now-forgotten
    competing detective fiction, to study the evolution of the idea of a ''clue'';
    his competitors reveal its difficult evolution and how everyone groped towards
    it. Surprisingly, clues were neither obvious nor popular nor showed any clear
    evolution towards success. This raises puzzling questions about how to create
    and interpret ''literary history''.]</p>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.508.2792&rep=rep1&type=pdf
  - Does High Self-Esteem Cause Better Performance, Interpersonal Success, Happiness,
    Or Healthier Lifestyles?
  - Roy F. Baumeister, Jennifer D. Campbell, Joachim I. Krueger, Kathleen D. Vohs
  - 2003-05-01
  - 10.1111/1529-1006.01431
  - ! '<p>Self-esteem has become a household word. Teachers, parents, therapists,
    and others have focused efforts on boosting self-esteem, on the assumption that
    high self-esteem will cause many positive outcomes and benefits—an assumption
    that is critically evaluated in this review.</p><p>Appraisal of the effects of
    self-esteem is complicated by several factors. Because many people with high self-esteem
    exaggerate their successes and good traits, we emphasize objective measures of
    outcomes. High self-esteem is also a heterogeneous category, encompassing people
    who frankly accept their good qualities along with narcissistic, defensive, and
    conceited individuals.</p><p>The modest correlations between self-esteem and school
    performance do not indicate that high self-esteem leads to good performance. Instead,
    high self-esteem is partly the result of good school performance. Efforts to boost
    the self-esteem of pupils have not been shown to improve academic performance
    and may sometimes be counterproductive. Job performance in adults is sometimes
    related to self-esteem, although the correlations vary widely, and the direction
    of causality has not been established. Occupational success may boost self-esteem
    rather than the reverse. Alternatively, self-esteem may be helpful only in some
    job contexts. Laboratory studies have generally failed to find that self-esteem
    causes good task performance, with the important exception that high self-esteem
    facilitates persistence after failure.</p><p>People high in self-esteem claim
    to be more likable and attractive, to have better relationships, and to make better
    impressions on others than people with low self-esteem, but objective measures
    disconfirm most of these beliefs. Narcissists are charming at first but tend to
    alienate others eventually. Self-esteem has not been shown to predict the quality
    or duration of relationships.</p><p>High self-esteem makes people more willing
    to speak up in groups and to criticize the group’s approach. Leadership does not
    stem directly from self-esteem, but self-esteem may have indirect effects. Relative
    to people with low self-esteem, those with high self-esteem show stronger in-group
    favoritism, which may increase prejudice and discrimination.</p><p>Neither high
    nor low self-esteem is a direct cause of violence. Narcissism leads to increased
    aggression in retaliation for wounded pride. Low self-esteem may contribute to
    externalizing behavior and delinquency, although some studies have found that
    there are no effects or that the effect of self-esteem vanishes when other variables
    are controlled. The highest and lowest rates of cheating and bullying are found
    in different subcategories of high self-esteem.</p><p>Self-esteem has a strong
    relation to happiness. Although the research has not clearly established causation,
    we are persuaded that high self-esteem does lead to greater happiness. Low self-esteem
    is more likely than high to lead to depression under some circumstances. Some
    studies support the buffer hypothesis, which is that high self-esteem mitigates
    the effects of stress, but other studies come to the opposite conclusion, indicating
    that the negative effects of low self-esteem are mainly felt in good times. Still
    others find that high self-esteem leads to happier outcomes regardless of stress
    or other circumstances.</p><p>High self-esteem does not prevent children from
    smoking, drinking, taking drugs, or engaging in early sex. If anything, high self-esteem
    fosters experimentation, which may increase early sexual activity or drinking,
    but in general effects of self-esteem are negligible. One important exception
    is that high self-esteem reduces the chances of bulimia in females.</p><p>Overall,
    the benefits of high self-esteem fall into two categories: enhanced initiative
    and pleasant feelings. We have not found evidence that boosting self-esteem (by
    therapeutic interventions or school programs) causes benefits. Our findings do
    not support continued widespread efforts to boost self-esteem in the hope that
    it will by itself foster improved outcomes. In view of the heterogeneity of high
    self-esteem, indiscriminate praise might just as easily promote narcissism, with
    its less desirable consequences. Instead, we recommend using praise to boost self-esteem
    as a reward for socially desirable behavior and self-improvement.</p>'
- - /docs/iq/1969-jensen-her.pdf
  - How Much Can We Boost IQ and Scholastic Achievement?
  - Arthur R. Jensen
  - 1969-05-01
  - 10.17763/haer.39.1.l3u15956627424k7
  - ! '<p>Arthur Jensen argues that the failure of recent compensatory education efforts
    to produce lasting effects on children''s IQ and achievement suggests that the
    premises on which these efforts have been based should be reexamined. He begins
    by questioning a central notion upon which these and other educational programs
    have recently been based: that IQ differences are almost entirely a result of
    environmental differences and the cultural bias of IQ tests. After tracing the
    history of IQ tests, Jensen carefully defines the concept of IQ, pointing out
    that it appears as a common factor in all tests that have been devised thus far
    to tap higher mental processes. Having defined the concept of intelligence and
    related it to other forms of mental ability, Jensen employs an analysis of variance
    model to explain how IQ can be separated into genetic and environmental components.
    He then discusses the concept of "heritability," a statistical tool for assessing
    the degree to which individual differences in a trait like intelligence can be
    accounted for by genetic factors. He analyzes several lines of evidence which
    suggest that the heritability of intelligence is quite high (i.e., genetic factors
    are much more important than environmental factors in producing IQ differences).
    After arguing that environmental factors are not nearly as important in determining
    IQ as are genetic factors, Jensen proceeds to analyze the environmental influences
    which may be most critical in determining IQ. He concludes that prenatal influences
    may well contribute the largest environmental influence on IQ. He then discusses
    evidence which suggests that social class and racial variations in intelligence
    cannot be accounted for by differences in environment but must be attributed partially
    to genetic differences. After he has discussed the influence on the distribution
    of IQ in a society on its functioning, Jensen examines in detail the results of
    educational programs for young children, and finds that the changes in IQ produced
    by these programs are generally small. A basic conclusion of Jensen''s discussion
    of the influence of environment on IQ is that environment acts as a "threshold
    variable." Extreme environmental deprivation can keep the child from performing
    up to his genetic potential, but an enriched educational program cannot push the
    child above that potential. Finally, Jensen examines other mental abilities that
    might be capitalized on in an educational program, discussing recent findings
    on diverse patterns of mental abilities between ethnic groups and his own studies
    of associative learning abilities that are independent of social class. He concludes
    that educational attempts to boost IQ have been misdirected and that the educational
    process should focus on teaching much more specific skills. He argues that this
    will be accomplished most effectively if educational methods are developed which
    are based on other mental abilities besides I.Q.'
- - /docs/statistics/causality/1987-fraker.pdf
  - The Adequacy of Comparison Group Designs for Evaluations of Employment-Related
    Programs
  - Thomas Fraker, Rebecca Maynard
  - '1987'
  - 10.2307/145902
  - ! 'This study investigates empirically the strengths and limitations of using
    experimental versus nonexperimental designs for evaluating employment and training
    programs. The assessment involves comparing results from an experimental-design
    study-the National Supported Work Demonstration-with the estimated impacts of
    Supported Work based on analyses using comparison groups constructed from the
    Current Population Surveys. The results indicate that nonexperimental designs
    cannot be relied on to estimate the effectiveness of employment programs. Impact
    estimates tend to be sensitive both to the comparison group construction methodology
    and to the analytic model used. There is currently no way a priori to ensure that
    the results of comparison group studies will be valid indicators of the program
    impacts. [Keywords: Public assistance programs, Analytical models, Analytical
    estimating, Employment, Control groups, Estimation methods, Random sampling, Human
    resources, Public works legislation, Statistical significance]'
- - /docs/radiance/1995-mackenzie.pdf
  - Tacit Knowledge, Weapons Design, and the Uninvention of Nuclear Weapons
  - Donald MacKenzie, Graham Spinardi
  - '1995'
  - 10.1086/230699
  - Tacit knowledge, embodied in people rather than words, equations,or diagrams,
    plays a vital role in science. The historical record of the development and spread
    of nuclear weapons and the recollections of their designers suggest that tacit
    knowledge is also crucial to nuclear weapons development. Therefore, if design
    ceases, and if there is no new generation of designers to whom that tacit knowledge
    can be passed, then in an important (though qualified) sense nuclear weapons will
    have been uninvented. Their renewed development would thus have some of the characteristics
    of reinvention rather than simply copying. In addition, knowledge may be lost
    not only as a result of complete disarmament, but also as a consequence of likely
    measures such as a nuclear test ban.
- - /docs/iq/2018-lee.pdf
  - Gene discovery and polygenic prediction from a genome-wide association study of
    educational attainment in 1.1 million individuals
  - James J. Lee, Robbee Wedow, Aysu Okbay, Edward Kong, Omeed Maghzian, Meghan Zacher,
    Tuan Anh Nguyen-Viet, Peter Bowers, Julia Sidorenko, Richard Karlsson Linnér,
    Mark Alan Fontana, Tushar Kundu, Chanwook Lee, Hui Li, Ruoxi Li, Rebecca Royer,
    Pascal N. Timshel, Raymond K. Walters, Emily A. Willoughby, Loïc Yengo, 23andMe
    Research Team, COGENT (Cognitive Genomics Consortium), Social Science Genetic
    Association Consortium, Maris Alver, Yanchun Bao, David W. Clark, Felix R. Day,
    Nicholas A. Furlotte, Peter K. Joshi, Kathryn E. Kemper, Aaron Kleinman, Claudia
    Langenberg, Reedik Mägi, Joey W. Trampush, Shefali Setia Verma, Yang Wu, Max Lam,
    Jing Hua Zhao, Zhili Zheng, Jason D. Boardman, Harry Campbell, Jeremy Freese,
    Kathleen Mullan Harris, Caroline Hayward, Pamela Herd, Meena Kumari, Todd Lencz,
    Jian’an Luan, Anil K. Malhotra, Andres Metspalu, Lili Milani, Ken K. Ong, John
    R. B. Perry, David J. Porteous, Marylyn D. Ritchie, Melissa C. Smart, Blair H.
    Smith, Joyce Y. Tung, Nicholas J. Wareham, James F. Wilson, Jonathan P. Beauchamp,
    Dalton C. Conley, Tõnu Esko, Steven F. Lehrer, Patrik K. E. Magnusson, Sven Oskarsson,
    Tune H. Pers, Matthew R. Robinson, Kevin Thom, Chelsea Watson, Christopher F.
    Chabris, Michelle N. Meyer, David I. Laibson, Jian Yang, Magnus Johannesson, Philipp
    D. Koellinger, Patrick Turley, Peter M. Visscher, Daniel J. Benjamin & David Cesarini
  - 10.1038/s41588-018-0147-3
  - 2018-07-23
  - Here we conducted a large-scale genetic association analysis of educational attainment
    in a sample of approximately 1.1 million individuals and identify 1,271 independent
    genome-wide-significant SNPs. For the SNPs taken together, we found evidence of
    heterogeneous effects across environments. The SNPs implicate genes involved in
    brain-development processes and neuron-to-neuron communication. In a separate
    analysis of the X chromosome, we identify 10 independent genome-wide-significant
    SNPs and estimate a SNP heritability of around 0.3% in both men and women, consistent
    with partial dosage compensation. A joint (multi-phenotype) analysis of educational
    attainment and three related cognitive phenotypes generates polygenic scores that
    explain 11–13% of the variance in educational attainment and 7–10% of the variance
    in cognitive performance. This prediction accuracy substantially increases the
    utility of polygenic scores as tools in research.
- - /docs/iq/2016-okbay-2.pdf
  - Genome-wide association study identifies 74 loci associated with educational attainment
  - Aysu Okbay, Jonathan P. Beauchamp, Mark Alan Fontana, James J. Lee, Tune H. Pers,
    Cornelius A. Rietveld, Patrick Turley, Guo-Bo Chen, Valur Emilsson, S. Fleur W.
    Meddens, Sven Oskarsson, Joseph K. Pickrell, Kevin Thom, Pascal Timshel, Ronald
    de Vlaming, Abdel Abdellaoui, Tarunveer S. Ahluwalia, Jonas Bacelis, Clemens Baumbach,
    Gyda Bjornsdottir, Johannes H. Brandsma, Maria Pina Concas, Jaime Derringer, Nicholas
    A. Furlotte, Tessel E. Galesloot, Giorgia Girotto, Richa Gupta, Leanne M. Hall,
    Sarah E. Harris, Edith Hofer, Momoko Horikoshi, Jennifer E. Huffman, Kadri Kaasik,
    Ioanna P. Kalafati, Robert Karlsson, Augustine Kong, Jari Lahti, Sven J. van der  Lee,
    Christiaan de Leeuw, Penelope A. Lind, Karl-Oskar Lindgren, Tian Liu, Massimo
    Mangino, Jonathan Marten, Evelin Mihailov, Michael B. Miller, Peter J. van der
    Most, Christopher Oldmeadow, Antony Payton, Natalia Pervjakova, Wouter J. Peyrot,
    Yong Qian, Olli Raitakari, Rico Rueedi, Erika Salvi, Börge Schmidt, Katharina
    E. Schraut, Jianxin Shi, Albert V. Smith, Raymond A. Poot, Beate St Pourcain,
    Alexander Teumer, Gudmar Thorleifsson, Niek Verweij, Dragana Vuckovic, Juergen
    Wellmann, Harm-Jan Westra, Jingyun Yang, Wei Zhao, Zhihong Zhu, Behrooz Z. Alizadeh,
    Najaf Amin, Andrew Bakshi, Sebastian E. Baumeister, Ginevra Biino, Klaus Bønnelykke,
    Patricia A. Boyle, Harry Campbell, Francesco P. Cappuccio, Gail Davies, Jan-Emmanuel
    De Neve, Panos Deloukas, Ilja Demuth, Jun Ding, Peter Eibich, Lewin Eisele, Niina
    Eklund, David M. Evans, Jessica D. Faul, Mary F. Feitosa, Andreas J. Forstner,
    Ilaria Gandin, Bjarni Gunnarsson, Bjarni V. Halldórsson, Tamara B. Harris, Andrew
    C. Heath, Lynne J. Hocking, Elizabeth G. Holliday, Georg Homuth, Michael A. Horan,
    Jouke-Jan Hottenga, Philip L. de Jager, Peter K. Joshi, Astanand Jugessur, Marika
    A. Kaakinen, Mika Kähönen, Stavroula Kanoni, Liisa Keltigangas-Järvinen, Lambertus
    A. L. M. Kiemeney, Ivana Kolcic, Seppo Koskinen, Aldi T. Kraja, Martin Kroh, Zoltan
    Kutalik, Antti Latvala, Lenore J. Launer, Maël P. Lebreton, Douglas F. Levinson,
    Paul Lichtenstein, Peter Lichtner, David C. M. Liewald, LifeLines Cohort Study,
    Anu Loukola, Pamela A. Madden, Reedik Mägi, Tomi Mäki-Opas, Riccardo E. Marioni,
    Pedro Marques-Vidal, Gerardus A. Meddens, George McMahon, Christa Meisinger, Thomas
    Meitinger, Yusplitri Milaneschi, Lili Milani, Grant W. Montgomery, Ronny Myhre,
    Christopher P. Nelson, Dale R. Nyholt, William E. R. Ollier, Aarno Palotie, Lavinia
    Paternoster, Nancy L. Pedersen, Katja E. Petrovic, David J. Porteous, Katri Räikkönen,
    Susan M. Ring, Antonietta Robino, Olga Rostapshova, Igor Rudan, Aldo Rustichini,
    Veikko Salomaa, Alan R. Sanders, Antti-Pekka Sarin, Helena Schmidt, Rodney J.
    Scott, Blair H. Smith, Jennifer A. Smith, Jan A. Staessen, Elisabeth Steinhagen-Thiessen,
    Konstantin Strauch, Antonio Terracciano, Martin D. Tobin, Sheila Ulivi, Simona
    Vaccargiu, Lydia Quaye, Frank J. A. van Rooij, Cristina Venturini, Anna A. E.
    Vinkhuyzen, Uwe Völker, Henry Völzke, Judith M. Vonk, Diego Vozzi, Johannes Waage,
    Erin B. Ware, Gonneke Willemsen, John R. Attia, David A. Bennett, Klaus Berger,
    Lars Bertram, Hans Bisgaard, Dorret I. Boomsma, Ingrid B. Borecki, Ute Bültmann,
    Christopher F. Chabris, Francesco Cucca, Daniele Cusi, Ian J. Deary, George V.
    Dedoussis, Cornelia M. van Duijn, Johan G. Eriksson, Barbara Franke, Lude Franke,
    Paolo Gasparini, Pablo V. Gejman, Christian Gieger, Hans-Jörgen Grabe, Jacob Gratten,
    Patrick J. F. Groenen, Vilmundur Gudnason, Pim van der Harst, Caroline Hayward,
    David A. Hinds, Wolfgang Hoffmann, Elina Hyppönen, William G. Iacono, Bo Jacobsson,
    Marjo-Riitta Järvelin, Karl-Heinz Jöckel, Jaakko Kaprio, Sharon L. R. Kardia,
    Terho Lehtimäki, Steven F. Lehrer, Patrik K. E. Magnusson, Nicholas G. Martin,
    Matt McGue, Andres Metspalu, Neil Pendleton, Brenda W. J. H. Penninx, Markus Perola,
    Nicola Pirastu, Mario Pirastu, Ozren Polasek, Danielle Posthuma, Christine Power,
    Michael A. Province, Nilesh J. Samani, David Schlessinger, Reinhold Schmidt, Thorkild
    I. A. Sørensen, Tim D. Spector, Kari Stefansson, Unnur Thorsteinsdottir, A. Roy
    Thurik, Nicholas J. Timpson, Henning Tiemeier, Joyce Y. Tung, André G. Uitterlinden,
    Veronique Vitart, Peter Vollenweider, David R. Weir, James F. Wilson, Alan F.
    Wright, Dalton C. Conley, Robert F. Krueger, George Davey Smith, Albert Hofman,
    David I. Laibson, Sarah E. Medland, Michelle N. Meyer, Jian Yang, Magnus Johannesson,
    Tõnu Esko, Peter M. Visscher, Philipp D. Koellinger, David Cesarini, Daniel J.
    Benjamin
  - 2016-05-11
  - 10.1038/nature17671
  - Educational attainment is strongly influenced by social and other environmental
    factors, but genetic factors are estimated to account for at least 20% of the
    variation across individuals<sup><a href="/docs/iq/2013-rietveld.pdf">1</a></sup>.
    Here we report the results of a genome-wide association study (GWAS) for educational
    attainment that extends our earlier discovery sample<sup>1,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4375246/"
    title="Replicability and robustness of genome-wide-association studies for behavioral
    traits">2</a></sup> of 101,069 individuals to 293,723 individuals, and a replication
    study in an independent sample of 111,349 individuals from the UK Biobank. We
    identify 74 genome-wide significant loci associated with the number of years of
    schooling completed. Single-nucleotide polymorphisms associated with educational
    attainment are disproportionately found in genomic regions regulating gene expression
    in the fetal brain. Candidate genes are preferentially expressed in neural tissue,
    especially during the prenatal period, and enriched for biological pathways involved
    in neural development. Our findings demonstrate that, even for a behavioural phenotype
    that is mostly environmentally determined, a well-powered GWAS identifies replicable
    associated genetic variants that suggest biologically relevant pathways. Because
    educational attainment is measured in large numbers of individuals, it will continue
    to be useful as a proxy phenotype in efforts to characterize the genetic influences
    of related phenotypes, including cognition and neuropsychiatric diseases.
- - /docs/iq/2013-rietveld.pdf
  - GWAS of 126,559 Individuals Identifies Genetic Variants Associated with Educational
    Attainment
  - Cornelius A. Rietveld, Sarah E. Medland, Jaime Derringer, Jian Yang, Tõnu Esko,
    Nicolas W. Martin, Harm-Jan Westra, Konstantin Shakhbazov, Abdel Abdellaoui, Arpana
    Agrawal, Eva Albrecht, Behrooz Z. Alizadeh, Najaf Amin, John Barnard, Sebastian
    E. Baumeister, Kelly S. Benke, Lawrence F. Bielak, Jeffrey A. Boatman, Patricia
    A. Boyle, Gail Davies, Christiaan de Leeuw, Niina Eklund, Daniel S. Evans, Rudolf
    Ferhmann, Krista Fischer, Christian Gieger, Håkon K. Gjessing, Sara Hägg, Jennifer
    R. Harris, Caroline Hayward, Christina Holzapfel, Carla A. Ibrahim-Verbaas, Erik
    Ingelsson, Bo Jacobsson, Peter K. Joshi, Astanand Jugessur, Marika Kaakinen, Stavroula
    Kanoni, Juha Karjalainen, Ivana Kolcic, Kati Kristiansson, Zoltán Kutalik, Jari
    Lahti, Sang H. Lee, Peng Lin, Penelope A. Lind, Yongmei Liu, Kurt Lohman, Marisa
    Loitfelder, George McMahon, Pedro Marques Vidal, Osorio Meirelles, Lili Milani,
    Ronny Myhre, Marja-Liisa Nuotio, Christopher J. Oldmeadow, Katja E. Petrovic,
    Wouter J. Peyrot, Ozren Polašek, Lydia Quaye, Eva Reinmaa, John P. Rice, Thais
    S. Rizzi, Helena Schmidt, Reinhold Schmidt, Albert V. Smith, Jennifer A. Smith,
    Toshiko Tanaka, Antonio Terracciano, Matthijs J. H. M. van der Loos, Veronique
    Vitart, Henry Völzke, Jürgen Wellmann, Lei Yu, Wei Zhao, Jüri Allik, John R. Attia,
    Stefania Bandinelli, François Bastardot, Jonathan Beauchamp, David A. Bennett,
    Klaus Berger, Laura J. Bierut, Dorret I. Boomsma, Ute Bültmann, Harry Campbell,
    Christopher F. Chabris, Lynn Cherkas, Mina K. Chung, Francesco Cucca, Mariza de
    Andrade, Philip L. De Jager, Jan-Emmanuel De Neve, Ian J. Deary, George V. Dedoussis,
    Panos Deloukas, Maria Dimitriou, Guðný Eiríksdóttir, Martin F. Elderson, Johan
    G. Eriksson, David M. Evans, Jessica D. Faul, Luigi Ferrucci, Melissa E. Garcia,
    Henrik Grönberg, Vilmundur Guðnason, Per Hall, Juliette M. Harris, Tamara B. Harris,
    Nicholas D. Hastie, Andrew C. Heath, Dena G. Hernandez, Wolfgang Hoffmann, Adriaan
    Hofman, Rolf Holle, Elizabeth G. Holliday, Jouke-Jan Hottenga, William G. Iacono,
    Thomas Illig, Marjo-Riitta Järvelin, Mika Kähönen, Jaakko Kaprio, Robert M. Kirkpatrick,
    Matthew Kowgier, Antti Latvala, Lenore J. Launer, Debbie A. Lawlor, Terho Lehtimäki,
    Jingmei Li, Paul Lichtenstein, Peter Lichtner, David C. Liewald, Pamela A. Madden,
    Patrik K. E. Magnusson, Tomi E. Mäkinen, Marco Masala, Matt McGue, Andres Metspalu,
    Andreas Mielck, Michael B. Miller, Grant W. Montgomery, Sutapa Mukherjee, Dale
    R. Nyholt, Ben A. Oostra, Lyle J. Palmer, Aarno Palotie, Brenda W. J. H. Penninx,
    Markus Perola, Patricia A. Peyser, Martin Preisig, Katri Räikkönen, Olli T. Raitakari,
    Anu Realo, Susan M. Ring, Samuli Ripatti, Fernando Rivadeneira, Igor Rudan, Aldo
    Rustichini, Veikko Salomaa, Antti-Pekka Sarin, David Schlessinger, Rodney J. Scott,
    Harold Snieder, Beate St Pourcain, John M. Starr, Jae Hoon Sul, Ida Surakka, Rauli
    Svento, Alexander Teumer, The LifeLines Cohort Study, Henning Tiemeier, Frank
    J. A. van Rooij, David R. Van Wagoner, Erkki Vartiainen, Jorma Viikari, Peter
    Vollenweider, Judith M. Vonk, Gérard Waeber, David R. Weir, H.-Erich Wichmann,
    Elisabeth Widen, Gonneke Willemsen, James F. Wilson, Alan F. Wright, Dalton Conley,
    George Davey-Smith, Lude Franke, Patrick J. F. Groenen, Albert Hofman, Magnus
    Johannesson, Sharon L. R. Kardia, Robert F. Krueger, David Laibson, Nicholas G.
    Martin, Michelle N. Meyer, Danielle Posthuma, A. Roy Thurik, Nicholas J. Timpson,
    André G. Uitterlinden, Cornelia M. van Duijn, Peter M. Visscher, Daniel J. Benjamin,
    David Cesarini, Philipp D. Koellinger
  - 2013-06-21
  - 10.1126/science.1235488
  - ! '<p>A genome-wide association study (GWAS) of educational attainment was conducted
    in a discovery sample of 101,069 individuals and a replication sample of 25,490.
    Three independent single-nucleotide polymorphisms (SNPs) are genome-wide significant
    (rs9320913, rs11584700, rs4851266), and all three replicate. Estimated effects
    sizes are small (coefficient of determination R<sup>2</sup> ≈ 0.02%), approximately
    1 month of schooling per allele. A linear polygenic score from all measured SNPs
    accounts for ≈2% of the variance in both educational attainment and cognitive
    function. Genes in the region of the loci have previously been associated with
    health, cognitive, and central nervous system phenotypes, and bioinformatics analyses
    suggest the involvement of the anterior caudate nucleus. These findings provide
    promising candidate SNPs for follow-up work, and our effect size estimates can
    anchor power analyses in social-science genetics.</p><p>[A landmark study in behavioral
    genetics and intelligence: the first well-powered GWAS to detect genetic variants
    for intelligence and education which replicate out of sample and are proven to
    be causal in a between-sibling study.]</p>'
- - /docs/genetics/selection/2017-kong.pdf
  - Selection against variants in the genome associated with educational attainment
  - Augustine Kong, Michael L. Frigge, Gudmar Thorleifsson, Hreinn Stefansson, Alexander
    I. Young, Florian Zink, Gudrun A. Jonsdottir, Aysu Okbay, Patrick Sulem, Gisli
    Masson, Daniel F. Gudbjartsson, Agnar Helgason, Gyda Bjornsdottir, Unnur Thorsteinsdottir,
    Kari Stefansson
  - 2017-01-11
  - 10.1073/pnas.1612113114
  - <p>Epidemiological studies suggest that educational attainment is affected by
    genetic variants. Results from recent genetic studies allow us to construct a
    score from a person’s genotypes that captures a portion of this genetic component.
    Using data from Iceland that include a substantial fraction of the population
    we show that individuals with high scores tend to have fewer children, mainly
    because they have children later in life. Consequently, the average score has
    been decreasing over time in the population. The rate of decrease is small per
    generation but marked on an evolutionary timescale. Another important observation
    is that the association between the score and fertility remains highly significant
    after adjusting for the educational attainment of the individuals.</p> <p>Epidemiological
    and genetic association studies show that genetics play an important role in the
    attainment of education. Here, we investigate the effect of this genetic component
    on the reproductive history of 109,120 Icelanders and the consequent impact on
    the gene pool over time. We show that an educational attainment polygenic score,
    POLY<sub>EDU</sub>, constructed from results of a recent study is associated with
    delayed reproduction (<em>p</em> &lt; 10<sup>−100</sup>) and fewer children overall.
    The effect is stronger for women and remains highly significant after adjusting
    for educational attainment. Based on 129,808 Icelanders born between 1910 and
    1990, we find that the average POLY<sub>EDU</sub> has been declining at a rate
    of ∼0.010 standard units per decade, which is substantial on an evolutionary timescale.
    Most importantly, because POLY<sub>EDU</sub> only captures a fraction of the overall
    underlying genetic component the latter could be declining at a rate that is two
    to three times faster.</p>
- - /docs/catnip/1999-bradshaw.pdf
  - ! 'Feral cats: their role in the population dynamics of <em>Felis catus</em>'
  - J.W.S. Bradshaw, G. F. Horsfield, J.A. Allen, I.H. Robinson
  - 1999-12
  - 10.1016/s0168-1591(99)00086-6
  - ! 'The so-called domestic cat occupies a unique position within the truly domestic
    animals since it freely interbreeds with feral populations, and there is considerable
    gene flow in both directions. This is possible because the likelihood of an individual
    cat forming a relationship with people is strongly affected by its experiences
    during the socialisation period (3–8 weeks of age), although this does not preclude
    differences between owned and feral populations in the relative frequencies of
    alleles which affect social behaviour towards humans. We suggest a hitherto unconsidered
    reason why a separate domesticated population of cats (apart from pedigree breeds)
    has not yet emerged: the unusual and stringent nutrient requirements of the cat
    may historically have militated against successful breeding on a completely human-provided
    diet, and led to the retention of the ability to achieve a nutritionally complete
    diet by scavenging and/or hunting. More recently, the widespread availability
    of nutritionally complete manufactured foods and veterinary care in western countries
    appears to be leading towards a rapid change in the population dynamics and population
    genetics of both owned and feral cats. [Keywords: Domestication, Feral populations,
    Population dynamics, Cat]'
- - http://www1.udel.edu/educ/gottfredson/reprints/1997whygmatters.pdf
  - ! 'Why <em>g</em> matters: The complexity of everyday life'
  - Linda S. Gottfredson
  - 1997-01
  - 10.1016/S0160-2896(97)90014-3
  - Personnel selection research provides much evidence that intelligence (g) is an
    important predictor of performance in training and on the job, especially in higher
    level work. This article provides evidence that <em>g</em> has pervasive utility
    in work settings because it is essentially the ability to deal with cognitive
    complexity, in particular, with complex information processing. The more complex
    a work task, the greater the advantages that higher <em>g</em> confers in performing
    it well. Everyday tasks, like job duties, also differ in their level of complexity.
    The importance of intelligence therefore differs systematically across different
    arenas of social life as well as economic endeavor. Data from the National Adult
    Literacy Survey are used to show how higher levels of cognitive ability systematically
    improve individual's odds of dealing successfully with the ordinary demands of
    modern life (such as banking, using maps and transportation schedules, reading
    and understanding forms, interpreting news articles). These and other data are
    summarized to illustrate how the advantages of higher <em>g</em>, even when they
    are small, cumulate to affect the overall life chances of individuals at different
    ranges of the IQ bell curve. The article concludes by suggesting ways to reduce
    the risks for low-IQ individuals of being left behind by an increasingly complex
    postindustrial economy.
- - http://movies2.nytimes.com/books/first/b/budiansky-lion.html
  - ! 'If a Lion Could Talk: Animal Intelligence and the Evolution of Consciousness'
  - Stephen Budiansky (NYT)
  - 1998-12-13
  - ''
  - ! '<p>[Excerpts from <a href="https://www.amazon.com/Lion-Could-Talk-Intelligence-Consciousness/dp/0684837102"><em>If
    a Lion Could Talk: Animal Intelligence and the Evolution of Consciousness</em></a>,
    Budiansky 1998 (ISBN 0684837102).]</p><p>How many of us have caught ourselves
    gazing into the eyes of a pet, wondering what thoughts lie behind those eyes?
    Or fallen into an argument over which is smarter, the dog or the cat? Scientists
    have conducted elaborate experiments trying to ascertain whether animals from
    chimps to pigeons can communicate, count, reason, or even lie. So does science
    tell us what we assume&mdash;that animals are pretty much like us, only not as
    smart? Simply, no. Now, in this superb book, Stephen Budiansky poses the fundamental
    question: "What is intelligence?" His answer takes us on the ultimate wildlife
    adventure to animal consciousness. Budiansky begins by exposing our tendency to
    see ourselves in animals. Our anthropomorphism allows us to perceive intelligence
    only in behavior that mimics our own. This prejudice, he argues, betrays a lack
    of imagination. Each species is so specialized that most of their abilities are
    simply not comparable. At the mercy of our anthropomorphic tendencies, we continue
    to puzzle over pointless issues like whether a wing or an arm is better, or whether
    night vision is better than day vision, rather than discovering the real world
    of a winged nighthawk, a thoroughbred horse, or an African lion. Budiansky investigates
    the sometimes bizarre research behind animal intelligence experiments: from horses
    who can count or ace history quizzes, and primates who seem fluent in sign language,
    to rats who seem to have become self-aware, he reveals that often these animals
    are responding to our tiny unconscious cues. And, while critically discussing
    scientists'' interpretations of animal intelligence, he is able to lay out their
    discoveries in terms of what we know about ourselves. For instance, by putting
    you in the minds of dogs or bees who travel by dead reckoning, he demonstrates
    that this is also how you find your way down a familiar street with almost no
    conscious awareness of your navigation system. Modern cognitive science and the
    new science of evolutionary ecology are beginning to show that thinking in animals
    is tremendously complex and wonderful in its variety. A pigeon''s ability to find
    its way home from almost anywhere has little to do with comparative intelligence;
    rather it is due to the pigeon''s very different perception of the world. That''s
    why, as Wittgenstein said, "If a lion could talk, we would not understand him."
    In this fascinating book, Budiansky frees us from the shackles of our ideas about
    the natural world, and opens a window to the astounding worlds of the animals
    that surround us.</p>'
- - /Complexity-vs-AI#technology-forecasting-errors-functional-fixedness-in-assuming-dependencies
  - ! 'Technology forecasting errors: functional fixedness in assuming dependencies'
  - Gwern Branwen
  - 2018-01-29
  - ''
  - <p>A classic cognitive bias in technological forecasting is motivated-stopping
    and lack of imagination in considering possibilities. Many people use a mental
    model of technologies in which they proceed in a serial sequential fashion and
    assume every step is necessary and only all together are they sufficient, and
    note that some particular step is difficult or unlikely to succeed and thus as
    a whole it will fail &amp; never happen. But in reality, few steps are truly required.
    A technology only needs to succeed in one way to succeed, and to fail it must
    fail in all ways. There may be many ways to work around, approximate, brute force,
    reduce the need for, or skip entirely a step, or redefine the problem to no longer
    involve that step at all. Examples of this include the parallel projects used
    by the Manhattan Project &amp; Apollo program, which reasoned that despite the
    formidable difficulties in each path to the end goal, at least one would work
    out—and they did. In forecasting, to counter this bias, one should make a strong
    effort to imagine <em>all</em> possible alternatives which could be pursued in
    parallel, and remember that overall failure requires <em>all</em> of them to fail.</p>
- - /docs/iq/2018-plomin.pdf
  - The new genetics of intelligence
  - Robert Plomin, Sophie von Stumm
  - '2018'
  - 10.1038/nrg.2017.104
  - Intelligence—the ability to learn, reason and solve problems—is at the forefront
    of behavioural genetic research. Intelligence is highly heritable and predicts
    important educational, occupational and health outcomes better than any other
    trait. Recent genome-wide association studies have successfully identified inherited
    genome sequence differences that account for 20% of the 50% heritability of intelligence.
    These findings open new avenues for research into the causes and consequences
    of intelligence using genome-wide polygenic scores that aggregate the effects
    of thousands of genetic variants.
- - /docs/iq/2017-sniekers.pdf
  - Genome-wide association meta-analysis of 78,308 individuals identifies new loci
    and genes influencing human intelligence
  - Suzanne Sniekers, Sven Stringer, Kyoko Watanabe, Philip R Jansen, Jonathan R I
    Coleman, Eva Krapohl, Erdogan Taskesen, Anke R Hammerschlag, Aysu Okbay, Delilah
    Zabaneh, Najaf Amin, Gerome Breen, David Cesarini, Christopher F Chabris, William
    G Iacono, M Arfan Ikram, Magnus Johannesson, Philipp Koellinger, James J Lee,
    Patrik K E Magnusson, Matt McGue, Mike B Miller, William E R Ollier, Antony Payton,
    Neil Pendleton, Robert Plomin, Cornelius A Rietveld, Henning Tiemeier, Cornelia
    M van Duijn, Danielle Posthuma
  - 2017-05-22
  - 10.1038/ng.3869
  - <p>Intelligence is associated with important economic and health-related life
    outcomes<sup>1</sup>. Despite intelligence having substantial heritability<sup>2</sup>
    (0.54) and a confirmed polygenic nature, initial genetic studies were mostly underpowered<sup>3,4,5</sup>.
    Here we report a meta-analysis for intelligence of 78,308 individuals. We identify
    336 associated SNPs (METAL <em>p</em> &lt; 5 × 10<sup>−8</sup>) in 18 genomic
    loci, of which 15 are new. Around half of the SNPs are located inside a gene,
    implicating 22 genes, of which 11 are new findings. Gene-based analyses identified
    an additional 30 genes (MAGMA <em>p</em> &lt; 2.73 × 10−<sup>6</sup>), of which
    all but one had not been implicated previously. We show that the identified genes
    are predominantly expressed in brain tissue, and pathway analysis indicates the
    involvement of genes regulating cell development (MAGMA competitive <em>p</em>
    = 3.5 × 10<sup>−6</sup>). Despite the well-known difference in twin-based heritability<sup>2</sup>
    for intelligence in childhood (0.45) and adulthood (0.80), we show substantial
    genetic correlation (<em>r<sub>g</sub></em> = 0.89, LD score regression <em>p</em>
    = 5.4 × 10<sup>−29</sup>). These findings provide new insight into the genetic
    architecture of intelligence.</p>
- - /docs/iodine/2015-monahan.pdf
  - ! 'Costs and benefits of iodine supplementation for pregnant women in a mildly
    to moderately iodine-deficient population: a modelling analysis'
  - Mark Monahan, Kristien Boelaert, Kate Jolly, Shiao Chan, Pelham Barton, Tracy
    E Roberts
  - 2015-08-10
  - 10.1016/S2213-8587(15)00212-0
  - ! '<p><em>Background</em>: Results from previous studies show that the cognitive
    ability of offspring might be irreversibly damaged as a result of their mother’s
    mild iodine deficiency during pregnancy. A reduced intelligence quotient (IQ)
    score has broad economic and societal cost implications because intelligence affects
    wellbeing, income, and education outcomes. Although pregnancy and lactation lead
    to increased iodine needs, no UK recommendations for iodine supplementation have
    been issued to pregnant women. We aimed to investigate the cost-effectiveness
    of iodine supplementation versus no supplementation for pregnant women in a mildly
    to moderately iodine-deficient population for which a population-based iodine
    supplementation programme—for example, universal salt iodisation—did not exist.</p><p><em>Methods</em>:
    We systematically searched MEDLINE, Embase, EconLit, and NHS EED for economic
    studies that linked IQ and income published in all languages until Aug 21, 2014.
    We took clinical data relating to iodine deficiency in pregnant women and the
    effect on IQ in their children aged 8–9 years from primary research. A decision
    tree was developed to compare the treatment strategies of iodine supplementation
    in tablet form with no iodine supplementation for pregnant women in the UK. Analyses
    were done from a health service perspective (analysis 1; taking direct health
    service costs into account) and societal perspective (analysis 2; taking education
    costs and the value of an IQ point itself into account), and presented in terms
    of cost (in sterling, relevant to 2013) per IQ point gained in the offspring.
    We made data-supported assumptions to complete these analyses, but used a conservative
    approach that limited the benefits of iodine supplementation and overestimated
    its potential harms.</p><p><em>Findings</em>: Our systematic search identified
    1361 published articles, of which eight were assessed to calculate the monetary
    value of an IQ point. A discounted lifetime value of an additional IQ point based
    on earnings was estimated to be £3297 (study estimates range from £1319 to £11 967)
    for the offspring cohort. Iodine supplementation was cost saving from both a health
    service perspective (saving £199 per pregnant woman [sensitivity analysis range
    –£42 to £229]) and societal perspective (saving £4476 per pregnant woman [sensitivity
    analysis range £540 to £4495]), with a net gain of 1·22 IQ points in each analysis.
    Base case results were robust to sensitivity analyses.</p><p><em>Interpretation</em>:
    Iodine supplementation for pregnant women in the UK is potentially cost saving.
    This finding also has implications for the 1·88 billion people in the 32 countries
    with iodine deficiency worldwide. Valuation of IQ points should consider non-earnings
    benefits—eg, health benefits associated with a higher IQ not germane to earnings.</p>'
- - https://bmcvetres.biomedcentral.com/articles/10.1186/s12917-017-0987-6
  - Responsiveness of cats (<em>Felidae</em>) to silver vine (<em>Actinidia polygama</em>),
    Tatarian honeysuckle (<em>Lonicera tatarica</em>), valerian (<em>Valeriana officinalis</em>)
    and catnip (<em>Nepeta cataria</em>)
  - Sebastiaan Bol, Jana Caspers, Lauren Buckingham, Gail Denise Anderson-Shelton,
    Carrie Ridgway, C. A. Tony Buffington, Stefan Schulz, Evelien M. Bunnik
  - 2017-03-16
  - 10.1186/s12917-017-0987-6
  - ! '<p><em>Background</em>: Olfactory stimulation is an often overlooked method
    of environmental enrichment for cats in captivity. The best known example of olfactory
    enrichment is the use of catnip, a plant that can cause an apparently euphoric
    reaction in domestic cats and most of the <em>Pantherinae</em>. It has long been
    known that some domestic cats and most tigers do not respond to catnip. Although
    many anecdotes exist of other plants with similar effects, data are lacking about
    the number of cats that respond to these plants, and if cats that do not respond
    to catnip respond to any of them. Furthermore, much is still unknown about which
    chemicals in these plants cause this response.</p><p><em>Methods</em>: We tested
    catnip, silver vine, Tatarian honeysuckle and valerian root on 100 domestic cats
    and observed their response. Each cat was offered all four plant materials and
    a control, multiple times. Catnip and silver vine also were offered to nine tigers.
    The plant materials were analyzed by gas chromatography coupled with mass spectrometry
    to quantify concentrations of compounds believed to exert stimulating effects
    on cats.</p><p><em>Results</em>: Nearly all domestic cats responded positively
    to olfactory enrichment. In agreement with previous studies, one out of every
    three cats did not respond to catnip. Almost 80% of the domestic cats responded
    to silver vine and about 50% to Tatarian honeysuckle and valerian root. Although
    cats predominantly responded to fruit galls of the silver vine plant, some also
    responded positively to its wood. Of the cats that did not respond to catnip,
    almost 75% did respond to silver vine and about one out of three to Tatarian honeysuckle.
    Unlike domestic cats, tigers were either not interested in silver vine or responded
    disapprovingly. The amount of nepetalactone was highest in catnip and only present
    at marginal levels in the other plants. Silver vine contained the highest concentrations
    of all other compounds tested.</p><p><em>Conclusions</em>: Olfactory enrichment
    for cats may have great potential. Silver vine powder from dried fruit galls and
    catnip were most popular among domestic cats. Silver vine and Tatarian honeysuckle
    appear to be good alternatives to catnip for domestic cats that do not respond
    to catnip.</p>'
- - /Amuse#loehlin-nichols-1976-a-study-of-850-sets-of-twins
  - ! 'Loehlin &amp; Nichols 1976: <em>A Study of 850 Sets of Twins</em>'
  - Gwern Branwen
  - 2018-05-19
  - ''
  - ! 'A discussion of extracting ~376 behavioral items relating to recreation/leisure
    from Loehlin &amp; Nichols 1976: <em>A Study of 850 Sets of Twins</em>, which
    reports comprehensive summary statistic twin correlations from an early large-scale
    twin study (canvassed via the National Merit Scholarship Qualifying Test, 1962).
    I transcribe them from the book, pool the weighted correlations by gender, and
    compute simple heritability estimates by Falconer''s formula for use in the recreation/leisure
    heritability literature review.'
- - https://www.pnas.org/content/early/2019/09/03/1821936116
  - Measuring actual learning versus feeling of learning in response to being actively
    engaged in the classroom
  - Louis Deslauriers, Logan S. McCarty, Kelly Miller, Kristina Callaghan, Greg Kestin
  - 2019-09-04
  - 10.1073/pnas.1821936116
  - ! '<p>Despite active learning being recognized as a superior method of instruction
    in the classroom, a major recent survey found that most college STEM instructors
    still choose traditional teaching methods. This article addresses the long-standing
    question of why students and faculty remain resistant to active learning. Comparing
    passive lectures with active learning using a randomized experimental approach
    and identical course materials, we find that students in the active classroom
    learn more, but they feel like they learn less. We show that this negative correlation
    is caused in part by the increased cognitive effort required during active learning.
    Faculty who adopt active learning are encouraged to intervene and address this
    misperception, and we describe a successful example of such an intervention.</p><p>We
    compared students’ self-reported perception of learning with their actual learning
    under controlled conditions in large-enrollment introductory college physics courses
    taught using (1) active instruction (following best practices in the discipline)
    and (2) passive instruction (lectures by experienced and highly rated instructors).
    Both groups received identical class content and handouts, students were randomly
    assigned, and the instructor made no effort to persuade students of the benefit
    of either method. Students in active classrooms learned more (as would be expected
    based on prior research), but their perception of learning, while positive, was
    lower than that of their peers in passive environments. This suggests that attempts
    to evaluate instruction based on students’ perceptions of learning could inadvertently
    promote inferior (passive) pedagogical methods. For instance, a superstar lecturer
    could create such a positive feeling of learning that students would choose those
    lectures over active learning. Most importantly, these results suggest that when
    students experience the increased cognitive effort associated with active learning,
    they initially take that effort to signify poorer learning. That disconnect may
    have a detrimental effect on students’ motivation, engagement, and ability to
    self-regulate their own learning. Although students can, on their own, discover
    the increased value of being actively engaged during a semester-long course, their
    learning may be impaired during the initial part of the course. We discuss strategies
    that instructors can use, early in the semester, to improve students’ response
    to being actively engaged in the classroom. [Keywords: scientific teaching, undergraduate
    education, evidence-based teaching, Constructivism]</p>'
- - /docs/melatonin/2002-cardinali.pdf
  - Melatonin in sleep disorders and jet-lag
  - Daniel P. Cardinali, Luis I. Brusco, Santiago Pérez Lloret, Analía M. Furio
  - '2002'
  - ''
  - In elderly insomniacs, melatonin treatment decreased sleep latency and increased
    sleep efficiency. This is particularly marked in Alzheimer’s disease (AD) patients.
    Melatonin is effective to reduce significantly benzodiazepine use. In addition,
    melatonin administration synchronizes the sleep-wake cycle in blind people and
    in individuals suffering from delayed sleep phase syndrome or jet lag. Urinary
    levels of 6-sulphatoxymelatonin decrease with age and in chronic diseases like
    AD or coronary heart disease. The effect of melatonin on sleep is probably the
    consequence of increasing sleep propensity (by inducing a fall in body temperature)
    and of a synchronizing effect on the circadian clock (chronobiotic effect).
- - /Timing#arpa-and-sci-surfing-ai-review-of-roland-shiman-2002
  - ! 'ARPA and SCI: Surfing AI (Review of Roland & Shiman 2002''s <em>Strategic Computing:
    DARPA and the Quest for Machine Intelligence, 1983&ndash;1993</em>)'
  - Gwern Branwen
  - 2018-08-01
  - ''
  - ! 'Review of DARPA history book, <em>Strategic Computing: DARPA and the Quest
    for Machine Intelligence, 1983&ndash;1993</em>, Roland & Shiman 2002, which reviews
    a large-scale DARPA effort to jumpstart real-world uses of AI in the 1980s by
    a multi-pronged research effort into more efficient computer chip R&D, supercomputing,
    robotics/self-driving cars, & expert system software. Roland & Shiman 2002 particularly
    focus on the various ''philosophies'' of technological forecasting & development,
    which guided DARPA''s strategy in different periods, ultimately endorsing a weak
    technological determinism where the bottlenecks are too large for a small (in
    comparison to the global economy & global R&D) organization best a DARPA can hope
    for is a largely agnostic & reactive strategy in which granters ''surf'' technological
    changes, rapidly exploiting new technology while investing their limited funds
    into targeted research patching up any gaps or lags that accidentally open up
    and block broader applications.'
- - /docs/sociology/2019-horowitz.pdf
  - ! 'Anthropology''s Science Wars: Insights from a New Survey'
  - Mark Horowitz, William Yaworsky, Kenneth Kickham
  - 2019-10
  - 10.1086/705409
  - In recent decades the field of anthropology has been characterized as sharply
    divided between pro-science and anti-science factions. The aim of this study is
    to empirically evaluate that characterization. We survey anthropologists in graduate
    programs in the United States regarding their views of science and advocacy, moral
    and epistemic relativism, and the merits of evolutionary biological explanations.
    We examine anthropologists’ views in concert with their varying appraisals of
    major controversies in the discipline (<a href="https://en.wikipedia.org/wiki/Napoleon_Chagnon">Chagnon/Tierney</a>,
    <a href="https://en.wikipedia.org/wiki/Margaret_Mead">Mead/Freeman</a>, and <a
    href="https://en.wikipedia.org/wiki/Rigoberta_Menchú#Controversies_about_her_testimony">Menchú/Stoll</a>).
    We find that disciplinary specialization and especially gender and political orientation
    are significant predictors of anthropologists’ views. We interpret our findings
    through the lens of an intuitionist social psychology that helps explain the dynamics
    of such controversies as well as ongoing ideological divisions in the field.
- - /docs/sr/2018-batikas.pdf
  - ! 'Entrepreneurs on the Darknet: Reaction to Negative Feedback'
  - Michail Batikas, Tobias Kretschmer
  - 2018-09-03
  - 10.2139/ssrn.3238141
  - ! 'Reputation is one of the key assets of a digital entrepreneur in markets for
    experience goods, especially in settings like Darknet and anonymous marketplaces.
    But what happens if this asset is diminished by a shock, i.e. negative feedback?
    We study how entrepreneurs on anonymous marketplaces respond to negative feedback
    by adjusting their product portfolio, or even exiting the market altogether. We
    find that the entrepreneurs are more likely to exit following negative feedback,
    but that a entrepreneur’s accumulated transactions experience on the market platform
    negatively moderates this. Interestingly, the entrepreneurs that do remain tend
    to expand their product portfolio. This effect, however, is again driven by entrepreneurs
    with relative high transactions experience, i.e. those with a high prior transactions
    volume. These results suggest that the reputation and the transactions experience
    of an entrepreneur interact in intricate ways to drive an entrepreneur’s choice
    of remaining in the market or adjusting her portfolio. We derive managerial and
    policy implications of these results. [Keywords: Digital Entrepreneurship, Reputation,
    Anonymous Marketplaces, Illicit Drugs, Darknet]'
- - /docs/sr/2013-aldridge.pdf
  - ! 'Not an ''Ebay for Drugs'': The Cryptomarket ''Silk Road'' as a Paradigm Shifting
    Criminal Innovation'
  - Judith Aldridge, David Décary-Hétu
  - 2014-05-15
  - 10.2139/ssrn.2436643
  - ! 'The online cryptomarket Silk Road has been oft-characterised as an ‘eBay for
    drugs’ with customers drug consumers making personal use-sized purchases. Our
    research demonstrates that this was not the case. Using a bespoke web crawler,
    we downloaded all drugs listings on Silk Road in September 2013. We found that
    a substantial proportion of transactions on Silk Road are best characterised as
    ‘business-to-business’, with sales in quantities and at prices typical of purchases
    made by drug dealers sourcing stock. High price-quantity sales generated between
    31-45% of revenue, making sales to drug dealers the key Silk Road drugs business.
    As such, Silk Road was what we refer to as a transformative, as opposed to incremental,
    criminal innovation. With the key Silk Road customers actually drug dealers sourcing
    stock for local street operations, we were witnessing a new breed of retail drug
    dealer, equipped with a technological subcultural capital skill set for sourcing
    stock. Sales on Silk Road increased from an estimate of $14.4 million in mid 2012
    to $89.7 million by our calculations. This is a more than 600% increase in just
    over a year, demonstrating the demand for this kind of illicit online marketplace.
    With Silk Road functioning to considerable degree at the wholesale/broker market
    level, its virtual location should reduce violence, intimidation and territorialism.
    Results are discussed in terms of the opportunities cryptomarkets provide for
    criminologists, who have thus far been reluctant to step outside of social surveys
    and administrative data to access the world of ‘webometric’ and ‘big data’. [Keywords:
    drug markets, cryptomarkets, webometrics, drug dealing]'
- - /docs/sr/2019-foley.pdf
  - ! 'Sex, Drugs, and Bitcoin: How Much Illegal Activity Is Financed through Cryptocurrencies?'
  - Sean Foley, Jonathan R. Karlsen, Tālis J. Putniņš
  - 2019-04-04
  - 10.1093/rfs/hhz015
  - Cryptocurrencies are among the largest unregulated markets in the world. We find
    that approximately one-quarter of bitcoin users are involved in illegal activity.
    We estimate that around $76 billion of illegal activity per year involve bitcoin
    (46% of bitcoin transactions), which is close to the scale of the U.S. and European
    markets for illegal drugs. The illegal share of bitcoin activity declines with
    mainstream interest in bitcoin and with the emergence of more opaque cryptocurrencies.
    The techniques developed in this paper have applications in cryptocurrency surveillance.
    Our findings suggest that cryptocurrencies are transforming the black markets
    by enabling “black e-commerce.”
- - https://osf.io/preprints/socarxiv/y4wgm/
  - ! 'Exit, Voice and Political Change: Evidence from Swedish Mass Migration to the
    United States'
  - Mounir Karadja, Erik Prawitz
  - 2019-09-06
  - 10.1086/701682
  - We study the political effects of mass emigration to the United States in the
    nineteenth century using data from Sweden. To instrument for total emigration
    over several decades, we exploit severe local frost shocks that sparked an initial
    wave of emigration, interacted with within-country travel costs. Our estimates
    show that emigration substantially increased the local demand for political change,
    as measured by labor movement membership, strike participation, and voting. Emigration
    also led to de facto political change, increasing welfare expenditures as well
    as the likelihood of adopting more inclusive political institutions.
- - /docs/sr/2019-du.pdf
  - ! 'Identifying High-Impact Opioid Products and Key Sellers in Dark Net Marketplaces:
    An Interpretable Text Analytics Approach'
  - Po-Yi Du, Mohammadreza Ebrahimi, Ning Zhang, Hsinchun Chen, Randall A. Brown,
    Sagar Samtani
  - 2019-07-01
  - 10.1109/ISI.2019.8823196
  - As the Internet based applications become more and more ubiquitous, drug retailing
    on Dark Net Marketplaces (DNMs) has raised public health and law enforcement concerns
    due to its highly accessible and anonymous nature. To combat illegal drug transaction
    among DNMs, authorities often require agents to impersonate DNM customers in order
    to identify key actors within the community. This process can be costly in time
    and resource. Research in DNMs have been conducted to provide better understanding
    of DNM characteristics and drug sellers’ behavior. Built upon the existing work,
    researchers can further leverage predictive analytics techniques to take proactive
    measures and reduce the associated costs. To this end, we propose a systematic
    analytical approach to identify key opioid sellers in DNMs. Utilizing machine
    learning and text analysis, this research provides prediction of high-impact opioid
    products in two major DNMs. Through linking the high-impact products and their
    sellers, we then identify the key opioid sellers among the communities. This work
    intends to help law enforcement authorities to formulate strategies by providing
    specific targets within the DNMs and reduce the time and resources required for
    prosecuting and eliminating the criminals from the market.
- - https://peerj.com/articles/6232/
  - ! 'Registered reports: an early example and analysis'
  - Richard Wiseman, Caroline Watt, Diana Kornbrot
  - 2019-01-16
  - 10.7717/peerj.6232
  - ! '<p>The recent ‘replication crisis’ in psychology has focused attention on ways
    of increasing methodological rigor within the behavioral sciences. Part of this
    work has involved promoting ‘Registered Reports’, wherein journals peer review
    papers prior to data collection and publication. Although this approach is usually
    seen as a relatively recent development, we note that a prototype of this publishing
    model was initiated in the mid-1970s by parapsychologist Martin Johnson in the
    <em>European Journal of Parapsychology</em> (<em>EJP</em>). A retrospective and
    observational comparison of Registered and non-Registered Reports published in
    the EJP during a seventeen-year period provides circumstantial evidence to suggest
    that the approach helped to reduce questionable research practices. This paper
    aims both to bring Johnson’s pioneering work to a wider audience, and to investigate
    the positive role that Registered Reports may play in helping to promote higher
    methodological and statistical standards.</p><p>...The final dataset contained
    60 papers: 25 RRs and 35 non-RRs. The RRs described 31 experiments that tested
    131 hypotheses, and the non-RRs described 60 experiments that tested 232 hypotheses.</p><p>28.4%
    of the statistical tests reported in non-RRs were significant (66/232: 95% CI
    [21.5%–36.4%]); compared to 8.4% of those in the RRs (11/131: 95% CI [4.0%–16.8%]).
    A simple 2 × 2 contingency analysis showed that this difference is highly statistically
    significant (Fisher’s exact test: <em>p</em> &lt; .0005, Pearson chi-square=20.1,
    Cohen’s <em>d</em> = .48).</p><p>…Parapsychologists investigate the possible existence
    of phenomena that, for many, have a low a priori likelihood of being genuine (see,
    e.g., Wagenmakers et al., 2011). This has often resulted in their work being subjected
    to a considerable amount of critical attention (from both within and outwith the
    field) that has led to them pioneering several methodological advances prior to
    their use within mainstream psychology, including the development of randomisation
    in experimental design (Hacking, 1988), the use of blinds (Kaptchuk, 1998), explorations
    into randomisation and statistical inference (Fisher, 1924), advances in replication
    issues (Rosenthal, 1986), the need for pre-specification in meta-analysis (Akers,
    1985; Milton, 1999; Kennedy, 2004), and the creation of a formal study registry
    (Watt, 2012; Watt &amp; Kennedy, 2015). Johnson’s work on RRs provides another
    striking illustration of this principle at work.</p>'
- - /docs/catnip/2002-hall.pdf
  - ! 'Object play in adult domestic cats: the roles of habituation and disinhibition'
  - Sarah L. Hall, John W.S. Bradshaw, Ian H. Robinson
  - 2002-11
  - 10.1016/S0168-1591(02)00153-3
  - ! 'We have investigated the role of habituation and disinhibition in the control
    of object (predatory) play by adult domestic cats Felis silvestris catus both
    with and without prior experience of hunting. We hypothesised that object play
    is terminated by rapid habituation to the sensory characteristics of the object
    played with, and therefore should be disinhibited if the sensory characteristics
    of the object are changed. Three sequential sessions of play with an unchanging
    object (a toy) caused almost complete habituation of the play response; replacing
    the toy with one of contrasting colours in a fourth session elicited intense disinhibited
    play, suggesting that motivation for play itself had not diminished substantially
    during the first three sessions. The time interval between sessions affected the
    extent of disinhibition. After a long delay (25–45 min) between each session play
    was less intense in the fourth session than in the first; if the interval was
    5 min, it was more intense, indicative of post-inhibitory rebound, possibly caused
    by initial positive feedback of play on its own performance. We suggest that object
    play by adult cats is controlled by two mechanisms derived from predatory behaviour:
    one responds to prey-like stimulus characteristics, such as texture and small
    size, which elicit play, while the second detects change in the toy. The behavioural
    default towards any object is initial interest if it possesses relevant stimulus
    characteristics, followed by rapid habituation unless these stimulus characteristics
    change.'
- - https://einstein.ai/presentations/ctrl.pdf
  - ! 'CTRL: A Conditional Transformer Language Model For Controllable Generation'
  - Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney, Caiming Xiong, Richard Socher
    (Salesforce)
  - 2019-09-11
  - ''
  - Large-scale language models show promising text generation capabilities, but users
    cannot easily control particular aspects of the generated text. We release CTRL,
    a 1.6 billion-parameter conditional transformer language model, trained to condition
    on control codes that govern style, content, and task-specific behavior. Control
    codes were derived from structure that naturally co-occurs with raw text, preserving
    the advantages of unsupervised learning while providing more explicit control
    over text generation. These codes also allow CTRL to predict which parts of the
    training data are most likely given a sequence. This provides a potential method
    for analyzing large amounts of data via model-based source attribution. We have
    released multiple full-sized, pretrained versions of CTRL at <a href="https://github.com/salesforce/ctrl"><code>github.com/salesforce/ctrl</code></a>.
- - /docs/genetics/editing/2019-zheng.pdf
  - Controlled modelling of human epiblast and amnion development using stem cells
  - Yi Zheng, Xufeng Xue, Yue Shao, Sicong Wang, Sajedeh Nasr Esfahani, Zida Li, Jonathon
    M. Muncie, Johnathon N. Lakins, Valerie M. Weaver, Deborah L. Gumucio, Jianping
    Fu
  - 2019-09-11
  - 10.1038/s41586-019-1535-2
  - Early human embryonic development involves extensive lineage diversification,
    cell-fate specification and tissue patterning1. Despite its basic and clinical
    importance, early human embryonic development remains relatively unexplained owing
    to interspecies divergence<sup>2,3</sup> and limited accessibility to human embryo
    samples. Here we report that human pluripotent stem cells (hPSCs) in a microfluidic
    device recapitulate, in a highly controllable and scalable fashion, landmarks
    of the development of the epiblast and amniotic ectoderm parts of the conceptus,
    including lumenogenesis of the epiblast and the resultant pro-amniotic cavity,
    formation of a bipolar embryonic sac, and specification of primordial germ cells
    and primitive streak cells. We further show that amniotic ectoderm-like cells
    function as a signalling centre to trigger the onset of gastrulation-like events
    in hPSCs. Given its controllability and scalability, the microfluidic model provides
    a powerful experimental system to advance knowledge of human embryology and reproduction.
    This model could assist in the rational design of differentiation protocols of
    hPSCs for disease modelling and cell therapy, and in high-throughput drug and
    toxicity screens to prevent pregnancy failure and birth defects.
- - https://www.ukbiobank.ac.uk/2019/09/uk-biobank-leads-the-way-in-genetics-research-to-tackle-chronic-diseases/
  - UK Biobank leads the way in genetics research to tackle chronic diseases
  - UK Biobank
  - 2019-09-11
  - ''
  - <p>A £200 million investment from government, industry and charity cements UK
    Biobank’s reputation as a world-leading health resource to tackle the widest range
    of common and chronic diseases&mdash;including dementia, mental illness, cancer
    and heart disease. The investment provides for the whole genome sequencing of
    450,000 UK Biobank participants. A Vanguard study, funded by the Medical Research
    Council to sequence the first 50,000 individuals, is already underway.</p><p>...The
    ambitious project is funded with:</p><ul><li>£50 million by the UK Government’s
    research and innovation agency, UK Research and Innovation (UKRI) through the
    Industrial Strategy Challenge Fund;</li><li>£50 million from The Wellcome Trust
    charity;</li><li>£100 million in total from pharmaceutical companies Amgen, AstraZeneca,
    GlaxoSmithKline (GSK) and Johnson &amp; Johnson (J&amp;J).</li></ul><p>...At the
    end of May 2020, the consortium of pharmaceutical companies will be provided independently
    with access for analysis to the first tranche of sequence data (anticipated to
    be for about 125,000 participants) linked to all of the other data in the UK Biobank
    resource. After an exclusive access period of 9 months, the whole genome sequence
    data will be made available to all other approved researchers around the world.
    A similar exclusive access period will also apply on the completion of the sequencing.
    The period of exclusive access mirrors the arrangements that UK Biobank had with
    the exome sequencing project which is being undertaken by Regeneron in the US
    and other industry partners. The first tranche of exome data on 50,000 participants
    is now being used in more than 100 research projects worldwide.</p>
- - https://www.econstor.eu/bitstream/10419/71700/1/739716212.pdf
  - ! 'Star Wars: The Empirics Strike Back'
  - Abel Brodeur, Mathias Lé, Marc Sangnier, Yanos Zylberberg
  - 2013-03
  - ''
  - <p>Journals favor rejection of the null hypothesis. This selection upon tests
    may distort the behavior of researchers. Using 50,000 tests published between
    2005 and 2011 in the <em>AER</em>, <em>JPE</em>, and <em>QJE</em>, we identify
    a residual in the distribution of tests that cannot be explained by selection.
    The distribution of <em>p</em>-values exhibits a camel shape with abundant <em>p</em>-values
    above 0.25, a valley between 0.25 and 0.10 and a bump slightly below 0.05. The
    missing tests (with <em>p</em>-values between 0.25 and 0.10) can be retrieved
    just after the 0.05 threshold and represent 10% to 20% of marginally rejected
    tests. Our interpretation is that researchers might be tempted to <em>inflate</em>
    the value of those almost-rejected tests by choosing a “significant” specification.
    We propose a method to measure <em>inflation</em> and decompose it along articles’
    and authors’ characteristics.</p>
- - /docs/statistics/bias/2014-andreoliversbach.pdf
  - ! 'Open Access to Data: An Ideal Professed but Not Practised'
  - Patrick Andreoli-Versbach, Frank Mueller-Langer
  - '2014'
  - 10.1016/j.respol.2014.04.008
  - Data-sharing is an essential tool for replication, validation and extension of
    empirical results. Using a hand-collected data set describing the data-sharing
    behaviour of 488 randomly selected empirical researchers, we provide evidence
    that most researchers in economics and management do not share their data voluntarily.
    We derive testable hypotheses based on the theoretical literature on information-sharing
    and relate data-sharing to observable characteristics of researchers. We find
    empirical support for the hypotheses that voluntary data-sharing significantly
    increases with (a) academic tenure, (b) the quality of researchers, (c) the share
    of published articles subject to a mandatory data-disclosure policy of journals,
    and (d) personal attitudes towards “open science” principles. On the basis of
    our empirical evidence, we discuss a set of policy recommendations.
- - /docs/statistics/bias/2009-ljungqvist.pdf
  - Rewriting History
  - Alexander Ljungqvist, Christopher Malloy, Felicia Marston
  - 2009-07-16
  - 10.1111/j.1540-6261.2009.01484.x
  - ! 'We document widespread changes to the historical I/B/E/S analyst stock recommendations
    database. Across seven I/B/E/S downloads, obtained between 2000 and 2007, we find
    that between 6,580 (1.6%) and 97,582 (21.7%) of matched observations are different
    from one download to the next. The changes include alterations of recommendations,
    additions and deletions of records, and removal of analyst names. These changes
    are nonrandom, clustering by analyst reputation, broker size and status, and recommendation
    boldness, and affect trading signal classifications and back‐tests of three stylized
    facts: profitability of trading signals, profitability of consensus recommendation
    changes, and persistence in individual analyst stock‐picking ability.'
- - https://szociologia.tk.mta.hu/uploads/files/archive/john_et_al_2012.pdf
  - Measuring the Prevalence of Questionable Research Practices with Incentives for
    Truth-Telling
  - Leslie K. John, George Loewenstein, Drazen Prelec
  - '2012'
  - 10.1177/095679761143095
  - ! 'Cases of clear scientific misconduct have received significant media attention
    recently, but less flagrantly questionable research practices may be more prevalent
    and, ultimately, more damaging to the academic enterprise. Using an anonymous
    elicitation format supplemented by incentives for honest reporting, we surveyed
    over 2,000 psychologists about their involvement in questionable research practices.
    The impact of truth-telling incentives on self-admissions of questionable research
    practices was positive, and this impact was greater for practices that respondents
    judged to be less defensible. Combining three different estimation methods, we
    found that the percentage of respondents who have engaged in questionable practices
    was surprisingly high. This finding suggests that some questionable practices
    may constitute the prevailing research norm. [Keywords: professional standards,
    judgment, disclosure, methodology]'
- - /docs/statistics/decision/2006-drescher-goodandreal.pdf
  - ! '<em>Good and Real: Demystifying Paradoxes from Physics to Ethics</em>'
  - Gary Drescher
  - '2006'
  - ''
  - <p>In <a href="https://www.amazon.com/Good-Real-Demystifying-Paradoxes-Bradford/dp/0262042339"><em>Good
    and Real</em></a>, a tour-de-force of metaphysical naturalism, computer scientist
    <a href="https://en.wikipedia.org/wiki/Gary_Drescher">Gary Drescher</a> examines
    a series of provocative paradoxes about consciousness, choice, ethics, quantum
    mechanics, and other topics, in an effort to reconcile a purely mechanical view
    of the universe with key aspects of our subjective impressions of our own existence.</p><p>Many
    scientists suspect that the universe can ultimately be described by a simple (perhaps
    even deterministic) formalism; all that is real unfolds mechanically according
    to that formalism. But how, then, is it possible for us to be conscious, or to
    make genuine choices? And how can there be an ethical dimension to such choices?
    Drescher sketches computational models of consciousness, choice, and subjunctive
    reasoning—what would happen if this or that were to occur?—to show how such phenomena
    are compatible with a mechanical, even deterministic universe.</p><p>Analyses
    of <a href="https://en.wikipedia.org/wiki/Newcomb%27s_paradox">Newcomb’s Problem</a>
    (a paradox about choice) and the <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">Prisoner’s
    Dilemma</a> (a paradox about self-interest vs altruism, arguably reducible to
    Newcomb’s Problem) help bring the problems and proposed solutions into focus.
    Regarding quantum mechanics, Drescher builds on <a href="https://en.wikipedia.org/wiki/Many-worlds_interpretation">Everett’s
    relative-state formulation</a>—but presenting a simplified formalism, accessible
    to laypersons—to argue that, contrary to some popular impressions, quantum mechanics
    is compatible with an objective, deterministic physical reality, and that there
    is no special connection between quantum phenomena and consciousness.</p><p>In
    each of several disparate but intertwined topics ranging from physics to ethics,
    Drescher argues that a missing technical linchpin can make the quest for objectivity
    seem impossible, until the elusive technical fix is at hand.:</p><ul><li>Chapter
    2 explores how inanimate, mechanical matter could be conscious, just by virtue
    of being organized to perform the right kind of computation.</li><li>Chapter 3
    explains why conscious beings would experience an apparent inexorable forward
    flow of time, even in a universe who physical principles are time-symmetric and
    have no such flow, with everything sitting statically in spacetime.</li><li>Chapter
    4, following [Hugh] Everett, looks closely at the paradoxes of quantum mechanics,
    showing how some theorists came to conclude—mistakenly, I argue—that consciousness
    is part of the story of quantum phenomena, or vice versa. Chapter 4 also shows
    how quantum phenomena are consistent with determinism (even though so-called <a
    href="https://en.wikipedia.org/wiki/Hidden-variable_theory">hidden-variable theories</a>
    of quantum determinism are provably wrong).</li><li>Chapter 5 examines in detail
    how it can be that we make genuine choices in in a mechanical, deterministic universe.</li><li>Chapter
    6 analyzes Newcomb’s Problem, a startling paradox that elicits some counterintuitive
    conclusions about choice and causality.</li><li>Chapter 7 considers how our choices
    can have a moral component&mdash;that is, how even a mechanical, deterministic
    universe can provide a basis for distinguishing right from wrong.</li><li>Chapter
    8 wraps up the presentation and touches briefly on some concluding metaphysical
    questions.</li></ul>
- - https://www.cs.virginia.edu/~robins/YouAndYourResearch.html
  - You and Your Research
  - Richard Hamming
  - 1986-03-07
  - ''
  - ! '<p>[Transcript of a talk by mathematician and <a href="https://en.wikipedia.org/wiki/Bell_Labs">Bell
    Labs</a> manager <a href="https://en.wikipedia.org/wiki/Richard_Hamming">Richard
    Hamming</a> about what he had learned about computers and how to do effective
    research (republished in expanded form as <em>Art of Doing Science and Engineering:
    Learning to Learn</em>; <a href="https://www.youtube.com/watch?v=a1zDuOPkMSw" title="Hamming, "You and Your Research" (June 6, 1995)">1995 video</a>). It is one of the most famous and most-quoted such discussions
    ever.]</p><p>At a seminar in the Bell Communications Research Colloquia Series,
    Dr. Richard W. Hamming, a Professor at the Naval Postgraduate School in Monterey,
    California and a retired Bell Labs scientist, gave a very interesting and stimulating
    talk, ''You and Your Research'' to an overflow audience of some 200 Bellcore staff
    members and visitors at the Morris Research and Engineering Center on March 7,
    1986. This talk centered on Hamming''s observations and research on the question
    "Why do so few scientists make significant contributions and so many are forgotten
    in the long run?" From his more than forty years of experience, thirty of which
    were at Bell Laboratories, he has made a number of direct observations, asked
    very pointed questions of scientists about what, how, and why they did things,
    studied the lives of great scientists and great contributions, and has done introspection
    and studied theories of creativity. The talk is about what he has learned in terms
    of the properties of the individual scientists, their abilities, traits, working
    habits, attitudes, and philosophy.</p>'
- - https://www.reddit.com/r/reinforcementlearning/
  - ! 'Reddit: Reinforcement Learning subreddit'
  - 'NA'
  - 'NA'
  - ''
  - ! 'Subreddit devoted to discussion of reinforcement learning research and projects,
    particularly deep reinforcement learning (more specialized than <code>/r/MachineLearning</code>).
    Major themes include deep learning, model-based vs model-free RL, robotics, multi-agent
    RL, exploration, meta-reinforcement learning, imitation learning, the psychology
    of RL in biological organisms such as humans, and safety/AI risk. Moderate activity
    level (as of 11 September 2019): ~10k subscribers, 2k pageviews/daily'
- - https://www.nature.com/mp/journal/vaop/ncurrent/full/mp2017121a.html
  - A genome-wide association study for extremely high intelligence
  - D. Zabaneh, E. Krapohl, H. A. Gaspar, C. Curtis, S. H. Lee, H. Patel, S. Newhouse,
    H. M. Wu, M. A. Simpson, M. Putallaz, David Lubinski, Robert Plomin, G. Breen
  - 2017-07-04
  - 10.1038/mp.2017.121
  - We used a case–control genome-wide association (GWA) design with cases consisting
    of 1238 individuals from the top 0.0003 (~170 mean IQ) of the population distribution
    of intelligence and 8172 unselected population-based controls. The single-nucleotide
    polymorphism heritability for the extreme IQ trait was 0.33 (0.02), which is the
    highest so far for a cognitive phenotype, and significant genome-wide genetic
    correlations of 0.78 were observed with educational attainment and 0.86 with population
    IQ. Three variants in locus ADAM12 achieved genome-wide significance, although
    they did not replicate with published GWA analyses of normal-range IQ or educational
    attainment. A genome-wide polygenic score constructed from the GWA results accounted
    for 1.6% of the variance of intelligence in the normal range in an unselected
    sample of 3414 individuals, which is comparable to the variance explained by GWA
    studies of intelligence with substantially larger sample sizes. The gene family
    <em>plexins</em>, members of which are mutated in several monogenic neurodevelopmental
    disorders, was significantly enriched for associations with high IQ. This study
    shows the utility of extreme trait selection for genetic study of intelligence
    and suggests that extremely high intelligence is continuous genetically with normal-range
    intelligence in the population.
- - https://www.nature.com/articles/s41380-017-0001-5
  - A combined analysis of genetically correlated traits identifies 187 loci and a
    role for neurogenesis and myelination in intelligence
  - William D. Hill, Robert E. Marioni, O. Maghzian, Stuart J. Ritchie, Sarah P. Hagenaars,
    A. M. McIntosh, C. R. Gale, G. Davies, Ian J. Deary
  - 2018-01-11
  - 10.1038/s41380-017-0001-5
  - ! 'Intelligence, or general cognitive function, is phenotypically and genetically
    correlated with many traits, including a wide range of physical, and mental health
    variables. Education is strongly genetically correlated with intelligence (<em>r<sub>g</sub></em> = 0.70).
    We used these findings as foundations for our use of a novel approach—multi-trait
    analysis of genome-wide association studies (MTAG; Turley et al. 2017)—to combine
    two large genome-wide association studies (GWASs) of education and intelligence,
    increasing statistical power and resulting in the largest GWAS of intelligence
    yet reported. Our study had four goals: first, to facilitate the discovery of
    new genetic loci associated with intelligence; second, to add to our understanding
    of the biology of intelligence differences; third, to examine whether combining
    genetically correlated traits in this way produces results consistent with the
    primary phenotype of intelligence; and, finally, to test how well this new meta-analytic
    data sample on intelligence predicts phenotypic intelligence in an independent
    sample. By combining datasets using MTAG, our functional sample size increased
    from 199,242 participants to 248,482. We found 187 independent loci associated
    with intelligence, implicating 538 genes, using both SNP-based and gene-based
    GWAS. We found evidence that neurogenesis and myelination—as well as genes expressed
    in the synapse, and those involved in the regulation of the nervous system—may
    explain some of the biological differences in intelligence. The results of our
    combined analysis demonstrated the same pattern of genetic correlations as those
    from previous GWASs of intelligence, providing support for the meta-analysis of
    these genetically-related phenotypes.'
- - http://www.nature.com/tp/journal/v6/n9/full/tp2016155a.html
  - Genome-wide association study of antisocial personality disorder
  - M-R. Rautiainen, T. Paunio, E. Repo-Tiihonen, M. Virkkunen, H. M. Ollila, S. Sulkava,
    O. Jolanki, A. Palotie, J. Tiihonen
  - 2016-09-06
  - 10.1038/tp.2016.155
  - <p>The pathophysiology of antisocial personality disorder (ASPD) remains unclear.
    Although the most consistent biological finding is reduced grey matter volume
    in the frontal cortex, about 50% of the total liability to developing ASPD has
    been attributed to genetic factors. The contributing genes remain largely unknown.
    Therefore, we sought to study the genetic background of ASPD. We conducted a genome-wide
    association study (GWAS) and a replication analysis of Finnish criminal offenders
    fulfilling DSM-IV criteria for ASPD (<em>N</em>=370, <em>N</em>=5850 for controls,
    GWAS; <em>N</em>=173, <em>N</em>=3766 for controls and replication sample). The
    GWAS resulted in suggestive associations of two clusters of single-nucleotide
    polymorphisms at 6p21.2 and at 6p21.32 at the human leukocyte antigen (HLA) region.
    Imputation of HLA alleles revealed an independent association with DRB1*01:01
    (odds ratio (OR)=2.19 (1.53–3.14), P=1.9 × 10<sup>-5</sup>). Two polymorphisms
    at 6p21.2 LINC00951–LRFN2 gene region were replicated in a separate data set,
    and rs4714329 reached genome-wide significance (OR=1.59 (1.37–1.85), P=1.6 × 10<sup>−9</sup>)
    in the meta-analysis. The risk allele also associated with antisocial features
    in the general population conditioned for severe problems in childhood family
    (<em>β</em>=0.68, <em>p</em>=0.012). Functional analysis in brain tissue in open
    access GTEx and Braineac databases revealed eQTL associations of rs4714329 with
    LINC00951 and LRFN2 in cerebellum. In humans, LINC00951 and LRFN2 are both expressed
    in the brain, especially in the frontal cortex, which is intriguing considering
    the role of the frontal cortex in behavior and the neuroanatomical findings of
    reduced gray matter volume in ASPD. To our knowledge, this is the first study
    showing genome-wide significant and replicable findings on genetic variants associated
    with any personality disorder.</p>
- - https://www.nature.com/articles/tp2016155
  - Genome-wide association study of antisocial personality disorder
  - M-R. Rautiainen, T. Paunio, E. Repo-Tiihonen, M. Virkkunen, H. M. Ollila, S. Sulkava,
    O. Jolanki, A. Palotie, J. Tiihonen
  - 2016-09-06
  - 10.1038/tp.2016.155
  - <p>The pathophysiology of antisocial personality disorder (ASPD) remains unclear.
    Although the most consistent biological finding is reduced grey matter volume
    in the frontal cortex, about 50% of the total liability to developing ASPD has
    been attributed to genetic factors. The contributing genes remain largely unknown.
    Therefore, we sought to study the genetic background of ASPD. We conducted a genome-wide
    association study (GWAS) and a replication analysis of Finnish criminal offenders
    fulfilling DSM-IV criteria for ASPD (<em>N</em>=370, <em>N</em>=5850 for controls,
    GWAS; <em>N</em>=173, <em>N</em>=3766 for controls and replication sample). The
    GWAS resulted in suggestive associations of two clusters of single-nucleotide
    polymorphisms at 6p21.2 and at 6p21.32 at the human leukocyte antigen (HLA) region.
    Imputation of HLA alleles revealed an independent association with DRB1*01:01
    (odds ratio (OR)=2.19 (1.53–3.14), <em>p</em>=1.9 × 10<sup>-5</sup>). Two polymorphisms
    at 6p21.2 LINC00951–LRFN2 gene region were replicated in a separate data set,
    and rs4714329 reached genome-wide significance (OR=1.59 (1.37–1.85), <em>p</em>=1.6
    × 10<sup>−9</sup>) in the meta-analysis. The risk allele also associated with
    antisocial features in the general population conditioned for severe problems
    in childhood family (<em>β</em>=0.68, <em>p</em>=0.012). Functional analysis in
    brain tissue in open access GTEx and Braineac databases revealed eQTL associations
    of rs4714329 with LINC00951 and LRFN2 in cerebellum. In humans, LINC00951 and
    LRFN2 are both expressed in the brain, especially in the frontal cortex, which
    is intriguing considering the role of the frontal cortex in behavior and the neuroanatomical
    findings of reduced gray matter volume in ASPD. To our knowledge, this is the
    first study showing genome-wide significant and replicable findings on genetic
    variants associated with any personality disorder.</p>
- - https://karpathy.github.io/2015/05/21/rnn-effectiveness/
  - The Unreasonable Effectiveness of Recurrent Neural Networks
  - Andrej Karpathy
  - 2015-05-21
  - ''
  - ! '<p>[Exploration of char-RNN neural nets for generating text. Karpathy codes
    a simple recurrent NN which generates character-by-character, and discovers that
    it is able to generate remarkably plausible text (at the syntactic level) for
    Paul Graham, Shakespeare, Wikipedia, LaTeX, Linux C code, and baby names&mdash;all
    using the same generic architecture. Visualizing the internal activity of the
    char-RNNs, they seem to be genuinely understanding some of the recursive syntactic
    structure of the text in a way that other text-generation methods like n-grams
    cannot. Inspired by this post, I began <a href="/RNN-metadata">tinkering with
    char-RNNs for poetry</a> myself; as of 2019, char-RNNs have been largely obsoleted
    by the new <a href="/GPT-2"><em>Transformer architecture</em></a>, but recurrency
    will make a comeback and Karpathy''s post is still a valuable and fun read.]</p><p>There’s
    something magical about Recurrent Neural Networks (RNNs). I still remember when
    I trained my first recurrent network for Image Captioning. Within a few dozen
    minutes of training my first baby model (with rather arbitrarily-chosen hyperparameters)
    started to generate very nice looking descriptions of images that were on the
    edge of making sense. Sometimes the ratio of how simple your model is to the quality
    of the results you get out of it blows past your expectations, and this was one
    of those times. What made this result so shocking at the time was that the common
    wisdom was that RNNs were supposed to be difficult to train (with more experience
    I’ve in fact reached the opposite conclusion). Fast forward about a year: I’m
    training RNNs all the time and I’ve witnessed their power and robustness many
    times, and yet their magical outputs still find ways of amusing me. This post
    is about sharing some of that magic with you.<em>We’ll train RNNs to generate
    text character by character and ponder the question “how is that even possible?”</em></p>'
- - https://archive.org/details/eassayonthepsych006281mbp
  - <em>An Essay On The Psychology Of Invention In The Mathematical Field</em>
  - Jacques Hadamard
  - '1945'
  - ''
  - ! '[<p>Relevant to an <a href="/The-Existential-Risk-of-Mathematical-Error">essay
    of mine on mathematical error</a>—Hadamard’s book is one of the classics in the
    area of mathematical discovery, mentioned along with <a href="http://paradise.caltech.edu/ist4/lectures/Poincare_Reflections.pdf"
    title="&#39;Mathematical Creation&#39;, 1908">Poincaré’s lecture</a>.</p><p>With
    due allowance for style and age, Hadamard ably describes and defends the basic
    model of ‘work, incubation, illumination, verification’, with reference to his
    own discoveries, his many famous acquaintances, Poincaré’s lecture, and a very
    interesting survey of mathematicians. In fact, it’s a little depressing that we
    don’t seem to have gone much beyond that in the half-century since this was published
    back in 1945 or so. While at least we no longer need his defense of the unconscious
    as a meaningful part of cognition, much of the rest is depressingly familiar—for
    example, his acute observations on mental imagery &amp; people who solely think
    in words, and mention of Francis Galton’s survey (little-known outside of psychology),
    could be usefully read by many who commit the <a href="http://lesswrong.com/lw/dr/generalizing_from_one_example/">typical
    mind fallacy</a>.</p><p>If Hadamard comes to no hard and fast conclusions, but
    merely raises many interesting points and criticizes a number of theories, we
    can hardly hold that against him, as we can do little better and so it becomes
    our failing to followup, not his.</p>]'
- - http://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/
  - The Control Group Is Out Of Control
  - Scott Alexander
  - 2014-04-28
  - ''
  - <p>Allan Crossman calls parapsychology <a href="http://lesswrong.com/lw/1ib/parapsychology_the_control_group_for_science/">the
    control group for science</a>. That is, in let’s say a drug testing experiment,
    you give some people the drug and they recover. That doesn’t tell you much until
    you give some other people a placebo drug you <em>know</em> doesn’t work—but which
    they themselves believe in—and see how many of them recover. That number tells
    you how many people will recover whether the drug works or not. Unless people
    on your real drug do significantly better than people on the placebo drug, you
    haven’t found anything. On the meta-level, you’re studying some phenomenon and
    you get some positive findings. That doesn’t tell you much until you take some
    other researchers who are studying a phenomenon you know doesn’t exist—but which
    they themselves believe in—and see how many of <em>them</em> get positive findings.
    That number tells you how many studies will discover positive results whether
    the phenomenon is real or not. Unless studies of the real phenomenon do significantly
    better than studies of the placebo phenomenon, you haven’t found anything.</p><p>Trying
    to set up placebo science would be a logistical nightmare. You’d have to find
    a phenomenon that definitely doesn’t exist, somehow convince a whole community
    of scientists across the world that it does, and fund them to study it for a couple
    of decades without them figuring it out.</p><p>Luckily we have a natural experiment
    in terms of parapsychology—the study of psychic phenomena—which most reasonable
    people believe don’t exist, but which a community of practicing scientists believes
    in and publishes papers on all the time. The results are pretty dismal. Parapsychologists
    are able to produce experimental evidence for psychic phenomena about as easily
    as normal scientists are able to produce such evidence for normal, non-psychic
    phenomena. This suggests the existence of a very large “placebo effect” in science—ie
    with enough energy focused on a subject, you can <em>always</em> produce “experimental
    evidence” for it that meets the usual scientific standards. As <a href="https://www.lesswrong.com/posts/9qCN6tRBtksSyXfHu/frequentist-statistics-are-frequently-subjective"
    title="Frequentist Statistics are Frequently Subjective">Eliezer Yudkowsky puts
    it</a>:</p><blockquote><p>Parapsychologists are constantly protesting that they
    are playing by all the standard scientific rules, and yet their results are being
    ignored—that they are unfairly being held to higher standards than everyone else.
    I’m willing to believe that. It just means that the standard statistical methods
    of science are so weak and flawed as to permit a field of study to sustain itself
    in the complete absence of any subject matter.</p></blockquote>
- - http://www.terrierman.com/russianfoxfarmstudy.pdf
  - ! 'Early Canid Domestication: The Farm-Fox Experiment: Foxes bred for tamability
    in a 40-year experiment exhibit remarkable transformations that suggest an interplay
    between behavioral genetics and development'
  - Lyudmila N. Trut
  - 1999-03
  - 10.2307/27857815
  - ! '<p>[Popular review of the <a href="https://en.wikipedia.org/wiki/Domesticated_red_fox">domesticated
    red fox</a> by the lead researcher. Trut gives the history of Belyaev''s founding
    of the experiment in 1959, and how the results gradually proved his theory about
    ''domestication syndrome'': that domestication produces multiple simultaneous
    effects like floppy ears despite the foxes being bred solely for being willing
    to approach a strange human, suggesting an underlying common genetic mechanism]</p><p>Forty
    years into our unique lifelong experiment, we believe that Dmitry Belyaev would
    be pleased with its progress. By intense selective breeding, we have compressed
    into a few decades an ancient process that originally unfolded over thousands
    of years. Before our eyes, “the Beast” has turned into “Beauty,” as the aggressive
    behavior of our herd’s wild progenitors entirely disappeared. We have watched
    new morphological traits emerge, a process previously known only from archaeological
    evidence. Now we know that these changes can burst into a population early in
    domestication, triggered by the stresses of captivity, and that many of them result
    from changes in the timing of developmental processes. In some cases the changes
    in timing, such as earlier sexual maturity or retarded growth of somatic characters,
    resemble pedomorphosis. Some long-standing puzzles remain. We believed at the
    start that foxes could be made to reproduce twice a year and all year round, like
    dogs. We would like to understand why this has turned out not to be quite so.
    We are also curious about how the vocal repertoire of foxes changes under domestication.
    Some of the calls of our adult foxes resemble those of dogs and, like those of
    dogs, appear to be holdovers from puppyhood, but only further study will reveal
    the details. The biggest unanswered question is just how much further our selective-breeding
    experiment can go. The domestic fox is not a domestic dog, but we believe that
    it has the genetic potential to become more and more doglike.</p>'
- - http://www.nature.com/mp/journal/vaop/ncurrent/full/mp201645a.html
  - Genome-wide association study of cognitive functions and educational attainment
    in UK Biobank (<em>N</em>=112 151)
  - G. Davies, R. E. Marioni, D. C. Liewald, W. D. Hill, S. P. Hagenaars, S. E. Harris,
    S. J. Ritchie, M. Luciano, C. Fawns-Ritchie, D. Lyall, B. Cullen, S. R. Cox, C.
    Hayward, D. J. Porteous, J. Evans, A. M. McIntosh, J. Gallacher, N. Craddock,
    J. P. Pell, D. J. Smith, C. R. Gale, I. J. Deary
  - 2016-04-05
  - 10.1038/mp.2016.45
  - <p>People’s differences in cognitive functions are partly heritable and are associated
    with important life outcomes. Previous genome-wide association (GWA) studies of
    cognitive functions have found evidence for polygenic effects yet, to date, there
    are few replicated genetic associations. Here we use data from the UK Biobank
    sample to investigate the genetic contributions to variation in tests of three
    cognitive functions and in educational attainment. GWA analyses were performed
    for verbal–numerical reasoning (<em>N</em>=36 035), memory (<em>N</em>=112 067),
    reaction time (<em>N</em>=111 483) and for the attainment of a college or a university
    degree (<em>N</em>=111 114). We report genome-wide significant single-nucleotide
    polymorphism (SNP)-based associations in 20 genomic regions, and significant gene-based
    findings in 46 regions. These include findings in the <em>ATXN2</em>, <em>CYP2DG</em>,
    <em>APBA1</em> and <em>CADM2</em> genes. We report replication of these hits in
    published GWA studies of cognitive function, educational attainment and childhood
    intelligence. There is also replication, in UK Biobank, of SNP hits reported previously
    in GWA studies of educational attainment and cognitive function. GCTA-GREML analyses,
    using common SNPs (minor allele frequency&gt;0.01), indicated significant SNP-based
    heritabilities of 31% (s.e.m.=1.8%) for verbal–numerical reasoning, 5% (s.e.m.=0.6%)
    for memory, 11% (s.e.m.=0.6%) for reaction time and 21% (s.e.m.=0.6%) for educational
    attainment. Polygenic score analyses indicate that up to 5% of the variance in
    cognitive test scores can be predicted in an independent cohort. The genomic regions
    identified include several novel loci, some of which have been associated with
    intracranial volume, neurodegeneration, Alzheimer’s disease and schizophrenia.</p>
- - https://www.nature.com/articles/mp201645
  - Genome-wide association study of cognitive functions and educational attainment
    in UK Biobank (<em>N</em>=112 151)
  - G. Davies, R. E. Marioni, D. C. Liewald, W. D. Hill, S. P. Hagenaars, S. E. Harris,
    S. J. Ritchie, M. Luciano, C. Fawns-Ritchie, D. Lyall, B. Cullen, S. R. Cox, C.
    Hayward, D. J. Porteous, J. Evans, A. M. McIntosh, J. Gallacher, N. Craddock,
    J. P. Pell, D. J. Smith, C. R. Gale, I. J. Deary
  - 2016-04-05
  - 10.1038/mp.2016.45
  - <p>People’s differences in cognitive functions are partly heritable and are associated
    with important life outcomes. Previous genome-wide association (GWA) studies of
    cognitive functions have found evidence for polygenic effects yet, to date, there
    are few replicated genetic associations. Here we use data from the UK Biobank
    sample to investigate the genetic contributions to variation in tests of three
    cognitive functions and in educational attainment. GWA analyses were performed
    for verbal–numerical reasoning (<em>N</em>=36 035), memory (<em>N</em>=112 067),
    reaction time (<em>N</em>=111 483) and for the attainment of a college or a university
    degree (<em>N</em>=111 114). We report genome-wide significant single-nucleotide
    polymorphism (SNP)-based associations in 20 genomic regions, and significant gene-based
    findings in 46 regions. These include findings in the <em>ATXN2</em>, <em>CYP2DG</em>,
    <em>APBA1</em> and <em>CADM2</em> genes. We report replication of these hits in
    published GWA studies of cognitive function, educational attainment and childhood
    intelligence. There is also replication, in UK Biobank, of SNP hits reported previously
    in GWA studies of educational attainment and cognitive function. GCTA-GREML analyses,
    using common SNPs (minor allele frequency&gt;0.01), indicated significant SNP-based
    heritabilities of 31% (s.e.m.=1.8%) for verbal–numerical reasoning, 5% (s.e.m.=0.6%)
    for memory, 11% (s.e.m.=0.6%) for reaction time and 21% (s.e.m.=0.6%) for educational
    attainment. Polygenic score analyses indicate that up to 5% of the variance in
    cognitive test scores can be predicted in an independent cohort. The genomic regions
    identified include several novel loci, some of which have been associated with
    intracranial volume, neurodegeneration, Alzheimer’s disease and schizophrenia.</p>
- - http://www.nature.com/mp/journal/vaop/ncurrent/full/mp2016244a.html
  - ! 'GWAS meta-analysis reveals novel loci and genetic correlates for general cognitive
    function: a report from the COGENT consortium'
  - J. W. Trampush, M. L. Z. Yang, J. Yu, E. Knowles, G. Davies, D. C. Liewald, J.
    M. Starr, S. Djurovic, I. Melle, K. Sundet, A. Christoforou, I. Reinvang, P. DeRosse,
    A. J. Lundervold, V. M. Steen, T. Espeseth, K. Räikkönen, E. Widen, A. Palotie,
    J. G. Eriksson, I. Giegling, B. Konte, P. Roussos, S. Giakoumaki, K. E. Burdick,
    A. Payton, W. Ollier, M. Horan, O. Chiba-Falek, D. K. Attix, A. C. Need, E. T.
    Cirulli, A. N. Voineskos, N. C. Stefanis, D. Avramopoulos, A. Hatzimanolis, D.
    E. Arking, N. Smyrnis, R. M. Bilder, N. A. Freimer, T. D. Cannon, E. London, R.
    A. Poldrack, F. W. Sabb, E. Congdon, E. D. Conley, M. A. Scult, D. Dickinson,
    R. E. Straub, G. Donohoe, D. Morris, A. Corvin, M. Gill, A. R. Hariri, D. R. Weinberger,
    N. Pendleton, P. Bitsios, D. Rujescu, J. Lahti, S. Le Hellard, M. C. Keller, O.
    A. Andreassen, I. J. Deary, D. C. Glahn, A. K. Malhotra, T. Lencz
  - 2017-01-17
  - 10.1038/mp.2016.244
  - ! 'The complex nature of human cognition has resulted in cognitive genomics lagging
    behind many other fields in terms of gene discovery using genome-wide association
    study (GWAS) methods. In an attempt to overcome these barriers, the current study
    utilized GWAS meta-analysis to examine the association of common genetic variation
    (~8M single-nucleotide polymorphisms (SNP) with minor allele frequency ⩾1%) to
    general cognitive function in a sample of 35 298 healthy individuals of European
    ancestry across 24 cohorts in the Cognitive Genomics Consortium (COGENT). In addition,
    we utilized individual SNP lookups and polygenic score analyses to identify genetic
    overlap with other relevant neurobehavioral phenotypes. Our primary GWAS meta-analysis
    identified two novel SNP loci (top SNPs: rs76114856 in the CENPO gene on chromosome
    2 and rs6669072 near LOC105378853 on chromosome 1) associated with cognitive performance
    at the genome-wide significance level (<em>p</em><5 × 10^−8^). Gene-based analysis
    identified an additional three Bonferroni-corrected significant loci at chromosomes
    17q21.31, 17p13.1 and 1p13.3. Altogether, common variation across the genome resulted
    in a conservatively estimated SNP heritability of 21.5% (s.e.=0.01%) for general
    cognitive function. Integration with prior GWAS of cognitive performance and educational
    attainment yielded several additional significant loci. Finally, we found robust
    polygenic correlations between cognitive performance and educational attainment,
    several psychiatric disorders, birth length/weight and smoking behavior, as well
    as a novel genetic association to the personality trait of openness. These data
    provide new insight into the genetics of neurocognitive function with relevance
    to understanding the pathophysiology of neuropsychiatric illness.'
- - https://www.nature.com/articles/mp2016244
  - ! 'GWAS meta-analysis reveals novel loci and genetic correlates for general cognitive
    function: a report from the COGENT consortium'
  - J. W. Trampush, M. L. Z. Yang, J. Yu, E. Knowles, G. Davies, D. C. Liewald, J.
    M. Starr, S. Djurovic, I. Melle, K. Sundet, A. Christoforou, I. Reinvang, P. DeRosse,
    A. J. Lundervold, V. M. Steen, T. Espeseth, K. Räikkönen, E. Widen, A. Palotie,
    J. G. Eriksson, I. Giegling, B. Konte, P. Roussos, S. Giakoumaki, K. E. Burdick,
    A. Payton, W. Ollier, M. Horan, O. Chiba-Falek, D. K. Attix, A. C. Need, E. T.
    Cirulli, A. N. Voineskos, N. C. Stefanis, D. Avramopoulos, A. Hatzimanolis, D.
    E. Arking, N. Smyrnis, R. M. Bilder, N. A. Freimer, T. D. Cannon, E. London, R.
    A. Poldrack, F. W. Sabb, E. Congdon, E. D. Conley, M. A. Scult, D. Dickinson,
    R. E. Straub, G. Donohoe, D. Morris, A. Corvin, M. Gill, A. R. Hariri, D. R. Weinberger,
    N. Pendleton, P. Bitsios, D. Rujescu, J. Lahti, S. Le Hellard, M. C. Keller, O.
    A. Andreassen, I. J. Deary, D. C. Glahn, A. K. Malhotra, T. Lencz
  - 2017-01-17
  - 10.1038/mp.2016.244
  - ! 'The complex nature of human cognition has resulted in cognitive genomics lagging
    behind many other fields in terms of gene discovery using genome-wide association
    study (GWAS) methods. In an attempt to overcome these barriers, the current study
    utilized GWAS meta-analysis to examine the association of common genetic variation
    (~8M single-nucleotide polymorphisms (SNP) with minor allele frequency ⩾1%) to
    general cognitive function in a sample of 35 298 healthy individuals of European
    ancestry across 24 cohorts in the Cognitive Genomics Consortium (COGENT). In addition,
    we utilized individual SNP lookups and polygenic score analyses to identify genetic
    overlap with other relevant neurobehavioral phenotypes. Our primary GWAS meta-analysis
    identified two novel SNP loci (top SNPs: rs76114856 in the CENPO gene on chromosome
    2 and rs6669072 near LOC105378853 on chromosome 1) associated with cognitive performance
    at the genome-wide significance level (<em>p</em><5 × 10^−8^). Gene-based analysis
    identified an additional three Bonferroni-corrected significant loci at chromosomes
    17q21.31, 17p13.1 and 1p13.3. Altogether, common variation across the genome resulted
    in a conservatively estimated SNP heritability of 21.5% (s.e.=0.01%) for general
    cognitive function. Integration with prior GWAS of cognitive performance and educational
    attainment yielded several additional significant loci. Finally, we found robust
    polygenic correlations between cognitive performance and educational attainment,
    several psychiatric disorders, birth length/weight and smoking behavior, as well
    as a novel genetic association to the personality trait of openness. These data
    provide new insight into the genetics of neurocognitive function with relevance
    to understanding the pathophysiology of neuropsychiatric illness.'
- - http://www.nature.com/mp/journal/v21/n3/full/mp20152a.html
  - Genetic link between family socioeconomic status and children’s educational achievement
    estimated from genome-wide SNPs
  - Eva Krapohl, Robert Plomin
  - 2015-03-10
  - 10.1038/mp.2015.2
  - One of the best predictors of children’s educational achievement is their family’s
    socioeconomic status (SES), but the degree to which this association is genetically
    mediated remains unclear. For 3000 UK-representative unrelated children we found
    that genome-wide single-nucleotide polymorphisms could explain a third of the
    variance of scores on an age-16 UK national examination of educational achievement
    and half of the correlation between their scores and family SES. Moreover, genome-wide
    polygenic scores based on a previously published genome-wide association meta-analysis
    of total number of years in education accounted for ~3.0% variance in educational
    achievement and ~2.5% in family SES. This study provides the first molecular evidence
    for substantial genetic influence on differences in children’s educational achievement
    and its association with family SES.
- - https://www.nature.com/articles/mp20152
  - Genetic link between family socioeconomic status and children’s educational achievement
    estimated from genome-wide SNPs
  - Eva Krapohl, Robert Plomin
  - 2015-03-10
  - 10.1038/mp.2015.2
  - One of the best predictors of children’s educational achievement is their family’s
    socioeconomic status (SES), but the degree to which this association is genetically
    mediated remains unclear. For 3000 UK-representative unrelated children we found
    that genome-wide single-nucleotide polymorphisms could explain a third of the
    variance of scores on an age-16 UK national examination of educational achievement
    and half of the correlation between their scores and family SES. Moreover, genome-wide
    polygenic scores based on a previously published genome-wide association meta-analysis
    of total number of years in education accounted for ~3.0% variance in educational
    achievement and ~2.5% in family SES. This study provides the first molecular evidence
    for substantial genetic influence on differences in children’s educational achievement
    and its association with family SES.
- - http://www.nature.com/mp/journal/v16/n10/full/mp201185a.html
  - Genome-wide association studies establish that human intelligence is highly heritable
    and polygenic
  - G. Davies, A. Tenesa, A. Payton, J. Yang, S. E. Harris, D. Liewald, X. Ke, S.
    Le Hellard, A. Christoforou, M. Luciano, K. McGhee, L. Lopez, A. J. Gow, J. Corley,
    P. Redmond, H. C. Fox, P. Haggarty, L. J. Whalley, G. McNeill, M. E. Goddard,
    T. Espeseth, A. J. Lundervold, I. Reinvang, A. Pickles, V. M. Steen, W. Ollier,
    D. J. Porteous, M. Horan, J. M. Starr, N. Pendleton, P. M. Visscher, I. J. Deary
  - 2011-08-09
  - 10.1038/mp.2011.85
  - General intelligence is an important human quantitative trait that accounts for
    much of the variation in diverse cognitive abilities. Individual differences in
    intelligence are strongly associated with many important life outcomes, including
    educational and occupational attainments, income, health and lifespan. Data from
    twin and family studies are consistent with a high heritability of intelligence,
    but this inference has been controversial. We conducted a genome-wide analysis
    of 3511 unrelated adults with data on 549 692 single nucleotide polymorphisms
    (SNPs) and detailed phenotypes on cognitive traits. We estimate that 40% of the
    variation in crystallized-type intelligence and 51% of the variation in fluid-type
    intelligence between individuals is accounted for by linkage disequilibrium between
    genotyped common SNP markers and unknown causal variants. These estimates provide
    lower bounds for the narrow-sense heritability of the traits. We partitioned genetic
    variation on individual chromosomes and found that, on average, longer chromosomes
    explain more variation. Finally, using just SNP data we predicted ∼1% of the variance
    of crystallized and fluid cognitive phenotypes in an independent sample (<em>p</em>=0.009
    and 0.028, respectively). Our results unequivocally confirm that a substantial
    proportion of individual differences in human intelligence is due to genetic variation,
    and are consistent with many genes of small effects underlying the additive genetic
    influences on intelligence.
- - https://www.nature.com/articles/mp201185
  - Genome-wide association studies establish that human intelligence is highly heritable
    and polygenic
  - G. Davies, A. Tenesa, A. Payton, J. Yang, S. E. Harris, D. Liewald, X. Ke, S.
    Le Hellard, A. Christoforou, M. Luciano, K. McGhee, L. Lopez, A. J. Gow, J. Corley,
    P. Redmond, H. C. Fox, P. Haggarty, L. J. Whalley, G. McNeill, M. E. Goddard,
    T. Espeseth, A. J. Lundervold, I. Reinvang, A. Pickles, V. M. Steen, W. Ollier,
    D. J. Porteous, M. Horan, J. M. Starr, N. Pendleton, P. M. Visscher, I. J. Deary
  - 2011-08-09
  - 10.1038/mp.2011.85
  - General intelligence is an important human quantitative trait that accounts for
    much of the variation in diverse cognitive abilities. Individual differences in
    intelligence are strongly associated with many important life outcomes, including
    educational and occupational attainments, income, health and lifespan. Data from
    twin and family studies are consistent with a high heritability of intelligence,
    but this inference has been controversial. We conducted a genome-wide analysis
    of 3511 unrelated adults with data on 549 692 single nucleotide polymorphisms
    (SNPs) and detailed phenotypes on cognitive traits. We estimate that 40% of the
    variation in crystallized-type intelligence and 51% of the variation in fluid-type
    intelligence between individuals is accounted for by linkage disequilibrium between
    genotyped common SNP markers and unknown causal variants. These estimates provide
    lower bounds for the narrow-sense heritability of the traits. We partitioned genetic
    variation on individual chromosomes and found that, on average, longer chromosomes
    explain more variation. Finally, using just SNP data we predicted ∼1% of the variance
    of crystallized and fluid cognitive phenotypes in an independent sample (<em>p</em>=0.009
    and 0.028, respectively). Our results unequivocally confirm that a substantial
    proportion of individual differences in human intelligence is due to genetic variation,
    and are consistent with many genes of small effects underlying the additive genetic
    influences on intelligence.
- - http://www.mdpi.com/1660-4601/14/6/627/htm
  - ! 'Lithium in Drinking Water and Incidence of Suicide: A Nationwide Individual-Level
    Cohort Study with 22 Years of Follow-Up'
  - Nikoline N. Knudsen, Jörg Schullehner, Birgitte Hansen, Lisbeth F. Jørgensen,
    Søren M. Kristiansen, Denitza D. Voutchkova, Thomas A. Gerds, Per K. Andersen,
    Kristine Bihrmann, Morten Grønbæk, Lars V. Kessing, Annette K. Ersbøll
  - 2017-06-10
  - 10.3390/ijerph14060627
  - ! 'Suicide is a major public health concern. High-dose lithium is used to stabilize
    mood and prevent suicide in patients with affective disorders. Lithium occurs
    naturally in drinking water worldwide in much lower doses, but with large geographical
    variation. Several studies conducted at an aggregate level have suggested an association
    between lithium in drinking water and a reduced risk of suicide; however, a causal
    relation is uncertain. Individual-level register-based data on the entire Danish
    adult population (3.7 million individuals) from 1991 to 2012 were linked with
    a moving five-year time-weighted average (TWA) lithium exposure level from drinking
    water hypothesizing an inverse relationship. The mean lithium level was 11.6 μg/L
    ranging from 0.6 to 30.7 μg/L. The suicide rate decreased from 29.7 per 100,000
    person-years at risk in 1991 to 18.4 per 100,000 person-years in 2012. We found
    no significant indication of an association between increasing five-year TWA lithium
    exposure level and decreasing suicide rate. The comprehensiveness of using individual-level
    data and spatial analyses with 22 years of follow-up makes a pronounced contribution
    to previous findings. Our findings demonstrate that there does not seem to be
    a protective effect of exposure to lithium on the incidence of suicide with levels
    below 31 μg/L in drinking water. [Keywords: drinking water; lithium; suicide;
    individual-level data; spatial analysis; Denmark; exposure assessment]'
- - http://www.matthewckeller.com/16.Hatemi.et.al.2010.Nuc.fam.ajps.pdf
  - ! 'Not by Twins Alone: Using the Extended Family Design to Investigate Genetic
    Influence on Political Beliefs'
  - Peter K. Hatemi, John R. Hibbing, Sarah E. Medland, Matthew C. Keller, John R.
    Alford, Kevin B. Smith, Nicholas G. Martin, Lindon J. Eaves
  - 2010-06-10
  - 10.1111/j.1540-5907.2010.00461.x
  - Variance components estimates of political and social attitudes suggest a substantial
    level of genetic influence, but the results have been challenged because they
    rely on data from twins only. In this analysis, we include responses from parents
    and nontwin full siblings of twins, account for measurement error by using a panel
    design, and estimate genetic and environmental variance by maximum‐likelihood
    structural equation modeling. By doing so, we address the central concerns of
    critics, including that the twin‐only design offers no verification of either
    the equal environments or random mating assumptions. Moving beyond the twin‐only
    design leads to the conclusion that for most political and social attitudes, genetic
    influences account for an even greater proportion of individual differences than
    reported by studies using more limited data and more elementary estimation techniques.
    These findings make it increasingly difficult to deny that—however indirectly—genetics
    plays a role in the formation of political and social attitudes.
- - http://www.louischauvel.org/DAVIES2089714.pdf
  - Toward a Theory of Revolution
  - James C. Davie
  - 1962-02
  - 10.2307/2089714
  - Revolutions are most likely to occur when a prolonged period of objective economic
    and social development is followed by a short period of sharp reversal. People
    then subjectively fear that ground gained with great effort will be quite lost;
    their mood becomes revolutionary. The evidence from Dorr's Rebellion, the Russian
    Revolution, and the Egyptian Revolution supports this notion; tentatively, so
    do data on other civil disturbances. Various statistics&mdash;as on rural uprisings,
    industrial strikes, unemployment, and cost of living&mdash;may serve as crude
    indexes of popular mood. More useful, though less easy to obtain, are direct questions
    in cross-sectional interviews. The goal of predicting revolution is conceived
    but not yet born or mature
- - http://www.rand.org/pubs/monographs/MG1026.html
  - An Economic Analysis of the Financial Records of al-Qa'ida in Iraq
  - Benjamin Bahney, Howard J. Shatz, Carroll Ganier, Renny McPherson, Barbara Sude,
    Sara Beth Elson, Ghassan Schbley (RAND)
  - '2010'
  - ''
  - ! 'This monograph analyzes the finances of the militant group al-Qa''ida in Iraq
    (AQI) in Anbar province during 2005 and 2006, at the peak of the group''s power
    and influence. The authors draw on captured documents that give details on the
    daily financial transactions of one specific sector within Anbar province and
    of the financial transactions of the AQI provincial administration. Some of their
    conclusions are: AQI was a hierarchical organization with decentralized decision-making;
    AQI in Anbar was profitable enough to send substantial revenues out of the province
    in 2006; AQI relied on extortion, theft, and black market sales to fund its operations
    in Anbar; AQI needed large, regular revenue sources to fund its operations, but
    its administrative leaders did not hold much cash on hand. The authors'' interpretation
    of data on compensation practices and participants'' risk of death indicates that
    AQI members were poorly compensated and suggests that they were not motivated
    primarily by money to join the group. The authors also find that mounting attacks
    required organizational expenditures well beyond the cost of material used in
    attacks. One major conclusion is that disrupting AQI''s financial flows could
    disrupt the pace of their attacks.'
- - /Turing-complete#on-seeing-through-and-unseeing
  - ! 'On Seeing Through: The Security Mindset as Reductionism Run Amok'
  - Gwern Branwen
  - 2019-06-15
  - ''
  - ! '<p>What is the ‘hacker mindset’ or ‘security mentality’? What do accidentally
    Turing-complete systems and weird machines have in common with heist movies or
    cons or stage magic? They all share a specific paradigm whose essence is about
    <em>seeing through</em> illusions to a truer more reduced reality.</p><p>What
    they/OP/security/<a href="!Wikipedia">speedrunning</a>/hacking/<a href="!Wikipedia"
    title="Social engineering (security)">social-engineering</a> all have in common
    is that they show that the much-ballyhooed ‘hacker mindset’ is, fundamentally,
    a sort of reductionism run amok, where one <a href="/docs/philo/2012-sistery-tryingtoseethrough.html">‘sees
    through’</a> abstractions to a manipulable reality. Like Neo in the <em>Matrix</em>—a
    deeply cliche analogy for hacking, but cliche because it resonates—one achieves
    enlightenment by seeing through the surface illusions of objects and can now see
    the endless lines of green code which make up the Matrix.</p><p>In each case,
    the fundamental principle is that the hacker asks: “here I have a system W, which
    pretends to be made out of a few <a href="https://github.com/kdeldycke/awesome-falsehood"
    title="Falsehoods Programmers Believe About X">Xs</a>; however, it is <strong>really</strong>
    made out of many <em>Y</em>, which form an entirely different system, <em>Z</em>;
    I will now proceed to ignore the <em>X</em> and understand how <em>Z</em> works,
    so I may use the <em>Y</em> to thereby change <em>W</em> however I like”.</p>'
- - https://www.theatlantic.com/technology/archive/2012/05/the-perfect-milk-machine-how-big-data-transformed-the-dairy-industry/256423/
  - ! 'The Perfect Milk Machine: How Big Data Transformed the Dairy Industry: Dairy
    scientists are the Gregor Mendels of the genomics age, developing new methods
    for understanding the link between genes and living things, all while quadrupling
    the average cow''s milk production since your parents were born.'
  - Alexis C. Madrigal (The Atlantic)
  - 2012-05-01
  - ''
  - ! '<p>…Already, Badger-Bluff Fanny Freddie has 346 daughters who are on the books
    and thousands more that will be added to his progeny count when they start producing
    milk. This is quite a career for a young animal: He was only born in 2004.</p><p>There
    is a reason, of course, that the semen that Badger-Bluff Fanny Freddie produces
    has become such a hot commodity in what one artificial-insemination company calls
    “today’s fast paced cattle semen market.” In January of 2009, before he had a
    single daughter producing milk, the United States Department of Agriculture took
    a look at his lineage and more than 50,000 markers on his genome and declared
    him the best bull in the land. And, three years and 346 milk- and data-providing
    daughters later, it turns out that they were right. “When Freddie [as he is known]
    had no daughter records our equations predicted from his DNA that he would be
    the best bull,” USDA research geneticist Paul VanRaden emailed me with a detectable
    hint of pride. “Now he is the best progeny tested bull (as predicted).”</p><p>Data-driven
    predictions are responsible for a massive transformation of America’s dairy cows.
    While other industries are just catching on to this whole “big data” thing, the
    animal sciences—and dairy breeding in particular—have been using large amounts
    of data since long before VanRaden was calculating the outsized genetic impact
    of the most sought-after bulls with a pencil and paper in the 1980s. Dairy breeding
    is perfect for quantitative analysis. Pedigree records have been assiduously kept;
    relatively easy artificial insemination has helped centralized genetic information
    in a small number of key bulls since the 1960s; there are a relatively small and
    easily measurable number of traits—milk production, fat in the milk, protein in
    the milk, longevity, udder quality—that breeders want to optimize; each cow works
    for three or four years, which means that farmers invest thousands of dollars
    into each animal, so it’s worth it to get the best semen money can buy. The economics
    push breeders to use the genetics.</p><p>The bull market (heh) can be reduced
    to one key statistic, lifetime net merit, though there are many nuances that the
    single number cannot capture. Net merit denotes the likely additive value of a
    bull’s genetics. The number is actually denominated in dollars because it is an
    estimate of how much a bull’s genetic material will likely improve the revenue
    from a given cow. A very complicated equation weights all of the factors that
    go into dairy breeding and—voila—you come out with this single number. For example,
    a bull that could help a cow make an extra 1000 pounds of milk over her lifetime
    only gets an increase of $1 in net merit while a bull who will help that same
    cow produce a pound more protein will get $3.41 more in net merit. An increase
    of a single month of predicted productive life yields $35 more.</p><p>…In 1942,
    when my father was born, the average dairy cow produced less than 5,000 pounds
    of milk in its lifetime. Now, the average cow produces over 21,000 pounds of milk.
    At the same time, the number of dairy cows has decreased from a high of 25 million
    around the end of World War II to fewer than nine million today…a mere 70 years
    of quantitative breeding optimized to suit corporate imperatives quadrupled what
    all previous civilization had accomplished.</p><p>…John Cole, yet another USDA
    animal improvement scientist, <a title="''Use of haplotypes to estimate Mendelian
    sampling effects and selection limits'', Cole &amp; VanRaden 2011" href="https://www.aipl.arsusda.gov/publish/other/2011/Cole-VanRaden_JABG-EV_4-13-11.pdf">generated
    an estimate of the perfect bull</a> by choosing the optimal observed genetic sequences
    and hypothetically combining them. He found that the optimal bull would have a
    net merit value of $7,515, which absolutely blows any current bull out of the
    water. In other words, we’re nowhere near creating the perfect milk machine.</p>'
- - https://www.aipl.arsusda.gov/publish/other/2011/Cole-VanRaden_JABG-EV_4-13-11.pdf
  - Use of haplotypes to estimate Mendelian sampling effects and selection limits
  - J.B. Cole, P.M. VanRaden
  - '2011'
  - 10.1111/j.1439-0388.2011.00922.x
  - ! '<p>Limits to selection and Mendelian sampling (MS) terms can be calculated
    using haplotypes by summing the individual additive effects on each chromosome.
    Haplotypes were imputed for 43&thinsp;382 single nucleotide polymorphisms (SNP) in 1455
    Brown Swiss, 40&thinsp;351 Holstein and4064 Jersey bulls and cows using the Fortran program
    <code>findhap.f90</code>, which combines population and pedigree haplotyping methods.
    Lower and upper bounds of MS variance were calculated for daughter pregnancy rate
    (a measure of fertility), milk yield, lifetime net merit (a measure of profitability)
    and protein yield assuming either no or complete linkage among SNP on the same
    chromosome. Calculated selection limits were greater than the largest direct genomic
    values observed in all breeds studied. The best chromosomal genotypes generally
    consisted of two copies of the same haplotype even after adjustment for inbreeding.
    Selection of animals rather than chromosomes may result in slower progress, but
    limits may be the same because most chromosomes will become homozygous with either
    strategy. Selection on functions of MS could be used to change variances in later
    generations.</p><p>…<em>Lifetime net merit</em>: Lower selection limits for NM$
    with no adjustment for inbreeding were $3857 (BS), $7515 (HO) and $4678 (JE).
    Adjusted values were slightly smaller and were $3817 (BS), $7494 (HO) and $4606
    (JE). Upper bounds had values of $9140 (BS), $23&thinsp;588 (HO) and $11517 (JE) and
    were not adjusted for inbreeding because they were calculated from individual
    loci rather than complete haplotypes. The largest DGV among all genotyped animals
    in each breed were $1102 (BS), $2528 (HO) and $1556 (JE). The top active bulls
    (AI and foreign bulls with semen distributed in the US that are in or above the
    80th percentile, based on NM) in each breed following the August 2010 genetic
    evaluation had GEBV (Genomic estimated breeding value) for NM$ of +$1094 (BS:
    054BS00374), +$1588 (HO: 001HO08784) and +$1292 (JE: 236JE00146).</p><p>…If two
    copies of each of the 30 best haplotypes in the US Holstein population were combined
    in a single animal (Lower bounds of selection limit/SL<sub>C</sub> for NM$), it
    would have a GEBV for NM$ of +$7515 (Figure 5), approximately five times larger
    than that of the current best Holstein bull in the US, whose GEBV for NM$ are
    +1588.</p>'
- - /docs/genetics/selection/2017-wiggans.pdf
  - ! 'Genomic Selection in Dairy Cattle: The USDA Experience'
  - George R. Wiggans, John B. Cole, Suzanne M. Hubbard, Tad S. Sonstegard
  - '2017'
  - 10.1146/annurev-animal-021815-111422
  - ! 'Genomic selection has revolutionized dairy cattle breeding. Since 2000, assays
    have been developed to genotype large numbers of single-nucleotide polymorphisms
    (SNPs) at relatively low cost. The first commercial SNP genotyping chip was released
    with a set of 54,001 SNPs in December 2007. Over 15,000 genotypes were used to
    determine which SNPs should be used in genomic evaluation of US dairy cattle.
    Official USDA genomic evaluations were first released in January 2009 for Holsteins
    and Jerseys, in August 2009 for Brown Swiss, in April 2013 for Ayrshires, and
    in April 2016 for Guernseys. Producers have accepted genomic evaluations as accurate
    indications of a bull''s eventual daughter-based evaluation. The integration of
    DNA marker technology and genomics into the traditional evaluation system has
    doubled the rate of genetic progress for traits of economic importance, decreased
    generation interval, increased selection accuracy, reduced previous costs of progeny
    testing, and allowed identification of recessive lethals. [Keywords: genetic evaluation,
    single-nucleotide polymorphism, SNP, reliability, imputation, haplotype, genotype]'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.492.757&rep=rep1&type=pdf
  - Selection on Net Merit to Improve Lifetime Profit
  - P. M. VanRaden
  - '2004'
  - 10.3168/jds.S0022-0302(04)73447-5
  - Genetic selection has made dairy cows more profit-able producers of milk. Genetic
    evaluations began with 2 traits measured on a few cows but now include many traits
    measured on millions of cows. Selection indexes from USDA included yield traits
    beginning in 1971, productive life and somatic cell score beginning in 1994, conformation
    traits in 2000, and cow fertility and calving ease in 2003. This latest revision
    of net merit should result in 2% more progress, worth $5 million/yr nationally,
    with improved cow health and fitness, but slightly less progress for yield. Fertility
    and longevity evaluations have similar reliability because cows can have several
    fertility records, each with lower heritability, compared with one longevity record
    with higher heritability. Lifetime profit can be estimated more accurately if
    less heritable traits are evaluated and included instead of ignored. Milk volume
    has a positive value for fluid use, but a negative value for cheese production.
    Thus, multiple selection indexes are needed for different markets and production
    systems. Breeding programs should estimate future rather than current costs and
    prices. Many other nations have derived selection indexes similar to US net merit.
- - http://www.jonathanstray.com/papers/Langlois.pdf
  - Maxims or myths of beauty? A meta-analytic and theoretical review
  - Judith H. Langlois, Lisa Kalakanis, Adam J. Rubenstein, Andrea Larson, Monica
    Hallam, Monica Smoot
  - 2000-05
  - 10.1037//0033-2909.126.3.390
  - Common maxims about beauty suggest that attractiveness is not important in life.
    In contrast, both fitness-related evolutionary theory and socialization theory
    suggest that attractiveness influences development and interaction. In 11 meta-analyses,
    the authors evaluate these contradictory claims, demonstrating that (a) raters
    agree about who is and is not attractive, both within and across cultures; (b)
    attractive children and adults are judged more positively than unattractive children
    and adults, even by those who know them; (c) attractive children and adults are
    treated more positively than unattractive children and adults, even by those who
    know them; and (d) attractive children and adults exhibit more positive behaviors
    and traits than unattractive children and adults. Results are used to evaluate
    social and fitness-related evolutionary theories and the veracity of maxims about
    beauty.
- - http://www.pnas.org/content/early/2018/07/03/1801238115
  - Genetic analysis of social-class mobility in five longitudinal studies
  - Daniel W. Belsky, Benjamin W. Domingue, Robbee Wedow, Louise Arseneault, Jason
    D. Boardman, Avshalom Caspi, Dalton Conley, Jason M. Fletcher, Jeremy Freese,
    Pamela Herd, Terrie E. Moffitt, Richie Poulton, Kamil Sicinski, Jasmin Wertz,
    Kathleen Mullan Harris
  - 2018-07-31
  - 10.1073/pnas.1801238115
  - ! '<p>Genome-wide association study (GWAS) discoveries about educational attainment
    have raised questions about the meaning of the genetics of success. These discoveries
    could offer clues about biological mechanisms or, because children inherit genetics
    and social class from parents, education-linked genetics could be spurious correlates
    of socially transmitted advantages. To distinguish between these hypotheses, we
    studied social mobility in five cohorts from three countries. We found that people
    with more education-linked genetics were more successful compared with parents
    and siblings. We also found mothers’ education-linked genetics predicted their
    children’s attainment over and above the children’s own genetics, indicating an
    environmentally mediated genetic effect. Findings reject pure social-transmission
    explanations of education GWAS discoveries. Instead, genetics influences attainment
    directly through social mobility and indirectly through family environments.</p><p>A
    summary genetic measure, called a “polygenic score,” derived from a genome-wide
    association study (GWAS) of education can modestly predict a person’s educational
    and economic success. This prediction could signal a biological mechanism: Education-linked
    genetics could encode characteristics that help people get ahead in life. Alternatively,
    prediction could reflect social history: People from well-off families might stay
    well-off for social reasons, and these families might also look alike genetically.
    A key test to distinguish biological mechanism from social history is if people
    with higher education polygenic scores tend to climb the social ladder beyond
    their parents’ position. Upward mobility would indicate education-linked genetics
    encodes characteristics that foster success. We tested if education-linked polygenic
    scores predicted social mobility in >20,000 individuals in five longitudinal studies
    in the United States, Britain, and New Zealand. Participants with higher polygenic
    scores achieved more education and career success and accumulated more wealth.
    However, they also tended to come from better-off families. In the key test, participants
    with higher polygenic scores tended to be upwardly mobile compared with their
    parents. Moreover, in sibling-difference analysis, the sibling with the higher
    polygenic score was more upwardly mobile. Thus, education GWAS discoveries are
    not mere correlates of privilege; they influence social mobility within a life.
    Additional analyses revealed that a mother’s polygenic score predicted her child’s
    attainment over and above the child’s own polygenic score, suggesting parents’
    genetics can also affect their children’s attainment through environmental pathways.
    Education GWAS discoveries affect socioeconomic attainment through influence on
    individuals’ family-of-origin environments and their social mobility. [Keywords:  genetics,
    social class, social mobility, sociogenomics, polygenic score]</p>'
- - https://www.pnas.org/content/early/2016/05/25/1523592113.full
  - Assortative mating and differential fertility by phenotype and genotype across
    the 20th century
  - Dalton Conley, Thomas Laidley, Daniel W. Belsky, Jason M. Fletcher, Jason D. Boardman,
    Benjamin W. Domingue
  - 2016-05-31
  - 10.1073/pnas.1523592113
  - ! '<p>We describe dynamics in assortative mating and fertility patterns by polygenic
    scores associated with anthropometric traits, depression, and educational attainment
    across birth cohorts from 1920 to 1955. We find that, for example, increases in
    assortative mating at the phenotypic level for education are not matched at the
    genotypic level. We also show that genes related to height are positively associated
    with fertility and that, despite a widening gap between the more and less educated
    with respect to fertility, there is no evidence that this trend is associated
    with genes. These findings are important to our understanding of the roots of
    shifting distributions of health and behavior across generations in US society.</p><p>This
    study asks two related questions about the shifting landscape of marriage and
    reproduction in US society over the course of the last century with respect to
    a range of health and behavioral phenotypes and their associated genetic architecture:
    (i) Has assortment on measured genetic factors influencing reproductive and social
    fitness traits changed over the course of the 20th century? (ii) Has the genetic
    covariance between fitness (as measured by total fertility) and other traits changed
    over time? The answers to these questions inform our understanding of how the
    genetic landscape of American society has changed over the past century and have
    implications for population trends. We show that husbands and wives carry similar
    loadings for genetic factors related to education and height. However, the magnitude
    of this similarity is modest and has been fairly consistent over the course of
    the 20th century. This consistency is particularly notable in the case of education,
    for which phenotypic similarity among spouses has increased in recent years. Likewise,
    changing patterns of the number of children ever born by phenotype are not matched
    by shifts in genotype–fertility relationships over time. Taken together, these
    trends provide no evidence that social sorting is becoming increasingly genetic
    in nature or that dysgenic dynamics have accelerated. [Keywords: assortative mating,
    fertility, polygenic scores, cohort trends]</p>'
- - /docs/iq/2011-gensowski.pdf
  - The Effects of Education, Personality, and IQ on Earnings of High-Ability Men
  - Miriam Gensowski, James Heckman, Peter Savelyev
  - 2011-01-24
  - ''
  - ! '<p>[Preprint version of <a href="/docs/iq/2018-gensowski.pdf">Gensowski 2018</a>]</p><p>This
    paper estimates the internal rate of return (IRR) to education for men and women
    of the Terman sample, a 70-year long prospective cohort study of high-ability
    individuals. The Terman data is unique in that it not only provides full working-life
    earnings histories of the participants, but it also includes detailed profiles
    of each subject, including IQ and measures of latent personality traits. Having
    information on latent personality traits is significant as it allows us to measure
    the importance of personality on educational attainment and lifetime earnings.</p><p>Our
    analysis addresses two problems of the literature on returns to education: First,
    we establish causality of the treatment effect of education on earnings by implementing
    generalized matching on a full set of observable individual characteristics and
    unobserved personality traits. Second, since we observe lifetime earnings data,
    our estimates of the IRR are direct and do not depend on the assumptions that
    are usually made in order to justify the interpretation of regression coefficients
    as rates of return.</p><p>For the males, the returns to education beyond high
    school are sizeable. For example, the IRR for obtaining a bachelor’s degree over
    a high school diploma is 11.1%, and for a doctoral degree over a bachelor’s degree
    it is 6.7%. These results are unique because they highlight the returns to high-ability
    and high-education individuals, who are not well-represented in regular data sets.</p><p>Our
    results highlight the importance of personality and intelligence on our outcome
    variables. We find that personality traits similar to the Big Five personality
    traits are significant factors that help determine educational attainment and
    lifetime earnings. Even holding the level of education constant, measures of personality
    traits have significant effects on earnings. Similarly, IQ is rewarded in the
    labor market, independently of education. Most of the effect of personality and
    IQ on life-time earnings arise late in life, during the prime working years. Therefore,
    estimates from samples with shorter durations underestimate the treatment effects.</p>'
- - /docs/iq/2018-gensowski.pdf
  - Personality, IQ, and lifetime earnings
  - Miriam Gensowski
  - 2018-04
  - 10.1016/j.labeco.2017.12.004
  - ! '<p>[Published version of <a href="/docs/iq/2011-gensowski.pdf">Gensowski et
    al 2011</a>]</p><ul><li>This paper estimates the effects of personality traits
    and IQ on lifetime earnings, both as a sum and individually by age.</li><li>The
    payoffs to personality traits display a concave life-cycle pattern, with the largest
    effects between the ages of 40 and 60.</li><li>The largest effects on earnings
    are found for Conscientiousness, Extraversion, and Agreeableness (negative).</li><li>An
    interaction of traits with education reveals that personality matters most for
    highly educated men.</li><li>The overall effect of Conscientiousness operates
    partly through education, which also has significant returns.</li></ul><p>This
    paper estimates the effects of personality traits and IQ on lifetime earnings
    of the men and women of the Terman study, a high-IQ U.S. sample. Age-by-age earnings
    profiles allow a study of <em>when</em> personality traits affect earnings most,
    and for <em>whom</em> the effects are strongest. I document a concave life-cycle
    pattern in the payoffs to personality traits, with the largest effects between
    the ages of 40 and 60. An interaction of traits with education reveals that personality
    matters most for highly educated men. The largest effects are found for Conscientiousness,
    Extraversion, and Agreeableness (negative), where Conscientiousness operates partly
    through education, which also has significant returns. [Keywords: Personality
    traits, Socio-emotional skills, Cognitive skills, Returns to education, Lifetime
    earnings, Big Five, Human capital, Factor analysis]</p>'
- - https://research.mozilla.org/files/2018/04/The-Effect-of-Ad-Blocking-on-User-Engagement-with-the-Web.pdf
  - The Effect of Ad Blocking on User Engagement with the Web
  - Ben Miroglio, David Zeber, Jofish Kaye, Rebecca Weiss
  - 2018-04-23
  - 10.1145/3178876.3186162
  - Web users are increasingly turning to ad blockers to avoid ads, which are often
    perceived as annoying or an invasion of privacy. While there has been significant
    research into the factors driving ad blocker adoption and the detrimental effect
    to ad publishers on the Web, the resulting effects of ad blocker usage on Web
    users' browsing experience is not well understood. To approach this problem, we
    conduct a retrospective natural field experiment using Firefox browser usage data,
    with the goal of estimating the effect of adblocking on user engagement with the
    Web. We focus on new users who installed an ad blocker after a baseline observation
    period, to avoid comparing different populations. Their subsequent browser activity
    is compared against that of a control group, whose members do not use ad blockers,
    over a corresponding observation period, controlling for prior baseline usage.
    In order to estimate causal effects, we employ propensity score matching on a
    number of other features recorded during the baseline period. In the group that
    installed an ad blocker, we find significant increases in both active time spent
    in the browser (+28% over control) and the number of pages viewed (+15% over control),
    while seeing no change in the number of searches. Additionally, by reapplying
    the same methodology to other popular Firefox browser extensions, we show that
    these effects are specific to ad blockers. We conclude that ad blocking has a
    positive impact on user engagement with the Web, suggesting that any costs of
    using ad blockers to users' browsing experience are largely drowned out by the
    utility that they offer.
- - https://nicholaswpapageorge.files.wordpress.com/2018/05/genes_wealth.pdf
  - Genetic Endowments and Wealth Inequality
  - Daniel Barth, Nicholas W. Papageorge, Kevin Thom
  - 2018-05-16
  - 10.3386/w24642
  - We show that genetic endowments linked to educational attainment strongly and
    robustly predict wealth at retirement. The estimated relationship is not fully
    explained by flexibly controlling for education and labor income. We therefore
    investigate a host of additional mechanisms that could help to explain the gene-wealth
    gradient, including inheritances, mortality, savings, risk preferences, portfolio
    decisions, beliefs about the probabilities of macroeconomic events, and planning
    horizons. The associations we report provide preliminary evidence that genetic
    endowments related to human capital accumulation are associated with wealth not
    only through educational attainment and labor income, but also through a facility
    with complex financial decision-making. Our study illustrates how economic research
    seeking to understand sources of inequality can benefit from recent advances in
    behavioral genetics linking specific observed genetic endowments to economic outcomes.
- - http://slatestarcodex.com/2018/10/30/sort-by-controversial/
  - Sort By Controversial
  - Scott Alexander
  - 2018-10-30
  - ''
  - ! '[Contemporary SF short story; inspired by NN text generation, social media
    dynamics, clickbait, and debates like <a href="https://en.wikipedia.org/wiki/The_dress">''the
    dress''</a>; imagines AI natural language processing systems run amok after being
    trained to maximize user reactions to create clickbait, leading to learning ''scissor
    statements'', claims which are maximally controversial and divide the population
    50-50 between those who find the statement obviously correct and moral, and those
    who find it equally obviously false and immoral, leading to intractable polarizing
    debates, contempt, and warfare.]'
- - http://researchdmr.com/ProbabilityTotalError.pdf
  - Disentangling Bias and Variance in Election Polls
  - Houshmand Shirani-Mehr, David Rothschild, Sharad Goel, Andrew Gelman
  - 2018-07-25
  - 10.1080/01621459.2018.1448823
  - ! 'It is well known among researchers and practitioners that election polls suffer
    from a variety of sampling and nonsampling errors, often collectively referred
    to as total survey error. Reported margins of error typically only capture sampling
    variability, and in particular, generally ignore nonsampling errors in defining
    the target population (e.g., errors due to uncertainty in who will vote). Here,
    we empirically analyze 4221 polls for 608 state-level presidential, senatorial,
    and gubernatorial elections between 1998 and 2014, all of which were conducted
    during the final three weeks of the campaigns. Comparing to the actual election
    outcomes, we find that average survey error as measured by root mean square error
    is approximately 3.5 percentage points, about twice as large as that implied by
    most reported margins of error. We decompose survey error into election-level
    bias and variance terms. We find that average absolute election-level bias is
    about 2 percentage points, indicating that polls for a given election often share
    a common component of error. This shared error may stem from the fact that polling
    organizations often face similar difficulties in reaching various subgroups of
    the population, and that they rely on similar screening rules when estimating
    who will vote. We also find that average election-level variance is higher than
    implied by simple random sampling, in part because polling organizations often
    use complex sampling designs and adjustment procedures. We conclude by discussing
    how these results help explain polling failures in the 2016 U.S. presidential
    election, and offer recommendations to improve polling practice. [Keywords: Margin
    of error, Non-sampling error, Polling bias, Total survey error]'
- - http://people.csail.mit.edu/andyd/rec_method.pdf
  - ! 'Multiplying 10-digit numbers using Flickr: The power of recognition memory'
  - Andrew Drucker
  - '2011'
  - ''
  - ! '<p>In this informal article, I’ll describe the “recognition method”—a simple,
    powerful technique for memorization and mental calculation. Compared to traditional
    memorization techniques, which use elaborate encoding and visualization processes
    [1], the recognition method is easy to learn and requires relatively little effort...The
    method <em>works</em>: using it, I was able to mentally multiply two random 10-digit
    numbers, by the usual grade-school algorithm, on my first attempt! I have a normal,
    untrained memory, and the task would have been impossible by a direct approach.
    (I can’t claim I was speedy: I worked slowly and carefully, using about 7 hours
    plus rest breaks. I practiced twice with 5-digit numbers beforehand.)</p><p>...It
    turns out that ordinary people are incredibly good at this task [recognizing whether
    a photograph has been seen before]. In one of the most widely-cited studies on
    recognition memory, <a href="https://www.sas.upenn.edu/psych/rust-lab/publications/standing_73.pdf"
    title="Learning 10000 pictures">Standing [2]</a> showed participants an epic 10,000
    photographs over the course of 5 days, with 5 seconds’ exposure per image. He
    then tested their familiarity, essentially as described above. The participants
    showed an 83% success rate, suggesting that they had become familiar with about
    6,600 images during their ordeal. Other volunteers, trained on a smaller collection
    of 1,000 images selected for vividness, had a 94% success rate.</p>'
- - /docs/economics/2014-lewis.pdf
  - ! 'Managing an iconic old luxury brand in a new luxury economy: Hermès handbags
    in the US market'
  - Tasha L. Lewis, Brittany Haas
  - 2014-03
  - 10.1386/gfb.1.1.167_1
  - The Hermès brand is synonymous with a wealthy global elite clientele and its products
    have maintained an enduring heritage of craftsmanship that has distinguished it
    among competing luxury brands in the global market. Hermès has remained a family
    business for generations and has successfully avoided recent acquisition attempts
    by luxury group LVMH. Almost half of the luxury firm’s revenue ($1.5B in 2012)
    is derived from the sale of its leather goods and saddlery, which includes its
    handbags. A large contributor to sales is global demand for one of its leather
    accessories, the Birkin bag, ranging in price from $10,000 to $250,000. Increased
    demand for the bag in the United States since 2002 resulted in an extensive customer
    waitlist lasting from months to a few years. Hermès retired the famed waitlist
    (sometimes called the ‘dream list’) in the United States in 2010, and while the
    waitlist has been removed, demand for the Birkin bag has not diminished and making
    the bag available to luxury consumers requires extensive, careful distribution
    management. In addition to inventory constraints related to demand for the Birkin
    bag in the United States, Hermès must also manage a range of other factors in
    the US market. These factors include competition with ‘affordable’ luxury brands
    like Coach, monitoring of unsolicited brand endorsers as well as counterfeit goods
    and resellers. This article examines some of the allocation practices used to
    carefully manage the Hermès brand in the US market.
- - https://www.cs.dartmouth.edu/~sergey/wm/
  - What are Weird Machines?
  - Sergey Bratus
  - '2015'
  - ''
  - <p>The expression <strong>"weird machines"</strong> was first used in the <a href="http://www.cs.dartmouth.edu/~sergey/hc/rss-hacker-research.pdf">RSS
    2009 talk</a>. It referred to state-of-the-art exploitation as finding and programming
    an execution model (a machine, such as a virtual automaton) within the target
    via crafted inputs. It was soon extended to other methods of reliably or probabilistically
    influencing the target's state. A compressed version of that original talk was
    given at the Chaos Computing Congress 27c3 <a href="http://events.ccc.de/congress/2010/Fahrplan/attachments/1807_ccc-hacker-research.pdf">[slides]</a>,
    <a href="http://www.youtube.com/watch?v=4sUmANLFD8s">[video]</a>.</p><p>The concept
    was further elaborated in <a href="http://immunityinc.com/infiltrate/archives/Fundamentals_of_exploitation_revisited.pdf">Exploitation
    and State Machines</a> by Thomas Dullien / Halvar Flake at Infiltrate 2011, <a
    href="http://census-labs.com/media/heap-owasp-appsec-2012.pdf">Heap Exploitation
    Abstraction by Example</a> by Census Labs at <a href="http://log.cedricbonhomme.org/44d3fc878b97103d1ffd5dff7548ba0f0f6de05d/007b37438f20d1dad6e8c92bc5a7af6e414b2c08.html">OWASP
    2012</a>, and others. A historical sketch can be found in <a href="http://langsec.org/papers/Bratus.pdf">From
    Buffer Overflows to "Weird Machines"</a> by Bratus et al.</p><p>Effort is underway
    to produce formal descriptions of weird machine classes in various computing environments.
    Thomas Dullien's 2017 paper <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8226852">Weird
    machines, exploitability, and provable unexploitability</a> is the most notable
    recent development (see <a href="#formalisms">Formalisms</a> below). The <a href="http://langsec.org">LangSec</a>
    effort is aimed at describing and eliminating broad classes of input-related bugs
    and associated weird machines.</p>
- - https://pdfs.semanticscholar.org/5bbe/46d0d07f1371cd8fa54bd05d9dccca9b3a58.pdf
  - Weird machines, exploitability, and provable unexploitability
  - Thomas Dullien
  - 2017-12-19
  - 10.1109/TETC.2017.2785299
  - ! '<p>The concept of <em>exploit</em> is central to computer security, particularly
    in the context of <em>memory corruptions</em>. Yet, in spite of the centrality
    of the concept and voluminous descriptions of various exploitation techniques
    or countermeasures, a good theoretical framework for describing and reasoning
    about exploitation has not yet been put forward.</p><p>A body of concepts and
    folk theorems exists in the community of exploitation practitioners; unfortunately,
    these concepts are rarely written down or made sufficiently precise for people
    outside of this community to benefit from them. This paper clarifies a number
    of these concepts, provides a clear definition of exploit, a clear definition
    of the concept of a <em>weird machine</em>, and how programming of a weird machine
    leads to exploitation. The papers also shows, somewhat counterintuitively, that
    it is feasible to design some software in a way that even powerful attackers&mdash;with
    the ability to corrupt memory once&mdash;cannot gain an advantage.</p><p>The approach
    in this paper is focused on <em>memory corruptions</em>. While it can be applied
    to many security vulnerabilities introduced by other programming mistakes, it
    does not address <em>side channel attacks</em>, <em>protocol weaknesses</em>,
    or security problems that are present by design. [Keywords: Computer Security,
    Computer hacking, Computation Theory, Information security, Language-theoretic
    security]</p>'
- - /docs/traffic/2019-shapiro.pdf
  - Generalizable and Robust TV Advertising Effects
  - Bradley Shapiro, Günter J. Hitsch, Anna Tuchman
  - 2019-06-11
  - 10.2139/ssrn.3273476
  - ! 'We provide generalizable and robust results on the causal sales effect of TV
    advertising based on the distribution of advertising elasticities for a large
    number of products (brands) in many categories. Such generalizable results provide
    a prior distribution that can improve the advertising decisions made by firms
    and the analysis and recommendations of anti-trust and public policy makers. A
    single case study cannot provide generalizable results, and hence the marketing
    literature provides several meta-analyses based on published case studies of advertising
    effects. However, <em>publication bias</em> results if the research or review
    process systematically rejects estimates of small, statistically insignificant,
    or “unexpected” advertising elasticities. Consequently, if there is publication
    bias, the results of a meta-analysis will not reflect the true population distribution
    of advertising effects. To provide <em>generalizable</em> results, we base our
    analysis on a large number of products and clearly lay out the research protocol
    used to select the products. We characterize the distribution of <em>all</em>
    estimates, irrespective of sign, size, or statistical significance. To ensure
    generalizability we document the <em>robustness</em> of the estimates. First,
    we examine the sensitivity of the results to the approach and assumptions made
    when constructing the data used in estimation from the raw sources. Second, as
    we aim to provide causal estimates, we document if the estimated effects are sensitive
    to the identification strategies that we use to claim causality based on observational
    data. Our results reveal substantially smaller effects of own-advertising compared
    to the results documented in the extant literature, as well as a sizable percentage
    of statistically insignificant or negative estimates. If we only select products
    with statistically significant and positive estimates, the mean or median of the
    advertising effect distribution increases by a factor of about five. The results
    are robust to various identifying assumptions, and are consistent with both publication
    bias and bias due to non-robust identification strategies to obtain causal estimates
    in the literature. [Keywords: Advertising, Publication Bias, Generalizability]'
- - /docs/traffic/2018-04-10-tavan-isadblockingtenpercenthigherthancommonlymeasured.html
  - Is Ad Blocking 10% Higher Than Commonly Measured?
  - Christoph Tavan (contentpass)
  - 2018-04-10
  - ''
  - ! '<p>A recent study by contentpass indicates that more than 25% of all ad blockers
    on desktop devices use the EasyPrivacy blocklist and are therefore invisible to
    common website analytics software...The by far most popular filter list to block
    ads is the so-called “Easylist”. It is activated by default in popular ad blockers
    like Adblock Plus, Adblock or uBlock Origin and focuses on blocking ads both on
    a network&mdash;and on a visual level. Even the built-in ad blocker of Google
    Chrome uses this list.</p><p>While EasyPrivacy users are now “invisible” to our
    service as well, we recently integrated our solution under the first party domain
    on a popular German IT news website. As a consequence of this first party integration
    the statistics about ad blocker usage were sent to a different URL, which was
    initially not being blocked by EasyPrivacy. It took about two weeks for the EasyPrivacy
    community to put the statistics URL of the first party domain on a filter list
    again.</p><p>These two weeks of unfiltered data allow us to get an idea of how
    many people use an ad blocker with EasyPrivacy activated (be it Adblock Plus/Adblock
    where the user manually activated EasyPrivacy or uBlock Origin where EasyPrivacy
    is activated by default).</p><p>Our data suggests that over 25% of all users with
    active ad blocking software on desktop devices use EasyPrivacy and are thus invisible
    to major web analytics software. In this specific case the <em>true</em> ad blocking
    rate on desktop was 37% while analytics software that is blocked by EasyPrivacy
    would only report what corresponds to 27% of ad blocking. Or from a different
    perspective: 10% of the total desktop traffic on this website is not analyzed
    and counted by common third party analytics software. Historical data from the
    time where our service was initially added to EasyPrivacy suggests similar proportions
    on other sites and verticals.</p>'
- - /docs/traffic/1991-abernethy.pdf
  - ! 'Television Exposure: Programs vs. Advertising'
  - Avery M. Abernethy
  - '1991'
  - 10.1080/01633392.1991.10504959
  - Although it is generally accepted that television program ratings are greater
    than the audience's exposure to the advertising, the key issue is the actual size
    of the difference. A review of advertising, marketing, communication, and sociology
    literature yields some indications of the degree of difference between ad and
    program exposure and factors in the viewing environment which could influence
    audience commercial avoidance.
- - /docs/traffic/2002-edwards.pdf
  - ! 'Forced Exposure and Psychological Reactance: Antecedents and Consequences of
    the Perceived Intrusiveness of Pop-Up Ads'
  - Steven M. Edwards, Hairong Li, Joo-Hyun Lee
  - '2002'
  - 10.1080/00913367.2002.10673678
  - This paper explores forced viewing of “pop-up ads” on the Internet to understand
    better how viewers come to define ads as irritating and decide to avoid them.
    Perceived intrusiveness was suggested as the underlying mechanism by which the
    process occurs. Antecedents of intrusiveness were identified that affect perceptions
    of ads as interruptions, including congruence of the advertisement content with
    the current task and intensity of cognition at the moment the ad pops up. The
    consequences of intrusiveness were shown to be caused by feelings of irritation
    and ad avoidance. The results provide an understanding of how consumers experience
    forced exposure situations in interactive environments and highlight implications
    for advertisers seeking to increase the effectiveness of on-line advertising.
- - /docs/traffic/2004-galletta.pdf
  - ! 'Web Site Delays: How Tolerant are Users?'
  - Dennis F. Galletta, Raymond Henry, Scott McCoy, Peter Polak
  - '2004'
  - ''
  - Web page loading speed continues to vex users, even as broadband adoption increases.
    Several studies have addressed delays in the context of Web sites as well as interactive
    corporate systems, and have recommended a wide range of 'rules of thumb'. Some
    studies conclude that response times should be no greater than 2 seconds while
    other studies caution on delays of 12 seconds or more. One of the strongest conclusions
    was that complex tasks seemed to allow longer response times. This study examined
    delay times of 0, 2, 4, 6, 8, 10, and 12 seconds using 196 undergraduate students
    in an experiment. Randomly assigned a constant delay time, subjects were asked
    to complete 9 search tasks, exploring a familiar and an unfamiliar site. Plots
    of the dependent variables performance, attitudes, and behavioral intentions,
    along those delays, suggested the use of non-linear regression, and the explained
    variance was in the neighborhood of 2%, 5%, and 7%, respectively. Focusing only
    on the familiar site, explained variance in attitudes and behavioral intentions
    grew to about 16%. A sensitivity analysis implies that decreases in performance
    and behavioral intentions begin to flatten when the delays extend to 4 seconds
    or longer, and attitudes flatten when the delays extend to 8 seconds or longer.
    Future research should include other factors such as expectations, variability,
    and feedback, and other outcomes such as actual purchasing behavior, to more fully
    understand the effects of delays in today's Web environment.
- - /docs/traffic/2000-bayles-justhowblindarewetoadvertisingbannersontheweb.html
  - Just How 'Blind' Are We to Advertising Banners on the Web?
  - Michelle Bayles
  - 2000-07
  - ''
  - ! '<p>Moreover, Benway (1998) showed that extremely colorful and obvious banners
    tend to be ignored by users. When participants in this study were asked to find
    specific information on a web page, the information was not found if it was embedded
    in a banner. Benway consequently named this phenomenon “banner blindness.” Benway
    also found that banners located at the top of the page (away from other links),
    tended to be ignored more often than banners located lower down the page (closer
    to other important links). This finding is supported by another study which showed
    a 77% increased click-through rate for advertisements placed <math display="inline"
    xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mn>3</mn></mfrac><annotation
    encoding="application/x-tex">\frac{1}{3}</annotation></semantics></math> of
    the way down the page (Athenia Assoc., 1997).</p><p>…In our study, we were curious
    to simply explore how much users remember about a web page after viewing it –
    in particular, we were interested in investigating user memory of banner advertisements:</p><ol
    type="1"><li>How well can users’ recall a banner advertisement on a web page?</li><li>How
    well can users’ recognize a banner advertisement on a web page?</li><li>Does animation
    affect user recall or recognition of an advertising banner?</li></ol><p>…Very
    few participants were able to complete both the recognition and recall tasks correctly.
    Only 3 (9%) of participants were able to correctly recall both advertisements,
    recognize both companies, and correctly recall and recognize the state in which
    they were presented. On the other hand, participants who were unable to recall
    anything for either company banner or correctly indicate the animation state of
    the banner (40%) had a surprisingly high recognition rate of 79% for two correctly
    recognized ads. Results also show that of the 26% who recognized only one ad,
    the banner recognized was typically presented in the animated state. In other
    words, 7 out of 9 times the single banner correctly recognized was in the animated
    state. This indicates that animation may have some effect on recognition.</p><p>Results
    from this study indicate that recognition of the banner advertisements were fairly
    high (74% for both banners). In addition, about half of the participants were
    able to recall at least seeing an advertisement on the page—and many of these
    actually recalled the name of the company. These results show that most users
    did notice and remember the banners even though they were not part of the search
    tasks they were performing.</p>'
- - /docs/traffic/2007-mccoy.pdf
  - ! 'The Effects Of Online Advertising: Consumers’ first impressions (and loyalties)
    are made in the opening moments of a Web site visit and the degree to which that
    visit may be intruded by pop-ups, pop-unders, and banner ads'
  - Scott McCoy, Andrea Everard, Peter Polak, Dennis F. Galletta
  - '2007'
  - 10.1145/1226736.1226740
  - <p>We conducted an experiment with different forms and types of ads. An artificial
    Web site was created for the experiment that contained images, prices, and descriptions
    of familiar products and product categories. The products were those that would
    be carried by a general store and included food, health care, and household products.
    Nine search tasks were assigned to participants that would force them to traverse
    a variety of portions of the site...The experimental websites were accessed over
    the Internet in a controlled laboratory setting by 536 undergraduate students.</p><p>...This
    study provides clear support for an assertion that users will adopt more negative
    intentions when a site displays advertisements than when the site does not. It
    is also clear that advertisements interfere with retention of site content and
    that features of advertisements also have important effects on retaining both
    site and ad content. Inline ads permit both site and ad content to be remembered
    more clearly than popups and popunders, a finding that is most interesting because
    it suggests the action of closing the advertisement window distracts users from
    the site, and further, it is visible for a shorter time. When ads are markedly
    different from the content of the site, they theoretically stimulate more effort
    as users work toward an important goal, and users remember more about both the
    Web site and the advertisement. It is interesting to note that while these effects
    might on the surface appear small, they are quite consistent and highly significant.
    Extrapolating to millions of site visitors, even small differences can amount
    to an urgent problem for management. Finally, it is also clear that popups and
    popunders are considered to be more intrusive than inline ads. Users seem to prefer
    not to have to divert their attention from their searching task or take additional
    steps to close the popup or pop-under windows.</p>
- - https://classic.esquire.com/article/1971/10/1/secrets-of-the-blue-box
  - ! 'Secrets of the Little Blue Box: A story so incredible it may even make you
    feel sorry for the phone company'
  - Ron Rosenbaum (Esquire)
  - 1971-10-01
  - ''
  - <p>[Early account of <a href="https://en.wikipedia.org/wiki/Phreaking">“phone
    phreakers”</a> and their most famous hacking device, the <a href="https://en.wikipedia.org/wiki/Blue_box">blue
    box</a>, used to control the Bell Phone System and enable free long-distance calls
    (then exorbitantly expensive); the blue box was famously based on an AT&amp;T
    research paper describing the tone frequencies and how they control the phone
    switching system. The author hangs out with phreaks such as <a href="https://en.wikipedia.org/wiki/John_Draper">Captain
    Crunch</a> to see how it all works.</p><p>After reading Rosenbaum’s article, Steve
    Jobs and his partner in founding Apple, Steve Wozniak, “collaborated on building
    and selling blue boxes, devices that were widely used for making free—and illegal—phone
    calls. They raised a total of $6,000 from the effort.”]</p>
- - /Inflation.hs
  - InflationAdjuster
  - Gwern Branwen
  - 2019-03-27
  - ''
  - ! '<p>Experimental Pandoc module for implementing automatic inflation adjustment
    of nominal date-stamped dollar or Bitcoin amounts to provide real prices; Bitcoin’s
    exchange rate has moved by multiple orders of magnitude over its early years (rendering
    nominal amounts deeply unintuitive), and this is particularly critical in any
    economics or technology discussion where a nominal price from 1950 is 11x the
    2019 real price!</p><p>Years/dates are specified in a variant of my interwiki
    link syntax; for example: <code>[$50]($2000)</code> or <code>[₿0.5]($2017-01-01)</code>,
    giving link adjustments which look like "<span class="inflationAdjusted" data-originalYear="2017-01-01"
    data-originalAmount="50.50" data-currentYear="2019" data-currentAmount="50,500">₿50.50<span
    class="math inline"><em></em><sub>2017</sub><sup>$50,500</sup></span></span>".
    Dollar amounts use year, and Bitcoins use full dates, as the greater temporal
    resolution is necessary. Inflation rates/exchange rates are specified in Inflation.hs
    and need to be manually updated every once in a while; if out of date, the last
    available rate is carried forward for future adjustments.</p>'
- - https://www.nature.com/articles/npp2011276
  - Is Cognitive Functioning Impaired in Methamphetamine Users? A Critical Review
  - Carl L. Hart, Caroline B. Marvin, Rae Silver, Edward E. Smith
  - 2011-11-16
  - 10.1038/npp.2011.276
  - The prevailing view is that recreational methamphetamine use causes a broad range
    of severe cognitive deficits, despite the fact that concerns have been raised
    about interpretations drawn from the published literature. This article addresses
    an important gap in our knowledge by providing a critical review of findings from
    recent research investigating the impact of recreational methamphetamine use on
    human cognition. Included in the discussion are findings from studies that have
    assessed the acute and long-term effects of methamphetamine on several domains
    of cognition, including visuospatial perception, attention, inhibition, working
    memory, long-term memory, and learning. In addition, relevant neuroimaging data
    are reviewed in an effort to better understand neural mechanisms underlying methamphetamine-related
    effects on cognitive functioning. In general, the data on acute effects show that
    methamphetamine improves cognitive performance in selected domains, that is, visuospatial
    perception, attention, and inhibition. Regarding long-term effects on cognitive
    performance and brain-imaging measures, statistically significant differences
    between methamphetamine users and control participants have been observed on a
    minority of measures. More importantly, however, the clinical significance of
    these findings may be limited because cognitive functioning overwhelmingly falls
    within the normal range when compared against normative data. In spite of these
    observations, there seems to be a propensity to interpret any cognitive and/or
    brain difference(s) as a clinically significant abnormality. The implications
    of this situation are multiple, with consequences for scientific research, substance-abuse
    treatment, and public policy.
- - /docs/catnip/2019-jones.pdf
  - ! 'Black Cat Bias: Prevalence and Predictors'
  - Haylie D. Jones, Christian L. Hart
  - 2019-04-29
  - 10.1177/0033294119844982
  - There is anecdotal and empirical evidence for black cat bias, the phenomenon where
    cats (<em>Felis silvestris catus</em>) with black coats are viewed more negatively,
    adopted less often, and euthanized more often than lighter colored cats. Despite
    the anecdotal claims, there is scarce empirical evidence for black cat bias. Using
    evaluations of cat photos, the researchers examined differences in people’s attitudes
    toward black and non-black cats of various colorations on measures of perceived
    aggression, perceived friendliness, and willingness to adopt. The researchers
    also explored whether participants’ levels of religiosity, superstitious beliefs,
    and prejudicial racial attitudes were related to black cat bias. Finally, the
    researchers explored whether black cat bias was related to difficulties people
    had in reading the emotions of black cats compared to non-black cats. This study
    provided evidence of black cat bias in the sample. People exhibiting higher degrees
    of black cat bias had higher levels of superstition, but not religiosity or racial
    prejudice. Additionally, people who had difficulty reading the emotions of black
    cats tended to exhibit a stronger bias against adopting black cats.
- - https://kk.org/thetechnium/the-unabomber-w/
  - The Unabomber Was Right
  - Kevin Kelly
  - 2009-02-18
  - ''
  - ! '<p>Ted Kaczynski, the convicted bomber who blew up dozens of technophilic professionals,
    was right about one thing: technology has its own agenda. The technium is not,
    as most people think, a series of individual artifacts and gadgets for sale. Rather,
    Kaczynski, speaking as the Unabomber, argued that technology is a dynamic holistic
    system. It is not mere hardware; rather it is more akin to an organism. It is
    not inert, nor passive; rather the technium seeks and grabs resources for its
    own expansion. It is not merely the sum of human action, but in fact it transcends
    human actions and desires. I think Kaczynski was right about these claims. In
    his own words the Unabomber says: “The system does not and cannot exist to satisfy
    human needs. Instead, it is human behavior that has to be modified to fit the
    needs of the system. This has nothing to do with the political or social ideology
    that may pretend to guide the technological system. It is the fault of technology,
    because the system is guided not by ideology but by technical necessity.”</p><p>…As
    best I understand, the Unabomber’s argument goes like this:</p><ul><li>Personal
    freedoms are constrained by society, as they must be.</li><li>The stronger that
    technology makes society, the less freedoms.</li><li>Technology destroys nature,
    which strengthens technology further.</li><li>This ratchet of technological self-amplification
    is stronger than politics.</li><li>Any attempt to use technology or politics to
    tame the system only strengthens it.</li><li>Therefore technological civilization
    must be destroyed, rather than reformed.</li><li>Since it cannot be destroyed
    by tech or politics, humans must push industrial society towards its inevitable
    end of self-collapse.</li><li>Then pounce on it when it is down and kill it before
    it rises again.</li></ul><p>…The problem is that Kaczynski’s most basic premise,
    the first axiom in his argument, is not true. The Unabomber claims that technology
    robs people of freedom. But most people of the world find the opposite. They gravitate
    towards venues of increasing technology because they recognize they have more
    freedoms when they are empowered with it. They (that is we) realistically weigh
    the fact that yes, indeed, some options are closed off when adopting new technology,
    but many others are opened, so that the net gain is a plus of freedom, choices,
    and possibilities…It is possible that the technium has brainwashed us all, except
    for a few clear-eyed anarcho-primitivists who like to blow up stuff. I would be
    inclined to believe in the anarchy if the Unabomber’s alternative to civilization
    was more clear. After we destroy civilization, then what?</p>'
- - https://www.nybooks.com/articles/2012/09/27/philosopher-defends-religion/?pagination=false
  - A Philosopher Defends Religion [review of Plantinga, <em>Where the Conflict Really
    Lies</em>]
  - Thomas Nagel
  - 2012-09-27
  - ''
  - ! '<p>The gulf in outlook between atheists and adherents of the monotheistic religions
    is profound. We are fortunate to live under a constitutional system and a code
    of manners that by and large keep it from disturbing the social peace; usually
    the parties ignore each other. But sometimes the conflict surfaces and heats up
    into a public debate. The present is such a time.</p><p>… In his absorbing new
    book, <em>Where the Conflict Really Lies</em>, Alvin Plantinga, a distinguished
    analytic philosopher known for his contributions to metaphysics and theory of
    knowledge as well as to the philosophy of religion, turns this alleged opposition
    on its head. His overall claim is that “there is superficial conflict but deep
    concord between science and theistic religion, but superficial concord and deep
    conflict between science and naturalism.” By naturalism he means the view that
    the world describable by the natural sciences is all that exists, and that there
    is no such person as God, or anything like God. Plantinga’s religion is the real
    thing, not just an intellectual deism that gives God nothing to do in the world.
    He himself is an evangelical Protestant, but he conducts his argument with respect
    to a version of Christianity that is the “rough intersection of the great Christian
    creeds”—ranging from the Apostle’s Creed to the Anglican Thirty-Nine Articles—according
    to which God is a person who not only created and maintains the universe and its
    laws, but also intervenes specially in the world, with the miracles related in
    the Bible and in other ways. It is of great interest to be presented with a lucid
    and sophisticated account of how someone who holds these beliefs understands them
    to harmonize with and indeed to provide crucial support for the methods and results
    of the natural sciences…Faith, according to Plantinga, is another basic way of
    forming beliefs, distinct from but not in competition with reason, perception,
    memory, and the others. However, it is</p><blockquote><p>a wholly different kettle
    of fish: according to the Christian tradition (including both Thomas Aquinas and
    John Calvin), faith is a special gift from God, not part of our ordinary epistemic
    equipment. Faith is a source of belief, a source that goes beyond the faculties
    included in reason.</p></blockquote><p>God endows human beings with a <em>sensus
    divinitatis</em> that ordinarily leads them to believe in him. (In atheists the
    <em>sensus divinitatis</em> is either blocked or not functioning properly.)<sup>2</sup>
    In addition, God acts in the world more selectively by “enabling Christians to
    see the truth of the central teachings of the Gospel.”</p><p>If all this is true,
    then by Plantinga’s standard of reliability and proper function, faith is a kind
    of cause that provides a warrant for theistic belief, even though it is a gift,
    and not a universal human faculty. (Plantinga recognizes that rational arguments
    have also been offered for the existence of God, but he thinks it is not necessary
    to rely on these, any more than it is necessary to rely on rational proofs of
    the existence of the external world to know just by looking that there is beer
    in the refrigerator.) It is illuminating to have the starkness of the opposition
    between Plantinga’s theism and the secular outlook so clearly explained. My instinctively
    atheistic perspective implies that if I ever found myself flooded with the conviction
    that what the Nicene Creed says is true, the most likely explanation would be
    that I was losing my mind, not that I was being granted the gift of faith. From
    Plantinga’s point of view, by contrast, I suffer from a kind of spiritual blindness
    from which I am unwilling to be cured. This is a huge epistemological gulf, and
    it cannot be overcome by the cooperative employment of the cognitive faculties
    that we share, as is the hope with scientific disagreements….The interest of this
    book, especially for secular readers, is its presentation from the inside of the
    point of view of a philosophically subtle and scientifically informed theist—an
    outlook with which many of them will not be familiar. Plantinga writes clearly
    and accessibly, and sometimes acidly—in response to aggressive critics of religion
    like Dawkins and Daniel Dennett. His comprehensive stand is a valuable contribution
    to this debate.</p>'
- - http://www.larspenke.eu/pdfs/Penke_&_Jokela_in_press_-_Evolutionary_Genetics_of_Personality_Revisited.pdf
  - The Evolutionary Genetics of Personality Revisited
  - Lars Penke, Markus Jokela
  - 2016-02
  - 10.1016/j.copsyc.2015.08.021
  - <ul><li>Evolutionary forces that maintain genetic variance in traits can be inferred
    from their genetic architecture and fitness correlates.</li><li>A substantial
    amount of new data on the genomics and reproductive success associated with personality
    traits and intelligence has recently become available.</li><li>Intelligence differences
    seem to have been selected for robustness against mutations.</li><li>Human tendencies
    to select, create and adapt to environments might support the maintenance of personality
    traits through balancing selection.</li></ul><p>Like all human individual differences,
    personality traits and intelligence are substantially heritable. From an evolutionary
    perspective, this poses the question what evolutionary forces maintain their genetic
    variation. Information about the genetic architecture and associations with evolutionary
    fitness permit inferences about these evolutionary forces. As our understanding
    of the genomics of personality and its associations with reproductive success
    have grown considerably in recent years, it is time to revisit this question.
    While mutations clearly affect the very low end of the intelligence continuum,
    individual differences in the normal intelligence range seem to be surprisingly
    robust against mutations, suggesting that they might have been canalized to withstand
    such perturbations. Most personality traits, by contrast, seem to be neither neutral
    to selection nor under consistent directional or stabilizing selection. Instead
    evidence is in line with balancing selection acting on personality traits, probably
    supported by human tendencies to seek out, construct and adapt to fitting environments.</p>
- - http://www.joelonsoftware.com/articles/StrategyLetterV.html
  - ! 'Joel on Software: Strategy Letter V'
  - Joel Spolsky
  - 2002-06-11
  - ''
  - ! '<p>Every product in the marketplace has <em>substitutes</em> and <em>complements</em>.
    A substitute is another product you might buy if the first product is too expensive.
    Chicken is a substitute for beef. If you’re a chicken farmer and the price of
    beef goes up, the people will want more chicken, and you will sell more. A complement
    is a product that you usually buy together with another product. Gas and cars
    are complements. Computer hardware is a classic complement of computer operating
    systems. And babysitters are a complement of dinner at fine restaurants. In a
    small town, when the local five star restaurant has a two-for-one Valentine’s
    day special, the local babysitters double their rates. (Actually, the nine-year-olds
    get roped into early service.) All else being equal, demand for a product increases
    when the prices of its complements decrease.</p><p>Let me repeat that because
    you might have dozed off, and it’s important. Demand for a product increases when
    the prices of its complements decrease. For example, if flights to Miami become
    cheaper, demand for hotel rooms in Miami goes up—because more people are flying
    to Miami and need a room. When computers become cheaper, more people buy them,
    and they all need operating systems, so demand for operating systems goes up,
    which means the price of operating systems can go up.</p><p>…Once again: demand
    for a product increases when the price of its complements decreases. In general,
    a company’s strategic interest is going to be to get the price of their complements
    as low as possible. The lowest theoretically sustainable price would be the “commodity
    price”—the price that arises when you have a bunch of competitors offering indistinguishable
    goods. So:</p><p><strong><em>Smart companies try to commoditize their products’
    complements.</em></strong></p><p>If you can do this, demand for your product will
    increase and you will be able to charge more and make more.</p>'
- - http://www.apa.org/pubs/journals/releases/dev-49-2-270.pdf
  - Is Working Memory Training Effective? A Meta-Analytic Review
  - Monica Melby-Lervåg, Charles Hulme
  - 2013-02
  - 10.1037/a002822
  - ! 'It has been suggested that working memory training programs are effective both
    as treatments for attention-deficit/hyperactivity disorder (ADHD) and other cognitive
    disorders in children and as a tool to improve cognitive ability and scholastic
    attainment in typically developing children and adults. However, effects across
    studies appear to be variable, and a systematic meta-analytic review was undertaken.
    To be included in the review, studies had to be randomized controlled trials or
    quasi-experiments without randomization, have a treatment, and have either a treated
    group or an untreated control group. 23 studies with 30 group comparisons met
    the criteria for inclusion. The studies included involved clinical samples and
    samples of typically developing children and adults. Meta-analyses indicated that
    the programs produced reliable short-term improvements in working memory skills.
    For verbal working memory, these near-transfer effects were not sustained at follow-up,
    whereas for visuospatial working memory, limited evidence suggested that such
    effects might be maintained. More importantly, there was no convincing evidence
    of the generalization of working memory training to other skills (nonverbal and
    verbal ability, inhibitory processes in attention, word decoding, and arithmetic).
    The authors conclude that memory training programs appear to produce short-term,
    specific training effects that do not generalize. Possible limitations of the
    review (including age differences in the samples and the variety of different
    clinical conditions included) are noted. However, current findings cast doubt
    on both the clinical relevance of working memory training programs and their utility
    as methods of enhancing cognitive functioning in typically developing children
    and healthy adults. [Keywords: working memory training, ADHD, attention, learning
    disabilities.]'
- - http://users.econ.umn.edu/~rusti001/Research/Genetics/Polygenic_Analysis.pdf
  - Polygenic Score Analysis Of Educational Achievement And Intergenerational Mobility
  - Aldo Rustichini, William G. Iacono, James Lee, Matt McGue
  - 2019-09-17
  - ''
  - <p>A Genome-wide association study (<em>GWAS</em>) estimates size and significance
    of the effect of common genetic variants on a phenotype of interest. A Polygenic
    Score (<em>PGS</em>) is a score, computed for each individual, summarizing the
    expected value of a phenotype on the basis of the individual’s genotype. The <em>PGS</em>
    is computed as a weighted sum of the values of the individual’s genetic variants,
    using as weights the <em>GWAS</em> estimated coefficients from a training sample.
    Thus, <em>PGS</em> carries information on the genotype, and only on the genotype,
    of an individual. In our case phenotypes of interest are measures of educational
    achievement, such as having a college degree, or the education years, in a sample
    of approximately 2700 adult twins and their parents.</p><p>We set up the analysis
    in a standard model of optimal parental investment and intergenerational mobility,
    extended to include a fully specified genetic analysis of skill transmission,
    and show that the model’s predictions on mobility differ substantially from those
    of the standard model. For instance, the coefficient of intergenerational income
    elasticity maybe larger, and may differ across countries because the distribution
    of the genotype is different, completely independently of any difference in institution,
    technology or preferences.</p><p>We then study how much of the educational achievement
    is explained by the <em>PGS</em> for education, thus estimating how much of the
    variance of education can be explained by genetic factors alone. We find a substantial
    effect of <em>PGS</em> on performance in school, years of education and college.</p><p>Finally
    we study the channels between <em>PGS</em> and the educational achievement, distinguishing
    how much is due to cognitive skills and to personality traits. We show that the
    effect of <em>PGS</em> is substantially stronger on Intelligence than on other
    traits, like Constraint, which seem natural explanatory factors of educational
    success. For educational achievement, both cognitive and non cognitive skills
    are important, although the larger fraction of success is channeled by Intelligence.</p>
- - http://www.paulgraham.com/nerds.html
  - Why Nerds Are Unpopular
  - Paul Graham
  - 2003-02
  - ''
  - ! '<p>I know a lot of people who were nerds in school, and they all tell the same
    story: there is a strong correlation between being smart and being a nerd, and
    an even stronger inverse correlation between being a nerd and being popular. Being
    smart seems to <em>make</em> you unpopular. Why? To someone in school now, that
    may seem an odd question to ask. The mere fact is so overwhelming that it may
    seem strange to imagine that it could be any other way. But it could. Being smart
    doesn’t make you an outcast in elementary school. Nor does it harm you in the
    real world. Nor, as far as I can tell, is the problem so bad in most other countries.
    But in a typical American secondary school, being smart is likely to make your
    life difficult. Why?</p><p>The answer, I think, is that they don’t really want
    to be popular. If someone had told me that at the time, I would have laughed at
    him. Being unpopular in school makes kids miserable, some of them so miserable
    that they commit suicide. Telling me that I didn’t want to be popular would have
    seemed like telling someone dying of thirst in a desert that he didn’t want a
    glass of water. Of course I wanted to be popular. But in fact I didn’t, not enough.
    There was something else I wanted more: to be smart. Not simply to do well in
    school, though that counted for something, but to design beautiful rockets, or
    to write well, or to understand how to program computers. In general, to make
    great things. At the time I never tried to separate my wants and weigh them against
    one another. If I had, I would have seen that being smart was more important.
    If someone had offered me the chance to be the most popular kid in school, but
    only at the price of being of average intelligence (humor me here), I wouldn’t
    have taken it.</p><p>Much as they suffer from their unpopularity, I don’t think
    many nerds would. To them the thought of average intelligence is unbearable. But
    most kids would take that deal. For half of them, it would be a step up. Even
    for someone in the eightieth percentile (assuming, as everyone seemed to then,
    that intelligence is a scalar), who wouldn’t drop thirty points in exchange for
    being loved and admired by everyone? And that, I think, is the root of the problem.
    Nerds serve two masters. They want to be popular, certainly, but they want even
    more to be smart. And popularity is not something you can do in your spare time,
    not in the fiercely competitive environment of an American secondary school.</p><p>…This
    is the sort of society that gets created in American secondary schools. And it
    happens because these schools have no real purpose beyond keeping the kids all
    in one place for a certain number of hours each day. What I didn’t realize at
    the time, and in fact didn’t realize till very recently, is that the twin horrors
    of school life, the cruelty and the boredom, both have the same cause.</p>'
- - http://nonsymbolic.org/PNSE-Article.pdf
  - Clusters of Individual Experiences form a Continuum of Persistent Non-Symbolic
    Experiences [PNSE] in Adults
  - Jeffery A. Martin
  - '2013'
  - ''
  - ! '<p>Persistent forms of nondual awareness, enlightenment, mystical experience,
    and so forth (Persistent Non-Symbolic Experience) have been reported since antiquity.
    Though sporadic research has been performed on them, the research reported here
    represents the initial report from the first larger scale cognitive psychology
    study of this population.</p><p><em>Method</em>: Assessment of the subjective
    experience of fifty adult participants reporting persistent non-symbolic experience
    was undertaken using 6–12 hour semi-structured interviews and evaluated using
    thematic analysis. Additional assessment was performed using psychometric measures,
    physiological measurement, and experimentation.</p><p><em>Results</em>: Five core,
    consistent categories of change were uncovered: sense-of-self, cognition, emotion,
    perception, and memory. Participants’ reports formed clusters in which the types
    of change in each of these categories were consistent. Multiple clusters were
    uncovered that formed a range of possible experiences. The variety of these experiences
    and their underlying categories may inform the debate between constructivist,
    common core, and participatory theorists.</p><p>…Over the course of a week, his
    father died followed very rapidly by his sister. He was also going through a significant
    issue with one of his children. Over dinner I asked him about his internal state,
    which he reported as deeply peaceful and positive despite everything that was
    happening. Having known that the participant was bringing his longtime girlfriend,
    I’d taken an associate researcher with me to the meeting to independently collect
    the observations from her. My fellow researcher isolated the participant’s girlfriend
    at the bar and interviewed her about any signs of stress that the participant
    might be exhibiting. I casually asked the same questions to the participant as
    we continued our dinner conversation. Their answers couldn’t have been more different.
    While the participant reported no stress, his partner had been observing many
    telltale signs: he wasn’t sleeping well, his appetite was off, his mood was noticeably
    different, his muscles were much tenser than normal, his sex drive was reduced,
    his health was suffering, and so forth…It was not uncommon for participants to
    state that they had gained increased bodily awareness upon their transition into
    PNSE. I arranged and observed private yoga sessions with a series of participants
    as part of a larger inquiry into their bodily awareness. During these sessions
    it became clear that participants believed they were far more aware of their body
    than they actually were…Many participants discussed the thought, just after their
    transition to PNSE, that they would have to go to work and explain the difference
    in themselves to co-workers. They went on to describe a puzzled drive home after
    a full day of work when no one seemed to notice anything different about them.
    Quite a few chose to never discuss the change that had occurred in them with their
    families and friends and stated that no one seemed to notice much of a difference.</p><p>There
    was also a progressively decreasing sense of agency. In the final stage, Location
    4, he reports: “These participants reported having no sense of agency or any ability
    to make a decision. It felt as if life was simply unfolding and they were watching
    the process happen. Severe memory deficits were common in these participants,
    including the inability to recall scheduled events that were not regular and ongoing.”
    And yet, almost all of the subjects reported it as a positive experience. The
    subjects, at whatever point they were in the scale, were often completely certain
    about the nature of the experience: “PNSE was often accompanied by a tremendous
    sense of certainty that participants were experiencing a ‘deeper’ or ‘more true’
    reality. As time passed, this often increased in strength.” They also tended to
    be dogmatic about their PNSE being the real thing (whichever location they were
    at) and descriptions of other people’s different PNSEs as not the real thing.
    Another way to say “completely certain” is “unable to doubt”.</p>'
- - /docs/traffic/2015-hohnhold.pdf
  - ! 'Focusing on the Long-term: It’s Good for Users and Business'
  - Henning Hohnhold, Deirdre O’Brien, Diane Tang
  - '2015'
  - 10.1145/2783258.2788583
  - ! '<p>Over the past 10+ years, online companies large and small have adopted widespread
    A/B testing as a robust data-based method for evaluating potential product improvements.
    In online experimentation, it is straightforward to measure the short-term effect,
    i.e., the impact observed during the experiment. However, the short-term effect
    is not always predictive of the long-term effect, i.e., the final impact once
    the product has fully launched and users have changed their behavior in response.
    Thus, the challenge is how to determine the long-term user impact while still
    being able to make decisions in a timely manner.</p><p>We tackle that challenge
    in this paper by first developing experiment methodology for quantifying long-term
    user learning. We then apply this methodology to ads shown on Google search, more
    specifically, to determine and quantify the drivers of ads blindness and sightedness,
    the phenomenon of users changing their inherent propensity to click on or interact
    with ads.</p><p>We use these results to create a model that uses metrics measurable
    in the short-term to predict the long-term. We learn that user satisfaction is
    paramount: ads blindness and sightedness are driven by the quality of previously
    viewed or clicked ads, as measured by both ad relevance and landing page quality.
    Focusing on user satisfaction both ensures happier users but also makes business
    sense, as our results illustrate. We describe two major applications of our findings:
    a conceptual change to our search ads auction that further increased the importance
    of ads quality, and a 50% reduction of the ad load on Google’s mobile search interface.</p><p>The
    results presented in this paper are generalizable in two major ways. First, the
    methodology may be used to quantify user learning effects and to evaluate online
    experiments in contexts other than ads. Second, the ads blindness/sightedness
    results indicate that a focus on user satisfaction could help to reduce the ad
    load on the internet at large with long-term neutral, or even positive, business
    impact. [Keywords: Controlled experiments; A/B testing; predictive modeling; overall
    evaluation criterion]</p>'
- - http://www.ushakrisna.com/cogability_proof.pdf
  - Cognitive Abilities and Household Financial Decision Making
  - Sumit Agarwal, Bhashkar Mazumder
  - '2013'
  - 10.1257/app.5.1.193
  - We analyze the effects of cognitive abilities [AFQT] on two examples of consumer
    financial decisions where suboptimal behavior is well defined. The first example
    features the optimal use of credit cards for convenience transactions after a
    balance transfer and the second involves a financial mistake on a home equity
    loan application. We find that consumers with higher overall test scores, and
    specifically those with higher math scores, are substantially less likely to make
    a financial mistake. These mistakes are generally not associated with nonmath
    test scores.
- - https://d4mucfpksywv.cloudfront.net/emergent-tool-use/paper/Multi_Agent_Emergence_2019.pdf#openai
  - Emergent Tool Use From Multi-Agent Autocurricula
  - Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi Wu, Glenn Powell, Bob McGrew,
    Igor Mordatch
  - 2019-09-17
  - ''
  - Through multi-agent competition, the simple objective of <em>hide-and-seek</em>,
    and standard reinforcement learning algorithms at scale, we find that agents create
    a self-supervised autocurriculum inducing multiple distinct rounds of emergent
    strategy, many of which require sophisticated tool use and coordination. We find
    clear evidence of six emergent phases in agent strategy in our environment, each
    of which creates a new pressure for the opposing team to adapt; for instance,
    agents learn to build multi-object shelters using movable boxes which in turn
    leads to agents discovering that they can overcome obstacles using ramps. We further
    provide evidence that multi-agent competition may scale better with increasing
    environment complexity and leads to behavior that centers around far more human-relevant
    skills than other self-supervised reinforcement learning methods such as intrinsic
    motivation. Finally, we propose transfer and fine-tuning as a way to quantitatively
    evaluate targeted capabilities, and we compare hide-and-seek agents to both intrinsic
    motivation and random initialization baselines in a suite of domain-specific intelligence
    tests.
- - https://statmodeling.stat.columbia.edu/2019/09/17/statistical-inference-enables-bad-science-statistical-thinking-enables-good-science/
  - On 'Statistical Inference Enables Bad Science; Statistical Thinking Enables Good
    Science', Tong 2019
  - Andrew Gelman
  - 2019-09-17
  - ''
  - ! '<p>First, the title, which makes an excellent point. It can be valuable to
    <em>think</em> about measurement, comparison, and variation, even if commonly-used
    statistical methods can mislead.</p> <p>This reminds me of the idea in decision
    analysis that the most important thing is not the solution of the decision tree
    but rather what you decide to put in the tree in the first place, or even, stepping
    back, what are your goals. The idea is that the threat of decision analysis is
    more powerful than its execution (as Chrissy Hesse might say): the decision-analytic
    thinking pushes you to think about costs and uncertainties and alternatives and
    opportunity costs, and that’s all valuable even if you never get around to performing
    the formal analysis. Similarly, I take Tong’s point that statistical thinking
    motivates you to consider design, data quality, bias, variance, conditioning,
    causal inference, and other concerns that will be relevant, whether or not they
    all go into a formal analysis.</p> <p>That said, I have one concern, which is
    that “the threat is more powerful than the execution” only works if the threat
    is plausible. If you rule out the possibility of the execution, then the threat
    is empty. Similarly, while I understand the appeal of “Statistical Inference Enables
    Bad Science; Statistical Thinking Enables Good Science,” I think this might be
    good static advice, applicable right now, but not good <em>dynamic</em> advice:
    if we do away with statistical inference entirely (except in the very rare cases
    when no external assumptions are required to perform statistical modeling), then
    there may be less of a sense of the need for statistical thinking.</p> <p>Overall,
    though, I agree with Tong’s message, and I think everybody should read his article.</p>'
- - http://www.slate.com/articles/health_and_science/medical_examiner/2017/09/genetic_testing_data_reveals_the_irrationality_of_human_behavior.html
  - ! 'We Don’t Want to Know What Will Kill Us: Years of data on genetic testing reveal
    that when given the option, most people want less information, not more'
  - Laura Spinney
  - 2017-09-27
  - ''
  - ! '<p>In the three decades since the first predictive genetic tests became available,
    a great deal of data has accumulated to show how people respond to knowing previously
    unknowable things. The rise of genetic testing has presented scientists with a
    30-year experiment that has yielded some surprising insights into human behavior.
    The data suggest that the vast majority react in ways that at first seem counterintuitive,
    or at least flout what experts predicted. But as genetic testing becomes more
    widespread, the irrational behavior of a frightened few might start to look like
    the rational behavior of an enlightened majority. Doctors’ repeatedly failed attempts
    to anticipate people’s responses to genetic testing is not for want of preparation.
    Starting in the 1980s, they conducted surveys in which they asked how people might
    approach the test, were one available. They noted the answers and planned accordingly.
    The trouble was, when the test became a reality, their respondents didn’t do what
    they had said they would.</p><p>… In those preparatory surveys, roughly 70% of
    those at risk of Huntington’s said they would take a test if it existed. In fact,
    only around 15% do—a proportion that has proved stable across countries and decades.
    A similar pattern emerged when tests became available for other incurable brain
    diseases…Prenatal genetic testing is widely available, but the uptake by expecting
    couples in which one partner is a known carrier of an incurable disease is even
    lower than that of testing among at-risk adults. Most opt to have a child whose
    risk of developing that disease is the same as theirs was at birth. Why do people
    act in this seemingly irresponsible way with respect to their offspring?</p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5110058/" title="‘Prenatal testing in Huntington disease: after the test, choices recommence’,
    Bouchghoul et al 2016">A unique longitudinal study published in 2016 by Hanane Bouchghoul</a>
    and colleagues at the Pitié-Salpêtrière Hospital in Paris
    unpacks that decision-making process. They interviewed 54 women—either Huntington’s
    carriers or wives of carriers—and found that if a couple received a favorable
    result in a first prenatal test, the majority had the child and stopped there.
    Most of those who got an unfavorable result terminated the pregnancy and tried
    again. If a second prenatal test produced a “good” result, they had the child
    and stopped. But if it produced a “bad” result and another termination, most changed
    strategy. Some opted for preimplantation genetic diagnosis, removing the need
    for termination, since only mutation-free embryos are implanted. Some abandoned
    the idea of having a child altogether. But nearly half, 45%, conceived naturally
    again, and this time they did not seek prenatal testing. Summarizing the findings,
    the geneticist on the team, Alexandra Dürr, says, “The desire to have a child
    overrides all else.”</p><p>… In a study that has yet to be published, Tibben has
    corroborated the French group’s conclusion. He followed 13 couples who, following
    counseling but prior to taking a prenatal test, agreed they would terminate in
    the case of an unfavorable result. None of them did so when they got that result.
    “That means there are 13 children alive in the Netherlands today, whom we can
    be 100% sure are [Huntington’s] carriers,” he says.</p>'
- - http://www.overcomingbias.com/2012/01/dear-young-eccentric.html
  - Dear Young Eccentric
  - Robin Hanson
  - 2012-01-05
  - ''
  - Weird folks are often tempted to give up on grand ambitions, thinking there is
    little chance the world will let them succeed. Turns out, however, it isn’t as
    bad as all that. Especially if your main weirdness is in the realm of ideas...I’ve
    known some very successful people with quite weird ideas. But these folks mostly
    keep regular schedules of sleep and bathing. Their dress and hairstyles are modest,
    they show up on time for meetings, and they finish assignments by deadline. They
    are willing to pay dues and work on what others think are important for a while,
    and they have many odd ideas they’d pursue if given a chance, instead of just
    one overwhelming obsession. They are willing to keep changing fields, careers,
    and jobs until they find one that works for them...if you are not overtly rebellious,
    you can get away with a lot of abstract idea rebellion—few folks will even notice
    such deviations, and fewer still will care. So, ask yourself, do you want to <em>look</em>
    like a rebel, or do you want to <em>be</em> a rebel?
- - https://escholarship.org/content/qt68h9h675/qt68h9h675.pdf#page=2
  - Dumb or smart asses? Donkey's (<em>Equus asinus</em>) cognitive capabilities share
    the heritability and variation patterns of human's (<em>Homo sapiens</em>) cognitive
    capabilities
  - Francisco Javier Navas González, Jordi Jordana Vidal, José Manuel León Jurado,
    Amy Katherine McLean, Juan Vicente Delgado Bermejo
  - 2019-09
  - 10.1016/j.jveb.2019.06.007
  - ! 'Scientific evidence for intelligence in donkeys could expose their historical
    unmerited cognitive derogatory status. Psychometric testing enables quantifying
    animal cognitive capabilities and their genetic background. Owing to the impossibility
    to use the language-dependent scales that are widely used to measure intelligence
    in humans, we used a nonverbal operant-conditioning problem-solving test to compute
    a human-analogous IQ, scoring the information of thirteen cognitive processes
    from 300 genetically tested donkeys. Principal components and Bayesian analyses
    were used to compute the variation in cognitive capabilities explained by the
    cognitive processes tested and their genetic parameters, respectively. According
    to our results, IQ may explain over 62% of the cognitive variance, and 0.06 to
    0.38 heritabilities suggest that we could ascribe a significant proportion to
    interacting genes describing the same patterns previously reported for humans
    and other animal species. Our results address the existence of a human-analogous
    heritable component and mechanisms underneath intelligence and cognition in probably
    one of the most traditionally misunderstood species from a cognitive perspective.
    [Keywords: cognition, <em>g</em>, genetic parameters, asses, intelligence quotient]'
- - https://www.math.uchicago.edu/~fcale/CCC/DC.pdf
  - Methods for Studying Coincidences
  - Persi Diaconis, Frederick Mosteller
  - 1989-12
  - 10.1080/01621459.1989.10478847
  - ! 'This article illustrates basic statistical techniques for studying coincidences.
    These include data-gathering methods (informal anecdotes, case studies, observational
    studies, and experiments) and methods of analysis (exploratory and confirmatory
    data analysis, special analytic techniques, and probabilistic modeling, both general
    and special purpose). We develop a version of the birthday problem general enough
    to include dependence, inhomogeneity, and almost and multiple matches. We review
    Fisher''s techniques for giving partial credit for close matches. We develop a
    model for studying coincidences involving newly learned words. Once we set aside
    coincidences having apparent causes, four principles account for large numbers
    of remaining coincidences: hidden cause; psychology, including memory and perception;
    multiplicity of endpoints, including the counting of “close” or nearly alike events
    as if they were identical; and the law of truly large numbers, which says that
    when enormous numbers of events and people and their interactions cumulate over
    time, almost any outrageous event is bound to occur. These sources account for
    much of the force of synchronicity. [Keywords: Birthday problems, Extrasensory
    perception, Jung, Kammerer, Multiple endpoints, Rare events, Synchronicity, Baader-Meinhof
    Effect, spaced repetition]'
- - http://www.ic.unicamp.br/~celio/peer2peer/math/mitzenmacher-power-of-two.pdf
  - ! 'The Power of Two Random Choices: A Survey of Techniques and Results'
  - Michael Mitzenmacher, Andrea W. Richa, Ramesh Sitaraman
  - '2001'
  - ''
  - ! '<p>…we begin with a simple problem that demonstrates a powerful fundamental
    idea. Suppose that <em>n</em> balls are thrown into <em>n</em> bins, with each
    ball choosing a bin independently and uniformly at random. Then the <em>maximum
    load</em>, or the largest number of balls in any bins, is approximately log <em>n</em>
    / log log <em>n</em> with high probability. Now suppose instead that the balls
    are placed sequentially, and each ball is placed in the least loaded of <em>d</em>≥2
    bins chosen independently and uniformly at random. <a href="http://users.eecs.northwestern.edu/~nickle/randAlg/AzarBKU99.pdf"
    title="Balanced Allocations">Azar et al 1999</a> showed that in this case, the
    maximum load is log log <em>n</em> / log <em>d</em> + Θ(1) with high probability.</p><p>The
    important implication of this result is that even a small amount of choice can
    lead to drastically different results in load balancing. Indeed, having just two
    random choices (ie <em>d</em>=2) yields a large reduction in the maximum load
    by just a constant factor. Over the past several years, there has been a great
    deal of research investigating this phenomenon. The picture that has emerged from
    this research is that the power of two choices is not simply an artifact of the
    simple balls-and-bins model, but a general and robust phenomenon applicable to
    a wide variety of situations. Indeed, this <em>two-choice paradigm</em> continues
    to be applied and refined, and new results appear frequently. <em>Applications
    of the two-choice paradigm</em>:… Hashing, Shared memory emulations, load balancing,
    low-congestion circuit routing.</p><p>[See also <a href="https://www.eecs.harvard.edu/~michaelm/postscripts/mythesis.pdf">“The
    Power of Two Choices in Randomized Load Balancing”</a>, Mitzenmacher 1996; <a
    href="https://www.nginx.com/blog/nginx-power-of-two-choices-load-balancing-algorithm/"
    title="&#39;NGINX and the &#39;Power of Two Choices&#39; Load-Balancing Algorithm&#39;,
    Garrett 2018">Nginx</a>/<a href="https://www.haproxy.com/blog/power-of-two-load-balancing/"
    title="&#39;Test Driving`&#39;Power of Two Random Choices` Load Balancing&#39;,
    Tarreau 2019">HAProxy</a>, <a href="https://brooker.co.za/blog/2012/01/17/two-random.html"
    title="The power of two random choices: Using less information to make better
    decisions">Marc Brooker</a>.]</p>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.8275&rep=rep1&type=pdf
  - ! 'Trustworthy online controlled experiments: Five puzzling outcomes explained'
  - Ron Kohavi, Alex Deng, Brian Frasca, Roger Longbotham, Toby Walker, Ya Xu
  - 2012-08-12
  - 10.1145/2339530.2339653
  - ! 'Online controlled experiments are often utilized to make data-driven decisions
    at Amazon, Microsoft, eBay, Facebook, Google, Yahoo, Zynga, and at many other
    companies. While the theory of a controlled experiment is simple, and dates back
    to Sir Ronald A. Fisher''s experiments at the Rothamsted Agricultural Experimental
    Station in England in the 1920s, the deployment and mining of online controlled
    experiments at scale—thousands of experiments now—has taught us many lessons.
    These exemplify the proverb that the difference between theory and practice is
    greater in practice than in theory. We present our learnings as they happened:
    puzzling outcomes of controlled experiments that we analyzed deeply to understand
    and explain. Each of these took multiple-person weeks to months to properly analyze
    and get to the often surprising root cause. The root causes behind these puzzling
    results are not isolated incidents; these issues generalized to multiple experiments.
    The heightened awareness should help readers increase the trustworthiness of the
    results coming out of controlled experiments. At Microsoft''s Bing, it is not
    uncommon to see experiments that impact annual revenue by millions of dollars,
    thus getting trustworthy results is critical and investing in understanding anomalies
    has tremendous payoff: reversing a single incorrect decision based on the results
    of an experiment can fund a whole team of analysts. The topics we cover include:
    the OEC (Overall Evaluation Criterion), click tracking, effect trends, experiment
    length and power, and carryover effects.'
- - https://www.nytimes.com/1990/12/29/arts/japan-sings-along-with-beethoven.html
  - Japan Sings Along With Beethoven
  - Steven R. Weisman
  - 1990-12-29
  - ''
  - <p>December in Japan is a festive season, filled with gift-giving, prayers for
    the new year, bamboo and pine branches in front of houses, office parties and
    Beethoven’s Ninth.</p><p>Beethoven’s Ninth? No one is sure how it happened, but
    indeed, Ludwig van Beethoven’s Choral Symphony is as much a staple of the season
    as dry weather and maddeningly short days. The symphony is being performed at
    least 170 times this month by professional and amateur groups throughout the country.
    Some orchestras play it several times in a row. The NHK Symphony Orchestra has
    performed what the Japanese call the Daiku, or Big Nine, five times this month,
    the Tokyo Symphony Orchestra 13 times and the Japan Philharmonic Symphony Orchestra
    11 times.</p><p>“For Japanese, listening to Beethoven’s Ninth at the end of the
    year is a semi-religious experience,” said Naoyuki Miura, the artistic director
    of Music from Japan, which sponsors concerts abroad. “People feel they have not
    completed the year spiritually until they hear it.” Like the Christmastime sing-alongs
    of Handel’s <em>Messiah</em> in the West, Beethoven’s Ninth also draws audiences
    to sing-along performances at which the audiences lustily join in the choruses
    of Schiller’s “Ode to Joy,” singing German words they barely understand.</p>
- - /docs/iq/2018-mansson.pdf
  - Agreement Between Bayley-III Measurements and WISC-IV Measurements in Typically
    Developing Children
  - Johanna Månsson, Karin Stjernqvist, Fredrik Serenius, Ulrika Ådén, Karin Källén
  - 2018-06-28
  - 10.1177/0734282918781431
  - The study aim was to explore the relationship between a developmental assessment
    at preschool age and an intelligence quotient (IQ) assessment at school age. One
    hundred sixty-two children were assessed at 2.5 years with the Bayley Scales of
    Infant and Toddler Development—Third Edition (Bayley-III) and then at 6.5 years
    with the Wechsler Intelligence Scale for Children—Fourth Edition (WISC-IV). The
    Bayley-III Cognitive Index score was the Bayley entity that showed the highest
    correlation with WISC-IV Full-Scale IQ (FSIQ; r = .41). There was a significant
    difference between the individual WISC-IV FSIQ and the Bayley-III Cognitive Index
    scores. Analyses showed an average difference of −4 units and 95% limits of agreement
    of −18.5 to 26.4 units. A multivariate model identified the Bayley-III Cognitive
    Index score as the most important predictor for FSIQ and General Ability Index
    (GAI), respectively, in comparison with demographic factors. The model explained
    24% of the total FSIQ variation and 26% of the GAI variation. It was concluded
    that the Bayley-III measurement was an insufficient predictor of later IQ.
- - https://rifters.com/real/articles/Sinclair%20ZX80%20spiders.pdf
  - Smarter than the average bug [<em>Portia</em>]
  - John McCrone (New Scientist)
  - 2006-05-27
  - ''
  - ! '<p>So perched on its branch, Portia begins to plot. For a good quarter of an
    hour it scans the undergrowth, its tiny brain working out possible pathways across
    boulders and branches. The retinas of its two principal eyes have only a few thousand
    photoreceptors, compared to the 200 million or so in a human eye. But Portia can
    swivel these tiny eyes across the scene in a systematic fashion, patiently building
    up an image. Eventually Portia makes up its mind and disappears from sight. A
    couple of hours later, the silent assassin is back, dropping down onto Scytodes
    on a silk dragline attached to a rocky overhang, like something out of <em>Mission:
    Impossible</em>. Once again, Portia’s guile wins the day…While Portia’s deception
    skills are impressive, what is most remarkable is its ability to plot a path to
    its victim. For an animal operating on instinct, out of sight is usually out of
    mind. Yet Portia can take several hours to get into the right spot, even if that
    means losing sight of its prey for long periods.</p><p>…One of Portia’s principal
    skills is luring other spiders from the safety of their webs. Portia will pluck
    out rhythms at the edge of a web to mimic a trapped insect or a hostile intruder.
    If it has encountered the resident spider before, it sometimes knows what rhythm
    to use—a remarkable ability in itself. If it hasn’t, Portia will try out various
    patterns by trial and error. It can tickle the web lightly, strum it vigorously,
    bob up and down as if on a trampoline—whatever it takes to persuade its target
    to move into the right position for an attack. Sometimes the foe will be two to
    three times Portia’s size. The trick is then to arouse its curiosity without provoking
    a full-blooded rush.</p><p>…Crazy talk, obviously. There just isn’t room in Portia’s
    head for anything approaching an inner mental life. The human brain has some 100
    billion brain cells, and a mouse has around 70 million. Harland says no one has
    done a precise count on Portia but it is reckoned to have a midway between the
    housefly’s 250,000 and the honeybee’s one million.So what do the researchers conclude?
    Does Portia have some inkling of a mind? Or can every behaviour be explained away
    in terms of instinctive responses? Harland says many of Portia’s cognitive abilities
    may eventually be explained by the design of its eyes—specifically by their inbuilt
    limitations. All jumping spiders have excellent vision and Portia’s is 10 times
    better than the average, making it sharper than that of most mammals. Being so
    small, though, there is a trade-off: Portia can only focus on one view at a time.
    It has to build up a picture of the world by scanning a scene point by point,
    as if peering through a keyhole. Harland thinks that understanding the serial
    nature of the spider’s vision makes it easier to imagine how prey recognition
    and other processes could be controlled by hard-wired programs. When Portia is
    looking for an egg sac, for example, it wouldn’t need to deal with the scene as
    a visual whole. Instead it could check a template, ticking off critical features
    in a sequence of fixations. Perhaps the less the eye sees with each fixation the
    better.</p>'
- - https://keinanlab.cb.bscb.cornell.edu/content/crowdsourcing-big-data-research-human-history-and-health-genealogies-genomes-and-back-again
  - ! 'Crowdsourcing big data research on human history and health: from genealogies
    to genomes and back again'
  - Alon Keinan, Alexandre Lussier
  - 2018-04-12
  - ''
  - Genealogies are likely the first, centuries-old “big data”, with their construction
    as old as human civilization itself. Globalization, and the identity crisis that
    ensued, turned many to online services, building family trees and investigating
    connections to historical records and other family trees [1]. An explosion has
    been underway since the beginning of the century in the number and usage of websites
    offering such genealogical services. About 130 million users combine to have created
    almost four billion profiles for family members across the three most popular
    websites of genealogy enthusiasts, Ancestry.com, MyHeritage, and Geni. More recent
    years have witnessed a similar rapid increase of genetic-based services that address
    the same need to learn about familial relationships and ancestry. These vast amounts
    of crowdsourced—and often crowdfunded (as users often pay for these services)—data
    offers ample scientific research opportunities that would otherwise require expansive
    collection. In a paper published today in Science, Kaplanis et al. [2, 3] introduce
    a genealogical dataset based on processing 86 million public Geni profiles. Armed
    with this crowdsourced dataset, they address fundamental research questions.
- - https://openai.com/blog/better-language-models/
  - ! 'Better Language Models and Their Implications: We''ve trained a large-scale
    unsupervised language model [GPT-2] which generates coherent paragraphs of text,
    achieves state-of-the-art performance on many language modeling benchmarks, and
    performs rudimentary reading comprehension, machine translation, question answering,
    and summarization—all without task-specific training'
  - Alec Radford, Jeffrey Wu, Dario Amodei, Daniela Amodei, Jack Clark, Miles Brundage,
    Ilya Sutskever (OpenAI)
  - 2019-02-14
  - ''
  - ! '<p>Our model, called GPT-2 (a successor to GPT), was trained simply to predict
    the next word in 40GB of Internet text. Due to our concerns about malicious applications
    of the technology, we are not releasing the trained model. As an experiment in
    responsible disclosure, we are instead releasing a much <a href="https://github.com/openai/gpt-2">smaller
    model</a> for researchers to experiment with, as well as a <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">technical
    paper</a>.</p><p>GPT-2 is a large <a href="https://arxiv.org/abs/1706.03762">Transformer</a>-based
    language model with 1.5 billion parameters, trained on a dataset of 8 million
    web pages. GPT-2 is trained with a simple objective: predict the next word, given
    all of the previous words within some text. The diversity of the dataset causes
    this simple goal to contain naturally occurring demonstrations of many tasks across
    diverse domains. GPT-2 is a direct scale-up of GPT, with more than 10X the parameters
    and trained on more than 10X the amount of data.</p><p>GPT-2 displays a broad
    set of capabilities, including the ability to generate conditional synthetic text
    samples of unprecedented quality, where we prime the model with an input and have
    it generate a lengthy continuation. In addition, GPT-2 outperforms other language
    models trained on specific domains (like Wikipedia, news, or books) without needing
    to use these domain-specific training datasets. On language tasks like question
    answering, reading comprehension, summarization, and translation, GPT-2 begins
    to learn these tasks from the raw text, using no task-specific training data.
    While scores on these downstream tasks are far from state-of-the-art, they suggest
    that the tasks can benefit from unsupervised techniques, given sufficient (unlabeled)
    data and compute.</p>'
- - https://danwang.co/college-girardian-terror/
  - ! 'Violence and the Sacred: College as an incubator of Girardian terror'
  - Dan Wang
  - 2017-06-25
  - ''
  - ! '<p>…competition is fiercer the more that competitors resemble each other. When
    we’re not so different from people around us, it’s irresistible to become obsessed
    about beating others.</p><p>It’s hard to construct a more perfect incubator for
    mimetic contagion than the American college campus. Most 18-year-olds are not
    super differentiated from each other. By construction, whatever distinctions any
    does have are usually earned through brutal, zero-sum competitions. These tournament-type
    distinctions include: SAT scores at or near perfection; being a top player on
    a sports team; gaining master status from chess matches; playing first instrument
    in state orchestra; earning high rankings in Math Olympiad; and so on, culminating
    in gaining admission to a particular college. Once people enter college, they
    get socialized into group environments that usually continue to operate in zero-sum
    competitive dynamics. These include orchestras and sport teams; fraternities and
    sororities; and many types of clubs. The biggest source of mimetic pressures are
    the classes. Everyone starts out by taking the same intro classes; those seeking
    distinction throw themselves into the hardest classes, or seek tutelage from star
    professors, and try to earn the highest grades.</p><p>There’s very little external
    intermediation, instead all competitive dynamics are internally mediated…Once
    internal rivalries are sorted out, people coalesce into groups united against
    something foreign. These tendencies help explain why events on campus so often
    make the news—it seems like every other week we see some campus activity being
    labeled a “witch hunt,” “riot,” or something else that involves violence, implied
    or explicit. I don’t care to link to these events, they’re so easy to find. It’s
    interesting to see that academics are increasingly becoming the target of student
    activities. The <a href="https://en.wikipedia.org/wiki/Ren%C3%A9_Girard">Girardian</a>
    terror devours its children first, who have tolerated or fanned mimetic contagion
    for so long.</p><p>…I’ll end with a quote from <a href="https://www.amazon.com/See-Satan-Fall-Like-Lightning/dp/1570753199"><em>I
    See Satan Fall Like Lightning</em></a>: <strong>“Mimetic desire enables us to
    escape from the animal realm. It is responsible for the best and the worst in
    us, for what lowers us below the animal level as well as what elevates us above
    it. Our unending discords are the ransom of our freedom.”</strong></p>'
- - /docs/statistics/causality/2001-ioannidis.pdf
  - Comparison of Evidence of Treatment Effects in Randomized and Nonrandomized Studies
  - John P. A. Ioannidis, Anna-Bettina Haidich, Maroudia Pappa, Nikos Pantazis, Styliani
    I. Kokori, Maria G. Tektonidou, Despina G. Contopoulos-Ioannidis, Joseph Lau
  - 2001-08-01
  - 10.1001/jama.286.7.821
  - ! '<p><strong>Context</strong>: There is substantial debate about whether the
    results of nonrandomized studies are consistent with the results of randomized
    controlled trials on the same topic.</p><p><strong>Objectives</strong>: To compare
    results of randomized and nonrandomized studies that evaluated medical interventions
    and to examine characteristics that may explain discrepancies between randomized
    and nonrandomized studies.</p><p><strong>Data Sources</strong>: MEDLINE (1966–March
    2000), the Cochrane Library (Issue 3, 2000), and major journals were searched.</p><p><strong>Study
    Selection</strong>: Forty-five diverse topics were identified for which both randomized
    trials (<em>n</em>=240) and nonrandomized studies (<em>n</em>=168) had been performed
    and had been considered in meta-analyses of binary outcomes.</p><p><strong>Data
    Extraction</strong>: Data on events per patient in each study arm and design and
    characteristics of each study considered in each meta-analysis were extracted
    and synthesized separately for randomized and nonrandomized studies.</p><p><strong>Data
    Synthesis</strong>: Very good correlation was observed between the summary odds
    ratios of randomized and nonrandomized studies (<em>r</em> = 0.75; <em>p</em>&lt;.001);
    however, nonrandomized studies tended to show larger treatment effects (28 vs
    11; <em>p</em>=.009). Between-study heterogeneity was frequent among randomized
    trials alone (23%) and very frequent among nonrandomized studies alone (41%).
    The summary results of the 2 types of designs differed beyond chance in 7 cases
    (16%). Discrepancies beyond chance were less common when only prospective studies
    were considered (8%). Occasional differences in sample size and timing of publication
    were also noted between discrepant randomized and nonrandomized studies. In 28
    cases (62%), the natural logarithm of the odds ratio differed by at least 50%,
    and in 15 cases (33%), the odds ratio varied at least 2-fold between nonrandomized
    studies and randomized trials.</p><p><strong>Conclusions</strong>: Despite good
    correlation between randomized trials and nonrandomized studies—in particular,
    prospective studies—discrepancies beyond chance do occur and differences in estimated
    magnitude of treatment effect are very common.</p>'
- - /docs/statistics/2015-gaukler.pdf
  - Low-dose paroxetine exposure causes lifetime declines in male mouse body weight,
    reproduction and competitive ability as measured by the novel organismal performance
    assay
  - James S. Ruff, Tessa Galland, Kirstie A. Kandaris, Tristan K. Underwood, Nicole
    M. Liu, Elizabeth L. Young, Linda C. Morrison, Garold S. Yost, Wayne K. Potts
  - '2015'
  - 10.1016/j.ntt.2014.11.002
  - ! 'Paroxetine is a selective serotonin reuptake inhibitor (SSRI) that is currently
    available on the market and is suspected of causing congenital malformations in
    babies born to mothers who take the drug during the first trimester of pregnancy.
    We utilized organismal performance assays (OPAs), a novel toxicity assessment
    method, to assess the safety of paroxetine during pregnancy in a rodent model.
    OPAs utilize genetically diverse wild mice (Mus musculus) to evaluate competitive
    performance between experimental and control animals as they compete amongst each
    other for limited resources in semi-natural enclosures. Performance measures included
    reproductive success, male competitive ability and survivorship. Paroxetine-exposed
    males weighed 13% less, had 44% fewer offspring, dominated 53% fewer territories
    and experienced a 2.5-fold increased trend in mortality, when compared with controls.
    Paroxetine-exposed females had 65% fewer offspring early in the study, but rebounded
    at later time points. In cages, paroxetine-exposed breeders took 2.3 times longer
    to produce their first litter and pups of both sexes experienced reduced weight
    when compared with controls. Low-dose paroxetine-induced health declines detected
    in this study were undetected in preclinical trials with dose 2.5-8 times higher
    than human therapeutic doses. These data indicate that OPAs detect phenotypic
    adversity and provide unique information that could useful towards safety testing
    during pharmaceutical development. [Keywords: intraspecific competition, pharmacodynamics,
    reproductive success, semi-natural enclosures, SSRI, toxicity assessment.]'
- - /docs/psychology/writing/1993-ericsson.pdf
  - The role of deliberate practice in the acquisition of expert performance
  - K. Anders Ericsson, Ralf T. Krampe, Clemens Tesch-Römer
  - 1993-07
  - 10.1037/0033-295x.100.3.363
  - The theoretical framework presented in this article explains expert performance
    as the end result of individuals' prolonged efforts to improve performance while
    negotiating motivational and external constraints. In most domains of expertise,
    individuals begin in their childhood a regimen of effortful activities (deliberate
    practice) designed to optimize improvement. Individual differences, even among
    elite performers, are closely related to assessed amounts of deliberate practice.
    Many characteristics once believed to reflect innate talent are actually the result
    of intense practice extended for a minimum of 10 yrs. Analysis of expert performance
    provides unique evidence on the potential and limits of extreme environmental
    adaptation and learning.
- - http://www.vpri.org/pdf/tr2012001_steps.pdf#page=2
  - ! 'STEPS Toward Expressive Programming Systems: ''A Science Experiment'''
  - Yoshiki Ohshima, Dan Amelang, Ted Kaehler, Bert Freudenberg, Aran Lunzer, Alan
    Kay, Ian Piumarta, Takashi Yamamiya, Alan Borning, Hesam Samimi, Bret Victor,
    Kim Rose
  - '2012'
  - ''
  - ! '<p>[Technical report from a research project aiming at writing a GUI OS in
    20k LoC; tricks include <a href="http://www.moserware.com/2008/04/towards-moores-law-software-part-3-of-3.html">ASCII
    art networking DSLs & generic optimization for text layout</a>, which lets them
    implement a full OS, sound, GUI desktops, Internet networking & web browsers,
    a text/document editor etc, all in less lines of code that most OSes need for
    small parts of any of those.]</p> <p>...Many software systems today are made from
    millions to hundreds of millions of lines of program code that is too large, complex
    and fragile to be improved, fixed, or integrated. (One hundred million lines of
    code at 50 lines per page is 5000 books of 400 pages each! This is beyond human
    scale.) What if this could be made literally 1000 times smaller&mdash;or more?
    And made more powerful, clear, simple and robust?...The ''STEPS Towards Expressive
    Programming Systems'' project is taking the familiar world of personal computing
    used by more than a billion people every day&mdash;currently requiring hundreds
    of millions of lines of code to make and sustain&mdash;and substantially recreating
    it using new programming techniques and ''architectures'' in dramatically smaller
    amounts of program code. This is made possible by new advances in design, programming,
    programming languages, systems organizations, and the use of science to analyze
    and create models of software artifacts.</p><p><em>STEPS Aims At ''Personal Computing''</em>&mdash;STEPS
    takes as its prime focus the dynamic modeling of ''personal computing'' as most
    people think of it...word processor, spreadsheet, Internet browser, other productivity
    SW; User Interface and Command Listeners: windows, menus, alerts, scroll bars
    and other controls, etc.; Graphics and Sound Engine: physical display, sprites,
    fonts, compositing, rendering, sampling, playing; Systems Services: development
    system, database query languages, etc.; Systems Utilities: file copy, desk accessories,
    control panels, etc.; Logical Level of OS: e.g. file management, Internet, and
    networking facilities, etc.; Hardware Level of OS: e.g. memory manager, process
    manager, device drivers, etc.</p>'
- - /docs/longevity/2019-zeraatkar.pdf
  - ! 'Effect of Lower Versus Higher Red Meat Intake on Cardiometabolic and Cancer
    Outcomes: A Systematic Review of Randomized Trials'
  - Dena Zeraatkar, Bradley C. Johnston, Jessica Bartoszko, Kevin Cheung, Malgorzata
    M. Bala, Claudia Valli, Montserrat Rabassa, Deagan Sit, Kirolos Milio, Behnam
    Sadeghirad, Arnav Agarwal, Adriana M. Zea, Yung Lee, Mi Ah Han, Robin W.M. Vernooij,
    Pablo Alonso-Coello, Gordon H. Guyatt, Regina El Dib
  - 2019-10-01
  - 10.7326/M19-0622
  - ! '<p><strong>Background</strong>: Few randomized trials have evaluated the effect
    of reducing red meat intake on clinically important outcomes.</p><p><strong>Purpose</strong>:
    To summarize the effect of lower versus higher red meat intake on the incidence
    of cardiometabolic and cancer outcomes in adults.</p><p><strong>Data Sources</strong>:
    EMBASE, CENTRAL, CINAHL, Web of Science, and ProQuest from inception to July 2018
    and MEDLINE from inception to April 2019, without language restrictions.</p><p><strong>Study
    Selection</strong>: Randomized trials (published in any language) comparing diets
    lower in red meat with diets higher in red meat that differed by a gradient of
    at least 1 serving per week for 6 months or more.</p><p><strong>Data Extraction</strong>:
    Teams of 2 reviewers independently extracted data and assessed the risk of bias
    and the certainty of the evidence.</p><p><strong>Data Synthesis</strong>: Of 12
    eligible trials, a single trial enrolling 48&thinsp;835 women provided the most credible,
    though still low-certainty, evidence that diets lower in red meat may have little
    or no effect on all-cause mortality (hazard ratio [HR], 0.99 [95% CI, 0.95 to
    1.03], cardiovascular mortality (HR, 0.98 [CI, 0.91 to 1.06]), and cardiovascular
    disease (HR, 0.99 [CI, 0.94 to 1.05]). That trial also provided low- to very-low-certainty
    evidence that diets lower in red meat may have little or no effect on total cancer
    mortality (HR, 0.95 [CI, 0.89 to 1.01]) and the incidence of cancer, including
    colorectal cancer (HR, 1.04 [CI, 0.90 to 1.20]) and breast cancer (HR, 0.97 [0.90
    to 1.04]).</p><p><strong>Limitations</strong>: There were few trials, most addressing
    only surrogate outcomes, with heterogeneous comparators and small gradients in
    red meat consumption between lower versus higher intake groups.</p><p><strong>Conclusion</strong>:
    Low- to very-low-certainty evidence suggests that diets restricted in red meat
    may have little or no effect on major cardiometabolic outcomes and cancer mortality
    and incidence.</p>'
- - https://blogs.msdn.microsoft.com/larryosterman/2004/03/30/one-in-a-million-is-next-tuesday/
  - ! '''One in a million'' is next Tuesday'
  - Larry Osterman
  - 2004-03-30
  - ''
  - ! '<p>I was looking into a bug with Gordon Letwin, the architect for DOS 4. I
    looked at the code and commented “Maybe this is what was happening? But if that
    were the case, it’d take a one in a million chance for it to happen”.</p><p>Gordon’s
    response was simply: “In our business, one in a million is next Tuesday”. He then
    went on to comment that at the speeds which modern computers operate (&gt;4.77
    MHz, remember), things happened so quickly that something with a one in a million
    chance of occurrence is likely to happen in the next day or so.</p><p>I’m not
    sure I’ve ever received better advice in my career. It has absolutely stood the
    test of time–no matter how small the chance of something happening, with modern
    computers and modern operating systems, essentially every possible race condition
    or deadlock will be found within a reasonable period of time. And I’ve seen some
    absolute doozies in my time–race conditions on MP machines where a non interlocked
    increment occurred (one variant of Michael Grier’s <code>i = i + 1</code> bug).
    Data corruptions because you have one non protected access to a data structure.
    I’m continually amazed at the NT scheduler’s uncanny ability to context switch
    my application at just the right time as to expose my data synchronization bug.
    Or to show just how I can get my data structures deadlocked in hideous ways.</p><p>So
    nowadays, whenever anyone comments on how unlikely it is for some event to occur,
    my answer is simply: “One in a million is next Tuesday”.</p>'
- - https://slate.com/news-and-politics/2017/03/outrageous-trial-transcript-fees-are-bad-for-defendants-journalists-and-democracy.html
  - ! 'Public Record, Astronomical Price: Court reporters charge outrageous fees to
    reproduce trial transcripts. That’s bad for defendants, journalists, and democracy.'
  - Emma Copley Eisenberg (Slate)
  - 2017-03-22
  - ''
  - <p>The trial transcripts were there, 12 neatly bound volumes…I needed a copy,
    I said. “Sure,” she replied warmly before noting that all transcript copies must
    come directly from the court reporter at a price of $1 per page. The transcript
    I wanted was 2,400 pages.</p><p>The court reporter, Twyla, picked up on the first
    ring. I pleaded poor journalist and poor grad student, but she, a veteran of the
    field, was unmoved. Twyla informed me that the rate was governed by law, and besides,
    she was entitled to that money—in fact, she needed it to be fairly compensated
    for her work. Could that be? It could. The West Virginia State Code of Civil Procedure
    dictates that a court reporter must provide on request a trial transcript for
    $2.85 per page, with any subsequent copies of that same transcript to be supplied
    for $1 per page. The cost is even higher in other states. In Georgia, for instance,
    the rate is $6 per page.</p><p>The rates are set that way to compensate court
    reporters for expenses they must pay themselves. Twyla explained to me that, while
    the state of West Virginia provides an office in the courthouse and a telephone
    for court reporters, it does not pay for most of the tools and equipment she needs
    to do her job. Laptops, note-taking machines and software, paper, and pencils
    are necessary items for professional transcription. All of it—which could cost
    as much as $13,000 a year—comes out of court reporters’ pockets, she said. It’s
    a huge expense for professionals earning an average $50,000 per year but can be
    worth it if a court reporter sells one or two copies of her transcripts. Twyla
    says she’s heard of some women (89 percent of court reporters in the United States
    are female) making up to $90,000 a year between their salaries and the sale of
    transcripts they’ve created—more than decent pay in a rural area like Greenbrier
    County, where the median household income is just shy of $40,000.</p><p>Using
    fees to subsidize court reporter pay works in theory, but in practice it makes
    trial transcripts too expensive for an average citizen or journalist to afford.
    It also can put a barrier between trial transcripts and individuals who should
    be entitled to them. I learned later that the defendant in the case I was researching
    paid more than $7,000 to obtain a copy of the transcript from his own trial so
    his lawyers could analyze it for grounds for appeal…For Twyla, the current law
    demands that she jealously guard each page of her work to ensure she makes a decent
    living. For those tried and convicted of crimes, this means ponying up thousands
    of dollars for a record of their experience in the courts. For journalists like
    me, it means not learning why a jury of a man’s peers found him guilty of murder—unless
    we can spare $2,400, which I still can’t.</p><p>The trial transcripts were there,
    12 neatly bound volumes…I needed a copy, I said. “Sure,” she replied warmly before
    noting that all transcript copies must come directly from the court reporter at
    a price of $1 per page. The transcript I wanted was 2,400 pages.</p><p>The court
    reporter, Twyla, picked up on the first ring. I pleaded poor journalist and poor
    grad student, but she, a veteran of the field, was unmoved. Twyla informed me
    that the rate was governed by law, and besides, she was entitled to that money—in
    fact, she needed it to be fairly compensated for her work. Could that be? It could.
    The West Virginia State Code of Civil Procedure dictates that a court reporter
    must provide on request a trial transcript for $2.85 per page, with any subsequent
    copies of that same transcript to be supplied for $1 per page. The cost is even
    higher in other states. In Georgia, for instance, the rate is $6 per page.</p><p>The
    rates are set that way to compensate court reporters for expenses they must pay
    themselves. Twyla explained to me that, while the state of West Virginia provides
    an office in the courthouse and a telephone for court reporters, it does not pay
    for most of the tools and equipment she needs to do her job. Laptops, note-taking
    machines and software, paper, and pencils are necessary items for professional
    transcription. All of it—which could cost as much as $13,000 a year—comes out
    of court reporters’ pockets, she said. It’s a huge expense for professionals earning
    an average $50,000 per year but can be worth it if a court reporter sells one
    or two copies of her transcripts. Twyla says she’s heard of some women (89% of
    court reporters in the United States are female) making up to $90,000 a year between
    their salaries and the sale of transcripts they’ve created—more than decent pay
    in a rural area like Greenbrier County, where the median household income is just
    shy of $40,000.</p><p>Using fees to subsidize court reporter pay works in theory,
    but in practice it makes trial transcripts too expensive for an average citizen
    or journalist to afford. It also can put a barrier between trial transcripts and
    individuals who should be entitled to them. I learned later that the defendant
    in the case I was researching paid more than $7,000 to obtain a copy of the transcript
    from his own trial so his lawyers could analyze it for grounds for appeal…For
    Twyla, the current law demands that she jealously guard each page of her work
    to ensure she makes a decent living. For those tried and convicted of crimes,
    this means ponying up thousands of dollars for a record of their experience in
    the courts. For journalists like me, it means not learning why a jury of a man’s
    peers found him guilty of murder—unless we can spare $2,400, which I still can’t.</p>
- - https://openreview.net/forum?id=Bkl8YR4YDB
  - Large-scale Pretraining for Neural Machine Translation with Tens of Billions of
    Sentence Pairs
  - Anonymous et al 2019
  - 2019-09-25
  - ''
  - In this paper, we investigate the problem of training neural machine translation
    (NMT) systems with a dataset of more than 40 billion bilingual sentence pairs,
    which is larger than the largest dataset to date by orders of magnitude. Unprecedented
    challenges emerge in this situation compared to previous NMT work, including severe
    noise in the data and prohibitively long training time. We propose practical solutions
    to handle these issues and demonstrate that large-scale pretraining significantly
    improves NMT performance. We are able to push the BLEU score of WMT17 Chinese-English
    dataset to 32.3, with a significant performance boost of +3.2 over existing state-of-the-art
    results.
- - https://www.usenix.org/system/files/conference/woot16/woot16-paper-wustrow.pdf
  - ! 'DDoSCoin: Cryptocurrency with a Malicious Proof-of-Work'
  - Eric Wustrow, Benjamin VanderSloot
  - 2016-08-08
  - ''
  - <p>[HTTPS connections can provide third-party-verifiable signatures and so HTTPS
    is a valid Proof-of-Work and one can incentivize creating HTTPS connections and
    hence DDoSes. This could also be used non-maliciously to create a distributed
    anonymous uptime-checking service, by incentivizing only a few connections each
    time period for small bounties.]</p> <p>Since its creation in 2009, Bitcoin has
    used a hash-based proof-of-work to generate new blocks, and create a single public
    ledger of transactions. The hash-based computational puzzle employed by Bitcoin
    is instrumental to its security, preventing Sybil attacks and making double-spending
    attacks more difficult. However, there have been concerns over the efficiency
    of this proof-of-work puzzle, and alternative “useful” proofs have been proposed.
    In this paper, we present DDoSCoin, which is a cryptocurrency with a <em>malicious</em>
    proof-of-work. DDoSCoin allows miners to prove that they have contributed to a
    distributed denial of service attack against specific target servers. This proof
    involves making a large number of TLS connections to a target server, and using
    cryptographic responses to prove that a large number of connections has been made.
    Like proof-of-work puzzles, these proofs are inexpensive to verify, and can be
    made arbitrarily difficult to solve.</p>
- - https://newcriterion.com/issues/2019/10/leninthink
  - ! 'Leninthink: On the practice behind the theory of Marxism-Leninism'
  - Gary Saul Morson
  - 2019-10
  - ''
  - ! '[This re-appraisal of Lenin is just about as damning as any re-appraisal of
    anybody could possibly be. “He invented a form of government we have come to call
    totalitarian, which rejected in principle the idea of any private sphere outside
    of state control. He invented the one-party state, a term that would previously
    have seemed self-contradictory since a party was, by definition, a part. He believed
    that state power had to be based on sheer terror, and so he created the terrorist
    state. Violence was a goal in itself”]'
- - http://cabinetmagazine.org/issues/33/allen.php
  - Mark of Integrity
  - Jonathan Allen
  - 2009-02
  - ''
  - <p>[Card marking is a venerable and sophisticated art. Jonathan Allen on juiced
    cards, luminous readers, sunning the deck, and other sharpers’ tricks <a href="https://en.wikipedia.org/wiki/Card_marking">card
    marking</a>)]</p><p>The history of the marked playing card, perhaps as old as
    the playing card itself, is a miscellany of inventive guile. “The systems of card-marking
    are as numerous as they are ingenious,” wrote John Nevil Maskelyne in 1894. “Card
    doctoring,” to use Erdnase’s term, covers many forms of subterfuge, but in the
    brief survey that follows, we shall focus our attention upon what might more usefully
    be termed the “language” of the marked card.</p><p>…“Luminous readers” are cards
    treated in such a way that pale green ink traces become clearly visible when viewed
    through red-filtered spectacles or contact lenses. The technology caused alarm
    upon its discovery but, due to its limited effectiveness and its reliance upon
    somewhat vampiric eye adornment, has remained more of a popular novelty than a
    serious subterfuge.<sup>11</sup> “Juiced cards,” on the other hand, do not need
    lens-based viewing, instead requiring the reader to defocus his or her eyes and
    spot liminal fluid-residue marks on an opponent’s distant cards (juiced cards
    are also known as “distance readers”). To many players, juicing, and its recent
    high-tech offshoot, “video juicing,” are the most effective real-world card-marking
    system available, and the considerable price of the closely guarded fluid recipe
    and application technique reflects this growing reputation.</p>
- - https://www.g3journal.org/content/9/9/2863
  - A Prospective Analysis of Genetic Variants Associated with Human Lifespan
  - Kevin M. Wright, Kristin A. Rand, Amir Kermany, Keith Noto, Don Curtis, Daniel
    Garrigan, Dmitri Slinkov, Ilya Dorfman, Julie M. Granka, Jake Byrnes, Natalie
    Myres, Catherine A. Ball, J. Graham Ruby
  - 2019-09
  - 10.1534/g3.119.400448
  - We present a massive investigation into the genetic basis of human lifespan. Beginning
    with a genome-wide association (GWA) study using a de-identified snapshot of the
    unique AncestryDNA database–more than 300,000 genotyped individuals linked to
    pedigrees of over 400,000,000 people–we mapped six genome-wide significant loci
    associated with parental lifespan. We compared these results to a GWA analysis
    of the traditional lifespan proxy trait, age, and found only one locus, APOE,
    to be associated with both age and lifespan. By combining the AncestryDNA results
    with those of an independent UK Biobank dataset, we conducted a meta-analysis
    of more than 650,000 individuals and identified fifteen parental lifespan-associated
    loci. Beyond just those significant loci, our genome-wide set of polymorphisms
    accounts for up to 8% of the variance in human lifespan; this value represents
    a large fraction of the heritability estimated from phenotypic correlations between
    relatives.
- - /docs/economics/2014-lewis.pdf
  - ! 'Managing an iconic old luxury brand in a new luxury economy: Hermès handbags
    in the US market'
  - Tasha L. Lewis, Brittany Haas
  - 2014-03
  - 10.1386/gfb.1.1.167_1
  - The Hermès brand is synonymous with a wealthy global elite clientele and its products
    have maintained an enduring heritage of craftsmanship that has distinguished it
    among competing luxury brands in the global market. Hermès has remained a family
    business for generations and has successfully avoided recent acquisition attempts
    by luxury group LVMH. Almost half of the luxury firm’s revenue ($1.5B in 2012)
    is derived from the sale of its leather goods and saddlery, which includes its
    handbags. A large contributor to sales is global demand for one of its leather
    accessories, the Birkin bag, ranging in price from $10,000 to $250,000. Increased
    demand for the bag in the United States since 2002 resulted in an extensive customer
    waitlist lasting from months to a few years. Hermès retired the famed waitlist
    (sometimes called the ‘dream list’) in the United States in 2010, and while the
    waitlist has been removed, demand for the Birkin bag has not diminished and making
    the bag available to luxury consumers requires extensive, careful distribution
    management. In addition to inventory constraints related to demand for the Birkin
    bag in the United States, Hermès must also manage a range of other factors in
    the US market. These factors include competition with ‘affordable’ luxury brands
    like Coach, monitoring of unsolicited brand endorsers as well as counterfeit goods
    and resellers. This article examines some of the allocation practices used to
    carefully manage the Hermès brand in the US market.
- - https://digitalcommons.sia.edu/cgi/viewcontent.cgi?article=1007&context=stu_proj
  - ! 'Birkin Demand: A Sage & Stylish Investment'
  - Brittanny Newsom
  - 2017-12-19
  - ''
  - <p>What Is A Birkin? / History / Design / Craftsmanship &amp; Quality / How To
    Buy A Birkin / Demand &amp; Exclusivity / The Secondhand Market / Clientele /
    Why the Birkin Is A Safe Investment / Investment Factors / Investment Pricing
    Factors / Comparisons with Other Investments / Fake vs. Real / How the Birkin
    Remains Dominant / The Media / The Defaced Birkin / Conclusion</p><p>Pricing factors
    for the Birkin are a huge piece of investing in these bags. Several factors make
    determining Birkin prices tricky. The first is the price variations that occur
    year to year at the discretion of Hermès. “They know they have a valuable product
    and generally increase the prices by between 5% and 10% annually for a new bag.”
    The bag’s price can vary among Hermès’s extended leather options, color, size
    and that’s before you start looking at exotic skins, custom hardware, and other
    personal touches which can bring the price upwards. Pricing for a Birkin can range
    from around $7,000 and can go as high as $300,000. As many collectors venture
    into the market for value when purchasing a Birkin, one of the most important
    consideration when looking at a Birkin is the condition. “If a bag is in good
    condition it can fetch up to or more than 80% of what the previous owner invested,
    a bag in excellent condition up to or more than 100%, and if a bag in pristine
    condition up to or more than 120% of what the previous owner invested.” When investing
    in a Birkin, it’s also wise to consider the length of the investment. For instance,
    if you are planning to hold on to the bag over a long period of time, or if you
    are planning on wearing or holding on to the bag, neutral colors are more advisable
    such as black, gold, brown or gray. These classic colors will never go out of
    style, and the bag will maintain its value. “Most people want something they can
    live in–that they can wear with jeans, with a suit, or carry on an airplane. So
    the most practical choice is a neutral”. However, one of the traits, which make
    Birkin handbags unique, is the variety of colors available, which are introduced
    every season, many of which are specific and exclusive to Hermès. New colors have
    shown to be more popular in the immediate resale market for collectors as a short
    term investment. These would include vivid colors such as bright red, blue or
    orange, which is Hermès signature company color. Most importantly, it is imperative
    to know your leathers when purchasing a Birkin bag. Each leather has its uniqueness,
    and each leather requires different levels of maintenance. Some of the standard
    leathers such as Togo, Clemence and Epsom are textured to protect them from scratches
    and tear. Rare and exotic skin Birkins are more valuable on the resale market
    due to the difficulty Hermès has in obtaining them. These skins include crocodile,
    alligator, lizard, snake, and ostrich. Crocodile, for example, is one of the most
    expensive leathers because Hermès has to obey strict ethical standards. The skin
    also takes decades to reach maturity, making it very rare. In June 2016, Christie’s
    Hong Kong sold a 3040cm Himalayan Birkin, with white gold hardware set with 245F
    color diamonds weighing close to ten karats for $300,168. This particular sale
    was expensive because the bag was in pristine condition, and aside from it being
    crocodile, it was white which is the hardest color to achieve with crocodile skin,
    as you have to remove all of its natural pigment. Bought in 2008 by the seller,
    the Himalayan bag had a presale estimate of $190,000 and was billed as the “most
    valuable handbag in the world”.</p><p>…Simply stated, it appears that the bag’s
    success hinges on this prestigious perception. A Birkin, terribly difficult to
    get is therefore highly coveted. In our global economy, that’s all the brand needs
    to pack the infinite waiting list. It is fashion’s version of Darwinism. We always
    want what we can’t have, so we will do whatever we can to get it. For instance,
    Victoria Beckham, the posh clothing designer, and wife of David Beckham reportedly
    owns about 100 Birkins, collectively valued at $2 million. It includes a pink
    Ostrich leather Birkin worth $150,000. Despite the fact that she has introduced
    her own line of handbags, she’s been spotted by the paparazzi wearing a Birkin
    bag. Kris Jenner also has a massive Birkin collection that she flaunts via social
    media and the willing participation of paparazzi. Her collection includes an Electric
    Blue 35cm which is supposedly worth $19,000. Actress Katie Holmes has gained attention
    for a bold red Birkin, while Julianne Moore has been seen wearing a hunter green
    40cm with gold hardware. Julia Roberts and Eva Longoria all have even been seen
    with the bag. Even B-listed personalities such as reality star, Nicole Richie,
    with a black Birkin workout bag, is famously noted as frequently asking the paparazzi,
    “Did you get my bag?”. The Birkin has looked extra special on the arms of models,
    Alessandra Ambrosio and Kate Moss. Singers such as Jennifer Lopez and Courtney
    Love ironically show off their Birkins, and even world leaders such as Princess
    Mary of Denmark, with her black crocodile Birkin worth $44,500, is aware of its
    meaning and status.</p>
- - https://www.newyorker.com/magazine/2010/11/22/natures-spoils
  - ! 'Nature''s Spoils: The underground food movement ferments revolution'
  - Burkhard Bilger (New Yorker)
  - 2010-11-22
  - ''
  - ! '<p>[Discussion of food subcultures: dumpster divers, raw food enthusiasts,
    fermenters, roadkill, and ''high'' (fully rotten meat) food advocates, with visits
    to gay commune Hickory Knoll and raw milk dairies. The author ultimately draws
    the line at trying high game, however.]</p><p>When Torma unclamped his jar, a
    sickly-sweet miasma filled the air—an odor as natural as it was repellent. Decaying
    meat produces its own peculiar scent molecules, I later learned, with names like
    putrescine and cadaverine. I could still smell them on my clothes hours later.
    Torma stuck two fingers down the jar and fished out a long, wet sliver. “Want
    a taste?” he said.</p> <p>It was the end of a long day. I’d spent most of it consuming
    everything set before me: ants, acorns, raw milk, dumpster stew, and seven kinds
    of mead, among other delicacies. But even Katz took a pass on high meat. While
    Torma threw back his head and dropped in his portion, like a seal swallowing a
    mackerel, we quietly took our leave. “You have to trust your senses,” Katz said,
    as we were driving away. “To me, that smelled like death.”</p>'
- - https://www.karger.com/Article/FullText/502257
  - ! 'Metformin and Aging: A Review'
  - Hartmut H. Glossmann, O.M. Lutz
  - 2019-09-13
  - 10.1159/000502257
  - ! '<p>Metformin is sometimes proposed to be an “anti-aging” drug, based on preclinical
    experiments with lower-order organisms and numerous retrospective data on beneficial
    health outcomes for type 2 diabetics. Large prospective, placebo-controlled trials
    are planned, in pilot stage or running, to find a new use (or indication) for
    an aging population. As one of the metformin trials has “frailty” as its endpoint,
    similar to a trial with a plant-derived senolytic, the latter class of novel anti-aging
    drugs is briefly discussed. Concerns exist not only for vitamin B12 and B6 deficiencies,
    but also about whether there are adverse effects of metformin on individuals who
    try to remain healthy by maintaining cardiovascular fitness via exercise.</p><p>...<em>Conclusions,
    Recommendations, and Perspectives</em>: The rationale for the ongoing or planned
    metformin trials is almost exclusively based on observations (associations) of
    potential benefits in a diabetic (or prediabetic) population. Its efficacy even
    in an at-risk cohort of aged people has not yet been proven. Metformin is associated
    with a higher risk of vitamin B12 and vitamin B6 deficiency, which may result
    in an increased risk of cognitive dysfunction [98]. Supplementation is strongly
    recommended to metformin users.</p> <p>Of greater concern are the results of small
    trials in which the effects of metformin on metabolic responses to exercise or
    on cardiorespiratory fitness were tested. In a placebo-controlled, double-blind,
    crossover trial with healthy young subjects, metformin caused a small but significant
    decline in maximal aerobic capacity [99]. A double-blind, placebo-controlled landmark
    trial with older adults with one risk factor for T2D investigated the effects
    of metformin and 12 weeks of aerobic exercise [100]. Contrary to expectations–namely,
    that the effects of exercise and the drug would be additive–“metformin attenuated
    the increase in whole-body insulin sensitivity and abrogated the exercise-mediated
    increase in skeletal muscle mitochondrial respiration.” The results of the (repurposing)
    MASTERS trial (NCT02308228; Metformin to Augment Strength Training Effective Response
    in Seniors) [100] will be instructive. MASTERS is testing the hypothesis that
    older individuals’ long-term treatment with metformin augments the effects of
    resistance exercise, especially in the “nonresponder” aging population.</p>'
- - /docs/history/2019-risi.pdf
  - Predicting History
  - Joseph Risi, Amit Sharma, Rohan Shah, Matthew Connelly, Duncan J. Watts
  - 2019-06-03
  - 10.1038/s41562-019-0620-8
  - Can events be accurately described as historic at the time they are happening?
    Claims of this sort are in effect predictions about the evaluations of future
    historians; that is, that they will regard the events in question as significant.
    Here we provide empirical evidence in support of earlier philosophical arguments<sup>1</sup>
    that such claims are likely to be spurious and that, conversely, many events that
    will one day be viewed as historic attract little attention at the time. We introduce
    a conceptual and methodological framework for applying machine learning prediction
    models to large corpora of digitized historical archives. We find that although
    such models can correctly identify some historically important documents, they
    tend to over-predict historical significance while also failing to identify many
    documents that will later be deemed important, where both types of error increase
    monotonically with the number of documents under consideration. On balance, we
    conclude that historical significance is extremely difficult to predict, consistent
    with other recent work on intrinsic limits to predictability in complex social
    systems<sup>2,3</sup>. However, the results also indicate the feasibility of developing
    ‘artificial archivists’ to identify potentially historic documents in very large
    digital corpora.
- - https://www.goodreads.com/review/show/396645245
  - ! 'Bakker''s <em>Second Apocalypse</em> & Frank Herbert''s <em>Dune</em>: time
    loops &amp; finding freedom in an unfree universe'
  - Gwern Branwen
  - 2019-08-30
  - ''
  - ! '<p>Review of SF/F author <a href="https://en.wikipedia.org/wiki/R._Scott_Bakker">R.
    Scott Bakker</a>‘s long-running <em>Second Apocalypse</em> series, which finished
    in 2017. The series, a loose retelling of the Crusades, set in a fallen-SF fantasy
    environment, has drawn attention for its ambitious scope and obscure philosophical
    message centering around determinism, free will, moral nihilism, eliminativism
    of cognitive states, and the interaction of technology &amp; ethics (which Bakker
    terms the ’Semantic Apocalypse’). In this series, the protagonist attempts to
    stop the apocalypse and ultimately accidentally causes it.</p><p>I highlight that
    Frank Herbert’s <em>Dune</em> universe is far more influential on Bakker than
    reviewers of Bakker have appreciated: countless elements are reflected in Bakker,
    and the very name of the primary antagonist, the ‘No-God’, uses a naming pattern
    from <em>Dune</em> and operates similarly. Further, both <em>Dune</em> and the
    <em>Second Apocalypse</em> are deeply concerned with the nature of time and temporal
    loops controlling ‘free’ behavior. Where they diverge is in what is to be done
    about the human lack of freedom and manipulability by external environments, and
    have radically different views about what is desirable: in <em>Dune</em>, humanity
    gradually grows up and achieves freedom from the time loops by the creation of
    a large time loop whose stable fixed point is the destruction of all time loops,
    ensuring that humanity will go on existing in some form forever; in the <em>Second
    Apocalypse</em>, liberation is achieved only through death.</p>'
- - https://www.nature.com/articles/s41534-019-0141-3
  - Universal quantum control through deep reinforcement learning
  - Murphy Yuezhen Niu, Sergio Boixo, Vadim N. Smelyanskiy, Hartmut Neven
  - 2019-04-23
  - 10.1038/s41534-019-0141-3
  - Emerging reinforcement learning techniques using deep neural networks have shown
    great promise in control optimization. They harness non-local regularities of
    noisy control trajectories and facilitate transfer learning between tasks. To
    leverage these powerful capabilities for quantum control optimization, we propose
    a new control framework to simultaneously optimize the speed and fidelity of quantum
    computation against both leakage and stochastic control errors. For a broad family
    of two-qubit unitary gates that are important for quantum simulation of many-electron
    systems, we improve the control robustness by adding control noise into training
    environments for reinforcement learning agents trained with trusted-region-policy-optimization.
    The agent control solutions demonstrate a two-order-of-magnitude reduction in
    average-gate-error over baseline stochastic-gradient-descent solutions and up
    to a one-order-of-magnitude reduction in gate time from optimal gate synthesis
    counterparts. These significant improvements in both fidelity and runtime are
    achieved by combining new physical understandings and state-of-the-art machine
    learning techniques. Our results open a venue for wider applications in quantum
    simulation, quantum chemistry and quantum supremacy tests using near-term quantum
    devices.
- - https://www.c82.net/blog/?id=79
  - Making of Byrne’s Euclid
  - Nicholas Rougeux
  - 2018-12-16
  - ''
  - <p>Creating a faithful online reproduction of a book considered one of the most
    beautiful and unusual publications ever published is a daunting task. <em>Byrne’s
    Euclid</em> is my tribute to Oliver Byrne’s most celebrated publication from 1847
    that illustrated the geometric principles established in Euclid’s original <em>Elements</em>
    from 300 BC.</p><p>In 1847, Irish mathematics professor Oliver Byrne worked closely
    with publisher William Pickering in London to publish his unique edition titled
    <em>The First Six Books of the Elements of Euclid in which Coloured Diagrams and
    Symbols are Used Instead of Letters for the Greater Ease of Learners</em>—or more
    simply, <em>Byrne’s Euclid</em>. Byrne’s edition was one of the first multicolor
    printed books and is known for its unique take on Euclid’s original work using
    colorful illustrations rather than letters when referring to diagrams. The precise
    use of colors and diagrams meant that the book was very challenging and expensive
    to reproduce. Little is known about why Byrne only designed 6 of the 13 books
    but it was could have been due to time and cost involved…I knew of other projects
    like Sergey Slyusarev’s ConTeXt rendition and Kronecker Wallis’ modern redesign
    but I hadn’t seen anyone reproduce the 1847 edition online in its entirety and
    with a design true to the original. This was my goal and I knew it was going to
    be a fun challenge.</p><figure><img src="https://www.c82.net/images/blog/euclid-book1-diagrams.jpg"
    alt="Diagrams from Book 1" /><figcaption>Diagrams from Book 1</figcaption></figure><p>[Detailed
    discussion of how to use Adobe Illustrator to redraw the modernist art-like primary
    color diagrams from Bryne in scalable vector graphics (SVG) for use in interactive
    HTML pages, creation of a custom <a href="https://en.wikipedia.org/wiki/Initial#Types_of_initial">drop
    caps/initials font</a> to replicate Bryne, his (questionable) efforts to use the
    <a href="https://en.wikipedia.org/wiki/Long_s">‘long s’</a> for greater authenticity,
    rendering the math using MathJax, and creating posters demonstrating all diagrams
    from the project for offline viewing.]</p>
- - https://www.math.ubc.ca/~cass/Euclid/byrne.html
  - Oliver Byrne's edition of Euclid [Scans]
  - Bill Casselman et al (University of British Columbia)
  - ''
  - ''
  - Online scanned edition; part of a set of Euclid editions.
- - /docs/statistics/1990-tufte-envisioninginformation-ch5-bryneseuclid.pdf
  - ! '<em>Envisioning Information</em>: chapter 5, ''Color and Information'', pg83-86
    [on Oliver Bryne''s color diagram version of Euclid''s <em>Elements</em>]'
  - Edward Tufte
  - '1990'
  - ''
  - ! '[Extracts from Tufte textbook on graphing information and visual design, where
    he revives & popularizes Oliver Bryne''s obscure Euclid edition, noting how effectively
    Bryne converts lengthy proofs into short sequences of cleanly-designed diagrams
    exploiting primary colors for legibility, and the curious anticipation of modernist
    design movements like De Stijl.]'
- - https://habr.com/ru/post/452520/
  - Fancy Euclid's <e>Elements</em> in T<sub>e</sub>X
  - Sergey Slyusarev
  - 2019-03-19
  - ''
  - <p>The most obvious option—to draw all the illustrations in Illustrator and compose
    the whole thing in InDesign—was promptly rejected. Geometrical constructions are
    not exactly the easiest thing to do in Illustrator, and no obvious way to automatically
    connect the main image to miniatures came to my mind. As for InDesign, although
    it's very good at dealing with such visually rich layouts, it promised to scare
    the hell out of me by the overcrowded “Links” panel. So, without thinking twice,
    I decided to use other tools that I was familiar with—MetaPost, which made it
    relatively easy to deal with geometry, and LaTeX, which I knew could do the job.
    Due to some problems with MetaPost libs for LaTeX, I replaced the latter with
    <a href="https://en.wikipedia.org/wiki/ConTeXt">ConTeXt</a> that enjoys an out-of-the-box
    merry relationship with MetaPost.</p><p><img src="https://hsto.org/webt/b9/xj/sq/b9xjsqwlk_6vlrkagvbpb2yfej0.jpeg"
    alt="Converting a Bryne Euclid diagram to ConTeXt vector graphics"></p><p>...
    There are also initials and vignettes in the original edition. On one hand, they
    were reasonably easy to recreate (at least, it wouldn't take a lot of thought
    to do this), but I decided to go with a more interesting (albeit hopeless) option—automatically
    generating the initials and vignettes with a random ornament. Not only is it fun,
    but also, the Russian translation would require adapting the style of the original
    initials to the Cyrillic script, which was not something I'd prefer to do. So,
    long story short, when you compile the book, a list of initial letters is written
    to the disk, and a separate MetaPost script can process it (very slowly) to produce
    the initials and vignettes. No two of them have the exact same ornament.</p>
- - /docs/statistics/peerreview/1975-johnson.pdf
  - Models of Control and Control of Bias
  - Martin U. Johnson
  - '1975'
  - ''
  - <p>The author discusses how to increase the quality and reliability of the research
    and reporting process in experimental parapsychology. Three levels of bias and
    control of bias are discussed. The levels are referred to as Model 1, Model 2
    and Model 3 respectively.</p><ol type="1"><li>Model 1 is characterized by its
    very low level of intersubjective control. The reliability of the results depends
    to a very great extent upon the reliability of the investigator and the editor.</li><li>Model
    2 is relevant to the case when the experimenter is aware of the potential risk
    of making both errors of observation and recording and tries to control this bias.
    However, this model of control does not make allowances for the case when data
    are intentionally manipulated.</li><li>Model 3 depicts a rather sophisticated
    system of control. One feature of this model is, that selective reporting will
    become harder since the editor has to make his decision as regards the acceptance
    or rejection of an experimental article prior to the results being obtained, and
    subsequently based upon the quality of the outline of the experiment. However,
    it should be stressed, that not even this model provides a fool-proof guarantee
    against deliberate fraud.</li></ol><p>It is assumed that the models of bias and
    control of bias under discussion are relevant to most branches of the behavioral
    sciences.</p>
- - /docs/statistics/peerreview/1975-johnson-2.pdf
  - Editorial [EJP editorial on registered reports]
  - Martin U. Johnson
  - '1975'
  - ''
  - ! 'This copy represents our first ''real'' issue of the <em>European Journal of
    Parapsychology</em>...As far as experimental articles are concerned, we would
    like to ask potential contributors to try and adhere to the publishing policy
    which we have outlined in the editorial of the demonstration copy, and which is
    also discussed at some length in the article: ''Models of Bias and Control of
    Bias'' [Johnson 1975a], in this issue. In short we shall try to avoid selective
    reporting and yet at the same time we shall try to refrain from making our journal
    a graveyard for all those studies which did not ''turn out''. These objectives
    may be fulfilled by the editorial rule of basing our judgment entirely on our
    impressions of the quality of the design and methodology of the planned study.
    The acceptance or rejection of a manuscript should if possible take place prior
    to the carrying out and the evaluation of the results of the study.'
- - /docs/statistics/peerreview/1976-johnson.pdf
  - ! 'On Publication Policy Regarding Non-Significant Results: Some comments on Dr.
    J.B. Rhine''s article in the comments section of the J.P., 39, No 2, 135-142'
  - Martin U. Johnson
  - '1976'
  - ''
  - ! '<p>…even the most proper use of statistics may lead to spurious correlations
    or conclusions if there are inadequacies regarding the research process itself.
    One of these sources of error in the research process is related to selective
    reporting; another to human limitations with regard to the ability to make reliable
    observations or evaluations. <a href="https://www.gwern.net/docs/statistics/bias/1966-dunnette.pdf"
    title="Fads, Fashions, and Folderols in Psychology">Dunette (1)</a> says:</p><blockquote><p>The
    most common variant is, of course, the tendency to bury negative results. I only
    recently became aware of the massive size of this great graveyard for dead studies
    when a colleague expressed gratification that only a third of his studies ‘turned
    out’—as he put it. Recently, a second variant of this secret game was discovered,
    quite inadvertently, by <a href="https://www.gwern.net/docs/statistics/bias/1962-wolins.pdf"
    title="Responsibility for raw data">Wolins 1962</a>, when he wrote to 37 authors
    to ask for the raw-data on which they had based recent journal articles. Wolins
    found that of the 37 who replied, 21 reported their data to be either misplaced,
    lost, or inadvertently destroyed. Finally, after some negotiation, Wolins was
    able to complete 7 re-analyses on the data supplied from 5 authors. Of the 7,
    he found gross errors in 3—errors so great as to clearly change the outcome of
    the experiments already reported.</p></blockquote><p>It should also be stressed
    that Rosenthal and others have demonstrated that experimenters tend to arrive
    at results found to be in full agreement with their expectancies, or with the
    expectancies of those within the scientific establishment in charge of the rewards.
    Even if some of Rosenthal’s results have been questioned [especially the ‘Pygmalion
    effect’] the general tendency seems to be unaffected.</p><p>I guess we can all
    agree upon the fact that selective reporting in studies on the reliability and
    validity, of for instance a personality test, is a bad thing. But what could be
    the reason for selective reporting? Why does a research worker manipulate his
    dead? Is it only because the research worker has a ‘weak’ mind or does there exist
    some kind of ‘steering field’ that exerts such an influence that improper behavior
    on the part of the research worker occurs?</p><p>It seems rather reasonable to
    assume that the editors of professional journals or research leaders in general
    could exert a certain harmful influence in this connection…There is no doubt at
    all in my mind about the ‘filtering’ or ‘shaping’ effect an editor may exert upon
    the output of his journal…As I see it, the major risk of selective reporting is
    not primarily a statistical one, but rather the research climate which the underlying
    policy create (“you are ‘good’ if you obtain supporting results; you are”no-good"
    if you only arrive at chance results").</p><p>…The analysis I carried out has
    had practical implications for the publication policy which we have stated as
    an ideal for our new journal: the <em>European Journal of Parapsychology</em>.</p>'
- - /docs/statistics/bias/1962-wolins.pdf
  - Responsibility for Raw Data
  - Leroy Wolins
  - 1962-09
  - 10.1037/h0038819
  - Comments on a Iowa State University graduate student's endeavor of requiring data
    of a particular kind in order to carry out a study for his master's thesis. This
    student wrote to 37 authors whose journal articles appeared in APA journals between
    1959 and 1961. Of these authors, 32 replied. 21 of those reported the data misplaced,
    lost, or inadvertently destroyed. 2 of the remaining 11 offered their data on
    the conditions that they be notified of our intended use of their data, and stated
    that they have control of anything that we would publish involving these data.
    Errors were found in some of the raw data that was obtained which caused a dilemma
    of either reporting the errors or not. The commentator states that if it were
    clearly set forth by the APA that the responsibility for retaining raw data and
    submitting them for scrutiny upon request lies with the author, this dilemma would
    not exist. The commentator suggests that a possibly more effective means of controlling
    quality of publication would be to institute a system of quality control whereby
    random samples of raw data from submitted journal articles would be requested
    by editors and scrutinized for accuracy and the appropriateness of the analysis
    performed.
- - /docs/statistics/bias/1966-dunnette.pdf
  - Fads, fashions, and folderol in psychology
  - Marvin D. Dunnette
  - '1966'
  - 10.1037/h0023535
  - ! '<p>[Influential early critique of academic psychology: weak theories, no predictions,
    poor measurements, poor replicability, high levels of publication bias, non-progressive
    theory building, and constant churn; many of these criticisms would be taken up
    by the ''Minnesota school'' of Bouchard/Meehl/Lykken/etc.]</p> <p>Fads include
    brain-storming, Q technique, level of aspiration, forced choice, critical incidents,
    semantic differential, role playing, and need theory. Fashions include theorizing
    and theory building, criterion fixation, model building, null-hypothesis testing,
    and sensitivity training. Folderol includes tendencies to be fixated on theories,
    methods, and points of view, conducting "little" studies with great precision,
    attaching dramatic but unnecessary trappings to experiments, grantsmanship, coining
    new names for old concepts, fixation on methods and apparatus, etc.</p>'
- - https://nostalgebraist.livejournal.com/68532.html
  - About Henry Darger
  - Nostalgebraist
  - 2011-05-26
  - ''
  - ! '<p>[On why <a href="https://en.wikipedia.org/wiki/Henry_Darger">Henry Darger</a>,
    a elderly, solitary dishwasher, wrote and illustrated a 15,000+ page unpublished
    fantasy novel.]</p><p>I’m here today to tell you about a book I read recently,
    namely <em>Henry Darger: In The Realms Of The Unreal</em>, by John MacGregor.
    It’s a study of <a href="http://en.wikipedia.org/wiki/Henry_Darger">Henry Darger</a>,
    a man I instantly became obsessed with upon encountering his Wikipedia entry sometime
    last fall.</p><p>Here’s a quick sketch of who Darger was, which will hopefully
    give you an idea of why I find him so fascinating. He was a reclusive man who
    worked various dishwashing jobs for most of his life. He only had one real friend
    in the course of his life, and although he occasionally interacted with the other
    residents of his apartment complex, they just saw him as a peculiar, taciturn
    eccentric. But when Darger was on his deathbed, his landlord Nathan Lerner began
    to clean out his room and discovered something incredible. Unknown to everyone
    around him, Darger had been writing and painting. Writing and painting <em>a lot</em>.
    Among the objects Lerner discovered were fifteen massive volumes comprising one
    continuous fictional work entitled <em>The Story of the Vivian Girls, in What
    is Known as the Realms of the Unreal, of the Glandeco-Angelinian War Storm Caused
    by the Child Slave Rebellion</em>. In total, the typed, single-spaced text was
    15,145 pages long—one of the longest fictional works ever produced by a human
    being, if not the longest. (Whether it is the longest or not depends on what counts
    as a single work; there are some long works of serial pulp fiction that, in total,
    are longer, but that’s only if you add up the length of hundreds of installments.)
    This was not Darger’s only writing project. There was also a sort of sequel, <em>Crazy
    House</em>, which ran to around 10,000 pages, and the 5000-page autobiography
    <em>The History of My Life</em>, as well as numerous journals and other miscellany.
    And then there were the paintings, hundreds of huge, odd-looking, compositions
    depicting battles, scenes of torture, and heroic adventures. (You can see some
    of Darger’s art thanks to Google Image Search <a href="http://images.google.com/images?hl=en&amp;q=henry+darger&amp;gbv=2&amp;biw=1218&amp;bih=673">here</a>).</p><p>It
    turned out that the paintings were illustrations for Darger’s 15,145-page masterwork,
    called <em>In The Realms Of The Unreal</em> for short. <em>In The Realms Of The
    Unreal</em> is, in some very broad sense, a fantasy novel. It takes place on a
    planet far larger than Earth, which Earth is said to orbit as a moon. This planet
    is mostly composed of Catholic nations, of which the most important to the plot
    are Angelinia, Calverinia and Abbieannia. (Protestants do not appear to exist
    in this world, though—confusingly enough—one of the Catholic nations is called
    Protestantia.) The story is about a war between the Catholic nations and the atheist
    nation Glandelinia, which is inhabited by evil, sadistic people who practice institutionalized
    child slavery. Shortly before the time period described in the text, some of the
    child slaves mounted a rebellion, led by a heroic 10-year-old named Annie Aronburg.
    The Glandelineans quashed the rebellion and killed Aronburg, but this started
    a chain of events that led to a Glandelinean invasion of Calverinia and eventually
    a full-scale war between the Catholic nations and Glandelinia. <em>In The Realms
    Of The Unreal</em> tells the story of this war, an incredibly long succession
    of huge battles, espionage missions, scenes of torture in the Glandelinean slave
    camps, and so on. The protagonists, curiously enough, are a set of seven prepubescent
    sisters—the titular Vivian girls—who follow the Christian armies, spy on the Glandelineans,
    and narrowly escape mortal danger on innumerable occasions. The battles are mostly
    realistic in nature—though they involve millions of combatants—but the world is
    an enchanted one, filled with chimeric beasts called “Blengiglomenean creatures”
    (or “Blengins,” for short) which assist and protect the Vivian girls.</p><p>…The
    problem comes when MacGregor tries to interpret the text psychologically, which
    happens often. MacGregor is a Freudian analyst—he studied with Anna Freud, in
    fact—and he is mainly interested in Darger as a psychological subject. Now, this
    is not the time or place to hash out whether Freudian psychology does or doesn’t
    succeed, generally speaking, at explaining the human mind. But even if I withhold
    judgment on MacGregor’s Freudian premises, his account of Darger’s psychology
    is just really, really bad and frustrating….So, without further ado, here are
    some interesting things about Henry Darger:</p><ul><li>In the <em>Realms</em>,
    there are numerous characters named after Darger…These Dargers do not all seem
    to be distinct in the author’s mind, and it’s often confusing which one is being
    referred to in any given instance.</li><li>Darger’s paintings are filled with
    prepubescent girls—usually the Vivian girls, but there are also sometimes anonymous
    child slaves, etc. They are usually depicted naked, even when there is no good
    reason for this…The little girls usually, but not always, have penises…</li><li>Darger
    collected lots of random junk in the course of his menial job. He was particularly
    fond of photographs of children…</li><li>The inspiration for writing the <em>Realms</em>
    was the loss of a particular newspaper clipping, a photo of Elsie Paroubek, a
    little girl who had been murdered, and whose murder was all over the Chicago papers
    for a short time. Darger’s journals express no particular interest in this picture
    <em>until</em> he discovered that he had lost it. After that, he spent much of
    the rest of his life in a profound state of anger at God, who he believed had
    taken the picture from him. He saw the fictional war between Christians and Glandelineans
    as a way of punishing God for taking the picture by causing harm to millions of
    (fictional?) Christians.</li><li>…Darger’s 5000-page work <em>The History Of My
    Life</em> is putatively an autobiography. However, that word does not accurately
    describe the vast majority of its contents. The first several hundred pages of
    the work are indeed an account of Darger’s early life. However, after describing
    a scene in which his younger self is entranced by the sight of a powerful storm,
    he apparently <em>gets distracted</em> by the storm and spends the remaining 4000-some
    pages of the text describing the wake of destruction caused by a fictional twister
    called “Sweetie Pie,” with no further mention of his own life whatsoever.</li><li>…Near
    the end of his life, Darger apparently spent a lot of time playing with string.
    In his journal he recounts collecting string and coiling and uncoiling it, and
    huge amounts of string were found in his room after his death.</li></ul><p>…Any
    account of Darger’s psychology is going to have to explain this weirdness. This
    is what, I contend, John MacGregor’s account fails to do. Fails pretty massively,
    in fact—massively enough that Darger seems less, rather than more, comprehensible
    after you read MacGregor try to “explain” him…But MacGregor also tells us that
    the battles sometimes lasted for hundreds of pages, and that they include vast
    amounts of bureaucratic detail (about particular regiments, commanders, tactical
    maneuvers, etc.—lots and lots of proper names), but that none of this detail is
    in any way self-consistent (so that it is impossible, for instance, to form a
    mental picture of the shape of the battlefield that does not distort over time).
    And that Darger is obsessed with what some might consider the more “boring” details
    of war—he spends huge amounts of time describing the way the supply lines work,
    for instance. It’s still conceivable that this sort of ridiculously long bureaucratic
    catalogue could be an expression of pent-up rage, but if so, it’s a very odd one,
    and naturally raises the question of <em>just what sort of guy</em> would deal
    with his frustrations by going home from his job every night and writing about
    the tedious technical details of a fictional war. But that’s exactly the question
    MacGregor does not want to answer… If writing this stuff was somehow pornographic
    for Darger, then how is it that so much of the text is composed of moralizing
    about the glorious Christians and the wicked Glandelineans, describing military
    maneuvers in mind-numbing detail, and so on, rather than talking about anything
    that smacks in any way of overt sexuality? Remember that this is a 15,000-page
    text in which no one ever gets it on; if we’re looking at a sexual fantasy, it
    must be <em>the coyest sexual fantasy ever produced by the human race</em>.</p>'
- - https://www.econstor.eu/bitstream/10419/204468/1/VfS-2019-Kerkhof-YouTube.pdf#page=2
  - ! 'Advertising and Content Differentiation: Evidence from YouTube'
  - Anna Kerkhof
  - 2019-09-04
  - ''
  - ! '<p>Does advertising revenue increase or diminish content differentiation in
    media markets? This paper shows that an increase in the technically feasible number
    of ad breaks per video leads to an increase in content differentiation between
    several thousand YouTube channels. I exploit two institutional features of YouTube''s
    monetization policy to identify the causal effect of advertising on the YouTubers''
    content choice. The analysis of around one million YouTube videos shows that advertising
    leads to a twenty percentage point reduction in the YouTubers'' probability to
    duplicate popular content, i.e., content in high demand by the audience. I also
    provide evidence of the economic mechanism behind the result: popular content
    is covered by many competing YouTubers; hence, viewers who perceive advertising
    as a nuisance could easily switch to a competitor if a YouTuber increased her
    number of ad-breaks per video. This is less likely, however, when the YouTuber
    differentiates her content from her competitors. [Keywords: advertising, content
    differentiation, economics of digitization, horizontal product differentiation,
    long tail, media diversity, user-generated content, YouTube]</p><p>...The analysis
    of around one million YouTube videos shows that an increase in the feasible number
    of ad breaks per video leads to a twenty percentage point reduction in the YouTubers''
    probability to duplicate popular content. The effect size is considerable: it
    corresponds to around 40% of a standard deviation in the dependent variable and
    to around 50% of its baseline value. The large sample size allows me to conduct
    several sub-group analyses to study effect heterogeneity. I find that the positive
    effect of advertising on content differentiation is driven by the YouTubers who
    have at least 1,000 subscribers,i.e., the YouTubers whose additional ad revenue
    is likely to exceed the costs from adapt-ing their videos'' content. In addition,
    I find heterogeneity along video categories: some categories are more flexible
    in terms of their typical video duration than others, hence, exploiting the ten
    minutes trick is more easy (e.g., a music clip is typically between three and
    five minutes long and cannot be easily extended). A battery of robustness checks
    confirms these results...Moreover, I show that ad revenue does not necessarily
    improve the YouTubers'' video quality. Although the number of views goes up when
    a video has more ad breaks, the relative number of likes decreases...Table 5 shows
    the results. The size of the estimates for δ′′(columns 1 to 3), though statistically
    significant at the 1%-level, is negligible: a one second increase in video duration
    corresponds to a 0.0001 percentage point increase in the fraction of likes. The
    estimates for δ′′′ in columns 4 to 6, though, are relatively large and statistically
    significant at the 1%-level, too. According to these estimates, one further second
    in video duration leads on average to about 1.5 percent more views. These estimates
    may reflect the algorithmic drift discussed in Section 9.2. YouTube wants to keep
    its viewers as long as possible on the platform to show as many ads as possible
    to them. As a result, longer videos get higher rankings and are watched more often.'
- - /docs/rotten.com/library/index.html
  - The Rotten Library archives
  - Rotten.com
  - 2019-1005
  - ''
  - ! '<p>Old Internet users will remember <a href="https://en.wikipedia.org/wiki/Rotten.com">Rotten.com</a>.
    I didn’t much care for the main site, but I enjoyed their writeups in the ‘Rotten
    Library’ section. The website has been offline for years now and shows no sign
    of coming back, so I have put up a mirror of the <a href="https://www.gwern.net/docs/rotten.com/library/index.html">Rotten
    Library</a> (<a href="https://www.gwern.net/docs/rotten.com/library/whatsnew/index.html">What’s
    New</a>).</p><p>You can now enjoy such classic entries as <a href="https://www.gwern.net/docs/rotten.com/library/sex/penis-cakes/index.html">Penis
    Cakes</a>, <a href="https://www.gwern.net/docs/rotten.com/library/crime/drugs/lsd-blotters/index.html">LSD
    blotters</a>, <a href="https://www.gwern.net/docs/rotten.com/library/history/mountain-meadows-massacre/index.html">the
    Mountain Meadows Massacre</a>, <a href="https://www.gwern.net/docs/rotten.com/library/sex/masturbation/kelloggs-cornflakes/index.html">Kellogg
    cornflakes</a>, <a href="https://www.gwern.net/docs/rotten.com/library/hoaxes/kinderhook-plates/index.html">Kinderhook
    plates</a>, <a href="https://www.gwern.net/docs/rotten.com/library/bio/crime/mafia/lucky-luciano/index.html">Lucky
    Luciano</a>, <a href="https://www.gwern.net/docs/rotten.com/library/bio/hackers/kevin-mitnick/index.html">Kevin
    Mitnick</a>, <a href="https://www.gwern.net/docs/rotten.com/library/culture/banned-cartoons/index.html">on
    banned cartoons</a>, &amp; <a href="https://www.gwern.net/docs/rotten.com/library/bio/hackers/steve-wozniak/index.html">Steve
    Wozniak</a>.</p><p>(I used <a href="https://github.com/zscole/rotten.com">zscole’s
    archive</a>, compressed the JPEGs, and rewrote all the absolute links to make
    it work on <code>gwern.net</code>, and fixed a few errors I found along the way—principally
    broken links and links to entries which appear to’ve never been written.)</p><p>Alternate
    mirror: <a href="https://www.rottenlibrary.net/"><code>rottenlibrary.net</code></a>.</p>'
- - https://www.wired.com/2016/04/susie-mckinnon-autobiographical-memory-sdam/
  - ! 'In A Perpetual Present: The Strange Case of the Woman Who Can’t Remember Her
    Past—Or Imagine Her Future'
  - Erika Hayasaki
  - 2016-04-10
  - ''
  - ! '<p>As they regale me with talk of their younger selves and their trips to Jamaica,
    Aruba, Cozumel, and Mazatlán, they present the very picture of well-adjusted adulthood
    on the verge of retirement. Except for one fairly major thing. As we chat, McKinnon
    makes clear that she has no memories of all those cruises. No memories of buying
    the lizard or finding that oilcloth collage. She doesn’t remember any vacation
    she’s ever taken. In fact, she cannot recall a single moment in her marriage to
    Green or before it.</p> <p>For decades, scientists suspected that someone like
    Susie McKinnon might exist. They figured she was probably out there, living an
    ordinary life—hard to tell apart from the next person in line at the grocery store,
    yet fundamentally different from the rest of us. And sure enough, they found her
    (or rather, she found them) in 2006. “I don’t remember being smaller or having
    to reach up for things. I have no impressions of myself as a kid.” McKinnon is
    the first person ever identified with a condition called severely deficient autobiographical
    memory. She knows plenty of facts about her life, but she lacks the ability to
    mentally relive any of it, the way you or I might meander back in our minds and
    evoke a particular afternoon. She has no episodic memories—none of those impressionistic
    recollections that feel a bit like scenes from a movie, always filmed from your
    perspective. To switch metaphors: Think of memory as a favorite book with pages
    that you return to again and again. Now imagine having access only to the index.
    Or the Wikipedia entry.</p> <p>...McKinnon first began to realize that her memory
    was not the same as everyone else’s back in 1977, when a friend from high school,
    who was studying to be a physician’s assistant, asked if she would participate
    in a memory test as part of a school assignment. When her friend asked basic questions
    about her childhood as part of the test, McKinnon would reply, “Why are you asking
    stuff like this? No one remembers that!” She knew that other people claimed to
    have detailed memories, but she always thought they embellished and made stuff
    up—just like she did. McKinnon’s friend was so disturbed by her responses that
    she suggested McKinnon get her memory checked by a professional. McKinnon put
    the exchange aside for almost three decades. Then one day in 2004, she came across
    an article about Endel Tulving, the researcher who had originally characterized
    the difference between episodic and semantic memory.</p>'
- - https://www.reddit.com/r/SDAM/
  - /r/SDAM
  - Reddit
  - 2017-11-10
  - ''
  - SDAM (Severely Deficient Autobiographical Memory) is a relatively new discovery
    of the inability of a person to recall events in the past. It is not memory loss,
    Alzheimer's, or dementia. It is associated with the inability to vividly recall
    experiences, such as not having many, if any at all, childhood memories. Another
    example would be not remembering many details about your wedding day. SDAM seems
    to be related somewhat with Aphantasia (the inability to vividly picture things
    in your mind). Both, though, seem to exist on a spectrum. Obviously it does not
    seem to limit normal functioning or learning ability. We are here to find out
    more about it and its impacts.
- - https://www.sciencedirect.com/science/article/pii/S002839321500158X
  - ! 'Severely deficient autobiographical memory (SDAM) in healthy adults: A new
    mnemonic syndrome'
  - Daniela J. Palombo, Claude Alain, Hedvig Söderlund, Wayne Khuu, Brian Levine
  - 2015-06
  - 10.1016/j.neuropsychologia.2015.04.012
  - ! '<p><em>Highlights:</em></p><ul><li>Profoundly impaired autobiographical re-experiencing
    in healthy adults.</li><li>Deficit specific to episodic (especially visual), rather
    than semantic processes.</li><li>Impaired activation of midline structures during
    autobiographical memory retrieval.</li><li>Absence of late positive component
    with intact recognition.</li><li>Performance on everyday mnemonic tasks mediated
    by non-episodic processes.</li></ul><p><em>Abstract</em>: Recollection of previously
    experienced events is a key element of human memory that entails recovery of spatial,
    perceptual, and mental state details. While deficits in this capacity in association
    with brain disease have serious functional consequences, little is known about
    individual differences in autobiographical memory (AM) in healthy individuals.
    Recently, healthy adults with highly superior autobiographical capacities have
    been identified (e.g., <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3764458/"
    title="Behavioral and neuroanatomical investigation of Highly Superior Autobiographical
    Memory (HSAM)">LePort et al 2012</a>. Here we report data from three healthy,
    high functioning adults with the reverse pattern: lifelong severely deficient
    autobiographical memory (SDAM) with otherwise preserved cognitive function. Their
    self-reported selective inability to vividly recollect personally experienced
    events from a first-person perspective was corroborated by absence of functional
    magnetic resonance imaging (fMRI) and event-related potential (ERP) biomarkers
    associated with naturalistic and laboratory episodic recollection, as well as
    by behavioral evidence of impaired episodic retrieval, particularly for visual
    information. Yet learning and memory were otherwise intact, as long as these tasks
    could be accomplished by non-episodic processes. Thus these individuals function
    normally in day-to-day life, even though their past is experienced in the absence
    of recollection. [Keywords: Episodic memory, Autobiographical memory, Hippocampus,
    Case study.]</p>'
- - https://osf.io/qr4f9/download?format=pdf
  - Individual differences in autobiographical memory
  - Daniela J. Palombo, Signy Sheldon, Brian Levine
  - 2018-07
  - 10.1016/j.tics.2018.04.007
  - ! '<p><em>Highlights</em>:</p><ul><li>The syndromes of highly superior autobiographical
    memory (HSAM) and severely deficient autobiographical memory (SDAM) have come
    under recent investigation. These syndromes pose challenges for theories of memory.</li><li>Research
    on individual differences in autobiographical memory across the spectrum have
    also emerged, complementing prior work involving individual differences in laboratory-based
    episodic memory.</li><li>Additional research that is focused on HSAM and SDAM,
    particularly those involving larger sample sizes, will provide a novel platform
    for understanding the cognitive and neural factors that are associated with the
    formation and retention of autobiographical memories.</li></ul><p>Although humans
    have a remarkable capacity to recall a wealth of detail from the past, there are
    marked interindividual differences in the quantity and quality of our mnemonic
    experiences. Such differences in autobiographical memory may appear self-evident,
    yet there has been little research on this topic. In this review, we synthesize
    an emerging body of research regarding individual differences in autobiographical
    memory. We focus on two syndromes that fall at the extremes of the ‘remembering’
    dimension: highly superior autobiographical memory (HSAM) and severely deficient
    autobiographical memory (SDAM). We also discuss findings from research on less
    extreme individual differences in autobiographical memory. This avenue of research
    is pivotal for a full description of the behavioral and neural substrates of autobiographical
    memory. [Keywords: Episodic memory, highly superior autobiographical memory, severely
    deficient autobiographical memory]</p>'
- - https://pureapps2.hw.ac.uk/ws/portalfiles/portal/8873489/Lives_without_imagery_1.pdf
  - Lives without imagery—Congenital aphantasia
  - Adam Zeman, Michaela Dewar, Sergio Della Sala
  - '2015'
  - 10.1016/j.cortex.2015.05.019
  - Presents a case report of 65 year old man. He became unable to summon images to
    the mind's eye after coronary angioplasty. Following a popular description of
    their paper, they were contacted by over twenty individuals who recognized themselves
    in the article's account of 'blind imagination', with the important difference
    that their imagery impairment had been lifelong. Here they describe the features
    of their condition, elicited by a questionnaire, and suggest a name—aphantasia—for
    this poorly recognized phenomenon. 21 individuals contacted them because of their
    lifelong reduction of visual imagery. They explored the features of their condition
    with a questionnaire devised for the purpose and the Vividness of Visual Imagery
    Questionnaire (VVIQ). Participants typically became aware of their condition in
    their teens or twenties when, through conversation or reading, they realized that
    most people who 'saw things in the mind's eye', unlike our participants, enjoyed
    a quasi-visual experience.
- - /docs/psychology/2019-wilkins.pdf
  - Reflections on the spoon test
  - Clive Wilkins, Nicola Clayton
  - '2019'
  - 10.1016/j.neuropsychologia.2019.107221
  - ! 'In this paper, we shall use Tulving''s seminal empirical and theoretical research
    including the ‘Spoon Test’ to explore memory and mental time travel and its origins
    and role in planning for the future. We will review the comparative research on
    future planning and episodic foresight in pre-verbal children and non-verbal animals
    to explore how this may be manifest as wordless thoughts. [Keywords: Mental time
    travel, episodic memory, convergent evolution of cognition, corvids, child development,
    subjective experience of thinking.]'
- - https://www.aiga.org/the-mostly-true-story-of-helvetica-and-the-new-york-city-subway
  - The (Mostly) True Story of Helvetica and the New York City Subway
  - Paul Shaw
  - 2008-11-18
  - ''
  - ! '<p>There is a commonly held belief that <a href="https://en.wikipedia.org/wiki/Helvetica">Helvetica</a>
    is <em>the</em> signage typeface of the New York City subway system, a belief
    reinforced by <a href="https://en.wikipedia.org/wiki/Helvetica_(film)"><em>Helvetica</em></a>,
    Gary Hustwit’s popular 2007 documentary about the typeface. But it is not true—or
    rather, it is only somewhat true. Helvetica is the official typeface of the <a
    href="https://en.wikipedia.org/wiki/Metropolitan_Transportation_Authority">MTA</a>
    today, but it was not the typeface specified by <a href="https://en.wikipedia.org/wiki/Unimark_International">Unimark
    International</a> when it created a new signage system at the end of the 1960s.
    Why was Helvetica not chosen originally? What was chosen in its place? Why is
    Helvetica used now, and when did the changeover occur? To answer those questions
    this essay explores several important histories: of the <a href="https://en.wikipedia.org/wiki/New_York_City_Subway">New
    York City subway system</a>, transportation signage in the 1960s, Unimark International
    and, of course, Helvetica. These four strands are woven together, over nine pages,
    to tell a story that ultimately transcends the simple issue of Helvetica and the
    subway.</p><p>…The sign system that Noorda and <a href="https://en.wikipedia.org/wiki/Massimo_Vignelli">Vignelli</a>
    first proposed to the NYCTA in 1966 has proved remarkably resilient. It endures
    today despite a number of severe changes that make one wonder if it can even be
    attributed to them and Unimark anymore. Their modular system survives but only
    as graphic units rather than physical components. The black stripe, mistakenly
    created by the sign shop but then integrated into the 1970 standards manual, exists
    in a variety of colors and iterations. The black-on-white color scheme is now
    reversed. The colored disks are still used—some with the original artwork—but
    the colors themselves have changed. Finally, Standard Medium has given way to
    Helvetica Medium—or, more accurately, to Neue Helvetica 65. Yet not only is the
    Unimark DNA still in evidence but it has served as the basis for a much broader
    transportation system identity. So, the answer to whether or not Helvetica is
    the typeface of the New York City subway system is that it is—but that it was
    not.</p>'
- - http://discovery.ucl.ac.uk/10080409/8/Bradley_10080409_thesis.pdf
  - On the Resilience of the Dark Net Market Ecosystem to Law Enforcement Intervention
  - Cerys Bradley
  - 2019-08
  - ''
  - <p>Dark Net Markets (DNMs) are websites found on the Dark Net that facilitate
    the anonymous trade of illegal items such as drugs and weapons. Despite repeated
    law enforcement interventions on DNMs, the ecosystem has continued to grow since
    the first DNM, Silk Road, in 2011. This research project investigates the resilience
    of the ecosystem and tries to understand which characteristics allow it to evade
    law enforcement.</p><p>This thesis is comprised of three studies. The first uses
    a dataset contained publicly available, scraped data from 34 DNMs to quantitatively
    measure the impact of a large-scale law enforcement operation, Operation Onymous,
    on the vendor population. This impact is compared to the impact of the closure
    of the DNM Evolution in an exit scam. For both events, the impact on different
    vendor populations (for example those who are directly affected and those who
    aren’t) are compared and the characteristics that make vendors resilient to each
    event are investigated.</p><p>In the second study, a dataset acquired from the
    server of the DNM Silk Road 2.0 [by UK LEA] is used to better understand the relationships
    between buyers and vendors. Network analysis and statistical techniques are used
    to explore when buyers trade and who with. This dataset is also used to measure
    the impact of a hack on Silk Road 2.0 on its population.</p><p>In the final study,
    discussions from the forum site Reddit were used to qualitatively assess user
    perceptions of two law enforcement interventions. These interventions were distinct
    in nature&mdash;one, Operation Hyperion, involved warning users and arresting
    individuals and the second, Operation Bayonet, actively closed a DNM. Grounded
    Theory was used to identify topics of conversation and directly compare the opinions
    held by users on each intervention.</p><p>These studies were used to evaluate
    hypotheses incorporated into two models of resilience. One model focuses on individual
    users and one on the ecosystem as a whole. The models were then used to discuss
    current law enforcement approaches on combating DNMs and how they might be improved.</p>
    <p>In the first study of this thesis, several methodologies for data preparation
    and validation within the study of DNMs were developed. In particular, this work
    presents a new technique for validating a publicly available dataset that has
    been used in multiple studies in this field. This is the first attempt to formally
    validate the dataset and determine what can reasonably used for research. The
    discussion of the dataset has implications for research already using the dataset
    and future research on datasets collected using the same methodology.</p><p>In
    order to conduct the second study in this thesis, a dataset was acquired from
    a law enforcement agency. This dataset gives a new insight on how buyers behave
    on DNMs. Buyers are an unstudied group because their activities are often hidden
    and so analysis of this dataset reveals new insights into the behaviour of these
    users. The results of this study have been used to comment on existing work using
    less complete datasets and contribute new findings.</p><p>The third study in this
    thesis presents a qualitative analysis of two law enforcement interventions. This
    is the first work to assess the impact of either intervention and so provides
    new insights into how they were received by the DNM ecosystem. It uses qualitative
    techniques which are rare within this discipline and so provides a different perspective,
    for example by revealing how individuals perceive the harms of law enforcement
    interventions on DNMs. The value of this work has been recognised through its
    acceptance at a workshop at the IEEE European Symposium on Security and Privacy,
    2019.</p><p>Part of this research has been conducted in consultation with a [UK]
    law enforcement agency who provided data for this research. The results of this
    research are framed specifically for this agency and other law enforcement groups
    currently investigating DNMs. Several suggestions are made on how to improve the
    efficacy of law enforcement interventions on DNMs</p><p>...A response to the criticisms
    of (Dolliver (2015a)) has been presented in (Dolliver (2015b)). Here, Dolliver
    (2015b) attempts to provide further evidence that Silk Road 2.0 overestimated
    the number of listings advertised by including the results of a manual inspection
    of the site (Dolliver (2015b)). The response also calls into question the use
    of the Branwen dataset which was collected by an independent researcher and has
    not been peer-reviewed. Dolliver (2015b) claims that the “manually crawling approach”
    adopted by Van Buskirk et al. (2015) is also problematic as it will miss listings
    that are uploaded and removed during the time it takes to crawl the site. Finally,
    other, unpublished datasets cited in (Dolliver (2015b)) also point to Silk Road
    2.0 being especially volatile in nature before it was closed down and show that
    the number of listings varied by thousands from week to week. This volatility
    could potentially explain the contradicting depictions of Silk Road 2.0 given
    by (Dolliver (2015a)) and (Munksgaard et al. (2016)) and allow for both studies
    to have accurately described the site. However, empirical evidence in the form
    of police reports that describe the size of Silk Road 2.0 after its closure shows
    that the data collected by Dolliver (2015a) is an underestimate. Indeed, new data
    presented in this body of work also demonstrates that Silk Road 2.0 was bigger
    than Dolliver (2015a) claims, even at the beginning of its lifetime.</p>
- - /docs/economics/2018-buterin.pdf
  - ! 'Liberal Radicalism: A Flexible Design For Philanthropic Matching Funds'
  - Vitalik Buterin, Zoë Hitzig, E. Glen Weyl
  - 2018-12-31
  - 10.2139/ssrn.3243656
  - ! 'We propose a design for philanthropic or publicly-funded seeding to allow (near)
    optimal provision of a decentralized, self-organizing ecosystem of public goods.
    The concept extends ideas from <a href="https://www8.gsb.columbia.edu/faculty-research/sites/faculty-research/files/finance/QV_Intro_Final.pdf"
    title="''Quadratic Voting and the Public Good: Introduction'', Posner & Weyl 2017">Quadratic
    Voting</a> to a funding mechanism for endogenous community formation. Citizens
    make public goods contributions to projects of value to them. The amount received
    by the project is (proportional to) the square of the sum of the square roots
    of contributions received. Under the "standard model" this yields first best public
    goods provision. Variations can limit the cost, help protect against collusion
    and aid coordination. We discuss applications to campaign finance, open source
    software ecosystems, news media finance and urban public projects. More broadly,
    we relate our mechanism to political theory, discussing how this solution to the
    public goods problem may furnish neutral and non-authoritarian rules for society
    that nonetheless support collective organization.'
- - https://www.fordfoundation.org/media/2976/roads-and-bridges-the-unseen-labor-behind-our-digital-infrastructure.pdf
  - ! 'Roads and Bridges: The Unseen Labor Behind Our Digital Infrastructure'
  - Nadia Eghbal
  - 2016-06-08
  - ''
  - ! '<p>[Post-<a href="https://en.wikipedia.org/wiki/Heartbleed">Heartbleed</a>/<a
    href="https://en.wikipedia.org/wiki/Shellshock_(software_bug)">Shellshock</a>
    discussion of the economics of funding open source software: universally used
    &amp; economically invaluable as a public good anyone can &amp; does use, it is
    also essentially completely unfunded, leading to serious problems in long-term
    maintenance &amp; improvement, exemplified by the Heartbleed bug—core cryptographic
    code run by almost every networked device on the planet could not fund more than
    a part-time developer.]</p><p>Our modern society—everything from hospitals to
    stock markets to newspapers to social media—runs on software. But take a closer
    look, and you’ll find that the tools we use to build software are buckling under
    demand…Nearly all software today relies on free, public code (called “open source”
    code), written and maintained by communities of developers and other talent. Much
    like roads or bridges, which anyone can walk or drive on, open source code can
    be used by anyone—from companies to individuals—to build software. This type of
    code makes up the digital infrastructure of our society today. Just like physical
    infrastructure, digital infrastructure needs regular upkeep and maintenance. In
    the United States, over half of government spending on transportation and water
    infrastructure goes just to maintenance.<sup>1</sup> But financial support for
    digital infrastructure is much harder to come by. Currently, any financial support
    usually comes through sponsorships, direct or indirect, from software companies.
    Maintaining open source code used to be more manageable. Following the personal
    computer revolution of the early 1980s, most commercial software was proprietary,
    not shared. Software tools were built and used internally by companies, and their
    products were licensed to customers. Many companies felt that open source code
    was too nascent and unreliable for commercial use. In their view, software was
    meant to be charged for, not given away for free. Today, everybody uses open source
    code, including Fortune 500 companies, government, major software companies and
    startups. Sharing, rather than building proprietary code, turned out to be cheaper,
    easier, and more efficient.</p><p>This increased demand puts additional strain
    on those who maintain this infrastructure, yet because these communities are not
    highly visible, the rest of the world has been slow to notice. Most of us take
    opening a software application for granted, the way we take turning on the lights
    for granted. We don’t think about the human capital necessary to make that happen.
    In the face of unprecedented demand, the costs of not supporting our digital infrastructure
    are numerous. On the risk side, there are security breaches and interruptions
    in service, due to infrastructure maintainers not being able to provide adequate
    support. On the opportunity side, we need to maintain and improve these software
    tools in order to support today’s startup renaissance, which relies heavily on
    this infrastructure. Additionally, open source work builds developers’ portfolios
    and helps them get hired, but the talent pool is remarkably less diverse than
    in tech overall. Expanding the pool of contributors can positively affect who
    participates in the tech industry at large.</p><p>No individual company or organization
    is incentivized to address the problem alone, because open source code is a public
    good. In order to support our digital infrastructure, we must find ways to work
    together. Current examples of efforts to support digital infrastructure include
    the Linux Foundation’s Core Infrastructure Initiative and Mozilla’s Open Source
    Support (MOSS) program, as well as numerous software companies in various capacities.
    Sustaining our digital infrastructure is a new topic for many, and the challenges
    are not well understood. In addition, infrastructure projects are distributed
    across many people and organizations, defying common governance models. Many infrastructure
    projects have no legal entity at all. Any support strategy needs to accept and
    work with the decentralized, community-centric qualities of open source code.
    Increasing awareness of the problem, making it easier for institutions to contribute
    time and money, expanding the pool of open source contributors, and developing
    best practices and policies across infrastructure projects will all go a long
    way in building a healthy and sustainable ecosystem.</p>'
- - https://gitcoin.co/blog/gitcoin-grants-clr-matching/
  - ! 'Gitcoin Grants: CLR Matching—Matching contributions with up to $25,000 in funding,
    in ETH'
  - Vivek Singh
  - 2019-02-01
  - ''
  - ! '<p>Gitcoin is excited to announce our first formal experiment with CLR, with
    $25,000 in matching contributions from Gitcoin’s CLR Fund. Our sponsors for this
    fund include the Ethereum Foundation and ConsenSys, via their respective grants
    programs, and unnamed donors in the Ethereum ecosystem.</p><p>As outlined in <a
    href="https://gitcoin.co/blog/experiments-with-liberal-radicalism/" title="Experiments
    With Liberal Radicalism: A crowdfund matching mechanism for public goods, like
    open source">our recent post</a>, the CLR mechanism is a concrete proposal for
    turning your small donations into something much larger. It requires a simple
    formula to achieve this goal.</p><ol type="1"><li><strong>Crowdfund</strong> individual
    donations towards open source projects.</li><li>A <strong>match</strong> from
    governments, grant programs, or private philanthropists</li></ol><p>We are providing
    the $25,000 match…EDIT 2019/02/23: Results announced <a href="https://gitcoin.co/blog/radical-results-gitcoins-25k-match/"
    title="Radical Results: Gitcoin&#39;s $25K Match—Results and lessons learned from
    our first $25K in matching"><em>here</em></a>.</p>'
- - https://gitcoin.co/blog/experiments-with-liberal-radicalism/
  - ! 'Experiments With Liberal Radicalism: A crowdfund matching mechanism for public
    goods, like open source'
  - Vivek Singh
  - 2019-01-16
  - ''
  - ! '<p>By making an individual donation, you contribute to a public good. This
    funding is guaranteed to be met by matching funding, widening the reach of your
    donation. What you do becomes “law.” By donating with one to one matching, you
    increase the power of any single donation in direct proportion to the size of
    the donation, making people more likely to feel like their money is having an
    impact. This is the premise of “Donate $1, [Company X] will match $1” programs.
    CLR takes this one step further, by emphasizing the importance of unique, individual
    contributors — even if they each only contribute a small amount. In short, while
    matching programs have traditionally chosen ‘equal matching’ by default, CLR tries
    to answer the question: When funding public goods, what is the ‘optimal’ match
    to maximize individual donations?</p><p>There’s a great amount of experimentation
    in sustaining open source (the Lemonade Stand by Nadia Eghbal is a seminal resource,
    for those interested). Yet, naturally, it’s hard to solve the problem from the
    ground up. Public goods are simply <em>hard</em> to fund. If we <em>could</em>
    find ‘ground up’ solutions, we can shift our open source conversations from ‘sustaining
    open source’ (all we can ask for, today) to ‘growing open source’ to promote a
    thriving, healthy internet infrastructure. The CLR mechanism is a concrete proposal
    for making grassroots donations something much larger. It requires a simple formula
    to achieve this goal.</p><ol type="1"><li>Crowdfund individual donations towards
    open source projects.</li><li>‘Match’ or ‘top-off’ the contributions of individuals
    from government, grant, or private philanthropy funding</li></ol><p>This is something
    we’re obviously interested in at Gitcoin. It just so happens we’ve launched a
    crowdfunding platform aiming contributions towards open source projects with Gitcoin
    Grants. The timing to explore CLR couldn’t be better.</p><p>…Gitcoin Grants, given
    Sybil / resistance via our Github integration, may be one of the best suited parties
    to help implement <a href="https://www.gwern.net/docs/economics/2018-buterin.pdf">"Liberal
    Radicalism"</a> ideas in a real and constructive way, within open source communities.
    These experiments fit quite well with what we’re doing both at Gitcoin Labs and
    Gitcoin Grants. We plan to carry on with CLR experiments. Please feel join our
    public Discourse around the topic and share with anyone who you think might be
    interested in contributing to the discussion. We don’t expect Liberal Radicalism
    to be a panacea, but are excited to engage in conversation and experimentation
    along the way. We look forward to continued conversation with the RadicalxChange
    community as we continue our research into structural support for a more resilient,
    open internet.</p>'
- - https://gitcoin.co/blog/radical-results-gitcoins-25k-match/
  - ! 'Radical Results: Gitcoin’s $25K Match—Results and lessons learned from our
    first $25K in matching'
  - Vivek Singh
  - 2019-02-22
  - ''
  - <p>A few weeks ago, we announced a radical experiment in Open Source Funding.
    Using the matching method outlined in <a href="https://www.gwern.net/docs/economics/2018-buterin.pdf">“Liberal
    Radicalism”</a>—a paper by Glen Weyl, Vitalik Buterin, and Zoë Hitzig—we announced
    a $25K fund to match any contributions made to 25 Ethereum infrastructure projects.</p><p>Gitcoin’s
    CLR Matching, By The Numbers</p><ul><li>The top three projects in matching funding
    for this round were <em>Prysmatic Labs</em>, <em>Moloch DAO</em>, and <em>Uniswap</em></li><li><em>$13,242</em>
    was contributed by <em>132 unique</em> contributors across <em>26 projects</em></li><li>The
    <em>top 10</em> projects all received over <em>$1,000</em> in matching donations
    from the CLR fund</li><li>A total of <em>$38,242</em> was contributed to Ethereum
    OSS infrastructure in two weeks</li></ul><p>…We are encouraged by the results
    made in the first round of CLR matching and are hopeful for the emergence of new
    mechanisms to enable funding to public goods. We’ll explore a few of these in
    future rounds, and are especially interested in inflation funding mechanisms to
    fund public infrastructure.</p>
- - https://www.reddit.com/r/gwern/comments/deqvft/how_often_do_researchers_not_read_the_papers_they/
  - How often do researchers not read the papers they cite?
  - Gwern Branwen
  - 2019-10-07
  - ''
  - ! 'How often do authors not read their cites? This might seem near-impossible
    to answer, but bibliographic analysis offers a cute trick. In olden times, citations
    and bibliographies had to be compiled by hand; this is an error-prone process,
    but one may make a different error from another author citing the same paper,
    and one might correct any error on reading the original. On the other hand, if
    you cite a paper because you blindly copied the citation from another paper and
    never get around to reading it, you may introduce additional errors but you definitely
    won''t fix any error in what you copied. So one can get an idea of how frequent
    non-reads are by <em>tracing lineages of bibliographic errors</em>: the more people
    copy around the same wrong version of a citation (out of the total set of citations
    for that cite), the fewer of them must be actually reading it. Such copied errors
    turn out to be quite common and represent a large fraction of citations, and thus
    suggests that many paper are being cited without being read. Simkin & Roychowdhury
    venture a guess that as many as 80% of authors citing a paper have not actually
    read the original. [Bibliography of papers in the area.]'
- - https://numinous.productions/ttft/
  - How Can We Develop Transformative Tools For Thought?
  - <a href="https://andymatuschak.org/">Andy Matuschak</a>, <a href="http://michaelnielsen.org/">Michael
    Nielsen</a>
  - 2019-10
  - ''
  - ! '<p>[Long writeup on experiment in integrating <a href="https://www.gwern.net/Spaced-repetition">spaced
    repetition systems</a> with a tutorial on quantum computing, <a href="https://quantum.country/qcvc"
    title="Presented in a new mnemonic medium which makes it almost effortless to
    remember what you read."><em>Quantum Country: Quantum Computing For The Very Curious</em></a>
    By combining explanation with spaced testing, a notoriously thorny subject may
    be learned more easily and then actually remembered—such a system demonstrating
    a possible ‘tool for thought’. Early results indicate users do indeed remember
    the quiz answers, and feedback has been positive.]</p><p><strong>Part I: Memory
    systems</strong></p><ul><li>Introducing the mnemonic medium</li><li>The early
    impact of the prototype mnemonic medium</li><li>Expanding the scope of memory
    systems: what types of understanding can they be used for?</li><li>Improving the
    mnemonic medium: making better cards</li><li>Two cheers for mnemonic techniques</li><li>How
    important is memory, anyway?</li><li>How to invent Hindu-Arabic numerals?</li></ul><p><strong>Part
    II: Exploring tools for thought more broadly</strong>:</p><ul><li><p>Mnemonic
    video</p></li><li><p>Why isn’t there more work on tools for thought today?</p></li><li><p>Questioning
    our basic premises</p><ul><li>What if the best tools for thought have already
    been discovered?</li><li>Isn’t this what the tech industry does? Isn’t there a
    lot of ongoing progress on tools for thought?</li><li>Why not work on AGI or BCI
    instead?</li></ul></li><li><p>Executable books</p><ul><li>Serious work and the
    aspiration to canonical content</li><li>Stronger emotional connection through
    an inverted writing structure</li></ul></li></ul><p><strong>Summary and Conclusion</strong></p><p>…
    in <em>Quantum Country</em> an expert writes the cards, an expert who is skilled
    not only in the subject matter of the essay, but also in strategies which can
    be used to encode abstract, conceptual knowledge. And so <em>Quantum Country</em>
    provides a much more scalable approach to using memory systems to do abstract,
    conceptual learning. In some sense, <em>Quantum Country</em> aims to expand the
    range of subjects users can comprehend at all. In that, it has very different
    aspirations to all prior memory systems.</p><p>More generally, we believe memory
    systems are a far richer space than has previously been realized. Existing memory
    systems barely scratch the surface of what is possible. We’ve taken to thinking
    of <em>Quantum Country</em> as a <em>memory laboratory</em>. That is, it’s a system
    which can be used both to better understand how memory works, and also to develop
    new kinds of memory system. We’d like to answer questions such as:</p><ul><li>What
    are new ways memory systems can be applied, beyond the simple, declarative knowledge
    of past systems?</li><li>How deep can the understanding developed through a memory
    system be? What patterns will help users deepen their understanding as much as
    possible?</li><li>How far can we raise the human capacity for memory? And with
    how much ease? What are the benefits and drawbacks?</li><li>Might it be that one
    day most human beings will have a regular <em>memory practice</em>, as part of
    their everyday lives? Can we make it so memory becomes a choice; is it possible
    to in some sense solve the problem of memory?</li></ul>'
- - https://github.com/lllyasviel/style2paints
  - Style2Paints GitHub repository
  - Lvmin Zhang, Chengze Li, Tien-Tsin Wong, Yi Ji, Chunping Liu
  - 2018-05-04
  - ''
  - <p>Github repo with screenshot samples of <em>style2paints</em>, a neural network
    for colorizing anime-style illustrations (trained on Danbooru2018), with or without
    user color hints, which was available as an online service in 2018. style2paints
    produces high-quality colorizations often on par with human colorizations. Many
    examples can be seen on <a href="https://twitter.com/iliiliiillillii">Twitter</a>
    or the Github repo:</p><figure><img src="https://raw.githubusercontent.com/lllyasviel/style2paints/master/temps/show/8.jpg"
    alt="Example style2paints colorization of a character from Prison School" /><figcaption>Example
    style2paints colorization of a character from <em>Prison School</em></figcaption></figure><p>style2paints
    has been described in more detail in <a href="https://pdfs.semanticscholar.org/7258/dbfce9eaa7d6397193839b07d606b505814e.pdf">“Two-Stage
    Sketch Colorization”</a>, Zhang et al 2018:</p><blockquote><p>Sketch or line art
    colorization is a research field with significant market demand. Different from
    photo colorization which strongly relies on texture information, sketch colorization
    is more challenging as sketches may not have texture. Even worse, color, texture,
    and gradient have to be generated from the abstract sketch lines. In this paper,
    we propose a semi-automatic learning-based framework to colorize sketches with
    proper color, texture as well as gradient. Our framework consists of two stages.
    In the first drafting stage, our model guesses color regions and splashes a rich
    variety of colors over the sketch to obtain a color draft. In the second refinement
    stage, it detects the unnatural colors and artifacts, and try to fix and refine
    the result.Comparing to existing approaches, this two-stage design effectively
    divides the complex colorization task into two simpler and goal-clearer subtasks.This
    eases the learning and raises the quality of colorization. Our model resolves
    the artifacts such as water-color blurring, color distortion, and dull textures.</p><p>We
    build an interactive software based on our model for evaluation. Users can iteratively
    edit and refine the colorization. We evaluate our learning model and the interactive
    system through an extensive user study. Statistics shows that our method outperforms
    the state-of-art techniques and industrial applications in several aspects including,
    the visual quality, the ability of user control, user experience, and other metric</p></blockquote>
- - https://d4mucfpksywv.cloudfront.net/papers/solving-rubiks-cube.pdf#openai
  - Solving Rubik's Cube With A Robot Hand
  - OpenAI et al 2019 [Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin,
    Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael
    Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng,
    Qiming Yuan, Wojciech Zaremba, Lei Zhang]
  - 2019-10-15
  - ''
  - ! 'We demonstrate that models trained only in simulation can be used to solve
    a manipulation problem of unprecedented complexity on a real robot. This is made
    possible by two key components: a novel algorithm, which we call *automatic domain
    randomization* (ADR) and a robot platform built for machine learning. ADR automatically
    generates a distribution over randomized environments of ever-increasing difficulty.
    Control policies and vision state estimators trained with ADR exhibit vastly improved
    sim2real transfer. For control policies, memory-augmented models trained on an
    ADR-generated distribution of environments show clear signs of emergent meta-learning
    at test time. The combination of ADR with our custom robot platform allows us
    to solve a Rubik’s cube with a humanoid robot hand, which involves both control
    and state estimation problems. <a href="https://openai.com/blog/solving-rubiks-cube/">Videos
    summarizing our results are available</a>.'
- - https://openai.com/blog/solving-rubiks-cube/
  - Solving Rubik's Cube with a Robot Hand
  - OpenAI et al 2019
  - 2019-10-15
  - ''
  - <p>[On <a title="Solving Rubik's Cube with a Robot Hand" href="https://d4mucfpksywv.cloudfront.net/papers/solving-rubiks-cube.pdf#openai">Akkaya
    et al 2019</a>.]</p> <p>We’ve trained a pair of neural networks to solve the Rubik’s
    Cube with a human-like robot hand. The neural networks are trained entirely in
    simulation, using the same reinforcement learning code as OpenAI Five paired with
    a new technique called Automatic Domain Randomization (ADR). The system can handle
    situations it never saw during training, such as being prodded by a stuffed giraffe.
    This shows that reinforcement learning isn’t just a tool for virtual tasks, but
    can solve physical-world problems requiring unprecedented dexterity.</p> <p>...Since
    May 2017, we’ve been trying to train a human-like robotic hand to solve the Rubik’s
    Cube. We set this goal because we believe that successfully training such a robotic
    hand to do complex manipulation tasks lays the foundation for general-purpose
    robots. We solved the Rubik’s Cube in simulation in July 2017. But as of July
    2018, we could only manipulate a block on the robot. Now, we’ve reached our initial
    goal. Solving a Rubik’s Cube one-handed is a challenging task even for humans,
    and it takes children several years to gain the dexterity required to master it.
    Our robot still hasn’t perfected its technique though, as it solves the Rubik’s
    Cube 60% of the time (and only 20% of the time for a maximally difficult scramble).</p>
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.8670&rep=rep1&type=pdf
  - Chess Masters' Hypothesis Testing
  - Michelle Cowley, Ruth M. J. Byrne
  - '2004'
  - ''
  - Falsification may demarcate science from non-science as the rational way to test
    the truth of hypotheses. But experimental evidence from studies of reasoning shows
    that people often find falsification difficult. We suggest that domain expertise
    may facilitate falsification. We consider new experimental data about chess experts’
    hypothesis testing. The results show that chess masters were readily able to falsify
    their plans. They generated move sequences that falsified their plans more readily
    than novice players, who tended to confirm their plans. The finding that experts
    in a domain are more likely to falsify their hypotheses has important implications
    for the debate about human rationality.
- - http://r.cs.purdue.edu/pub/ecoop12.pdf
  - ! 'Evaluating the Design of the R Language: Objects and Functions for Data Analysis'
  - Floreal Morandat, Brandon Hill, Leo Osvald, Jan Vitek
  - 2012-06-11
  - 10.1007/978-3-642-31057-7_6
  - ! '<p>[Parsing CRAN to see what in the strange set of R features are actually
    used in the real world—not <a href="https://en.wikipedia.org/wiki/Lazy_evaluation">laziness</a>
    or its weirdo context-dependent <a href="https://en.wikipedia.org/wiki/Scope_(computer_science)">scoping</a>,
    turns out.]</p><p>R is a dynamic language for statistical computing that combines
    lazy functional features and object-oriented programming. This rather unlikely
    linguistic cocktail would probably never have been prepared by computer scientists,
    yet the language has become surprisingly popular. With millions of lines of R
    code available in repositories, we have an opportunity to evaluate the fundamental
    choices underlying the R language design. Using a combination of static and dynamic
    program analysis we assess the success of different language features.</p><ul><li>…<em>Corpus
    Gathering</em>: We curated a large corpus of R programs composed of over 1000
    executable R packages from the Bioconductor and CRAN repositories, as well as
    hand picked end-user codes and small performance benchmark programs that we wrote
    ourselves.</li><li><em>Implementation Evaluation</em>: We evaluate the status
    of the R implementation. While its speed is not acceptable for use in production
    systems, many end users report being vastly more productive in R than in other
    languages. R is decidedly single-threaded, its semantics has no provisions for
    concurrency, and its implementation is hopelessly non-thread safe. Memory usage
    is also an issue; even small programs have been shown to use immoderate amounts
    of heap for data and meta-data. Improving speed and memory usage will require
    radical changes to the implementation, and a tightening of the language definition.</li><li><em>Language
    Evaluation</em>: We examine the usage and adoption of different language features.
    R permits many programming styles, access to implementation details, and little
    enforcement of data encapsulation. Given the large corpus at hand, we look at
    the usage impacts of these design decisions.</li></ul><p>…Given the nature of
    R, many numerical functions are written in C or Fortran; one could thus expect
    execution time to be dominated by native libraries. The time spent in calls to
    foreign functions, on average 22%, shows that this is clearly not the case.</p><p>…As
    a language, R is like French; it has an elegant core, but every rule comes with
    a set of ad-hoc exceptions that directly contradict it.</p>'
- - https://fontsinuse.com/uses/28760/neon-genesis-evangelion
  - ! '<em>Neon Genesis Evangelion</em>: Graphic designer Peiran Tan plumbs the typographic
    psyche of the celebrated anime franchise'
  - Peiran Tan
  - 2019-10-17
  - ''
  - ! '<p>[A look into the signature typefaces of <em>Evangelion</em>: Matisse EB,
    mechanical compression for distorted resizing, and <a href="https://en.wikipedia.org/wiki/Intertitle">title
    cards</a>. Covered typefaces: Matisse/Helvetica/Neue Helvetica/Times/Helvetica
    Condensed/Chicago/Cataneo/Futura/Eurostile/ITC Avant Garde Gothic/Gill Sans.]</p>
    <p><em>Evangelion</em> was among the first anime to create a consistent typographic
    identity across its visual universe, from title cards to NERV’s user interfaces.
    Subcontractors usually painted anything type-related in an anime by hand, so it
    was a novel idea at the time for a director to use desktop typesetting to exert
    typographic control. Although sci-fi anime tended to use either sans serifs or
    hand lettering that mimicked sans serifs in 1995, Anno decided to buck that trend,
    choosing a display serif for stronger visual impact. After flipping through iFontworks’
    specimen catalog, he personally selected the extra-bold (EB) weight of <strong>Matisse</strong>
    (マティス), a Mincho-style serif family… A combination of haste and inexperience gave
    Matisse a plain look and feel, which turned out to make sense for <em>Evangelion</em>.
    The conservative skeletal construction restrained the characters’ personality
    so it wouldn’t compete with the animation; the extreme stroke contrast delivered
    the desired visual punch. Despite the fact that Matisse was drawn on the computer,
    many of its stroke corners were rounded, giving it a hand-drawn, <em>fin-de-siècle</em>
    quality.</p><p>…In addition to a thorough graphic identity, <em>Evangelion</em>
    also pioneered a deep integration of typography as a part of animated storytelling—a
    technique soon to be imitated by later anime. Prime examples are the show’s title
    cards and flashing type-only frames mixed in with the animation. The title cards
    contain nothing but crude, black-and-white Matisse EB, and are often mechanically
    compressed to fit into interlocking compositions. This brutal treatment started
    as a hidden homage to the title cards in old Toho movies from the sixties and
    seventies, but soon became visually synonymous with <em>Evangelion</em> after
    the show first aired. Innovating on the media of animated storytelling, <em>Evangelion</em>
    also integrates type-only flashes. Back then, these black-and-white, split-second
    frames were Anno’s attempt at imprinting subliminal messages onto the viewer,
    but have since become Easter eggs for die-hard <em>Evangelion</em> fans as well
    as motion signatures for the entire franchise.</p><p>…Established in title cards,
    this combination of Matisse EB and all-caps Helvetica soon bled into various aspects
    of <em>Evangelion</em>, most notably the HUD user interfaces in NERV. Although
    it would be possible to attribute the mechanical compression to technical limitations
    or typographic ignorance, its ubiquitous occurrence did evoke haste and, at times,
    despair—an emotional motif perfectly suited to a post-apocalyptic story with existentialist
    themes.</p>'
- - http://klenow.com/Jones_Klenow.pdf
  - Beyond GDP? Welfare across Countries and Time
  - Charles I. Jones, Peter J. Klenow
  - '2016'
  - 10.1257/aer.20110236
  - ! '<p>We propose a summary statistic for the economic well-being of people in
    a country. Our measure incorporates consumption, leisure, mortality, and inequality,
    first for a narrow set of countries using detailed micro data, and then more broadly
    using multi-country datasets. While welfare is highly correlated with GDP per
    capita, deviations are often large. Western Europe looks considerably closer to
    the United States, emerging Asia has not caught up as much, and many developing
    countries are further behind. Each component we introduce plays a significant
    role in accounting for these differences, with mortality being most important.</p><p><strong>KEY
    POINT</strong> 1: <em>GDP per person is an excellent indicator of welfare across
    the broad range of countries: the two measures have a correlation of 0.98. Nevertheless,for
    any given country, the difference between the two measures can be important. Across
    13 countries, the median deviation is about 35%.</em></p><p>Figure 5 illustrates
    this first point. The top panel plots the welfare measure, λ, against GDP per
    person. What emerges prominently is that the two measures are highly correlated,
    with a correlation coefficient (for the logs) of 0.98. Thus per capita GDP is
    a good proxy for welfare under our assumptions. At the same time, there are clear
    departures from the 45° line. In particular, many countries with very low GDP
    per capita exhibit even lower welfare. As a result, welfare is more dispersed
    (standard deviation of 1.51 in logs) than is income (standard deviation of 1.27
    in logs).</p><p>The bottom panel provides a closer look at the deviations. This
    figure plots the ratio of welfare to per capita GDP across countries. The European
    countries have welfare measures 22% higher than their incomes. The remaining countries,
    in contrast, have welfare levels that are typically 25–50% below their incomes.
    The way to reconcile these large deviations with the high correlation between
    welfare and income is that the “scales” are so different. Incomes vary by more
    than a factor of 64 in our sample, i.e., 6,300%, whereas the deviations are on
    the order of 25–50%.</p>'
- - https://alexandercoppock.com/papers/CHV_ads.pdf
  - ! 'Persuasive Effects of Presidential Campaign Advertising: Results of 53 Real-time
    Experiments in 2016'
  - Alexander Coppock, Seth J. Hill, Lynn Vavreck
  - 2019-08-23
  - ''
  - <p>In this letter, we report the results of 53 randomized advertising experiments
    conducted over 29 weeks on 34,000 people during the US 2016 Presidential election.
    Our treatments were drawn in real time from advertisements on air each week. The
    ads vary on many dimensions:election type (primary or general), tone (attack or
    promotional), sponsor (candidates or SuperPACS), context (timing), and content
    (topics). We manipulate which ads respondents see, when they see them, whether
    they see more than one ad, which ad they see first, and whether they see competing,
    reinforcing, or no additional information. Owing to the large size of our study,
    the meta-analytic estimates of the average treatment effects on favorability and
    vote choice are sometimes distinguishable from zero, but are always quite modest,
    even accounting for variation across advertisements and contexts…We conducted
    53 survey experiments over 29 weeks on nationally representative samples totaling
    34,000 people over 8 months of 2016 campaign.</p><p>…We conducted 53 survey experiments
    over 29 weeks on nationally-representative samples totaling 34,000 people over
    8 months of 2016 campaign. The ads we test are actual presidential advertisements
    resulting from strategies of presidential candidates trying to win the highest
    office in the land over the entire campaign. In this sense, our treatments—both
    content and timing—are determined by the equilibrium strategies of people who
    are highly motivated to persuade voters and win campaigns. This unique design
    (a) tests the ads that the best in the business thought would be effective and
    (b) maximizes external validity because these were the actual ads seen by voters
    delivered contemporaneously by the campaign.</p><p>Week after week, ad after ad,
    our experiments return modest effects. The estimated effects are <em>consistently</em>
    modest across many variations in tone, content, sponsor, election type, context,
    information environments, and characteristics of people. On some outcomes (respondents’
    positions on the issues in the ads, the importance of the topics in the ads) we
    find effects that are so small they are essentially non-existent even though we
    can estimate them very precisely. On candidate favorability and vote choice, we
    find slightly larger effects that we can sometimes isolate from zero, but that
    look remarkably similar in magnitude across candidates and features of ads.</p>
- - /Statistical-notes#program-for-non-spaced-repetition-review-of-past-written-materials-for-serendipity-rediscovery-archive-revisiter
  - ! 'Anti-Spaced Repetition: A Program For Non-Spaced-Repetition Review Of Past
    Written Materials For Serendipity & Rediscovery In Personal Archives'
  - Gwern Branwen
  - 2017-03-25
  - ''
  - ! '<p><a href="https://www.gwern.net/Spaced-repetition"><q>“Spaced repetition”</q></a>
    helps one remember facts by creating discrete flashcards which one tests oneself
    on at increasingly distant ‘spaced’ time periods, repeating the fact just before
    one probably would have forgotten it; using software to track &amp; automate tests
    &amp; review scheduling, spaced repetition can scale to hundreds of thousands
    of discrete items.</p><p>If spacing out facts can help one remember by repeating
    items just <em>before</em> they are forgotten, is there any use for an <q>“anti-spaced
    repetition”</q> with the opposite method of repeating items only <em>after</em>
    they are probably forgotten?</p><p>I can think of two: first, it could be used
    to plan <a href="https://www.gwern.net/Media-RL">consumption of media such as
    movies</a> by eg tracking one’s favorite movies of all time and scheduling a rewatch
    whenever one is predicted to have forgotten enough to make them novel &amp; highly
    enjoyable again. Second, and more interestingly, it could be used as a <em>serendipity
    generator</em> by allowing efficient processing of notes or excerpts or old writings.</p><p>In
    rereading such materials many years later, one often gains a new perspective or
    learns something useful because one forgot something: one didn’t understand something
    about it at the time, or new material has radically changed one’s interpretation,
    and since it’d been forgotten, no use could be made of it. Unfortunately, using
    spaced repetition to memorize such material, while ensuring any serendipitous
    connections get made as soon as possible, would be radically infeasible for bulky
    items (a single lengthy text excerpt might correspond to hundreds of discrete
    items, quickly overloading even SRS systems) and for almost all items, useless.
    One can justify rereading old material once or perhaps twice, but not many rereads
    nor full memorization. But rereading haphazardly is likely to inefficiently cover
    some material many times while neglecting others, and such rereads will often
    be far too early in time (or—a lesser concern here—too late).</p><p>Instead of
    spaced repetition, one would instead use <em>anti-spaced repetition</em>: each
    item would be tracked and reviewed and its expected forgetting time predicted,
    as in spaced repetition, but instead of scheduling a review <em>before</em> forgetting,
    a review is scheduled for some time (probably long afterwards) <em>after</em>
    forgetting. The total number of reviews of each item per user lifetime would be
    set to a small number, perhaps 1–4, bounding the time consumption at a feasible
    amount.</p><p>Such an anti-spaced repetition system could be used with hundreds
    of thousands of notes or clippings which a person might accumulate over a lifetime,
    and enable them to invest a few minutes a day into reading old notes, occasionally
    coming up with new insights, while ensuring they don’t waste time reading notes
    too many times or reading notes they likely already remember &amp; have exhausted.</p>'
- - https://pdos.csail.mit.edu/6.828/2008/readings/engler95exokernel.pdf
  - ! 'Exokernel: An Operating System Architecture for Application-Level Resource
    Management'
  - Dawson R. Engler, M. Frans Kaashoek, James O’Toole Jr.
  - 1995-12-03
  - 10.1145/224057.224076
  - <p>Traditional operating systems limit the performance, flexibility, and functionality
    of applications by fixing the interface and implementation of operating system
    abstractions such as interprocess communication and virtual memory. The <em>exokernel</em>
    operating system architecture addresses this problem by providing application-level
    management of physical resources. In the exokernel architecture, a small kernel
    securely exports all hardware resources through a low-level interface to untrusted
    library operating systems. Library operating systems use this interface to implement
    system objects and policies. This separation of resource protection from management
    allows application-specific customization of traditional operating system abstractions
    by extending, specializing, or even replacing libraries.</p><p>We have implemented
    a prototype exokernel operating system. Measurements show that most primitive
    kernel operations (such as exception handling and protected control transfer)
    are 10 to 100 times faster than in Ultrix, a mature monolithic UNIX operating
    system. In addition, we demonstrate that an exokernel allows applications to control
    machine resources in ways not possible in traditional operating systems. For instance,
    virtual memory and interprocess communication abstractions are implemented entirely
    within an application-level library. Measurements show that application-level
    virtual memory and interprocess communication primitives are 5 to 40 times faster
    than Ultrix's kernel primitives. Compared to state-of-the-art implementations
    from the literature, the prototype exokernel system is at least 5 times faster
    on operations such as exception dispatching and interprocess communication.</p>
- - http://web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf
  - End-To-End Arguments In System Design
  - J.H. Saltzer, D.P. Reed, D.D. Clark
  - '1984'
  - ''
  - This paper presents a design principle that helps guide placement of functions
    among the modules of a distributed computer system. The principle, called 'the
    end-to-end argument', suggests that functions placed at low levels of a system
    may be redundant or of little value when compared with the cost of providing them
    at that low level. Examples discussed in the paper include bit error recovery,
    security using encryption, duplicate message suppression, recovery from system
    crashes, and delivery acknowledgement. Low level mechanisms to support these functions
    are justified only as performance enhancements.
- - /docs/sr/2019-miller.pdf
  - ! 'The War On Drugs 2.0: Darknet Fentanyl''s Rise And The Effects Of Regulatory
    And Law Enforcement Action'
  - Jacob N. Miller
  - 2019-10-08
  - 10.1111/coep.12447
  - U.S. overdose deaths attributed to synthetic opioids, such as fentanyl, have increased
    from under 3,000 in 2013 to nearly 20,000 in 2016, making up half of all opioid-related
    overdose deaths. Using web scrapes of darknet markets from 2014 to 2016, I provide
    historical prices for fentanyl and its most popular analogues and find that fentanyl
    vendors priced fentanyl in 2014 at a 90% discount compared to an equivalent dose
    of heroin. Using regression discontinuity, I evaluate the effects of two major
    law enforcement and regulatory events. I find minimal lasting effects of U.S.
    legal actions intended to disrupt darknet markets, but there are statistically
    significant indications of a price increase corresponding with regulatory action
    in China. Despite these indications of some regulatory success, fentanyl prices
    remained approximately 90% cheaper than heroin.
- - https://www2.psy.uq.edu.au/~uqbziets/Mosing%20et%20al%202015%20Did%20sexual%20selection%20shape%20human%20music.pdf
  - Did sexual selection shape human music? Testing predictions from the sexual selection
    hypothesis of music evolution using a large genetically informative sample of
    over 10,000 twins
  - Miriam A. Mosing, Karin J.H. Verweij, Guy Madison, Nancy L. Pedersen, Brendan
    P. Zietsch, Fredrik Ullén
  - '2015'
  - 10.1016/j.evolhumbehav.2015.02.004
  - Although music is a universal feature of human culture, little is known about
    its origins and functions. A prominent theory of music evolution is the sexual
    selection hypothesis, which proposes that music evolved as a signal of genetic
    quality to potential mates. The sexual selection hypothesis offers several empirically
    testable predictions. First, musically skilled and active individuals should have
    greater mating success than less-skilled individuals. Second, if musical ability
    functions as an indicator of genetic quality, it is expected to be associated
    with other traits putatively related to genetic quality. Third, associations as
    per the first and second predictions are expected to be at least partly due to
    overlapping genetic influences. We tested these predictions in a large genetically
    informative sample of 10,975 Swedish twin individuals aged between 27 and 54 years
    (M = 40.1, SD = 7.7), using musical aptitude and music achievement as measures
    of musical ability. To assess mating success we examined number of sex-partners,
    age of first intercourse, sociosexuality, and number of offspring. General intelligence,
    simple reaction time, and height were used to investigate relationships with traits
    putatively related to genetic quality. Twin modeling showed moderate genetic influences
    on musical aptitude for both sexes (heritability estimates were 38% for males
    and 51% for females). Music achievement was also moderately influenced by genetic
    influences in males (heritability = 57%), but the genetic influences were low
    and nonsignificant for females (heritability = 9%). Contrary to predictions, the
    majority of phenotypic associations between musical ability and music achievement
    with mating success were nonsignificant or significant in the other direction,
    with those with greater musical ability scoring lower on the measures of mating
    success. Genetic correlations between these measures were also nonsignificant.
    Most correlations of musical aptitude and music achievement with genetic quality
    measures were significant, including correlations with general intelligence, simple
    reaction time, and, in females, height (but only for aptitude). However, only
    the correlation between musical aptitude and general intelligence in men was significantly
    driven by overlapping genetic influences. Our findings provide little support
    for a role of sexual selection in the evolution of musical ability. Alternative
    explanations and limitations are discussed.
- - http://ftp.iza.org/dp12687.pdf#page=3)
  - ! 'Be Cautious with the Precautionary Principle: Evidence from Fukushima Daiichi
    Nuclear Accident'
  - Matthew Neidell
  - 2019-10
  - 10.3386/w26395
  - This paper provides a large scale, empirical evaluation of unintended effects
    from invoking the precautionary principle after the Fukushima Daiichi nuclear
    accident. After the accident, all nuclear power stations ceased operation and
    nuclear power was replaced by fossil fuels, causing an exogenous increase in electricity
    prices. This increase led to a reduction in energy consumption, which caused an
    increase in mortality during very cold temperatures. We estimate that the increase
    in mortality from higher electricity prices outnumbers the mortality from the
    accident itself, suggesting the decision to cease nuclear production has contributed
    to more deaths than the accident itself.
- - https://veridici.com/how-airbnb-is-silently-changing-himalayan-villages/
  - How Airbnb Is Silently Changing Himalayan Villages
  - Shanu Athiparambath
  - 2019-10-21
  - ''
  - <p>[Letter from the eastern Himalayas about the social and economic impact of
    Airbnb.]</p> <p>It’s expensive to farm in Himalayan villages like mine. The farms
    are small and cannot leverage economies of scale. Hill people see the process
    of selling land as a humiliating ordeal they would never consider. Everybody chips
    in to cultivate the land. Women spend many hours a day cutting grass for their
    cows. This is not yet a division of labour society. It is this world that Airbnb
    has penetrated, turning it upside down.</p><p>Millions of people stay in Airbnb
    homes every night. It’s not trust which makes this possible. My pup is fearless
    when he sleeps with the door wide open, in a cottage in the woods. There are leopards
    around. Dogs here don’t live very long. He doesn’t trust leopards, but he knows
    they are afraid of humans. My pup sleeps on my bed, and so is well-protected from
    the vicissitudes of life. But I’m not the living proof that dogs can trust leopards.
    Dogs wouldn’t need humans to guard them if they could trust leopards. Similarly,
    Airbnb puts hosts and guests in a position where behaving badly would ruin their
    reputations. In one of my bad moods, I held my pup quite firmly. At midnight,
    he ran out of the cottage and barked for hours. I couldn’t bring him back to my
    bed. I did something he thought I wouldn’t consider. He felt I betrayed his trust
    in me. I’m, here, talking about a more meaningful form of trust. Intellectuals
    miss this obvious distinction, because they’re not the wonderful people they think
    they are. The distinction between trust and assurance is all too obvious. But
    if doing wrong doesn’t fill you with moral horror, you won’t get it. You can’t
    trust anybody who doesn’t feel that way, and there are not many such people. Unconditional
    trustworthiness is one of the rarest things in the world. Institutions can’t produce
    this kind of trust, because people aren’t conditionable beyond a point. In any
    case, how do you produce something you don’t even understand?</p>
- - /Questions#cats-earwax
  - On Cats' Love of Earwax
  - Gwern Branwen
  - 2019-11-05
  - ''
  - While petting cats, I accidentally discovered cats are fascinated by the smell
    & taste of earwax, particularly that of humans, and this interest can last indefinitely.
    Dogs & humans, for comparison, are not. A number of anecdotes have reported this
    over the years, but no formal research appears to have been done on this. What
    makes earwax attractive to cats? Pheromones? Some nutrient?
- - http://ide.mit.edu/sites/default/files/publications/Multi-Sided%20Platform%20Strategy%2C%20Taxation%20and%20Regulation%20October%202019.pdf#page=14
  - ! 'Multi-Sided Platform Strategy, Taxation, and Regulation: A Quantitative Model
    and Application to Facebook'
  - Seth G. Benzell, Avinash Collis
  - 2019-10-12
  - ''
  - Digital platforms, such as Facebook, Uber, and AirBnB, create value by connecting
    users, creators, and contractors of different types. Their rapid growth, untraditional
    business model, and disruptive nature presents challenges for managers and asset
    pricers. These features also, arguably, make them natural monopolies, leading
    to increasing calls for special regulations and taxes. We construct and illustrate
    a approach for modeling digital platforms. The model allows for heterogeneity
    in elasticity of demand and heterogeneous network effects across different users.
    We parameterize our model using a survey of over 40,000 US internet users on their
    demand for Facebook. Facebook creates about 11.2 billion dollars in consumer surplus
    a month for US users age 25 or over, in line with previous estimates. We find
    Facebook has too low a level of advertising relative to their revenue maximizing
    strategy, suggesting that they also value maintaining a large user base. We simulate
    six proposed government policies for digital platforms, taking Facebook’s optimal
    response into account. Taxes only slightly change consumer surplus. Three more
    radical proposals, including ‘data as labor’ and nationalization, have the potential
    to raise consumer surplus by up to 42%. But a botched regulation that left the
    US with two smaller, non-competitive social media monopolies would decrease consumer
    surplus by 44%.
- - http://pawsoflife-org.k9handleracademy.com/Library/Scent/Porter2006.pdf
  - Mechanisms of scent-tracking in humans
  - Jess Porter, Brent Craven, Rehan M Khan, Shao-Ju Chang, Irene Kang, Benjamin Judkewitz,
    Jason Volpe, Gary Settles, Noam Sobel
  - 2006-12-17
  - 10.1038/nn1819
  - Whether mammalian scent-tracking is aided by inter-nostril comparisons is unknown.
    We assessed this in humans and found that (i) humans can scent-track, (ii) they
    improve with practice, (iii) the human nostrils sample spatially distinct regions
    separated by ∼3.5 cm and, critically, (iv) scent-tracking is aided by inter-nostril
    comparisons. These findings reveal fundamental mechanisms of scent-tracking and
    suggest that the poor reputation of human olfaction may reflect, in part, behavioral
    demands rather than ultimate abilities.
- - /docs/economics/2019-hoynes.pdf
  - Universal Basic Income in the United States and Advanced Countries
  - Hilary Hoynes, Jesse Rothstein
  - 2019-08
  - 10.1146/annurev-ec-11
  - ! 'We discuss the potential role of universal basic incomes (UBIs) in advanced
    countries. A feature of advanced economies that distinguishes them from developing
    countries is the existence of well-developed, if often incomplete, safety nets.
    We develop a framework for describing transfer programs that is flexible enough
    to encompass most existing programs as well as UBIs, and we use this framework
    to compare various UBIs to the existing constellation of programs in the United
    States. A UBI would direct much larger shares of transfers to childless, nonelderly,
    nondisabled households than existing programs, and much more to middle-income
    rather than poor households. A UBI large enough to increase transfers to low-income
    families would be enormously expensive. We review the labor supply literature
    for evidence on the likely impacts of a UBI. We argue that the ongoing UBI pilot
    studies will do little to resolve the major outstanding questions. [Keywords:
    safety net, income transfer, universal basic income, labor supply, JEL I38, JEL
    H24]'
- - /docs/sociology/2019-lichter.pdf
  - Mismatches in the Marriage Market
  - Daniel T. Lichter, Joseph P. Price, Jeffrey M. Swigert
  - 2019-09-04
  - 10.1111/jomf.12603
  - ! '<p><em>Objective</em>: This article provides an assessment of whether unmarried
    women currently face demographic shortages of marital partners in the U.S. marriage
    market.</p><p><em>Background</em>: One explanation for the declines in marriage
    is the putative shortage of economically attractive partners for unmarried women
    to marry. Previous studies provide mixed results but are usually focused narrowly
    on sex ratio imbalances rather than identifying shortages on the multiple socioeconomic
    characteristics that typically sort women and men into marriages.</p><p><em>Methods</em>:
    This study identifies recent marriages from the 2008 to 2012 and 2013 to 2017
    cumulative 5-year files of the American Community Survey. Data imputation methods
    provide estimates of the sociodemographic characteristics of unmarried women’s
    potential (or synthetic) spouses who resemble the husbands of otherwise comparable
    married women. These estimates are compared with the actual distribution of unmarried
    men at the national, state, and local area levels to identify marriage market
    imbalances.</p><p><em>Results</em>: These synthetic husbands have an average income
    that is about 58% higher than the actual unmarried men that are currently available
    to unmarried women. They also are 30% more likely to be employed (90% vs. 70%)
    and 19% more likely to have a college degree (30% vs. 25%). Racial and ethnic
    minorities, especially Black women, face serious shortages of potential marital
    partners, as do low socioeconomic status and high socioeconomic status unmarried
    women, both at the national and subnational levels.</p><p><em>Conclusions</em>:
    This study reveals large deficits in the supply of potential male spouses. One
    implication is that the unmarried may remain unmarried or marry less well-suited
    partners.</p>'
- - /docs/sociology/2012-henrich.pdf
  - The puzzle of monogamous marriage
  - Joseph Henrich, Robert Boyd, Peter J. Richerson
  - '2012'
  - 10.1098/rstb.2011.0290
  - ! 'The anthropological record indicates that approximately 85% of human societies
    have permitted men to have more than one wife (polygynous marriage), and both
    empirical and evolutionary considerations suggest that large absolute differences
    in wealth should favour more polygynous marriages. Yet, monogamous marriage has
    spread across Europe, and more recently across the globe, even as absolute wealth
    differences have expanded. Here, we develop and explore the hypothesis that the
    norms and institutions that compose the modern package of monogamous marriage
    have been favoured by cultural evolution because of their group-beneficial effects—promoting
    success in inter-group competition. In suppressing intrasexual competition and
    reducing the size of the pool of unmarried men, normative monogamy reduces crime
    rates, including rape, murder, assault, robbery and fraud, as well as decreasing
    personal abuses. By assuaging the competition for younger brides, normative monogamy
    decreases (i) the spousal age gap, (ii) fertility, and (iii) gender inequality.
    By shifting male efforts from seeking wives to paternal investment, normative
    monogamy increases savings, child investment and economic productivity. By increasing
    the relatedness within households, normative monogamy reduces intra-household
    conflict, leading to lower rates of child neglect, abuse, accidental death and
    homicide. These predictions are tested using converging lines of evidence from
    across the human sciences. [Keywords: cultural group selection; monogamy; polygyny;
    marriage; norms; institutional evolution]'
- - https://www.nature.com/articles/s41467-019-12283-6
  - Associations of autozygosity with a broad range of human phenotypes
  - David W Clark, Yukinori Okada, Kristjan H S Moore, Dan Mason, Nicola Pirastu,
    Ilaria Gandin, Hannele Mattsson, Catriona L K Barnes, Kuang Lin, Jing Hua Zhao,
    Patrick Deelen, Rebecca Rohde, Claudia Schurmann, Xiuqing Guo, Franco Giulianini,
    Weihua Zhang, Carolina Medina-Gomez, Robert Karlsson, Yanchun Bao, Traci M Bartz,
    Clemens Baumbach, Ginevra Biino, Matthew J Bixley, Marco Brumat, Jin-Fang Chai,
    Tanguy Corre, Diana L Cousminer, Annelot M Dekker, David A Eccles, Kristel R van
    Eijk, Christian Fuchsberger, He Gao, Marine Germain, Scott D Gordon, Hugoline
    G de Haan, Sarah E Harris, Edith Hofer, Alicia Huerta-Chagoya, Catherine Igartua,
    Iris E Jansen, Yucheng Jia, Tim Kacprowski, Torgny Karlsson, Marcus E Kleber,
    Shengchao Alfred Li, Ruifang Li-Gao, Anubha Mahajan, Koichi Matsuda, Karina Meidtner,
    Weihua Meng, May E Montasser, Peter J van der Most, Matthias Munz, Teresa Nutile,
    Teemu Palviainen, Gauri Prasad, Rashmi B Prasad, Tallapragada Divya Sri Priyanka,
    Federica Rizzi, Erika Salvi, Bishwa R Sapkota, Daniel Shriner, Line Skotte, Melissa
    C Smart, Albert Vernon Smith, Ashley van der Spek, Cassandra N Spracklen, Rona
    J Strawbridge, Salman M Tajuddin, Stella Trompet, Constance Turman, Niek Verweij,
    Clara Viberti, Lihua Wang, Helen R Warren, Robyn E Wootton, Lisa R Yanek, Jie
    Yao, Noha A Yousri, Wei Zhao, Adebowale A Adeyemo, Saima Afaq, Carlos Alberto
    Aguilar-Salinas, Masato Akiyama, Matthew L Albert, Matthew A Allison, Maris Alver,
    Tin Aung, Fereidoun Azizi, Amy R Bentley, Heiner Boeing, Eric Boerwinkle, Judith
    B Borja, Gert J de Borst, Erwin P Bottinger, Linda Broer, Harry Campbell, Stephen
    Chanock, Miao-Li Chee, Guanjie Chen, Yii-Der I Chen, Zhengming Chen, Yen-Feng
    Chiu, Massimiliano Cocca, Francis S Collins, Maria Pina Concas, Janie Corley,
    Giovanni Cugliari, Rob M van Dam, Anna Damulina, Maryam S Daneshpour, Felix R
    Day, Graciela E Delgado, Klodian Dhana, Alexander S F Doney, Marcus Dörr, Ayo
    P Doumatey, Nduna Dzimiri, S Sunna Ebenesersdóttir, Joshua Elliott, Paul Elliott,
    Ralf Ewert, Janine F Felix, Krista Fischer, Barry I Freedman, Giorgia Girotto,
    Anuj Goel, Martin Gögele, Mark O Goodarzi, Mariaelisa Graff, Einat Granot-Hershkovitz,
    Francine Grodstein, Simonetta Guarrera, Daniel F Gudbjartsson, Kamran Guity, Bjarni
    Gunnarsson, Yu Guo, Saskia P Hagenaars, Christopher A Haiman, Avner Halevy, Tamara
    B Harris, Mehdi Hedayati, David A van Heel, Makoto Hirata, Imo Höfer, Chao Agnes
    Hsiung, Jinyan Huang, Yi-Jen Hung, M Arfan Ikram, Anuradha Jagadeesan, Pekka Jousilahti,
    Yoichiro Kamatani, Masahiro Kanai, Nicola D Kerrison, Thorsten Kessler, Kay-Tee
    Khaw, Chiea Chuen Khor, Dominique P V de Kleijn, Woon-Puay Koh, Ivana Kolcic,
    Peter Kraft, Bernhard K Krämer, Zoltán Kutalik, Johanna Kuusisto, Claudia Langenberg,
    Lenore J Launer, Deborah A Lawlor, I-Te Lee, Wen-Jane Lee, Markus M Lerch, Liming
    Li, Jianjun Liu, Marie Loh, Stephanie J London, Stephanie Loomis, Yingchang Lu,
    Jian’an Luan, Reedik Mägi, Ani W Manichaikul, Paolo Manunta, Gísli Másson, Nana
    Matoba, Xue W Mei, Christa Meisinger, Thomas Meitinger, Massimo Mezzavilla, Lili
    Milani, Iona Y Millwood, Yukihide Momozawa, Amy Moore, Pierre-Emmanuel Morange,
    Hortensia Moreno-Macías, Trevor A Mori, Alanna C Morrison, Taulant Muka, Yoshinori
    Murakami, Alison D Murray, Renée de Mutsert, Josyf C Mychaleckyj, Mike A Nalls,
    Matthias Nauck, Matt J Neville, Ilja M Nolte, Ken K Ong, Lorena Orozco, Sandosh
    Padmanabhan, Gunnar Pálsson, James S Pankow, Cristian Pattaro, Alison Pattie,
    Ozren Polasek, Neil Poulter, Peter P Pramstaller, Lluis Quintana-Murci, Katri
    Räikkönen, Sarju Ralhan, Dabeeru C Rao, Wouter van Rheenen, Stephen S Rich, Paul
    M Ridker, Cornelius A Rietveld, Antonietta Robino, Frank J A van Rooij, Daniela
    Ruggiero, Yasaman Saba, Charumathi Sabanayagam, Maria Sabater-Lleal, Cinzia Felicita
    Sala, Veikko Salomaa, Kevin Sandow, Helena Schmidt, Laura J Scott, William R Scott,
    Bahareh Sedaghati-Khayat, Bengt Sennblad, Jessica van Setten, Peter J Sever, Wayne
    H-H Sheu, Yuan Shi, Smeeta Shrestha, Sharvari Rahul Shukla, Jon K Sigurdsson,
    Timo Tonis Sikka, Jai Rup Singh, Blair H Smith, Alena Stančáková, Alice Stanton,
    John M Starr, Lilja Stefansdottir, Leon Straker, Patrick Sulem, Gardar Sveinbjornsson,
    Morris A Swertz, Adele M Taylor, Kent D Taylor, Natalie Terzikhan, Yih-Chung Tham,
    Gudmar Thorleifsson, Unnur Thorsteinsdottir, Annika Tillander, Russell P Tracy,
    Teresa Tusié-Luna, Ioanna Tzoulaki, Simona Vaccargiu, Jagadish Vangipurapu, Jan
    H Veldink, Veronique Vitart, Uwe Völker, Eero Vuoksimaa, Salma M Wakil, Melanie
    Waldenberger, Gurpreet S Wander, Ya Xing Wang, Nicholas J Wareham, Sarah Wild,
    Chittaranjan S Yajnik, Jian-Min Yuan, Lingyao Zeng, Liang Zhang, Jie Zhou, Najaf
    Amin, Folkert W Asselbergs, Stephan J L Bakker, Diane M Becker, Benjamin Lehne,
    David A Bennett, Leonard H van den Berg, Sonja I Berndt, Dwaipayan Bharadwaj,
    Lawrence F Bielak, Murielle Bochud, Mike Boehnke, Claude Bouchard, Jonathan P
    Bradfield, Jennifer A Brody, Archie Campbell, Shai Carmi, Mark J Caulfield, David
    Cesarini, John C Chambers, Giriraj Ratan Chandak, Ching-Yu Cheng, Marina Ciullo,
    Marilyn Cornelis, Daniele Cusi, George Davey Smith, Ian J Deary, Rajkumar Dorajoo,
    Cornelia M van Duijn, David Ellinghaus, Jeanette Erdmann, Johan G Eriksson, Evangelos
    Evangelou, Michele K Evans, Jessica D Faul, Bjarke Feenstra, Mary Feitosa, Sylvain
    Foisy, Andre Franke, Yechiel Friedlander, Paolo Gasparini, Christian Gieger, Clicerio
    Gonzalez, Philippe Goyette, Struan F A Grant, Lyn R Griffiths, Leif Groop, Vilmundur
    Gudnason, Ulf Gyllensten, Hakon Hakonarson, Anders Hamsten, Pim van der Harst,
    Chew-Kiat Heng, Andrew A Hicks, Hagit Hochner, Heikki Huikuri, Steven C Hunt,
    Vincent W V Jaddoe, Philip L De Jager, Magnus Johannesson, Åsa Johansson, Jost
    B Jonas, J Wouter Jukema, Juhani Junttila, Jaakko Kaprio, Sharon L. R. Kardia,
    Fredrik Karpe, Meena Kumari, Markku Laakso, Sander W van der Laan, Jari Lahti,
    Matthias Laudes, Rodney A Lea, Wolfgang Lieb, Thomas Lumley, Nicholas G Martin,
    Winfried März, Giuseppe Matullo, Mark I McCarthy, Sarah E Medland, Tony R Merriman,
    Andres Metspalu, Brian F Meyer, Karen L Mohlke, Grant W Montgomery, Dennis Mook-Kanamori,
    Patricia B Munroe, Kari E North, Dale R Nyholt, Jeffery R O’connell, Carole Ober,
    Albertine J Oldehinkel, Walter Palmas, Colin Palmer, Gerard G Pasterkamp, Etienne
    Patin, Craig E Pennell, Louis Perusse, Patricia A Peyser, Mario Pirastu, Tinca
    J. C. Polderman, David J Porteous, Danielle Posthuma, Bruce M Psaty, John D Rioux,
    Fernando Rivadeneira, Charles Rotimi, Jerome I Rotter, Igor Rudan, Hester M Den
    Ruijter, Dharambir K Sanghera, Naveed Sattar, Reinhold Schmidt, Matthias B Schulze,
    Heribert Schunkert, Robert A Scott, Alan R Shuldiner, Xueling Sim, Neil Small,
    Jennifer A Smith, Nona Sotoodehnia, E-Shyong Tai, Alexander Teumer, Nicholas J
    Timpson, Daniela Toniolo, David-Alexandre Tregouet, Tiinamaija Tuomi, Peter Vollenweider,
    Carol A Wang, David R Weir, John B Whitfield, Cisca Wijmenga, Tien-Yin Wong, John
    Wright, Jingyun Yang, Lei Yu, Babette S Zemel, Alan B Zonderman, Markus Perola,
    Patrik K. E. Magnusson, André G Uitterlinden, Jaspal S Kooner, Daniel I Chasman,
    Ruth J. F. Loos, Nora Franceschini, Lude Franke, Chris S Haley, Caroline Hayward,
    Robin G Walters, John R. B. Perry, Tōnu Esko, Agnar Helgason, Kari Stefansson,
    Peter K Joshi, Michiaki Kubo, James F Wilson
  - 2019-10-31
  - 10.1038/s41467-019-12283-6
  - ! '<p>In many species, the offspring of related parents suffer reduced reproductive
    success, a phenomenon known as inbreeding depression. In humans, the importance
    of this effect has remained unclear, partly because reproduction between close
    relatives is both rare and frequently associated with confounding social factors.
    Here, using genomic inbreeding coefficients (<em>F<sub>ROH</sub></em>) for &gt;1.4
    million individuals, we show that <em>F<sub>ROH</sub></em> is significantly associated
    (<em>p</em>&lt; 0.0005) with apparently deleterious changes in 32 out of 100 traits
    analysed. These changes are associated with runs of homozygosity (ROH), but not
    with common variant homozygosity, suggesting that genetic variants associated
    with inbreeding depression are predominantly rare. The effect on fertility is
    striking: <em>F<sub>ROH</sub></em> equivalent to the offspring of first cousins
    is associated with a 55% decrease [95% CI 44–66%] in the odds of having children.
    Finally, the effects of <em>F<sub>ROH</sub></em> are confirmed within full-sibling
    pairs, where the variation in <em>F<sub>ROH</sub></em> is independent of all environmental
    confounding.</p>'
- - /docs/rl/2019-vinyals.pdf#deepmind
  - Grandmaster level in StarCraft II using multi-agent reinforcement learning
  - Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, Michaël Mathieu, Andrew
    Dudzik, Junyoung Chung, David H. Choi, Richard Powell, Timo Ewalds, Petko Georgiev,
    Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang, Laurent Sifre,
    Trevor Cai, John P. Agapiou, Max Jaderberg, Alexander S. Vezhnevets, Rémi Leblond,
    Tobias Pohlen, Valentin Dalibard, David Budden, Yury Sulsky, James Molloy, Tom
    L. Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani
    Yogatama, Dario Wünsch, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap,
    Koray Kavukcuoglu, Demis Hassabis, Chris Apps, David Silver
  - 2019-10-30
  - 10.1038/s41586-019-1724-z
  - ! 'Many real-world applications require artificial agents to compete and coordinate
    with other agents in complex environments. As a stepping stone to this goal, the
    domain of StarCraft has emerged as an important challenge for artificial intelligence
    research, owing to its iconic and enduring status among the most difficult professional
    e-sports and its relevance to the real world in terms of its raw complexity and
    multi-agent challenges. Over the course of a decade and numerous competitions,
    the strongest agents have simplified important aspects of the game, utilized superhuman
    capabilities, or employed hand-crafted sub-systems. Despite these advantages,
    no previous agent has come close to matching the overall skill of top StarCraft
    players. We chose to address the challenge of StarCraft using general-purpose
    learning methods that are in principle applicable to other complex domains: a
    multi-agent reinforcement learning algorithm that uses data from both human and
    agent games within a diverse league of continually adapting strategies and counter-strategies,
    each represented by deep neural networks. We evaluated our agent, AlphaStar,
    in the full game of StarCraft II, through a series of online games against human
    players. AlphaStar was rated at Grandmaster level for all three StarCraft races
    and above 99.8% of officially ranked human players.'
- - https://www.fhi.ox.ac.uk/reports/2012-1.pdf
  - Indefinite survival through backup copies
  - Anders Sandberg, Stuart Armstrong
  - 2012-06-06
  - ''
  - ! 'If an individual entity endures a fixed probability μ <1 of disappearing ("dying") in a given fixed time period, then, as time approaches infinity, the probability of death approaches certainty. One approach to avoid this fate is for individuals to copy themselves into different locations; if the copies each have an independent probability of dying, then the total risk is much reduced.  However, to avoid the same ultimate fate, the entity must continue copying itself to continually reduce the risk of death. In this paper, we show that to get a non-zero probability of ultimate survival, it suffices that the number of copies grows logarithmically with time. Accounting for expected copy casualties, the required rate of copying is hence bounded.'
- - http://jcsm.aasm.org/ViewAbstract.aspx?pid=31280
  - Stevens-Johnson Syndrome After Armodafinil Use
  - Steven Holfinger, Asim Roy, Markus Schmidt
  - 2018-05-15
  - 10.5664/jcsm.7132
  - "We present the case of a 21-year-old woman in whom Stevens-Johnson syndrome (SJS) developed after initiation of armodafinil. Although this rare and life-threatening reaction is listed on armodafinil's label, no cases have been reported in the literature. This case, in addition to an update of the drug's label after post-marketing research, both support the link between armodafinil and SJS. Providers should maintain a high clinical suspicion for SJS when starting therapy to minimize associated morbidity and mortality by discontinuing armodafinil at the onset of first symptoms."
- - /docs/genetics/selection/2019-karavani.pdf
  - Screening Human Embryos for Polygenic Traits Has Limited Utility
  - Ehud Karavani, Or Zuk, Danny Zeevi, Nir Barzilai, Nikos C. Stefanis, Alex Hatzimanolis, Nikolaos Smyrnis, Dimitrios Avramopoulos, Leonid Kruglyak, Gil Atzmon, Max Lam, Todd Lencz
  - 2019-11-21
  - 10.1016/j.cell.2019.10.033
  - ! '<ul><li>IVF embryos could be profiled with polygenic scores for traits such as height or IQ</li><li>The top-scoring embryo is expected to be ≈2.5 cm or ≈2.5 IQ points above the average</li><li>The adult trait value of the top-scoring embryo would remain widely distributed</li><li>Multiple ethical and other factors impose practical limits on the actual gain</li></ul><p>The increasing proportion of variance in human complex traits explained by polygenic scores, along with progress in preimplantation genetic diagnosis, suggests the possibility of screening embryos for traits such as height or cognitive ability. However, the expected outcomes of embryo screening are unclear, which undermines discussion of associated ethical concerns. Here, we use theory, simulations, and real data to evaluate the potential gain of embryo screening, defined as the difference in trait value between the top-scoring embryo and the average embryo. The gain increases very slowly with the number of embryos but more rapidly with the variance explained by the score. Given current technology, the average gain due to screening would be ≈2.5 cm for height and ≈2.5 IQ points for cognitive ability. These mean values are accompanied by wide prediction intervals, and indeed, in large nuclear families, the majority of children top-scoring for height are not the tallest.</p>'
- - http://www.emcdda.europa.eu/system/files/attachments/12104/EDMR2019_BackgroundReport_Darknet.pdf
  - "Analysis of the supply of drugs and new psychoactive substances by Europe-based vendors via darknet markets in 2017–18: Background paper commissioned by the EMCDDA for the EU Drug Markets Report 2019"
  - Nicolas Christin, Jeremy Thomas
  - 2019-11-21
  - ''
  - ! '<p>Online anonymous marketplaces are a relatively recent technological development that enables sellers and buyers to transact online with far stronger anonymity guarantees than are available on traditional electronic commerce platforms. This has led certain individuals to engage in transactions of illicit or illegal goods. We investigated how commerce on online anonymous marketplaces evolved after the takedown of the AlphaBay marketplace. Namely, we studied, over the summers of 2017 and 2018, a collection of market-places—Dream Market, TradeRoute, Berlusconi, and Valhalla. In this report, we present an analysis of sales,with a focus on the drug supply coming from the European Union (EU). Keeping in mind the limitations inherent to such data collection, we found that, for the period and the marketplaces considered:</p><ul><li>The overall ecosystem appears to have (slightly) grown again since the combined takedown of the AlphaBay and Hansa marketplaces, and now exceeds EUR 750&thinsp;000 euros per day. This calls into question the long-term impact of such takedowns on the overall online anonymous marketplace ecosystem.</li><li>Dream Market is overwhelmingly the dominant marketplace, and its daily volume exceeds previous numbers gathered for AlphaBay (Christin, 2017).</li><li>EU-based suppliers represent approximately 43% of all drug sales; this is in line with the 46% for marketplaces previously studied (Christin, 2016) in the 2011–15 period, and a marked increase compared with the roughly 25% observed in the subsequent AlphaBay study (Christin, 2017).</li><li>EU-originating drugs continued to come primarily from Germany, the Netherlands, and the United Kingdom.</li><li>Cannabis, cocaine and other stimulants altogether continued to represent the majority of all EU-based drug sales.</li><li>The supply of new psychoactive substances (NPS) remained modest with revenues below EUR 10&thinsp;000 per day at market peak, but these slightly increased compared with our previous measurements.</li><li>As in our previous studies, marketplace vendors primarily operated in the retail space, but there was evidence of larger (bulk) sales. Volume-based discounting tended to occur, albeit at relatively modest levels.</li><li>As in our previous studies, half of the vendors specialised in one type of drug, and half of the drug sellers tended to stick to a given weight category.</li><li>Most of the trends observed in this report confirm what we had previously found for other market-places in the 2011–17 period (Christin, 2016, 2017). In other words, despite takedowns and scams, the ecosystem, as a whole, appears relatively stable over time, with the fluctuation in the European sales share noted above indicating an exception.</li></ul><p>…we collected 35 scrapes of four markets—Dream Market, Traderoute, Valhalla, and Berlusconi Market—between summer 2017 and summer 2018.</p><p>[Full report: <a href="http://www.emcdda.europa.eu/system/files/publications/12078/20192630_TD0319332ENN_PDF.pdf">“EU Drug Markets Report: 2019”</a>, DOI: <code>10.2810/561192</code>.]</p>'
- - https://alexdanco.com/2019/11/27/the-social-subsidy-of-angel-investing/
  - The Social Subsidy of Angel Investing
  - Alex Danco
  - 2019-11-27
  - ''
  - ! '<p>The difference in angel investing between Silicon Valley and everywhere else isn’t just a difference in perceived risk/reward or a difference in FOMO. It’s that angel investing fulfils a completely different purpose in Silicon Valley than it does elsewhere. It’s not just a financial activity; it’s a social status exercise.</p><p><strong>Angel Investors in the Bay Area aren’t just in it for the financial returns; they’re also in it for the social returns.</strong></p><p>The Bay Area tech ecosystem has been so successful that startup-related news has become the principal determinant of social status in San Francisco. In other cities, you acquire and flex social status by joining exclusive neighbourhoods or country clubs, or through philanthropic gestures, or even something as simple as what car you drive. In San Francisco, it’s angel investing. Other than founding a successful startup yourself, there’s not much higher-status in the Bay Area than backing founders that go on to build Uber or Stripe…The end result is that the Bay Area has a critical density of people who are willing to offer founders a term sheet for enough investment, and at attractive enough valuations, that it makes sense for the founder to actually accept them. I honestly believe that without this social “subsidy”, a lot of angel investing stops working. If investors were being purely rational, they could only offer something like a $2 million valuation for founders’ first cheques. And if entrepreneurs are smart, they know they can’t accept it; it makes them un-fundable from that day forward.</p><p><strong>The social rewards of angel investing solve an important chicken-and-egg problem in early stage fundraising that financial rewards does not.</strong></p><p>One of the biggest frustrations you face as a founder out fundraising is the refrain: “This sounds really interesting. I love it. Let me know when there are a bunch of other people investing, and then I’ll invest too.” From far away, it’s easy to label this behaviour as cowardly investing. But it happens for a reason…The social returns to angel investing resolve our chicken/egg problem: they turn angel investing into a kind of “race to be first” that is much more aligned with the founder, and more conducive to breaking inertia and completing deals. The founder wants you to move first, and so do you.</p><p><strong>The social returns to angel investing have a strong geographical network effect, because they require a threshold density in order to kick in.</strong></p><p>…If you can assemble enough early stage investors together, it should conceptually become self-sustaining. Once you have that sufficient density of people who care about the social return to angel investing, and you establish a genuine “early stage capital market” that is subsidized in part by the social and emotional job that it’s doing for its angel members, you create something really special. You get the rare conditions where capital is available for founders at high enough valuations, with no strings attached, and by investors who are evaluating them “the right way”, that you actually sustain a scene that produces startups in sufficient numbers to generate those few unlikely mega-winners that replenish angels’ bank accounts and keep the cycle going.</p>'
- - /docs/catnip/1962-todd.pdf
  - Inheritance of the catnip response in domestic cats
  - Neil B. Todd
  - '1962'
  - 10.1093/oxfordjournals.jhered.a107121
  - ! '<p>Four behavioral components of the catnip response are described briefly. The analysis of a pedigree indicates that responding is inherited as an autosomal dominant. Other aspects of inheritance of the catnip response are discussed.</p><p>An essential oil, nepetalactone, was isolated from the catnip plant <em>(Nepeta cataria)</em> by McElvain et al. <sup>2</sup>, <sup>3</sup>, <sup>4</sup> and Meinwald <sup>5</sup>. McElvain<sup>2</sup> demonstrated with lions that the oil is the substance which is responsible for the attraction of cats to the plant and the only constituent capable of inducing a response. This familiar response has been broken down into four components, <em>viz</em>, 1. sniffing, 2. licking and chewing with head shaking, 3. chin and cheek rubbing and 4. head-over roll and body rubbing. None of these automatisms is unique to catnip, each of them apparently belonging normally to sexual or ingestive behavior<sup>1</sup>. These components almost invariably appear in the above sequence. In fact, among 58 responding cats, all tested with dried leaves, only 3 individuals deviated from this sequence and omitted the licking and chewing with head shaking. These animals went immediately into the rolling phase, which seemed to be exceptionally violent. Component four may last from three to six minutes before all response is extinguished. Additional behavior patterns noted occasionally are claw sharpening and washing, both of which occur as displacement activities in the ethological sense in sexual behavior<sup>1</sup>.</p><p>Among responding animals the response may occasionally be inhibited for obscure reasons, necessitating repeated testing of non-responders before drawing conclusions. Also, the response is not manifested in kittens under 6 to 8 weeks of age and may not develop fully until three months of age. In fact, catnip often produces a distinct avoidance response in young kittens which is gradually replaced by indifference in non-responders and by heightened curiosity in responders. Whether nursing is in any way connected with inhibiting the response has not yet been determined. In one case a 6- to 7-week-old nursing kitten gave a total response, but this seems exceptional. A distressed or enraged animal may still respond, and neutering appears to have no effect on behavior towards catnip.</p>'
- - /docs/culture/2005-moretti-graphsmapstrees-3-trees.pdf
  - ! '<em>Graphs, Maps, Trees: Abstract Models for a Literary History</em>, ch. 3: Trees'
  - Franco Moretti
  - ! '2005'
  - ! ''
  - ! '<p>After the quantitative diagrams of the first chapter, and the spatial ones of the second, evolutionary trees constitute <em>morphological</em> diagrams, where history is systematically correlated with form. And indeed, in contrast to literary studies—where theories of form are usually blind to history, and historical work blind to form—for evolutionary thought morphology and history are truly the two dimensions of the same tree: where the vertical axis charts, from the bottom up, the regular passage of time (every interval, writes Darwin, ‘one thousand generations’), while the horizontal one follows the formal diversification (‘the little fans of diverging dotted lines’) that will eventually lead to ‘well-marked varieties’, or to entirely new species.</p><p>The horizontal axis follows formal diversification . . . But Darwin’s words are stronger: he speaks of ‘this rather perplexing subject’—elsewhere, ‘perplexing &amp; unintelligible’ <sup>4</sup>—whereby forms don’t just ‘change’, but change by always <em>diverging</em> from each other (remember, we are in the section on ‘Divergence of Character’).<sup>5</sup> Whether as a result of historical accidents, then, or under the action of a specific ‘principle’, <sup>6</sup> the reality of divergence pervades the history of life, defining its morphospace—its space-of-forms: an important concept, in the pages that follow—as an intrinsically expanding one.</p><p>From a single common origin, to an immense variety of solutions: it is this incessant growing-apart of life forms that the branches of a morphological tree capture with such intuitive force. ‘A tree can be viewed <em>as a simplified description of a matrix of distances</em>’, write Cavalli-Sforza, Menozzi and Piazza in the methodological prelude to their <em>History and Geography of Human Genes</em>; and figure 29, with its mirror-like alignment of genetic groups and linguistic families drifting away from each other (in a ‘correspondence [that] is remarkably high but not perfect’, as they note with aristocratic aplomb), <sup>7</sup> makes clear what they mean: a tree is a way of sketching <em>how far</em> a certain language has moved from another one, or from their common point of origin.</p><p>And if language evolves by diverging, why not literature too?</p>'
- - /docs/genetics/correlation/2015-power.pdf
  - Polygenic risk scores for schizophrenia and bipolar disorder predict creativity
  - Robert A Power, Stacy Steinberg, Gyda Bjornsdottir, Cornelius A Rietveld, Abdel Abdellaoui, Michel M Nivard, Magnus Johannesson, Tessel E Galesloot, Jouke J Hottenga, Gonneke Willemsen, David Cesarini, Daniel J Benjamin, Patrik K E Magnusson, Fredrik Ullén, Henning Tiemeier, Albert Hofman, Frank J A van Rooij, G Bragi Walters, Engilbert Sigurdsson, Thorgeir E Thorgeirsson, Andres Ingason, Agnar Helgason, Augustine Kong, Lambertus A Kiemeney, Philipp Koellinger, Dorret I Boomsma, Daniel Gudbjartsson, Hreinn Stefansson & Kari Stefansson
  - 2015-06-08
  - 10.1038/nn.4040
  - ! '<p>We tested whether polygenic risk scores for schizophrenia and bipolar disorder would predict creativity. Higher scores were associated with artistic society membership or creative profession in both Icelandic (<em>p</em> = 5.2 × 10<sup>−6</sup> and 3.8 × 10<sup>−6</sup> for schizophrenia and bipolar disorder scores, respectively) and replication cohorts (<em>p</em> = 0.0021 and 0.00086). This could not be accounted for by increased relatedness between creative individuals and those with psychoses, indicating that creativity and psychosis share genetic roots.</p>'
- - /docs/genetics/correlation/2016-day.pdf
  - Physical and neurobehavioral determinants of reproductive onset and success
  - Felix R Day, Hannes Helgason, Daniel I Chasman, Lynda M Rose, Po-Ru Loh, Robert A Scott, Agnar Helgason, Augustine Kong, Gisli Masson, Olafur Th Magnusson, Daniel Gudbjartsson, Unnur Thorsteinsdottir, Julie E Buring, Paul M Ridker, Patrick Sulem, Kari Stefansson, Ken K Ong & John R B Perry
  - 2016-04-18
  - 10.1038/ng.3551
  - ! '<p>The ages of puberty, first sexual intercourse and first birth signify the onset of reproductive ability, behavior and success, respectively. In a genome-wide association study of 125,667 UK Biobank participants, we identify 38 loci associated (<em>p</em> &lt; 5 × 10<sup>−8</sup>) with age at first sexual intercourse. These findings were taken forward in 241,910 men and women from Iceland and 20,187 women from the Women’s Genome Health Study. Several of the identified loci also exhibit associations (<em>p</em> &lt; 5 × 10<sup>−8</sup>) with other reproductive and behavioral traits, including age at first birth (variants in or near <em>ESR1</em> and <em>RBM6–SEMA3F</em>), number of children (<em>CADM2</em> and <em>ESR1</em>), irritable temperament (<em>MSRA</em>) and risk-taking propensity (<em>CADM2</em>). Mendelian randomization analyses infer causal influences of earlier puberty timing on earlier first sexual intercourse, earlier first birth and lower educational attainment. In turn, likely causal consequences of earlier first sexual intercourse include reproductive, educational, psychiatric and cardiometabolic outcomes.</p>'
- - /docs/genetics/correlation/2018-turley.pdf
  - Multi-trait analysis of genome-wide association summary statistics using MTAG
  - Patrick Turley, Raymond K. Walters, Omeed Maghzian, Aysu Okbay, James J. Lee, Mark Alan Fontana, Tuan Anh Nguyen-Viet, Robbee Wedow, Meghan Zacher, Nicholas A. Furlotte, 23andMe Research Team, Social Science Genetic Association Consortium, Patrik Magnusson, Sven Oskarsson, Magnus Johannesson, Peter M. Visscher, David Laibson, David Cesarini, Benjamin M. Neale, Daniel J. Benjamin
  - ! '2017-10-23'
  - ! '10.1038/s41588-017-0009-4'
  - ! 'We introduce multi-trait analysis of GWAS (MTAG), a method for joint analysis of summary statistics from genome-wide association studies (GWAS) of different traits, possibly from overlapping samples. We apply MTAG to summary statistics for depressive symptoms (<em>N</em><sub>eff</sub>= 354,862), neuroticism (<em>N</em>= 168,105), and subjective well-being (<em>N</em>= 388,538). As compared to the 32, 9, and 13 genome-wide significant loci identified in the single-trait GWAS (most of which are themselves novel), MTAG increases the number of associated loci to 64, 37, and 49, respectively. Moreover, association statistics from MTAG yield more informative bioinformatics analyses and increase the variance explained by polygenic scores by approximately 25%, matching theoretical expectations.'
- - /docs/genetics/heritable/1976-loehlin-heredityenvironmentandpersonality.pdf
  - ! '<em>Heredity, Environment, & Personality: A Study of 850 Sets of Twins</em>'
  - John C. Loehlin, Robert C. Nichols
  - ! '1976'
  - ''
  - ! '<p>This volume reports on a study of 850 pairs of twins who were tested to determine the influence of heredity and environment on individual differences in personality, ability, and interests. It presents the background, research design, and procedures of the study, a complete tabulation of the test results, and the authors’ extensive analysis of their findings. Based on one of the largest studies of twin behavior ever conducted, the book challenges a number of traditional beliefs about genetic and environmental contributions to personality development.</p> <p>The subjects were chosen from participants in the National Merit Scholarship Qualifying Test of 1962 and were mailed a battery of personality and interest questionnaires. In addition, parents of the twins were sent questionnaires asking about the twins’ early experiences. A similar sample of nontwin students who had taken the merit exam provided a comparison group. The questions investigated included how twins are similar to or different from non-twins, how identical twins are similar to or different from fraternal twins, how the personalities and interests of twins reflect genetic factors, how the personalities and interests of twins reflect early environmental factors, and what implications these questions have for the general issue of how heredity and environment influence the development of psychological characteristics. In attempting to answer these questions, the authors shed new light on the importance of both genes and environment and have formed the basis for new approaches in behavior genetic research.</p>'
- - /docs/genetics/heritable/2017-visscher.pdf
  - '10 Years of GWAS Discovery: Biology, Function, and Translation'
  - Peter M. Visscher, Naomi R. Wray, Qian Zhang, Pamela Sklar, Mark I. McCarthy, Matthew A. Brown, and Jian Yang
  - '2017-07-06'
  - '10.1016/j.ajhg.2017.06.005'
  - ! 'Application of the experimental design of genome-wide association studies (GWASs) is now 10 years old (young), and here we review the remarkable range of discoveries it has facilitated in population and complex-trait genetics, the biology of diseases, and translation toward new therapeutics. We predict the likely discoveries in the next 10 years, when GWASs will be based on millions of samples with array data imputed to a large fully sequenced reference panel and on hundreds of thousands of samples with whole-genome sequencing data.'
- - /docs/genetics/heritable/2018-papageorge.pdf
  - 'Genes, Education, and Labor Market Outcomes: Evidence from the Health and Retirement Study'
  - Nicholas W. Papageorge, Kevin Thom
  - 2018-09
  - 10.3386/w25114
  - ! 'Recent advances have led to the discovery of specific genetic variants that predict educational attainment. We study how these variants, summarized as a linear index—known as a polygenic score—are associated with human capital accumulation and labor market outcomes in the Health and Retirement Study (HRS). We present two main sets of results. First, we find evidence that the genetic factors measured by this score interact strongly with childhood socioeconomic status in determining educational outcomes. In particular, while the polygenic score predicts higher rates of college graduation on average, this relationship is substantially stronger for individuals who grew up in households with higher socioeconomic status relative to those who grew up in poorer households. Second, the polygenic score predicts labor earnings even after adjusting for completed education, with larger returns in more recent decades. These patterns suggest that the genetic traits that promote education might allow workers to better accommodate ongoing skill biased technological change. Consistent with this interpretation, we find a positive association between the polygenic score and non-routine analytic tasks that have benefited from the introduction of new technologies. Nonetheless, the college premium remains the dominant determinant of earnings differences at all levels of the polygenic score. Given the role of childhood SES in predicting college attainment, this raises concerns about wasted potential arising from limited household resources.'
- - /docs/genetics/selection/2014-montague.pdf
  - Comparative analysis of the domestic cat genome reveals genetic signatures underlying feline biology and domestication
  - Michael J. Montague, Gang Li, Barbara Gandolfi, Razib Khan, Bronwen L. Aken, Steven M. J. Searle, Patrick Minx, LaDeana W. Hillier, Daniel C. Koboldt, Brian W. Davis, Carlos A. Driscoll, Christina S. Barr, Kevin Blackistone, Javier Quilez, Belen Lorente-Galdos, Tomas Marques-Bonet, Can Alkan, Gregg W. C. Thomas, Matthew W. Hahn, Marilyn Menotti-Raymond, Stephen J. O’Brien, Richard K. Wilson, Leslie A. Lyons, William J. Murphy, and Wesley C. Warren
  - 2014-10-03
  - 10.1073/pnas.1410083111
  - ! 'Little is known about the genetic changes that distinguish domestic cat populations from their wild progenitors. Here we describe a high-quality domestic cat reference genome assembly and comparative inferences made with other cat breeds, wildcats, and other mammals. Based upon these comparisons, we identified positively selected genes enriched for genes involved in lipid metabolism that underpin adaptations to a hypercarnivorous diet. We also found positive selection signals within genes underlying sensory processes, especially those affecting vision and hearing in the carnivore lineage. We observed an evolutionary tradeoff between functional olfactory and vomeronasal receptor gene repertoires in the cat and dog genomes, with an expansion of the feline chemosensory system for detecting pheromones at the expense of odorant detection. Genomic regions harboring signatures of natural selection that distinguish domestic cats from their wild congeners are enriched in neural crest-related genes associated with behavior and reward in mouse models, as predicted by the domestication syndrome hypothesis. Our description of a previously unidentified allele for the gloving pigmentation pattern found in the Birman breed supports the hypothesis that cat breeds experienced strong selection on specific mutations drawn from random bred populations. Collectively, these findings provide insight into how the process of domestication altered the ancestral wildcat genome and build a resource for future disease mapping and phylogenomic studies across all members of the <em>Felidae</em>.'
- - /docs/genetics/selection/2015-robinson.pdf
  - Population genetic differentiation of height and body mass index across Europe
  - Matthew R Robinson, Gibran Hemani, Carolina Medina-Gomez, Massimo Mezzavilla, Tonu Esko, Konstantin Shakhbazov, Joseph E Powell, Anna Vinkhuyzen, Sonja I Berndt, Stefan Gustafsson, Anne E Justice, Bratati Kahali, Adam E Locke, Tune H Pers, Sailaja Vedantam, Andrew R Wood, Wouter van Rheenen, Ole A Andreassen, Paolo Gasparini, Andres Metspalu, Leonard H van den Berg, Jan H Veldink, Fernando Rivadeneira, Thomas M Werge, Goncalo R Abecasis, Dorret I Boomsma, Daniel I Chasman, Eco J C de Geus, Timothy M Frayling, Joel N Hirschhorn, Jouke Jan Hottenga, Erik Ingelsson, Ruth J F Loos, Patrik K E Magnusson, Nicholas G Martin, Grant W Montgomery, Kari E North, Nancy L Pedersen, Timothy D Spector, Elizabeth K Speliotes, Michael E Goddard, Jian Yang, Peter M Visscher
  - 2015-09-14
  - 10.1038/ng.3401
  - ! '<p>Across-nation differences in the mean values for complex traits are common<sup>1–8</sup>, but the reasons for these differences are unknown. Here we find that many independent loci contribute to population genetic differences in height and body mass index (BMI) in 9,416 individuals across 14 European countries. Using discovery data on over 250,000 individuals and unbiased effect size estimates from 17,500 sibling pairs, we estimate that 24% (95% credible interval (CI) = 9%, 41%) and 8% (95% CI = 4%, 16%) of the captured additive genetic variance for height and BMI, respectively, reflect population genetic differences. Population genetic divergence differed significantly from that in a null model (height, <em>P</em> &lt; 3.94 × 10<sup>−8</sup>; BMI, <em>P</em> &lt; 5.95 × 10<sup>−4</sup>), and we find an among-population genetic correlation for tall and slender individuals (<em>r</em> = −0.80, 95% CI = −0.95, −0.60), consistent with correlated selection for both phenotypes. Observed differences in height among populations reflected the predicted genetic means (<em>r</em> = 0.51; <em>P</em> &lt; 0.001), but environmental differences across Europe masked genetic differentiation for BMI (<em>P</em> &lt; 0.58).</p>'
- - /docs/genetics/selection/2017-gazal.pdf
  - Linkage disequilibrium–dependent architecture of human complex traits shows action of negative selection
  - Steven Gazal, Hilary K Finucane, Nicholas A Furlotte, Po-Ru Loh, Pier Francesco Palamara, Xuanyao Liu, Armin Schoech, Brendan Bulik-Sullivan, Benjamin M Neale, Alexander Gusev, Alkes L Price
  - 2017-09-11
  - 10.1038/ng.3954
  - ! 'Recent work has hinted at the linkage disequilibrium (LD)-dependent architecture of human complex traits, where SNPs with low levels of LD (LLD) have larger per-SNP heritability. Here we analyzed summary statistics from 56 complex traits (average <em>n</em> = 101,401) by extending stratified LD score regression to continuous annotations. We determined that SNPs with low LLD have significantly larger per-SNP heritability and that roughly half of this effect can be explained by functional annotations negatively correlated with LLD, such as DNase I hypersensitivity sites (DHSs). The remaining signal is largely driven by our finding that more recent common variants tend to have lower LLD and to explain more heritability (<em>p</em> = 2.38 × 10^−104^); the youngest 20% of common SNPs explain 3.9 times more heritability than the oldest 20%, consistent with the action of negative selection. We also inferred jointly significant effects of other LD-related annotations and confirmed via forward simulations that they jointly predict deleterious effects.'
- - /docs/genetics/selection/2018-pardinas.pdf
  - Common schizophrenia alleles are enriched in mutation-intolerant genes and in regions under strong background selection
  - Antonio F. Pardiñas, Peter Holmans, Andrew J. Pocklington, Valentina Escott-Price, Stephan Ripke , Noa Carrera, Sophie E. Legge, Sophie Bishop, Darren Cameron, Marian L. Hamshere, Jun Han, Leon Hubbard, Amy Lynham, Kiran Mantripragada, Elliott Rees, James H. MacCabe, Steven A. McCarroll, Bernhard T. Baune, Gerome Breen, Enda M. Byrne, Udo Dannlowski, Thalia C. Eley, Caroline Hayward, Nicholas G. Martin, Andrew M. McIntosh, Robert Plomin, David J. Porteous, Naomi R. Wray, Armando Caballero, Daniel H. Geschwind, Laura M. Huckins, Douglas M. Ruderfer, Enrique Santiago, Pamela Sklar, Eli A. Stahl, Hyejung Won, Esben Agerbo, Thomas D. Als, Ole A. Andreassen, Marie Bækvad-Hansen, Preben Bo Mortensen, Carsten Bøcker Pedersen, Anders D. Børglum, Jonas Bybjerg-Grauholm, Srdjan Djurovic, Naser Durmishi, Marianne Giørtz Pedersen, Vera Golimbet, Jakob Grove, David M. Hougaard, Manuel Mattheisen, Espen Molden, Ole Mors, Merete Nordentoft, Milica Pejovic-Milovancevic, Engilbert Sigurdsson, Teimuraz Silagadze, Christine Søholm Hansen, Kari Stefansson, Hreinn Stefansson, Stacy Steinberg, Sarah Tosato, Thomas Werge, GERAD1 Consortium, CRESTAR Consortium, David A. Collier, Dan Rujescu, George Kirov, Michael J. Owen, Michael C. O’Donovan and James T. R. Walters
  - '2018'
  - 10.1038/s41588-018-0059-2
  - ! 'Schizophrenia is a debilitating psychiatric condition often associated with poor quality of life and decreased life expectancy. Lack of progress in improving treatment outcomes has been attributed to limited knowledge of the underlying biology, although large-scale genomic studies have begun to provide insights. We report a new genome-wide association study of schizophrenia (11,260 cases and 24,542 controls), and through meta-analysis with existing data we identify 50 novel associated loci and 145 loci in total. Through integrating genomic fine-mapping with brain expression and chromosome conformation data, we identify candidate causal genes within 33 loci. We also show for the first time that the common variant association signal is highly enriched among genes that are under strong selective pressures. These findings provide new insights into the biology and genetic architecture of schizophrenia, highlight the importance of mutation-intolerant genes and suggest a mechanism by which common risk variants persist in the population.'
- - /docs/iq/2014-benyamin.pdf
  - Childhood intelligence is heritable, highly polygenic and associated with <em>FNBP1L</em>
  - B Benyamin, BSt Pourcain, OS Davis, G Davies, NK Hansell, M-JA Brion, RM Kirkpatrick, RAM Cents, S Franić, MB Miller, CMA Haworth, E Meaburn, TS Price, DM Evans, N Timpson, J Kemp, S Ring, W McArdle, SE Medland, J Yang, SE Harris, DC Liewald, P Scheet, X Xiao, JJ Hudziak, EJC de Geus, Wellcome Trust Case Control Consortium 2 (WTCCC2), VWV Jaddoe, JM Starr, FC Verhulst, C Pennell, H Tiemeier, WG Iacono, LJ Palmer, GW Montgomery, NG Martin, DI Boomsma, D Posthuma, M McGue, MJ Wright, G Davey Smith, IJ Deary, R Plomin, PM Visscher
  - 2013-01-29
  - 10.1038/mp.2012.184
  - ! '<p>Intelligence in childhood, as measured by psychometric cognitive tests, is a strong predictor of many important life outcomes, including educational attainment, income, health and lifespan. Results from twin, family and adoption studies are consistent with general intelligence being highly heritable and genetically stable throughout the life course. No robustly associated genetic loci or variants for childhood intelligence have been reported. Here, we report the first genome-wide association study (GWAS) on childhood intelligence (age range 6–18 years) from 17&thinsp;989 individuals in six discovery and three replication samples. Although no individual single-nucleotide polymorphisms (SNPs) were detected with genome-wide significance, we show that the aggregate effects of common SNPs explain 22–46% of phenotypic variation in childhood intelligence in the three largest cohorts (<em>P</em> = 3.9 x 10<sup>-15</sup>, 0.014 and 0.028). <em>FNBP1L</em>, previously reported to be the most significantly associated gene for adult intelligence, was also significantly associated with childhood intelligence (<em>P</em> = 0.003). Polygenic prediction analyses resulted in a significant correlation between predictor and outcome in all replication cohorts. The proportion of childhood intelligence explained by the predictor reached 1.2% (<em>P</em> = 6 x 10<sup>-5</sup>), 3.5% (<em>P</em> = 10<sup>-3</sup>) and 0.5% (<em>P</em> = 6 x 10<sup>-5</sup>) in three independent validation cohorts. Given the sample sizes, these genetic prediction results are consistent with expectations if the genetic architecture of childhood intelligence is like that of body mass index or height. Our study provides molecular support for the heritability and polygenic nature of childhood intelligence. Larger sample sizes will be required to detect individual variants with genome-wide significance.</p>'
- - /docs/genetics/selection/2017-wehby.pdf
  - Genetic Predisposition to Obesity and Medicare Expenditures
  - George L. Wehby, Benjamin W. Domingue, Fred Ullrich, and Fredric D. Wolinsky
  - 2017-05-10
  - 10.1093/gerona/glx062
  - ! 'Background: The relationship between obesity and health expenditures is not well understood. We examined the relationship between genetic predisposition to obesity measured by a polygenic risk score for body mass index (BMI) and Medicare expenditures. Methods: Biennial interview data from the Health and Retirement Survey for a nationally representative sample of older adults enrolled in fee-for-service Medicare were obtained from 1991 through 2010 and linked to Medicare claims for the same period and to Genome-Wide Association Study (GWAS) data. The study included 6,628 Medicare beneficiaries who provided 68,627 complete person-year observations during the study period. Outcomes were total and service-specific Medicare expenditures and indicators for expenditures exceeding the 75th and 90th percentiles. The BMI polygenic risk score was derived from GWAS data. Regression models were used to examine how the BMI polygenic risk score was related to health expenditures adjusting for demographic factors and GWAS-derived ancestry. Results: Greater genetic predisposition to obesity was associated with higher Medicare expenditures. Specifically, a 1 SD increase in the BMI polygenic risk score was associated with a $805 (<em>p</em> &lt; .001) increase in annual Medicare expenditures per person in 2010 dollars (~15% increase), a $370 (<em>p</em> &lt; .001) increase in inpatient expenses, and a $246 (<em>p</em> &lt; .001) increase in outpatient services. A 1 SD increase in the polygenic risk score was also related to increased likelihood of expenditures exceeding the 75th percentile by 18% (95% CI: 10%–28%) and the 90th percentile by 27% (95% CI: 15%–40%). Conclusion: Greater genetic predisposition to obesity is associated with higher Medicare expenditures.'
- - /docs/genetics/selection/2017-mcrae.pdf
  - Prevalence and architecture of de novo mutations in developmental disorders
  - Jeremy F. McRae, Stephen Clayton, Tomas W. Fitzgerald, Joanna Kaplanis, Elena Prigmore, Diana Rajan, Alejandro Sifrim, Stuart Aitken, Nadia Akawi, Mohsan Alvi, Kirsty Ambridge, Daniel M. Barrett, Tanya Bayzetinova, Philip Jones, Wendy D. Jones, Daniel King, Netravathi Krishnappa, Laura E. Mason, Tarjinder Singh, Adrian R. Tivey, Munaza Ahmed, Uruj Anjum, Hayley Archer, Ruth Armstrong, Jana Awada, Meena Balasubramanian, Siddharth Banka, Diana Baralle, Angela Barnicoat, Paul Batstone, David Baty, Chris Bennett, Jonathan Berg, Birgitta Bernhard, A. Paul Bevan, Maria BitnerGlindzicz, Edward Blair, Moira Blyth, David Bohanna, Louise Bourdon, David Bourn, Lisa Bradley, Angela Brady, Simon Brent, Carole Brewer, Kate Brunstrom, David J. Bunyan, John Burn, Natalie Canham, Bruce Castle, Kate Chandler, Elena Chatzimichali, Deirdre Cilliers, Angus Clarke, Susan Clasper, Jill ClaytonSmith, Virginia Clowes, Andrea Coates, Trevor Cole, Irina Colgiu, Amanda Collins, Morag N. Collinson, Fiona Connell, Nicola Cooper, Helen Cox, Lara Cresswell, Gareth Cross, Yanick Crow, Mariella DAlessandro, Tabib Dabir, Rosemarie Davidson, Sally Davies, Dylan de Vries, John Dean, Charu Deshpande, Gemma Devlin, Abhijit Dixit, Angus Dobbie, Alan Donaldson, Dian Donnai, Deirdre Donnelly, Carina Donnelly, Angela Douglas, Sofia Douzgou, Alexis Duncan, Jacqueline Eason, Sian Ellard, Ian Ellis, Frances Elmslie, Karenza Evans, Sarah Everest, Tina Fendick, Richard Fisher, Frances Flinter, Nicola Foulds, Andrew Fry, Alan Fryer, Carol Gardiner, Lorraine Gaunt, Neeti Ghali, Richard Gibbons, Harinder Gill, Judith Goodship, David Goudie, Emma Gray, Andrew Green, Philip Greene, Lynn Greenhalgh, Susan Gribble, Rachel Harrison, Lucy Harrison, Victoria Harrison, Rose Hawkins, Liu He, Stephen Hellens, Alex Henderson, Sarah Hewitt, Lucy Hildyard, Emma Hobson, Simon Holden, Muriel Holder, Susan Holder, Georgina Hollingsworth, Tessa Homfray, Mervyn Humphreys, Jane Hurst,  Ben Hutton, Stuart Ingram, Melita Irving, Lily Islam, Andrew Jackson, Joanna Jarvis, Lucy Jenkins, Diana Johnson, Elizabeth Jones, Dragana Josifova, Shelagh Joss, Beckie Kaemba, Sandra Kazembe, Rosemary Kelsell, Bronwyn Kerr, Helen Kingston, Usha Kini, Esther Kinning, Gail Kirby, Claire Kirk, Emma Kivuva, Alison Kraus, Dhavendra Kumar, V. K. Ajith Kumar, Katherine Lachlan, Wayne Lam, Anne Lampe, Caroline Langman, Melissa Lees, Derek Lim, Cheryl Longman, Gordon Lowther, Sally A. Lynch, Alex Magee, Eddy Maher, Alison Male, Sahar Mansour, Karen Marks, Katherine Martin, Una Maye, Emma McCann, Vivienne McConnell, Meriel McEntagart, Ruth McGowan, Kirsten McKay, Shane McKee, Dominic J. McMullan, Susan McNerlan, Catherine McWilliam, Sarju Mehta, Kay Metcalfe, Anna Middleton, Zosia Miedzybrodzka, Emma Miles, Shehla Mohammed, Tara Montgomery, David Moore, Sian Morgan, Jenny Morton, Hood Mugalaasi, Victoria Murday, Helen Murphy, Swati Naik, Andrea Nemeth, Louise Nevitt, Ruth NewburyEcob, Andrew Norman, Rosie OShea, Caroline Ogilvie, KaiRen Ong, SooMi Park, Michael J. Parker, Chirag Patel, Joan Paterson, Stewart Payne, Daniel Perrett, Julie Phipps, Daniela T. Pilz, Martin Pollard, Caroline Pottinger, Joanna Poulton, Norman Pratt, Katrina Prescott, Sue Price, Abigail Pridham, Annie Procter, Hellen Purnell, Oliver Quarrell, Nicola Ragge, Raheleh Rahbari, Josh Randall, Julia Rankin, Lucy Raymond, Debbie Rice, Leema Robert, Eileen Roberts, Jonathan Roberts, Paul Roberts, Gillian Roberts, Alison Ross, Elisabeth Rosser, Anand Saggar, Shalaka Samant, Julian Sampson, Richard Sandford, Ajoy Sarkar, Susann Schweiger, Richard Scott, Ingrid Scurr, Ann Selby, Anneke Seller, Cheryl Sequeira, Nora Shannon, Saba Sharif, Charles ShawSmith, Emma Shearing, Debbie Shears, Eamonn Sheridan, Ingrid Simonic, Roldan Singzon, Zara Skitt, Audrey Smith, Kath Smith, Sarah Smithson, Linda Sneddon, Miranda Splitt, Miranda Squires, Fiona Stewart, Helen Stewart, Volker Straub, Mohnish Suri, Vivienne Sutton, Ganesh Jawahar Swaminathan, Elizabeth Sweeney, Kate TattonBrown, Cat Taylor, Rohan Taylor, Mark Tein, I. Karen Temple, Jenny Thomson, Marc Tischkowitz, Susan Tomkins, Audrey Torokwa, Becky Treacy, Claire Turner, Peter Turnpenny, Carolyn Tysoe, Anthony Vandersteen, Vinod Varghese, Pradeep Vasudevan, Parthiban Vijayarangakannan, Julie Vogt, Emma Wakeling, Sarah Wallwark, Jonathon Waters, Astrid Weber, Diana Wellesley, Margo Whiteford, Sara Widaa, Sarah Wilcox, Emily Wilkinson, Denise Williams, Nicola Williams, Louise Wilson, Geoff Woods, Christopher Wragg, Michael Wright, Laura Yates, Michael Yau, Chris Nellker, Michael Parker, Helen V. Firth, Caroline F. Wright, David R. FitzPatrick, Jeffrey C. Barrett  Matthew E. Hurles
  - 2017-01-25
  - 10.1038/nature21062
  - ! 'The genomes of individuals with severe, undiagnosed developmental disorders are enriched in damaging de novo mutations (DNMs) in developmentally important genes. Here we have sequenced the exomes of 4,293 families containing individuals with developmental disorders, and meta-analysed these data with data from another 3,287 individuals with similar disorders. We show that the most important factors influencing the diagnostic yield of DNMs are the sex of the affected individual, the relatedness of their parents, whether close relatives are affected and the parental ages. We identified 94 genes enriched in damaging DNMs, including 14 that previously lacked compelling evidence of involvement in developmental disorders. We have also characterized the phenotypic diversity among these disorders. We estimate that 42% of our cohort carry pathogenic DNMs in coding sequences; approximately half of these DNMs disrupt gene function and the remainder result in altered protein function. We estimate that developmental disorders caused by DNMs have an average prevalence of 1 in 213 to 1 in 448 births, depending on parental age. Given current global demographics, this equates to almost 400,000 children born per year.'
- - /docs/genetics/selection/2015-gianola.pdf
  - One Hundred Years of Statistical Developments in Animal Breeding
  - Daniel Gianola, Guilherme J.M. Rosa
  - 2014-11-03
  - 10.1146/annurev-animal-022114-110733
  - 'Statistical methodology has played a key role in scientific animal breeding. Approximately one hundred years of statistical developments in animal breeding are reviewed. Some of the scientific foundations of the field are discussed, and many milestones are examined from historical and critical perspectives. The review concludes with a discussion of some future challenges and opportunities arising from the massive amount of data generated by livestock, plant, and human genome projects.'
- - /docs/genetics/heritable/2018-kaplanis.pdf
  - Quantitative analysis of population-scale family trees with millions of relatives
  - Joanna Kaplanis, Assaf Gordon, Tal Shor, Omer Weissbrod, Dan Geiger, Mary Wahl, Michael Gershovits, Barak Markus, Mona Sheikh, Melissa Gymrek, Gaurav Bhatia, Daniel G. MacArthur, Alkes L. Price, Yaniv Erlich
  - 2018-03-01
  - 10.1126/science.aam9309
  - 'Family trees have vast applications in multiple fields from genetics to anthropology and economics. However, the collection of extended family trees is tedious and usually relies on resources with limited geographical scope and complex data usage restrictions. Here, we collected 86 million profiles from publicly-available online data shared by genealogy enthusiasts. After extensive cleaning and validation, we obtained population-scale family trees, including a single pedigree of 13 million individuals. We leveraged the data to partition the genetic architecture of longevity by inspecting millions of relative pairs and to provide insights into the geographical dispersion of families. We also report a simple digital procedure to overlay other datasets with our resource in order to empower studies with population-scale genealogical data.'
- - /docs/genetics/heritable/2015-yang.pdf
  - Genetic variance estimation with imputed variants finds negligible missing heritability for human height and body mass index
  - Jian Yang, Andrew Bakshi, Zhihong Zhu, Gibran Hemani, Anna A E Vinkhuyzen, Sang Hong Lee, Matthew R Robinson, John R B Perry, Ilja M Nolte, Jana V van VlietOstaptchouk, Harold Snieder, The LifeLines Cohort Study, Tonu Esko, Lili Milani, Reedik Mgi, Andres Metspalu, Anders Hamsten, Patrik K E Magnusson, Nancy L Pedersen, Erik Ingelsson, Nicole Soranzo, Matthew C Keller, Naomi R Wray, Michael E Goddard, Peter M Visscher
  - 2015-08-31
  - 10.1038/ng.3390
  - ! 'We propose a method (GREML-LDMS) to estimate heritability for human complex traits in unrelated individuals using whole-genome sequencing data. We demonstrate using simulations based on whole-genome sequencing data that ~97% and ~68% of variation at common and rare variants, respectively, can be captured by imputation. Using the GREML-LDMS method, we estimate from 44,126 unrelated individuals that all ~17 million imputed variants explain 56% (standard error (s.e.) = 2.3%) of variance for height and 27% (s.e. = 2.5%) of variance for body mass index (BMI), and we find evidence that height- and BMI-associated variants have been under natural selection. Considering the imperfect tagging of imputation and potential overestimation of heritability from previous family-based studies, heritability is likely to be 60–70% for height and 30–40% for BMI. Therefore, the missing heritability is small for both traits. For further discovery of genes associated with complex traits, a study design with SNP arrays followed by imputation is more cost-effective than whole-genome sequencing at current prices.'
- - /docs/genetics/heritable/2012-vandongen.pdf
  - The continuing value of twin studies in the omics era
  - Jenny van Dongen, P. Eline Slagboom, Harmen H. M. Draisma, Nicholas G. Martin, Dorret I. Boomsma
  - 2012-07-31
  - 10.1038/nrg3243
  - 'The classical twin study has been a powerful heuristic in biomedical, psychiatric and behavioural research for decades. Twin registries worldwide have collected biological material and longitudinal phenotypic data on tens of thousands of twins, providing a valuable resource for studying complex phenotypes and their underlying biology. In this Review, we consider the continuing value of twin studies in the current era of molecular genetic studies. We conclude that classical twin methods combined with novel technologies represent a powerful approach towards identifying and understanding the molecular pathways that underlie complex traits.'
- - /docs/genetics/editing/2017-niu.pdf
  - Inactivation of porcine endogenous retrovirus in pigs using CRISPR-Cas9
  - Dong Niu, HongJiang Wei, Lin Lin, Haydy George, Tao Wang, IHsiu Lee, HongYe Zhao, Yong Wang, Yinan Kan, Ellen Shrock, Emal Lesha, Gang Wang, Yonglun Luo, Yubo Qing, Deling Jiao, Heng Zhao, Xiaoyang Zhou, Shouqi Wang, Hong Wei, Marc Gell, George M. Church, Luhan Yang
  - 2017-08-10
  - 10.1126/science.aan4187
  - 'Xenotransplantation is a promising strategy to alleviate the shortage of organs for human transplantation. In addition to the concern on pig-to-human immunological compatibility, the risk of cross-species transmission of porcine endogenous retroviruses (PERVs) has impeded the clinical application of this approach. Earlier, we demonstrated the feasibility of inactivating PERV activity in an immortalized pig cell line. Here, we confirmed that PERVs infect human cells, and observed the horizontal transfer of PERVs among human cells. Using CRISPR-Cas9, we inactivated all the PERVs in a porcine primary cell line and generated PERV-inactivated pigs via somatic cell nuclear transfer. Our study highlighted the value of PERV inactivation to prevent cross-species viral transmission and demonstrated the successful production of PERV-inactivated animals to address the safety concern in clinical xenotransplantation.'
- - /docs/genetics/correlation/2017-xu.pdf
  - Genetic and Environmental Influences on Household Financial Distress
  - Yilan Xu, Daniel A. Briley, Jeffrey R. Brown, William G. Karnes, Brent W. Roberts
  - 2017-01-08
  - 10.1016/j.jebo.2017.08.001
  - ! 'Heterogeneity of household financial outcomes emerges from various individual and environmental factors, including personality, cognitive ability, and socioeconomic status (SES), among others. Using a genetically informative data set, we decompose the variation in financial management behavior into genetic, shared environmental and non-shared environmental factors. We find that about half of the variation in financial distress is genetically influenced, and personality and cognitive ability are associated with financial distress through genetic and within-family pathways. Moreover, the genetic influences of financial distress are highest at the extremes of SES, which in part can be explained by neuroticism and cognitive ability being more important predictors of financial distress at low and high levels of SES, respectively.'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5971142/
  - Polygenic prediction of the phenome, across ancestry, in emerging adulthood
  - Anna R. Docherty, Arden Moscati, Danielle Dick, Jeanne E. Savage, Jessica E. Salvatore, Megan Cooke, Fazil Aliev, Ashlee A. Moore, Alexis C. Edwards, Brien P. Riley, Daniel E. Adkins, Roseann Peterson, Bradley T. Webb, Silviu A. Bacanu, and Kenneth S. Kendler
  - 2017-11-27
  - 10.1017/S0033291717003312
  - ! '<em>Background</em>: Identifying genetic relationships between complex traits in emerging adulthood can provide useful etiological insights into risk for psychopathology. College-age individuals are under-represented in genomic analyses thus far, and the majority of work has focused on the clinical disorder or cognitive abilities rather than normal-range behavioral outcomes. <em>Methods</em>: This study examined a sample of emerging adults 18–22 years of age (<em>N</em> = 5947) to construct an atlas of polygenic risk for 33 traits predicting relevant phenotypic outcomes. 28 hypotheses were tested based on the previous literature on samples of European ancestry, and the availability of rich assessment data allowed for polygenic predictions across 55 psychological and medical phenotypes. <em<Results</em>: Polygenic risk for schizophrenia (SZ) in emerging adults predicted anxiety, depression, nicotine use, trauma, and family history of psychological disorders. Polygenic risk for neuroticism predicted anxiety, depression, phobia, panic, neuroticism, and was correlated with polygenic risk for cardiovascular disease.  <em>Conclusions</em: These results demonstrate the extensive impact of genetic risk for SZ, neuroticism, and major depression on a range of health outcomes in early adulthood. Minimal cross-ancestry replication of these phenomic patterns of polygenic influence underscores the need for more genome-wide association studies of non-European populations.'
- - /docs/genetics/correlation/2017-akiyama.pdf
  - Genome-wide association study identifies 112 new loci for body mass index in the Japanese population
  - Masato Akiyama, Yukinori Okada, Masahiro Kanai, Atsushi Takahashi, Yukihide Momozawa, Masashi Ikeda, Nakao Iwata, Shiro Ikegawa, Makoto Hirata, Koichi Matsuda, Motoki Iwasaki, Taiki Yamaji, Norie Sawada, Tsuyoshi Hachiya, Kozo Tanno, Atsushi Shimizu, Atsushi Hozawa, Naoko Minegishi, Shoichiro Tsugane, Masayuki Yamamoto, Michiaki Kubo Yoichiro Kamatani
  - 2017-09-11
  - 10.1038/ng.3951
  - ! 'Obesity is a risk factor for a wide variety of health problems. In a genome-wide association study (GWAS) of body mass index (BMI) in Japanese people (<em>n</em> = 173,430), we found 85 loci significantly associated with obesity (<em>P</em> &lt; 5.0 × 10<sup>−8</sup>), of which 51 were previously unknown. We conducted trans-ancestral meta-analyses by integrating these results with the results from a GWAS of Europeans and identified 61 additional new loci. In total, this study identifies 112 novel loci, doubling the number of previously known BMI-associated loci. By annotating associated variants with cell-type-specific regulatory marks, we found enrichment of variants in CD19+ cells. We also found significant genetic correlations between BMI and lymphocyte count (<em>P</em> = 6.46 × 10<sup>−5</sup>, <em>r<sub>g</sub></em> = 0.18) and between BMI and multiple complex diseases. These findings provide genetic evidence that lymphocytes are relevant to body weight regulation and offer insights into the pathogenesis of obesity.'
- - /docs/genetics/correlation/2016-hyde.pdf
  - Identification of 15 genetic loci associated with risk of major depression in individuals of European descent
  - Craig L Hyde, Michael W Nagle, Chao Tian, Xing Chen, Sara A Paciga, Jens R Wendland, Joyce Y Tung, David A Hinds, Roy H Perlis, Ashley R Winslow
  - 2016-08-01
  - 10.1038/ng.3623
  - ! 'Despite strong evidence supporting the heritability of major depressive disorder (MDD), previous genome-wide studies were unable to identify risk loci among individuals of European descent. We used self-report data from 75,607 individuals reporting clinical diagnosis of depression and 231,747 individuals reporting no history of depression through 23andMe and carried out meta-analysis of these results with published MDD genome-wide association study results. We identified five independent variants from four regions associated with self-report of clinical diagnosis or treatment for depression. Loci with a <em>P</em> value &lt;1.0 × 10<sup>−5</sup> in the meta-analysis were further analyzed in a replication data set (45,773 cases and 106,354 controls) from 23andMe. A total of 17 independent SNPs from 15 regions reached genome-wide significance after joint analysis over all three data sets. Some of these loci were also implicated in genome-wide association studies of related psychiatric traits. These studies provide evidence for large-scale consumer genomic data as a powerful and efficient complement to data collected from traditional means of ascertainment for neuropsychiatric disease genomics.'
- - /docs/genetics/correlation/2016-barban.pdf
  - Genome-wide analysis identifies 12 loci influencing human reproductive behavior
  - Nicola Barban, Rick Jansen, Ronald de Vlaming, Ahmad Vaez, Jornt J Mandemakers, Felix C Tropf, Xia Shen, James F Wilson, Daniel I Chasman, Ilja M Nolte, Vinicius Tragante, Sander W van der Laan, John R B Perry, Augustine Kong, BIOS Consortium, Tarunveer S Ahluwalia, Eva Albrecht, Laura YergesArmstrong, Gil Atzmon, Kirsi Auro, Kristin Ayers, Andrew Bakshi, Danny BenAvraham, Klaus Berger, Aviv Bergman, Lars Bertram, Lawrence F Bielak, Gyda Bjornsdottir, Marc Jan Bonder, Linda Broer, Minh Bui, Caterina Barbieri, Alana Cavadino, Jorge E Chavarro, Constance Turman, Maria Pina Concas, Heather J Cordell, Gail Davies, Peter Eibich, Nicholas Eriksson, Tõnu Esko, Joel Eriksson, Fahimeh Falahi, Janine F Felix, Mark Alan Fontana, Lude Franke, Ilaria Gandin, Audrey J Gaskins, Christian Gieger, Erica P Gunderson, Xiuqing Guo, Caroline Hayward, Chunyan He, Edith Hofer, Hongyan Huang, Peter K Joshi, Stavroula Kanoni, Robert Karlsson, Stefan Kiechl, Annette Kifley, Alexander Kluttig, Peter Kraft, Vasiliki Lagou, Cecile Lecoeur, Jari Lahti, Ruifang LiGao, Penelope A Lind, Tian Liu, Enes Makalic, Crysovalanto Mamasoula, Lindsay Matteson, Hamdi Mbarek, Patrick F McArdle, George McMahon, S Fleur W Meddens, Evelin Mihailov, Mike Miller, Stacey A Missmer, Claire Monnereau, Peter J van der Most, Ronny Myhre, Mike A Nalls, Teresa Nutile, Ioanna Panagiota Kalafati, Eleonora Porcu, Inga Prokopenko, Kumar B Rajan, Janet RichEdwards, Cornelius A Rietveld, Antonietta Robino, Lynda M Rose, Rico Rueedi, Kathleen A Ryan, Yasaman Saba, Daniel Schmidt, Jennifer A Smith, Lisette Stolk, Elizabeth Streeten, Anke Tönjes, Gudmar Thorleifsson, Sheila Ulivi, Juho Wedenoja, Juergen Wellmann, Peter Willeit, Jie Yao, Loic Yengo, Jing Hua Zhao, Wei Zhao, Daria V Zhernakova, Najaf Amin, Howard Andrews, Beverley Balkau, Nir Barzilai, Sven Bergmann, Ginevra Biino, Hans Bisgaard, Klaus Bønnelykke, Dorret I Boomsma, Julie E Buring, Harry Campbell, Stefania Cappellani, Marina Ciullo, Simon R Cox, Francesco Cucca, Daniela Toniolo, George DaveySmith, Ian J Deary, George Dedoussis, Panos Deloukas, Cornelia M van Duijn, Eco J C de Geus, Johan G Eriksson, Denis A Evans, Jessica D Faul, Cinzia Felicita Sala, Philippe Froguel, Paolo Gasparini, Giorgia Girotto, HansJörgen Grabe, Karin Halina Greiser, Patrick J F Groenen, Hugoline G de Haan, Johannes Haerting, Tamara B Harris, Andrew C Heath, Kauko Heikkilä, Albert Hofman, Georg Homuth, Elizabeth G Holliday, John Hopper, Elina Hyppönen, Bo Jacobsson, Vincent W V Jaddoe, Magnus Johannesson, Astanand Jugessur, Mika Kähönen, Eero Kajantie, Sharon L R Kardia, Bernard Keavney, Ivana Kolcic, Päivikki Koponen, Peter Kovacs, Florian Kronenberg, Zoltan Kutalik, Martina La Bianca, Genevieve Lachance, William G Iacono, Sandra Lai, Terho Lehtimäki, David CLiewald, LifeLines Cohort Study, Cecilia M Lindgren, Yongmei Liu, Robert Luben, Michael Lucht, Riitta Luoto, Per Magnus, Patrik K E Magnusson, Nicholas G Martin, Matt McGue, Ruth McQuillan, Sarah E Medland, Christa Meisinger, Dan Mellström, Andres Metspalu, Michela Traglia, Lili Milani, Paul Mitchell, Grant W Montgomery, Dennis MookKanamori, Renée de Mutsert, Ellen A Nohr, Claes Ohlsson, Jørn Olsen, Ken K Ong, Lavinia Paternoster, Alison Pattie, Brenda W J H Penninx, Markus Perola, Patricia A Peyser, Mario Pirastu, Ozren Polasek, Chris Power, Jaakko Kaprio, Leslie J Raffel, Katri Räikkönen, Olli Raitakari, Paul M Ridker, Susan M Ring, Kathryn Roll, Igor Rudan, Daniela Ruggiero, Dan Rujescu, Veikko Salomaa, David Schlessinger, Helena Schmidt, Reinhold Schmidt, Nicole Schupf, Johannes Smit, Rossella Sorice, Tim D Spector, John M Starr, Doris Stöckl, Konstantin Strauch, Michael Stumvoll, Morris A Swertz, Unnur Thorsteinsdottir, A Roy Thurik, Nicholas J Timpson, Joyce Y Tung, André G Uitterlinden, Simona Vaccargiu, Jorma Viikari, Veronique Vitart, Henry Völzke, Peter Vollenweider, Dragana Vuckovic, Johannes Waage, Gert G Wagner, Jie Jin Wang, Nicholas J Wareham, David R Weir, Gonneke Willemsen, Johann Willeit, Alan F Wright, Krina T Zondervan, Kari Stefansson, Robert F Krueger, James J Lee, Daniel J Benjamin, David Cesarini, Philipp D Koellinger, Marcel den Hoed, Harold Snieder, Melinda C Mills
  - 2016-10-31
  - 10.1038/ng.3698
  - ! 'The genetic architecture of human reproductive behavior—age at first birth (AFB) and number of children ever born (NEB)—has a strong relationship with fitness, human development, infertility and risk of neuropsychiatric disorders. However, very few genetic loci have been identified, and the underlying mechanisms of AFB and NEB are poorly understood. We report a large genome-wide association study of both sexes including 251,151 individuals for AFB and 343,072 individuals for NEB. We identified 12 independent loci that are significantly associated with AFB and/or NEB in a SNP-based genome-wide association study and 4 additional loci associated in a gene-based effort. These loci harbor genes that are likely to have a role, either directly or by affecting non-local gene expression, in human reproduction and infertility, thereby increasing understanding of these complex traits.'
- - /docs/genetics/correlation/2014-sariaslan-2.pdf
  - ! 'Does Population Density and Neighborhood Deprivation Predict Schizophrenia? A Nationwide Swedish Family-Based Study of 2.4 Million Individuals'
  - ! 'Amir Sariaslan, Henrik Larsson, Brian D’Onofrio, Niklas Långström, Seena Fazel, Paul Lichtenstein'
  - ! '2014-07-22'
  - ! '10.1093/schbul/sbu105'
  - ! 'People living in densely populated and socially disorganized areas have higher rates of psychiatric morbidity, but the potential causal status of such factors is uncertain. We used nationwide Swedish longitudinal registry data to identify all children born 1967–1989 (<em>n</em> = 2361585), including separate datasets for all cousins (<em>n</em> = 1&thinsp;715&thinsp;059) and siblings (<em>n</em> = 1667&thinsp;894). The nature of the associations between population density and neighborhood deprivation and individual risk for a schizophrenia diagnosis was investigated while adjusting for unobserved familial risk factors (through cousin and sibling comparisons) and then compared with similar associations for depression. We generated familial pedigree structures using the Multi-Generation Registry and identified study participants with schizophrenia and depression using the National Patient Registry. Fixed-effects logistic regression models were used to study within-family estimates. Population density, measured as ln(population size/km<sup>2</sup>), at age 15 predicted subsequent schizophrenia in the population (OR = 1.10; 95% CI: 1.09; 1.11). Unobserved familial risk factors shared by cousins within extended families attenuated the association (1.06; 1.03; 1.10), and the link disappeared entirely within nuclear families (1.02; 0.97; 1.08). Similar results were found for neighborhood deprivation as predictor and for depression as outcome. Sensitivity tests demonstrated that timing and accumulation effects of the exposures (mean scores across birth, ages 1–5, 6–10, and 11–15 years) did not alter the findings. Excess risks of psychiatric morbidity, particularly schizophrenia, in densely populated and socioeconomically deprived Swedish neighborhoods appear, therefore, to result primarily from unobserved familial selection factors. Previous studies may have overemphasized the etiological importance of these environmental factors.'
- - /docs/economics/2001-warner.pdf
  - ! 'The Personal Discount Rate: Evidence from Military Downsizing Programs'
  - John T. Warner, Saul Pleeter
  - ! '2001-03'
  - ''
  - ! 'The military drawdown program of the early 1990’s provides an opportunity to obtain estimates of personal discount rates based on large numbers of people making real choices involving large sums. The program offered over 65,000 separatees the choice between an annuity and a lump-sum payment. Despite break-even discount rates exceeding 17%, most of the separatees selected the lump sum—saving taxpayers $1.7 billion in separation costs. Estimates of discount rates range from 0 to over 30% and vary with education, age, race, sex, number of dependents, ability test score, and the size of payment.'
- - /docs/culture/2010-dobelli.pdf
  - 'Avoid News: Towards a Healthy News Diet'
  - Rolf Dobelli
  - '2010'
  - ''
  - ! 'This article is the antidote to news. It is long, and you probably won’t be able to skim it. Thanks to heavy news consumption, many people have lost the reading habit and struggle to absorb more than four pages straight. This article will show you how to get out of this trap–if you are not already too deeply in it.'
- - /docs/borges/1951-borges-theargentinewriterandtradition.pdf
  - The Argentine Writer and Tradition
  - Jorge Luis Borges
  - '1951'
  - ''
  - ! 'Borges considers the problem of whether Argentinian writing on non-Argentinian subjects can still be truly "Argentine."  His conclusion: ...We should not be alarmed and that we should feel that our patrimony is the universe; we should essay all themes, and we cannot limit ourselves to purely Argentine subjects in order to be Argentine; for either being Argentine is an inescapable act of fate—and in that case we shall be so in all events—or being Argentine is a mere affectation, a mask. I believe that if we surrender ourselves to that voluntary dream which is artistic creation, we shall be Argentine and we shall also be good or tolerable writers.'
- - https://www1.udel.edu/educ/gottfredson/reprints/1997whygmatters.pdf
  - 'Why <em>g</em> Matters: The Complexity of Everyday Life'
  - Linda S. Gottfredson
  - '1997'
  - ''
  - ! 'Personnel selection research provides much evidence that intelligence (<em>g</em>) is an important predictor of performance in training and on the job, especially in higher level work. This article provides evidence that g has pervasive utility in work settings because it is essentially the ability to deal with cognitive complexity, in particular, with complex information processing. The more complex a work task, the greater the advantages that higher g confers in performing it well. Everyday tasks, like job duties, also differ in their level of complexity. The importance of intelligence therefore differs systematically across different arenas of social life as well as economic endeavor. Data from the National Adult Literacy Survey are used to show how higher levels of cognitive ability systematically improve individuals’ odds of dealing successfully with the ordinary demands of modem life (such as banking, using maps and transportation schedules, reading and understanding forms, interpreting news articles). These and other data are summarized to illustrate how the advantages of higher <em>g</em>, even when they are small, cumulate to affect the overall life chances of individuals at different ranges of the IQ bell curve. The article concludes by suggesting ways to reduce the risks for low-IQ individuals of being left behind by an increasingly complex postindustrial economy.'
- - https://www.sociologicalscience.com/download/volume-2/february/SocSci_v2_82to105.pdf
  - Is the Effect of Parental Education on Offspring Biased or Moderated by Genotype?
  - Dalton Conley, Benjamin W. Domingue, David Cesarini, Christopher Dawes, Cornelius A. Rietveld, Jason D. Boardman
  - 2015-02-25
  - 10.15195/v2.a6
  - ! 'Parental education is the strongest measured predictor of offspring education, and thus many scholars see the parent–child correlation in educational attainment as an important measure of social mobility. But if social changes or policy interventions are going to have dynastic effects, we need to know what accounts for this intergenerational association, that is, whether it is primarily environmental or genetic in origin. Thus, to understand whether the estimated social influence of parental education on offspring education is biased owing to genetic inheritance (or moderated by it), we exploit the findings from a recent large genome-wide association study of educational attainment to construct a genetic score designed to predict educational attainment. Using data from two independent samples, we find that our genetic score significantly predicts years of schooling in both between-family and within-family analyses. We report three findings that should be of interest to scholars in the stratification and education fields. First, raw parent–child correlations in education may reflect one-sixth genetic transmission and five-sixths social inheritance. Second, conditional on a child’s genetic score, a parental genetic score has no statistically significant relationship to the child’s educational attainment. Third, the effects of offspring genotype do not seem to be moderated by measured sociodemographic variables at the parental level (but parent–child genetic interaction effects are significant). These results are consistent with the existence of two separate systems of ascription: genetic inheritance (a random lottery within families) and social inheritance (across-family ascription). We caution, however, that at the presently attainable levels of explanatory power, these results are preliminary and may change when better-powered genetic risk scores are developed.'
- - https://www.psychologytoday.com/files/attachments/56143/wai-americas-elite-2013.pdf
  - ! "Investigating America's elite: Cognitive ability, education, and sex differences"
  - Jonathan Wai
  - 2013-03-25
  - '10.1016/j.intell.2013.03.005'
  - ! "Are the American elite drawn from the cognitive elite? To address this, five groups of America's elite (total <em>N</em> = 2254) were examined: Fortune 500 CEOs, federal judges, billionaires, Senators, and members of the House of Representatives. Within each of these groups, nearly all had attended college with the majority having attended either a highly selective undergraduate institution or graduate school of some kind. High average test scores required for admission to these institutions indicated those who rise to or are selected for these positions are highly filtered for ability. Ability and education level differences were found across various sectors in which the billionaires earned their wealth (e.g., technology vs. fashion and retail); even within billionaires and CEOs wealth was found to be connected to ability and education. Within the Senate and House, Democrats had a higher level of ability and education than Republicans. Females were underrepresented among all groups, but to a lesser degree among federal judges and Democrats and to a larger degree among Republicans and CEOs. America's elite are largely drawn from the intellectually gifted, with many in the top 1% of ability."
- - https://www.pawsoflife.org/Library/Temperment/Sinn%202010.pdf
  - 'Personality and performance in military working dogs: Reliability and predictive validity of behavioral tests'
  - David L. Sinna, Samuel D. Goslinga, Stewart Hilliard
  - 2010-09-09
  - 10.1016/j.applanim.2010.08.007
  - ! 'Quantification and description of individual differences in behavior, or personality differences, is now well-established in the working dog literature. What is less well-known is the predictive relationship between particular dog behavioral traits (if any) and important working outcomes. Here we evaluate the validity of a dog behavioral test instrument given to military working dogs (MWDs) from the 341<sup>st</sup> Training Squadron, USA Department of Defense (DoD); the test instrument has been used historically to select dogs to be trained for deployment. A 15-item instrument was applied on three separate occasions prior to training in patrol and detection tasks, after which dogs were given patrol-only, detection-only, or dual-certification status. On average, inter-rater reliability for all 15 items was high (mean = 0.77), but within this overall pattern, some behavioral items showed lower inter-rater reliability at some time points (&lt;0.40). Test–retest reliability for most (but not all) single item behaviors was strong (&gt;0.50) across shorter test intervals, but decreased with increasing test interval (&lt;0.40). Principal components analysis revealed four underlying dimensions that summarized test behavior, termed here ‘object focus’, ‘sharpness’, ‘human focus’, and ‘search focus’. These four aggregate behavioral traits also had the same pattern of short-, but not long-term test–retest reliability as that observed for single item behaviors. Prediction of certification outcomes using an independent test data set revealed that certification outcomes could not be predicted by breed, sex, or early test behaviors. However, prediction was improved by models that included two aggregate behavioral trait scores and three single item behaviors measured at the final test period, with 1 unit increases in these scores resulting in 1.7–2.8 increased odds of successful dual- and patrol-only certification outcomes. No improvements to odor-detection certification outcomes were made by any model. While only modest model improvements in prediction error were made by using behavioral parameters (2–7%), model predictions were based on data from dogs that had successfully completed all three test periods only, and therefore did not include data from dogs that were rejected during testing or training due to behavioral or medical reasons. Thus, future improvements to predictive models may be more substantial using independent predictors with less restrictions in range. Reports of the reliability and validity estimates of behavioral instruments currently used to select MWDs are scarce, and we discuss these results in terms of improving the efficiency by which working dog programs may select dogs for patrol and odor-detection duties using behavioral pre-screening instruments.'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4183313/bin/pnas.1404623111.sapp.pdf
  - Proxy-Phenotype Method Identifies Common Genetic Variants Associated with Cognitive Performance
  - Rietveld et al 2014
  - 2015-01-08
  - '10.1073/pnas.1404623111'
  - ! 'This document provides further details about materials, methods and additional analyses to accompany the research report “Proxy-Phenotype Method Identifies Common Genetic Variants Associated with Cognitive Performance.”'
- - https://www.mattblaze.org/papers/humancambridgepreproc.pdf
  - Toward a Broader View of Security Protocols
  - Matt Blaze
  - 2004-03-06
  - ''
  - ! 'This position paper initiates and advocates the study of “Human-Scale Security Protocols” as a core activity of computing and network security research. The Human-Scale Security Protocols (HSSP) project treats “human scale” security problems and protocols as a central part of computer science. Our aim is to identify, stimulate research on, analyze, and improve “non-traditional” protocols that might either have something to teach us or be susceptible to improvement via the techniques and tools of computer security. There are compelling security problems across a wide spectrum of areas that do not outwardly involve computers or electronic communication and yet are remarkably similar in structure to the systems computer scientists routinely study. Interesting and relevant problem spaces that computer security has traditionally ignored range from the very serious (preventing terrorists from subverting aviation security) to the trivial and personal (ensuring that a restaurant serves the same wine that was ordered and charged for).'
- - https://www.mathematica-mpr.com/-/media/publications/pdfs/nonexperimentalreps.pdf'
  - ! 'Nonexperimental Replications of Social Experiments: A Systematic Review'
  - Steven Glazerman, Dan M. Levy, David Myers
  - 2002-09
  - ''
  - ! 'Controlled experiments, where subjects are randomly assigned to receive interventions, are desirable but frequently perceived to be infeasible or overly burdensome, especially in social settings. Therefore, nonexperimental (also called quasi-experimental) methods are often used instead. Quasi-experimental methods are less intrusive and sometimes less costly than controlled experiments, but their validity rests on particular assumptions that are often difficult to test. It is therefore important to find empirical evidence to assess the likelihood that a given method applied in a given context will yield unbiased estimates. The current study is a systematic review of validation research to better understand the conditions under which quasiexperimental methods most closely approximate the results that would be found in a well-designed and well-executed experimental study. We collect and summarize a set of earlier studies that each tried, using convenience samples and one or more quasi-experimental methods, to replicate the findings from a social experiment. Our synthesis aims to give both producers and consumers of social program evaluations a clear understanding of what we know and what we do not know about the performance of quasi-experimental evaluation methods.'
- - https://www.dropbox.com/s/77amimyqhy9cjuu/2007-chiang-themerchantandthealchemistsgate.pdf
  - ! "The Merchant and the Alchemist's Gate"
  - Ted Chiang
  - 2007-09
  - ''
  - ! 'This fantasy short story by Ted Chiang follows Fuwaad ibn Abbas, a fabric merchant in the ancient city of Baghdad. It begins when he is searching for a gift to give a business associate and happens to discover a new shop in the marketplace. The shop owner, who makes and sells a variety of very interesting items, invites Fuwaad into the back workshop to see a mysterious black stone arch which serves as a gateway into the future, which the shop owner has made by the use of alchemy. Fuwaad is intrigued, and the shop owner tells him 3 stories of others who have traveled through the gate to meet and have conversation with their future selves. When Fuwaad learns that the shop keeper has another gate in Cairo that will allow people to travel even into the past, he makes the journey there to try to rectify a mistake he made 20 years earlier. [Summary adapted from Wikipedia]'
- - ! 'https://web.archive.org/web/20171025150859/http://nitro.biosci.arizona.edu:80/zbook/NewVolume_2/pdf/Chapter38.pdf'
  - 'Applications of Index Selection'
  - 'Bruce Walsh, Michael Lynch'
  - '1997-08-04'
  - ''
  - ! 'The first topic, which consists of the bulk of this chapter, is using index selection to improve a single trait. One can have a number of measures of the same trait in either relatives of a focal individual or as multiple measures of the same trait in a single individual, or both. How does one best use this information? We start by developing the general theory for using an index to improve the response in a single trait (which follows as a simplification of the Smith-Hazel index). We then apply these results to several important cases—a general analysis when either phenotypic or genotypic correlations are zero, improving response using repeated measurements of a characters over time, and using information from relatives to improve response with a special focus on combined selection (the optimal weighting of individual and family information, proving many of the details first presented in Chapter 17). As we will see in Chapter 35, the mixed-model power of BLUP provides a better solution to many of these problems, but index selection is both historically important as well as providing clean analytic results.  In contrast to the first topic, the final three are essentially independent of each other and we try to present them as such (so that the reader can simply turn to the section of interest without regard to previous material in this chapter). They include selection on a ratio, selection on sex-specific and sexually-dimorphic traits, and finally selection on the environmental variance σ<sup>2</sup><sub>E</sub> when it shows heritable variation (expanding upon results from Chapter 13).'
- - ! 'https://web.archive.org/web/20171025141547/http://nitro.biosci.arizona.edu:80/zbook/NewVolume_2/pdf/Chapter37.pdf'
  - Theory of Index Selection
  - Bruce Walsh, Michael Lynch
  - 1997-08-04
  - ''
  - ! 'While Chapters 28 and 29 present the basic theory for multivariate response, how, in practice, does one perform artificial selection on multiple traits? One of the commonest schemes is to construct some sort of index, wherein the investigator assigns (either explicitly or implicitly) a weighting scheme to each trait, creating a univariate character that becomes the target of selection. For example, if <em>z</em> is the vector of character values measured in an individual, the most common index is a linear combination <em>Pb<sub>i</sub>z<sub>i</sub> = b<sup>T</sup> z</em> and most of our discussion focuses on such linear indices. We start with a general review of the theory of selection on a linear index and then cover in great detail the Smith-Hazel index (the index giving the largest expected response in a specified linear combination of characters) and its extensions. We also discuss a number of other indices for different purposes, such as restricted (constraining changes in specified traits) and desired-gains (specifying how the components, rather than the index, will evolve) indices. We conclude our discussion of index selection by considering how to best handle nonlinear indices. We finish the chapter by examining the other approach for selecting on multiple traits, namely choosing traits sequentially. Tandem selection, focusing on a single trait each generation (where the focal trait changes over generations) is one such approach, while the other is to select different traits at different times within the life span of single individuals (independent culling and multistage index selection).'
- - ! 'https://tylermoore.utulsa.edu/toit17.pdf'
  - Revisiting the Risks of Bitcoin Currency Exchange Closure
  - Tyler Moore, Nicolas Christin, Janos Szurdi
  - '2016'
  - 10.1145/0000000.0000000
  - ! 'Bitcoin has enjoyed wider adoption than any previous cryptocurrency; yet its success has also attracted the attention of fraudsters who have taken advantage of operational insecurity and transaction irreversibility. We study the risk investors face from the closure of Bitcoin exchanges, which convert between Bitcoins and hard currency. We examine the track record of 80 Bitcoin exchanges established between 2010 and 2015. We find that nearly half (38) have since closed, with customer account balances sometimes wiped out. Fraudsters are sometimes to blame, but not always. 25 exchanges suffered security breaches, 15 of which subsequently closed. We present logistic regressions using using longitudinal data on Bitcoin exchanges aggregated quarterly. We find that experiencing a breach is correlated with a 13-times greater odds that an exchange will close in that same quarter. We find that higher-volume exchanges are less likely to close (each doubling in trade volume corresponds to a 12 percent decrease in the odds of closure). We also find that exchanges who derive most of their business from trading less popular (fiat) currencies, which are offered by at most one competitor, are less likely to close.'
- - ! 'https://sites.duke.edu/timurkuran/files/2017/09/Islam-Economic-Performance-Kuran-JEL-in-press.pdf'
  - 'Islam and Economic Performance: Historical and Contemporary Links'
  - Timur Kuran
  - '2018'
  - ''
  - ! 'This essay critically evaluates the analytic literature concerned with causal connections between Islam and economic performance. It focuses on works since 1997, when this literature was last surveyed. Among the findings are the following: Ramadan fasting by pregnant women harms prenatal development; Islamic charities mainly benefit the middle class; Islam affects educational outcomes less through Islamic schooling than through structural factors that handicap learning as a whole; Islamic finance hardly affects Muslim financial behavior; and low generalized trust depresses Muslim trade. The last feature reflects the Muslim world’s delay in transitioning from personal to impersonal exchange. The delay resulted from the persistent simplicity of the private enterprises formed under Islamic law. Weak property rights reinforced the private sector’s stagnation by driving capital out of commerce and into rigid waqfs. Waqfs limited economic development through their inflexibility and democratization by restraining the development of civil society. Parts of the Muslim world conquered by Arab armies are especially undemocratic, which suggests that early Islamic institutions, including slave-based armies, were particularly critical to the persistence of authoritarian patterns of governance. States have contributed themselves to the persistence of authoritarianism by treating Islam as an instrument of governance. As the world started to industrialize, non-Muslim subjects of Muslim-governed states pulled ahead of their Muslim neighbors by exercising the choice of law they enjoyed under Islamic law in favor of a Western legal system.'
- - https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.22.4.199
  - "Retrospectives Guinnessometrics: The Economic Foundation of “Student’s” t"
  - Stephen T. Ziliak
  - 2008-09
  - ''
  - ! 'In economics and other sciences, “statistical significance” is by custom, habit, and education a necessary and sufficient condition for proving an empirical result (Ziliak and McCloskey, 2008; McCloskey and Ziliak, 1996). The canonical routine is to calculate what’s called a t-statistic and then to compare its estimated value against a theoretically expected value of it, which is found in “Student’s” <em>t</em> table. A result yielding a <em>t</em>-value greater than or equal to about 2.0 is said to be “statistically significant at the 95 percent level.” Alternatively, a regression coefficient is said to be “statistically significantly different from the null, <em>p</em> &lt; .05.” Canonically speaking, if a coefficient clears the 95 percent hurdle, it warrants additional scientific attention. If not, not. The first presentation of “Student’s” test of significance came a century ago, in “The Probable Error of a Mean” (1908b), published by an anonymous “Student.” The author’s commercial employer required that his identity be shielded from competitors, but we have known for some decades that the article was written by William Sealy Gosset (1876–1937), whose entire career was spent at Guinness’s brewery in Dublin, where Gosset was a master brewer and experimental scientist (E. S. Pearson, 1937). Perhaps surprisingly, the ingenious “Student” did not give a hoot for a single finding of “statistical” significance, even at the 95 percent level of significance as established by his own tables. Beginning in 1904, “Student,” who was a businessman besides a scientist, took an economic approach to the logic of uncertainty, arguing finally that statistical significance is “nearly valueless” in itself.'
- - https://people.csail.mit.edu/pkrafft/papers/krafft-thesis-final.pdf
  - A Rational Choice Framework for Collective Behavior
  - Peter M. Krafft
  - 2017-09
  - ''
  - ! 'As the world becomes increasingly digitally mediated, people can more and more easily form groups, teams, and communities around shared interests and goals. Yet there is a constant struggle across forms of social organization to maintain stability and coherency in the face of disparate individual experiences and agendas. When are collectives able to function and thrive despite these challenges? In this thesis I propose a theoretical framework for reasoning about collective intelligence—the ability of people to accomplish their shared goals together. A simple result from the literature on multiagent systems suggests that strong general collective intelligence in the form of “rational group agency” arises from three conditions: aligned utilities, accurate shared beliefs, and coordinated actions. However, achieving these conditions can be difficult, as evidenced by impossibility results related to each condition from the literature on social choice, belief aggregation, and distributed systems. The theoretical framework I propose serves as a point of inspiration to study how human groups address these difficulties. To this end, I develop computational models of facets of human collective intelligence, and test these models in specific case studies. The models I introduce suggest distributed Bayesian inference as a framework for understanding shared belief formation, and also show that people can overcome other difficult computational challenges associated with achieving rational group agency, including balancing the group “exploration versus exploitation dilemma” for information gathering and inferring levels of “common p-belief” to coordinate actions.'
- - https://pdfs.semanticscholar.org/e17a/aaf487ec6415cac38e7e96490511e4b3b05d.pdf
  - "Why Aren’t We Smarter Already: Evolutionary Trade-Offs and Cognitive Enhancements"
  - Thomas T. Hills, Ralph Hertwig
  - '2011'
  - 10.1177/0963721411418300
  - ! 'Pharmacological enhancers of cognition promise a bright new future for humankind: more focus, more willpower, and better memory, with applications ranging from education to military combat. Underlying such promises is a linear, more-is-better vision of cognition that makes intuitive sense. This vision is at odds, however, with our understanding of cognition’s evolutionary origins. The mind has evolved under various constraints and consequently represents a delicate balance among these constraints. Evidence of the trade-offs that have shaped cognition include (a) inverted U-shaped performance curves commonly found in response to pharmacological interventions and (b) unintended side effects of enhancement on other traits. Taking an evolutionary perspective, we frame the above two sets of findings in terms of within-task (exemplified by optimal-control problems) and between-task (associated with a gain/loss asymmetry) trade-offs, respectively. With this framework, psychological science can provide much-needed guidance to enhancement development, a field that still lacks a theoretical foundation.'
- - https://pdfs.semanticscholar.org/b596/4787fc1abf739148d604abfbd2689e73e52f.pdf
  - The Fallacy Of The Null-Hypothesis Significance Test
  - William W. Rozeboom
  - '1960'
  - ''
  - ! 'In this paper, I wish to examine a dogma of inferential procedure which, for psychologists at least, has attained the status of a religious conviction. The dogma to be scrutinized is the "null-hypothesis significance test" orthodoxy that passing statistical judgment on a scientific hypothesis by means of experimental observation is a decision procedure wherein one rejects or accepts a null hypothesis according to whether or not the value of a sample statistic yielded by an experiment falls within a certain predetermined "rejection region" of its possible values. The thesis to be advanced is that despite the awesome preeminence this method has attained in our experimental journals and textbooks of applied statistics, it is based upon a fundamental misunderstanding of the nature of rational inference, and is seldom if ever appropriate to the aims of scientific research.'
- - https://pdfs.semanticscholar.org/76c6/ce0abf6f67f2c089df372261203989b43903.pdf
  - "Does Incubation Enhance Problem Solving? A Meta-Analytic Review"
  - Ut Na Sio, Thomas C. Ormerod
  - '2009'
  - 10.1037/a0014212
  - ! 'A meta-analytic review of empirical studies that have investigated incubation effects on problem solving is reported. Although some researchers have reported increased solution rates after an incubation period (i.e., a period of time in which a problem is set aside prior to further attempts to solve), others have failed to find effects. The analysis examined the contributions of moderators such as problem type, presence of solution-relevant or misleading cues, and lengths of preparation and incubation periods to incubation effect sizes. The authors identified a positive incubation effect, with divergent thinking tasks benefiting more than linguistic and visual insight tasks from incubation. Longer preparation periods gave a greater incubation effect, whereas filling an incubation period with high cognitive demand tasks gave a smaller incubation effect. Surprisingly, low cognitive demand tasks yielded a stronger incubation effect than did rest during an incubation period when solving linguistic insight problems. The existence of multiple types of incubation effect provides evidence for differential invocation of knowledge-based vs. strategic solution processes across different classes of problem, and it suggests that the conditions under which incubation can be used as a practical technique for enhancing problem solving must be designed with care.'
- - https://pdfs.semanticscholar.org/6698/bf91c9333faa0d333a800254b8063230d4f4.pdf
  - 'Optimizing retrieval as a learning event: When and why expanding retrieval practice enhances long-term retention'
  - Benjamin C. Storm, Robert Bjork, Jennifer C Storm
  - '2010'
  - 10.3758/MC.38.2.244
  - ! 'Retrieving information from memory makes that information more recallable in the future than it otherwise would have been. Optimizing retrieval practice has been assumed, on the basis of evidence and arguments tracing back to Landauer and Bjork (1978), to require an expanding-interval schedule of successive retrievals, but recent findings suggest that expanding retrieval practice may be inferior to uniform-interval retrieval practice when memory is tested after a long retention interval. We report three experiments in which participants read educational passages and were then repeatedly tested, without feedback, after an expanding or uniform sequence of intervals. On a test 1 week later, recall was enhanced by the expanding schedule, but only when the task between successive retrievals was highly interfering with memory for the passage. These results suggest that the extent to which learners benefit from expanding retrieval practice depends on the degree to which the to-be-learned information is vulnerable to forgetting.'
- - https://pdfs.semanticscholar.org/48cc/e5ee49facf75eeb12832c387452424b645dd.pdf
  - A Bayesian Framework for Reinforcement Learning
  - Malcolm Strens
  - 2000-06-28
  - ''
  - ! 'The reinforcement learning problem can be decomposed into two parallel types of inference: (i) estimating the parameters of a model for the underlying process; (ii) determining behavior which maximizes return under the estimated model. Following Dearden, Friedman and Andre (1999), it is proposed that the learning process estimates online the full posterior distribution over models. To determine behavior, a hypothesis is sampled from this distribution and the greedy policy with respect to the hypothesis is obtained by dynamic programming. By using a different hypothesis for each trial appropriate exploratory and exploitative behavior is obtained. This Bayesian method always converges to the optimal policy for a stationary process with discrete states.'
- - https://pdfs.semanticscholar.org/2e41/7612892dfb22ece5a98976a340d51dec06ed.pdf
  - IQ, Academic Performance, Environment and Earnings
  - Jeffrey S. Zax, Daniel I. Rees
  - 2001-05
  - ''
  - ! 'This paper explores the effects of peers, friends, family, IQ and academic performance, observed in the last year of high school, on earnings at ages 35 and 53. All significantly affect earnings at both ages. The effects of IQ are much smaller than asserted in, for example, <em>The Bell Curve</em>, and badly overstated in the absence of controls for family, wider context or academic performance. Aspirations appear to be very important. Socialization and role models may be as well, but not ability spillovers. Feasible increases in academic performance and education can compensate for the effects of many cognitive and contextual deficits. [This paper exemplifies the fallacy of controlling for intermediate variables&mdash;as if all those "controls" had nothing to do with IQ causing earnings! &mdash;Editor]'
- - https://ondoc.logand.com/d/2721/pdf
  - 'DARPA and the Quest for Machine Intelligence, 1983–1993'
  - Alex Roland, Philip Shiman
  - '2002'
  - ''
  - ! 'Between 1983 and 1993, the Defense Advanced Research Projects Agency (DARPA) spent an extra $1 billion on computer research to achieve machine intelligence.<sup>1</sup> The Strategic Computing Initiative (SCI) was conceived at the outset as an integrated plan to promote computer chip design and manufacturing, computer architecture, and artificial intelligence software. These technologies seemed ripe in the early 1980s. If only DARPA could connect them, it might achieve what Pamela McCorduck called “machines who think.” What distinguishes Strategic Computing (SC) from other stories of modern, large-scale technological development is that the program self-consciously set about advancing an entire research front. Instead of focusing on one problem after another, or of funding a whole field in hopes that all would prosper, SC treated intelligent machines as a single problem composed of interrelated subsystems. The strategy was to develop each of the subsystems cooperatively and map out the mechanisms by which they would connect. While most research programs entail tactics or strategy, SC boasted grand strategy, a master plan for an entire campaign.'
- - https://labs.la.utexas.edu/tucker-drob/files/2015/02/Hambrick-Tucker-Drob-2014-PBR-Genetics-of-Music-Accomplishment.pdf
  - 'The genetics of music accomplishment: Evidence for gene-environment correlation and interaction'
  - David Z. Hambrick, Elliot M. Tucker-Drob
  - '2014'
  - 10.3758/s13423-014-0671-9
  - ! 'Theories of skilled performance that emphasize training history, such as K. Anders Ericsson and colleagues’ deliberate-practice theory, have received a great deal of recent attention in both the scientific literature and the popular press. Twin studies, however, have demonstrated evidence for moderate-to-strong genetic influences on skilled performance. Focusing on musical accomplishment in a sample of over 800 pairs of twins, we found evidence for gene–environment correlation, in the form of a genetic effect on music practice. However, only about one quarter of the genetic effect on music accomplishment was explained by this genetic effect on music practice, suggesting that genetically influenced factors other than practice contribute to individual differences in music accomplishment. We also found evidence for gene-environment interaction, such that genetic effects on music accomplishment were most pronounced among those engaging in music practice, suggesting that genetic potentials for skilled performance are most fully expressed and fostered by practice.'
- - https://github.com/lllyasviel/style2paints/blob/master/papers/sa.pdf
  - Two-stage Sketch Colorization
  - Lvmin Zhang, Chengze Li, Tientsin Wong, Yi Ji, Chunping Liu
  - '2018'
  - 10.1145/3272127.3275090
  - ! 'Sketch or line art colorization is a research field with significant market demand. Different from photo colorization which strongly relies on texture information, sketch colorization is more challenging as sketches may not have texture. Even worse, color, texture, and gradient have to be generated from the abstract sketch lines. In this paper, we propose a semi-automatic learning-based framework to colorize sketches with proper color, texture as well as gradient. Our framework consists of two stages. In the first drafting stage, our model guesses color regions and splashes a rich variety of colors over the sketch to obtain a color draft. In the second refinement stage, it detects the unnatural colors and artifacts, and try to fix and refine the result. Comparing to existing approaches, this two-stage design effectively divides the complex colorization task into two simpler and goal-clearer subtasks. This eases the learning and raises the quality of colorization. Our model resolves the artifacts such as water-color blurring, color distortion, and dull textures.  We build an interactive software based on our model for evaluation. Users can iteratively edit and refine the colorization. We evaluate our learning model and the interactive system through an extensive user study. Statistics shows that our method outperforms the state-of-art techniques and industrial applications in several aspects including, the visual quality, the ability of user control, user experience, and other metrics.'
- - https://academic.oup.com/beheco/article/21/3/639/220022
  - Social context of shell acquisition in Coenobita clypeatus hermit crabs
  - Randi D. Rotjan, Jeffrey R. Chabot, Sara M. Lewis
  - 2010-04-01
  - 10.1093/beheco/arq027
  - ! 'Vacancy chains involve unique patterns of resource acquisition behaviors that determine how reusable resources are distributed through animal populations. Shell vacancy chains have been described for several hermit crab species, both terrestrial and marine, but little is known about the ecological and behavioral dynamics of shell choice in social versus solitary contexts. Here, we present a novel conceptual framework that differentiates 2 types of shell vacancy chain in hermit crabs and discuss fundamentally distinct predictions concerning the behavioral and ecological costs and benefits associated with synchronous versus asynchronous vacancy chains. In laboratory studies of the terrestrial hermit crab <em>Coenobita clypeatus</em>, we found support for the prediction that social context alters shell acquisition behaviors. Field observations demonstrated that both synchronous and asynchronous vacancy chains are common and revealed previously undescribed waiting and piggybacking behaviors that appear to facilitate synchronous vacancy chains. Additionally, simulation results from an agent-based model showed that population density and waiting behaviors can both influence the likelihood of synchronous vacancy chains. Together, these results indicate that better understanding of hermit crab resource acquisition requires studying social behaviors, including vacancy chain formation.'
- - https://mpra.ub.uni-muenchen.de/74268/1/MPRA_paper_74268.pdf
  - Redundancy, Unilateralism and Bias beyond GDP – results of a Global Index Benchmark
  - Alexander Dill, Nicolas Gebhart
  - 2016-09-25
  - ''
  - ! 'Eight out of ten leading international indices to assess developing countries in aspects beyond GDP are showing strong redundancy, bias and unilateralism. The quantitative comparison gives evidence for the fact that always the same countries lead the ranks with a low standard deviation. The dependency of the GDP is striking: do the indices only measure indicators that are direct effects of a strong GDP? While the impact of GDP can be discussed reverse as well, the standard deviation shows a strong bias: only one out of the twenty countries with the highest standard deviation is among the Top-20 countries of the world, but 11 countries among those with the lowest standard deviation. Let’s have a look at the backsides of global statistics and methods to compare their findings. The article is the result of a pre-study to assess Social Capital for development countries made for the German Federal Ministry for Economic Cooperation and Development. The study led to the UN Sustainable Development Goals (UN SDG) project World Social Capital Monitor.'
- - http://www.incompleteideas.net/IncIdeas/BitterLesson.html
  - The Bitter Lesson
  - Rich Sutton
  - 2019-03-13
  - ''
  - ! '<p><strong>The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective</strong>, and by a large margin. The ultimate reason for this is Moore’s law, or rather its generalization of continued exponentially falling cost per unit of computation. Most AI research has been conducted as if the computation available to the agent were constant (in which case leveraging human knowledge would be one of the only ways to improve performance) but, over a slightly longer time than a typical research project, massively more computation inevitably becomes available. Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation.</p><p>…In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer-chess researchers who had pursued methods that leveraged human understanding of the special structure of chess…A similar pattern of research progress was seen in computer Go, only delayed by a further 20 years. Enormous initial efforts went into avoiding search by taking advantage of human knowledge, or of the special features of the game, but all those efforts proved irrelevant, or worse, once search was applied effectively at scale…In speech recognition, there was an early competition, sponsored by DARPA, in the 1970s. Entrants included a host of special methods that took advantage of human knowledge—knowledge of words, of phonemes, of the human vocal tract, etc. On the other side were newer methods that were more statistical in nature and did much more computation, based on hidden Markov models (HMMs). Again, the statistical methods won out over the human-knowledge-based methods… In computer vision…Modern deep-learning neural networks use only the notions of convolution and certain kinds of invariances, and perform much better.</p><p>…We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that (1) AI researchers have often tried to build knowledge into their agents, (2) this always helps in the short term, and is personally satisfying to the researcher, but (3) in the long run it plateaus and even inhibits further progress, and (4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.</p>'
- - /docs/genetics/heritable/2019-khera.pdf
  - Rare Genetic Variants Associated With Sudden Cardiac Death in Adults
  - Amit V. Khera, Heather Mason-Suares, Deanna Brockman, Minxian Wang, Martin J. VanDenburgh, Ozlem Senol-Cosar, Candace Patterson, Christopher Newton-Cheh, Seyedeh M. Zekavat, Julie Pester, Daniel I. Chasman, Christopher Kabrhel, Majken K. Jensen, JoAnn E. Manson, J. Michael Gaziano, Kent D. Taylor, Nona Sotoodehnia, Wendy S. Post, Stephen S. Rich, Jerome I. Rotter, Eric S. Lander, Heidi L. Rehm, Kenney Ng, Anthony Philippakis, Matthew Lebo, Christine M. Albert, Sekar Kathiresan
  - 2019-11-18
  - 10.1016/j.jacc.2019.08.1060
  - ! '<p><em>Background</em>: Sudden cardiac death occurs in ∼220,000 U.S. adults annually, the majority of whom have no prior symptoms or cardiovascular diagnosis. Rare pathogenic DNA variants in any of 49 genes can pre-dispose to 4 important causes of sudden cardiac death: cardiomyopathy, coronary artery disease, inherited arrhythmia syndrome, and aortopathy or aortic dissection.</p><p><em>Objectives</em>: This study assessed the prevalence of rare pathogenic variants in sudden cardiac death cases versus controls, and the prevalence and clinical importance of such mutations in an asymptomatic adult population.</p><p><em>Methods</em>: The authors performed whole-exome sequencing in a case-control cohort of 600 adult-onset sudden cardiac death cases and 600 matched controls from 106,098 participants of 6 prospective cohort studies. Observed DNA sequence variants in any of 49 genes with known association to cardiovascular disease were classified as pathogenic or likely pathogenic by a clinical laboratory geneticist blinded to case status. In an independent population of 4,525 asymptomatic adult participants of a prospective cohort study, the authors performed whole-genome sequencing and determined the prevalence of pathogenic or likely pathogenic variants and prospective association with cardiovascular death.</p><p><em>Results</em>: Among the 1,200 sudden cardiac death cases and controls, the authors identified 5,178 genetic variants and classified 14 as pathogenic or likely pathogenic. These 14 variants were present in 15 individuals, all of whom had experienced sudden cardiac death—corresponding to a pathogenic variant prevalence of 2.5% in cases and 0% in controls (<em>p</em> &lt; 0.0001). Among the 4,525 participants of the prospective cohort study, 41 (0.9%) carried a pathogenic or likely pathogenic variant and these individuals had 3.24-fold higher risk of cardiovascular death over a median follow-up of 14.3 years (<em>p</em> = 0.02).</p><p><em>Conclusions</em>: Gene sequencing identifies a pathogenic or likely pathogenic variant in a small but potentially important subset of adults experiencing sudden cardiac death; these variants are present in ∼1% of asymptomatic adults.</p>'
- - /docs/genetics/heritable/2016-bagnall.pdf
  - A Prospective Study of Sudden Cardiac Death among Children and Young Adults
  - Richard D. Bagnall, Robert G. Weintraub, Jodie Ingles, Johan Duflou, Laura Yeates, Lien Lam, Andrew M. Davis, Tina Thompson, Vanessa Connell, Jennie Wallace, Charles Naylor, Jackie Crawford, Donald R. Love, Lavinia Hallam, Jodi White, Christopher Lawrence, Matthew Lynch, Natalie Morgan, Paul James, Desirée du Sart, Rajesh Puranik, Neil Langlois, Jitendra Vohra, Ingrid Winship, John Atherton, Julie McGaughran, Jonathan R. Skinner, Christopher Semsarian
  - 2016-06-23
  - 10.1056/NEJMoa1510687
  - ! '<p><em>Background</em>: Sudden cardiac death among children and young adults is a devastating event. We performed a prospective, population-based, clinical and genetic study of sudden cardiac death among children and young adults.</p><p><em>Methods</em>: We prospectively collected clinical, demographic, and autopsy information on all cases of sudden cardiac death among children and young adults 1 to 35 years of age in Australia and New Zealand from 2010 through 2012. In cases that had no cause identified after a comprehensive autopsy that included toxicologic and histologic studies (unexplained sudden cardiac death), at least 59 cardiac genes were analyzed for a clinically relevant cardiac gene mutation.</p><p><em>Results</em>: A total of 490 cases of sudden cardiac death were identified. The annual incidence was 1.3 cases per 100,000 persons 1 to 35 years of age; 72% of the cases involved boys or young men. Persons 31 to 35 years of age had the highest incidence of sudden cardiac death (3.2 cases per 100,000 persons per year), and persons 16 to 20 years of age had the highest incidence of unexplained sudden cardiac death (0.8 cases per 100,000 persons per year). The most common explained causes of sudden cardiac death were coronary artery disease (24% of cases) and inherited cardiomyopathies (16% of cases). Unexplained sudden cardiac death (40% of cases) was the predominant finding among persons in all age groups, except for those 31 to 35 years of age, for whom coronary artery disease was the most common finding. Younger age and death at night were independently associated with unexplained sudden cardiac death as compared with explained sudden cardiac death. A clinically relevant cardiac gene mutation was identified in 31 of 113 cases (27%) of unexplained sudden cardiac death in which genetic testing was performed. During follow-up, a clinical diagnosis of an inherited cardiovascular disease was identified in 13% of the families in which an unexplained sudden cardiac death occurred.</p><p><em>Conclusions</em>: The addition of genetic testing to autopsy investigation substantially increased the identification of a possible cause of sudden cardiac death among children and young adults.</p>'
- - https://www.newscientist.com/article/2224569-controversial-dna-screening-technique-used-for-at-least-one-pregnancy/
  - Controversial DNA screening technique used for at least one pregnancy
  - Michael Le Page (<em>New Scientist</em>)
  - 2019-11-22
  - ''
  - ! '<p>A company called Genomic Prediction has confirmed that at least one woman is pregnant with embryos selected after analysing hundreds of thousands of DNA variants to assess the risk of disease. It is the first time this approach has been used for screening IVF embryos, but some don’t think this use of the technology is justified.</p><p>“Embryos have been chosen to reduce disease risk using pre-implantation genetic testing for polygenic traits, and this has resulted in pregnancy,” Laurent Tellier, CEO of Genomic Prediction, told New Scientist. He didn’t say how many pregnancies there were, or what traits or conditions were screened for.</p>'
- - /docs/genetics/editing/2019-anzalone.pdf
  - 'Search-and-replace genome editing without double-strand breaks or donor DNA'
  - Andrew V. Anzalone, Peyton B. Randolph, Jessie R. Davis, Alexander A. Sousa, Luke W. Koblan, Jonathan M. Levy, Peter J. Chen, Christopher Wilson, Gregory A. Newby, Aditya Raguram, David R. Liu
  - '2019-10-21'
  - '10.1038/s41586-019-1711-4'
  - ! 'Most genetic variants that contribute to disease<sup>1</sup> are challenging to correct efficiently and without excess byproducts<sup>2,3,4,5</sup>. Here we describe prime editing, a versatile and precise genome editing method that directly writes new genetic information into a specified DNA site using a catalytically impaired Cas9 endonuclease fused to an engineered reverse transcriptase, programmed with a prime editing guide RNA (pegRNA) that both specifies the target site and encodes the desired edit. We performed more than 175 edits in human cells, including targeted insertions, deletions, and all 12 types of point mutation, without requiring double-strand breaks or donor DNA templates. We used prime editing in human cells to correct, efficiently and with few byproducts, the primary genetic causes of sickle cell disease (requiring a transversion in HBB) and Tay–Sachs disease (requiring a deletion in HEXA); to install a protective transversion in PRNP; and to insert various tags and epitopes precisely into target loci. Four human cell lines and primary post-mitotic mouse cortical neurons support prime editing with varying efficiencies. Prime editing shows higher or similar efficiency and fewer byproducts than homology-directed repair, has complementary strengths and weaknesses compared to base editing, and induces much lower off-target editing than Cas9 nuclease at known Cas9 off-target sites. Prime editing substantially expands the scope and capabilities of genome editing, and in principle could correct up to 89% of known genetic variants associated with human diseases.'
- - https://www.wired.com/story/a-new-crispr-technique-could-fix-many-more-genetic-diseases/
  - ! 'A New Crispr Technique Could Fix Almost All Genetic Diseases: A less error-prone DNA editing method could correct many more harmful mutations than was previously possible'
  - Megan Molteni (<em>Wired</em>)
  - 2019-10-21
  - ''
  - ! '<p>Crispr, for all its DNA-snipping precision, has always been best at breaking things. But if you want to replace a faulty gene with a healthy one, things get more complicated. In addition to programming a piece of guide RNA to tell Crispr where to cut, you have to provide a copy of the new DNA and then hope the cell’s repair machinery installs it correctly. Which, spoiler alert, it often doesn’t. Anzalone wondered if instead there was a way to combine those two pieces, so that one molecule told Crispr both where to make its changes and what edits to make. Inspired, he cinched his coat tighter and hurried home to his apartment in Chelsea, sketching and Googling late into the night to see how it might be done.</p><p>A few months later, his idea found a home in the lab of David Liu, the Broad Institute chemist who’d recently developed a host of more surgical Crispr systems, known as base editors. Anzalone joined Liu’s lab in 2018, and together they began to engineer the Crispr creation glimpsed in the young post-doc’s imagination. After much trial and error, they wound up with something even more powerful. The system, which Liu’s lab has dubbed “prime editing,” can for the first time make virtually any alteration—additions, deletions, swapping any single letter for any other—without severing the DNA double helix. “If Crispr-Cas9 is like scissors and base editors are like pencils, then you can think of prime editors to be like word processors,” Liu told reporters in a press briefing.</p><p>Why is that a big deal? Because with such fine-tuned command of the genetic code, prime editing could, according to Liu’s calculations, correct around 89% of the mutations that cause heritable human diseases. Working in human cell cultures, his lab has already used prime editors to fix the genetic glitches that cause sickle cell anemia, cystic fibrosis, and Tay-Sachs disease. Those are just three of more than 175 edits the group unveiled today in a scientific article published in the journal <em>Nature</em>.</p><p>The work “has a strong potential to change the way we edit cells and be transformative,” says Gaétan Burgio, a geneticist at the Australian National University who was not involved in the work, in an email. He was especially impressed at the range of changes prime editing makes possible, including adding up to 44 DNA letters and deleting up to 80. “Overall, the editing efficiency and the versatility shown in this paper are remarkable.”</p><p>…The bigger problem, according to folks like Burgio, is that prime editors are huge, in molecular terms. They’re so big that they won’t pack up neatly into the viruses researchers typically use to shuttle editing components into cells. These colossi might even clog a microinjection needle, making it difficult to deliver into mouse (or potentially human) embryos. That, says Burgio, could make prime editing a lot less practical than existing techniques.</p>'
- - https://www.sciencemag.org/news/2019/10/new-prime-genome-editor-could-surpass-crispr
  - New ‘prime’ genome editor could surpass CRISPR
  - Jon Cohen (<em>Science Magazine</em>)
  - 2019-10-21
  - 10.1126/science.aaz9297
  - ! '<p>CRISPR, an extraordinarily powerful genome-editing tool invented in 2012, can still be clumsy. It sometimes changes genes it shouldn’t, and it edits by hacking through both strands of DNA’s double helix, leaving the cell to clean up the mess—shortcomings that limit its use in basic research and agriculture and pose safety risks in medicine. But a new entrant in the race to refine CRISPR promises to steer around some of its biggest faults. “It’s a huge step in the right direction,” chemist George Church, a CRISPR pioneer at Harvard University, says about the work, which appears online today in <em>Nature</em>.</p><p>…Liu’s earlier handwork, base editing, does not cut the double-stranded DNA but instead uses the CRISPR targeting apparatus to shuttle an additional enzyme to a desired sequence, where it converts a single nucleotide into another. Many genetic traits and diseases are caused by a single nucleotide change, so base editing offers a powerful alternative for biotechnology and medicine. But the method has limitations, and it, too, often introduces off-target mutations.</p><p>Prime editing steers around shortcomings of both techniques by heavily modifying the Cas9 protein and the guide RNA. The altered Cas9 only “nicks” a single strand of the double helix, instead of cutting both. The new guide, called a pegRNA, contains an RNA template for a new DNA sequence, to be added to the genome at the target location. That requires a second protein, attached to Cas9: a reverse transcriptase enzyme, which can make a new DNA strand from the RNA template and insert it at the nicked site.</p><p>Liu, who has already formed a company around the new technology, Prime Medicine, stresses that to gain a place in the editing toolkit, it will have to prove robust and useful in many labs. Delivering the large construct of RNA and enzymes into living cells will also be difficult, and no one has yet shown it can work in an animal model.</p>'
- - https://openreview.net/forum?id=r1lyTjAqYX#deepmind
  - Recurrent Experience Replay in Distributed Reinforcement Learning
  - Steven Kapturowski, Georg Ostrovski, John Quan, Remi Munos, Will Dabney
  - 2018-09-27
  - ''
  - ! '<p><em>Abstract</em>: Building on the recent successes of distributed training of RL agents, in this paper we investigate the training of RNN-based RL agents from distributed prioritized experience replay. We study the effects of parameter lag resulting in representational drift and recurrent state staleness and empirically derive an improved training strategy. Using a single network architecture and fixed set of hyper-parameters, the resulting agent, Recurrent Replay Distributed DQN (R2D2), quadruples the previous state of the art on Atari-57, and matches the state of the art on DMLab-30. It is the first agent to exceed human-level performance in 52 of the 57 Atari games.</p><p><em>Keywords</em>: RNN, LSTM, experience replay, distributed training, reinforcement learning</p><p><em>TL;DR</em>: Investigation on combining recurrent neural networks and experience replay leading to state-of-the-art agent on both Atari-57 and DMLab-30 using single set of hyper-parameters.</p>'
- - https://www.pnas.org/content/116/47/23505
  - A single combination gene therapy treats multiple age-related diseases
  - Noah Davidsohn, Matthew Pezzone, Andyna Vernet, Amanda Graveline, Daniel Oliver, Shimyn Slomovic, Sukanya Punthambaker, Xiaoming Sun, Ronglih Liao, Joseph V. Bonventre, George M. Church
  - 2019-11-19
  - 10.1073/pnas.1910073116
  - ! '<p><em>Significance</em>: Human and animal longevity is directly bound to their health span. While previous studies have provided evidence supporting this connection, therapeutic implementation of this knowledge has been limited. Traditionally, diseases are researched and treated individually, which ignores the interconnectedness of age-related conditions, necessitates multiple treatments with unrelated substances, and increases the accumulative risk of side effects. In this study, we address and overcome this deadlock by creating adeno-associated virus (AAV)-based antiaging gene therapies for simultaneous treatment of several age-related diseases. We demonstrate the modular and extensible nature of combination gene therapy by testing therapeutic AAV cocktails that confront multiple diseases in a single treatment. We observed that 1 treatment comprising 2 AAV gene therapies was efficacious against all 4 diseases.</p><p><em>Abstract</em>: Comorbidity is common as age increases, and currently prescribed treatments often ignore the interconnectedness of the involved age-related diseases. The presence of any one such disease usually increases the risk of having others, and new approaches will be more effective at increasing an individual’s health span by taking this systems-level view into account. In this study, we developed gene therapies based on 3 longevity associated genes (fibroblast growth factor 21 [FGF21], αKlotho, soluble form of mouse transforming growth factor-β receptor 2 [sTGFβR2]) delivered using adeno-associated viruses and explored their ability to mitigate 4 age-related diseases: obesity, type II diabetes, heart failure, and renal failure. Individually and combinatorially, we applied these therapies to disease-specific mouse models and found that this set of diverse pathologies could be effectively treated and in some cases, even reversed with a single dose. We observed a 58% increase in heart function in ascending aortic constriction ensuing heart failure, a 38% reduction in α-smooth muscle actin (αSMA) expression, and a 75% reduction in renal medullary atrophy in mice subjected to unilateral ureteral obstruction and a complete reversal of obesity and diabetes phenotypes in mice fed a constant high-fat diet. Crucially, we discovered that a single formulation combining 2 separate therapies into 1 was able to treat all 4 diseases. These results emphasize the promise of gene therapy for treating diverse age-related ailments and demonstrate the potential of combination gene therapy that may improve health span and longevity by addressing multiple diseases at once. [Keywords: gene therapy, AAV, combination therapy, age-related diseases]</p>'
- - https://jetpress.org/volume1/moravec.htm
  - When will computer hardware match the human brain?
  - Hans Moravec
  - '1998'
  - ''
  - ! 'This paper describes how the performance of AI machines tends to improve at the same pace that AI researchers get access to faster hardware. The processing power and memory capacity necessary to match general intellectual performance of the human brain are estimated. Based on extrapolation of past trends and on examination of technologies under development, it is predicted that the required hardware will be available in cheap machines in the 2020s...At the present rate, computers suitable for human-like robots will appear in the 2020s. Can the pace be sustained for another three decades?'
- - https://d4mucfpksywv.cloudfront.net/papers/GPT_2_Report.pdf#openai
  - Release Strategies and the Social Impacts of Language Models
  - Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, Jasmine Wang
  - '2019-11-05'
  - ''
  - ! '<p>GPT-2 is a large-scale unsupervised language model that generates coherent paragraphs of text, first announced by OpenAI in February 2019<sup>[63]</sup>. We developed four variants of the model, ranging in size from small (124 million parameters) to large (~1.5 billion parameters). We chose a staged release process, releasing the smallest model in February, but withholding larger models due to concerns about the potential for misuse, such as generating fake news content, impersonating others in email, or automating abusive social media content production<sup>[54]</sup>. We released the 355 million parameter model in May as part of a staged release process. We released our 774 million parameter model in August with a six-month follow up announcement, and we are now releasing our 1.5 billion parameter model.</p><p>While large language models’ flexibility and generative capabilities raise misuse concerns, they also have a range of beneficial uses—they can assist in prose, poetry, and programming; analyze dataset biases; and more. We want to release systems that will have a widely-distributed positive impact on society and have low misuse potential, and have striven to make release decisions informed by analysis,engagement, and empirical evidence.</p><p>Instead of releasing the full 1.5 billion model in February, we adopted a ‘staged release’ process. This delay of nine months allowed time between model releases to conduct risk and benefit analyses as model sizes increased. We also hope our staged release process was helpful in allowing others time to adapt and react: giving researchers a chance to mitigate risk of potential misuse, and giving the general public time to adapt to a world in which it is prudent to mistrust everything they read a little more. In addition to finding minimal evidence of misuse so far, several other factors contributed to our confidence in publishing our 774 million and 1.5 billion parameter models. These include what we learned about the positive social impact of beneficial uses, and what we learned through our partnerships among the AI community and through discussions across fields about establishing norms for responsible publication. This report discusses OpenAI’s work related to staged release of large models, partnership-based research, and broader issues in responsible publication that the AI community will need to address.</p><ul><li><p>Overview</p></li><li><p>Staged Release</p></li><li><p>Partnerships</p></li><li><p>Engagement</p></li><li><p>Social Impacts of Large Language Models</p><ul><li>Beneficial Use Potential</li><li>Misuse: Actor Assessment</li><li>Detecting Synthetic Text</li><li>Bias: Exploratory Research</li></ul></li><li><p>Future Trends in Language Models</p></li><li><p>Recommendations for Publication Norms in AI</p></li><li><p>Conclusion</p></li><li><p>Acknowledgments</p></li><li><p>References</p></li><li><p>Appendices</p><ul><li>Appendix A: Summary of Model Sharing Agreement</li><li>Appendix B: Release Timeline</li><li>Appendix C: Examples of Biases in GPT-2</li><li>Appendix D: Partner Research, Middlebury Institute of International Studies’ Center on Terrorism, Extremism, and Counterterrorism</li><li>Appendix E: Partner Research, Cornell University</li></ul></li></ul>'
- - https://openai.com/blog/gpt-2-1-5b-release/
  - ! 'GPT-2: 1.5B Release'
  - Irene Solaiman, Jack Clark, Miles Brundage
  - 2019-11-05
  - ''
  - ! '<p>As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we’ve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we’re actively continuing the conversation with the AI community on responsible publication.</p><p><em>Our findings</em>:</p><ol type="1"><li>Humans find GPT-2 outputs convincing.</li><li>GPT-2 can be fine-tuned for misuse.</li><li>Detection is challenging.</li><li>We’ve seen no strong evidence of misuse so far.</li><li>We need standards for studying bias.</li></ol><p>…<em>Next steps</em>: Our experience with GPT-2 over the past 9 months has given us valuable insight into the challenges and opportunities for creating responsible publication norms in AI. We’re continuing our work on this issue via participation in the Partnership on AI’s “Responsible Publication Norms for Machine Learning” project and discussions with our colleagues in the research community.</p>'
- - https://sites.google.com/view/videopredictioncapacity
  - ! 'High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks: Videos'
  - Ruben Villegas, Arkanath Pathak, Harini Kannan, Dumitru Erhan, Quoc V. Le, Honglak Lee
  - '2019'
  - ''
  - ! '<p>Sample videos generated by large-scale RNNs:</p><ul><li><p>128x128 Videos:</p><ul><li>Human 3.6M</li><li>KITTI Driving</li></ul></li><li><p>Video Comparisons (64x64):</p><ul><li>Towel pick</li><li>Human 3.6M</li><li>KITTI Driving</li><li>Towel pick</li><li>Human 3.6M</li><li>KITTI Driving</li></ul></li></ul>'
- - https://learningtopredict.github.io/
  - Learning to Predict Without Looking Ahead World Models Without Forward Prediction [blog writeup]
  - C. Daniel Freeman, Luke Metz, David Ha
  - 2019-10-29
  - ''
  - ! '<p>Much of model-based reinforcement learning involves learning a model of an agent’s world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware—e.g., a brain—arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call <em>observational dropout</em>, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into <em>learning</em> a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment.</p><p>[Image caption: “Our agents are only given infrequent observations of the real environment. As a side effect for optimizing performance in this setting, a “world model” emerges. We show the true dynamics in color, with full saturation denoting frames the policy can see. The black and white outline shows the state of the emergent world model. These world model exhibits similar, but not identical dynamics to forward predictive models but only model “important” aspects of the environment."]</p>'
- - http://www.aidungeon.io/2019/11/my-orc-band-and-our-quest-for-equal.html
  - 'AI Dungeon 2: My Musical Troupe of Orcs Uses Music to Advance Orc Rights'
  - Nick Walton
  - 2019-11-26
  - ''
  - ! '<p>[Demonstration dialogue of interacting with a GPT-2-1.5b trained on text adventures/RPGs. The player chooses to join a band of orcs as a musician and tries to steer the game towards orc rights, with moderate success, reaching the Emperor himself.]</p><p>In the first AI Dungeon, we created and deployed a deep learning generated text adventure using OpenAI’s 124M parameter GPT-2 model. In the interest of computational cost, possible actions and their results were generated and given to the player to choose from.</p><p>In AI Dungeon 2 we do away with pregenerated actions and allow the user to enter any action. The model then continues generating the story resulting from that action. We also upgrade the size of our model to OpenAI’s largest 1.5B parameter model and fine-tune it on a collection of text adventures obtained from <code>chooseyourstory.com</code>. Following the example of the <a href="https://arxiv.org/abs/1909.05858" title="&#39;CTRL: A Conditional Transformer Language Model for Controllable Generation&#39;, Keskar et al 2019">Salesforce CTRL model</a> we also modified the sampling of our model to add a penalty to already generated words to reduce the repetition issues that GPT-2 has and enable a lower temperature setting.</p><p>When playing AI Dungeon 2 the player can choose from several possible settings and characters. These choices generate a starting prompt and context sentence. The context sentence is always included as input to the model to help keep it grounded to the chosen setting while the starting prompt is the beginning of the story.</p> <p>[Dialogue sample:] </p> <p>...After the Gnoll War ends, the orcs decide to hold a big celebration. You immediately organize concert to entertain everyone. It goes well and you even win a few awards for your work. However, you still aren’t satisfied and you decide to do something else.</p><pre><code>&gt; write plays for the orcs to perform in</code></pre><p>You write a series of plays based on the stories of the orcs. These works are performed throughout the Empire and they are very popular. You also take an interest in the orcs’ future and begin to study their language and culture. In time you even develop a liking for the orcs themselves.</p><pre><code>&gt; found a human-orc friendship organization</code></pre><p>While you were studying the orcs, you came across a group called the Human-Orc Friendship Association (HOOFA). While they weren’t exactly like the Orcs, they had similar goals. You decided to form a separate chapter just for them.</p><pre><code>&gt; write some pamphlets support orc-human friendship</code></pre><p>You wrote a pamphlet explaining what the HOOFA was and how it worked. You also explained that the orcs were the only race that could truly understand each other and that humans were inferior to the orcs.</p><pre><code>&gt; promote inter-racial marriage between humans and orcs</code></pre><p>In order to promote inter-racial marriage between humans and orcs, you started a branch of the HOOFA called the Inter-Race Marriage Bureau (IRMB) which was located in the city of Kishak...</p>'
- - https://pkhungurn.github.io/talking-head-anime/
  - Talking Head Anime from a Single Image
  - Pramook Khungurn
  - 2019-11-25
  - ''
  - ! '<p>Fascinated by <a href="https://en.wikipedia.org/wiki/Virtual_YouTuber">virtual YouTubers</a>, I put together a deep neural network system that makes becoming one much easier. More specifically, the network takes as input an image of an anime character’s face and a desired pose, and it outputs another image of the same character in the given pose.'
- - /docs/conscientiousness/2019-wilmot.pdf
  - A century of research on conscientiousness at work
  - Michael P. Wilmot, Deniz S. Ones
  - 2019-11-12
  - 10.1073/pnas.1908430116
  - ! '<p><em>Significance</em>: Conscientiousness (C) is the most potent noncognitive predictor of occupational performance. However, questions remain about how C relates to a plethora of occupational variables, what its defining characteristics and functions are in occupational settings, and whether its performance relation differs across occupations. To answer these questions, we quantitatively review 92 meta-analyses reporting relations to 175 occupational variables. Across variables, results reveal a substantial mean effect of <em>ρ<sub>M</sub></em>=20.</p><p>We then use results to synthesize 10 themes that characterize C in occupational settings. Finally, we discover that performance effects of C are weaker in high-complexity versus low- to moderate-complexity occupations. Thus, for optimal occupational performance, we encourage decision makers to match C’s goal-directed motivation and behavioral restraint to more predictable environments.</p><p><em>Abstract</em>: Evidence from more than 100 y of research indicates that conscientiousness (C) is the most potent noncognitive construct for occupational performance. However, questions remain about the magnitudes of its effect sizes across occupational variables, its defining characteristics and functions in occupational settings, and potential moderators of its performance relation. Drawing on 92 unique meta-analyses reporting effects for 175 distinct variables, which represent <em>n</em> &gt; 1.1 million participants across <em>k</em> &gt; 2,500 studies, we present the most comprehensive, quantitative review and synthesis of the occupational effects of C available in the literature. Results show C has effects in a desirable direction for 98% of variables and a grand mean of <em>ρ<sub>M</sub></em>=0.20 (SD = 0.13), indicative of a potent, pervasive influence across occupational variables. Using the top 33% of effect sizes (<em>ρ</em>≥0.24), we synthesize 10 characteristic themes of C’s occupational functioning: (1) motivation for goal-directed performance, (2) preference for more predictable environments, (3) interpersonal responsibility for shared goals, (4) commitment, (5) perseverance, (6) self-regulatory restraint to avoid counterproductivity, and (7) proficient performance—especially for (8) conventional goals, (9) requiring persistence. Finally, we examine C’s relation to performance across 8 occupations. Results indicate that occupational complexity moderates this relation. That is, (10) high occupational complexity versus low-to-moderate occupational complexity attenuates the performance effect of C. Altogether, results suggest that goal-directed performance is fundamental to C and that motivational engagement, behavioral restraint, and environmental predictability influence its optimal occupational expression. We conclude by discussing applied and policy implications of our findings. [Keywords: conscientiousness, personality, meta-analysis, second-order meta-analysis, occupations]</p>'
- - https://www.nature.com/articles/d41586-019-03268-y
  - ! 'On the troubling trail of psychiatry’s pseudopatients stunt: Susannah Cahalan’s investigation of the social-psychology experiment that saw healthy people sent to mental hospitals finds inconsistencies'
  - ! 'Alison Abbott (<em>Nature</em>)'
  - ! '2019-10-29'
  - ! '10.1038/d41586-019-03268-y'
  - ! '<p>Although Rosenhan died in 2012, Cahalan easily tracked down his archives, held by social psychologist Lee Ross, his friend and colleague at Stanford. They included the first 200 pages of Rosenhan’s unfinished draft of a book about the experiment…Ross warned her that Rosenhan had been secretive. As her attempts to identify the pseudonymous pseudopatients hit one dead end after the other, she realized Ross’s prescience.</p><p>The archives did allow Cahalan to piece together the beginnings of the experiment in 1969, when Rosenhan was teaching psychology at Swarthmore College in Pennsylvania…Rosenhan cautiously decided to check things out for himself first. He emerged humbled from nine traumatizing days in a locked ward, and abandoned the idea of putting students through the experience.</p><p>…According to Rosenhan’s draft, it was at a conference dinner that he met his first recruits: a recently retired psychiatrist and his psychologist wife. The psychiatrist’s sister also signed up. But the draft didn’t explain how, when and why subsequent recruits signed up. Cahalan interviewed numerous people who had known Rosenhan personally or indirectly. She also chased down the medical records of individuals whom she suspected could have been involved in the experiment, and spoke with their families and friends. But her sleuthing brought her to only one participant, a former Stanford graduate student called Bill Underwood.</p><p>…Underwood and his wife were happy to talk, but two of their comments jarred. Rosenhan’s draft described how he prepared his volunteers very carefully, over weeks. Underwood, however, remembered only brief guidance on how to avoid swallowing medication by hiding pills in his cheek. His wife recalled Rosenhan telling her that he had prepared writs of <em>habeas corpus</em> for each pseudopatient, in case an institution would not discharge them. But Cahalan had already worked out that that wasn’t so.</p><p>Comparing the <em>Science</em> report with documents in Rosenhan’s archives, she also noted many mismatches in numbers. For instance, Rosenhan’s draft, and the Science paper, stated that Underwood had spent seven days in a hospital with 8,000 patients, whereas he spent eight days in a hospital with 1,500 patients.</p><p>When all of the leads from her contacts led to ground, she published a commentary in <em>The Lancet Psychiatry</em> asking for help in finding them—to no avail. Had Rosenhan invented them, she found herself asking?</p>'
- - https://pdfs.semanticscholar.org/57c8/aa6e7101b6cb7f1db2076401318cdb60b0c1.pdf
  - ! "On Pseudoscience in Science, Logic in Remission, and Psychiatric Diagnosis: A Critique of Rosenhan's 'On Being Sane in Insane Places'"
  - Robert L. Spitzer
  - '1975'
  - ''
  - ! '<p>Rosenhan’s “On Being Sane in Insane Places” is pseudoscience presented as science. Just as his pseudopatients were diagnosed at discharge as “schizophrenia in remission”, so a careful examination of this study’s methods, results, and conclusion leads to a diagnosis of “logic in remission”. Rosenhan’s study proves that pseudopatients are not detected by psychiatrists as having simulated signs of mental illness. This rather unremarkable finding is not relevant to the real problems of the reliability and validity of psychiatric diagnosis and only serves to obscure them. A correct interpretation of these data contradicts the conclusions that were drawn. In the setting of a psychiatric hospital, psychiatrists seem remarkably able to distinguish the “sane” from the “insane”.</p>'
- - https://nypost.com/2019/11/02/stanford-professor-who-changed-america-with-just-one-study-was-also-a-liar/
  - Stanford professor who changed America with just one study was also a liar
  - Susannah Cahalan
  - 2019-11-02
  - ''
  - ! "[Summary of investigation into David Rosenhan: like the Robbers Cave or Stanford Prison Experiment, his famous fake-insane patients experiment cannot be verified and many troubling anomalies have come to light. Cahalan is unable to find almost all of the supposed participants, Rosenhan hid his own participation & his own medical records show he fabricated details of his case, he throw out participant data that didn't match his narrative, reported numbers are inconsistent, Rosenhan abandoned a lucrative book deal about it and avoided further psychiatric research, and showed some character traits of a fabulist eager to please.]"
- - https://medium.com/@jsmp/orchestrating-false-beliefs-about-gender-discrimination-a25a48e1d02
  - Orchestrating false beliefs about gender discrimination
  - Jonatan Pallesen
  - 2019-02-19
  - ''
  - ! 'Blind auditions and gender discrimination: A seminal paper from 2000 investigated the impact of blind auditions in orchestras, and found that they increased the proportion of women in symphony orchestras. I investigate the study, and find that there is no good evidence presented. [The study is temporally confounded by a national trend of increasing female participation, does not actually establish any particular correlate of blind auditions, much less randomized experiments of blinding, the dataset is extremely underpowered, the effects cited in coverage cannot be found anywhere in the paper, and the critical comparisons which <em>are</em> there are not even statistically-significant in the first place. None of these caveats are included in the numerous citations of the study as "proving" discrimination against women.]'
- - https://onlinelibrary.wiley.com/doi/full/10.1002/anie.201410356
  - Disappearing Polymorphs Revisited
  - Dejan-Krešimir Bučar, Robert W. Lancaster, Joel Bernstein
  - 2015-06-01
  - 10.1002/anie.201410356
  - ! 'Nearly twenty years ago, Dunitz and Bernstein described a selection of intriguing cases of polymorphs that disappear. The inability to obtain a crystal form that has previously been prepared is indeed a frustrating and potentially serious problem for solid-state scientists. This Review discusses recent occurrences and examples of disappearing polymorphs (as well as the emergence of elusive crystal forms) to demonstrate the enduring relevance of this troublesome, but always captivating, phenomenon in solid-state research. A number of these instances have been central issues in patent litigations. This Review, therefore, also highlights the complex relationship between crystal chemistry and the law.'
- - /docs/science/1995-dunitz.pdf
  - Disappearing Polymorphs
  - Jack D. Dunitz, Joel Bernstein
  - '1995'
  - ''
  - ! '<p>When a compound exhibits polymorphism—the existence of more than one crystal structure—it may be important to obtain a particular polymorph under controlled and reproducible conditions. However, this is not always easy to achieve. Tales of difficulties in obtaining crystals of a particular known form or in reproducing results from another laboratory (or even from one’s own!) abound. Indeed, there are cases where it was difficult to obtain a given polymorphic form even though this had previously been obtained routinely over long time periods. Several monographs contain explicit or passing references to these problems, but much of this lore has gone undocumented, especially in the last 30 years or so. In this Account we present and discuss old and new examples.</p>'
- - https://www.theguardian.com/news/2019/nov/07/the-dice-man-elusive-author-luke-rhinehart-george-cockroft-emmanuel-carrere
  - ! "Who is the real Dice Man? The elusive writer behind the disturbing cult novel: A search for the mysterious author of a counterculture classic led to someone else entirely. Or did it?"
  - Emmanuel Carrère (<em>Guardian</em>)
  - 2019-11-07
  - ''
  - ! "<p>[A writer tracks down the author of <em>Dice Man</em>, George Cockcroft, who turns out to be an ordinary old novelist retired on a farm in upstate New York, who developed the novel’s idea from a minor game played as a youth. He profiles followers of the dice man approach, who turn out to be far more interesting as the dice pushes them into unusual risk-taking: for example, one Cuadrado, who “Like his father, he is a tax lawyer, but thanks to the dice he has also become a wine importer, a webmaster, a Go teacher, a fan of Iceland and the publisher of the Mauritian poet Malcolm de Chazal.”]</p>"
- - https://blogs.sciencemag.org/pipeline/archives/2019/11/26/perverse-polymorphism
  - Perverse Polymorphism
  - Derek Lowe
  - 2019-11-26
  - ''
  - ! '<p>…as the case of ritonavir shows, you can have a compound that has been worked on for years and produced commercially in bulk that hits upon a more stable solid phase. And since these more stable crystal forms tend to have very different solubilities, the effect on a drug development program (or in ritonavir’s case, a drug that is already rolling off the manufacturing line!) can be extremely unwelcome. When this happens, it can seem as if the original crystal form is going extinct and never to be seen again, an effect that seems almost supernatural. But as these papers note, the “unintentional crystalline seed” hypothesis is surely the explanation.</p><p>…What’s more, a given cubic foot of air could easily contain a million or so particles under a half-micron size without anyone noticing at all. Consider also that such too-small-to-see particles can lurk in what looks like a clear solution, and you have plenty of opportunities to spread a given polymorph around by what seems like magic. The 2015 paper tracks down several examples of the spread of such material…It’s also not true that polymorphs can truly go extinct, either, although it’s understandable that it might appear that way. There are always conditions out there to obtain the old crystalline form, although there is no requirement that these be easy to find (!) Indeed, the original form of ritonavir was recovered and brought back into production after a great deal of effort, although not before HIV-positive patients had seen their medicine disappear from the shelves for months (and not before Abbott had lost a quarter of a billion dollars along the way).</p><p>…There are compounds for which only one crystalline form has ever been reported, and there are others with two dozen polymorphs (and when that’s happening, you can be pretty sure that there are some others that haven’t shown up yet). Only one polymorph of aspirin was known until 2005, when another turned up.</p>'
- - https://www.atlasobscura.com/articles/imposter-brooklyn-weyman-clifford
  - "The Many Faces of Brooklyn’s Greatest Imposter: Stanley Clifford Weyman lived many, many lives"
  - Eric Grundhauser
  - 2017-08-23
  - ''
  - ! '<p>There are those who impersonate other people for money and fame, and then there are people like Stanley Clifford Weyman (not his real name), Brooklyn’s greatest imposter, who did it for the love of living in the skin of others. Throughout his life, Weyman impersonated military officials, political figures, and even the personal doctor of Rudolph Valentino’s widow—all just because he wanted to.</p><p>…Weinberg never impersonated specific people, but rather invented figures with variations of his name, such as “Rodney S. Wyman” and “Allen Stanley Weyman.” A couple of his recurring favorites were “Ethan Allen Weinberg” and “Royal St. Cyr”, but according to a 1968 story about him in The New Yorker, he settled on Stanley Clifford Weyman, as his more or less permanent name, around middle age.</p><p>…According to <em>The New Yorker</em> profile, his years of faking included time as “several doctors of medicine, and two psychiatrists, he was a number of officers in the United States Navy—ranging in rank from lieutenant to admiral—five or six United States Army officers, a couple of lawyers, the State Department Naval Liaison Officer, an aviator, a sanitation expert, many consuls-general, and a United Nations expert on Balkan and Asian affairs.” Weyman was no hero, but his ambition and dedication to craft are, perhaps, admirable. Very few images of Weyman exist, so his face isn’t so recognizable today, but that’s probably exactly as he would have had it.</p>'
- - https://vitalik.ca/general/2019/11/22/progress.html
  - "Hard Problems in Cryptocurrency: Five Years Later"
  - Vitalik Buterin
  - 2019-11-22
  - ''
  - ! '<p>[Vitalik Buterin of Ethereum reviews cryptocurrency technological developments since 2014, in cryptography, consensus theory, &amp; economics:]</p><ol type="1"><li><p>Cryptographic:</p><ul><li><em>Blockchain scalability</em>: Great theoretical progress, pending more real-world evaluation.</li><li><em>Distributed secure timestamping</em>: Some progress.</li><li><em>Arbitrary Proof of Computation</em>: Great theoretical and practical progress. [SNARKs/STARK/SHARK etc]</li><li><em>Code Obfuscation [DRM]</em>: Slow progress.</li><li><em>Hash-Based Cryptography [which is quantum-secure]</em>: Some progress.</li></ul></li><li><p>Consensus theory:</p><ul><li><em>ASIC-Resistant Proof of Work</em>: Solved as far as we can.</li><li><em>Useful Proof of Work</em>: Probably not feasible, with one exception.</li><li><em>Proof of Stake</em>: Great theoretical progress, pending more real-world evaluation.</li><li><em>Proof of Storage</em>: A lot of theoretical progress, though still a lot to go, as well as more real-world evaluation.</li></ul></li><li><p>Economics:</p><ul><li><p><em>Stable-value cryptoassets</em>: Some progress.</p></li><li><p><em>Decentralized Public Goods Incentivization</em>: Some progress.</p></li><li><p><em>Reputation systems</em>: Slow progress</p></li><li><p><em>Proof of excellence</em>: No progress, problem is largely forgotten.</p></li><li><p><em>Anti-Sybil systems</em>: Some progress.</p><ul><li><em>Decentralized contribution metrics</em>: Some progress, some change in focus.</li></ul></li><li><p><em>Decentralized success metrics</em>: Some progress.</p></li></ul></li></ol><p>…In general, base-layer problems are slowly but surely decreasing, but application-layer problems are only just getting started.</p>'
- - https://pointersgonewild.com/2019/11/02/they-might-never-tell-you-its-broken/
  - They Might Never Tell You It’s Broken
  - Maxime Chevalier-Boisvert
  - 2019-11-02
  - ''
  - ! '<p>As part of my PhD, I developed Higgs, an experimental JIT compiler…I developed it on GitHub, completely in the open, and wrote about my progress on this blog. Pretty soon, the project had 300 stars on GitHub, a handful of open source contributors, and I was receiving some nice feedback.</p><p>…One day, someone I had been exchanging with on the chat room for two weeks reached out to me to signal a strange bug. They couldn’t get the tests to pass and were getting a segmentation fault. I was puzzled. They asked me if Higgs had MacOS support. I explained that I’d never tested it on MacOS myself, but I couldn’t see any reason why it wouldn’t work. I told this person that the problem was surely on their end. Higgs had been open source for over a year. It was a pretty niche project, but I knew for a fact that at least 40–60 people must have tried it, and at least 50% of these people must have been running MacOS. I assumed that surely, if Higgs didn’t run on MacOS at all, someone would have opened a GitHub issue by now. Again, I was wrong.</p><p>…It’s a horrifying thought, but it could be that for every one person who opens an issue on GitHub, 100 or more people have already tried your project, run into that same bug, and simply moved on.</p>'
- - https://www.frontiersin.org/articles/10.3389/fphys.2012.00082/full
  - Fatigue is a brain-derived emotion that regulates the exercise behavior to ensure the protection of whole body homeostasis
  - Timothy David Noakes
  - 2012-04-12
  - 10.3389/fphys.2012.00082
  - ! 'An influential book written by A. Mosso in the late nineteenth century proposed that fatigue that “at first sight might appear an imperfection of our body, is on the contrary one of its most marvelous perfections. The fatigue increasing more rapidly than the amount of work done saves us from the injury which lesser sensibility would involve for the organism” so that “muscular fatigue also is at bottom an exhaustion of the nervous system.” It has taken more than a century to confirm Mosso’s idea that both the brain and the muscles alter their function during exercise and that fatigue is predominantly an emotion, part of a complex regulation, the goal of which is to protect the body from harm. Mosso’s ideas were supplanted in the English literature by those of A. V. Hill who believed that fatigue was the result of biochemical changes in the exercising limb muscles–“peripheral fatigue”–to which the central nervous system makes no contribution. The past decade has witnessed the growing realization that this brainless model cannot explain exercise performance. This article traces the evolution of our modern understanding of how the CNS regulates exercise specifically to insure that each exercise bout terminates whilst homeostasis is retained in all bodily systems. The brain uses the symptoms of fatigue as key regulators to insure that the exercise is completed before harm develops. These sensations of fatigue are unique to each individual and are illusory since their generation is largely independent of the real biological state of the athlete at the time they develop. The model predicts that attempts to understand fatigue and to explain superior human athletic performance purely on the basis of the body’s known physiological and metabolic responses to exercise must fail since subconscious and conscious mental decisions made by winners and losers, in both training and competition, are the ultimate determinants of both fatigue and athletic performance.'
- - https://nintil.com/
  - Nintil
  - Jose Luis Ricon
  - ''
  - ''
  - ! 'Blog of Jose Luis Ricon (<a href="https://twitter.com/ArtirKel">Twitter</a>), machine learning engineer. Ricon blogs primarily about economics and progress studies, mixing link compilations with more researched essays such as about the economic (in)efficiency of the USSR, or the extent to which tutoring & "direct instruction" boost educational achievement.'
- - https://talktotransformer.com/
  - Talk To Transformer
  - Adam King
  - '2019'
  - ''
  - ! "[Interactive web interface to GPT-2-1.5b.] See how a modern neural network completes your text. Type a custom snippet or try one of the examples...Built by Adam King (@AdamDanielKing) as an easier way to play with OpenAI's new machine learning model. This site runs the full-sized GPT-2 model, called 1558M."
- - https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/
  - 'XLM-R: State-of-the-art cross-lingual understanding through self-supervision'
  - FAIR
  - 2019-11-07
  - ''
  - ! '<p>A new model, called XLM-R, that uses self-supervised training techniques to achieve state-of-the-art performance in cross-lingual understanding, a task in which a model is trained in one language and then used with other languages without additional training data. Our model improves upon previous multilingual approaches by incorporating more training data and languages—including so-called low-resource languages, which lack extensive labeled and unlabeled data sets.</p><p>XLM-R has achieved the best results to date on four cross-lingual understanding benchmarks, with increases of 4.7 percent average accuracy on the XNLI cross-lingual natural language inference data set, 8.4 percent average F1 score on the recently introduced MLQA question answering data set, and 2.1 percent F1 score on NER. After extensive experiments and ablation studies, we’ve shown that XLM-R is the first multilingual model to outperform traditional monolingual baselines that rely on pretrained models.</p><p>In addition to sharing our results, we’re releasing the code and models that we used for this research. Those resources can be found on our fairseq, Pytext and XLM repositories on GitHub.</p><p>…With people on Facebook posting content in more than 160 languages, XLM-R represents an important step toward our vision of providing the best possible experience on our platforms for everyone, regardless of what language they speak. Potential applications include serving highly accurate models for identifying hate speech and other policy-violating content across a wide range of languages. As this work helps us transition toward a one-model-for-many-languages approach—as opposed to one model per language—it will also make it easier to continue launching high-performing products in multiple languages at once.</p>'
- - /docs/science/1960-campbell.pdf#page=5
  - The Self-Repairing Robot
  - John W. Campbell
  - '1960'
  - ''
  - ! '<p>[From <em>Analog Magazine</em>, October 1960 (v66, #2), pg87–88.</p><p>Campbell describes two examples:</p><ol type="1"><li>glycerine, where attempts to freeze it per a German chemist’s research failed and resulted only in a glass, until they contacted him for information and he sent a sample of his glycerine back, which ‘contaminated’ their own samples and resulted in frozen glycerine but now never glass.</li><li>EDT: Bell Labs was growing quartz-substitute crystals called EDT which worked perfectly, replacing expensive quartz, until one day a new polymorph showed up, destroying all EDT crystal production. All attempts to recreate EDT failed, but fortunately, the problem of growing quartz had been solved in the mean time, so it was ultimately not a disaster.]</li></ol>'
- - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.75.2289&rep=rep1&type=pdf
  - Computer-Generated Floral Ornament
  - Michael T. Wong, Douglas E. Zongker, David H. Salesin
  - '1998'
  - ''
  - ! 'This paper describes some of the principles of traditional floral ornamental design, and explores ways in which these designs can be created algorithmically. It introduces the idea of “adaptive clip art”, which encapsulates the rules for creating a specific ornamental pattern. Adaptive clip art can be used to generate patterns that are tailored to fit a particularly shaped region of the plane. If the region is resized or reshaped, the ornament can be automatically regenerated to fill this new area in an appropriate way. Our ornamental patterns are created in two steps: first, the geometry of the pattern is generated as a set of two-dimensional curves and filled boundaries; second, this geometry is rendered in any number of styles. We demonstrate our approach with a variety of floral ornamental designs.'
- - https://pdfs.semanticscholar.org/ccac/0394825b1a8ab9933f8ca3449e5b66a5a526.pdf
  - 'Magnetic Curves: Curvature-Controlled Aesthetic Curves Using Magnetic Fields'
  - Ling Xu, David Mould
  - '2009'
  - ''
  - ! 'We describe “magnetic curves”, a particle-tracing method that creates curves with constantly changing curvature. It is well known that charged particles in a constant magnetic field trace out circular or helical trajectories. Motivated by John Ruskin’s advice to use variation in curvature to achieve aesthetic curves, we propose to continuously change the charge on a simulated particle so that it can trace out a complex curve with continuously varying curvature. We show some examples of abstract figures created by this method and also show how some stylized representational forms, including fire, hair, and trees, can be drawn with magnetic curves.'
- - https://medium.com/@tokudu/computer-generated-floral-ornament-based-on-magnetic-curves-d77a3f206893
  - Computer-generated Floral Ornament Based on Magnetic Curves
  - Anton Lopyrev
  - 2016-08-02
  - ''
  - ! '<p>While the concept of using vegetation to produce ornament seems to be very trivial to take up, it proves to be difficult to create a good floral ornament design by hand. It turns out that hand drawn floral ornamentation is a very time-consuming task that requires a great deal of skill and training. In fact, most of the floral clip-art found on the web (Figure 3) is usually produced by experienced artists and is usually quite costly. As a result, one naturally tends to think about automated ways of generate floral motifs.</p><p>This article explores the problem of how to produce aesthetically pleasing computer-generated ornament. The method described here is a combination of two papers by Ling Xu et al. [11] and M. T. Wong et al. [1], which are further discussed in the next section. However, instead of making the entire process fully automated, as aforementioned papers suggest, this article focuses on an idea of interactive user control. The vision here is that while it is possible to automatically produce a relatively attractive floral ornament, artistic input still remains the best tool for evaluation, about whether or not the resultant ornament is indeed aesthetically pleasing. Consequently, the tool that is described in this article relies on a heavy UI component.</p><p>…The starting point of my algorithm is the basic implementation of the magnetic curves paper. The idea behind the magnetic curves algorithm is that under certain constraints a charged particle that moves under the influence of a magnetic field will trace out interesting spiral curves. By recursively releasing secondary particles from the original particle at constant intervals, more complicated curves that resemble branching vegetation can be produced.</p><p>…In this article I presented an overview of a tool I developed for interactive generation of floral ornament. While constrained to a pre-set selection of clip-art, this tool showcases the great possibilities of the magnetic curves algorithm to produce aesthetically pleasing ornament, when combined with the idea of adaptive clip-art. Without a doubt, the algorithm I presented in this article greatly improves upon Ling Xu’s results from his original “magnetic curves” article. The results that I was able to achieve with my tool are comparable in their quality to a floral design that can be produced by a professional artist. I hope that the work I’ve done here can be used one day to aid an artist in the generation of beautiful designs.</p>'
- - https://publicdomainreview.org/about/
  - 'The Public Domain Review: About'
  - The Public Domain Review
  - ''
  - ''
  - ! '<p>Founded in 2011, <strong>The Public Domain Review</strong> is an online journal and not-for-profit project dedicated to the exploration of curious and compelling works from the history of art, literature, and ideas.</p><p>In particular, as our name suggests, the focus is on works which have now fallen into the public domain, that vast commons of out-of-copyright material that everyone is free to enjoy, share, and build upon without restriction. Our aim is to promote and celebrate the public domain in all its abundance and variety, and help our readers explore its rich terrain–like a small exhibition gallery at the entrance to an immense network of archives and storage rooms that lie beyond. With a focus on the surprising, the strange, and the beautiful, we hope to provide an ever-growing cabinet of curiosities for the digital age, a kind of hyperlinked <em>Wunderkammer</em>–an archive of content which truly celebrates the breadth and diversity of our shared cultural commons and the minds that have made it.</p><p>…Some highlights include visions of the future from late 19th century France, a dictionary of Victorian slang and a film showing the very talented “hand-farting” farmer of Michigan… from a history of the smile in portraiture to the case of the woman who claimed to give birth to rabbits.</p>'
- - https://identitydesigned.com/issho/
  - 'Issho: Designed by Dutchscot, London'
  - Identity Designed
  - 2018-11-20
  - ''
  - ! 'Gallery of a Japanese restaurant, Issho, which has been redesigned by the minimalist design firm Dutchscot. The design emphasises <em>kintsugi</em>, irregular gold stripes used to repair pottery, white/red/blue, and traditional Japanese cloud motifs.'
- - https://publicdomainreview.org/essay/the-lost-world-of-the-london-coffeehouse/
  - The Lost World of the London Coffeehouse
  - Matthew Green
  - 2013-08-07
  - ''
  - ! "In contrast to today's rather mundane spawn of coffeehouse chains, the London of the 17th and 18th century was home to an eclectic and thriving coffee drinking scene. Dr Matthew Green explores the halcyon days of the London coffeehouse, a haven for caffeine-fueled debate and innovation which helped to shape the modern world."
- - '/docs/anime/1993-anno-charscounterattackfanclubbook-khodazattranslation.pdf#page=4'
  - "Excerpts from the Hideaki Anno/Yoshiyuki Tomino interview from the <em>Char's Counterattack Fan Club Book</em> (1993)"
  - 'Hideaki Anno, Yoshiyuki Tomino, trans. kohdazat'
  - '1993'
  - ''
  - ! '<p><code>Ogura</code>: Usually he’s [Mamoru Oshii] very critical of other people’s works. Did you hear what he had to say about <em>Porco Rosso</em>?</p><p><code>Anno</code>: Oh, I’m critical of <em>Porco Rosso</em>, myself.</p><p><code>Tomino</code>: What was wrong with <em>Porco</em>?</p><p><code>Anno</code>: As a picture, nothing. But because I know Miyazaki-san personally, I can’t view it objectively. His presence in the film is too conspicuous, it’s no good. In other words… it feels like he’s showing off.</p><p><code>Tomino</code>: How so?</p><p><code>Anno</code>: He has the main character act all self-deprecating, calling himself a pig… but then puts him in a bright red plane, has him smoking all cool-like, even creates a love triangle between a cute young thing and a sexy older lady.</p><p><code>Tomino</code>: Ha! I see what you mean. He and I are around the same age, though. So I get how he feels, unconditionally. So I may think, “Oh boy…” but I can’t stay mad at him (laughs).</p>'
- - https://www.tabletmag.com/jewish-arts-and-culture/290042/writing-akhnaten
  - "Writing ‘Akhnaten’: A co-author of Philip Glass’ Egyptian opera, opening at the Met this weekend, recalls how the monotheistic ‘heretic Pharaoh’ became the fat lady"
  - Shalom Goldman
  - '2019-11-06'
  - ''
  - ! '<p><em>Akhnaten</em>, Philip Glass’ “Egyptian opera,” opening at the Metropolitan Opera this weekend, premiered in 1984 and since then has been produced in many different stagings, primarily in European cities, where the composer has a very large and enthusiastic audience. Akhnaten’s American production story has been much more modest.</p><p>…Someone at the party had told Glass that I was studying Egyptian language and culture. He sought me out, introduced himself and asked if I knew anything about Akhnaten, the “heretic Pharaoh.” The party had put me in a jocular mood and my immediate response was “know about him? I just saw him!” I explained that I had only recently returned from Cairo, where the massive statue of Akhnaten in the Cairo Museum was the Egyptian artifact that had made the deepest impression on me. (Later I realized that in my response I was channeling a skit in <em>2000 Year Old Man</em> in which Carl Reiner asks Mel Brooks if he had known Joan of Arc. “What do you mean knew her,” said Brooks, “I dated her!”) Our initial conversation about Egypt and Akhnaten lasted for more than an hour.</p><p>In his remarkably creative way, Glass had been reading widely about Egypt and Akhnaten. He had studied James Henry Breasted’s authoritative <em>History of Egypt</em> and he read Freud’s speculations about Akhnaten in his last book, <em>Moses and Monotheism</em>. We agreed to meet the following week to continue our conversation. I told Glass that for our next meeting I would bring pictures of Akhnaten, his wife Nefertiti, and of his artistic creations. For Akhnaten was an artist and poet, as well as a Pharaoh—or at least that was the claim of some experts. Our subsequent meetings at which I was introduced to Glass’ theater and music collaborators, Robert Israel and Richard Riddell, went very well. They had worked with Glass on <em>Satyagraha</em> and were collaborating with him on the creation of <em>Akhnaten</em>. Asked by Glass if I would be able to serve as a researcher on his Egyptian project, I said yes.</p><p>…His formulation was: “Einstein as the man of science, Gandhi as the man of politics, Akhnaten as the man of religion.”</p><p>In his 1987 book, <em>Music by Philip Glass</em>, the composer explained his fascination with the heretic king: “On becoming Pharaoh, he declared a new religion based upon Aten, associated with the sun, but not actually the sun itself, a very important point theologically. His new god was supreme and alone, making Akhnaten the first declared monotheist in history. … Finally, by not completely identifying his god with the physical sun but emphasizing his independent nature, Akhnaten’s god is the first truly abstract god head we know.” Glass knew that not all historians of religion and culture agreed with this description. But for Glass, the main point was that “Akhnaten had changed his (and our) world through the force of his ideas and not through the force of arms.”</p>'
- - https://tvtropes.org/pmwiki/pmwiki.php/Main/KickTheDog
  - "Trope: 'Kick the Dog'"
  - TVTropes
  - ''
  - ''
  - ! '<p>When a character does something evil, cruel or very mean for no apparent gain, because the author wants to demonstrate that he’s not a nice guy and shift audience sympathy away from him.</p><p>Why this trope works could be expressed in the words of William Cowper: “I would not enter on my list of friends (though graced with polished manners and fine sense, yet wanting sensibility) the man who needlessly sets foot upon a worm.” In other words, a cruel act, no matter how trivial, establishes someone as a cruel person. Conversely, the creator may show a character being kind for no apparent gain, to demonstrate that the character is a nice person and someone the audience is meant to cheer for. Both devices are used to help the audience become emotionally invested in the story.</p><p>What separates this trope from a character’s other evil or cruel acts is that this bit of evil is gratuitous. It doesn’t get the character anything or even advance the plot. The sole reason for this story beat existing is to place one or more characters squarely on the wrong side of the Rule of Empathy.</p>'
- - /newsletter/2019/10#manon
  - "Opera review: <em>Manon</em>"
  - Gwern Branwen
  - 2019-10-27
  - ''
  - ! '<p>Review of <em>Manon</em>, a French opera about a beautiful countryside girl whose craving for the ‘good life’ leads her into the Parisian <em>demimondaine</em> as a courtesan.</p><p>Exemplifying Girardian <em>mimesis</em>, Manon wants what everyone else wants, and wants what she can’t have, like her spurned lover only once he has taken religious vows. She plays off suitors, who compete in negative-sum games for her favors, until eventually she goes too far and is imprisoned, destroying her health; cast down, she realizes that ‘living only for pleasure’ was not the ideal life.</p><p>This scenario seems to exemplify the extent to which polygynous competition can result in negative-sum games, making almost everyone worse off except a few winners (and those possibly only temporarily).</p>'
- - https://www.animenewsnetwork.com/review/belladonna-of-sadness/.102644
  - "Review: <em>Belladonna of Sadness</em>"
  - Gabriella Elkins (ANN)
  - 2016-06-17
  - ''
  - ! '<p><em>Summary</em>: Medieval peasants Jean and Jeanne are idyllic newlyweds. Their happiness vanishes, however, when Jeanne is raped by the local lord in a legally sanctioned deflowering ritual. Afterwards, while the couple tries to resume their life together, Jeanne starts receiving visions from a demon. It comforts her in her sadness, but it also encourages her to act out against the lord. Jeanne resists at first, but as her fortunes continue to wane, she’s thrown further into the demon’s embrace. As time goes on, Jeanne is drawn into an experience that radically reconfigures her sense of herself, the world, and the course of history itself.</p><p><em>Review</em>: An X-rated anime classic newly remastered for the screen, <em>Belladonna of Sadness</em> is one of animation’s premiere psychedelic experiences, brought over to North America for nearly the first time ever in 2016. Its history has already been covered by us before, but here’s a quick refresher: <em>Belladonna of Sadness</em> is a legendarily low-budget, sexual, and psychedelic anime film from the 1970s. Poorly received at the time of its release, it accrued a cult audience over the next few decades. Recently, its reputation has been rehabilitated to the point where it’s considered an overlooked classic. Still, wider appreciation of the film was hampered by the lack of an English release and poor quality of existing prints. That changed in 2014, when the high-end distribution company Cinelicious chose it as their first candidate for an in-house 4k restoration and re-release. This May, the completed film began screening in theaters across the United States and Canada, and will continue to do so until September. I attended one of these screenings at International House theater in Philadelphia. This was my first time seeing the film, and I left very much impressed by both its artistry and storytelling.</p><p>…Fair warning, though—it’s not an exaggeration that this film is touted as ultra-sexual. I’d say most of the film’s runtime is made up of sex scenes, some of them violent and disturbing. It literally opens with a rape. These scenes are appropriate to the story, and the scenes are gorgeous in their artistry, but they are unpleasant. Otherwise, the sexual imagery is largely abstract. Flowers become vaginas, figures in cloaks become disembodied penises, and Jeanne’s rape is depicted as her being bisected from the groin upwards. Some psychedelic sequences also contain intense strobe lighting, so epileptics be warned. As for the visuals themselves, expect watercolors, morphing lineart, and little in terms of actual animation. There are no lush Kyoto Animation frame counts here. Much of the film’s motion consists of pans and zooms across static illustrations. There aren’t even any lip flaps. The studio went under while making this film, so this was a method of cutting costs. However, the results are memorable and even contribute to the film’s power. (There’s a great analysis to be written about its use of vertical versus horizontal space.) Despite these limitations, <em>Belladonna of Sadness</em> is, on a purely aesthetic level, almost unbelievably beautiful. I’d hang any given frame of it up on my wall. Even if you don’t care about it’s message, this film is still worth watching as a work of altered-state eroticism.</p><p>Overall, viewers who can handle the content will probably be entertained by this gorgeous and trippy movie. However, I especially recommend <em>Belladonna of Sadness</em> to anyone interested in the history of anime.</p><p>…<em>Belladonna of Sadness</em> is the culmination of a rare attempt to make blatantly un-commercial, artistically challenging anime. At the cost of bankruptcy, Mushi Productions made a masterpiece that wouldn’t be fully appreciated for 40 years. Now hindsight allows us to see the breadth of its influence and depth of its daring. Get in on this experience while you have the chance.</p>'
- - /newsletter/2019/02#filmtv
  - "Opera review: <em>Carmen</em>"
  - Gwern Branwen
  - 2019-03-02
  - ''
  - ! '[Review of Met HD broadcast of the opera <em>Carmen</em>. This was my first time watching an opera or a Met HD broadcast, and I was greatly impressed by the technical quality of the broadcast & the opera performance itself. The experience convinced me to watch additional Met HD broadcasts to learn more about opera. I understand now the description of opera as a totalizing <em>Gesamtkunstwerk</em>. The opera was interestingly "red pill"-like in depicting Carmen as demanding ever more sacrifices and ultimately abandoning her lover, leading to the final murder-suicide.]'
- - https://publicdomainreview.org/essay/made-in-taiwan-how-a-frenchman-fooled-18th-century-london/
  - "Made in Taiwan? How a Frenchman Fooled 18th-Century London"
  - Benjamin Breen
  - 2018-04-18
  - ''
  - ! 'Benjamin Breen on the remarkable story of George Psalmanazar, the mysterious Frenchman who successfully posed as a native of Formosa (now modern Taiwan) and gave birth to a meticulously fabricated culture with bizarre customs, exotic fashions, and its own invented language...Who was this man? The available facts remain surprisingly slim. Despite hundreds of years of research by everyone from the father of British Prime Minister Benjamin Disraeli to contemporary scholars at Penn and the National Taiwan University, we still don’t even know Psalmanazar’s real name or place of origin (although he was likely from southern France). We know that elite figures ranging from the scientists of the Royal Society to the Bishop of London initially believed his claims, but he eventually fell into disgrace as competing experts confirmed that he was a liar. Beyond this, we move into the fictional realms that "Psalmanazar", like a Borges character come to life, summoned into existence with his voice and pen...Although the scale and singularity of his deception made him unique, Psalmanazar was also representative: while he was inventing tales of Formosan cannibalism, his peers were writing falsified histories of pirate utopias, parodic accounts of islands populated by super-intelligent horses, and sincere descriptions of demonic sacrifices.'
- - https://publicdomainreview.org/essay/exquisite-rot-spalted-wood-and-the-lost-art-of-intarsia/
  - "Exquisite Rot: Spalted Wood and the Lost Art of Intarsia"
  - Daniel Elkind
  - 2018-05-16
  - ''
  - ! '<p>The technique of intarsia—the fitting together of pieces of intricately cut wood to make often complex images—has produced some of the most awe-inspiring pieces of Renaissance craftsmanship. Daniel Elkind explores the history of this masterful art, and how an added dash of colour arose from a most unlikely source: lumber ridden with fungus...painting in wood is in many ways more complicated than painting on wood. Rather than fabricating objects from a single source, the art of intarsia is the art of mosaic, of picking the right tone, of sourcing only properly seasoned lumber from mature trees and adapting materials intended for one context to another. Painting obscures the origins of a given material, whereas intarsia retains the original character of the wood grain—whose knots and whorls are as individual as the islands and deltas of friction ridges that constitute the topography of a fingerprint—while forming a new image. From a distance, the whole appears greater than the sum of its parts; up close, one can appreciate the heterogeneity of the components...</p> <p>Inspired by the New Testament and uninhibited by Mosaic proscription, craftsmen in the city of Siena began to introduce flora and fauna into their compositions in the 14th century. Figures and faces became common by the late fifteenth century and, by the early sixteenth century, <em>intarsiatori</em> in Florence were making use of a wide variety of dyes in addition to natural hardwoods to mimic the full spectrum from the lightest (spindlewood) to medium (walnut) and dark (bog oak)—with the tantalizing exception of an aquamarine color somewhere between green and blue which required treating wood with “copper acetate (verdigris) and copper sulfate (vitriol).”<sup>8</sup></p><p>…Furnishings that featured slivers of <em>griinfaule</em> or “green oak” were especially prized by master cabinetmakers like Bartholomew Weisshaupt and coveted by the elite of the Holy Roman Empire.<sup>10</sup> Breaking open rotting hardwood logs to reveal delicate veins of turquoise and aquamarine, craftsmen discovered that the green in green oak was the result of colonization by the green elf-cup fungus, <em>Chlorociboria aeruginascens</em>, whose tiny teal fruiting bodies grow on felled, barkless conifers and hardwoods like oak and beech across much of Europe, Asia, and North America. Fungal rot usually devalues wood, but green oak happened to fill a lucrative niche in a burgeoning luxury trade, and that made it, for a time at least, as precious as some rare metals. During the reign of Charles V, when the Hapsburgs ruled both Spain and Germany, a lively trade in these intarsia pieces sprang up between the two countries.</p>'
- - https://publicdomainreview.org/essay/o-uommibatto-how-the-pre-raphaelites-became-obsessed-with-the-wombat/
  - ! '"O Uommibatto": How the Pre-Raphaelites Became Obsessed with the Wombat'
  - Angus Trumble
  - 2019-01-10
  - ''
  - ! '<p>Angus Trumble on Dante Gabriel Rossetti and company’s curious but longstanding fixation with the furry oddity that is the wombat—that “most beautiful of God’s creatures”—which found its way into their poems, their art, and even, for a brief while, their homes…the Pre-Raphaelites were not the first English to become enamoured by the unusual creature. Wombats captured the attention of English naturalists as soon as they found out about them from early settlers, explorers, and naturalists at the time of first contact. The Aboriginal word wombat was first recorded near Port Jackson, and though variants such as wombach, womback, the wom-bat and womat were noted, the present form of the name stuck very early, from at least 1797. Beautiful drawings survive from the 1802 voyages of the <em>Investigator</em> and <em>Le Géographe</em>. Ferdinand Bauer, who sailed with Matthew Flinders, and Charles-Alexandre Lesueur, who was in the rival French expedition of Nicolas Baudin, both drew the creature. These were engraved and carefully studied at home. Wombats were admired for their stumpy strength, their patience, their placid, not to say congenial manners, and also a kind of stoic determination. Occasionally they were thought clumsy, insensible or even stupid, but these isolated observations are out of step with the majority of nineteenth-century opinion.</p>'
- - https://publicdomainreview.org/essay/visions-of-algae-in-eighteenth-century-botany/
  - Visions of Algae in Eighteenth-Century Botany
  - Ryan Feigenbaum
  - 2016-09-07
  - ''
  - ! "Although not normally considered the most glamorous of Mother Nature's offerings, algae has found itself at the heart of many a key moment in the last few hundred years of botanical science. Ryan Feigenbaum traces the surprising history of one particular species—<em>Conferva fontinalis</em>—from the vials of Joseph Priestley's laboratory to its possible role as inspiration for Shelley's <em>Frankenstein</em>."
- - https://publicdomainreview.org/essay/greenland-unicorns-and-the-magical-alicorn/
  - Greenland Unicorns and the Magical Alicorn
  - Natalie Lawrence
  - 2019-09-19
  - ''
  - ! 'When the existence of unicorns, and the curative powers of the horns ascribed to them, began to be questioned, one Danish physician pushed back through curious means—by reframing the unicorn as an aquatic creature of the northern seas. Natalie Lawrence on a fascinating convergence of established folklore, nascent science, and pharmaceutical economy.'
- - https://publicdomainreview.org/essay/mesmerising-science-the-franklin-commission-and-the-modern-clinical-trial/
  - Mesmerising Science The Franklin Commission and the Modern Clinical Trial
  - Urte Laukaityte
  - 2018-11-20
  - ''
  - ! 'Benjamin Franklin, magnetic trees, and erotically-charged séances— Urte Laukaityte on how a craze for sessions of "animal magnetism" in late 18th-century Paris led to the randomised placebo-controlled and double-blind clinical trials we know and love today...By a lucky coincidence, Benjamin Franklin was in France as the first US ambassador with a mission to ensure an official alliance against its arch nemesis, the British. On account of his fame as a great man of science in general and his experiments on one such invisible force—electricity—in particular, Franklin was appointed as head of the royal commission. The investigating team also included the chemist Antoine-Laurent Lavoisier, the astronomer Jean-Sylvain Bailly, and the doctor Joseph-Ignace Guillotin. It is a curious fact of history that both Lavoisier and Bailly were later executed by the guillotine—the device attributed to their fellow commissioner. The revolution also, of course, brought the same fate to King Louis XVI and his Mesmer-supporting wife Marie Antoinette. In a stroke of insight, the commissioners figured that the cures might be affected by one of two possible mechanisms: psychological suggestion (what they refer to as “imagination”) or some actual physical magnetic action. Mesmer and his followers claimed it was the magnetic fluid, so that served as the experimental condition if you like. Continuing with the modern analogies, suggestion would then represent a rudimentary placebo control condition. So to test animal magnetism, they came up with two kinds of trials to try and separate the two possibilities: either the research subject is being magnetised but does not know it (magnetism without imagination) or the subject is not being magnetised but thinks that they are (imagination without magnetism). The fact that the trials were blind, or in other words, the patients did not know when the magnetic operation was being performed, marks the commission’s most innovative contribution to science...Whatever the moral case may be, the report paved the way for the modern empirical approach in more ways than one. Stephen Jay Gould called the work “a masterpiece of the genre, an enduring testimony to the power and beauty of reason” that “should be rescued from its current obscurity, translated into all languages”. Just to mention a few further insights, the commissioners were patently aware of psychological phenomena like the experimenter effect, concerned as they were that some patients might report certain sensations because they thought that is what the eminent men of science wanted to hear. That seems to be what propelled them to make the study placebo-controlled and single-blind. Other phenomena reminiscent of the modern-day notion of priming, and the role of expectations more generally, are pointed out throughout the document. The report also contains a detailed account of how self-directed attention can generate what are known today as psychosomatic symptoms. Relatedly, there is an incredibly lucid discussion of mass psychogenic illness, and mass hysteria more generally, including in cases of war and political upheaval. Just five years later, France would descend into the chaos of a violent revolution.'
- - https://publicdomainreview.org/essay/bugs-and-beasts-before-the-law/
  - Bugs and Beasts Before the Law
  - Nicholas Humphrey
  - 2011-03-27
  - ''
  - ! '<p>Murderous pigs sent to the gallows, sparrows prosecuted for chattering in church, a gang of thieving rats let off on a wholly technical acquittal—theoretical psychologist and author Nicholas Humphrey explores the strange world of medieval animal trials.</p><p>…Such stories, however, are apparently not news for very long. Indeed the most extraordinary examples of people taking retribution against animals seem to have been almost totally forgotten. A few years ago I lighted on a book, first published in 1906, with the surprising title <em>The Criminal Prosecution and Capital Punishment of Animals</em> by E.P.Evans, author of <em>Animal Symbolism in Ecclesiastical Architecture</em>, <em>Bugs and Beasts before the Law</em>, etc., etc. The frontispiece showed an engraving of a pig, dressed up in a jacket and breeches, being strung up on a gallows in the market square of a town in Normandy in 1386; the pig had been formally tried and convicted of murder by the local court. When I borrowed the book from the Cambridge University Library, I showed this picture of the pig to the librarian. “Is it a joke?”, she asked.</p><p>No, it was not a joke. All over Europe, throughout the middle-ages and right on into the 19th century, animals were, as it turns out, tried for human crimes. Dogs, pigs, cows, rats and even flies and caterpillars were arraigned in court on charges ranging from murder to obscenity. The trials were conducted with full ceremony: evidence was heard on both sides, witnesses were called, and in many cases the accused animal was granted a form of legal aid—a lawyer being appointed at the tax-payer’s expense to conduct the animal’s defence.</p><p>…Evans’ book details more than two hundred such cases: sparrows being prosecuted for chattering in Church, a pig executed for stealing a communion wafer, a cock burnt at the stake for laying an egg. As I read my eyes grew wider and wider.</p>'
- - https://publicdomainreview.org/essay/the-snowflake-man-of-vermont/
  - The Snowflake Man of Vermont
  - Keith C. Heidorn
  - 2011-02-14
  - ''
  - ! 'Keith C. Heidorn takes a look at the life and work of Wilson Bentley, a self-educated farmer from a small American town who, by combining a bellows camera with a microscope, managed to photograph the dizzyingly intricate and diverse structures of the snow crystal.'
- - https://resobscura.blogspot.com/2017/05/why-are-there-so-many-17th-century.html
  - 'Why Are There So Many 17th Century Paintings of Monkeys Getting Drunk?'
  - Benjamin Breen
  - 2017-05-04
  - ''
  - ! '<p>One cold Friday in 1660, Samuel Pepys encountered two unpleasant surprises. “At home found all well,” he wrote in his diary, “but the monkey loose, which did anger me, and so I did strike her.” Later that night, a candlemaker named Will Joyce (the good-for-nothing husband of one of Pepys’s cousins) stumbled in on Pepys and his aunt while “drunk, and in a talking vapouring humour of his state, and I know not what, which did vex me cruelly.” Presumably, Pepys didn’t resort to blows this time around.</p><p>The two objects of Pepys’ scorn that day, his disobedient pet monkey and his drunken cousin-in-law, were not as distant as one might think. Monkeys stood in for intoxicated humans on a surprisingly frequent basis in 17th century culture. In early modern paintings, tippling primates can frequently be seen in human clothing, smoking tobacco, playing cards, rolling dice, and just plain getting wasted.</p><p>Why?</p><p>… So what is going on with these images showing drunken and drug-selling monkeys? I think that what we’re missing when we simply see these as a form of social satire is that these are also paintings about <em>addiction</em>. Desire is a dominant theme in these works: monkeys are shown jealously squabbling over piles of tobacco, or even, in the example below, hoarding tulip flowers during the height of the Dutch tulipmania (they appear to be using the profits to get drunk, in the upper left)…But there’s an alternative narrative running through these paintings as well. It epitomizes the ambivalence that has long surrounded intoxicating substances, in many cultures and in many times: These monkeys seem to be having fun.</p>'
- - https://publicdomainreview.org/collection/alexander-graham-bell-s-tetrahedral-kites-1903-9/
  - "Alexander Graham Bell's Tetrahedral Kites (1903–9) [image gallery]"
  - The Public Domain Review
  - ''
  - ''
  - ! "<p>The wonderful imagery documenting Alexander Graham Bell's experiments with tetrahedral kites.…the Scottish-born inventor Alexander Graham Bell is also noted for his work in aerodynamics, a rather more photogenic endeavour perhaps, as evidenced by the wonderful imagery documenting his experiments with tetrahedral kites. The series of photographs depict Bell and his colleagues demonstrating and testing out a number of different kite designs, all based upon the tetrahedral structure, to whose pyramid-shaped cells Bell was drawn as they could share joints and spars and so crucially lessen the weight-to-surface area ratio…Bell began his experiments with tetrahedral box kites in 1898, eventually developing elaborate structures comprised of multiple compound tetrahedral kites covered in maroon silk, constructed with the aim of carrying a human through the air. Named <em>Cygnet</em> I, II, and III (for they took off from water) these enormous tetrahedral beings were flown both unmanned and manned during a five year period from 1907 until 1912.</p>"
- - https://publicdomainreview.org/collection/the-model-book-of-calligraphy-1561-1596/
  - "The Model Book of Calligraphy (1561–1596) [image gallery]"
  - The Public Domain Review
  - ''
  - ''
  - ! '<p>Pages from a remarkable book entitled <em>Mira calligraphiae monumenta</em> (<em>The Model Book of Calligraphy</em>), the result of a collaboration across many decades between a master scribe, the Croatian-born Georg Bocskay, and Flemish artist Joris Hoefnagel. In the early 1560s, while secretary to the Holy Roman Emperor Ferdinand I, Bocksay produced his Model Book of Calligraphy, showing off the wonderful range of writing style in his repertoire. Some 30 years later (and 15 years after the death of Bocskay), Ferdinand’s grandson, who had inherited the book, commissioned Hoefnagel to add his delightful illustrations of flowers, fruits, and insects. It would prove to be, as The Getty, who now own the manuscript, comment, “one of the most unusual collaborations between scribe and painter in the history of manuscript illumination”. In addition to the amendments to Bocksay’s pages shown here, Hoefnagel also added an elaborately illustrated section on constructing the letters of the alphabet which we featured on the site a while back.</p>'
- - https://publicdomainreview.org/essay/christopher-smarts-jubilate-agno/
  - ! "Christopher Smart’s Jubilate Agno"
  - Frank Key
  - 2011-01-31
  - ''
  - ! '<p>The poet Christopher Smart—also known as “Kit Smart”, “Kitty Smart”, “Jack Smart” and, on occasion, “Mrs Mary Midnight”—was a well known figure in 18th-century London. Nowadays he is perhaps best known for considering his cat Jeoffry. Writer and broadcaster Frank Key looks at Smart’s weird and wonderful <em>Jubilate Agno</em>…</p><p>It was not until 1939 that his masterpiece, written during his confinement in St Luke’s, was first published. <em>Jubilate Agno</em> is one of the most extraordinary poems in the English language, and almost certainly the reason we remember Christopher Smart today. It has been described as a vast hymn of praise to God and all His works, and also as the ravings of a madman. Indeed, that first edition was published under the title <em>Rejoice In The Lamb: A Song From Bedlam</em>, clearly marking it as a curio from the history of mental illness. It was W H Bond’s revised edition of 1954 which gave order to Smart’s surviving manuscript, restoring the Latin title <em>Jubilate Agno</em>, bringing us the poem in the form we know it today.</p><p>Christopher Smart never completed the work, which consists of four fragments making a total of over 1,200 lines, each beginning with the words “Let” or “For”. For example, Fragment A is all “Let”s, whereas in Fragment B the “Let”s and “For”s are paired, which may have been the intention for the entire work, modelled on <a href="https://en.wikipedia.org/wiki/Antiphon">antiphonal</a> <a href="https://en.wikipedia.org/wiki/Biblical_poetry">Hebrew poetry</a>. References and allusions abound to Biblical (especially Old Testament) figures, plants and animals, gems, contemporary politics and science, the poet’s family and friends, even obituary lists in current periodicals. The language is full of puns, archaisms, coinages, and unfamiliar usages. Dr Johnson famously said “Nothing odd will do long; <em>Tristram Shandy</em> did not last”. <em>Jubilate Agno</em> is, if anything, “odder” than Sterne’s novel, and perhaps we are readier to appreciate it in the twenty-first century than when it was written…one of the great joys of <em>Jubilate Agno</em> is in its sudden dislocations and unexpected diversions. The “my cat Jeoffrey” passage is justly famous, but the poem is cram-packed with similar wonders, and must be read in full to appreciate its inimitable genius.</p>'
- - https://publicdomainreview.org/essay/illustrations-of-madness-james-tilly-matthews-and-the-air-loom/
  - 'Illustrations of Madness: James Tilly Matthews and the Air Loom'
  - Mike Jay
  - 2014-11-12
  - ''
  - ! '<p>Mike Jay recounts the tragic story of James Tilly Matthews, a former peace activist of the Napoleonic Wars who was confined to London’s notorious Bedlam asylum in 1797 for believing that his mind was under the control of the “Air Loom”—a terrifying machine whose mesmeric rays and mysterious gases were brainwashing politicians and plunging Europe into revolution, terror, and war.</p><p>…Over the ten years they had spent together in Bedlam, Matthews revealed his secret world to Haslam in exhaustive detail. Around the corner from Bedlam, in a dank basement cellar by London Wall, a gang of villains were controlling and tormenting him with a machine called an “Air Loom”. Matthews had even drawn a technical diagram of the device, which Haslam included in his book with a sarcastic commentary that invited the reader to laugh at its absurdity: a literal “illustration of madness”. But Matthews’ drawing has a more unnerving effect than Haslam allows. Levers, barrels, batteries, brass retorts and cylinders are rendered with the cool conviction of an engineer’s blueprint. It is the first ever published work of art by an asylum inmate, but it would hardly have looked out of place in the scientific journals or enyclopaedias of its day.</p><p>The Air Loom worked, as its name suggests, by weaving “airs”, or gases, into a “warp of magnetic fluid” which was then directed at its victim. Matthews’ explanation of its powers combined the cutting-edge technologies of pneumatic chemistry and the electric battery with the controversial science of animal magnetism, or mesmerism. The finer detail becomes increasingly strange. It was fuelled by combinations of “fetid effluvia”, including “spermatic-animal-seminal rays”, “putrid human breath”, and “gaz from the anus of the horse”, and its magnetic warp assailed Matthews’ brain in a catalogue of forms known as “event-workings”. These included “brain-saying” and “dream-working”, by which thoughts were forced into his brain against his will, and a terrifying array of physical tortures from “knee nailing”, “vital tearing” and “fibre ripping” to “apoplexy-working with the nutmeg grater” and the dreaded “lobster-cracking”, where the air around his chest was constricted until he was unable to breathe. To facilitate their control over him, the gang had implanted a magnet into his brain. He was tormented constantly by hallucinations, physical agonies, fits of laughter or being forced to parrot whatever words they chose to feed into his head. No wonder some people thought he was mad.</p><p>The machine’s operators were a gang of undercover Jacobin terrorists, who Matthews described with haunting precision. Their leader, Bill the King, was a coarse-faced and ruthless puppetmaster who “has never been known to smile”; his second-in-command, Jack the Schoolmaster, took careful notes on the Air Loom’s operations, pushing his wig back with his forefinger as he wrote. The operator was a sinister, pockmarked lady known only as the “Glove Woman”. The public face of the gang was a sharp-featured woman named Augusta, superficially charming but “exceedingly spiteful and malignant” when crossed, who roamed London’s west end as an undercover agent.</p><p>The operation directed at Matthews was only part of a larger story. There were more Air Looms and their gangs concealed across London, and their unseen influence extended all the way up to the Prime Minister, William Pitt, whose mind was firmly under their control. Their agents lurked in streets, theatres and coffee-houses, where they tricked the unsuspecting into inhaling magnetic fluids. If the gang were recognised in public, they would grasp magnetised batons that clouded the perception of anyone in the vicinity. The object of their intrigues was to poison the minds of politicians on both sides of the Channel, and thereby keep Britain and revolutionary France locked into their ruinous war.</p>'
- - https://www.scientificamerican.com/article/vacancy-hermit-crab-social-networks/
  - "On a Tiny Caribbean Island, Hermit Crabs Form Sophisticated Social Networks [Video]: Hermit crabs have evolved sophisticated social strategies to exchange resources so that everyone benefits"
  - Ferris Jabr (<em>Scientific American</em>)
  - 2012-06-05
  - ''
  - ! '<p>…As they grow, hermit crabs must move into larger shells, so they are always on the lookout for a more spacious dwelling. And an undamaged shell is preferable to a broken one, even if the shells are the same size. Knowing this, the researchers decided to dramatically change the available hermit crab real estate on Carrie Bow Cay. They placed 20 beautifully intact shells that were a little too big for most hermit crabs at various spots around the island and watched what happened.</p><p>When a lone crab encountered one of the beautiful new shells, it immediately inspected the shelter with its legs and antennae and scooted out of its current home to try on the new shelter for size. If the new shell was a good fit, the crab claimed it. Classic hermit crab behavior. But if the new shell was too big, the crab did not scuttle away disappointed—instead, it stood by its discovery for anywhere between 15 minutes and 8 hours, waiting. This was unusual. Eventually other crabs showed up, each one trying on the shell. If the shell was also too big for the newcomers, they hung around too, sometimes forming groups as large as 20. The crabs did not gather in a random arrangement, however. Rather, they clamped onto one another in a conga line stretching from the largest to smallest animal—a behavior the biologists dubbed “piggybacking.”</p><p>Only one thing could break up the chain of crabs: a Goldilocks hermit crab for whom the shell introduced by Lewis and Rotjan was just right. As soon as such a crab claimed its new home, all the crabs in queue swiftly exchanged shells in sequence. The largest crab at the front of the line seized the Goldilocks crab’s abandoned shell. The second largest crab stole into the first’s old shell. And so on.</p><p>No one had ever documented such well-orchestrated shell swapping before, but similar behavior was not unknown. In 1986, Ivan Chase of Stony Brook University made the first observations of hermit crabs exchanging shells in a “vacancy chain”—a term originally coined by social scientists to describe the ways that people trade coveted resources like apartments and jobs. When one person leaves, another moves in. Since then, several researchers—including Lewis and Rotjan—have studied the behavior in different hermit crab species. Some preliminary evidence suggests that other animals use vacancy chains too, including clown fish, lobsters, octopuses and some birds. As Chase explains in the June issue of Scientific American, vacancy chains are an excellent way to distribute resources: Unlike more typical competition, a single vacancy chain benefits everyone involved—each individual gets an upgrade. So it makes sense that hermit crabs and other animals have evolved sophisticated social behaviors to make the most of vacancy chains.</p>'
- - https://www.ianwatson.info/plumbing-stanley-kubrick/
  - Plumbing Stanley Kubrick
  - Ian Watson
  - '1999'
  - ''
  - ! '<p>[A Scottish writer’s memoir of years working on <a href="https://en.wikipedia.org/wiki/A.I._Artificial_Intelligence"><em>A.I. Artificial Intelligence</em></a> &amp; coping with <a href="https://en.wikipedia.org/wiki/Stanley_Kubrick">Stanley Kubrick’s</a> eccentricities.</p><p>Summoned to Kubrick’s secluded mansion and offered an enormous sum of money, Watson began collaborating on a film idea with Kubrick, who was a perfectionist who demanded endless marathon revisions of possible stories and ideas, only to throw them out and hare off on an entirely different avenue; he would spend extravagantly on travel or books on a topic or demand photos of a particular place or a specific item like a bag on sale only discard them without a second look, perennially challenging his assistants’ patience. (This attitude extended to his films, where he thought nothing of ordering in an entire plastic replica garden, only to decide it was inadequate, discard it, and order real palm trees flown in.) He was a lover of animals like cats, dogs, and birds, requiring a servant to mow grass &amp; deliver it to a cat kept upstairs on a daily basis, although his affection was often quite as harmful as helpful (his generosity in ordering feeding of the birds made them obese). Careless of rough drafts, he’d lose printouts or erase disks, but even more paranoid, he would be infuriated when the local hacker who assisted them with computer problems restored files from backups the hacker had prudently kept. This paranoia further kept him terrified about global geopolitics, such as whether Saddam Hussein would trigger nuclear war in the Middle East.</p><p>For all the surreal comedy, when Kubrick dies—<em>A.I</em> still being nowhere near filming, of course—and Watson writes up his memoirs, he finds that he misses Kubrick and “I remain sad that he’s gone.”]</p>'
- - https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/17526/%22%20manuscript.pdf?sequence=1&isAllowed=y
  - "Humans can identify cats’ affective states from subtle facial expressions"
  - L.C. Dawson, J. Cheal, L. Niel, G. Mason
  - 2019-11
  - '10.7120/09627286.28.4.519'
  - ! '<p>Although cats’ popularity as pets rivals that of dogs, cats are little studied, and people’s abilities to read this apparently ’inscrutable’ species have attracted negligible research. To determine whether people can identify feline emotions from cats’ faces, participants (<em>n</em> = 6,329) each viewed 20 video clips of cats in carefully operationalised positively (<em>n</em> = 10) or negatively valenced states (<em>n</em> = 10) (cross-factored with low and high activity levels). Obvious cues (eg open mouths or fully retracted ears) were eliminated. Participants’ average scores were low (11.85/20 correct), but overall above chance; furthermore, 13% of participants were individually significantly successful at identifying the valence of cats’ states (scoring ≥ 15/20 correct). Women were more successful at this task than men, and younger participants more successful than older, as were participants with professional feline (eg veterinary) experience. In contrast, personal contact with cats (eg pet-owning) had little effect. Cats in positive states were most likely to be correctly identified, particularly if active rather than inactive. People can thus infer cats’ affective states from subtle aspects of their facial expressions (although most find this challenging); and some individuals are very good at doing so. Understanding where such abilities come from, and precisely how cats’ expressions change with affective state, could potentially help pet owners, animal care staff and veterinarians optimise feline care and welfare.</p>'
- - https://dspace.mit.edu/handle/1721.1/116112
  - "Pricing the Future in the Seventeenth Century: Calculating Technologies in Competition"
  - William P. Deringer
  - 2017-04
  - ''
  - ! 'Time is money. But how much? What is money in the future worth to you today? This question of "present value" arises in myriad economic activities, from valuing financial securities to real estate transactions to governmental cost-benefit analysis—even the economics of climate change. In modern capitalist practice, one calculation offers the only "rational" way to answer: compound-interest discounting. In the early modern period, though, economic actors used at least two alternative calculating technologies for thinking about present value, including a vernacular technique called years purchase and discounting by simple interest. All of these calculations had different strengths and affordances, and none was unquestionably better or more "rational" than the others at the time. The history of technology offers distinct resources for understanding such technological competitions, and thus for understanding the emergence of modern economic temporality.'
- - https://bitcoin.org/bitcoin.pdf
  - "Bitcoin: A Peer-to-Peer Electronic Cash System"
  - Satoshi Nakamoto
  - 2008-10-31
  - ''
  - ! "A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network.The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone."
- - https://www.avmf.org/clientuploads/documents/News%20Articles/Cat%20Health%20Network%20Feline%20SNP%20Chip%20Studies%20-%20Final%20Accomplishments%20MAFFINAL%2005-23-13.pdf#page=5
  - Cat Health Network Feline SNP Chip Studies Final Accomplishments
  - Cat Health Network
  - '2011'
  - ''
  - ! 'Morris Animal Foundation, the American Veterinary Medical Foundation, Winn Feline Foundation and the American Association of Feline Practitioners collaborated to form the Cat Health Network in 2011. The partners are all committed to improving feline health and recognize that combining resources may lead to major advances in cat care. Through the Cat Health Network, scientists used a gene chip containing single nucleotide polymorphisms (SNPs, pronounced “snips”) to study numerous genetic predispositions to feline diseases and conditions. Following are final, lay-language status updates for all awards that have completed.'
- - https://www.apa.org/pubs/journals/releases/neu-24-5-563.pdf
  - Influence of Age on Practice Effects in Longitudinal Neurocognitive Change
  - Timothy A. Salthouse
  - '2010'
  - 10.1037/a0019026
  - ! '<p>Longitudinal comparisons of neurocognitive functioning often reveal stability or age-related increases in performance among adults under about 60 years of age. Because nearly monotonic declines with increasing age are typically evident in cross-sectional comparisons, there is a discrepancy in the inferred age trends based on the two types of comparisons. The current research investigated the role of practice effects in longitudinal comparisons on the discrepancy.</p><p><em>Method</em>: Longitudinal data over an average interval of 2.5 years were available on five abilities (i.e., reasoning, spatial visualization, episodic memory, perceptual speed, vocabulary) in a sample of 1,616 adults ranging from 18 to over 80 years of age. Practice effects were estimated from comparisons of the performance of people of the same age tested for either the first or second time, after adjusting for the possibility of selective attrition.</p><p><em>Results</em>:Increased age was associated with significantly more negative longitudinal changes with each ability. All of the estimated practice effects were positive, but they varied in magnitude across neurocognitive abilities and as a function of age. After adjusting for practice effects the longitudinal changes were less positive at younger ages and slightly less negative at older ages.</p><p><em>Conclusions</em>: It was concluded that some, but not all, of the discrepancy between cross-sectional and longitudinal age trends in neurocognitive functioning is attributable to practice effects positively biasing the longitudinal trends. These results suggest that the neurobiological substrates of neurocognitive functioning may change across different periods in adulthood.</p>'
- - https://www.albany.edu/faculty/kretheme/PAD705/PastExams/JPE_RolePreMarketBWWageDiff.pdf
  - "The Role of Premarket Factors in Black-White Wage Differences"
  - Derek A. Neal, William R. Johnson
  - '1996'
  - 10.1086/262045
  - ! "Many attempts to measure the wage effects of current labor market discrimination against minorities include controls for worker productivity that could themselves be affected by market discrimination and are very imprecise measures of worker skill. The resulting estimates of residual wage gaps may be biased. Our approach is a parsimoniously specified wage equation that controls for skill with the score of a test administered as teenagers prepared to leave high school and embark on work careers or post-secondary education. Independent evidence shows that this test score is a racially unbiased measure of the skills and abilities these teenagers were about to bring to the labor market. We find that this one test score explains all of the black-white wage gap for young women and much of the gap for young men. For today's young adults, the black-white wage gap primarily reflects a skill gap, which in turn we can trace, at least in part, to observable differences in the family backgrounds and school environments of black and white children. While our results do provide some evidence of current labor market discrimination, skill gaps play such a large role that we believe future research should focus on the obstacles black children face in acquiring productive skill."
- - https://foundation.wikimedia.org/wiki/File:UK_BOARD_MEETING.pdf
  - Wikimedia UK Board Meeting, London
  - Sue Gardner
  - 2011-11-19
  - ''
  - ! "It's getting harder for new people to join our projects. Newbies are making up a smaller percentage of editors overall than ever before, and the absolute number of newbies is dropping as well. Wikimedia needs to attract and retain more new and diverse editors, and to retain our experienced editors. A stable editing community is critical to the long-term sustainability and quality of both our current projects and our movement.We consider meeting this challenge our top priority."
- - http://web.elastic.org/~fche/mirrors/www.cryptome.org/2014/06/wmd-4th-gen-quest.pdf
  - The physical principles of thermonuclear explosives, inertial confinement fusion, and the quest for fourth generation nuclear weapons
  - Andre Gsponer, Jean-Pierre Hurni
  - 2009-01-20
  - ''
  - ! "<p>This report is an assessment of the prospect of developing new (i.e., fourth generation) nuclear weapons in the context of the Comprehensive Nuclear Test-Ban Treaty (CTBT) that was adopted by the UN General Assembly in 1996 and of the current moratorium on nuclear testing in effect in all nuclear-weapon States.</p> <p>The conclusion stresses that considerable research is underway in all five nuclear-weapon States (as well as in several other major industrialized States such as Germany and Japan) on ICF and on many physical processes that provide the scientific basis necessary to develop fourth generation nuclear weapons. Substantial progress has been made in the past few years on all these processes, and the construction of large ICF microexplosion facilities in both nuclear-weapon and non-nuclear-weapon States is giving the arms race a fresh boost. The world runs the risk that certain countries will equip themselves directly with fourth generation nuclear weapons, bypassing the acquisition of previous generations of nuclear weapons.</p>"
- - http://uweb.cas.usf.edu/~drohrer/pdfs/Cepeda_et_al_2006PsychBull.pdf
  - ! "Distributed Practice in Verbal Recall Tasks: A Review and Quantitative Synthesis"
  - 'Nicholas J. Cepeda, Harold Pashler, Edward Vul, John T. Wixted, Doug Rohrer'
  - '2006'
  - '10.1037/0033-2909.132.3.354'
  - ! 'The authors performed a meta-analysis of the distributed practice effect to illuminate the effects of temporal variables that have been neglected in previous reviews. This review found 839 assessments of distributed practice in 317 experiments located in 184 articles. Effects of spacing (consecutive massed presentations vs. spaced learning episodes) and lag (less spaced vs. more spaced learning episodes) were examined, as were expanding inter study interval (ISI) effects. Analyses suggest that ISI and retention interval operate jointly to affect final-test retention; specifically, the ISI producing maximal retention increased as retention interval increased. Areas needing future research and theoretical implications are discussed.'
- - https://sites.williams.edu/nk2/files/2011/08/Kornell.2009b.pdf
  - 'Optimising Learning Using Flashcards: Spacing Is More Effective Than Cramming'
  - Nate Kornell
  - 2009-01-19
  - 10.1002/acp.1537
  - ! "The spacing effect—that is, the benefit of spacing learning events apart rather than massing them together—has been demonstrated in hundreds of experiments, but is not well known to educators or learners. I investigated the spacing effect in the realistic context of flashcard use. Learners often divide flashcards into relatively small stacks, but compared to a large stack, small stacks decrease the spacing between study trials. In three experiments, participants used a web-based study programme to learn GRE-type word pairs. Studying one large stack of flashcards (i.e. spacing) was more effective than studying four smaller stacks of flashcards separately (i.e. massing). Spacing was also more effective than cramming—that is, massing study on the last day before the test. Across experiments, spacing was more effective than massing for 90% of the participants, yet after the first study session, 72% of the participants believed that massing had been more effective than spacing."
- - https://scottbarrykaufman.com/wp-content/uploads/2012/01/Nisbett-et-al.-2012.pdf
  - "Intelligence: New Findings and Theoretical Developments"
  - Richard E. Nisbett, Joshua Aronson, Clancy Blair, William Dickens, James Flynn, Diane F. Halpern, Eric Turkheimer
  - 2012-01-02
  - 10.1037/a0026699
  - ! "We review new findings and new theoretical developments in the field of intelligence. New findings include the follow-ing: (a) Heritability of IQ varies significantly by social class. (b) Almost no genetic polymorphisms have been discovered that are consistently associated with variation in IQ in the normal range. (c) Much has been learned about the biological underpinnings of intelligence. (d) “Crystallized” and “fluid” IQ are quite different aspects of intelligence at both the behavioral and biological levels. (e) The importance of the environment for IQ is established by the 12-point to 18-point increase in IQ when children are adopted from working-class to middle-class homes. (f) Even when improvements in IQ produced by the most effective early childhood interventions fail to persist, there can be very marked effects on academic achievement and life outcomes. (g) In most developed countries studied, gains on IQ tests have continued, and they are beginning in the developing world. (h) Sex differences in aspects of intelligence are due partly to identifiable biological factors and partly to socialization factors. (i) The IQ gap between Blacks and Whites has been reduced by 0.33 SD in recent years. We report theorizing concerning (a) the relationship between working memory and intelligence, (b) the apparent contradiction between strong heritability effects on IQ and strong secular effects on IQ, (c) whether a general intelligence factor could arise from initially largely independent cognitive skills, (d) the relation between self-regulation and cognitive skills, and (e) the effects of stress on intelligence."
- - https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.2004.1468
  - 'Chemistry of the adaptive mind'
  - Roshan Cools, Trevor W. Robbins
  - 2004-09-20
  - 10.1098/rsta.2004.1468
  - ! "A failure to adapt to novel or changing environmental demands is a core feature of a wide variety of neuropsychiatric disorders as well as the normal states of stress and fatigue. We review the neurochemistry of cognitive control, which has been associated primarily with the prefrontal cortex. Many drugs affect the functioning of the prefrontal cortex, but the direction and extent of drug effects vary across individuals and tasks. Apparently paradoxical effects are often observed, where the same medication causes both cognitive enhancement as well as cognitive side effects. We review neurobiological research that is beginning to elucidate the nature of these contrasting effects and the factors underlying the large variability across individuals and behaviours. The work has considerable implications for the understanding of and treatment development for abnormalities such as Parkinson's disease, attention deficit hyperactivity disorder and drug addiction."
- - https://api.research-repository.uwa.edu.au/portalfiles/portal/11790041/Flematti_MS.pdf
  - "Identification of the cat attractants isodihydronepetalactone and isoiridomyrmecin from <em>Acalypha indica</em>"
  - Adrian Scaffidi, Dave Algar, Björn Bohman, Emilio L. Ghisalberti1, Gavin Flematti
  - '2016'
  - 10.1071/CH15476_AC
  - ! "<em>Acalypha indica</em> is a herb that grows throughout the tropical regions of the world. As well as being exploited for medicinal use, the roots of this plant are known to elicit a drug-like effect on cats. Recent research into feral cat control on Christmas Island has investigated whether a preparation of the roots of <em>A. indica</em> might be effective in traps to attract feral cats. However, the volatile nature of the attractants made it unviable for use in traps for more than a few days. In this study we investigated the volatile components emitted by the plant roots and identified two iridoid compounds, (4R,4aR,7S,7aR)-isodihydronepetalactone and (4R,4aS,7S,7aR)-isoiridomyrmecin, which are known to affect behavioural activity in cats. Synthesis of standards confirmed the stereochemistry of both compounds emitted by the plant. Potential application for these compounds in feral cat control is discussed."
- - https://pdfs.semanticscholar.org/7687/cce675f3b1b51067ed9d0a3d70da64741764.pdf
  - "Energetics And The Evolution Of The Genus <em>Homo</em>"
  - Leslie C. Aiello, Jonathan C. K. Wells
  - 2002-10
  - 10.1146/annurev.anthro.31.040402.085403
  - ! '<p>The genus <em>Homo</em> as represented by <em>Homo ergaster</em> (= early African <em>Homo erectus</em>) is characterized by a pattern of features that is more similar to modern humans than to the earlier and contemporaneous australopithecines and paranthropines. These features include larger relative brain sizes, larger bodies, slower rates of growth and maturation, dedicated bipedal locomotion, and smaller teeth and jaws. These features are phenotypic expressions of a very different lifestyle for the earliest members of the genus <em>Homo</em>. This paper considers the energetic correlates of the emergence of the genus <em>Homo</em> and suggests that there were three major changes in maintenance energy requirements. First, there was an absolute increase in energy requirements due to greater body size. Second, there was a shift in the relative requirements of the different organs, with increased energy diverted to brain metabolism at the expense of gut tissue, possibly mediated by changes in the proportion of weight comprised of fat. And third, there was a slower rate of childhood growth, offset by higher growth costs during infancy and adolescence. These changes, as well as energetic requirements of reproduction and bipedal locomotion, are considered in a discussion of one of the major transitions in adaptation in human evolution, the appearance of our own genus.</p><p>[Keywords: human evolution; metabolic rate; diet; growth; <em>Homo erectus</em>; <em>Homo ergaster</em>; australopithecines; brain evolution.]</p>'
- - http://repec.org/sed2006/up.30684.1139268077.pdf
  - "IQ in the Ramsey Model: A Naïve Calibration"
  - Garett Jones
  - '2006'
  - ''
  - ! 'I show that in a conventional Ramsey model, between one-fourth and one-half of the global income distribution can be explained by a single factor: The effect of large, persistent differences in national average IQ on the private marginal product of labor. Thus, differences in national average IQ may be a driving force behind global income inequality. These persistent differences in cognitive ability&mdash;which are well-supported in the psychology literature&mdash;are likely to be somewhat malleable through better health care, better education, and especially better nutrition in the world’s poorest countries. A simple calibration exercise in the spirit of Bils and Klenow (2000) and Castro (2005) is conducted. I show that an IQ-augmented Ramsey model can explain more than half of the empirical relationship between national average IQ and GDP per worker. I provide evidence that little of the IQ-productivity relationship is likely to be due to reverse causality.'
- - /docs/nootropics/2008-dejongh.pdf
  - "Botox for the brain: enhancement of cognition, mood and pro-social behavior and blunting of unwanted memories"
  - Reinoud de Jongh, Ineke Bolt, Maartje Schermer, Berend Olivier
  - 2007-12-17
  - 10.1016/j.neubiorev.2007.12.001
  - ! 'It has been suggested that the recent rapid developments in the fields of neuroscience and psychopharmacology have increased the possibilities for pharmacological enhancement of mental functioning. Here, evidence is reviewed which shows that drugs acting on a variety of neurotransmitter systems can indeed enhance cognition, and to a lesser extent mood and pro-social behavior. Moreover, it seems possible to interfere with the (re)consolidation of traumatic memories. There are, however, a number of caveats: first, as cognition-enhancing drugs can simultaneously exert both linear and quadratic (U-shaped) effects, doses most effective in facilitating one behavior could at the same time exert null or even detrimental effects on other cognitive domains. Second, individuals with a ‘low memory span’ might benefit from cognition-enhancing drugs, whereas ‘high span subjects’ are ‘overdosed’. And finally, evidence suggests that a number of trade-offs could occur. For example, increases of cognitive stability might come at the cost of a decreased capacity to flexibly alter behavior. A short overview of ethical issues raised by the use of cognition and mood enhancing drugs demonstrates the tremendous variety in views and opinions regarding the subject.'
- - http://psychnet.wustl.edu/coglab/wp-content/uploads/2015/01/2007-Is-expanded.pdf
  - "Is Expanded Retrieval Practice a Superior Form of Spaced Retrieval? A Critical Review of the Extant Literature"
  - David A. Balota, Janet M. Duchek, Jessica M. Logan
  - '2015'
  - ''
  - ! 'The spacing effect is one of the most ubiquitous findings in learning and memory.Performance on a variety of tasks is better when the repetition of the to-be-learned information is distributed as opposed to massed in presentation. This observation was first formalized in Jost’s law, which states that “if two associations are of equal strength but of different age, a new repetition has a greater value for the older one” (McGeogh, 1943). Spacing effects occur across domains (e.g., learning perceptual motor tasks vs. learning lists of words), across species (e.g., rats, pigeons, and humans), across age groups and individuals with different memory impairments,and across retention intervals of seconds to months (see Cepeda, Pashler, Vul,Wixted, & Rohrer, 2006; Crowder, 1976; Dempster, 1996, for reviews). In this light, it is interesting that spacing effects have not received much attention in Cognitive Psychology textbooks. In fact, in our sampling of seven such textbooks,only one had a section dedicated to this topic, while virtually all cognitive text-books discussed mnemonic techniques such as the pegword or method of loci. Given the power and simplicity of implementing spaced practice, we clearly hope this changes in the future.'
- - https://people.seas.harvard.edu/~salil/research/timelock.pdf
  - Time-Lock Puzzles in the Random Oracle Model
  - Mohammad Mahmoody, Tal Moran, Salil Vadhan
  - 2011-07-18
  - 10.1007/978-3-642-22792-9_3
  - ! 'A time-lock puzzle is a mechanism for sending messages “to the future”. The sender publishes a puzzle whose solution is the message to be sent, thus hiding it until enough time has elapsed for the puzzle to be solved. For time-lock puzzles to be useful, generating a puzzle should take less time than solving it. Since adversaries may have access to many more computers than honest solvers, massively parallel solvers should not be able to produce a solution much faster than serial ones.To date, we know of only one mechanism that is believed to satisfy these properties: the one proposed by Rivest, Shamir and Wagner (1996), who originally introduced the notion of time-lock puzzles. Their puzzle is based on the serial nature of exponentiation and the hardness of factoring, and is therefore vulnerable to advances in factoring techniques (as well as to quantum attacks). In this work, we study the possibility of constructing time-lock puzzles in the random-oracle model. Our main result is negative, ruling out time-lock puzzles that require more parallel time to solve than the total work required to generate a puzzle. In particular, this rules out black-box constructions of such time-lock puzzles from one-way permutations and collision-resistant hash-functions. On the positive side, we construct a time-lock puzzle with a linear gap in parallel time: a new puzzle can be generated with one round of <em>n</em> parallel queries to the random oracle, but <em>n</em> rounds of serial queries are required to solve it (even for massively parallel adversaries).'
- - /docs/algernon/1995-aiello.pdf
  - "The Expensive-Tissue Hypothesis: The Brain and the Digestive System in Human and Primate Evolution"
  - Leslie C. Aiello, Peter Wheeler
  - '1995'
  - 10.2307/2744104
  - ! 'Brain tissue is metabolically expensive, but there is no significant correlation between relative basal metabolic rate and relative brain size in humans and other encephalized mammals. The expensive-tissue hypothesis suggests that the metabolic requirements of relatively large brains are offset by a corresponding reduction of the gut. The splanchnic organs (liver and gastro-intestinal tract) are as metabolically expensive as brains, and the gut is the only one of the metabolically expensive organs in the human body that is markedly small in relation to body size. Gut size is highly correlated with diet, and relatively small guts are compatible only with high-quality, easy-to-digest food. The often-cited relationship between diet and relative brain size is more properly viewed as a relationship between relative brain size and relative gut size, the latter being determined by dietary quality. No matter what is selecting for relatively large brains in humans and other primates, they cannot be achieved without a shift to a high-quality diet unless there is a rise in the metabolic rate. Therefore the incorporation of increasingly greater amounts of animal products into the diet was essential in the evolution of the large human brain.'
- - https://paulbingley.com/papers/signals-manuscript.pdf
  - Signaling and Productivity in the Private Financial Returns to Schooling
  - Paul Bingley; Kaare Christensen; Kristoffer Markwardt
  - 2015-06-20
  - ''
  - ! 'Does formal schooling contribute to individual labor market productivity or does it act as a signal to employers of predetermined labor market skills? We test for whether employers statistically discriminate between workers on the basis of their schooling, by assuming we can observe a proxy for worker productivity that the employer cannot&mdash;father, brother and co-twin earnings. Using population-based Danish administrative data, we find that employers initially statistically discriminate be-tween workers on the basis of schooling, but schooling earnings differentials fall overtime as employers learn about worker productivity. We further propose a novel test for job market signaling using differences in twin pair earnings growth, and find that signaling is important at the upper end of the schooling distribution&mdash;explaining a large proportion of the college wage premium.'
- - https://papers.nips.cc/paper/5185-more-efficient-reinforcement-learning-via-posterior-sampling.pdf#deepmind
  - (More) Efficient Reinforcement Learning via Posterior Sampling
  - Ian Osband; Benjamin Van Roy; Daniel Russo
  - 2013-06-04
  - ''
  - ! 'Most provably-efficient learning algorithms introduce optimism about poorly-understood states and actions to encourage exploration. We study an alternative approach for efficient exploration, posterior sampling for reinforcement learning (PSRL). This algorithm proceeds in repeated episodes of known duration. At the start of each episode, PSRL updates a prior distribution over Markov decision processes and takes one sample from this posterior. PSRL then follows the policy that is optimal for this sample during the episode. The algorithm is conceptually simple, computationally efficient and allows an agent to encode prior knowledge in a natural way. We establish an Õ(τ ⋅ S ⋅ √(AT)) bound on the expected regret, where <em>T</em> is time, τ is the episode length and <em>S</em> and <em>A</em> are the cardinalities of the state and action spaces. This bound is one of the first for an algorithm not based on optimism, and close to the state of the art for any reinforcement learning algorithm. We show through simulation that PSRL significantly outperforms existing algorithms with similar regret bounds.'
- - http://oops.uni-oldenburg.de/624/13/grafee01.pdf
  - Feeling Pain and Being in Pain
  - Nikola Grahek
  - '2001'
  - ''
  - ! 'This book is principally devoted to the thorough consideration and general theoretical appreciation of the two most radical dissociation syndromes to be found in human pain experience. The first syndrome is related to the complete dissociation between sensory and affective, cognitive and behavioral components of pain, while the second one has to do with absolute dissociation that goes into opposite direction: the full dissociation of affective components of human pain experience from its sensory-discriminative components. The former syndrome can be called pain without painfulness and the latter one painfulness without pain. In the first case, one is able to feel pain but is not able to be in pain, while in the second case one is able to be in pain but not able to feel pain. Taking into account our common experience of pain, it might well seem to us that the two syndromes just described are inconceivable and, thus, impossible. In order to make them more intelligible and, thus, less inconceivable, the crucial distinction between feeling pain and being in pain is introduced and explained on conceptual and empirical grounds. But the main point is that pain without painfulness as well as painfulness without pain are, however bizarre or outlandish, nonetheless possible, for the simple reason that ample clinical evidence conclusively shows that they can be found in human pain experience. So, the question is not whether they exist or can exist, but what they can teach us about the true nature and structure of human pain experience. Accordingly, the major theoretical aim of this book will be to appreciate what lessons are to be learned from the consideration of these syndromes as far as our very concept or, more importantly, our very experience of pain is concerned.'
- - https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD007469.pub2/pdf/full
  - "Vitamin D supplementation for prevention of cancer in adults (Review)"
  - G. Bjelakovic, L.L. Gluud, D. Nikolova, K. Whitfield, G. Krstic, J. Wetterslev, C. Gluud
  - '2014'
  - 10.1002/14651858.CD007469.pub2
  - ! 'There is currently no firm evidence that vitamin D supplementation decreases or increases cancer occurrence in predominantly elderly community-dwelling women. Vitamin DE supplementation decreased cancer mortality and vitamin D supplementation decreased all-cause mortality, but these estimates are at risk of type I errors due to the fact that too few participants were examined, and to risks of attrition bias originating from substantial dropout of participants. Combined vitamin DE and calcium supplements increased nephrolithiasis, whereas it remains unclear from the included trials whether vitamin DE, calcium, or both were responsible for this effect. We need more trials on vitamin D supplementation, assessing the benefits and harms among younger participants, men, and people with low vitamin D status, and assessing longer duration of treatments as well as higher dosages of vitamin D. Follow-up of all participants is necessary to reduce attrition bias.'
- - https://link.springer.com/content/pdf/10.1007%2Fs13238-015-0153-5.pdf
  - 'CRISPR/Cas9-mediated gene editing in human tripronuclear zygotes'
  - Puping Liang, Yanwen Xu, Xiya Zhang, Chenhui Ding, Rui Huang, Zhen Zhang, Jie Lv, Xiaowei Xie,Yuxi Chen, Yujing Li, Ying Sun, Yaofu Bai, Zhou Songyang, Wenbin Ma, Canquan Zhou, Junjiu Huang
  - 2015-04-01
  - 10.1007/s13238-015-0153-5
  - ! 'Genome editing tools such as the clustered regularly interspaced short palindromic repeat (CRISPR)-associated system (Cas) have been widely used to modify genes in model systems including animal zygotes and human cells, and hold tremendous promise for both basic research and clinical applications. To date, a serious knowledge gap remains in our understanding of DNA repair mechanisms in human early embryos, and in the efficiency and potential off-target effects of using technologies such as CRISPR/Cas9 in human pre-implantation embryos. In this report, we used tripronuclear(3PN) zygotes to further investigate CRISPR/Cas9-mediated gene editing in human cells. We found that CRISPR/Cas9 could effectively cleave the endogenousβ-globin gene (HBB). However, the efficiency of homologous recombination directed repair (HDR) of HBB was low and the edited embryos were mosaic. Off-target cleavage was also apparent in these 3PN zygotes as revealed by the T7E1 assay and whole-exome sequencing. Furthermore, the endogenous delta-globin gene (HBD), which is homologous to HBB, competed with exogenous donor oligos to act as the repair template, leading to untoward mutations. Our data also indicated that repair of the HBB locus in these embryos occurred preferentially through the non-crossover HDR pathway. Taken together, our work highlights the pressing need to further improve the fidelity and specificity of the CRISPR/Cas9 platform, a prerequisite for any clinical applications of CRISPR/Cas9-mediated editing.'
- - http://learningsys.org/nips17/assets/slides/dean-nips17.pdf
  - 'Machine Learning for Systems and Systems for Machine Learning'
  - Jeff Dean
  - '2017'
  - ''
  - ! 'Slide deck for Google Brain presentation on Machine Learning and the future of ML development processes. Conclusions: ML hardware is at its infancy. Even faster systems and wider deployment will lead to many more breakthroughs across a wide range of domains. Learning in the core of all of our computer systems will make them better/more adaptive. There are many opportunities for this.'
- - https://philarchive.org/archive/SOTAOAv1
  - Advantages of Artificial Intelligences, Uploads, and Digital Minds
  - Kaj Sotala
  - '2012'
  - 10.1142/S1793843012400161
  - ! 'I survey four categories of factors that might give a digital mind, such as an upload or an artificial general intelligence, an advantage over humans. Hardware advantages include greater serial speeds and greater parallel speeds. Self-improvement advantages include improvement of algorithms, design of new mental modules, and modification of motivational system. Co-operative advantages include copyability, perfect co-operation, improved communication, and transfer of skills. Human handicaps include computational limitations and faulty heuristics, human-centric biases, and socially motivated cognition. The shape of hardware growth curves, as well as the ease of modifying minds, are found to have a major impact on how quickly a digital mind may take advantage of these factors.'
- - http://jtoomim.org/brain-training/fluid%20intelligence%20and%20sleep.pdf
  - Adolescent sleep and fluid intelligence performance
  - Anna Johnston, Michael Gradisar, Hayley Dohnt, Michael Billows, Stephanie McCappin
  - '2010'
  - 10.1111/j.1479-8425.2010.00442.x
  - ! 'Fluid intelligence involves novel problem-solving and may be susceptible to poor sleep. This study examined relationships between adolescent sleep, fluid intelligence, and academic achievement. Participants were 217 adolescents (42% male) aged 13 to 18 years (mean age, 14.9 years; SD=1.0) in grades 9–11. Fluid intelligence was predicted to mediate the relationship between adolescent sleep and academic achievement. Students completed online questionnaires of self-reported sleep, fluid intelligence (Letter Sets and Number Series), and self-reported grades. Total sleep time was not significantly related to fluid intelligence nor academic achievement (both <em>p</em>&gt;0.05); however, sleep difficulty (e.g. difficulty initiating sleep, unrefreshing sleep) was related to both (<em>p</em>&lt;0.05). The strength of the relationship between sleep difficulty and grades was reduced when fluid intelligence was introduced into the model; however, the z-score was not significant to confirm mediation.Nevertheless, fluid intelligence is a cognitive ability integral in academic achievement, and in this study has been shown it to be susceptible to sleep impairments (but not duration) in adolescents.'
- - http://ije.oxfordjournals.org/content/42/4/1057.full.pdf+html
  - "The impact of neighbourhood deprivation on adolescent violent criminality and substance misuse: A longitudinal, quasi-experimental study of the total Swedish population"
  - Amir Sariaslan, Niklas Langstrom, Brian D’Onofrio, Johan Hallqvist, Johan Franck, Paul Lichtenstein
  - 2013-03-26
  - 10.1093/ije/dyt066
  - ! 'We found that the adverse effect of neighbourhood deprivation on adolescent violent criminality and substance misuse in Sweden was not consistent with a causal inference. Instead, our findings highlight the need to control for familial confounding in multilevel studies of criminality and substance misuse.'
- - http://gscan2pdf.sourceforge.net/
  - 'gscan2pdf: A GUI to produce PDFs or DjVus from scanned documents'
  - Jeffrey Ratcliffe
  - '2019'
  - ''
  - 'FLOSS Perl GUI program for scanning and processing large documents such as books, doing simple editing, and exporting to PDF.'
- - https://files.eric.ed.gov/fulltext/ED471814.pdf
  - "Can Nonexperimental Comparison Group Methods Match the Findings from a Random Assignment Evaluation of Mandatory Welfare-to-Work Programs? MDRC Working Papers on Research Methodology"
  - Howard S. Bloom, Michael Michalopoulos, Carolyn J. Hill, Ying Lei
  - '2002'
  - ''
  - ! 'A study explored which nonexperimental comparison group methods provide the most accurate estimates of the impacts of mandatory welfare-to-work programs and whether the best methods work well enough to substitute for random assignment experiments. Findings were compared for nonexperimental comparison groups and statistical adjustment procedures with those for experimental control groups from a large-sample, six-state random assignment experiment&mdash;the National Evaluation of Welfare-to-Work Strategies. The methods were assessed in terms of their ability to estimate program impacts on annual earnings during short-run and medium-run follow-up periods. Findings with respect to the first issue suggested in-state comparison groups perform somewhat better than out-of-state or multi-state, especially for medium-run impact estimates; a simple difference of means or ordinary least squares regression can perform as well or better than more complex methods when used with a local comparison group; impact estimates for out-of-state or multi-state comparison groups are not improved substantially by more complex estimation procedures but are improved somewhat when propensity score methods are used to eliminate comparison groups that are not balanced on their baseline characteristics. Findings with respect to the second issue indicated the best methods did not work well enough to replace random assignment.Statistical analyses are appended.'
- - https://eprint.iacr.org/2015/482.pdf
  - How to build time-lock encryption
  - Jia Liu, Tibor Jager, Saqib A. Kakvi, Bogdan Warinschi
  - 2018-01-20
  - 10.1007/s10623-018-0461-x
  - ! 'Time-lock encryption is a method to encrypt a message such that it can only be decrypted after a certain deadline has passed. We propose a novel time-lock encryption scheme, whose main advantage over prior constructions is that even receivers with relatively weak computational resources should immediately be able to decrypt after the deadline, without any interaction with the sender, other receivers, or a trusted third party. We build our time-lock encryption on top of the new concept of computational reference clocks and an extractable witness encryption scheme. We explain how to construct a computational reference clock based on Bitcoin. We show how to achieve constant level of multilinearity for witness encryption by using SNARKs. We propose a new construction of a witness encryption scheme which is of independent interest: our scheme, based on SubsetSum, achieves extractable security without relying on obfuscation. The scheme employs multilinear maps of arbitrary order and is independent of the implementations of multilinear maps.'
- - https://cryptome.org/0002/ja-conspiracies.pdf
  - CRYPTOME
  - Julian Assange
  - 2006-12-03
  - ''
  - ! 'These essays on conspiracies by Julian Assange (me@iq.org) were retrieved today from his website iq.org. The first from the currently active site, dated November 10, 2006, and the second at archive.org, dated December 3, 2006.'
- - http://coalition4evidence.org/wp-content/uploads/2013/06/IES-Commissioned-RCTs-positive-vs-weak-or-null-findings-7-2013.pdf
  - 'Randomized Controlled Trials Commissioned by the Institute of Education Sciences Since 2002: How Many Found Positive Versus Weak or No Effects?'
  - Coalition for Evidence-Based Policy
  - '2013'
  - ''
  - ! "Since the establishment of the Institute for Education Sciences (IES) within the U.S. Department of Education in 2002, IES has commissioned a sizable number of well-conducted randomized controlled trials (RCTs) evaluating the effectiveness of diverse educational programs, practices, and strategies (“interventions”). These interventions have included, for example, various educational curricula, teacher professional development programs, school choice programs, educational software, and data-driven school reform initiatives. Largely as a result of these IES studies, there now exists–for the first time in U.S. education–a sizable body of credible knowledge about what works and what doesn't work to improve key educational outcomes of American students. A clear pattern of findings in these IES studies is that the large majority of interventions evaluated produced weak or no positive effects compared to usual school practices. This pattern is consistent with findings in other fields where RCTs are frequently carried out, such as medicine and business,<sup>1</sup> and underscores the need to test many different interventions so as to build the number shown to work."
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.659.8433&rep=rep1&type=pdf
  - Artificial Selection on Relative Brain Size in the Guppy Reveals Costs and Benefits of Evolving a Larger Brain
  - Alexander Kotrschal, Bjorn Rogell, Andreas Bundsen, Beatrice Svensson, Susanne Zajitschek, Ioana Brannstrom, Simone Immler, Alexei A. Maklakov, Niclas Kolm
  - 2013-01-21
  - 10.1016/j.cub.2012.11.058
  - ! 'The large variation in brain size that exists in the animal kingdom has been suggested to have evolved through the balance between selective advantages of greater cognitive ability and the prohibitively high energy demands of a larger brain (the ‘‘expensive-tissue hypothesis’’). Despite over a century of research on the evolution of brain size, empirical support for the trade-off between cognitive ability and energetic costs is based exclusively on correlative evidence, and the theory remains controversial. Here we provide experimental evidence for costs and benefits of increased brain size. We used artificial selection for large and small brain size relative to body size in a live-bearing fish, the guppy (Poecilia reticulata), and found that relative brain size evolved rapidly in response to divergent selection in both sexes. Large-brained females outperformed small-brained females in a numerical learning assay designed to test cognitive ability. Moreover, large-brained lines, especially males, developed smaller guts, as predicted by the expensive-tissue hypothesis, and produced fewer offspring. We propose that the evolution of brain size is mediated by a functional trade-off between increased cognitive ability and reproductive performance and discuss the implications of these findings for vertebrate brain evolution.'
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.649.2804&rep=rep1&type=pdf
  - Proceeding From Observed Correlation to Causal Inference
  - Michael Rutter
  - '2007'
  - ''
  - ! 'This article notes 5 reasons why a correlation between a risk (or protective) factor and some specified outcome might not reflect environmental causation. In keeping with numerous other writers, it is noted that a causal effect is usually composed of a constellation of components acting in concert. The study of causation, therefore, will necessarily be informative on only one or more subsets of such components. There is no such thing as a single basic necessary and sufficient cause. Attention is drawn to the need (albeit unobservable) to consider the counterfactual (i.e., what would have happened if the individual had not had the supposed risk experience). 15 possible types of natural experiments that may be used to test causal inferences with respect to naturally occurring prior causes (rather than planned interventions) are described. These comprise 5 types of genetically sensitive designs intended to control for possible genetic mediation (as well as dealing with other issues), 6 uses of twin or adoptee strategies to deal with other issues such as selection bias or the contrasts between different environmental risks, 2 designs to deal with selection bias, regression discontinuity designs to take into account unmeasured confounders, and the study of contextual effects. It is concluded that, taken in conjunction, natural experiments can be very helpful in both strengthening and weakening causal inferences.'
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.648.1155&rep=rep1&type=pdf
  - 'The Mystery Machine: End-to-end performance analysis of large-scale Internet services'
  - Michael Chow, David Meisner, Jason Flinn, Daniel Peek, Thomas F. Wenisch
  - 2014-10-06
  - ''
  - ! 'Current debugging and optimization methods scale poorly to deal with the complexity of modern Internet services, in which a single request triggers parallel execution of numerous heterogeneous software components over a distributed set of computers. The Achilles’ heel of current methods is the need for a complete and accurate model of the system under observation: producing such a model is challenging because it requires either assimilating the collective knowledge of hundreds of programmers responsible for the individual components or restricting the ways in which components interact. Fortunately, the scale of modern Internet services offers a compensating benefit: the sheer volume of re-quests serviced means that, even at low sampling rates, one can gather a tremendous amount of empirical performance observations and apply “big data” techniques to analyze those observations. In this paper, we show how one can automatically construct a model of request execution from preexisting component logs by generating a large number of potential hypotheses about program behavior and rejecting hypotheses contradicted by the empirical observations. We also show how one can validate potential performance improvements without costly implementation effort by leveraging the variation in component behavior that arises naturally over large numbers of requests to measure the impact of optimizing individual components or changing scheduling behavior.'
- - https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.217.2276&rep=rep1&type=pdf
  - 'How Close Is Close Enough? Testing Nonexperimental Estimates of Impact against Experimental Estimates of Impact with Education Test Scores as Outcomes'
  - Elizabeth Ty Wilde, Robinson Hollister
  - '2002'
  - ''
  - ! '<p>In this study we test the performance of some nonexperimental estimators of impacts applied to an educational intervention—reduction in class size—where achievement test scores were the outcome. We compare the nonexperimental estimates of the impacts to “true impact” estimates provided by a random-assignment design used to assess the effects of that intervention. Our primary focus in this study is on a nonexperimental estimator based on a complex procedure called propensity score matching.</p> <p>We put greatest emphasis on looking at the question of “how close is close enough?” in terms of a decision-maker trying to use the evaluation to determine whether to invest in wider application of the intervention being assessed—in this case, reduction in class size. We illustrate this in terms of a rough cost-benefit framework for small class size as applied to Project Star. We find that in 30 to 45% of the 11 cases, the propensity-score-matching nonexperimental estimators would have led to the “wrong” decision.</p>'
- - http://bjp.rcpsych.org/content/195/3/271.2.full.pdf
  - Lithium in drinking water and food, and risk of suicide
  - Prabha S. Chandra, Girish N. Babu
  - 2018-01-02
  - 10.1192/bjp.195.3.271a
  - ! "<p>The study by Ohgami et al raises serious ethical issues related to the interpretation of research findings and, as a consequence, their possible application. While not denying that the findings are interesting and have caused a stir in the lay press and on the internet, we question the methodology and the possible implications if the results are taken seriously.</p> <p>First, sociological reasons for suicide are important, and changing rates of suicide in many countries are linked to changes such as migration, poverty, relationships and economic issues. The finding that when gender was included in the analysis there was a difference in the significance levels between men and women (with the results being less significant in women) is one such example. Adding lithium to tap water is not going to change these demographic and social factors that contribute to suicide rates, and not having accounted for at least some of these is a major limitation of the study. Second, although we agree with Young in his commentary that more research is needed to prove or disprove this tantalizing idea, it is also important to assess what the impact of different levels of tap-water lithium is going to be on thyroid function, pregnant women and on the unborn fetus. It is also important to assess whether tap-water levels of lithium directly correlate with serum lithium levels in the respective populations. The levels of lithium in body fluids in normal healthy controls have varied from 0.01 to 0.09 meq/1 in one study, but there are no data about serum lithium levels among individuals attempting suicide. Maybe assessment of serum lithium levels among those with suicidal behaviour can be a place to start. More data are also needed on the role of low-dose lithium in individuals without mood disorders who are at risk of suicide.</p> <p>Finally, several foods (particularly spices) are known to have relatively high levels of lithium as reported by a study in India several years ago. This study reported levels as high as 12 μg/g of lithium in tobacco and high levels in crude salt, rock salt and several spices. Maybe, until such time that we are certain about lithium's role in decreasing suicidality in non-psychiatric populations, it might be worth conducting randomised controlled trials with these foods in individuals with suicidal behaviour to see whether low doses of lithium really help.</p> <p>Let us not throw the lithium out with the tap water yet!</p>"
- - http://barabasi.com/f/995.pdf
  - The universal decay of collective memory and attention
  - Cristian Candia, C. Jara-Figueroa, Carlos Rodriguez-Sickert, Albert-László Barabási, César A. Hidalgo
  - '2019'
  - 10.1038/s41562-018-0474-5
  - ! 'Collective memory and attention are sustained by two channels: oral communication (communicative memory) and the physical recording of information (cultural memory). Here, we use data on the citation of academic articles and patents, and on the online attention received by songs, movies and biographies, to describe the temporal decay of the attention received by cultural products. We show that, once we isolate the temporal dimension of the decay, the attention received by cultural products decays following a universal biexponential function. We explain this universality by proposing a mathematical model based on communicative and cultural memory, which fits the data better than previously proposed log-normal and exponential models. Our results reveal that biographies remain in our communicative memory the longest (20–30 years) and music the shortest (about 5.6 years). These findings show that the average attention received by cultural products decays following a universal biexponential function.'
- - https://archive.ahrq.gov/downloads/pub/evidence/pdf/meditation/medit.pdf
  - 'Meditation Practices for Health: State of the Research'
  - University of Alberta Evidence-based Practice Center
  - '2007'
  - ''
  - ! 'Many uncertainties surround the practice of meditation. Scientific research on meditation practices does not appear to have a common theoretical perspective and is characterized by poor methodological quality. Firm conclusions on the effects of meditation practices in healthcare cannot be drawn based on the available evidence. Future research on meditation practices must be more rigorous in the design and execution of studies and in the analysis and reporting of results.'
- - https://antilop.cc/sr/files/Silk_Road_JTAN_com_Search_Warrant.pdf
  - Search And Seizure Warrant
  - United States District Court for the Eastern District of Pennsylvania
  - 2013-09-09
  - ''
  - ! 'Search warrant for the Silk Road server hosted in Sellersville, PA.'
- - /docs/statistics/causality/1999-dehejia.pdf
  - 'Causal Effects in Nonexperimental Studies: Reevaluating the Evaluation of Training Programs'
  - Rajeev H. Dehejia, Sadek Wahba
  - 1999-10-01
  - ''
  - ! "This article uses propensity score methods to estimate the treatment impact of the National Supported Work (NSW) Demonstration, a labor training program, on post-intervention earnings. We use data from Lalonde's evaluation of nonexperimental methods that combine the treated units from a randomized evaluation of the NSW with nonexperimental comparison units drawn from survey datasets. We apply propensity score methods to this composite dataset and demonstrate that, relative to the estimators that Lalonde evaluates, propensity score estimates of the treatment impact are much closer to the experimental benchmark estimate. Propensity score methods assume that the variables associated with assignment to treatment are observed (referred to as ignorable treatment assignment, or selection on observables). Even under this assumption, it is difficult to control for differences between the treatment and comparison groups when they are dissimilar and when there are many pre-intervention variables. The estimated propensity score (the probability of assignment to treatment, conditional on pre-intervention variables) summarizes the pre-intervention variables. This offers a diagnostic on the comparability of the treatment and comparison groups, because one has only to compare the estimated propensity score across the two groups. We discuss several methods (such as stratification and matching) that use the propensity score to estimate the treatment impact. When the range of estimated propensity scores of the treatment and comparison groups overlap, these methods can estimate the treatment impact for the treatment group. A sensitivity analysis shows that our estimates are not sensitive to the specification of the estimated propensity score, but are sensitive to the assumption of selection on observables. We conclude that when the treatment and comparison groups overlap, and when the variables determining assignment to treatment are observed, these methods provide a means to estimate the treatment impact. Even though propensity score methods are not always applicable, they offer a diagnostic on the quality of nonexperimental comparison groups in terms of observable pre-intervention variables."
- - https://www.newyorker.com/magazine/2008/04/21/up-and-then-down
  - "Up and Then Down: The lives of elevators"
  - Nick Paumgarten (<em>The New Yorker</em>)
  - 2008-04-21
  - ''
  - ! "[Profile of elevator safety, technology, and economics: the history and present day of elevators, interweaved with a story of a man trapped in an elevator for 41 hours. Elevators are remarkably safe and overengineered, and make skyscrapers, and hence dense cities, economically possible. Balancing elevator space with tenant space is a critical part of elevator design, as is routing between floors and figuring out the exact socially-acceptable density of passengers. Elevator technology continues advancing, driven by ultra-tall skyscrapers like the Burj Khalifa. Nevertheless, the standard elevator design is so simple, energetically-efficient, and safe that it's hard to improve on.]"
- - http://journal.frontiersin.org/article/10.3389/fnhum.2016.00375/full
  - "Revisiting hydrocephalus as a model to study brain resilience [RETRACTED]"
  - "Matheus Fernandes de Oliveira, Fernando Campos Gomes Pinto, Koshiro Nishikuni, Ricardo Vieira Botelho, Alessandra Moura Lima, José Marcus Rotta"
  - 2012-01-06
  - 10.3389/fnhum.2011.00181
  - ! 'Hydrocephalus is an entity which embraces a variety of diseases whose final result is the enlarged size of cerebral ventricular system, partially or completely. The physiopathology of hydrocephalus lies in the dynamics of circulation of cerebrospinal fluid (CSF). The consequent CSF stasis in hydrocephalus interferes with cerebral and ventricular system development. Children and adults who sustain congenital or acquired brain injury typically experience a diffuse insult that impacts many areas of the brain. Development and recovery after such injuries reflects both restoration and reorganization of cognitive functions. Classic examples were already reported in literature. This suggests the presence of biological mechanisms associated with resilient adaptation of brain networks. We will settle a link between the notable modifications to neurophysiology secondary to hydrocephalus and the ability of neuronal tissue to reassume and reorganize its functions.'
- - https://www.sciencedirect.com/science/article/pii/S0160289619300789
  - "Structural brain imaging correlates of general intelligence in UK Biobank"
  - S.R. Cox, S.J. Ritchie, C. Fawns-Ritchie, E.M. Tucker-Drob, Ian J. Deary
  - 2019-09
  - 10.1016/j.intell.2019.101376
  - ! '<p><em>Highlights</em>:</p><ul><li>We used a large sample from UK Biobank (<em>N</em> = 29,004, age range = 44–81 years).</li><li>The association between brain volume and intelligence (‘<em>g</em>’) was <em>r</em> = 0.276.</li><li>Multiple global tissue measures explained twice the <em>g</em> variance in older than middle age.</li><li>The size of the association between <em>g</em> and global brain measures did not vary by sex.</li><li>We investigate the regional cortical, subcortical and white matter correlates of g.</li></ul><p><em>Abstract</em>:The associations between indices of brain structure and measured intelligence are unclear. This is partly because the evidence to-date comes from mostly small and heterogeneous studies. Here, we report brain structure-intelligence associations on a large sample from the UK Biobank study. The overall <em>N</em> = 29,004, with <em>N</em> = 18,426 participants providing both brain MRI and at least one cognitive test, and a complete four-test battery with MRI data available in a minimum <em>N</em> = 7201, depending upon the MRI measure. Participants’ age range was 44–81 years (M = 63.13, SD = 7.48). A general factor of intelligence (<em>g</em>) was derived from four varied cognitive tests, accounting for one third of the variance in the cognitive test scores. The association between (age- and sex-corrected) total brain volume and a latent factor of general intelligence is <em>r</em> = 0.276, 95% C.I. = [0.252, 0.300]. A model that incorporated multiple global measures of grey and white matter macro- and microstructure accounted for more than double the <em>g</em> variance in older participants compared to those in middle-age (13.6% and 5.4%, respectively). There were no sex differences in the magnitude of associations between <em>g</em> and total brain volume or other global aspects of brain structure. The largest brain regional correlates of <em>g</em> were volumes of the insula, frontal, anterior/superior and medial temporal, posterior and paracingulate, lateral occipital cortices, thalamic volume, and the white matter microstructure of thalamic and association fibres, and of the forceps minor. Many of these regions exhibited unique contributions to intelligence, and showed highly stable out of sample prediction.</p>'
- - /docs/iq/2019-lee.pdf
  - "The causal influence of brain size on human intelligence: Evidence from within-family phenotypic associations and GWAS modeling"
  - James J. Lee, Matt McGue, William G. Iacono, Andrew M. Michael, Christopher F. Chabris
  - 2019-07
  - 10.1016/j.intell.2019.01.011
  - ! '<p>There exists a moderate correlation between MRI-measured brain size and the general factor of IQ performance (<em>g</em>), but the question of whether the association reflects a theoretically important causal relationship or spurious confounding remains somewhat open. Previous small studies (<em>n</em>&lt;100) looking for the persistence of this correlation within families failed to find a tendency for the sibling with the larger brain to obtain a higher test score. We studied the within-family relationship between brain volume and intelligence in the much larger sample provided by the Human Connectome Project (<em>n</em> = 1022) and found a highly significant correlation (disattenuated <em>ρ</em> = 0.18, p_ &lt; .001). We replicated this result in the Minnesota Center for Twin and Family Research (<em>n</em> = 2698), finding a highly significant within-family correlation between head circumference and intelligence (disattenuated <em>ρ</em> = 0.19, <em>p</em> &lt; .001). We also employed novel methods of causal inference relying on summary statistics from genome-wide association studies (GWAS) of head size (<em>n</em> ≈ 10,000) and measures of cognition (257,000 &lt; <em>n</em> &lt; 767,000). Using bivariate LD Score regression, we found a genetic correlation between intracranial volume (ICV) and years of education (EduYears) of 0.41 (<em>p</em> &lt; .001). Using the Latent Causal Variable method, we found a genetic causality proportion of 0.72 (<em>p</em> &lt; .001); thus the genetic correlation arises from an asymmetric pattern, extending to sub-significant loci, of genetic variants associated with ICV also being associated with EduYears but many genetic variants associated with EduYears not being associated with ICV. This is the pattern of genetic results expected from a causal effect of brain size on intelligence. These findings give reason to take up the hypothesis that the dramatic increase in brain volume over the course of human evolution has been the result of natural selection favoring general intelligence.</p>'
- - https://rifters.com/real/articles/Forsdyke-2015-BrainScansofHydrocephalicsChallengeCherishedAssumptions.pdf
  - "Wittgenstein’s Certainty is Uncertain: Brain Scans of Cured Hydrocephalics Challenge Cherished Assumptions"
  - Donald R. Forsdyke
  - 2015-07-24
  - 10.1007/s13752-015-0219-x
  -  ! '<p>The philosopher Ludwig Wittgenstein chose as his prime exemplar of certainty the fact that the skulls of normal people are filled with neural tissue, not sawdust. In 1980 the British pediatrician John Lorber reported that some normal adults, apparently cured of childhood hydrocephaly, had no more than 5% of the volume of normal brain tissue. While initially disbelieved, Lorber’s observations have since been independently confirmed by clinicians in France and Brazil. Thus Wittgenstein’s certainty has become uncertain. Furthermore, the paradox that the human brain’s information content (memory) appears to exceed the storage capacity of even normal-sized brains, requires resolution. This article is one of a series on disparities between brain size and its assumed information content, as seen in cases of savant syndrome, microcephaly, and hydrocephaly, and with special reference to the Victorian era views of Conan Doyle, Samuel Butler, and Darwin’s research associate, George Romanes. The articles argue that, albeit unlikely, the scope of explanations must not exclude extracorporeal information storage.</p><p>[Keywords: Female brain, Head size, Information storage capacity, Long-term memory, John Lorber, Neuronal reductionism, Plasticity limits, Redundancy, Supernatural explanations, Ventricle size]</p>'
- - https://www.frontiersin.org/articles/10.3389/fnhum.2014.00397/full
  - "Long-term memory: scaling of information to brain size"
  - Donald R. Forsdyke
  - 2014-06-03
  - 10.3389/fnhum.2014.00397
  - ! 'The material bases of information—paper, computer discs—usually scale with information quantity. Large quantities of information usually require large material bases. Conventional wisdom has it that human long-term memory locates within brain tissue, and so might be expected to scale with brain size which, in turn, depends on cranial capacity. Large memories, as in savants, should always require large heads. Small heads should always scale with small memories. While it was previously concluded that neither of these predictions was invariably true, the evidence was weak. Brain size also depends on ventricle size, which can remain large in some survivors of childhood hydrocephaly, occupying 95% of cranial volume. Yet some of these have normal or advanced intelligence, indicating little impairment of long-term memory. This paradox challenges the scaling hypothesis. Perhaps we should be looking further afield?'
- - http://blogs.discovermagazine.com/neuroskeptic/2015/07/26/is-your-brain-really-necessary-revisited/
  - '"Is Your Brain Really Necessary?", Revisited'
  - Neuroskeptic
  - 2015-07-26
  - ''
  - ! '<p>According to British biochemist Donald R. Forsdyke in a new paper in <em>Biological Theory</em>, the existence of people who seem to be missing most of their brain tissue calls into question some of the “cherished assumptions” of neuroscience. I’m not so sure.</p><p>…There’s no question that some of these brains are very striking. But I don’t think we need to throw out the textbooks yet.</p><p>While the enormous “holes” in these brains seem dramatic, the bulk of the grey matter of the cerebral cortex, around the outside of the brain, appears to be intact and in the correct place—this is visible as the dark grey ‘shell’ beneath the skull. What appears to be missing is the white matter, the nerve tracts that connect the various parts of the cerebral cortex with each other, and with the other areas of the brain. However, some white matter is still visible as the pale grey layer that borders the holes. The big question is whether this layer of white matter is sufficient to connect up the grey matter and allow it to function normally. There doesn’t seem to be much of it, but on the other hand, we really don’t know how much white matter is strictly necessary.</p><p>I wonder also if the white matter might be denser than normal i.e. if the fibers were packed together due to being gradually compressed by the expanding fluid spaces? No-one seems to have looked at this possibility directly; while there have been brain scanning studies of these adult post-hydrocephalics, no detailed post-mortem studies of their brain tissue have been published, as far as I know. (Forsdyke does not discuss any and I couldn’t find any in my searches.) For more on the neuroanatomy of this issue, see John Hawks (discussed by Forsdyke.)</p><p>Therefore in my view, these cases probably won’t require us to rethink neuroscience, although they do raise the issue of how much white matter is necessary. It may be that much of our white matter is redundant, which would be interesting, but not on a metaphysical level.</p>'
- - /docs/iq/2007-feuillet.pdf
  - "Brain of a white-collar worker"
  - Lionel Feuillet, Henry Dufour, Jean Pelletier
  - '2007-07-21'
  - 10.1016/S0140-6736(07)61127-1
  - ! '[Very brief case study.] On neuropsychological testing, he proved to have an intelligence quotient (IQ) of 75: his verbal IQ was 84, and his performance IQ 70. CT showed severe dilatation of the lateral ventricles (figure); MRI revealed massive enlargement of the lateral, third, and fourth ventricles, a very thin cortical mantle and a posterior fossa cyst. We diagnosed a non-communicating hydrocephalus...after a ventriculoperitoneal shunt was inserted, the findings on neurological examination became normal within a few weeks. The findings on neuropsychological testing and CT did not change.'
- - http://www.pnas.org/content/early/2012/06/19/1201895109.full.pdf
  - 'The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost'
  - Suzana Herculano-Houzel
  - 2012-06-19
  - 10.1073/pnas.1201895109
  - ! 'Neuroscientists have become used to a number of “facts” about the human brain: It has 100 billion neurons and 10- to 50-fold more glial cells; it is the largest-than-expected for its body among primates and mammals in general, and therefore the most cognitively able; it consumes an outstanding 20% of the total body energy budget despite representing only 2% of body mass because of an increased metabolic need of its neurons; and it is endowed with an overdeveloped cerebral cortex, the largest compared with brain size. These facts led to the widespread notion that the human brain is literally extraordinary: an outlier among mammalian brains, defying evolutionary rules that apply to other species, with a uniqueness seemingly necessary to justify the superior cognitive abilities of humans over mammals with even larger brains. These facts, with deep implications for neurophysiology and evolutionary biology, are not grounded on solid evidence or sound assumptions, however. Our recent development of a method that allows rapid and reliable quantification of the numbers of cells that compose the whole brain has provided a means to verify these facts. Here, I review this recent evidence and argue that, with 86 billion neurons and just as many nonneuronal cells, the human brain is a scaled-up primate brain in its cellular composition and metabolic cost, with a relatively enlarged cerebral cortex that does not have a relatively larger number of brain neurons yet is remarkable in its cognitive abilities and metabolism simply because of its extremely large number of neurons.'
- - https://onlinelibrary.wiley.com/doi/full/10.1111/epi.12342
  - "Long-term functional outcomes and their predictors after hemispherectomy in 115 children"
  - Ahsan N. V. Moosa, Lara Jehi, Ahmad Marashly, Gary Cosmo, Deepak Lachhwani, Elaine Wyllie, Prakash Kotagal, William Bingaman, Ajay Gupta
  - 2013-08-23
  - 10.1111/epi.12342
  - ! '<p><em>Purpose</em>: To examine the long-term functional outcomes and their predictors using a patient/family centered approach in a cohort of children who had hemispherectomy. Functional outcome measures studied were the following: ambulation ability, visual symptoms, spoken language, reading skills, and behavioral problems.</p><p><em>Methods</em>: We reviewed 186 consecutive children who underwent hemispherectomy between 1997 and 2009 at our center. Preoperative clinical, electroencephalography (EEG), imaging, and surgical data were collected. 125 families completed a structured questionnaire to assess the functional status and seizure outcome. Prognostic predictors were examined using a multivariate regression analysis.</p><p><em>Key Findings</em>: At a mean follow-up of 6.05 years after hemispherectomy, 70 patients (56%) were seizure-free and 45 (36%) had seizure recurrence; 10 patients (8%) were free of their preoperative seizures but had new-onset nonepileptic spells and were excluded from further analysis. Of 115, at follow-up (mean age at follow-up 12.7 years, range 2–28 years), 96 patients (83%) walked independently, 10 (8.7%) walked with assistance, and 9 (7.8%) were unable to walk. New visual symptoms that were not present preoperatively were reported only in 28 patients (24%). Eighty patients (70%) had satisfactory spoken language skills but only 44 (42%) of the 105 children older than 6 years had satisfactory reading skills. Significant behavioral problems were reported in 30 patients (27%). Only five (6.2%) of the 81 children aged between 6 and 18 years attended mainstream school without assistance; 48 (59%) were in mainstream school with assistance and the rest were in special school for disabled or home cared. Five (21%) of the 24 patients older than 18 years of age were gainfully employed. Multivariate logistic regression analysis identified the following factors as independently associated with poor functional outcome. (1) Seizure recurrence negatively affected all functional domains—ambulation ability, spoken language and reading skills, and behavior (<em>p</em> &lt; 0.05). (2) Abnormalities in the unoperated hemisphere on magnetic resonance imaging (MRI) (<em>p</em> &lt; 0.05) and preexisting quadriparesis (<em>p</em> &lt; 0.01) correlated with poor motor outcome. (3) Multilobar MRI abnormalities in the contralateral hemisphere (odds ratio [OR] = 13.9, <em>p</em> = 0.001) and young age (indeterminate preoperative language status) at hemispherectomy (OR = 11.1, <em>p</em> = 0.01) also correlated with poor language outcome. (4) Younger age at epilepsy onset correlated with poor reading skills (<em>p</em> = 0.01) but not with spoken language skills.</p><p><em>Significance</em>: This study highlights the long-term functional status of patients after hemispherectomy. The majority of patients were ambulant independently; however, impairments in reading and spoken language were frequent. Seizure recurrence after hemispherectomy and contralateral hemisphere abnormalities on MRI were the major predictors of poor outcome in ambulation, spoken language, and reading abilities. This study will assist in presurgical counseling using simple understandable functional outcome measures and may help in planning early interventions after hemispherectomy to improve functional outcome.</p>'
- - https://www.nytimes.com/2019/11/19/health/brain-removal-hemispherectomies-scans.html
  - "How the Brain Can Rewire Itself After Half of It Is Removed: New scans showed how the brains of people who had a hemisphere removed in childhood continue to function"
  - Knvul Sheikh (NYT)
  - 2019-11-19
  - ''
  - ! '<p>Her son, Henry, endured hundreds of seizures a day. Despite receiving high doses of medication, his little body seemed like a rag doll as one episode blended into another. He required several surgeries, starting when he was 3 1/2 months old, eventually leading to a complete anatomical hemispherectomy, or the removal of half of his brain, when he turned 3. The procedure was first developed in the 1920s to treat malignant brain tumors. But its success in children who have brain malformations, intractable seizures or diseases where damage is confined to half the brain, has astonished even seasoned scientists. After the procedure, many of the children are able to walk, talk, read and do everyday tasks. Roughly 20 percent of patients who have the procedure go on to find gainful employment as adults.</p><p>Now, research published Tuesday in the journal <em>Cell Reports</em> suggests that some individuals recover so well from the surgery because of a reorganization in the remaining half of the brain. Scientists identified the variety of networks that pick up the slack for the removed tissue, with some of the brain’s specialists learning to operate like generalists. “The brain is remarkably plastic,” said Dorit Kliemann, a cognitive neuroscientist at the California Institute of Technology, and the first author of the study. “It can compensate for dramatic loss of brain structure, and in some cases the remaining networks can support almost typical cognition.”</p><p>…Instead, researchers found that while the type of connections remained the same in the individuals with just one hemisphere, different regions responsible for processing sensorimotor information, vision, attention and social cues strengthened existing connections, communicating more frequently with each other compared with ordinary brains. It was almost as if parts of the brain that may have normally been specialized, say, as trumpet players, had talked to the rest of the band and taken additional responsibilities to play percussion instruments as well, Dr. Behrmann said. “Their brain networks seem to be multitasking.”</p><p>The results are encouraging for researchers and families trying to understand how the brain adapts and functions after a hemispherectomy. “I think there’s more and more evidence to suggest that brain plasticity is a really long-lasting phenomena,” said Dr. Ajay Gupta, a pediatric neurologist at the Cleveland Clinic, who has followed nearly 200 children after the surgery. Until recently, the scientific consensus has been that hemispherectomy surgery is best performed at a very young age, before a child reaches the age of 4 or 5. That way, they can regain normal function as they grow older. While neuroplasticity is stronger in early childhood, the new study suggests that surgery should not be withheld after an arbitrary end date, Dr. Gupta said. Adults in the study had undergone hemispherectomy surgery at ages ranging from 3 months to 11 years old.</p><p>A factor that may play a more important role in patient outcomes is the age at which seizures begin to occur. The surgery is still considered a last resort after medical treatment. But if the duration of seizures and resulting brain damage can be limited, patients may recover more function. “The other hemisphere is already having to handle extra responsibilities before patients get treated,” said Lynn K. Paul, a neuroscientist at California Institute of Technology and a co-author of the study. “It continues to do so when you take out the damaged hemisphere. So what we really want is to protect the hemisphere that’s working.”</p><p>…After the operation, children become significantly weaker in their hands and arms on the side opposite the operation. Their vision becomes blocked on that side, and they may also lose some ability to recognize where sounds are coming from. “There are some things that definitely require a higher level of rehab and learning. For example, reading and writing and math,” Dr. Gupta said. In many cases, however, those skills have already been compromised by the underlying diseases…For now, she is happy that her son can walk independently, communicate with an iPad and eat meals without a feeding tube.</p>'
- - https://ai.facebook.com/blog/understanding-the-generalization-of-lottery-tickets-in-neural-networks/
  - "Understanding the generalization of ‘lottery tickets’ in neural networks"
  - Ari Morcos, Yuandong Tian (FAIR)
  - 2019-11-25
  - ''
  - ! '<p>The lottery ticket hypothesis, initially proposed by researchers Jonathan Frankle and Michael Carbin at MIT, suggests that by training deep neural networks (DNNs) from “lucky” initializations, often referred to as “winning lottery tickets,” we can train networks which are 10-100x smaller with minimal losses—or even while achieving gains—in performance. This work has exciting implications for potentially finding ways to not only train with fewer resources, but also run faster inference of models on smaller devices, like smartphones and VR headsets. But the lottery ticket hypothesis is not yet fully understood by the AI community. In particular, it has remained unclear whether winning tickets are dependent on specific factors or rather represent an intrinsic feature of DNNs.</p><p>New research from Facebook AI finds the first definitive evidence that lottery tickets generalize across related, but distinct datasets and can extend to reinforcement learning (RL) and natural language processing (NLP). We’re sharing details on the results of our experiments using winning tickets, and we’re also introducing a new theoretical framework on the formation of lottery tickets to help researchers advance toward a better understanding of lucky initializations.</p><p>…there are many more open questions about the underlying properties and behaviors of neural networks, such as how do these winning tickets form, why do they exist, and how do they work?</p><p>To begin to analyze these questions in the context of deep ReLU networks, we used a student-teacher setting, in which a larger student network must learn to mimic exactly what the smaller teacher is doing. Since we can define the teacher network with fixed parameters in this setting, we can quantitatively measure the student network’s learning progress, and, critical to our investigation of lottery tickets, how the student network’s initialization affects the learning process.</p><p>In the student-teacher setting, we see that after training, the activity patterns of select student neurons correlate more strongly with those of teacher neurons than with the activity of other student neurons—a concept that is referred to as “student specialization.” This stronger correlation suggests that, during training, the student network not only learns the teacher’s network output but also the internal structure of the teacher by mimicking individual teacher neurons.</p><p>In our analysis, we show this occurrence happens locally in a 2-layer ReLU network: if the initial weights of a student neuron happen to be similar to those of some teacher neurons, then specialization will follow. The size of the neural network is important because the larger the student network, the more likely that one of the student neurons will start out close enough to a teacher neuron to learn to mimic its activity during training. What’s more, if a student neuron’s initial activation region has a more substantial overlap with a teacher neuron, then that student neuron specializes faster. This behavior corroborates the lottery ticket hypothesis, which similarly proposes that some lucky subset of initializations exist within neural networks, and “winning tickets” are the lucky student neurons that happen to be in the right location at the beginning of training. In our follow-up research, we strengthen our results by removing many mathematical assumptions, including independent activations and locality, and still prove that student specialization happens in the lowest layer in deep ReLU networks after training. From our analysis, we find certain mathematical properties in the training dynamics resonate with the lottery ticket phenomenon: those weights with a slight advantage in the initialization may have a greater chance of being the winning tickets after training converges.</p>'
- - /docs/iq/1980-lewin.pdf
  - "Is Your Brain Really Necessary? John Lorber, a British neurologist, claims that some patients are more normal than would be inferred from their brain scans"
  - Roger Lewin
  - 1980-12-12
  - 10.2307/1684473
  - ! '<p>…Lorber was not jesting totally when he addressed a conference of pediatricians with a paper entitled “Is your brain really necessary?” Lorber believes that his observations on a series of hydrocephalics who have severely reduced brain tissue throws into question many traditional notions about the brain, both in clinical and scientific terms.</p><p>“There’s a young student at this university,” says Lorber, “who has an IQ of 126, has gained a first-class honors degree in mathematics, and is socially completely normal. And yet the boy has virtually no brain.” The student’s physician at the university noticed that the youth had a slightly larger than normal head, and so referred him to Lorber, simply out of interest. “When we did a brain scan on him,” Lorber recalls, “we saw that instead of the normal 4.5-centimeter thickness of brain tissue between the ventricles and the cortical surface, there was just a thin layer of mantle measuring a millimeter or so. His cranium is filled mainly with cerebrospinal fluid.”</p><p>…In young children, whose skulls are still malleable, one obvious consequence can be a grossly enlarged head. Additionally, this physical assault from within leads to a real loss of brain matter. It is therefore not surprising that many hydrocephalics suffer intellectual and physical disabilities. What is surprising, however, is that a substantial proportion of patients appear to escape functional impairment in spite of grossly abnormal brain structure.</p><p>“The spina bifida unit at the Children’s Hospital here in Sheffield is one of the largest in the world,” explains Lorber, “and this gives us an opportunity to make many observations. Since the introduction of the safe, noninvasive brain scanning technique just a few years ago we have done more than 600 scans on patients with hydrocephalus.” Lorber divides the subjects into four categories: those with minimally enlarged ventricles; those whose ventricles fill 50 to 70% of the cranium; those in which the ventricles fill between 70 and 90% of the intracranial space; and the most severe group, in which ventricle expansion fills 95% of the cranium. Many of the individuals in this last group, which forms just less than 10% of the total sample, are severely disabled, but half of them have IQ’s greater than 100. This group provides some of the most dramatic examples of apparently normal function against all odds.</p><p>Commenting on Lorber’s work, Kenneth Till, a former neurosurgeon at the Great Ormond Street Hospital for Sick Children, London, has this to say: “Interpreting brain scans can be very tricky. There can be a great deal more brain tissue in the cranium than is immediately apparent.” Till echoes the cautions of many practitioners when he says, “Lorber may be being rather overdramatic when he says that someone has ‘virtually no brain.’” Lorber acknowledges the problem of interpretation of brain scans, and he counters Till’s remarks by insisting, “Of course these results are dramatic, but they’re not overdramatic. One would not make the claim if one did not have the evidence.”</p><p>…Lorber concludes from these observations that “there must be a tremendous amount of redundancy or spare capacity in the brain, just as there is with kidney and liver.” He also contends that “the cortex probably is responsible for a great deal less than most people imagine.” These are two areas of considerable dispute in neurobiology. Wall lends support for this second point. “One reason why results such as Lorber’s have been neglected for so long is because of the implied attack on the predominance of the cerebral cortex,” suggests Wall. “For hundreds of years neurologists have assumed that all that is dear to them is performed by the cortex, but it may well be that the deep structures in the brain carry out many of the functions assumed to be the sole province of the cortex.” He likens the cortex to a “reference library” that may be consulted from time to time.</p><p>On the question of the brain’s spare capacity there is equal contention. “To talk of redundancy in the brain is an intellectual cop-out to try to get round something you don’t understand,” states Wall. Geschwind agrees: “Certainly the brain has a remarkable capacity for reassigning functions following trauma, but you can usually pick up some kind of deficit with the right tests, even after apparently full recovery.” However, Colin Blakemore, professor of physiology at Oxford University, England, sees spare capacity as an important quality of the human brain. “The brain frequently has to cope with minor lesions and it’s crucial that it can overcome these readily,” he says; “there may be some reorganization of brain tissue, but mostly there’s a reallocation of function.”</p><p>It is perhaps significant that many of the instances in which gross enlargement of cerebral ventricles is compatible with normal life are cases where the condition develops slowly. Gross surgical lesions in rat brains are known to inflict severe functional disruption, but if the same damage is done bit by bit over a long period of time, the dysfunction can be minimal. Just as the rat brains appear to cope with a stepwise reduction of available hardware, so too do the human brains in some cases of hydrocephalus…The sparing of the gray matter even in severe hydrocephalus could go some way to explaining the remarkable retention of many normal functions in severely affected individuals. …</p>'
- - https://moxie.org/stories/brink-of-death/
  - Hypothermia
  - Moxie Marlinspike
  - ''
  - ''
  - ! '<p>"I made a series of mistakes that culminated in the worst sailing accident of my life, and almost took me to the bottom of the ocean."</p> <p>[One fall evening after work, Marlinspike and a friend made a simple plan to sail a 15-foot catamaran out 600 feet into the San Francisco Bay, where they’d drop anchor and row back in a smaller boat, leaving the sailboat to wait for their next adventure. (Anarchist sailors don’t like to pay dockage fees.) Marlinspike headed out into the bay on the catamaran with his friend following in a rowboat. Only after Marlinspike had passed the pier did he realize the wind was blowing at a treacherous 30 miles an hour. He decided to turn back but discovered that he’d misrigged the craft and had to fix his mistake. As the sun sank toward the horizon, he shouted to his friend that they should give up and return to shore, and the friend rowed back to safety.</p><p>Then, without warning, the wind gusted. The catamaran flipped, throwing Marlinspike into the ice-cold water. “The suddenness of it was unbelievable, as if I was on a tiny model made of paper which someone had simply flicked with their finger,” he would later write in a blog post about the experience. Soon the boat was fully upside down, pinned in place by the wind. Marlinspike tried to swim for shore. But the pier was too far away, the waves too strong, and he could feel his body succumbing to hypothermia, blackness creeping into the edges of his vision. He headed back to the overturned boat. Alone now in the dark, he clung to the hull, took stock of the last hour’s events, and realized, with slow and lonely certainty, that he was very likely going to die.</p><p>When a tugboat finally chanced upon his soaked and frozen form he was nearly unconscious and had to be towed up with a rope. When he arrived at the hospital, Marlinspike says, the nurses told him his temperature was so low their digital thermometers couldn’t register it. As he recovered over the next days, he had the sort of realization that sometimes results from a near-death experience. “It definitely sharpened my focus,” he says of the incident. “It made me question what I was doing with my life.”</p><p>Marlinspike’s time at Twitter had given him an ambitious sense of scale: He was determined to encrypt core chunks of the Internet. A normal person might have quit sailing. Instead, Marlinspike quit Twitter. A year and a day after he had started, he walked away from over $1 million in company stock.]</p>'
- - /Replications#animal-models
  - "Animal Research Methodological Problems & Transferrability"
  - Gwern Branwen
  - 2013-03-22
  - ''
  - ! '<p>On the general topic of animal model external validity &amp; translation to humans, a number of op-eds, reviews, and meta-analyses have been done; reading through some of the literature up to March 2013, I would summarize them as indicating that the animal research literature in general is of considerably lower quality than human research, and that for those and intrinsic biological reasons, the probability of meaningful transfer from animal to human can be astoundingly low, far below 50% and in some categories of results, 0%.</p><p>The primary reasons identified for this poor performance are generally: small samples (much smaller than the already underpowered norms in human research), lack of blinding in taking measurements, pseudo-replication due to animals being correlated by genetic relatedness/living in same cage/same room/same lab, extensive non-normality in data, large differences between labs due to local differences in reagents/procedures/personnel illustrating the importance of “tacit knowledge”, publication bias (small cheap samples + little perceived ethical need to publish + no preregistration norms), unnatural &amp; unnaturally easy lab environments (more naturalistic environments both offer more realistic measurements &amp; challenge animals), large genetic differences due to inbreeding/engineering/drift of lab strains mean the same treatment can produce dramatically different results in different strains (or sexes) of the same species, different species can have different responses, and none of them may be like humans in the relevant biological way in the first place.</p><p>So it is no wonder that “we can cure cancer in mice but not people” and almost all amazing breakthroughs in animals never make it to human practice; medicine &amp; biology are difficult.</p>'
- - /Replication
  - "The Replication Crisis: Flaws in Mainstream Science"
  - Gwern Branwen
  - 2010-10-27
  - ''
  - ! '<p>Long-standing problems in standard scientific methodology have exploded as the <q>“<a href="https://en.wikipedia.org/wiki/Replication_Crisis" class="docMetadata" data-popup-title="Replication crisis" data-popup-author="English Wikipedia" data-popup-abstract="<p>The <b>replication crisis</b> is, as of 2019, an ongoing methodological crisis in which it has been found that many scientific studies are difficult or impossible to replicate or reproduce. The replication crisis affects the social sciences and medicine most severely. The crisis has long-standing roots; the phrase was coined in the early 2010s as part of a growing awareness of the problem. The replication crisis represents an important body of research in the field of metascience.</p>" title="Wikipedia: Replication Crisis">Replication Crisis</a>”</q>: the discovery that many results in fields as diverse as psychology, economics, medicine, biology, and sociology are in fact false or quantitatively highly inaccurately measured. I cover here a handful of the issues and publications on this large, important, and rapidly developing topic up to about 2013, at which point the Replication Crisis became too large a topic to cover more than cursorily.</p> <p>The crisis is caused by methods &amp; publishing procedures which interpret random noise as important results, far too small datasets, selective analysis by an analyst trying to reach expected/desired results, publication bias, poor implementation of existing best-practices, nontrivial levels of research fraud, software errors, philosophical beliefs among researchers that false positives are acceptable, neglect of known confounding like genetics, and skewed incentives (financial &amp; professional) to publish ‘hot’ results.</p> <p>Thus, any individual piece of research typically establishes little. Scientific validation comes not from small <em>p</em>-values, but from discovering a regular feature of the world which disinterested third parties can discover with straightforward research done independently on new data with new procedures—<em>replication</em>.</p>'
- - https://scottbarrykaufman.com/wp-content/uploads/2018/08/Gideon-et-al.-2018.pdf
  - "Are Bigger Brains Smarter? Evidence From a Large-Scale Preregistered Study"
  - Gideon Nave, Wi Hoon Jung, Richard Karlsson Linnér, Joseph W. Kable, Philipp D. Koellinger
  - 2018-11-30
  - 10.1177/0956797618808470
  - ! '<p>A positive relationship between brain volume and intelligence has been suspected since the 19th century, and empirical studies seem to support this hypothesis. However, this claim is controversial because of concerns about publication bias and the lack of systematic control for critical confounding factors (e.g., height, population structure). We conducted a preregistered study of the relationship between brain volume and cognitive performance using a new sample of adults from the United Kingdom that is about 70% larger than the combined samples of all previous investigations on this subject (<em>N</em> = 13,608). Our analyses systematically controlled for sex, age, height, socioeconomic status, and population structure, and our analyses were free of publication bias. We found a robust association between total brain volume and fluid intelligence (<em>r</em> = .19), which is consistent with previous findings in the literature after controlling for measurement quality of intelligence in our data. We also found a positive relationship between total brain volume and educational attainment (<em>r</em> = .12). These relationships were mainly driven by gray matter (rather than white matter or fluid volume), and effect sizes were similar for both sexes and across age groups.</p><p>[Keywords: intelligence, educational attainment, brain volume, preregistered analysis, UK Biobank, open data, open materials, preregistered]</p>'
- - https://www.theguardian.com/science/2018/apr/16/a-real-life-lord-of-the-flies-the-troubling-legacy-of-the-robbers-cave-experiment
  - "A real-life Lord of the Flies: the troubling legacy of the Robbers Cave experiment; In the early 1950s, the psychologist Muzafer Sherif brought together a group of boys at a US summer camp – and tried to make them fight each other. Does his work teach us anything about our age of resurgent tribalism? [an extract from <em>The Lost Boys</em>]"
  - David Shariatmadari
  - 2018-04-16
  - ''
  - ! '<p>In 50s Middle Grove, things didn’t go according to plan either, though the surprise was of a different nature. Despite his pretence of leaving the 11-year-olds to their own devices, Sherif and his research staff, posing as camp counsellors and caretakers, interfered to engineer the result they wanted. He believed he could make the two groups, called the Pythons and the Panthers, sworn enemies via a series of well-timed “frustration exercises”. These included his assistants stealing items of clothing from the boys’ tents and cutting the rope that held up the Panthers’ homemade flag, in the hope they would blame the Pythons. One of the researchers crushed the Panthers’ tent, flung their suitcases into the bushes and broke a boy’s beloved ukulele. To Sherif’s dismay, however, the children just couldn’t be persuaded to hate each other…The robustness of the boy’s “civilised” values came as a blow to Sherif, making him angry enough to want to punch one of his young academic helpers. It turned out that the strong bonds forged at the beginning of the camp weren’t easily broken. Thankfully, he never did start the forest fire—he aborted the experiment when he realised it wasn’t going to support his hypothesis.</p><p>But the Rockefeller Foundation had given Sherif $38,000. In his mind, perhaps, if he came back empty-handed, he would face not just their anger but the ruin of his reputation. So, within a year, he had recruited boys for a second camp, this time in Robbers Cave state park in Oklahoma. He was determined not to repeat the mistakes of Middle Grove.</p><p>…At Robbers Cave, things went more to plan. After a tug-of-war in which they were defeated, the Eagles burned the Rattler’s flag. Then all hell broke loose, with raids on cabins, vandalism and food fights. Each moment of confrontation, however, was subtly manipulated by the research team. They egged the boys on, providing them with the means to provoke one another—who else, asks Perry in her book, could have supplied the matches for the flag-burning?</p><p>…Sherif was elated. And, with the publication of his findings that same year, his status as world-class scholar was confirmed. The “Robbers Cave experiment” is considered seminal by social psychologists, still one of the best-known examples of “realistic conflict theory”. It is often cited in modern research. But was it scientifically rigorous? And why were the results of the Middle Grove experiment—where the researchers couldn’t get the boys to fight—suppressed? “Sherif was clearly driven by a kind of a passion,” Perry says. “That shaped his view and it also shaped the methods he used. He really did come from that tradition in the 30s of using experiments as demonstrations—as a confirmation, not to try to find something new.” In other words, think of the theory first and then find a way to get the results that match it. If the results say something else? Bury them…“I think people are aware now that there are real ethical problems with Sherif’s research,” she tells me, “but probably much less aware of the backstage [manipulation] that I’ve found. And that’s understandable because the way a scientist writes about their research is accepted at face value.” The published report of Robbers Cave uses studiedly neutral language. “It’s not until you are able to compare the published version with the archival material that you can see how that story is shaped and edited and made more respectable in the process.” That polishing up still happens today, she explains. “I wouldn’t describe him as a charlatan … every journal article, every textbook is written to convince, persuade and to provide evidence for a point of view. So I don’t think Sherif is unusual in that way.”</p>'
- - /docs/sr/2016-munksgaard.pdf
  - 'A replication and methodological critique of the study “Evaluating drug trafficking on the Tor Network”'
  - Rasmus Munksgaard, Jakob Demant, Gwern Branwen
  - 2016-09
  - 10.1016/j.drugpo.2016.02.027
  - ! "[Debunking a remarkably sloppy darknet market paper which screwed up its scraping and somehow concluded that the notorious Silk Road 2, in defiance of all observable evidence & subsequent FBI data, actually sold primarily e-books and hardly any drugs. This study has yet to be retracted.] The development of cryptomarkets has gained increasing attention from academics, including growing scientific literature on the distribution of illegal goods using cryptomarkets. Dolliver's 2015 article “Evaluating drug trafficking on the Tor Network: Silk Road 2, the Sequel” addresses this theme by evaluating drug trafficking on one of the most well-known cryptomarkets, Silk Road 2.0. The research on cryptomarkets in general—particularly in Dolliver's article—poses a number of new questions for methodologies. This commentary is structured around a replication of Dolliver's original study. The replication study is not based on Dolliver's original dataset, but on a second dataset collected applying the same methodology. We have found that the results produced by Dolliver differ greatly from our replicated study. While a margin of error is to be expected, the inconsistencies we found are too great to attribute to anything other than methodological issues. The analysis and conclusions drawn from studies using these methods are promising and insightful. However, based on the replication of Dolliver's study, we suggest that researchers using these methodologies consider and that datasets be made available for other researchers, and that methodology and dataset metrics (e.g. number of downloaded pages, error logs) are described thoroughly in the context of web-o-metrics and web crawling."
- - /statistics/bias/2005-jussim.pdf
  - "Teacher expectations and self-fulfilling prophecies: knowns and unknowns, resolved and unresolved controversies"
  - Lee Jussim, Kent D. Harber
  - '2005'
  - 10.1207/s15327957pspr0902_3
  - ! '<p>This article shows that 35 years of empirical research on teacher expectations justifies the following conclusions: (a) Self-fulfilling prophecies in the classroom do occur, but these effects are typically small, they do not accumulate greatly across perceivers or over time, and they may be more likely to dissipate than accumulate; (b) powerful self-fulfilling prophecies may selectively occur among students from stigmatized social groups; (c) whether self-fulfilling prophecies affect intelligence, and whether they in general do more harm than good, remains unclear, and (d) teacher expectations may predict student outcomes more because these expectations are accurate than because they are self-fulfilling. Implications for future research, the role of self-fulfilling prophecies in social problems, and perspectives emphasizing the power of erroneous beliefs to create social reality are discussed.</p><p>[Jussim discusses the famous ‘Pygmalion effect’. It demonstrates the Replication crisis: an initial extraordinary finding indicating that teachers could raise student IQs by dozens of points gradually shrunk over repeated replications to essentially zero net long-term effect. The original finding was driven by statistical malpractice bordering on research fraud: some students had “pretest IQ scores near zero, and others had post-test IQ scores over 200”! Rosenthal further maintained the Pygmalion effect by statistical trickery, such as his ‘fail-safe <em>N</em>’, which attempted to show that hundreds of studies would have to have not been published in order for the Pygmalion effect to be true—except this assumes zero publication bias in those unpublished studies and begs the question.]</p>'
- - http://www.2arms1head.com/
  - "Two Arms and a Head: The Death of a Newly Paraplegic Philosopher"
  - Clayton Atreus
  - 2008-02-24
  - ''
  - ! '<p>[Paper/suicide note by a philosophy graduate <a href="https://advrider.com/f/threads/seattle-to-argentina-on-a-klr650.136505/">who went on a motorcycle tour of Mexico</a> and ran into a goat, instantly becoming a <a href="https://en.wikipedia.org/wiki/Paraplegia">paraplegic</a>. Atreus discusses how paraplegia robs him of the ability to do almost everything he valued in life, from running to motorcycling to sex, while burdening him down with dead weight equivalent to hundreds of pounds, which make the simplest action, like getting out of a car, take minutes or hours, radically shortening his effective days. He is an ambulatory corpse, “two arms and a head”. Atreus discusses in detail the existential horror of his condition, from complete lack of bowel control requiring him to constantly dig his own feces out of his anus to being trapped in a wheelchair larger than a washing machine to the cruelty of well-intentioned encouragement to social alienation and his constant agonized awareness of everything he has lost. If the first question of philosophy is whether to commit suicide, Atreus finds that for him, the answer is "yes". The paper/book concludes with his description of stabbing himself and slowly bleeding to death.]</p><p>This book is born of pain. I wrote it out of <em>compulsion</em> during the most hellish time of my life. Writing it hurt me and was at times extremely unpleasant. Is the book my death-rattle or the sound of me screaming inside of my cage? Does its tone tell you I am angry or merely seeking a psychological expedient against the madness I see around me? The book is my creation but is also in many ways foreign to me for I am living in a foreign land. Most generally perhaps it is just the thoughts that passed through my head over the twenty months I spent moving toward death. I am certainly not a man who is at peace with his life, but on the contrary I despise it as I have never before despised anything. Who can sort it all out? Being imprisoned in the nightmarish cage of paraplegia has done all manner of violence to the deepest parts of me. Still, I have not gone mad. I am no literary genius and don’t expect everything I say to be understood, but if you would like to know what my experiences have been like, and what I am like, I will try my best to show you.</p><p>What do I think of this book? I have no affection for it. I find it odious and unattractive and am very saddened that I wrote it. But it is what I had to say. It took on a life of its own and when I now step back and look at what I created I regard it with distaste. If I could, I would put all of these horrible thoughts in a box, seal it forever, then go out and live life. I would run in the sun, enjoy my freedom, and revel in myself. But that’s the point. I cannot go out and live life because this is not life. So instead I speak to you from the place I now occupy, between life and death.</p><p>… Imagine a man cut off a few inches below the armpits. Neglect for a moment questions concerning how he eliminates waste and so forth, and just assume that the site of the “amputation” is, to borrow from Gogol, “as uniform as a newly fried pancake”. This man would be vastly, immensely better off than me. If you don’t know who <a href="https://en.wikipedia.org/wiki/Johnny_Eck">Johnny Eck</a> is, he had a role in the <a href="https://en.wikipedia.org/wiki/Freaks_(1932_film)">1932 movie <em>Freaks</em></a>. He was the guy who was essentially a torso with arms. He walked on his hands. How fortunate he was compared to me may not register right away, because the illusion I mentioned above would probably make you find Johnny Eck’s condition far more shocking than mine. But the truth is that mine is much more horrible than his, barring whatever social “advantages” the illusion of being whole might confer on me. The other day I saw a picture of a woman missing both legs. They were cut off mid-thigh. I thought that if only I was like her perhaps my life would be bearable. She was, in my opinion, better off than the pancake man, who is beyond any doubt far better off than me. One man said to me, “At least you didn’t lose your legs.” No, I <em>did</em> lose my legs, and my penis, and my pelvis. Let’s get something very clear about the difference between paraplegics and double-leg amputees. If tomorrow every paraplegic woke up as a double-leg amputee, the Earth itself would quiver with ecstasy from the collective bursting forth of joyous emotion. Tears of the most exquisitely overwhelming relief and happiness would stream down the cheeks of former paraplegics the world over. My wording here is deliberate. It’s no exaggeration. Losing both legs is bad, but paraplegia is ghoulishly, nightmarishly worse.</p> <p>Part of what I wanted in desiring to die in the company of those I loved was to reassure them and perhaps give them courage to face death well.  That was something I really wanted to give to them and I’m sorry I can only do it with these words. I was driven almost mad by all of the things many other people said about paraplegia, suicide, and what was still possible in my condition. I hope everyone understands how all of that affected the tone of what I wrote. I was so frustrated with all of it, I thought it was so insane. But I only wanted to break free of it all and say what I felt. I felt like it stifled me so horribly.</p> <p>I cut some more and the blood is flowing well again. I’m surprised how long it is taking me to even feel anything. I thought I was dizzy but I’m not sure I am now. It’s 8:51 pm. I thought I would get cold but I’m not cold either, I’m actually hot but that’s probably the two sweaters. Starting to feel a little badly. Sweating, a little light-headed.</p> <p>I’m going to go now, done writing. Goodbye everyone.</p>'
- - https://emptypath.wordpress.com/2011/12/16/in-praise-of-self-deprecation/
  - "In praise of self-deprecation"
  - Wislawa Szymborska
  - '1976'
  - ''
  - ! '<blockquote><p>The buzzard has nothing to fault himself with.<br />Scruples are alien to the black panther.<br />Piranhas do not doubt the rightness of their actions.<br />The rattlesnake approves of himself without reservations.<br /></p><p>The self-critical jackal does not exist.<br />The locust, alligator, trichina, horsefly<br />live as they live and are glad of it.<br /></p><p>The killer whale’s heart weighs one hundred kilos<br />but in other respects it is light.<br /></p><p>There is nothing more animal-like<br />than a clear conscience<br />on the third planet of the Sun.<br /></p></blockquote>'
- - https://www.wsj.com/articles/the-summers-most-unread-book-is-1404417569
  - ! "The Summer's Most Unread Book Is… A simple index drawn from e-books shows which best sellers are going unread (we're looking at you, Piketty)"
  - Jordan Ellenberg
  - 2014-07-03
  - ''
  - ! '<p>Sadly overlooked is that other crucial literary category: the summer <em>non</em>-read, the book that you pick up, all full of ambition, at the beginning of June and put away, the bookmark now and forever halfway through chapter 1, on Labor Day. The classic of this genre is Stephen Hawking’s <em>A Brief History of Time</em>, widely called “the most unread book of all time.”…How can we find today’s greatest non-reads? Amazon’s “Popular Highlights” feature provides one quick and dirty measure. Every book’s Kindle page lists the five passages most highlighted by readers. If every reader is getting to the end, those highlights could be scattered throughout the length of the book. If nobody has made it past the introduction, the popular highlights will be clustered at the beginning.</p><p>Thus, the Hawking Index (HI): Take the page numbers of a book’s five top highlights, average them, and divide by the number of pages in the whole book. The higher the number, the more of the book we’re guessing most people are likely to have read. (Disclaimer: This is not remotely scientific and is for entertainment purposes only!) Here’s how some current best sellers and classics weigh in, from highest HI to lowest:</p><ul><li><p><em>Thinking Fast and Slow</em> by Daniel Kahneman: 6.8%</p><p>Apparently the reading was more slow than fast. To be fair, Prof. Kahneman’s book, the summation of a life’s work at the forefront of cognitive psychology, is more than twice as long as <em>Lean In</em>, so his score probably represents just as much total reading as Ms. Sandberg’s does.</p></li><li><p><em>A Brief History of Time</em> by Stephen Hawking: 6.6%</p><p>The original avatar backs up its reputation pretty well. But it’s outpaced by one more recent entrant—which brings us to our champion, the most unread book of this year (and perhaps any other). Ladies and gentlemen, I present:</p></li><li><p><em>Capital in the Twenty-First Century</em> by Thomas Piketty: 2.4%</p><p>Yes, it came out just three months ago. But the contest isn’t even close. Mr. Piketty’s book is almost 700 pages long, and the last of the top five popular highlights appears on page 26. Stephen Hawking is off the hook; from now on, this measure should be known as the Piketty Index.</p></li></ul>'
- - https://www.inc.com/minda-zetlin/amazon-book-stuffing-authors-scam-chance-carter-romance-kindle-unlimited.html
  - ! "Kindle Unlimited Book Stuffing Scam Earns Millions and Amazon Isn't Stopping It: Book stuffer Chance Carter is gone. But readers are still paying for books that are 90 percent filler."
  - Minda Zetlin
  - 2018-06-13
  - ''
  - ! '<p>…a distasteful practice called “book stuffing” by some Kindle Unlimited authors. Kindle Unlimited is an Amazon program that works like Netflix for books: You can read as much as you want for a flat monthly fee. For various reasons, Kindle Unlimited is filled with books written and self-published by independent authors, many of them in the romance genre.</p><p>How do authors get compensated when readers pay a flat fee for the service? Amazon has created a pool of funds that authors are paid from, currently around $22.5 million. Up until 2015, authors earned a flat fee for each download of their books. But the company noticed that many of these Kindle Unlimited books were very, very short. So instead, Amazon began paying a bit less than ¢0.5 cent for each page that was actually read. That’s how book stuffing was born.</p><p>It works like this. An Amazon author publishes a new book that’s, say, 300 pages long. At ¢0.5 per page, the author would earn about $1.50 every time that book was read to the end. To beef up their earnings, book stuffers add several other already-published books, or a long series of newsletters, to the end of the book as “bonus material.” Most stuffed books run near 3,000 pages, the maximum that Amazon will pay for. In the current system, an author could earn about $13.50 per book this way, which is more than most authors earn from traditional publishers when their books are sold as hardcovers.</p><p><strong>$1.2 million a year?</strong></p><p>Serious book stuffers acquire email lists that they sometimes share with each other. They boost their sales by sending out promotional email to hundreds of thousands of email addresses. They also spend a lot of money on Amazon Marketing Services, promoting their books as “sponsored” to Kindle Unlimited subscribers and other Kindle shoppers. These tactics, in combination with artificially producing positive reviews (against Amazon’s rules), help them rank high in Amazon’s romance category, crowding out authors who take a more traditional approach. Some book stuffers publish a new book every couple of weeks (they may use ghostwriters to actually write the books), doing a new promotion for each one. In this way, observers report, they can earn as much as $100,000 <em>per month</em>.</p><p>…Why would anyone read through 2,700 pages of uninteresting bonus material? They usually don’t, but many authors do something that gets people to turn to the last page of the book, such as promising a contest or giveaway (forbidden by Amazon rules), or putting some new and perhaps particularly racy content right at the end of the book. On some devices, Amazon may simply be using the last page opened as a measure of how much of a book was “read.” Thus, the author gets full credit for the book, even though the customer didn’t read all of it.</p><p>…Carter openly invited other authors to pay for the use of his “platform” to send out promotional emails to their own mailing lists and also share mailing lists and cross-promote with other authors/book stuffers. In fact, he was so proud of his book stuffing talents that he posted his credo for the world to see in a Kindle publishing forum:</p><blockquote><ul><li>Making content as long as possible.</li><li>Releasing as frequently as possible.</li><li>Advertising as hard as possible.</li><li>Ranking as high as possible.</li><li>And then doing it all over again.</li></ul></blockquote>'
- - https://www.theverge.com/2018/7/16/17566276/cockygate-amazon-kindle-unlimited-algorithm-self-published-romance-novel-cabal
  - "Bad romance: To cash in on Kindle Unlimited, a cabal of authors gamed Amazon’s algorithm"
  - Sarah Jeong
  - 2018-07-16
  - ''
  - ! '<p>On June 4th, a group of lawyers shuffled into a federal court in Manhattan to argue over two trademark registrations. The day’s hearing was the culmination of months of internet drama—furious blog posts, Twitter hashtags, YouTube videos, claims of doxxing, and death threats….They were gathered there that day because one self-published romance author was suing another for using the word “cocky” in her titles. And as absurd as this courtroom scene was—with a federal judge soberly examining the shirtless doctors on the cover of an “MFM Menage Romance”—it didn’t even begin to scratch the surface.</p><p>The fight over <code>#Cockygate</code>, as it was branded online, emerged from the strange universe of Amazon Kindle Unlimited, where authors collaborate and compete to game Amazon’s algorithm. Trademark trolling is just the beginning: There are private chat groups, ebook exploits, conspiracies to seed hyper-specific trends like “Navy SEALs” and “mountain men,” and even a controversial sweepstakes in which a popular self-published author offered his readers a chance to win diamonds from Tiffany’s if they reviewed his new book…A genre that mostly features shiny, shirtless men on its covers and sells ebooks for ¢99 a pop might seem unserious. But at stake are revenues sometimes amounting to a million dollars a year, with some authors easily netting six figures a month. The top authors can drop $50,000 on a single ad campaign that will keep them in the charts—and see a worthwhile return on that investment.</p><p>…According to Willink, over the course of RWA, Valderrama told her about certain marketing and sales strategies, which she claimed to handle for other authors. Valderrama allegedly said that she organized newsletter swaps, in which authors would promote each other’s books to their respective mailing lists. She also claimed to manage review teams—groups of assigned readers who were expected to leave reviews for books online. According to Willink, Valderrama’s authors often bought each other’s books to improve their ranking on the charts—something that she arranged, coordinating payments through her own PayPal account. Valderrama also told her that she used multiple email addresses to buy authors’ books on iBooks when they were trying to hit the USA Today list. When Valderrama invited Willink to a private chat group of romance authors, Willink learned practices like chart gaming and newsletter placement selling—and much more—were surprisingly common.</p><p>…In yet more screencaps, members discuss the mechanics of “book stuffing.” Book stuffing is a term that encompasses a wide range of methods for taking advantage of the Kindle Unlimited revenue structure. In Kindle Unlimited, readers pay $9.99 a month to read as many books as they want that are available through the KU program. This includes both popular mainstream titles like the <em>Harry Potter</em> series and self-published romances put out by authors like Crescent and Hopkins. Authors are paid according to pages read, creating incentives to produce massively inflated and strangely structured books. The more pages Amazon thinks have been read, the more money an author receives.</p><p>…Book stuffing is particularly controversial because Amazon pays authors from a single communal pot. In other words, Kindle Unlimited is a zero-sum game. The more one author gets from Kindle Unlimited, the less the other authors get. The romance authors Willink was discovering didn’t go in for clumsy stuffings of automatic translations or HTML cruft; rather, they stuffed their books with ghostwritten content or repackaged, previously published material. In the latter case, the author will bait readers with promises of fresh content, like a new novella, at the end of the book. Every time a reader reads to the end of a 3,000-page book, the author earns almost 14 dollars. For titles that break into the top of the Kindle Unlimited charts, this trick can generate a fortune.</p>'
- - https://www.vox.com/culture/2019/2/6/18212431/black-leopard-red-wolf-marlon-james-review
  - "Black Leopard Red Wolf was sold as an African Game of Thrones. It’s a weirder book than that. Man Booker Prize winner Marlon James goes genre with his latest novel."
  - Constance Grady
  - 2019-02-06
  - ''
  - ! '<p>The oft-repeated elevator pitch on <em>Black Leopard Red Wolf</em>, the buzzy new novel from Man Booker Prize winner Marlon James, is that it’s the African <em>Game of Thrones</em>. (“I said that as a joke,” James protested in an interview this week.) To a certain extent, the comparison holds. <em>Black Leopard Red Wolf</em> is a lush epic fantasy set in an enchanted and mythical Africa, filled with quests and magical beasts and vicious battles to the death. But it’s also a much weirder, twistier book than the <em>Game of Thrones</em> parallels would suggest. Most notably, it is not driven by story. <em>Black Leopard Red Wolf</em> actively resists any attempts on the reader’s part to sink inside the world of the book and lose themselves. It is deliberately opaque, on the level of sentence as well as plot.</p><p>On the sentence level, James likes to withhold proper nouns until the last possible moment and then waits to reveal them just a little bit longer than you’d think he should be able to get away with. That means his sentences are generally carried by verbs, and you don’t know who is doing what or why for long stretches at a time: You just get an impression of anonymous limbs tangled together in sex or battle for some reason that is not immediately clear.</p><p>On the plot level, the quest for a missing boy that ostensibly powers the action of the book is so confusing, and has so little to do with the main character’s motivations, that the rest of the characters are constantly complaining about it. “This child carries no stakes for you,” one says toward the end of the novel to Tracker, our protagonist, and she’s correct. So is the poor sad giant who has the premise of the quest he is on explained to him multiple times and can only conclude, “Confusing, this is.”</p><p>…In other words, we know that the quest will be futile and the child will die. We also know that the protagonist is not particularly interested in the quest. It is nearly impossible for a reader to hook into the narrative. Yet <em>Black Leopard Red Wolf</em> spends hundreds and hundreds of pages tracking its many twists and permutations. The opacity here is clearly a deliberate choice on James’s part. He is not interested in easy reads or straightforward stories. “The African folktale is not your refuge from skepticism,” he told the New Yorker earlier this year. “It is not here to make things easy for you, to give you faith so you don’t have to think.” And James plans to keep things challenging through the rest of the Dark Star trilogy, of which <em>Black Leopard</em> is only the first volume. He’s modeling it on Showtime’s <em>Rashomon</em>-like series <em>The Affair</em>, he says, so that each volume will present the same events to the reader through a different point of view. “The series is three different versions of the same story, and I’m not going to tell people which they should believe,” James says.</p>'
- - https://github.com/paul-buerkner/brms
  - "brms: an R package for Bayesian generalized multivariate non-linear multilevel models using Stan"
  - Paul Bürkner et al
  - ''
  - ''
  - ! 'The brms package provides an interface to fit Bayesian generalized (non-)linear multivariate multilevel models using Stan, which is a C++ package for performing full Bayesian inference (see http://mc-stan.org/). The formula syntax is very similar to that of the package lme4 to provide a familiar and simple interface for performing regression analyses. A wide range of response distributions are supported, allowing users to fit—among others—linear, robust linear, count data, survival, response times, ordinal, zero-inflated, and even self-defined mixture models all in a multilevel context. Further modeling options include non-linear and smooth terms, auto-correlation structures, censored data, missing value imputation, and quite a few more. In addition, all parameters of the response distribution can be predicted in order to perform distributional regression. Multivariate models (i.e., models with multiple response variables) can be fit, as well. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. Model fit can easily be assessed and compared with posterior predictive checks, cross-validation, and Bayes factors.'
- - https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html#additive-distributional-models
  - "Estimating Distributional Models with brms: Additive Distributional Models"
  - Paul Bürkner
  - 2019-08-29
  - ''
  - ! '<p>This vignette provides an introduction on how to fit distributional regression models with brms. We use the term distributional model to refer to a model, in which we can specify predictor terms for all parameters of the assumed response distribution. In the vast majority of regression model implementations, only the location parameter (usually the mean) of the response distribution depends on the predictors and corresponding regression parameters. Other parameters (e.g., scale or shape parameters) are estimated as auxilliary parameters assuming them to be constant across observations. This assumption is so common that most researchers applying regression models are often (in my experience) not aware of the possibility of relaxing it. This is understandable insofar as relaxing this assumption drastically increase model complexity and thus makes models hard to fit. Fortunately, brms uses Stan on the backend, which is an incredibly flexible and powerful tool for estimating Bayesian models so that model complexity is much less of an issue.</p> <p>...In the examples so far, we did not have multilevel data and thus did not fully use the capabilities of the distributional regression framework of brms. In the example presented below, we will not only show how to deal with multilevel data in distributional models, but also how to incorporate smooth terms (i.e., splines) into the model. In many applications, we have no or only a very vague idea how the relationship between a predictor and the response looks like. A very flexible approach to tackle this problems is to use splines and let them figure out the form of the relationship.</p>'
- - /docs/iq/2014-abdulkadiroglu.pdf
  - "The Elite Illusion: Achievement Effects at Boston and New York Exam Schools"
  - "Atila Abdulkadiroğlu, Joshua Angrist, Parag Pathak"
  - 2014-02-05
  - 10.3982/ECTA10266
  - ! "Parents gauge school quality in part by the level of student achievement and a school's racial and socioeconomic mix. The importance of school characteristics in the housing market can be seen in the jump in house prices at school district boundaries where peer characteristics change. The question of whether schools with more attractive peers are really better in a value-added sense remains open, however. This paper uses a fuzzy regression-discontinuity design to evaluate the causal effects of peer characteristics. Our design exploits admissions cutoffs at Boston and New York City's heavily over-subscribed exam schools. Successful applicants near admissions cutoffs for the least selective of these schools move from schools with scores near the bottom of the state SAT score distribution to schools with scores near the median. Successful applicants near admissions cutoffs for the most selective of these schools move from above-average schools to schools with students whose scores fall in the extreme upper tail. Exam school students can also expect to study with fewer nonwhite classmates than unsuccessful applicants. Our estimates suggest that the marked changes in peer characteristics at exam school admissions cutoffs have little causal effect on test scores or college quality."
- - /docs/iq/2014-dobbie.pdf
  - "The Impact of Attending a School with High-Achieving Peers: Evidence from the New York City Exam Schools"
  - "Will Dobbie, Roland G. Fryer Jr."
  - 2014-07
  - "10.1257/app.6.3.58"
  - ! ' This paper uses data from three prominent exam high schools in New York City to estimate the impact of attending a school with high-achieving peers on college enrollment and graduation. Our identification strategy exploits sharp discontinuities in the admissions process. Applicants just eligible for an exam school have peers that score 0.17 to 0.36 standard deviations higher on eighth grade state tests and that are 6.4 to 9.5 percentage points less likely to be black or Hispanic. However, exposure to these higher-achieving and more homogeneous peers has little impact on college enrollment, college graduation, or college quality.'
- - https://articlegateway.com/index.php/AJM/article/view/2392
  - "Non-Cognitive Skills: How Much Do They Matter for Earnings in Canada?"
  - "Dawson McLean, Mohsen Bouaissa, Bruno Rainville, Ludovic Auger"
  - 2019-12-04
  - 10.33423/ajm.v19i4.2392
  - ! 'Evidence from different countries suggests that non-cognitive skills play an important role in wage determination and overall social outcomes, but studies for Canada are scarce. We contribute to filling this gap by estimating wage regressions with the Big Five traits using the Longitudinal and International Study of Adults. Our results indicate that conscientiousness is positively associated with wages, while agreeableness, extraversion, and neuroticism are associated with negative returns, with higher magnitudes on agreeableness and conscientiousness for females. Cognitive ability has the highest estimated wage return so, while significant, non-cognitive skills do not seem to be the most important wage determinant. [Keywords: Management, Labour Market, Returns to Skills, Non-Cognitive Skill, Cognitive Skill, Wage Regressions, Personality Traits, Five-Factor Model]'
- - https://openai.com/blog/musenet/
  - "MuseNet: a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles"
  - Christine Payne (OpenAI)
  - 2019-04-25
  - ''
  - ! '<p>We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as GPT-2, a large-scale transformer model trained to predict the next token in a sequence, whether audio or text.</p><p>[See also: <a href="https://arxiv.org/abs/1904.10509">“Generating Long Sequences with Sparse Transformers”</a>, Child et al 2019</p><blockquote><p>Transformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to O(n ⋅ √n). We also introduce (a) a variation on architecture and initialization to train deeper networks, (b) the recomputation of attention matrices to save memory, and (c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, CIFAR-10, and ImageNet-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more. ]</p></blockquote>'
- - https://magenta.tensorflow.org/music-transformer
  - "Music Transformer: Generating Music with Long-Term Structure"
  - Cheng-Zhi Anna Huang, Ian Simon, Monica Dinculescu (Google Magenta)
  - 2018-12-13
  - ''
  - ! '<p><strong>Update (9/16/19)</strong>: <em><a href="https://magenta.tensorflow.org/piano-transformer">Play with Music Transformer</a> in an interactive Colab!</em></p><figure style="text-align: center;"><img src="https://magenta.tensorflow.org/assets/music_transformer/motifs_shaded_boxes.png" style="max-width: 100%; margin: auto" /></figure><p>Generating long pieces of music is a challenging problem, as music contains structure at multiple timescales, from millisecond timings to motifs to phrases to repetition of entire sections. We present <a href="https://arxiv.org/abs/1809.04281">Music Transformer</a>, an attention-based neural network that can generate music with improved long-term coherence. Here are three piano performances generated by the model:</p><center><div><audio controls=""><source src="https://magenta.tensorflow.org/assets/music_transformer/relatively_jazz.mp3" type="audio/mpeg" /></audio></div><div><audio controls=""><source src="https://magenta.tensorflow.org/assets/music_transformer/classical_favourite_sample.mp3" type="audio/mpeg" /></audio></div><div><audio controls=""><source src="https://magenta.tensorflow.org/assets/music_transformer/transformer_nice.mp3" type="audio/mpeg" /></audio></div></center><p>Similar to <a href="performance-rnn">Performance RNN</a>, we use an event-based representation that allows us to generate expressive performances directly (i.e. without first generating a score). In contrast to an LSTM-based model like Performance RNN that compresses earlier events into a fixed-size hidden state, here we use a <a href="https://arxiv.org/abs/1706.03762">Transformer</a>-based model that has direct access to all earlier events.</p><p>Our recent <a href="https://magenta.tensorflow.org/maestro-wave2midi2wave">Wave2Midi2Wave</a> project also uses Music Transformer as its language model.</p>'
- - https://cdn.openai.com/dota-2.pdf
  - "Dota 2 with Large Scale Deep Reinforcement Learning"
  - Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław Dębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael Petrov, Henrique Pondé de Oliveira Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter, Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, Susan Zhang (OpenAI)
  - 2019-12-13
  - ''
  - ! 'On April 13th, 2019, OpenAI Five became the first AI system to defeat the world champions at an e-sports game. The game of Dota 2 presents novel challenges for AI systems such as long time horizons, imperfect information, and complex, continuous state-action spaces, all challenges which will become increasingly central to more capable AI systems. OpenAI Five leveraged existing reinforcement learning techniques, scaled to learn from batches of approximately 2 million frames every 2 seconds. We developed a distributed training system and tools for continual training which allowed us to train OpenAI Five for 10 months. By defeating the Dota 2 world champion (Team OG), OpenAI Five demonstrates that self-play reinforcement learning can achieve superhuman performance on a difficult task'
- - https://openai.com/projects/five/
  - "OpenAI Five: 2016–2019"
  - OpenAI
  - 2019-12-13
  - ''
  - ! '<p>At OpenAI, we’ve used the multiplayer video game Dota 2 as a research platform for general-purpose AI systems. Our Dota 2 AI, called OpenAI Five, learned by playing over 10,000 years of games against itself. It demonstrated the ability to achieve expert-level performance, learn human–AI cooperation, and operate at internet scale.</p> <p>[OpenAI final report on OA5: timeline, training curve, index of blog posts.]</p>'
- - /docs/psychology/1996-petrie.pdf
  - "Environment is not the Most Important Variable in Determining Oral Morphine Consumption in Wistar Rats"
  - B. F. Petrie
  - 1996-04-01
  - 10.2466/pr0.1996.78.2.391
  - ! 'The role of differential housing on sucrose-morphine consumption in outbred Wistar rats was investigated in two studies. The results of earlier research, indicating rats housed in a quasinatural colony drank significantly less sucrose-morphine than rats isolated in standard laboratory cages, could not be replicated, as the consumption of sucrose-morphine by the isolated animals in the present two studies was reduced. It is possible that during a colony conversion the supplier inadvertently introduced strain differences making the present rats more resistant to xenobiotic consumption. Discussion documents the role of genetics in morphine consumption.'
- - https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf#page=5
  - "GPT-1: Improving Language Understanding by Generative Pre-Training"
  - "Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever"
  - 2018-06-08
  - ''
  - ! 'Natural language understanding comprises a wide range of diverse tasks suchas textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by <em>generative pre-training</em> of a language model on a diverse corpus of unlabeled text, followed by <em>discriminative fine-tuning</em> on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI).'
- - https://ftfy.readthedocs.io/en/latest/
  - "ftfy: fixes text for you"
  - 'ftfy'
  - ''
  - ''
  - ! '<p><code>ftfy</code> fixes Unicode that’s broken in various ways.</p><p>The goal of ftfy is to <strong>take in bad Unicode and output good Unicode</strong>, for use in your Unicode-aware code. This is different from taking in non-Unicode and outputting Unicode, which is not a goal of ftfy. It also isn’t designed to protect you from having to write Unicode-aware code. ftfy helps those who help themselves.</p><p>Of course you’re better off if your input is decoded properly and has no glitches. But you often don’t have any control over your input; it’s someone else’s mistake, but it’s your problem now.</p><p>ftfy will do everything it can to fix the problem.</p>'
- - https://onlinelibrary.wiley.com/doi/full/10.1111/ele.13438
  - "Individual differences in behaviour explain variation in survival: a meta-analysis"
  - "Maria Moiron, Kate L. Laskowski, Petri T. Niemelä"
  - 2019-12-06
  - 10.1111/ele.13438
  - ! 'Research focusing on among-individual differences in behaviour (‘animal personality’) has been blooming for over a decade. Central theories explaining the maintenance of such behavioural variation posits that individuals expressing greater “risky” behaviours should suffer higher mortality. Here, for the first time, we synthesize the existing empirical evidence for this key prediction. Our results did not support this prediction as there was no directional relationship between riskier behaviour and greater mortality; however there was a significant absolute relationship between behaviour and survival. In total, behaviour explained a significant, but small, portion (5.8%) of the variance in survival. We also found that risky (vs. “shy”) behavioural types live significantly longer in the wild, but not in the laboratory. This suggests that individuals expressing risky behaviours might be of overall higher quality but the lack of predation pressure and resource restrictions mask this effect in laboratory environments. Our work demonstrates that individual differences in behaviour explain important differences in survival but not in the direction predicted by theory. Importantly, this suggests that models predicting behaviour to be a mediator of reproduction-survival trade-offs may need revision and/or empiricists may need to reconsider their proxies of risky behaviours when testing such theory.'
- - https://journals.sagepub.com/doi/pdf/10.1177/1098612X15582080
  - Audiogenic reflex seizures in cats
  - Mark Lowrie, Claire Bessant, Robert J Harvey, Andrew Sparkes, Laurent Garosi
  - 2015-04-27
  - '10.1177/1098612X15582080'
  - ! '<p><strong>Objectives</strong>: This study aimed to characterise feline audiogenic reflex seizures (FARS).</p><p><strong>Methods</strong>: An online questionnaire was developed to capture information from owners with cats suffering from FARS. This was collated with the medical records from the primary veterinarian. 96 cats were included.</p><p><strong>Results</strong>: Myoclonic seizures were one of the cardinal signs of this syndrome (90/96), frequently occurring prior to generalised tonic–clonic seizures (GTCSs) in this population. Other features include a late onset (median 15 years) and absence seizures (6/96), with most seizures triggered by high-frequency sounds amid occasional spontaneous seizures (up to 20%). Half the population (48/96) had hearing impairment or were deaf. One-third of cats (35/96) had concurrent diseases, most likely reflecting the age distribution. Birmans were strongly represented (30/96). Levetiracetam gave good seizure control. The course of the epilepsy was non-progressive in the majority (68/96), with an improvement over time in some (23/96). Only 33/96 and 11/90 owners, respectively, felt the GTCSs and myoclonic seizures affected their cat’s quality of life (QoL). Despite this, many owners (50/96) reported a slow decline in their cat’s health, becoming less responsive (43/50), not jumping (41/50), becoming uncoordinated or weak in the pelvic limbs (24/50) and exhibiting dramatic weight loss (39/50). These signs were exclusively reported in cats experiencing seizures for &gt;2 years, with 42/50 owners stating these signs affected their cat’s QoL.</p><p><strong>Conclusions and relevance</strong>: In gathering data on audiogenic seizures in cats, we have identified a new epilepsy syndrome named FARS with a geriatric onset. Further studies are warranted to investigate potential genetic predispositions to this condition.</p>'
- - https://thesession.org/
  - The Sesson
  - 'The Session community'
  - ''
  - ''
  - ! 'The Session is an online community and website dedicated to Irish traditional music. You can find >40k tunes to play, find sessions to play them in, and join in discussions about the music. You can also find events (like concerts and festivals), or explore the track listings of recordings.'
- - https://www.nature.com/articles/s41467-019-13585-5
  - "Genome-wide analysis identifies molecular systems and 149 genetic loci associated with income"
  - W. David Hill, Neil M. Davies, Stuart J. Ritchie, Nathan G. Skene, Julien Bryois, Steven Bell, Emanuele Di Angelantonio, David J. Roberts, Shen Xueyi, Gail Davies, David C. M. Liewald, David J. Porteous, Caroline Hayward, Adam S. Butterworth, Andrew M. McIntosh, Catharine R. Gale, Ian J. Deary
  - 2019-12-16
  - 10.1038/s41467-019-13585-5
  - ! 'Socioeconomic position (SEP) is a multi-dimensional construct reflecting (and influencing) multiple socio-cultural, physical, and environmental factors. In a sample of 286,301 participants from UK Biobank, we identify 30 (29 previously unreported) independent-loci associated with income. Using a method to meta-analyze data from genetically-correlated traits, we identify an additional 120 income-associated loci. These loci show clear evidence of functionality, with transcriptional differences identified across multiple cortical tissues, and links to GABAergic and serotonergic neurotransmission. By combining our genome wide association study on income with data from eQTL studies and chromatin interactions, 24 genes are prioritized for follow up, 18 of which were previously associated with intelligence. We identify intelligence as one of the likely causal, partly-heritable phenotypes that might bridge the gap between molecular genetic inheritance and phenotypic consequence in terms of income differences. These results indicate that, in modern era Great Britain, genetic effects contribute towards some of the observed socioeconomic inequalities.'
- - https://danluu.com/keyboard-latency/
  - Keyboard latency
  - Dan Luu
  - 2017-10-16
  - ''
  - ! '<p>[Dan Luu continues his investigation of why computers feel so laggy and have such high latency compared to old computers (<a href="https://danluu.com/input-lag/">total computer latency</a>, <a href="https://danluu.com/term-latency/">terminal latency</a>, <a href="https://danluu.com/web-bloat/">web bloat</a>, cf <a href="https://pavelfatin.com/typing-with-pleasure/">Pavel Fatin’s “Typing with pleasure”</a> text editor analysis).</p><p>He measures 21 keyboard latencies using a logic analyzer, finding a range of 15–60ms (!), representing a waste of a large fraction of the available ~100–200ms latency budget before a user notices and is irritated (“the median keyboard today adds as much latency as the entire end-to-end pipeline as a fast machine from the 70s.”). The latency estimates are surprising, and do not correlate with advertised traits. They simply have to be measured empirically.]</p><p>We can see that, even with the limited set of keyboards tested, there can be as much as a 45ms difference in latency between keyboards. Moreover, a modern computer with one of the slower keyboards attached can’t possibly be as responsive as a quick machine from the 70s or 80s because the keyboard alone is slower than the entire response pipeline of some older computers. That establishes the fact that modern keyboards contribute to the latency bloat we’ve seen over the past forty years…Most keyboards add enough latency to make the user experience noticeably worse, and keyboards that advertise speed aren’t necessarily faster. The two gaming keyboards we measured weren’t faster than non-gaming keyboards, and the fastest keyboard measured was a minimalist keyboard from Apple that’s marketed more on design than speed.</p>'
- - https://danluu.com/input-lag/
  - 'Computer latency: 1977–2017'
  - Dan Luu
  - 2017-12
  - ''
  - ! '<p>I’ve had this nagging feeling that the computers I use today feel slower than the computers I used as a kid. As a rule, I don’t trust this kind of feeling because human perception has been shown to be unreliable in empirical studies, so I carried around a high-speed camera and measured the response latency of devices I’ve run into in the past few months. These are tests of the latency between a keypress and the display of a character in a terminal (see appendix for more details) …If we look at overall results, the fastest machines are ancient. Newer machines are all over the place. Fancy gaming rigs with unusually high refresh-rate displays are almost competitive with machines from the late 70s and early 80s, but “normal” modern computers can’t compete with thirty to forty year old machines.</p><p>…Almost every computer and mobile device that people buy today is slower than common models of computers from the 70s and 80s. Low-latency gaming desktops and the iPad Pro can get into the same range as quick machines from thirty to forty years ago, but most off-the-shelf devices aren’t even close.</p><p>If we had to pick one root cause of latency bloat, we might say that it’s because of “complexity”. Of course, we all know that complexity is bad. If you’ve been to a non-academic non-enterprise tech conference in the past decade, there’s a good chance that there was at least one talk on how complexity is the root of all evil and we should aspire to reduce complexity.</p><p>Unfortunately, it’s a lot harder to remove complexity than to give a talk saying that we should remove complexity. A lot of the complexity buys us something, either directly or indirectly. When we looked at the input of a fancy modern keyboard vs. the Apple 2 keyboard, we saw that using a relatively powerful and expensive general purpose processor to handle keyboard inputs can be slower than dedicated logic for the keyboard, which would both be simpler and cheaper. However, using the processor gives people the ability to easily customize the keyboard, and also pushes the problem of “programming” the keyboard from hardware into software, which reduces the cost of making the keyboard. The more expensive chip increases the manufacturing cost, but considering how much of the cost of these small-batch artisanal keyboards is the design cost, it seems like a net win to trade manufacturing cost for ease of programming.</p>'
- - https://danluu.com/term-latency/
  - Terminal Latency
  - Dan Luu
  - 2017-07-18
  - ''
  - ! '<p>These graphs show the distribution of latencies for each terminal. The y-axis has the latency in milliseconds. The x-axis is the percentile (e.g., 50 means represents 50%-ile keypress i.e., the median keypress). Measurements are with macOS unless otherwise stated. The graph on the left is when the machine is idle, and the graph on the right is under load. If we just look at median latencies, some setups don’t look too bad – terminal.app and emacs-eshell are at roughly 5ms unloaded, small enough that many people wouldn’t notice. But most terminals (st, alacritty, hyper, and iterm2) are in the range where you might expect people to notice the additional latency even when the machine is idle. If we look at the tail when the machine is idle, say the 99.9%-ile latency, every terminal gets into the range where the additional latency ought to be perceptible, according to studies on user interaction. For reference, the internally generated keypress to GPU memory trip for some terminals is slower than the time it takes to send a packet from Boston to Seattle and back, about 70ms.</p><p>…Most terminals have enough latency that the user experience could be improved if the terminals concentrated more on latency and less on other features or other aspects of performance. However, when I search for terminal benchmarks, I find that terminal authors, if they benchmark anything, benchmark the speed of sinking stdout or memory usage at startup. This is unfortunate because most “low performance” terminals can already sink stdout many orders of magnitude faster than humans can keep up with, so further optimizing stdout throughput has a relatively small impact on actual user experience for most users. Likewise for reducing memory usage when an idle terminal uses 0.01% of the memory on my old and now quite low-end laptop. If you work on a terminal, perhaps consider relatively more latency and interactivity (e.g., responsiveness to ^C) optimization and relatively less throughput and idle memory usage optimization.</p>'
- - https://www.inkandswitch.com/slow-software.html
  - Slow Software
  - Mark McGranaghan (Ink & Switch)
  - 2018-11
  - ''
  - ! '<p>You spend lots of time waiting on your computer. You pause while apps start and web pages load. Spinner icons are everywhere. Hardware gets faster, but software still feels slow. What gives? If you use your computer to do important work, you deserve fast software. Too much of today’s software falls short. At the Ink &amp; Switch research lab we’ve researched why that is, so that we can do better. This article shares we’ve learned…Let’s look at an example of how latency can add up:</p><figure><img src="https://www.inkandswitch.com/media/slow-software/input-latency-cascade.png" alt="Latency waterfall example: A hypothetical example of end-to-end latency from input to display. Dashed vertical lines indicate cycles the pipeline needs to wait for." /><figcaption><em>Latency waterfall example</em>: A hypothetical example of end-to-end latency from input to display. Dashed vertical lines indicate cycles the pipeline needs to wait for.</figcaption></figure><p>…There is a deep stack of technology that makes a modern computer interface respond to a user’s requests. Even something as simple as pressing a key on a keyboard and having the corresponding character appear in a text input box traverses a lengthy, complex gauntlet of steps, from the scan rate of the keyboard, through the OS and framework processing layers, through the graphics card rendering and display refresh rate. There is reason for this complexity, and yet we feel sad that computer users trying to be productive with these devices are so often left waiting, watching spinners, or even just with the slight but still perceptible sense that their devices simply can’t keep up with them.</p><ul><li><p>What feels slow</p><ul><li>Latency not throughput</li><li>Touch interfaces</li><li>Typing</li><li>Mousing</li><li>Applications</li><li>Real-world apps</li></ul></li><li><p>Where slowness comes from</p><ul><li>Input devices</li><li>Sample rates</li><li>Displays and GPUs</li><li>Cycle stacking</li><li>Runtime overhead</li><li>Latency by design</li><li>User-hostile work</li><li>Application code</li><li>Putting it together</li></ul></li><li><p>Toward fast software</p></li><li><p>References</p></li></ul>'
- - https://www.inkandswitch.com/local-first.html
  - "Local-first software: You own your data, in spite of the cloud"
  - Martin Kleppmann, Adam Wiggins, Peter van Hardenberg, Mark McGranaghan (Ink & Switch)
  - 2019-04
  - ''
  - ! '<p>[<a href="https://www.inkandswitch.com/media/local-first/local-first.pdf" title="Kleppmann et al 2019">PDF version</a>]</p><p>Cloud apps like Google Docs and Trello are popular because they enable real-time collaboration with colleagues, and they make it easy for us to access our work from all of our devices. However, by centralizing data storage on servers, cloud apps also take away ownership and agency from users. If a service shuts down, the software stops functioning, and data created with that software is lost.</p><p>In this article we propose “local-first software”: a set of principles for software that enables both collaboration and ownership for users. Local-first ideals include the ability to work offline and collaborate across multiple devices, while also improving the security, privacy, long-term preservation, and user control of data.</p><p>We survey existing approaches to data storage and sharing, ranging from email attachments to web apps to Firebase-backed mobile apps, and we examine the trade-offs of each. We look at Conflict-free Replicated Data Types (CRDTs): data structures that are multi-user from the ground up while also being fundamentally local and private. CRDTs have the potential to be a foundational technology for realizing local-first software.</p><p>We share some of our findings from developing local-first software prototypes at Ink &amp; Switch over the course of several years. These experiments test the viability of CRDTs in practice, and explore the user interface challenges for this new data model. Lastly, we suggest some next steps for moving towards local-first software: for researchers, for app developers, and a startup opportunity for entrepreneurs.</p><p>…in the cloud, ownership of data is vested in the servers, not the users, and so we became borrowers of our own data. The documents created in cloud apps are destined to disappear when the creators of those services cease to maintain them. Cloud services defy long-term preservation. No Wayback Machine can restore a sunsetted web application. The Internet Archive cannot preserve your Google Docs.</p><p>In this article we explored a new way forward for software of the future. We have shown that it is possible for users to retain ownership and control of their data, while also benefiting from the features we associate with the cloud: seamless collaboration and access from anywhere. It is possible to get the best of both worlds.</p><p>But more work is needed to realize the local-first approach in practice. Application developers can take incremental steps, such as improving offline support and making better use of on-device storage. Researchers can continue improving the algorithms, programming models, and user interfaces for local-first software. Entrepreneurs can develop foundational technologies such as CRDTs and peer-to-peer networking into mature products able to power the next generation of applications.</p><ul><li><p>Motivation: collaboration and ownership</p></li><li><p>Seven ideals for local-first software</p><ul><li>No spinners: your work at your fingertips</li><li>Your work is not trapped on one device</li><li>The network is optional</li><li>Seamless collaboration with your colleagues</li><li>The Long Now</li><li>Security and privacy by default</li><li>You retain ultimate ownership and control</li></ul></li><li><p>Existing data storage and sharing models</p><ul><li>How application architecture affects user experience<ul><li>Files and email attachments</li><li>Web apps: Google Docs, Trello, Figma</li><li>Dropbox, Google Drive, Box, OneDrive, etc.</li><li>Git and GitHub</li></ul></li><li>Developer infrastructure for building apps<ul><li>Web app (thin client)</li><li>Mobile app with local storage (thick client)</li><li>Backend-as-a-Service: Firebase, CloudKit, Realm</li><li>CouchDB</li></ul></li></ul></li><li><p>Towards a better future</p><ul><li>CRDTs as a foundational technology</li><li>Ink &amp; Switch prototypes<ul><li>Trello clone</li><li>Collaborative drawing</li><li>Media canvas</li><li>Findings</li></ul></li><li>How you can help<ul><li>For distributed systems and programming languages researchers</li><li>For Human-Computer Interaction (HCI) researchers</li><li>For practitioners</li><li>Call for startups</li></ul></li></ul></li><li><p>Conclusions</p></li></ul>'
- - https://www.inkandswitch.com/media/local-first/local-first.pdf
  - "Local-First Software: You Own Your Data, in spite of the Cloud"
  - Martin Kleppmann, Adam Wiggins, Peter van Hardenberg, Mark McGranaghan (Ink & Switch)
  - 2019-10-23
  - 10.1145/3359591.3359737
  - ! '<p>Cloud apps like Google Docs and Trello are popular because they enable real-time collaboration with colleagues, and they make it easy for us to access our work from all of our devices. However, by centralizing data storage on servers, cloud apps also take away ownership and agency from users. If a service shuts down, the software stops functioning, and data created with that software is lost.</p><p>In this article we propose <em>local-first</em> software, a set of principles for software that enables both collaboration <em>and</em> ownership for users. Local-first ideals include the ability to work offline and collaborate across multiple devices, while also improving the security, privacy, long-term preservation, and user control of data.</p><p>We survey existing approaches to data storage and sharing, ranging from email attachments to web apps to Firebase-backed mobile apps, and we examine the trade-offs of each. We look at Conflict-free Replicated Data Types (CRDTs): data structures that are multi-user from the ground up while also being fundamentally local and private. CRDTs have the potential to be a foundational technology for realizing local-first software.</p><p>We share some of our findings from developing local-first software prototypes at the Ink &amp; Switch research lab over the course of several years. These experiments test the viability of CRDTs in practice, and explore the user interface challenges for this new data model. Lastly, we suggest some next steps for moving towards local-first software: for researchers, for app developers, and a startup opportunity for entrepreneurs.</p><p>[Keywords: collaboration software, mobile computing, data ownership, CRDTs, peer-to-peer communication]</p>'
- - /docs/traffic/2017-sinha.pdf
  - "Anti-Ad Blocking Strategy: Measuring its True Impact"
  - Atanu R. Sinha, Meghanath Macha, Pranav Maneriker, Sopan Khosla, Avani Samdariya, Navjot Singh
  - 2017-08-14
  - '10.1145/3124749.3124756'
  - ! "The increasing use of ad blocking software poses a major threat for publishers in loss of online ad revenue, and for advertisers in the loss of audience. Major publishers have adopted various anti-ad blocking strategies such as denial of access to website content and asking users to subscribe to paid ad-free versions. However, publishers are unsure about the true impact of these strategies [2, 3]. We posit that the real problem lies in the measurement of effectiveness because the existing methods compare metrics after implementation of such strategies with that of metrics just before implementation, making them error prone due to sampling bias. The errors arise due to differences in group compositions across before and after periods, as well as differences in time-period selection for the before measurement. We propose a novel algorithmic method which modifies the difference-in-differences approach to address the sampling bias due to differences in time-period selection. Unlike difference-in-differences, we choose the time-period for comparison in an endogenous manner, as well as, exploit differences in ad blocking tendencies among visitors' arriving on the publisher's site to allow cluster specific choice of the control time-period. We evaluate the method on both synthetic data (which we make available) and proprietary real data from an online publisher and find good support."
- - https://onlinelibrary.wiley.com/doi/10.1111/desc.12925
  - "Predicting educational achievement from genomic measures and socioeconomic status"
  - Sophie von Stumm, Emily Smith-Woolley, Ziada Ayorech, Andrew McMillan, Kaili Rimfeld, Philip S. Dale, Robert Plomin
  - 2019-11-23
  - 10.1111/desc.12925
  - ! '<p>The two best predictors of children’s educational achievement available from birth are parents’ socioeconomic status (SES) and, recently, children’s inherited DNA differences that can be aggregated in genome-wide polygenic scores (GPS). Here, we chart for the first time the developmental interplay between these two predictors of educational achievement at ages 7, 11, 14 and 16 in a sample of almost 5,000 UK school children. We show that the prediction of educational achievement from both GPS and SES increases steadily throughout the school years. Using latent growth curve models, we find that GPS and SES not only predict educational achievement in the first grade but they also account for systematic changes in achievement across the school years. At the end of compulsory education at age 16, GPS and SES, respectively, predict 14% and 23% of the variance of educational achievement. Analyses of the extremes of GPS and SES highlight their influence and interplay: In children who have high GPS and come from high SES families, 77% go to university, whereas 21% of children with low GPS and from low SES backgrounds attend university. We find that the associations of GPS and SES with educational achievement are primarily additive, suggesting that their joint influence is particularly dramatic for children at the extreme ends of the distribution.</p><p>Research Highlights</p><ul><li>Genome-wide polygenic scores (GPS) and socioeconomic status (SES) account together for 27% of the variance in educational achievement from age 7 through 16 years</li><li>The predictive validity of GPS and SES increases over the course of compulsory schooling</li><li>The association of GPS and SES is primarily additive: their joint long-term influence is particularly pronounced in children at the extreme ends of the distribution</li><li>77% of children with high GPS from high SES families go to university compared to 21% of children with low GPS from low SES</li></ul>'
- - https://danluu.com/web-bloat/
  - Web Bloat
  - Dan Luu
  - 2017-02-08
  - ''
  - ! '<p>A couple years ago, I took a road trip from Wisconsin to Washington and mostly stayed in rural hotels on the way. I expected the internet in rural areas too sparse to have cable internet to be slow, but I was still surprised that a large fraction of the web was inaccessible. Some blogs with lightweight styling were readable, as were pages by academics who hadn’t updated the styling on their website since 1995. But very few commercial websites were usable (other than Google). When I measured my connection, I found that the bandwidth was roughly comparable to what I got with a 56k modem in the 90s. The latency and packet loss were significantly worse than the average day on dialup: latency varied between 500ms and 1000ms and packet loss varied between 1% and 10%. Those numbers are comparable to what I’d see on dialup on a bad day.</p><p>Despite my connection being only a bit worse than it was in the 90s, the vast majority of the web wouldn’t load…When Microsoft looked at actual measured connection speeds, they found that half of Americans don’t have broadband speed. Heck, AOL had 2 million dial-up subscribers in 2015, just AOL alone. Outside of the U.S., there are even more people with slow connections. I recently chatted with Ben Kuhn, who spends a fair amount of time in Africa, about his internet connection:</p><blockquote><p>I’ve seen ping latencies as bad as ~45 sec and packet loss as bad as 50% on a mobile hotspot in the evenings from Jijiga, Ethiopia. (I’m here now and currently I have 150ms ping with no packet loss but it’s 10am). There are some periods of the day where it ~never gets better than 10 sec and ~10% loss. The internet has gotten a lot better in the past ~year; it used to be that bad all the time except in the early mornings.</p></blockquote><p>…Let’s load some websites that programmers might frequent with a variety of simulated connections to get data on page load times…The timeout for tests was 6 minutes; anything slower than that is listed as <strong>FAIL</strong>. Pages that failed to load are also listed as <strong>FAIL</strong>. A few things that jump out from the table are:</p><ol type="1"><li>A large fraction of the web is unusable on a bad connection. Even on a good (0% packet loss, no ping spike) dialup connection, some sites won’t load…If you were to look at the 90%-ile results, you’d see that most pages fail to load on dialup and the “Bad” and “😱” connections are hopeless for almost all sites.</li><li>Some sites will use a lot of data!</li></ol><p>…The flaw in the “page weight doesn’t matter because average speed is fast” [claim] is that if you average the connection of someone in my apartment building (which is wired for 1Gbps internet) and someone on 56k dialup, you get an average speed of 500 Mbps. That doesn’t mean the person on dialup is actually going to be able to load a 5MB website. The average speed of 3.9 Mbps comes from a 2014 Akamai report, but it’s just an average. If you look at Akamai’s 2016 report, you can find entire countries where more than 90% of IP addresses are slower than that!..“Use bcrypt” has become the mantra for a reasonable default if you’re not sure what to do when storing passwords. The web would be a nicer place if “use webpagetest” caught on in the same way. It’s not always the best tool for the job, but it sure beats the current defaults.</p>'
- - http://www.stuartcheshire.org/rants/latency.html
  - "It's the Latency, Stupid"
  - Stuart Cheshire
  - '2001'
  - ''
  - ! '<p>[Seminal essay explaining why the rollout of “broadband” home connections to replace 56k dialups had not improved regular WWW browsing as much as people expected: while broadband had greater <em>throughput</em>, it had similar (or worse) <em>latency</em>.</p><p>Because much of the wallclock time of any Internet connection is spent setting up and negotiating with the other end, and not that much is spent on the raw transfer of large numbers of bytes, the speedup is far smaller than one would expect by dividing the respective bandwidths.</p><p>Further, while bandwidth/throughput is easy to improve by adding more or higher-quality connections and can be patched elsewhere in the system by adding parallelism or upgrading parts or investing in data compression, the latency-afflicted steps are stubbornly serial, any time lost is physically impossible to retrieve, and many steps are inherently limited by the speed of light—more capacious connections quickly run into <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s law</a>, where the difficult-to-improve serial latency-bound steps dominate the overall task. As Cheshire summarizes it:]</p><ol type="1"><li>Fact One: Making more bandwidth is easy.</li><li>Fact Two: Once you have bad latency you’re stuck with it.</li><li>Fact Three: Current consumer devices have appallingly bad latency.</li><li>Fact Four: Making limited bandwidth go further is easy.</li></ol><p>…That’s the problem with communications devices today. Manufacturers say “speed” when they mean “capacity”. The other problem is that as far as the end-user is concerned, the thing they want to do is transfer large files quicker. It may seem to make sense that a high-capacity slow link might be the best thing for the job. What the end-user doesn’t see is that in order to manage that file transfer, their computer is sending dozens of little control messages back and forth. The thing that makes computer communication different from television is interactivity, and interactivity depends on all those little back-and-forth messages.</p><p>The phrase “high-capacity slow link” that I used above probably looked very odd to you. Even to me it looks odd. We’ve been used to wrong thinking for so long that correct thinking looks odd now. How can a high-capacity link be a slow link? High-capacity means fast, right? It’s odd how that’s not true in other areas. If someone talks about a “high-capacity” oil tanker, do you immediately assume it’s a very fast ship? I doubt it. If someone talks about a “large-capacity” truck, do you immediately assume it’s faster than a small sports car?</p><p>We have to start making that distinction again in communications. When someone tells us that a modem has a speed of 28.8 kbit/sec we have to remember that 28.8 kbit/sec is its capacity, not its speed. Speed is a measure of distance divided by time, and ‘bits’ is not a measure of distance.</p><p>I don’t know how communications came to be this way. Everyone knows that when you buy a hard disk you should check what its seek time is. The maximum transfer rate is something you might also be concerned with, but the seek time is definitely more important. Why does no one think to ask what a modem’s ‘seek time’ is? The latency is exactly the same thing. It’s the minimum time between asking for a piece of data and getting it, just like the seek time of a disk, and it’s just as important.</p>'
- - https://blog.chriszacharias.com/page-weight-matters
  - Page Weight Matters
  - Chris Zacharias
  - 2012-12-21
  - ''
  - ! '<p>[Google engineer recounts the results of heavily optimizing YouTube to make it usable in slow Third World Countries: in an example of <a href="https://en.wikipedia.org/wiki/Jevons_paradox">Jevons Paradox</a> &amp; <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a>, he found that despite making YouTube better for all users, average page load time got <em>worse</em>—because now Africans were actually able to use it.]</p><p>When we plotted the data geographically and compared it to our total numbers broken out by region, there was a disproportionate increase in traffic from places like Southeast Asia, South America, Africa, and even remote regions of Siberia. Further investigation revealed that, in these places, the average page load time under [the optimized version] Feather was over <strong>2 minutes</strong>! This meant that a regular video page, at over a megabyte, was taking more than <strong>20 minutes</strong> to load! This was the penalty incurred before the video stream even had a chance to show the first frame. Correspondingly, entire populations of people simply could not use YouTube because it took too long to see anything. Under Feather, despite it taking over 2 minutes to get to the first frame of video, watching a video actually became a real possibility. Over the week, word of Feather had spread in these areas and our numbers were completely skewed as a result. Large numbers of people who were previously unable to use YouTube before were suddenly able to.</p><p>Through Feather, I learned a valuable lesson about the state of the Internet throughout the rest of the world. Many of us are fortunate to live in high bandwidth regions, but there are still large portions of the world that do not. By keeping your client side code small and lightweight, you can literally open your product up to new markets.</p>'
- - https://pavelfatin.com/typing-with-pleasure/
  - "Typing with pleasure"
  - Pavel Fatin
  - 2015-12-20
  - ''
  - ! '<p>In this article I examine human- and machine aspects of typing latency (“typing lag”) and present experimental data on latency of popular text / code editors. The article is inspired by my work on implementing <a href="https://blog.jetbrains.com/idea/2015/08/experimental-zero-latency-typing-in-intellij-idea-15-eap/">“zero-latency typing”</a> in IntelliJ IDEA.</p><ol type="1"><li><p>Human side</p><p>1.1. Feedback 1.2. Motor skill 1.3. Internal model 1.4. Multisensory integration 1.5. Effects</p></li><li><p>Machine side</p><p>2.1. Input latency 2.2. Processing latency 2.3. Output latency 2.4. Total latency</p></li><li><p>Editor benchmarks</p><p>3.1. Configuration 3.2. Methodology 3.3. Windows 3.4. Linux 3.5. VirtualBox</p></li><li><p>Summary</p></li><li><p>Links</p></li></ol><p>…To measure processing delays experimentally I created <a href="https://pavelfatin.com/typometer">Typometer</a>—a tool to determine and analyze visual latency of text editors (sources). Typometer works by generating OS input events and using screen capture to measure the delay between a keystroke and a corresponding screen update. Hence, the measurement encompasses all the constituents of processing latency (i. e. OS queue, VM, editor, GPU pipeline, buffering, window manager and possible V-Sync). That is the right thing to do, because all those components are inherently intertwined with the editor, and in principle, editor application has influence on all the parts. … [He tested 9] Editors: Atom 1.1 / Eclipse 4.5.1 / Emacs 24.5.1 / Gedit 3.10.4 / GVim 7.4.712 / IntelliJ Idea CE 15.0 / Netbeans 8.1 / Notepad++ 6.8.4 / Sublime Text 3083.</p><figure><img src="https://pavelfatin.com/images/typing/editor-latency-windows-text.png" alt="“Editor latency in MS Windows (text file) in milliseconds”" /><figcaption>“Editor latency in MS Windows (text file) in milliseconds”</figcaption></figure><p>Apparently, editors are not created equal (at least, from the standpoint of latency).</p>'
- - http://www.cap-lore.com/Hardware/Wheel.html
  - "The Wheel of Reincarnation"
  - Norman Hardy
  - ''
  - ''
  - ! '<p>Short technology essay based on <a href="http://cva.stanford.edu/classes/cs99s/papers/myer-sutherland-design-of-display-processors.pdf" title="On the Design of Display Processors">Myer &amp; Sutherland 1968</a> (!) discussing a perennial pattern in computing history dubbed the ‘Wheel of Reincarnation’ for how old approaches inevitably reincarnate as the exciting new thing: shifts between ‘local’ and ‘remote’ computing resources, which are exemplified by repeated cycles in graphical display technologies from dumb ‘terminals’ which display only raw pixels to smart devices which interpret more complicated inputs like text or vectors or programming languages (eg PostScript). These cycles are driven by cost, latency, architectural simplicity, and available computing power.</p><p>The Wheel of Reincarnation paradigm has played out for computers as well, in shifts from local terminals attached to mainframes to PCs to smartphones to ‘cloud computing’.</p>'
- - http://cva.stanford.edu/classes/cs99s/papers/myer-sutherland-design-of-display-processors.pdf
  - On the Design of Display Processors
  - T.H. Meyer, I.E. Sutherland
  - 1968-06
  - 10.1145/363347.363368
  - ! 'The flexibility and power needed in the channel for a computer display are considered. To work efficiently, such a channel must have a sufficient number of instruction that it is best understood as a small processor rather than a powerful channel. As it was found that successive improvements to the display processor design lie on a circular path, by making improvements one can return to the original simple design plus one new general purpose computer for each trip around. The degree of physical separation between display and parent computer is a key factor in display processor design. [Keywords: display processor design, display system, computer graphics, graphic terminal, displays, graphics, display generator, display channel, dFsplay programming, graphical interaction, remote displays, Wheel of Reincarnation]'
- - https://www.theatlantic.com/science/archive/2017/11/how-the-zombie-fungus-takes-over-ants-bodies-to-control-their-minds/545864/
  - "How the Zombie Fungus Takes Over Ants’ Bodies to Control Their Minds: The infamous parasite’s methods are more complex and more sinister than anyone suspected"
  - Ed Yong
  - 2017-11-14
  - ''
  - ! '<p>When the fungus infects a carpenter ant, it grows through the insect’s body, draining it of nutrients and hijacking its mind. Over the course of a week, it compels the ant to leave the safety of its nest and ascend a nearby plant stem. It stops the ant at a height of 25 centimeters—a zone with precisely the right temperature and humidity for the fungus to grow. It forces the ant to permanently lock its mandibles around a leaf. Eventually, it sends a long stalk through the ant’s head, growing into a bulbous capsule full of spores. And because the ant typically climbs a leaf that overhangs its colony’s foraging trails, the fungal spores rain down onto its sisters below, zombifying them in turn.</p><p>…It’s also an obsession of one David Hughes, an entomologist at Pennsylvania State University, who has been studying it for years. He wants to know exactly how this puppet master controls its puppets—and <a href="https://www.pnas.org/content/114/47/12590.full" title="&#39;Three-dimensional visualization and a deep-learning model reveal complex fungal parasite networks in behaviorally manipulated ants&#39;, Fredericksen et al 2017">his latest experiments</a> suggest that it’s even more ghoulish than it first appears.</p><p>…When the fungus first enters its host, it exists as single cells that float around the ant’s bloodstream, budding off new copies of themselves. But at some point, as Fredericksen’s images show, these single cells start working together. They connect to each other by building short tubes, of a kind that have only ever been seen before in fungi that infects plants. Hooked up in this way, they can communicate and exchange nutrients. They can also start invading the ant’s muscles, either by penetrating the muscle cells themselves or growing into the spaces between them. The result is what you can see in this video: a red muscle fiber, encircled and drained by a network of interconnected yellow fungal cells. This is something unique to Ophiocordyceps. Hughes’s team found that another parasitic fungus, which fatally infects ants but doesn’t manipulate their minds, also spreads into muscles but doesn’t form tubes between individual cells, and doesn’t wire itself into large networks.</p><p>Whenever Hughes or anyone else discusses the zombie-ant fungus, they always talk about it as a single entity, which corrupts and subverts a host. But you could also think of the fungus as a colony, much like the ants it targets. Individual microscopic cells begin life alone but eventually come to cooperate, fusing into a superorganism. Together, these brainless cells can commandeer the brain of a much larger creature. But surprisingly, they can do that without ever physically touching the brain itself. Hughes’s team found that fungal cells infiltrate the ant’s entire body, including its head, but they leave its brain untouched… “But manipulation of ants by <em>Ophiocordyceps</em> is so exquisitely precise that it is perhaps surprising that the fungus doesn’t invade the brain of its host,” Weinersmith says.</p>'
- - https://www.pnas.org/content/110/2/696.full
  - Eight pairs of descending visual neurons in the dragonfly give wing motor centers accurate population vector of prey direction
  - Paloma T. Gonzalez-Bellido, Hanchuan Peng, Jinzhu Yang, Apostolos P. Georgopoulos, Robert M. Olberg
  - 2013-01-08
  - 10.1073/pnas.1210489109
  - ! 'Intercepting a moving object requires prediction of its future location. This complex task has been solved by dragonflies, who intercept their prey in midair with a 95% success rate. In this study, we show that a group of 16 neurons, called target-selective descending neurons (TSDNs), code a population vector that reflects the direction of the target with high accuracy and reliability across 360°. The TSDN spatial (receptive field) and temporal (latency) properties matched the area of the retina where the prey is focused and the reaction time, respectively, during predatory flights. The directional tuning curves and morphological traits (3D tracings) for each TSDN type were consistent among animals, but spike rates were not. Our results emphasize that a successful neural circuit for target tracking and interception can be achieved with few neurons and that in dragonflies this information is relayed from the brain to the wing motor centers in population vector form. [Keywords: vision, invertebrate, predatory behavior, electrophysiology, confocal microscopy]'
- - http://paradise.caltech.edu/cook/papers/TwoNeurons.pdf
  - It Takes Two Neurons To Ride a Bicycle
  - Matthew Cook
  - '2004'
  - ''
  - ! 'Past attempts to get computers to ride bicycles have required an inordinate amount of learning time (1700 practice rides for a reinforcement learning approach [1], while still failing to be able to ride in a straight line), or have required an algebraic analysis of the exact equations of motion for the specific bicycle to be controlled [2, 3]. Mysteriously, humans do not need to do either of these when learning to ride a bicycle. Here we present a two-neuron network<sup>1</sup> that can ride a bicycle in a desired direction (for example, towards a desired goal or along a desired path), which may be chosen or changed at run time. Just as when a person rides a bicycle, the network is very accurate for long range goals, but in the short run stability issues dominate the behavior. This happens not by explicit design, but arises as a natural consequence of how the network controls the bicycle.'
- - /docs/genetics/selection/2019-delguidice.pdf
  - "Invisible Designers: Brain Evolution Through the Lens of Parasite Manipulation"
  - Marco Del Giudice
  - 2019-09
  - 10.1086/705038
  - ! 'The ability of parasites to manipulate host behavior to their advantage has been studied extensively, but the impact of parasite manipulation on the evolution of neural and endocrine mechanisms has remained virtually unexplored. If selection for countermeasures has shaped the evolution of nervous systems, many aspects of neural functioning are likely to remain poorly understood until parasites—the brain’s invisible designers—are included in the picture. This article offers the first systematic discussion of brain evolution in light of parasite manipulation. After reviewing the strategies and mechanisms employed by parasites, the paper presents a taxonomy of host countermeasures with four main categories, namely: restrict access to the brain; increase the costs of manipulation; increase the complexity of signals; and increase robustness. For each category, possible examples of countermeasures are explored, and the likely evolutionary responses by parasites are considered. The article then discusses the metabolic, computational, and ecological constraints that limit the evolution of countermeasures. The final sections offer suggestions for future research and consider some implications for basic neuroscience and psychopharmacology. The paper aims to present a novel perspective on brain evolution, chart a provisional way forward, and stimulate research across the relevant disciplines. [Keywords: behavior, brain evolution, hormones, neurobiology, parasite-host interactions, parasite manipulation.]'
- - https://www.scottaaronson.com/papers/pnp.pdf#page=5
  - "P≟NP"
  - Scott Aaronson
  - '2017'
  - '10.1007/978-3-319-32162-2_1'
  - ! 'In 1955, John Nash sent a remarkable letter to the National Security Agency, in which—seeking to build theoretical foundations for cryptography—he all but formulated what today we call the P≟NP problem, considered one of the great open problems of science. Here I survey the status of this problem in 2017, for a broad audience of mathematicians, scientists,and engineers. I offer a personal perspective on what it’s about, why it’s important, why it’s reasonable to conjecture that P≠NP is both true and provable, why proving it is so hard, the landscape of related problems, and crucially, what progress has been made in the last half-century toward solving those problems. The discussion of progress includes diagonalization and circuit lower bounds; the relativization, algebrization, and natural proofs barriers; and the recent works of Ryan Williams and Ketan Mulmuley, which (in different ways) hint at a duality between impossibility proofs and algorithms. [2017 revised version of 2016 paper.]'
- - https://scale.com/
  - "Scale: The Data Platform for AI; High quality training and validation data for AI applications"
  - Scale AI, Inc.
  - ''
  - ''
  - ! '<p>["Scale is an API for training data, providing access to human-powered data for a multitude of use cases located in San Francisco, California, United States; founded 2016-06-01. Scale accelerates the development of AI applications by helping computer vision teams generate high-quality ground truth data. Our advanced LiDAR, video, and image annotation APIs allow self-driving, drone, and robotics teams at companies like Waymo, OpenAI, Lyft, Zoox, Pinterest, and Airbnb focus on building differentiated models vs. labeling data."]</p> <p>["Scale has around 100 employees, according to Wang, but its limited full-time staff is a small fraction of the human-power behind the services Scale offers. The startup has nearly 30,000 contractors aiding in the labeling process. “The humans are pretty critical to what we’re doing because they’re there to make sure that all the data we provide is really high quality,” Wang says.</p><p>Companies provide Scale with data via their API and the startup puts its resources to work labeling the text, audio, pictures and video so that its customers’ machine learning models can be trained. The startup’s customers include Waymo, OpenAI, Airbnb and Lyft.</p><p>For a customer working with autonomous driving data, Scale’s services may mean taking collected video frames and manually segmenting out individual cars, humans or other obstacles. For another customer, it can mean making common sense language connections to ensure natural language processing models can understand language in context. The “human insight” can help minimize labeling bias and give customers data that is more precise and more accurate, though, as with just about all AI startups, the hope is that these insights will gradually usher in a future where reliance on these humans-in-the-loop will be lessened. In the meantime, Scale sits atop an army of contractors that might hold the key to bulking up Silicon Valley’s machine learning intelligence."]</p>'
- - https://openai.com/blog/fine-tuning-gpt-2/
  - "Fine-Tuning GPT-2 from Human Preferences"
  - Daniel Ziegler, Nisan Stiennon, Jeffrey Wu, Tom Brown, Dario Amodei, Alec Radford, Paul Christiano, Geoffrey Irving (OpenAI)
  - 2019-09-19
  - ''
  - ! '<p>We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of “machines talking to humans,” which we believe is key to extracting information about human values.</p><p>This work applies human preference learning to several natural language tasks: continuing text with positive sentiment or physically descriptive language using the BookCorpus, and summarizing content from the TL;DR and CNN/Daily Mail datasets. Each of these tasks can be viewed as a text completion problem: starting with some text X, we ask what text Y should follow. [For summarization, the text is the article plus the string “TL;DR:”.]</p><p>We start with a pretrained language model (the 774M parameter version of GPT-2) and fine-tune the model by asking human labelers which of four samples is best. Fine-tuning for the stylistic continuation tasks is sample efficient: 5,000 human samples suffice for strong performance according to humans. For summarization, models trained with 60,000 comparisons learn to copy whole sentences from the input while skipping irrelevant preamble; this copying is an easy way to ensure accurate summaries, but may exploit the fact that labelers rely on simple heuristics.</p><p><em>Bugs can optimize for bad behavior</em></p><p>One of our code refactors introduced a bug which flipped the sign of the reward. Flipping the reward would usually produce incoherent text, but the same bug also flipped the sign of the KL penalty. The result was a model which optimized for negative sentiment while preserving natural language. Since our instructions told humans to give very low ratings to continuations with sexually explicit text, the model quickly learned to output only content of this form. This bug was remarkable since the result was not gibberish but maximally bad output. The authors were asleep during the training process, so the problem was noticed only once training had finished. A mechanism such as Toyota’s Andon cord could have prevented this, by allowing any labeler to stop a problematic training process.</p><p><strong>Looking forward</strong></p><p>We’ve demonstrated reward learning from human preferences on two kinds of natural language tasks, stylistic continuation and summarization. Our results are mixed: for continuation we achieve good results with very few samples, but our summarization models are only “smart copiers”: they copy from the input text but skip over irrelevant preamble. The advantage of smart copying is truthfulness: the zero-shot and supervised models produce natural, plausible-looking summaries that are often lies. We believe the limiting factor in our experiments is data quality exacerbated by the online data collection setting, and plan to use batched data collection in the future.</p><p>We believe the application of reward learning to language is important both from a capability and safety perspective. On the capability side, reinforcement learning lets us correct mistakes that supervised learning would not catch, but RL with programmatic reward functions “can be detrimental to model quality.” On the safety side, reward learning for language allows important criteria like “don’t lie” to be represented during training, and is a step towards scalable safety methods such as a debate and amplification.</p>'
- - https://openai.com/blog/deep-reinforcement-learning-from-human-preferences/
  - Learning from Human Preferences
  - Dario Amodei, Paul Christiano, Alex Ray (OpenAI)
  - 2017-06-13
  - ''
  - ! '<p>One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.</p><p>We present a learning algorithm that uses small amounts of human feedback to solve modern RL environments. Machine learning systems with human feedback have been explored before, but we’ve scaled up the approach to be able to work on much more complicated tasks. Our algorithm needed 900 bits of feedback from a human evaluator to learn to backflip—a seemingly simple task which is simple to judge but challenging to specify.</p><p>The overall training process is a 3-step feedback cycle between the human, the agent’s understanding of the goal, and the RL training.</p><figure><img src="https://openai.com/content/images/2017/06/diagram@2x-2.png" alt="Preference learning architecture" /><figcaption>Preference learning architecture</figcaption></figure><p>Our AI agent starts by acting randomly in the environment. Periodically, two video clips of its behavior are given to a human, and the human decides which of the two clips is closest to fulfilling its goal—in this case, a backflip. The AI gradually builds a model of the goal of the task by finding the reward function that best explains the human’s judgments. It then uses RL to learn how to achieve that goal. As its behavior improves, it continues to ask for human feedback on trajectory pairs where it’s most uncertain about which is better, and further refines its understanding of the goal.</p>'
- - https://deepmind.com/blog/article/learning-through-human-feedback
  - Learning through human feedback
  - Jan Leike, Miljan Martic, Shane Legg (DeepMind)
  - 2017-06-12
  - ''
  - ! '<p>The system—described in our paper “Deep Reinforcement Learning from Human Preferences”—departs from classic RL systems by training the agent from a neural network known as the ‘reward predictor’, rather than rewards it collects as it explores an environment.</p><p>It consists of three processes running in parallel:</p><ol type="1"><li>A reinforcement learning agent explores and interacts with its environment, such as an Atari game.</li><li>Periodically, a pair of 1–2 second clips of its behaviour is sent to a human operator, who is asked to select which one best shows steps towards fulfilling the desired goal.</li><li>The human’s choice is used to train a reward predictor, which in turn trains the agent. Over time, the agent learns to maximise the reward from the predictor and improve its behaviour in line with the human’s preferences.</li></ol><p>The system separates learning the goal from learning the behaviour to achieve it</p><p>This iterative approach to learning means that a human can spot and correct any undesired behaviours, a crucial part of any safety system. The design also does not put an onerous burden on the human operator, who only has to review around 0.1% of the agent’s behaviour to get it to do what they want. However, this can mean reviewing several hundred to several thousand pairs of clips, something that will need to be reduced to make it applicable to real world problems.</p>'
- - /Tea#water-experiment
  - "Tea/Water Experiment: Blinded Randomized Racing-Arms Experiment of Mineral Water Taste"
  - Gwern Branwen
  - 2017-04-04
  - ''
  - ! '<p>The kind of water used in tea is claimed to make a difference in the flavor: mineral water being better than tap water or distilled water. However, mineral water is vastly more expensive than tap water. To test the claim, I run a preliminary test of pure water to see if any water differences are detectable at all. Compared my tap water, 3 distilled water brands (Great Value, Nestle Pure Life, &amp; Poland Spring), 1 osmosis-purified brand (Aquafina), and 3 non-carbonated mineral water brands (Evian, Voss, &amp; Fiji) in a series of <em>n</em>=67 blinded randomized comparisons of water flavor. The comparisons are modeled using a Bradley-Terry competitive model implemented in Stan; comparisons were chosen using an adaptive Bayesian best-arm sequential trial (racing) method designed to locate the best-tasting water in the minimum number of samples by preferentially comparing the best-known arm to potentially superior arms. Blinding &amp; randomization are achieved by using a Lazy Susan to physically randomize two identical (but marked in a hidden spot) cups of water. The final posterior distribution indicates that some differences between waters are likely to exist but are small &amp; imprecisely estimated and of little practical concern.</p>'
- - /GPT-2-music#spaceless-model
  - "GPT-2 Folk Music: Training a Spaceless Model"
  - Gwern Branwen
  - 2019-12-12
  - ''
  - ! 'While training a GPT-2-117M on a folk music corpus written in ABC format, persistent syntax errors kept being generated by an otherwise-high-quality model: random spaces would be generated, rendering a music piece either erroneous or lower-quality. Why? It seems to be some issue with the GPT BPE encoder handling of spaces which makes it difficult to emit the right space-separated characters. We found that ABC does not actually require spaces, and we simply removed all spaces from the corpus—noticeably improving quality of generated pieces.'
- - /Faces#discriminator-ranking
  - "Generating Anime Faces with StyleGAN: Using a trained Discriminator to Rank and Clean Data"
  - Gwern Branwen
  - 2019-04-22
  - ''
  - ! 'The Discriminator of a GAN is trained to detect outliers or bad datapoints. So it can be used for cleaning the original dataset of aberrant samples. This works reasonably well and I obtained BigGAN/StyleGAN quality improvements by manually deleting the worst samples (typically badly-cropped or low-quality faces), but has peculiar behavior which indicates that the Discriminator is not learning anything equivalent to a "quality" score but may be doing some form of <em>memorization</em> of specific real datapoints. What does this mean for how GANs work?'
- - 'lm-human-preferences GitHub repo'
  - OpenAI
  - 2019-09-14
  - ''
  - ''
  - ! '<p><strong>Status:</strong> Archive (code is provided as-is, no updates expected)</p><h1 id="lm-human-preferences">lm-human-preferences</h1><p>This repository contains code for the paper <a href="https://arxiv.org/abs/1909.08593">Fine-Tuning Language Models from Human Preferences</a>. See also our <a href="https://openai.com/blog/fine-tuning-gpt-2/">blog post</a>.</p><p>We provide code for:</p><ul><li>Training reward models from human labels</li><li>Fine-tuning language models using those reward models</li></ul><p>It does not contain code for generating labels. However, we have released human labels collected for our experiments, at <code>gs://lm-human-preferences/labels</code>. For those interested, the question and label schemas are simple and documented in <a href="https://github.com/openai/lm-human-preferences/blob/master/lm_human_preferences/label_types.py"><code>label_types.py</code></a>.</p><p>The code has only been tested using the smallest GPT-2 model (124M parameters).</p>'
- - https://www.ism.ac.jp/editsec/aism/pdf/011_3_0195.pdf
  - "Bivariate Extreme Statistics, I"
  - Masaaki Sibuya
  - '1960'
  - '10.1007/BF01682329'
  - ! '<p>The largest and the smallest value in a sample, and other statistics related to them are generally named extreme statistics. Their sampling distributions, especially the limit distributions, have been studied by many authors, and principal results are summarized in the recent Gumbel book.</p><p>The author extends here the notion of extreme statistics into bivariate distributions and considers the joint distributions of maxima of components in sample vectors. This Part I treats asymptotic properties of the joint distributions.</p><p>In the univariate case the limit distributions of the sample maximum were limited to only three types. In the bivariate case, however, types of the limit joint distribution are various: Theorem 5 in Chapter 2 shows that infinitely many types of limit distributions may exist. For a wide class of distributions, two maxima are asymptotically independent or degenerate on a curve. Theorems 2 and 4 give the attraction domains for such limits. In bivariate normal case, two maxima are asymptotically independent unless the correlation coefficient is equal to one.</p><p>Throughout these arguments we remark only the dependence between marginal distributions, whose behaviors are well established. For this purpose a fundamental notion of ‘dependence function’ is introduced and discussed in Section 1.</p>'
- - /docs/statistics/order/1967-srivastava.pdf
  - "Asymptotic Independence of Certain Statistics Connected with the Extreme Order Statistics in a Bivariate Distribution"
  - "O. P. Srivastava"
  - "1967-06"
  - "10.2307/25049462"
  - ! 'The exact distribution of extremes in a sample and its limiting forms are well known in the univariate case. The limiting form for the largest observation in a sample was derived by Fisher and Tippet (1928) as early as 1927 by a functional equation, and that for the smallest was studied by Smirnov (1952). Though the joint distribution of two extremes has not been fully studied yet Sibuya (1960) gave a necessary and sufficient condition for the asymptotic independence of two largest extremes in a bivariate distribution. In this paper a necessary and sufficient condition for the asymptotic independence of two smallest observations in a bivariate sample has been derived, and the result has been used to find the condition for the asymptotic independence of any pair of extreme order statistics, one in each component of the bivariate sample. This result is further extended to find the condition for asymptotic independence of the pair of distances between two order statistics, arising from each component.'
- - /docs/statistics/order/1964-mardia.pdf
  - Asymptotic Independence of Bivariate Extremes
  - K. V. Mardia
  - 1964-11-01
  - 10.1177/0008068319640305
  - ! '<p>Sibuya (1960) has given a necessary and sufficient condition for asymptotic independence of two extremes for a sample from bivariate population. We shall obtain such a condition for asymptotic independence of all the four extremes <em>X</em>, <em>X’</em>, <em>Y</em> and <em>Y’</em>. It assumes a very simple form when <em>f(x,y)</em> is symmetrical in <em>x</em> and <em>y</em>, and the marginal p. d. f. of <em>x</em> and <em>y</em> have the same form. Under these conditions on the p. d. f., a modification is possible in the condition given by Sibuya (1960) which reduces to one given by Watson (1954) for other purpose. It is further shown that extremes for samples from bivariate normal population satisfy our condition if <em>|p|</em> &lt; 1, where <em>p</em> is the population correlation coefficient. Geffroy (1958) and Sibuya (1960} have proved a particular result for asymptotic independence of only two extremes <em>X</em> and <em>Y</em> in the normal case.</p>'
- - https://gantdaily.com/2019/12/11/former-area-physician-charged-with-forging-prescriptions-sent-to-ard/
  - "Former Area Physician Charged with Forging Prescriptions Sent to ARD"
  -  Julie Rae Rickard (GANT Daily)
  - 2019-12-11
  - ''
  - ! '<p>A former area physician charged with forging prescriptions was placed into a special program Monday. John Sylvester O’Shea, 69, of Washington, D.C. was charged by the attorney general’s office with procuring for self/other drug by fraud, identity theft and forgery, all misdemeanors, in July after a tip from a DuBois pharmacist led to an investigation into his prescriptions. According to the affidavit of probable cause, O’Shea was receiving prescriptions for Modafinil and Armodafinil from doctors in DuBois, Washington, D.C., and Raleigh, N.C., as well as others.</p><p>…In his interview with police, O’Shea explained he was taking the drugs because of his shift work. He stated he knew the maximum dosage for the drugs was 200 mg for the Modafinil and 250 mg for the Armodafinil per day. O’Shea admitted he was taking approximately 800 mg per day or three to four pills per shift since he had built up a tolerance to the drugs. He reportedly admitted he was “doctor shopping” and the other doctors did not know about his other prescriptions. He said his need for the drug “got out of hand.”</p><p>On Monday President Judge Fredric J. Ammerman placed O’Shea into the accelerated rehabilitative disposition program, which is for first-time offenders. He must serve two years ARD probation and was ordered to complete drug and alcohol counseling. He will not be able to prescribe any drugs for this time period and he is not to be practicing medicine for one year. O’Shea’s attorney noted that O’Shea’s medical license has been suspended and he is on a drug monitoring program already in his home area.</p>'
- - 'https://www.cell.com/cell-reports/fulltext/S2211-1247(19)31571-2'
  - Functional Oocytes Derived from Granulosa Cells
  - Chenglei Tian, Linlin Liu, Xiaoying Ye, Haifeng Fu, Xiaoyan Sheng, Lingling Wang, Huasong Wang, Dai Heng, Lin Liu
  - 2019-12-24
  - 10.1016/j.celrep.2019.11.080
  - ! '<ul><li>Granulosa cells can be reprogrammed to form oocytes by chemical reprogramming</li><li>Rock inhibition and crotonic acid facilitate the chemical induction of gPSCs from GCs</li><li>PGCLCs derived from gPSCs exhibit longer telomeres and high genomic stability</li></ul><p>The generation of genomically stable and functional oocytes has great potential for preserving fertility and restoring ovarian function. It remains elusive whether functional oocytes can be generated from adult female somatic cells through reprogramming to germline-competent pluripotent stem cells (gPSCs) by chemical treatment alone. Here, we show that somatic granulosa cells isolated from adult mouse ovaries can be robustly induced to generate gPSCs by a purely chemical approach, with additional Rock inhibition and critical reprogramming facilitated by crotonic sodium or acid. These gPSCs acquired high germline competency and could consistently be directed to differentiate into primordial-germ-cell-like cells and form functional oocytes that produce fertile mice. Moreover, gPSCs promoted by crotonylation and the derived germ cells exhibited longer telomeres and high genomic stability like PGCs in vivo, providing additional evidence supporting the safety and effectiveness of chemical induction, which is particularly important for germ cells in genetic inheritance. [Keywords: chemical reprogramming, pluripotent stem cell, oocyte, granulosa cell]</p>'
- - https://phys.org/news/2019-12-mouse-pups-born-eggs-derived.html
  - Mouse pups born from eggs derived from the granulosa cells that surround oocytes
  - Cell Press
  - 2019-12-24
  - ''
  - ! '<p>Ovarian follicles are the basic functional unit of the ovary and consist of an oocyte, the immature egg, which is surrounded by granulosa cells. Besides being crucial to the development of follicles, studies have shown that granulosa cells possess plasticity that shows stem cell-like properties.</p><p>“The thing about in vitro fertilization is that they only use the oocyte for the procedure,” says senior author Lin Liu, of the College of Life Sciences at Nankai University. “After the egg retrieval, the granulosa cells in the follicle are discarded. It got us thinking, what if we can utilize these granulosa cells? Since every egg has thousands of granulosa cells surrounding it, if we can induce them into pluripotent cells and turn those cells into oocytes, aren’t we killing two birds with one stone?”</p><p>Granulosa cells tend to undergo cell death and differentiation once removed from the follicles. Liu and his team including Ph.D. students Chenglei Tian and Haifeng Fu developed a chemical “cocktail” with Rock inhibitor and crotonic acid for creating chemically induced pluripotent stem cells (CiPSCs) from granulosa cells. The research team introduced Rock inhibitor to prevent cell death and promote proliferation. In combination with other important small chemicals, crotonic acid facilitates the induction of granulosa cells into germline-competent pluripotent stem cells that exhibit pluripotency similar to embryonic stem cells.</p>'
- - http://web.maths.unsw.edu.au/~jim/wrongthoughts.html
  - "What is Wrong with Our Thoughts? A Neo-Positivist Credo [ch7, <em>The Plato Cult and Other Philosophical Follies</em>]"
  - '<a href="https://en.wikipedia.org/wiki/David_Stove">David Stove</a>'
  - '1991'
  - ''
  - ! '[Fierce but witty critique of philosophy throughout the ages and defense of Logical Positivism, with Christian theology, Neoplatonism, and German Idealism as examples. Logical Positivists took the easy way out: the problem with these philosophies is not that they are gibberish or meaningless, because at least then they would all be wrong in the same way and could perhaps be refuted in the same way, but that they each are wrong in a myriad of different ways, ways for which we have no existing "fallacy" defined, entire universes of new errors---undermining the hope of using reason or philosophy to make any kind of progress. What is wrong with philosophy, and ourselves, if we cannot even explain why these are so badly wrong after millennia of thought and debate?]'
- - /docs/statistics/bias/2019-kvarven.pdf
  - "Comparing meta-analyses and preregistered multiple-laboratory replication projects"
  - Amanda Kvarven, Eirik Strømland, Magnus Johannesson
  - 2019-12-23
  - 10.1038/s41562-019-0787-z
  - ! 'Many researchers rely on meta-analysis to summarize research evidence. However, there is a concern that publication bias and selective reporting may lead to biased meta-analytic effect sizes. We compare the results of meta-analyses to large-scale preregistered replications in psychology carried out at multiple laboratories. The multiple-laboratory replications provide precisely estimated effect sizes that do not suffer from publication bias or selective reporting. We searched the literature and identified 15 meta-analyses on the same topics as multiple-laboratory replications. We find that meta-analytic effect sizes are significantly different from replication effect sizes for 12 out of the 15 meta-replication pairs. These differences are systematic and, on average, meta-analytic effect sizes are almost 3 times as large as replication effect sizes. We also implement 3 methods of correcting meta-analysis for bias, but these methods do not substantively improve the meta-analytic results.'
- - http://buttersafe.com/2012/05/24/the-floppy-toast/
  - "The Floppy Toast"
  - Buttersafe
  - 2012-04-24
  - ''
  - ! '<p><strong>The Floppy Toast</strong></p><p>The morning started off the way that every morning did<br />A small meal and cup of joe to perk up drooping lids.<br /><br />But when it came to making toast,<br />Today was not a copy.<br />Even after it emerged,<br />The toast was hella floppy.<br /><br />He tried and tried to make the toast<br />Become what it should be,<br />Yet every time the timer stopped<br />It popped up floppily.<br /><br />He simply couldn’t understand this strange phenomenon,<br />And so he tried to get some facts by calling up his mom.<br /><br />“That’s stupid weird,” his mother offered, somewhat groggily.<br />“But you’re a grown up dude. Why don’t you solve this without me?”<br /><br />So he decided he would take<br />His toast into the doctor,<br />Who hopefully would find a way<br />To make it much less softer.<br /><br />“Though floppy human body parts<br />Can be firmed up with pills,<br />Alas your loaf’s not stricken with<br />Those special types of ills.”<br /><br />“It seems your toast must have been cursed,<br />By magics dark and bleak,<br />And so a magic answer to your problems<br />You must seek.”<br /><br />“Mt. Crazy-Hot is home to dangers<br />Quite antagonistic,<br />But at the summit lives a very helpful<br />Wise old mystic.”<br /><br />What choice had he except to scale this ancient no man’s land?<br />His breakfast problems had already gotten out of hand.<br /><br />He tucked away his floppy toast,<br />And started on his way.<br />His muscles burned first from the climb,<br />And then burned from the flames.<br /><br />With every step the fires licked<br />His body up and down<br />Which frankly did not nearly feel<br />As sexy as it sounds.<br /><br />And then from the inferno rose a creature of the deep<br />Who did not seem too happy to be woken from its sleep.<br /><br />Long time the manxome foe he pondered, brewing strategy<br />Until the monster chose to force his hand more rapidly.<br /><br />An incendiary breath is<br />Quite the motivator,<br />To run like hell and save your clever<br />Plans for some point later.<br /><br />And so he ran and ran and ran<br />And ran and ran and ran<br />And ran and ran and ran and ran<br />Then ran into a man.<br /><br />“You must be the mystic with the culinary talents!<br />You’ve got to help me sir! My morning toast hangs in the balance!”<br /><br />“No matter how I tried,<br />Its floppiness was unimpeded.<br />Were my methods lacking something<br />That was absolutely needed?”<br /><br />“Though I am wise, perhaps the one with answers here is you.<br />Look upon your meal again, you may see something new.”<br /><br />And lo, he did produce it<br />For his enigmatic host<br />But no longer was it floppy!<br />’Twas the perfect piece of toast!<br /><br />The oils he secreted from his skin<br />Amidst the climb<br />Had soaked into the slice<br />As if a butter most divine!<br /><br />And after in that butter<br />It had practically been drowned<br />The scorching flames transformed it<br />To a crispy, golden brown!<br /><br />“Perfection comes through hardship,<br />A truth hidden from my eyes.<br />This cursed toast revealed it.<br />’Twas a blessing in disguise!<br /><br />Despite the difficulties,<br />Through my journey I stayed strong.<br />It seems that the perfect toast<br />Was inside me all along!”<br /><br />“I’m glad this less has awakened<br />Wisdom from within.<br />And next time you can simply think<br />To plug the toaster in.”</p>'
- - https://blog.aboutamazon.com/company-news/2016-letter-to-shareholders
  - "2016 Letter to Shareholders"
  - Jeff Bezos (Amazon)
  - 2017-04-17
  - ''
  - ! '<p>“Jeff, what does Day 2 look like?” That’s a question I just got at our most recent all-hands meeting. I’ve been reminding people that it’s Day 1 for a couple of decades. I work in an Amazon building named Day 1, and when I moved buildings, I took the name with me. I spend time thinking about this topic. “Day 2 is stasis. Followed by irrelevance. Followed by excruciating, painful decline. Followed by death. And <em>that</em> is why it is <em>always</em> Day 1.”</p><p>To be sure, this kind of decline would happen in extreme slow motion. An established company might harvest Day 2 for decades, but the final result would still come. I’m interested in the question, how do you fend off Day 2? What are the techniques and tactics? How do you keep the vitality of Day 1, even inside a large organization?</p><ol type="1"><li><p>True Customer Obsession …</p></li><li><p>Resist Proxies …</p></li><li><p>Embrace External Trends …</p></li><li><p>High-Velocity Decision Making</p><ol type="1"><li><p>…First, never use a one-size-fits-all decision-making process. Many decisions are reversible, two-way doors. Those decisions can use a light-weight process. For those, so what if you’re wrong? I wrote about this in more detail in last year’s letter.</p></li><li><p>Second, most decisions should probably be made with somewhere around 70% of the information you wish you had. If you wait for 90%, in most cases, you’re probably being slow. Plus, either way, you need to be good at quickly recognizing and correcting bad decisions. If you’re good at course correcting, being wrong may be less costly than you think, whereas being slow is going to be expensive for sure.</p></li><li><p>Third, use the phrase “disagree and commit.” This phrase will save a lot of time. If you have conviction on a particular direction even though there’s no consensus, it’s helpful to say, “Look, I know we disagree on this but will you gamble with me on it? Disagree and commit?” By the time you’re at this point, no one can know the answer for sure, and you’ll probably get a quick yes.</p><p>This isn’t one way. If you’re the boss, you should do this too. I disagree and commit all the time. We recently greenlit a particular Amazon Studios original. I told the team my view: debatable whether it would be interesting enough, complicated to produce, the business terms aren’t that good, and we have lots of other opportunities. They had a completely different opinion and wanted to go ahead. I wrote back right away with “I disagree and commit and hope it becomes the most watched thing we’ve ever made.” Consider how much slower this decision cycle would have been if the team had actually had to <em>convince</em> me rather than simply get my commitment.</p><p>Note what this example is not: it’s not me thinking to myself “well, these guys are wrong and missing the point, but this isn’t worth me chasing.” It’s a genuine disagreement of opinion, a candid expression of my view, a chance for the team to weigh my view, and a quick, sincere commitment to go their way. And given that this team has already brought home 11 Emmys, 6 Golden Globes, and 3 Oscars, I’m just glad they let me in the room at all!</p></li></ol></li></ol>'
- - /docs/statistics/2014-copss-pastpresentfuturestatistics.pdf
  - Past, Present, and Future of Statistical Science
  - Xihong Lin, Christian Genest, David L. Banks, Geert Molenberghs, David W. Scott, Jane-Ling Wang
  - 2014-03-26
  - 10.1201/b16720
  - ! '<p><em>Past, Present, and Future of Statistical Science</em> was commissioned in 2013 by the Committee of Presidents of Statistical Societies (COPSS) to celebrate its 50th anniversary and the International Year of Statistics. COPSS consists of five charter member statistical societies in North America and is best known for sponsoring prestigious awards in statistics, such as the COPSS Presidents’ award. Through the contributions of a distinguished group of 50 statisticians who are past winners of at least one of the five awards sponsored by COPSS, this volume showcases the breadth and vibrancy of statistics, describes current challenges and new opportunities, highlights the exciting future of statistical science, and provides guidance to future generations of statisticians. The book is not only about statistics and science but also about people and their passion for discovery. Distinguished authors present expository articles on a broad spectrum of topics in statistical education, research, and applications. Topics covered include reminiscences and personal reflections on statistical careers, perspectives on the field and profession, thoughts on the discipline and the future of statistical science, and advice for young statisticians. Many of the articles are accessible not only to professional statisticians and graduate students but also to undergraduate students interested in pursuing statistics as a career and to all those who use statistics in solving real-world problems. A consistent theme of all the articles is the passion for statistics enthusiastically shared by the authors. Their success stories inspire, give a sense of statistics as a discipline, and provide a taste of the exhilaration of discovery, success, and professional accomplishment.</p><blockquote><p>“This collection of reminiscences, musings on the state of the art, and advice for young statisticians makes for compelling reading. There are 52 contributions from eminent statisticians who have won a Committee of Presidents of Statistical Societies award. Each is a short, focused chapter and so one could even say this is ideal bedtime (or coffee break) reading. Anyone interested in the history of statistics will know that much has been written about the early days but little about the field since the Second World War. This book goes some way to redress this and is all the more valuable for coming from the horse’s mouth…the closing chapter, the shortest of all, from Brad Efron: a list of”thirteen rules for giving a really bad talk“. This made me laugh out loud and should be posted on the walls of all conferences. I shall leave the final word to Peter Bickel:”We should glory in this time when statistical thinking pervades almost every field of endeavor. It is really a lot of fun."</p><p>―Robert Grant, in <em>Significance</em>, April 2017</p></blockquote><p><strong>The History of COPSS</strong>: “A brief history of the Committee of Presidents of Statistical Societies (COPSS)”, Ingram Olkin</p><p><strong>Reminiscences and Personal Reflections on Career Paths</strong></p><p>“Reminiscences of the Columbia University Department of Mathematical Statistics in the late 1940s”, Ingram Olkin¶“A career in statistics”, Herman Chernoff¶“. . . how wonderful the field of statistics is . . .”, David R. Brillinger¶“An unorthodox journey to statistics: Equity issues, remarks on multiplicity”, Juliet Popper Shaffer¶“Statistics before and after my COPSS Prize”, Peter J. Bickel¶“The accidental biostatistics professor”, Donna Brogan¶“Developing a passion for statistics”, Bruce G. Lindsay¶“Reflections on a statistical career and their implications”, R. Dennis Cook¶“Science mixes it up with statistics”, Kathryn Roeder¶“Lessons from a twisted career path”, Jeffrey S. Rosenthal¶“Promoting equity”, Mary Gray</p><p><strong>Perspectives on the Field and Profession</strong></p><p>“Statistics in service to the nation”, Stephen E. Fienberg¶“Where are the majors?”, Iain M. Johnstone¶“We live in exciting times”, Peter Hall¶“The bright future of applied statistics”, Rafael A. Irizarry¶“The road travelled: From a statistician to a statistical scientist”, Nilanjan Chatterjee¶“Reflections on a journey into statistical genetics and genomics”, Xihong Lin¶“Reflections on women in statistics in Canada”, Mary E. Thompson¶“The whole women thing”, Nancy Reid¶“Reflections on diversity”, Louise Ryan</p><p><strong>Reflections on the Discipline</strong></p><p>“Why does statistics have two theories?”, Donald A.S. Fraser¶“Conditioning is the issue”, James O. Berger¶“Statistical inference from a Dempster–Shafer perspective”, Arthur P. Dempster¶“Nonparametric Bayes”, David B. Dunson¶“How do we choose our default methods?”, Andrew Gelman¶“Serial correlation and Durbin–Watson bounds”, T.W. Anderson¶“A non-asymptotic walk in probability and statistics”, Pascal Massart¶“The past’s future is now: What will the present’s future bring?”, Lynne Billard¶“Lessons in biostatistics”, Norman E. Breslow¶“A vignette of discovery”, Nancy Flournoy¶“Statistics and public health research”, Ross L. Prentice¶“Statistics in a new era for finance and health care”, Tze Leung Lai¶“Meta-analyses: Heterogeneity can be a good thing”, Nan M. Laird¶“Good health: Statistical challenges in personalizing disease prevention”, Alice S. Whittemore¶“Buried treasures”, Michael A. Newton¶“Survey sampling: Past controversies, current orthodoxy, future paradigms”, Roderick J.A. Little¶“Environmental informatics: Uncertainty quantification in the environmental sciences”, Noel A. Cressie¶“A journey with statistical genetics”, Elizabeth Thompson¶“Targeted learning: From MLE to TMLE”, Mark van der Laan¶“Statistical model building, machine learning, and the ah-ha moment”, Grace Wahba¶“In praise of sparsity and convexity”, Robert J. Tibshirani¶“Features of Big Data and sparsest solution in high confidence set”, Jianqing Fan¶“Rise of the machines”, Larry A. Wasserman¶“A trio of inference problems that could win you a Nobel Prize in statistics (if you help fund it)”, Xiao-Li Meng</p><p><strong>Advice for the Next Generation</strong></p><p>“Inspiration, aspiration, ambition”, C.F. Jeff Wu¶“Personal reflections on the COPSS Presidents’ Award”, Raymond J. Carroll¶“Publishing without perishing and other career advice”, Marie Davidian¶“Converting rejections into positive stimuli”, Donald B. Rubin¶“The importance of mentors”, Donald B. Rubin¶“Never ask for or give advice, make mistakes, accept mediocrity, enthuse”, Terry Speed¶“Thirteen rules”, Bradley Efron</p>'
- - https://www.discovermagazine.com/planet-earth/freedom-from-fungus-why-dont-humans-have-chestnut-style-blights-and-white-nose-style-syndromes
  - "Freedom From Fungus: Why Don't Humans Have Chestnut-Style Blights and White Nose-Style Syndromes?"
  - Sarah Zhang (Discover)
  - 2012-05-16
  - ''
  - ! '[Fungi are some of the most common organisms around, prolific, hardy, and fungal infections are major causes of infection-related mortality in plants and reptiles and can infect and kill almost anything, but <em>mammals</em> usually die of bacteria/viruses/parasites. Dying of a fungus is rare, and we hardly even get fungal infections except in odd places like our extremities (eg toes), or odd times of life like when bats hibernate. Why? Perhaps because we are warm-blooded, so our body heat is fatal to fungi. This explains why extremities or hibernating bats are vulnerable (colder). And perhaps this even played a role in the extinction of the dinosaurs and triumph of mammals?]'
- - https://www.bellingcat.com/resources/how-tos/2019/12/26/guide-to-using-reverse-image-search-for-investigations/
  - "Guide To Using Reverse Image Search For Investigations"
  - Aric Toller (Bellingcat)
  - 2019-12-26
  - ''
  - ! '<p>…if you only use Google for reverse image searching, you will be disappointed more often than not. Limiting your search process to uploading a photograph in its original form to just images.google.com may give you useful results for the most obviously stolen or popular images, but for most any sophisticated research project, you need additional sites at your disposal—along with a lot of creativity.</p><p>This guide will walk through detailed strategies to use reverse image search in digital investigations, with an eye towards identifying people and locations, along with determining an image’s progeny. After detailing the core differences between the search engines, Yandex, Bing, and Google are tested on five test images showing different objects and from various regions of the world.</p><p>…Reverse image search engines have progressed dramatically over the past decade, with no end in sight. Along with the ever-growing amount of indexed material, a number of search giants have enticed their users to sign up for image hosting services, such as <a href="https://www.theringer.com/2017/5/25/16043842/google-photos-data-collection-e8578b3256e0">Google Photos</a>, giving these search algorithms an endless amount of material for machine learning. On top of this, facial recognition AI is entering the consumer space with products like <a href="https://findclone.ru/">FindClone</a> and may already be used in some search algorithms, namely with Yandex. There are no publicly available facial recognition programs that use any Western social network, such as Facebook or Instagram, but perhaps it is only a matter of time until something like this emerges, dealing a major blow to online privacy while also (at that great cost) increasing digital research functionality.</p><p>If you skipped most of the article and are just looking for the bottom line, here are some easy-to-digest tips for reverse image searching:</p><ul><li>Use <strong>Yandex</strong> first, second, and third, and then try <strong>Bing</strong> and <strong>Google</strong> if you still can’t find your desired result.</li><li>If you are working with source imagery that is <strong>not from a Western or former Soviet country</strong>, then you may not have much luck. These search engines are hyper-focused on these areas, and struggle for photographs taken in South America, Central America/Caribbean, Africa, and much of Asia.</li><li><strong>Increase the resolution</strong> of your source image, even if it just means doubling or tripling the resolution until it’s a pixelated mess. None of these search engines can do much with an image that is under 200×200.</li><li>Try <strong>cropping out</strong> elements of the image, or <strong>pixelating</strong> them if it trips up your results. Most of these search engines will focus on people and their faces like a heat-seeking missile, so pixelate them to focus on the background elements.</li><li>If all else fails, get really creative: <strong>mirror</strong> your image horizontally, add some color <strong>filters</strong>, or use the <strong>clone</strong> <strong>tool</strong> on your image editor to fill in elements on your image that are disrupting searches.</li></ul>'
- - https://www.nature.com/articles/s41467-019-13549-9
  - A 5700 year-old human genome and oral microbiome from chewed birch pitch
  - Theis Z. T. Jensen, Jonas Niemann, Katrine Højholt Iversen, Anna K. Fotakis, Shyam Gopalakrishnan, Åshild J. Vågene, Mikkel Winther Pedersen, Mikkel-Holger S. Sinding, Martin R. Ellegaard, Morten E. Allentoft, Liam T. Lanigan, Alberto J. Taurozzi, Sofie Holtsmark Nielsen, Michael W. Dee, Martin N. Mortensen, Mads C. Christensen, Søren A. Sørensen, Matthew J. Collins, M. Thomas P. Gilbert, Martin Sikora, Simon Rasmussen, Hannes Schroeder
  - 2019-12-17
  - 10.1038/s41467-019-13549-9
  - ! 'The rise of ancient genomics has revolutionised our understanding of human prehistory but this work depends on the availability of suitable samples. Here we present a complete ancient human genome and oral microbiome sequenced from a 5700 year-old piece of chewed birch pitch from Denmark. We sequence the human genome to an average depth of 2.3× and find that the individual who chewed the pitch was female and that she was genetically more closely related to western hunter-gatherers from mainland Europe than hunter-gatherers from central Scandinavia. We also find that she likely had dark skin, dark brown hair and blue eyes. In addition, we identify DNA fragments from several bacterial and viral taxa, including Epstein-Barr virus, as well as animal and plant DNA, which may have derived from a recent meal. The results highlight the potential of chewed birch pitch as a source of ancient DNA.'
- - https://www.fightaging.org/archives/2019/12/a-look-back-at-2019-progress-towards-the-treatment-of-aging-as-a-medical-condition/
  - "A Look Back at 2019: Progress Towards the Treatment of Aging as a Medical Condition"
  - 'Reason (Fight Aging)'
  - 2019-12-31
  - ''
  - ! '<p>[Aging research over the past year, 2019. Categories include: The State of Funding, Conferences and Community, Clinical Development, Cellular Senescence, Mitochondria in Aging, Nuclear DNA Damage, Cross-Links, Neurodegeneration, Upregulation of Cell Maintenance, In Vivo Cell Reprogramming, Parabiosis, The Gut Microbiome in Aging, Biomarkers of Aging, Cancer, The Genetics of Longevity, Regenerative Medicine, Odds and Ends, Short Articles, and In Conclusion.]</p> <p>As has been the case for a few years now, progress towards the implementation of rejuvenation therapies is accelerating dramatically, ever faster with each passing year. While far from everyone is convinced that near term progress in addressing human aging is plausible, it is undeniable that we are far further ahead than even a few years ago. Even the public at large is beginning to catch on. While more foresightful individuals of past generations could do little more than predict a future of rejuvenation and extended healthy lives, we are in a position to make it happen.</p>'
- - https://web.mit.edu/~yandros/rpg/ogf-interview.html
  - "Interview with Ryan Dancey: D20 System and Open Gaming Movement"
  - Ryan Dancey
  - 2000-03-09
  - ''
  - ! '<p>Q. <strong>Can you briefly summarize what the Open Gaming Movement is about? Where did it come from, and what does it mean to the average gamer?</strong></p><p>A. Sure. Prepare yourself for a big gulp of business theory…That brings us to Open Gaming, and why we’re pursuing this initiative inside Wizards and outside to the larger community of game publishers.</p><p>Here’s the logic in a nutshell. We’ve got a theory that says that D&amp;D is the most popular role playing game because it is the game more people know how to play than any other game. (For those of you interested researching the theory, this concept is called <q>“The Theory of Network Externalities”</q>). Note: This is a very painful concept for a lot of people to embrace, including a lot of our own staff, and including myself for many years. The idea that D&amp;D is somehow “better” than the competition is a powerful and entrenched concept. The idea that D&amp;D can be “beaten” by a game that is “better” than D&amp;D is at the heart of every business plan from every company that goes into marketplace battle with the D&amp;D game. If you accept the Theory of Network Externalities, you have to admit that the battle is lost before it begins, because the value doesn’t reside in the game itself, but in the network of people who know how to play it.</p><p>If you accept (as I have finally come to do) that the theory is valid, then the logical conclusion is that the larger the number of people who play D&amp;D, the harder it is for competitive games to succeed, and the longer people will stay active gamers, and the more value the network of D&amp;D players will have to Wizards of the Coast. In fact, we believe that there may be a secondary market force we jokingly call <q>“The Skaff Effect”</q>, after our own <a href="https://en.wikipedia.org/wiki/Skaff_Elias">Skaff Elias</a>. Skaff is one of the smartest guys in the company, and after looking at lots of trends and thinking about our business over a long period of time, he enunciated his theory thusly:</p><blockquote><p><q>“All marketing and sales activity in a hobby gaming genre eventually contributes to the overall success of the market share leader in that genre.”</q></p></blockquote><p>In other words, the more money other companies spend on their games, the more D&amp;D sales are eventually made. Now, there are clearly issues of efficiency—not every dollar input to the market results in a dollar output in D&amp;D sales; and there is a substantial time lag between input and output; and a certain amount of people are diverted from D&amp;D to other games never to return. However, we believe very strongly that the net effect of the competition in the <span class="smallcaps">RPG</span> genre is positive for D&amp;D. The downside here is that I believe that one of the reasons that the <span class="smallcaps">RPG</span> as a category has declined so much from the early 90’s relates to the proliferation of systems. Every one of those different game systems creates a “bubble” of market inefficiency; the cumulative effect of all those bubbles has proven to be a massive downsizing of the marketplace. I have to note, highlight, and reiterate: The problem is not competitive product, the problem is competitive systems. I am very much for competition and for a lot of interesting and cool products.</p><p>So much for the dry theory and background. Here’s the logical conclusions we’ve drawn: We make more revenue and more profit from our core rulebooks than any other part of our product lines. In a sense, every other <span class="smallcaps">RPG</span> product we sell other than the core rulebooks is a giant, self-financing marketing program to drive sales of those core books. At an extreme view, you could say that the core <em>book</em> of D&amp;D—the <span class="smallcaps">PHB</span> [<em>Player’s Handbook</em> rulebook]—is the focus of all this activity, and in fact, the <span class="smallcaps">PHB</span> is the #1 best selling, and most profitable <span class="smallcaps">RPG</span> product Wizards of the Coast makes year in and year out.</p><p>The logical conclusion says that reducing the “cost” to other people to publishing and supporting the core D&amp;D game to zero should eventually drive support for all other game systems to the lowest level possible in the market, create customer resistance to the introduction of new systems, and the result of all that “support” redirected to the D&amp;D game will be to steadily increase the number of people who play D&amp;D, thus driving sales of the core books. This is a feedback cycle—the more effective the support is, the more people play D&amp;D. The more people play D&amp;D, the more effective the support is.</p><p>The other great effect of Open Gaming should be a rapid, constant improvement in the quality of the rules. With lots of people able to work on them in public, problems with math, with ease of use, of variance from standard forms, etc. should all be improved over time. The great thing about Open Gaming is that it is interactive—someone figures out a way to make something work better, and everyone who uses that part of the rules is free to incorporate it into their products. Including us. So D&amp;D as a game should benefit from the shared development of all the people who work on the Open Gaming derivative of D&amp;D.</p><p>After reviewing all the factors, I think there’s a very, very strong business case that can be made for the idea of embracing the ideas at the heart of the Open Source movement and finding a place for them in gaming.</p>'
- - https://www.sciencemag.org/news/2019/12/eyeing-organs-human-transplants-companies-unveil-most-extensively-gene-edited-pigs-yet
  - "Eyeing organs for human transplants, companies unveil the most extensively gene-edited pigs yet"
  - Kelly Servick (Science)
  - 2019-12-19
  - 10.1126/science.aba6487
  - ! '<p>If any swine is fit to be an organ donor for people, then the dozens of pigs snuffling around Qihan Bio’s facility in Hangzhou, China, may be the best candidates so far. The Chinese company and its U.S. collaborators reported today that they have used the genome editor CRISPR to create the most extensively genetically engineered pigs to date—animals whose tissues, the researchers say, finally combine all the features necessary for a safe and successful transplant into humans. “This is the first prototype,” says Luhan Yang, a geneticist at Qihan Bio. In a preprint published today on bioRxiv, Qihan researchers and collaborators, including Cambridge, Massachusetts–based eGenesis—which Yang co-founded with Harvard University geneticist George Church—described the new generation of animals and various tests on their cells; the researchers have already begun to transplant the pigs’ organs into nonhuman primates, a key step toward human trials.</p><p>…In the new study, the team for the first time combined these PERV “knockouts” with a suite of other changes to prevent immune rejection, for a record-setting 13 modified genes. In pig ear cells, they removed three genes coding for enzymes that help produce molecules on pig cells that provoke an immune response. They also inserted six genes that inhibit various aspects of the human immune response and three more that help regulate blood coagulation. The researchers then put the DNA-containing nuclei of these edited cells into eggs from pig ovaries collected at a slaughterhouse. These eggs developed into embryos that were implanted into surrogate mothers. Cells from the resulting piglets got another round of edits to remove the PERV sequences, after which their DNA went into another set of egg cells to create a new generation of pigs with all the desired edits. (In future, Yang says, the team will try to make all the modifications in a single generation.)</p><p>The resulting pigs appeared healthy and fertile with functioning organs, the team reports today. And initial tests of their cells in lab dishes suggest their organs will be much less prone to immune rejection than those of unmodified pigs: The tendency of the pig cells to bind to certain human antibodies was reduced by 90%, and the modified cells better survived interactions with human immune cells. But a key test is still to come: Yang says her team has begun to transplant organs from the highly edited pigs into monkeys to gauge their safety and longevity.</p><p>The combination of edits described in the new paper is “a technical feat,” says Marilia Cascalho, a transplant immunologist at the University of Michigan in Ann Arbor. “Whether it offers an advantage [over other engineered pig organs] … the jury is out on that,” she says…Yang says that Qihan plans to remain “laser-focused” on preclinical studies in 2020, but expects to be testing pig organs in humans within 5 years. Many in the field now feel an inevitable momentum around xenotransplantation: “There is so much need for organs,” Cascalho says. “I think it’s going to be a reality.”</p>'
- - https://openreview.net/forum?id=rkgNKkHtvB#googlebrain
  - "Reformer: The Efficient Transformer"
  - Nikita Kitaev, Lukasz Kaiser, Anselm Levskaya
  - 2019-09-25
  - ''
  - ! '<ul><li><p><em>Keywords</em>: attention, locality sensitive hashing, reversible layers</p></li><li><p><em>TL;DR</em>: Efficient Transformer with locality-sensitive hashing and reversible layers</p></li><li><p><em>Abstract</em>:</p><p>Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(<em>L</em><sup>2</sup>) to O(<em>L</em>), where <em>L</em> is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of <em>N</em> times, where <em>N</em> is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.</p></li><li><p><em>Code</em>: https://pastebin.com/62r5FuEW</p></li></ul>'
- - https://www.theatlantic.com/family/archive/2019/01/how-do-people-communicate-before-death/580303/
  - "What People Actually Say Before They Die: Insights into the little-studied realm of last words"
  - Michael Erard (Atlantic)
  - 2019-01-16
  - ''
  - ! '<p>…“There’s so much <em>so</em> in sorrow,” he said at one point. “Let me down from here,” he said at another. “I’ve lost my modality.” To the surprise of his family members, the lifelong atheist also began hallucinating angels and complaining about the crowded room—even though no one was there.</p><p>Felix’s 53-year-old daughter, Lisa Smartt, kept track of his utterances, writing them down as she sat at his bedside in those final days. Smartt majored in linguistics at UC Berkeley in the 1980s and built a career teaching adults to read and write. Transcribing Felix’s ramblings was a sort of coping mechanism for her, she says….eventually she wrote a book, <a href="https://www.amazon.com/Words-Threshold-What-Nearing-Death/dp/1608684601"><em>Words on the Threshold</em></a>, published in early 2017, about the linguistic patterns in 2,000 utterances from 181 dying people, including her father. Despite the limitations of this book, it’s unique—it’s the only published work I could find when I tried to satisfy my curiosity about how people <em>really</em> talk when they die.</p><p>…Many people die in such silence, particularly if they have advanced dementia or Alzheimer’s that robbed them of language years earlier. For those who do speak, it seems their vernacular is often banal. From a doctor I heard that people often say, “Oh fuck, oh fuck.” Often it’s the names of wives, husbands, children. “A nurse from the hospice told me that the last words of dying men often resembled each other,” wrote Hajo Schumacher in a <a href="http://www.spiegel.de/plus/maenner-und-ihre-muetter-der-milf-komplex-a-40b6d23f-0677-4c9c-9e3a-3a43cab12d0d">September essay in <em>Der Spiegel</em></a>. “Almost everyone is calling for ‘Mommy’ or ‘Mama’ with the last breath.”…Delirium is so frequent then, wrote the New Zealand psychiatrist Sandy McLeod, that “it may even be regarded as exceptional for patients to remain mentally clear throughout the final stages of malignant illness.” About half of people who recover from postoperative delirium recall the disorienting, fearful experience.</p><p>…He also repeated words and phrases, often ones that made no sense. “The green dimension! The green dimension!” (Repetition is common in the speech of people with dementia and also those who are delirious.) Smartt found that repetitions often expressed themes such as gratitude and resistance to death. But there were also unexpected motifs, such as circles, numbers, and motion. “I’ve got to get off, get off! Off of this life,” Felix had said…In <em>Final Gifts</em>, the hospice nurses Callanan and Kelley note that “the dying often use the metaphor of travel to alert those around them that it is time for them to die.” They quote a 17-year-old, dying of cancer, distraught because she can’t find the map. “If I could find the map, I could go home! Where’s the map? I want to go home!”</p>'
- - https://www.reddit.com/r/slatestarcodex/comments/dwtr0m/matthew_walkers_why_we_sleep_is_riddled_with/#thing_t1_f7mid7m
  - '[Comment on Guzey post]'
  - Kinkajoe
  - 2019-11-16
  - ''
  - ! '<p>I study sleep. While some of walker’s claims may be hyperbolic, I think they are within reason and justified by the important message he is trying to convey. Too many people have begun to forego sleep in their health choices, and he has helped raise awareness of sleep’s role in our health.</p><p>Many of these criticisms are quite unfair or misunderstanding the science...</p>'
- - http://famouspoetsandpoems.com/poets/mary_oliver/poems/15844
  - "The Kingfisher"
  - Mary Oliver
  - '1990'
  - ''
  - ! '<p>The kingfisher rises out of the black wave<br />like a blue flower, in his beak<br />he carries a silver leaf. I think this is<br />the prettiest world—so long as you don’t mind<br />a little dying, how could there be a day in your whole life<br />that doesn’t have its splash of happiness?<br />There are more fish than there are leaves<br />on a thousand trees, and anyway the kingfisher<br />wasn’t born to think about it, or anything else.<br />When the wave snaps shut over his blue head, the water<br />remains water—hunger is the only story<br />he has ever heard in his life that he could believe.<br />I don’t say he’s right. Neither<br />do I say he’s wrong. Religiously he swallows the silver leaf<br />with its broken red river, and with a rough and easy cry<br />I couldn’t rouse out of my thoughtful body<br />if my life depended on it, he swings back<br />over the bright sea to do the same thing, to do it<br />(as I long to do something, anything) perfectly.</p>'
- - https://www.ibiblio.org/ipa/poems/milosz/a_conversation_with_jeanne.php
  - A Conversation With Jeanne
  - Czesław Miłosz
  - '1984'
  - ''
  - ! '<p>Let us not talk philosophy, drop it, Jeanne. So many words, so much paper, who can stand it. I told you the truth about my distancing myself. I’ve stopped worrying about my misshapen life. It was no better and no worse than the usual human tragedies.</p><p>For over thirty years we have been waging our dispute As we do now, on the island under the skies of the tropics. We flee a downpour, in an instant the bright sun again, And I grow dumb, dazzled by the emerald essence of the leaves.</p><p>We submerge in foam at the line of the surf, We swim far, to where the horizon is a tangle of banana bush, With little windmills of palms. And I am under accusation: That I am not up to my oeuvre, That I do not demand enough from myself, As I could have learned from Karl Jaspers, That my scorn for the opinions of this age grows slack.</p><p>I roll on a wave and look at white clouds.</p><p>You are right, Jeanne, I don’t know how to care about the salvation of my soul. Some are called, others manage as well as they can. I accept it, what has befallen me is just. I don’t pretend to the dignity of a wise old age. Untranslatable into words, I chose my home in what is now, In things of this world, which exist and, for that reason, delight us: Nakedness of women on the beach, coppery cones of their breasts, Hibiscus, alamanda, a red lily, devouring With my eyes, lips, tongue, the guava juice, the juice of <em>la prune de Cythère</em>, Rum with ice and syrup, lianas-orchids In a rain forest, where trees stand on the stilts of their roots.</p><p>Death, you say, mine and yours, closer and closer, We suffered and this poor earth was not enough. The purple-black earth of vegetable gardens Will be here, either looked at or not. The sea, as today, will breathe from its depths. Growing small, I disappear in the immense, more and more free.</p><p><em>Guadeloupe</em></p>'
- - /docs/genetics/2016-plomin.pdf#page=10
  - Top 10 Replicated Findings From Behavioral Genetics
  - Robert Plomin, John C. DeFries, Valerie S. Knopik, Jenae M. Neiderhiser
  - '2016'
  - '10.1177/1745691615617439'
  - ! '<p><strong>Finding 7. Most measures of the “environment” show significant genetic influence</strong></p><p>Although it might seem a peculiar thing to do, measures of the environment widely used in psychological science—such as parenting, social support, and life events—can be treated as dependent measures in genetic analyses. If they are truly measures of the environment, they should not show genetic influence. To the contrary, in 1991, Plomin and Bergeman conducted a review of the first 18 studies in which environmental measures were used as dependent measures in genetically sensitive designs and found evidence for genetic influence for these measures of the environment. Significant genetic influence was found for objective measures such as videotaped observations of parenting as well as self-report measures of parenting, social support, and life events. How can measures of the environment show genetic influence? The reason appears to be that such measures do not assess the environment independent of the person. As noted earlier, humans select, modify, and create environments correlated with their genetic behavioral propensities such as personality and psychopathology (McAdams, Gregory, &amp; Eley, 2013). For example, in studies of twin children, parenting has been found to reflect genetic differences in children’s characteristics such as personality and psychopathology (Avinun &amp; Knafo, 2014; Klahr &amp; Burt, 2014; Plomin, 1994).</p><p>Since 1991, more than 150 articles have been published in which environmental measures were used in genetically sensitive designs; they have shown consistently that there is significant genetic influence on environmental measures, extending the findings from family environments to neighborhood, school, and work environments. Kendler and Baker (2007) conducted a review of 55 independent genetic studies and found an average heritability of 0.27 across 35 diverse environmental measures (confidence intervals not available). Meta-analyses of parenting, the most frequently studied domain, have shown genetic influence that is driven by child characteristics (Avinun &amp; Knafo, 2014) as well as by parent characteristics (Klahr &amp; Burt, 2014). Some exceptions have emerged. Not surprisingly, when life events are separated into uncontrollable events (e.g., death of a spouse) and controllable life events (e.g., financial problems), the former show nonsignificant genetic influence. In an example of how all behavioral genetic results can differ in different cultures, Shikishima, Hiraishi, Yamagata, Neiderhiser, and Ando (2012) compared parenting in Japan and Sweden and found that parenting in Japan showed more genetic influence than in Sweden, consistent with the view that parenting is more child centered in Japan than in the West.</p><p>Researchers have begun to use GCTA to replicate these findings from twin studies. For example, GCTA has been used to show significant genetic influence on stressful life events (Power et al., 2013) and on variables often used as environmental measures in epidemiological studies such as years of schooling (C. A. Rietveld, Medland, et al., 2013). Use of GCTA can also circumvent a limitation of twin studies of children. Such twin studies are limited to investigating within-family (twin-specific) experiences, whereas many important environmental factors such as socioeconomic status (SES) are the same for two children in a family. However, researchers can use GCTA to assess genetic influence on family environments such as SES that differ between families, not within families. GCTA has been used to show genetic influence on family SES (Trzaskowski et al., 2014) and an index of social deprivation (Marioni et al., 2014).</p>'
- - https://edwardtufte.github.io/tufte-css/#sidenotes
  - "Tufte-CSS: Sidenotes: Footnotes and Marginal Notes"
  - Dave Liepmann (Tufte-CSS)
  - ''
  - ''
  - ! '<p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<sup>3</sup> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p><p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p><p>…If you want a sidenote without footnote-style numberings, then you want a margin note. Notice there isn’t a number preceding the note. On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text.</p>'
- - /Causality#overview-the-current-situation
  - "Causality in the Social Sciences: Overview: The Current Situation"
  - Gwern Branwen
  - 2019-12-05
  - ''
  -  ! '<p>Here is how I currently understand the relationship between correlation and causality, and the collective findings of meta-scientific research:</p><ol type="1"><li><p><a href="https://www.gwern.net/Replication"><em>The Replication Crisis</em></a>: a shockingly large fraction of psychological research and other fields is simple random noise which cannot be replicated.</p></li><li><p><a href="https://www.gwern.net/Everything"><em>Everything Is Correlated</em></a>: when we systematically measure many variables at large scale with large <em>n</em>, we find that ‘everything is correlated’—even things which seem to have no causal relationship whatsoever.</p></li><li><p><a href="https://www.gwern.net/docs/sociology/1987-rossi"><em>The Metallic Laws</em></a>: empirically, most efforts to change human behavior and sociology and economics and education fail in randomized evaluation and the mean effect size of experiments in meta-analyses typically approaches zero, despite promising correlations.</p></li><li><p><a href="https://www.gwern.net/Correlation"><em>Correlation ≠ Causation</em></a>: so, we live in a world where research manufactures many spurious results and, even once we see through the fake findings, finding a correlation is meaningless because everything is correlated to begin with and accordingly, they are little better than experimenting at random, which doesn’t work well either.</p><p>But <em>why</em> is correlation ≠ causation?</p></li><li><p><a href="https://www.gwern.net/Causality#what-a-tangled-net-we-weave-when-first-we-practice-to-believe"><em>Dense Causal Graphs</em></a>: because, if we write down a causal graph consistent with ‘everything is correlated’ and the empirical facts of average null effects + unpredictive correlations, this implies that all variables are part of enormous dense causal graphs where each variable is connected to several others.</p></li><li><p><a href="https://www.gwern.net/Causality#heuristics-biases"><em>Incorrect Intuitions</em></a>: This inequality between observable correlations and actual useful causal manipulability merely grows with larger networks, and causal networks in fields like economics or biology are far more complex than those in more ordinary everyday fields like ‘catching a ball’.</p><p>Our intuitions, formed in simple domains designed to have sparse causal networks (it would be bad if balls could make you do random things! your brain is carefully designed to control the influence of any outside forces &amp; model the world as simple for planning purposes), turn out to be profoundly misleading in these other domains.</p></li><li><p><em>No, Really, Correlation ≠ Causation</em>: This cognitive bias is why correlation ≠ causation is so difficult to internalize and accept, and honored primarily in the breach even by sophisticated researchers, and is why randomized experiments are historically late developed, neglected, counterintuitive, and criticized when run despite routinely debunking conventional wisdom of experts in almost every field.</p></li></ol>'
- - https://slatestarcodex.com/2013/07/17/who-by-very-slow-decay/
  - Who By Very Slow Decay
  - Scott Alexander
  - 2013-07-17
  - ''
  - ! '<p>[Essay by psychiatrist about care of the dying in American healthcare: people die agonizing, slow, expensive deaths, prolonged by modern healthcare, deprived of all dignity and joy by disease and decay. There is little noble about it.]</p><p>You will become bedridden, unable to walk or even to turn yourself over. You will become completely dependent on nurse assistants to intermittently shift your position to avoid pressure ulcers. When they inevitably slip up, your skin develops huge incurable sores that can sometimes erode all the way to the bone, and which are perpetually infected with foul-smelling bacteria. Your limbs will become practically vestigial organs, like the appendix, and when your vascular disease gets too bad, one or more will be amputated, sacrifices to save the host. Urinary and fecal continence disappear somewhere in the process, so you’re either connected to catheters or else spend a while every day lying in a puddle of your own wastes until the nurses can help you out….</p><p>Somewhere in the process your mind very quietly and without fanfare gives up the ghost. It starts with forgetting a couple of little things, and progresses…They don’t remember their own names, they don’t know where they are or what they’re doing there, and they think it’s the 1930s or the 1950s or don’t even have a concept of years at all. When you’re alert and oriented “x0”, the world becomes this terrifying place where you are stuck in some kind of bed and can’t move and people are sticking you with very large needles and forcing tubes down your throat and you have no idea why or what’s going on.</p><p>So of course you start screaming and trying to attack people and trying to pull the tubes and IV lines out. Every morning when I come in to work I have to check the nurses’ notes for what happened the previous night, and every morning a couple of my patients have tried to pull all of their tubes and lines out. If it’s especially bad they try to attack the staff, and although the extremely elderly are really bad at attacking people this is nevertheless Unacceptable Behavior and they have to be restrained ie tied down to the bed. A presumably more humane alternative sometimes used instead or in addition is to just drug you up on all of those old-timey psychiatric medications that actual psychiatrists don’t use anymore because of their bad reputation…Nevertheless, this is the way many of my patients die. Old, limbless, bedridden, ulcerated, in a puddle of waste, gasping for breath, loopy on morphine, hopelessly demented, in a sterile hospital room with someone from a volunteer program who just met them sitting by their bed.</p><p>…I work in a Catholic hospital. People here say the phrase “culture of life” a lot, as in “we need to cultivate a culture of life.” They say it almost as often as they say “patient-centered”. At my hospital orientation, a whole bunch of nuns and executives and people like that got up and told us how we had to do our part to “cultivate a culture of life.”</p><p>And now every time I hear that phrase I want to scream. 21st century American hospitals do not need to “cultivate a culture of life”. We have enough life. We have life up the wazoo. We have more life than we know what to do with. We have life far beyond the point where it becomes a sick caricature of itself. We prolong life until it becomes a sickness, an abomination, a miserable and pathetic flight from death that saps out and mocks everything that made life desirable in the first place. 21st century American hospitals need to cultivate a culture of life the same way that Newcastle needs to cultivate a culture of coal, the same way a man who is burning to death needs to cultivate a culture of fire.</p><p>And so every time I hear that phrase I want to scream, or if I cannot scream, to find some book of hospital poetry that really is a book of hospital poetry and shove it at them, make them read it until they understand. There is no such book, so I hope it will be acceptable if I just rip off of Wilfred Owen directly:</p><blockquote><p>If in some smothering dreams you too could pace<br />Behind the gurney that we flung him in,<br />And watch the white eyes writhing in his face,<br />His hanging face, like a devil’s sack of sin;<br />If you could hear, at every jolt, the blood<br />Come gargling from the froth-corrupted lungs,<br />Obscene with cancer, bitter with the cud<br />Of vile, incurable sores on innocent tongues<br />My friend, you would not so pontificate<br />To reasoners beset by moral strife<br />The old lie: we must try to cultivate<br />A culture of life.</p></blockquote>'
- - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1119282/
  - "Instinctive sleeping and resting postures: an anthropological and zoological approach to treatment of low back and joint pain"
  - Michael Tetley
  - 2000-12-23
  - '10.1136/bmj.321.7276.1616'
  - ! '<p>If you are a medical professional and have been trained in a “civilised” country you probably know next to nothing about the primate <em>Homo sapiens</em> and how they survive in the wild. You probably do not know that nature has provided an automatic manipulator to correct most spinal and peripheral joint lesions in primates. In common with millions of other so called civilised people you suffer unnecessarily from musculoskeletal problems and are discouraged about how to treat the exponential rise in low back pain throughout the developed world. Humans are one of 200 species of primates.<sup>1</sup> All primates suffer from musculoskeletal problems; nature, recognising this fact, has given primates a way to correct them.</p><p>The study of animals in the wild has been a lifelong pursuit. I grew up with tribal people and in 1953–4 commanded a platoon of African soldiers from 9 tribes, who taught me to sleep on my side without a pillow so that I could listen out for danger with both ears. I have organised over 14 expeditions all over the world to meet native peoples and study their sleeping and resting postures. They all adopted similar postures and exhibited few musculoskeletal problems. I must emphasise that this is not a comparison of genes or races but of lifestyles. I tried to carry out surveys to collect evidence but they were meaningless, as tribespeople give you the answer they think you want. They often object to having their photographs taken, so I have demonstrated the postures.</p><p><em>Summary points</em>:</p><ul><li>Forest dwellers and nomads suffer fewer musculoskeletal lesions than “civilised” people</li><li>Nature’s automatic manipulator during sleep is the kickback against the vertebrae by the ribs when the chest is prevented from movement by the forest floor</li><li>Various resting postures correct different joints</li><li>Pillows are not necessary</li></ul>'
- - https://www.nytimes.com/2019/12/30/business/china-scientist-genetic-baby-prison.html
  - "Chinese Scientist Who Genetically Edited Babies Gets 3 Years in Prison: He Jiankui’s work was also carried out on a third infant, according to China’s state media, in a new disclosure that is likely to add to the global uproar over such experiments."
  - Sui-Lee Wee (NYT)
  - 2019-12-30
  - ''
  -  ! '<p>A court in China on Monday sentenced He Jiankui, the researcher who shocked the global scientific community when he claimed that he had created the world’s first genetically edited babies, to three years in prison for carrying out “illegal medical practices.” In a surprise announcement from a trial that was closed to the public, the court in the southern city of Shenzhen found Dr. He guilty of forging approval documents from ethics review boards to recruit couples in which the man had H.I.V. and the woman did not, Xinhua, China’s official news agency, reported. Dr. He had said he was trying to prevent H.I.V. infections in newborns, but the state media on Monday said he deceived the subjects and the medical authorities alike.</p><p>Dr. He, 35, sent the scientific world into an uproar last year when he announced at a conference in Hong Kong that he had created the world’s first genetically edited babies—twin girls. On Monday, China’s state media said his work had resulted in a third genetically edited baby, who had been previously undisclosed.</p><p>Dr. He pleaded guilty and was also fined $430,000, according to Xinhua. In a brief trial, the court also handed down prison sentences to two other scientists who it said had “conspired” with him: Zhang Renli, who was sentenced to two years in prison, and Qin Jinzhou, who got a suspended sentence of one and a half years…The court said the trial had to be closed to the public to guard the privacy of the people involved.</p>'
- - https://www.statnews.com/2019/06/25/alzheimers-cabal-thwarted-progress-toward-cure/
  - "The maddening saga of how an Alzheimer’s ‘cabal’ thwarted progress toward a cure for decades"
  - Sharon Begley (STAT)
  - 2019-06-25
  - ''
  -  ! '<p>In the 30 years that biomedical researchers have worked determinedly to find a cure for Alzheimer’s disease, their counterparts have developed drugs that helped cut deaths from cardiovascular disease by more than half, and cancer drugs able to eliminate tumors that had been incurable. But for Alzheimer’s, not only is there no cure, there is not even a disease-slowing treatment.</p><p>…In more than two dozen interviews, scientists whose ideas fell outside the dogma recounted how, for decades, believers in the dominant hypothesis suppressed research on alternative ideas: They influenced what studies got published in top journals, which scientists got funded, who got tenure, and who got speaking slots at reputation-buffing scientific conferences. The scientists described the frustrating, even career-ending, obstacles that they confronted in pursuing their research. A top journal told one that it would not publish her paper because others hadn’t. Another got whispered advice to at least pretend that the research for which she was seeking funding was related to the leading idea—that a protein fragment called beta-amyloid accumulates in the brain, creating neuron-killing clumps that are both the cause of Alzheimer’s and the key to treating it. Others could not get speaking slots at important meetings, a key showcase for research results. Several who tried to start companies to develop Alzheimer’s cures were told again and again by venture capital firms and major biopharma companies that they would back only an amyloid approach.</p><p>…For all her regrets about the amyloid hegemony, Neve is an unlikely critic: She co-led the 1987 discovery of mutations in a gene called APP that increases amyloid levels and causes Alzheimer’s in middle age, supporting the then-emerging orthodoxy. Yet she believes that one reason Alzheimer’s remains incurable and untreatable is that the amyloid camp “dominated the field,” she said. Its followers were influential “to the extent that they persuaded the National Institute of Neurological Disorders and Stroke [part of the National Institutes of Health] that it was a waste of money to fund any Alzheimer’s-related grants that didn’t center around amyloid.” To be sure, NIH did fund some Alzheimer’s research that did not focus on amyloid. In a sea of amyloid-focused grants, there are tiny islands of research on oxidative stress, neuroinflammation, and, especially, a protein called tau. But Neve’s NINDS program officer, she said, “told me that I should at least collaborate with the amyloid people or I wouldn’t get any more NINDS grants.” (She hoped to study how neurons die.) A decade after her APP discovery, a disillusioned Neve left Alzheimer’s research, building a distinguished career in gene editing. Today, she said, she is “sick about the millions of people who have needlessly died from” the disease.</p><p>Dr. Daniel Alkon, a longtime NIH neuroscientist who started a company to develop an Alzheimer’s treatment, is even more emphatic: “If it weren’t for the near-total dominance of the idea that amyloid is the only appropriate drug target,” he said, “we would be 10 or 15 years ahead of where we are now.”</p><p>Making it worse is that the empirical support for the amyloid hypothesis has always been shaky. There were numerous red flags over the decades that targeting amyloid alone might not slow or reverse Alzheimer’s. “Even at the time the amyloid hypothesis emerged, 30 years ago, there was concern about putting all our eggs into one basket, especially the idea that ridding the brain of amyloid would lead to a successful treatment,” said neurobiologist Susan Fitzpatrick, president of the James S. McDonnell Foundation. But research pointing out shortcomings of the hypothesis was relegated to second-tier journals, at best, a signal to other scientists and drug companies that the criticisms needn’t be taken too seriously. Zaven Khachaturian spent years at NIH overseeing its early Alzheimer’s funding. Amyloid partisans, he said, “came to permeate drug companies, journals, and NIH study sections,” the groups of mostly outside academics who decide what research NIH should fund. “Things shifted from a scientific inquiry into an almost religious belief system, where people stopped being skeptical or even questioning.”</p><p>…“You had a whole industry going after amyloid, hundreds of clinical trials targeting it in different ways,” Alkon said. Despite success in millions of mice, “none of it worked in patients.”</p><p>Scientists who raised doubts about the amyloid model suspected why. Amyloid deposits, they thought, are a response to the true cause of Alzheimer’s and therefore a marker of the disease—again, the gravestones of neurons and synapses, not the killers. The evidence? For one thing, although the brains of elderly Alzheimer’s patients had amyloid plaques, so did the brains of people the same age who died with no signs of dementia, a pathologist discovered in 1991. Why didn’t amyloid rob them of their memories? For another, mice engineered with human genes for early Alzheimer’s developed both amyloid plaques and dementia, but there was no proof that the much more common, late-onset form of Alzheimer’s worked the same way. And yes, amyloid plaques destroy synapses (the basis of memory and every other brain function) in mouse brains, but there is no correlation between the degree of cognitive impairment in humans and the amyloid burden in the memory-forming hippocampus or the higher-thought frontal cortex. “There were so many clues,” said neuroscientist Nikolaos Robakis of the Icahn School of Medicine at Mount Sinai, who also discovered a mutation for early-onset Alzheimer’s. “Somehow the field believed all the studies supporting it, but not those raising doubts, which were very strong. The many weaknesses in the theory were ignored.”</p>'
- - /docs/biology/2019-thomas.pdf
  - 'Objective subtle cognitive difficulties predict future amyloid accumulation and neurodegeneration'
  - ! "Kelsey R. Thomas, Katherine J. Bangen, Alexandra J. Weigand, Emily C. Edmonds, Christina G. Wong, Shanna Cooper, Lisa Delano-Wood, Mark W. Bondi, for the Alzheimer's Disease Neuroimaging Initiative"
  - 2019-12-30
  - '10.1212/WNL.0000000000008838'
  - ! '<p><em>Objective</em>: To determine the temporal sequence of objectively defined subtle cognitive difficulties (Obj-SCD) in relation to amyloidosis and neurodegeneration, the current study examined the trajectories of amyloid PET and medial temporal neurodegeneration in participants with Obj-SCD relative to cognitively normal (CN) and mild cognitive impairment (MCI) groups.</p><p><em>Method</em>: A total of 747 Alzheimer’s Disease Neuroimaging Initiative participants (305 CN, 153 Obj-SCD, 289 MCI) underwent neuropsychological testing and serial amyloid PET and structural MRI examinations. Linear mixed effects models examined 4-year rate of change in cortical 18F-florbetapir PET, entorhinal cortex thickness, and hippocampal volume in those classified as Obj-SCD and MCI relative to CN.</p><p><em>Result</em>: Amyloid accumulation was faster in the Obj-SCD group than in the CN group; the MCI and CN groups did not significantly differ from each other. The Obj-SCD and MCI groups both demonstrated faster entorhinal cortical thinning relative to the CN group; only the MCI group exhibited faster hippocampal atrophy than CN participants.</p><p><em>Conclusion</em>: Relative to CN participants, Obj-SCD was associated with faster amyloid accumulation and selective vulnerability of entorhinal cortical thinning, whereas MCI was associated with faster entorhinal and hippocampal atrophy. Findings suggest that Obj-SCD, operationally defined using sensitive neuropsychological measures, can be identified prior to or during the preclinical stage of amyloid deposition. Further, consistent with the Braak neurofibrillary staging scheme, Obj-SCD status may track with early entorhinal pathologic changes, whereas MCI may track with more widespread medial temporal change. Thus, Obj-SCD may be a sensitive and noninvasive predictor of encroaching amyloidosis and neurodegeneration, prior to frank cognitive impairment associated with MCI.</p>'
- - https://mlp.fandom.com/wiki/The_Last_Problem
  - "MLP:FiM: S9E26: The Last Problem"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>The Last Problem</strong> is the twenty-sixth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and twenty-second episode overall.[1] It premiered as the final episode of the series, as part of the 90-minute finale with <em>The Ending of the End - Part 1</em> and <em>The Ending of the End - Part 2</em>.</p><p>In this epilogue episode, an older and wiser Princess Twilight Sparkle is visited by a student with a friendship problem. As she attempts to solve it, she looks back on the times she and her friends spent together.</p><p>A sequel event to the episode, “The Crowning Achievement”, was included in Gameloft’s mobile game.</p>'
- - https://mlp.fandom.com/wiki/The_Big_Mac_Question
  - "MLP:FiM: S9E23: The Big Mac Question"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>The Big Mac Question</strong> is the twenty-third[1][2] episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and nineteenth episode overall.[3] The title is a reference to the saying “the big question”, which is often used as a euphemism for a marriage proposal.</p><p>When Big McIntosh and Sugar Belle decide to propose to each other, everything their friends do to help ends up making a mess of the whole thing.</p>'
- - https://mlp.fandom.com/wiki/Sparkle%27s_Seven
  - "MLP:FiM: S9E4: Sparkle's Seven"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>Sparkle’s Seven</strong> (also titled “Twilight’s Seven” by some sources and in the episode’s script,[1]) is the fourth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundredth episode overall,[2] celebrated as a milestone episode. The title is a reference to the 1960 film <em>Ocean’s 11</em>, its 2001 remake, and/or the all-female spin-off to the latter <em>Ocean’s 8</em>, previously referenced by “Sparkle’s Six” in <em>Twilight Sparkle and the Crystal Heart Spell</em> and “Luna’s 5” on the <em>My Little Pony: Nightmare Knights</em> Issue #1 cover RI.</p><p>In this episode, Twilight Sparkle and Shining Armor pit their wits against each other to settle a long-standing sibling rivalry, but they soon discover they are not the only competitors.</p>'
- - https://mlp.fandom.com/wiki/Daring_Doubt
  - "MLP:FiM: S9E21: Daring Doubt"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>Daring Doubt</strong> is the twenty-first episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and seventeenth episode overall.[1]</p><p>When another author releases his own version of the events in A. K. Yearling’s Daring Do books, Rainbow Dash is furious, while Fluttershy is curious to know the truth.</p>'
- - https://mlp.fandom.com/wiki/The_Last_Laugh
  - "MLP:FiM: S9E14: The Last Laugh"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>The Last Laugh</strong> (incorrectly[1] titled as “That’s a Laugh” by some sources), is the fourteenth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and tenth episode overall.[2]</p><p>When Pinkie Pie seeks help from her old friend Cheese Sandwich in finding her life’s purpose, she discovers the unimaginable has happened.</p>'
- - https://mlp.fandom.com/wiki/Between_Dark_and_Dawn
  - "MLP:FiM: S9E13: Between Dark and Dawn"
  - MLP Wikia
  - ''
  - ''
  - ! '<p><strong>Between Dark and Dawn</strong> is the thirteenth episode of season nine of <em>My Little Pony: Friendship is Magic</em> and the show’s two hundred and ninth episode overall.[1] It marks season nine’s midseason finale.[2]</p><p>In this episode, Celestia and Luna take a “bucket-list” sister vacation while Twilight and her friends struggle to cover the princesses’ many royal duties alone.</p>'
- - https://www.kickscondor.com/
  - Kicks Condor
  - Kicks Condor
  - ''
  - ''
  - ! '[Homepage of programmer Kicks Condor; hypertext-oriented link compilation and experimental design blog.]'
- - https://href.cool/2010s/
  - "Cool Links of the Decade: 2010s"
  - Kicks Condor
  - 2019-12
  - ''
  - ! '<p>Eh, this is doomed - <a href="https://waxy.org/">Waxy</a> or <a href="https://imperica.com/">Imperica</a> should take a crack at this. The AV Club did a <a href="https://aux.avclub.com/the-100-best-worst-and-weirdest-things-we-saw-on-the-1839566367">list</a> of ‘things’. I wanted to cover stuff that wasn’t on there. A lot happened outside of celebrities, Twitter and momentary memes. (We all obviously love <span class="citation" data-cites="electrolemon">@electrolemon</span>, “double rainbow”, Key &amp; Peele’s <em>Gremlins 2 Brainstorm</em>, 10 hr vids, etc.)</p><pre><code>  &lt;p&gt;There is a master &lt;a href=&quot;https://www.fimoculous.com/decade-review-2010.cfm&quot;&gt;list of lists&lt;/a&gt; as well.&lt;/p&gt;  &lt;p&gt;Hope for this list - get u mad &amp;amp; u destroy me &amp;amp; u blog in 2020.&lt;/p&gt;</code></pre>'
- - https://www.goodreads.com/review/show/2821183153
  - "Review of 'String of Beads: Complete Poems of Princess Shikishi'"
  - Gwern Branwen
  - 2019-12-29
  - ''
  - ! "[Review of translation of complete corpus of imperial court poet Princess Shikishi (1149–1201). While well-annotated, Sato's decision to translate each poem in a single line drains it of any enjoyability, turning it into a prose-like slog.]"
- - https://www.goodreads.com/review/show/1798638457
  - "Review of 'Experimenter Effects In Behavioral Research', Robert Rosenthal"
  - Gwern Branwen
  - 2019-12-28
  - ''
  - ! "Review of a major and widely-cited psychology monograph purporting to demonstrate pervasive and powerful effects of social expectations and settings and the general environment on all aspects of human psychology, experimentation, and research, even to the point of the 'Pygmalion effect' proving that teacher expectations can boost student IQs by hundreds of points. The Pygmalion effect was based on impossible data, was defended by statistical malpractice, and repeatedly failed to replicate, and this exemplifies the problem with Rosenthal's research and the book as a whole: despite its appearance of extreme rigor and concern for bias, it is clear that the results actually exemplify the Replication Crisis and that almost none of his research is reliable, bogus from beginning to end, and the results were designed to serve ideological goals despite the intrinsic absurdity and inconsistency with basic observations of the stability and consistency and predictive power of individual differences and the impotence of environmental interventions."
- - https://www.reddit.com/r/AIDungeon/
  - '/r/AIDungeon/'
  - Reddit
  - ''
  - ''
  - ! '[Subreddit for sharing AI Dungeon 2 game transcripts and discussing bugs/issues/upgrades; <a href="https://www.reddit.com/r/AIDungeon/comments/e8fz8l/putting_together_a_frequently_asked_questions_list/">FAQ</a>.]'
- - https://www.edwardtufte.com/tufte/books_visex
  - '<em>Visual Explanations: Images and Quantities, Evidence and Narrative</em>, Tufte 1997'
  - Edward Tufte
  - '1997'
  - ''
  - ! '<p><em>Visual Explanations: Images and Quantities, Evidence and Narrative</em> [Tufte #3] is about pictures of verbs, the representation of mechanism and motion, process and dynamics, causes and effects, explanation and narrative. Practical applications and examples include statistical graphics, charts for making important decisions in engineering and medicine, technical manuals, diagrams, design of computer interfaces and websites and on-line manuals, animations and scientific visualizations, techniques for talks, and design strategies for enhancing the rate of information transfer in print, presentations, and computer screens. The use of visual evidence in deciding to launch the space shuttle Challenger is discussed in careful detail. Video snapshots show redesigns of a supercomputer animation of a thunderstorm. The book is designed and printed to the highest standards, with luscious color throughout and four built-in flaps for showing motion and before/after effects.</p><p>158 pages; ISBN 1930824157</p><figure><img src="https://www.edwardtufte.com/tufte/graphics/visex_bookcover.gif" alt="Cover of Visual Explanations" /><figcaption>Cover of <em>Visual Explanations</em></figcaption></figure>'
- - https://statmodeling.stat.columbia.edu/2019/12/27/why-we-sleep-data-manipulation-a-smoking-gun/
  - '<em>Why we sleep</em> data manipulation: A smoking gun?'
  - Andrew Gelman
  - 2019-12-27
  - ''
  - ! '<p>In his post, Matthew Walker’s “Why We Sleep” Is Riddled with Scientific and Factual Errors” (see our discussions <a href="https://statmodeling.stat.columbia.edu/2019/11/18/is-matthew-walkers-why-we-sleep-riddled-with-scientific-and-factual-errors/">here</a>, <a href="https://statmodeling.stat.columbia.edu/2019/11/24/why-we-sleep-update-some-thoughts-while-we-wait-for-matthew-walker-to-respond-to-alexey-guzeys-criticisms/">here</a>, and <a href="https://statmodeling.stat.columbia.edu/2019/12/26/whassup-with-why-we-sleep/">here</a>), Alexey Guzey added the following <a href="https://guzey.com/books/why-we-sleep/#appendix-what-do-you-do-when-a-part-of-the-graph-contradicts-your-argument-you-cut-it-out-of-course">stunner</a>:</p><p><img src="https://statmodeling.stat.columbia.edu/wp-content/uploads/2019/12/Screen-Shot-2019-12-27-at-8.18.51-AM.png" alt="" width="550" /></p><p>We’ve left “super-important researcher too busy to respond to picky comments” territory and left “well-intentioned but sloppy researcher can’t keep track of citations” territory and entered “research misconduct” territory.</p><p>…This seems like a good time to revisit that Dan Davies <a href="https://blog.danieldavies.com/2004_05_23_d-squareddigest_archive.html">line</a>:</p><blockquote><p>Good ideas do not need lots of lies told about them in order to gain public acceptance.</p></blockquote>'
- - https://statmodeling.stat.columbia.edu/2019/12/26/whassup-with-why-we-sleep/
  - "Whassup with <em>Why We Sleep</em>?"
  - Andrew Gelman
  - 2019-12-26
  - ''
  - ! '<p>Last month <a href="https://statmodeling.stat.columbia.edu/2019/11/18/is-matthew-walkers-why-we-sleep-riddled-with-scientific-and-factual-errors/">we reported</a> on the book Why We Sleep, which had been dismantled in a <a href="https://guzey.com/books/why-we-sleep/">long and detailed blog post</a> by Alexey Guzey. A week later I looked again, and Walker had not responded to Guzey in any way. In the meantime, Why We Sleep has also been <a href="https://www.gatesnotes.com/About-Bill-Gates/Holiday-Books-2019">endorsed</a> by O.G. software entrepreneur Bill Gates. Programmers typically have lots of personal experience of sleep deprivation, so this is a topic close to their hearts.</p><p>As of this writing, it seems that Walker still has not responded to most of the points Guzey made about errors in his book. The closest thing I can find is <a href="https://sleepdiplomat.wordpress.com">this post</a> dated 19 Dec 2019, titled “Why We Sleep: Responses to questions from readers.” The post is on a site called On Sleep that appears to have been recently set up—I say this because I see no internet record of it, and it currently has just this one post. I’m not trying to be some sort of sleuth here, I’m just trying to figure out what’s going on. For now, I’ll assume that this post is written by Walker.</p><p>The post begins:</p><blockquote><p>The aim of the book, Why We Sleep, is to provide the general public access to a broad collection of sleep research. Below, I address thoughtful questions that have been raised regarding the book and its content in <a href="https://bookmarks.reviews/reviews/all/why-we-sleep/">reviews</a>, <a href="https://bookmarks.reviews/reviews/all/why-we-sleep/">online</a> forums and direct emails that I have received. Related, I very much appreciate being made aware of any errors in the book requiring revision. I see this as a key part of good scholarship. Necessary corrections will be made in future editions.</p></blockquote><p>The first link above goes to a page of newspaper and magazine reviews, and the second link goes to Guzey’s post. I didn’t really see any questions raised regarding the book in those newspaper and magazine reviews, so I’m guessing that the “thoughtful questions” that Walker is referring to are coming entirely, or nearly entirely, from Guzey. It seems odd for Walker to cite “online forums” and only link to one of them. Also, although Walker links to Guzey, he does not address the specific criticisms Guzey made of his book.</p><p>…Based on his book and his Ted talk, it seems that Walker has a message to send, and he doesn’t care much about the details. He’s sloppy with sourcing, gets a lot wrong, and has not responded well to criticism.</p><p>But this does not mean we should necessarily dismiss his message. Ultimately his claims need to be addressed on their merits.</p>'
- - https://statmodeling.stat.columbia.edu/2019/11/24/why-we-sleep-update-some-thoughts-while-we-wait-for-matthew-walker-to-respond-to-alexey-guzeys-criticisms/
  - '<em>Why We Sleep</em> update: some thoughts while we wait for Matthew Walker to respond to Alexey Guzey’s criticisms'
  - Andrew Gelman
  - 2019-11-24
  - ''
  - '<p>So. It’s been a week since Alexey Guzey posted his wonderfully-titled article, “Matthew Walker’s ‘Why We Sleep’ Is Riddled with Scientific and Factual Errors.”…As of this writing, the ball remains in Walker’s court.</p><p>I googled <em>”matthew walker” “alexey guzey”</em> and <em>”matthew walker” sleep</em> and a few other things, but nowhere did I find any response from Walker to Guzey’s criticisms.</p><p>It’s hard for me to imagine that Walker hasn’t heard about Guzey’s article by now, but I guess it’s possible that he (Walker) is on vacation or that he’s preparing a response but has not finished yet….While we’re waiting for Walker to respond, I had a few more thoughts:</p><ol type="1"><li>A few years ago, if someone were to claim that a celebrated professor of neuroscience and psychology at a major university had published a book on his own field of expertise, and the book was full of scientific and factual errors, that would’ve been a major scandal, no? But now, we’re like, yeah, sure, that’s just more same old same old. As the saying goes, the big scandal is how little a scandal this has been.</li><li>What would be really cool would be if NPR and Joe Rogan ran interviews with Alexey Guzey about this story. NPR probably won’t bite. But Joe Rogan . . . he might go for this, right? I bet Joe Rogan, or someone on his team, reads social media. And Rogan likes combat. He’s had Walker on his show, now time to have Guzey come in with the critique. That said, I don’t know that a podcast is the best format for such a debate. I think blogging is a better way to go, as then there’s enough space to lay out all the evidence.</li><li>Assuming Guzey’s criticisms hold up, I’m still trying to figure out what happened with that book. How could Walker introduce <em>so many</em> errors on his own area of expertise (or, I guess I should say, supposed expertise)? Was he just really really confused? Did he delegate the research and writing to lazy research assistants? Did he feel that his underlying story was important so the details didn’t matter? Did he conduct his research by putting all his notes onto index cards, then mistype material off the cards? I just don’t have a good way of thinking about these things.</li><li>Guzey’s article is careful and in many ways bulletproof: he backs up each of his statements, he doesn’t exaggerate (even for humorous purposes), and nobody seems to have found any mistakes in what he wrote. In addition, Guzey has gone on the web and responded to comments: where people claim he got things wrong, he has responded in detail.</li></ol><p>This is excellent behavior on Guzey’s part but I just want to say that it should not be <em>required</em>. Suppose, just for the sake of argument, that Guzey was gratuitously rude, that he made some claims without making his the evidence clear, even that he made some mistakes. Suppose that he spent 13 hours or even 1.3 hours rather than 130 hours writing this post, so that he only got to the highlights and didn’t carefully check everything he wrote? That would be unfortunate, <em>but it wouldn’t make his critique less valid.</em></p><p>What I’m saying is: by preparing a critique that’s clean, clear, well sourced, well written—actually enjoyable to read—, a critique that doesn’t make any questionable claims, by being so careful, Guzey has done us a favor. He’s made it easier to follow what he’s written, and he’s making it more difficult for someone to dismiss his arguments on superficial grounds. He’s raising the game, and that’s wonderful.</p><p>But if Guzey hadn’t gone to that trouble, he could still be making a useful contribution. It would just be the duty of Walker to extract that contribution.</p>'
- - https://statmodeling.stat.columbia.edu/2019/11/18/is-matthew-walkers-why-we-sleep-riddled-with-scientific-and-factual-errors/
  - 'Is Matthew Walker’s <em>Why We Sleep</em> Riddled with Scientific and Factual Errors?'
  - Andrew Gelman
  - 2019-11-18
  - ''
  - ! '<p>Asher Meir points to this hilarious post by Alexey Guzey entitled, <a href="https://guzey.com/books/why-we-sleep/">Matthew Walker’s “Why We Sleep” Is Riddled with Scientific and Factual Errors</a>.</p><p>Just to start with, the post has a wonderful descriptive title. And the laffs start right away:</p><p><img src="https://statmodeling.stat.columbia.edu/wp-content/uploads/2019/11/Screen-Shot-2019-11-17-at-9.37.25-PM.png" alt="" width="550" /></p><p>Positively Nabokovian, I’d say. I mean it. The above table of contents makes me want to read more.</p><p>I’ve not read Walker’s book and I don’t know anything about sleep research, so I won’t try to judge Guzey’s claims. I read through and I found Guzey’s arguments to be persuasive, but, hey, I’m easily persuaded.</p><p>I’d be happy to read a followup article by Michael Walker, “Alexey Guzey’s ‘Matthew Walker’s “Why We Sleep” Is Riddled with Scientific and Factual Errors’ Is Riddled with Scientific and Factual Errors.” That (hypothetical) post could completely turn me around! Then, of course, I’d be waiting for Guzey’s reply, “Michael Walker’s ‘Alexey Guzey’s “Matthew Walker’s ‘Why We Sleep’ Is Riddled with Scientific and Factual Errors” Is Riddled with Scientific and Factual Errors’ Is Riddled with Scientific and Factual Errors.” At that point, I’d probably have heard enough to have formed a firm opinion. Right now, the ball is totally in Walker’s court.</p><p>…Let me tell you a story. I went to graduate school at Harvard. Finest university in the world. My first day in a Harvard class, I was sitting with rapt attention, learning all sorts of interesting and important things (for reals; it was an amazing class that motivated me to become a statistician), sitting at one of those chairs with a desk attached to it, you know, the kind of chair where the desk part flips up so it’s in front of you, and, on the bottom of that desk was a wad of gum.</p><p>Back when I was in junior high, gum was almost a form of currency. I’d buy a pack of grape Bubble Yum for a quarter at the corner store on the way to school, then chew it in the morning during the endless hours between first period and lunch. I’d put one piece of gum in my mouth, chew it until it lost all its flavor, then add the second piece, chew it etc., and continue until I had a massive wad, all five pieces, ultimately flavorless, and I’d chew and chew and blow huge bubbles when the teacher wasn’t looking.</p><p>I’m not trying to make myself out into some big rebel here; the point is, we all did that. So of course there was yucky gum under all the desks. You knew to never run your hands under a desk, cos you never knew what might turn up. That was junior high.</p><p>Then in high school, everyone was much more mature, a lot less gum chewing . . . but still, gum under the desks. I took classes at the University of Maryland, a fine university with an OK basketball team . . . still, they had gum. Then I went to MIT, one of the finest engineering schools in the world . . . yup, gum. But Harvard? I’d hoped Harvard was better than that. But it wasn’t.</p><p>Anyway, that’s how I felt, learning that this purveyor of (possibly) horribly false claims is not just a professor of neuroscience at a top university—we know that top universities have lots of frauds—but was hired by Google. Google! Here I am, almost sixty years old (I don’t <em>feel</em> close to 60, but that’s my problem, not yours), and still there’s room for disillusionment.</p>'
- - https://guzey.com/books/why-we-sleep/
  - "Matthew Walker's <em>Why We Sleep</em> Is Riddled with Scientific and Factual Errors"
  - Alexey Guzey
  - 2019-11-15
  - ''
  - ! '<p>…In the process of reading the book and encountering some extraordinary claims about sleep, I decided to compare the facts it presented with the scientific literature. I found that the book consistently overstates the problem of lack of sleep, sometimes egregiously so. It misrepresents basic sleep research and contradicts its own sources.</p><p>In one instance, Walker claims that sleeping less than six or seven hours a night doubles one’s risk of cancer–this is not supported by the scientific evidence (Section 1.1). In another instance, Walker seems to have invented a “fact” that the WHO has declared a sleep loss epidemic (Section 4). In yet another instance, he falsely claims that the National Sleep Foundation recommends 8 hours of sleep per night, and then uses this “fact” to falsely claim that two-thirds of people in developed nations sleep less than the “the recommended eight hours of nightly sleep” (Section 5).</p><p>Walker’s book has likely wasted thousands of hours of life and worsened the health of people who read it and took its recommendations at face value (Section 7).</p><ul><li><ul><li><a href="https://guzey.com/books/why-we-sleep/#no-shorter-sleep-does-not-imply-shorter-life-span">No, shorter sleep does not imply shorter life span</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#also-no-sleeping-less-than-6-hours-a-night-does-not-double-your-risk-of-cancer">Also, no – sleeping less than 6 hours a night does not double your risk of cancer</a></li><li><a href="https://guzey.com/books/why-we-sleep/#how-much-confidence-should-we-place-in-epidemiological-sleep-data">How much confidence should we place in epidemiological sleep data?</a></li></ul></li><li><a href="https://guzey.com/books/why-we-sleep/#no-a-good-night-s-sleep-is-not-always-beneficial-sleep-deprivation-therapy-in-depression">No, a good night’s sleep is not always beneficial: sleep deprivation therapy in depression</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-lack-of-sleep-will-not-outright-kill-you">No, lack of sleep will not outright kill you</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-the-world-health-organization-never-declared-a-sleep-loss-epidemic">No, the World Health Organization never declared a sleep loss epidemic</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-two-thirds-of-adults-in-developed-nations-do-not-fail-to-obtain-the-recommended-amount-of-sleep">No, two-thirds of adults in developed nations do not fail to obtain the recommended amount of sleep</a></li><li><a href="https://guzey.com/books/why-we-sleep/#summary">Summary</a></li><li><a href="https://guzey.com/books/why-we-sleep/#the-potential-harm-done-by-the-book">The potential harm done by the book</a></li><li><a href="https://guzey.com/books/why-we-sleep/#conclusion">Conclusion</a></li><li><a href="https://guzey.com/books/why-we-sleep/#acknowledgements">Acknowledgements</a></li><li><a href="https://guzey.com/books/why-we-sleep/#citation">Citation</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-things-i-m-not-saying-in-this-essay">Appendix: things I’m <em>not</em> saying in this essay</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-people-who-sleep-just-6-hours-a-day-might-have-the-lowest-mortality">Appendix: people who sleep just 6 hours a day might have the lowest mortality</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-why-i-only-checked-chapter-1">Appendix: why I only checked Chapter 1</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-is-why-we-sleep-pop-science-or-is-it-an-academic-book-also-miscitations-impossible-numbers-and-walker-copy-pasting-papers">Appendix: is <em>Why We Sleep</em> pop-science or is it an academic book? Also, miscitations, impossible numbers, and Walker copy-pasting papers</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#three-papers-referring-to-why-we-sleep">Three papers referring to <em>Why We Sleep</em></a></li><li><a href="https://guzey.com/books/why-we-sleep/#two-papers-by-walker-citing-why-we-sleep">Two papers by Walker citing <em>Why We Sleep</em></a></li><li><a href="https://guzey.com/books/why-we-sleep/#walker-copy-pasting-papers">Walker copy-pasting papers</a></li><li><a href="https://guzey.com/books/why-we-sleep/#further-reading">Further reading</a></li></ul></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-common-objections">Appendix: common objections</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#walker-is-a-professor-of-psychology-and-neuroscience-at-berkeley-who-spent-more-than-20-years-studying-sleep-who-the-fuck-are-you">“Walker is a professor of psychology and neuroscience at Berkeley who spent more than 20 years studying sleep. Who the fuck are you?”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#the-mortality-sleep-j-curve-from-section-1-doesn-t-disprove-walker-s-the-shorter-your-sleep-the-shorter-your-life-span-first-the-association-between-long-sleep-and-short-life-span-is-generally-considered-to-reflect-underlying-comorbidities-that-prolong-time-in-bed-second-this-doesn-t-look-at-sleep-loss-or-sleep-extension-at-the-level-of-the-individual-person-and-if-you-look-at-the-individual-person-then-shorter-sleep-is-likely-to-be-associated-with-shorter-life">“The mortality/sleep J-curve from section 1 doesn’t disprove Walker’s ‘the shorter your sleep, the shorter your life span’. First, the association between long sleep and short life span is generally considered to reflect underlying comorbidities that prolong time in bed. Second, this doesn’t look at sleep loss or sleep extension at the level of the individual person and if you look at the individual person, then shorter sleep is likely to be associated with shorter life.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#only-checking-the-introduction-is-wrong-because-it-s-not-representative-of-the-rest-of-the-book-in-later-chapters-walker-is-much-more-rigorous">“Only checking the introduction is wrong because it’s not representative of the rest of the book. In later chapters, Walker is much more rigorous.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#but-don-t-many-people-get-8-9-hours-of-sleep-when-they-don-t-restrict-sleep">“But don’t many people get 8-9 hours of sleep when they don’t restrict sleep?”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#in-chapter-1-walker-writes-vehicular-accidents-caused-by-drowsy-driving-exceed-those-caused-by-alcohol-and-drugs-combined-this-shows-how-dangerous-it-is-to-not-sleep-and-you-have-not-refuted-this-part">“In Chapter 1, Walker writes ‘vehicular accidents caused by drowsy driving exceed those caused by alcohol and drugs combined’. This shows how dangerous it is to not sleep and you have not refuted this part.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#ok-maybe-sleep-and-longevity-are-not-positively-related-but-the-part-of-the-book-i-found-most-important-is-about-sleep-and-learning-for-example-in-chapter-7-walker-writes-that-a-memory-retention-benefit-of-between-20-and-40-percent-is-being-offered-by-sleep-this-shows-how-important-sleep-is-for-memory-and-you-have-not-refuted-this-part">“Ok, maybe sleep and longevity are not positively related, but the part of the book I found most important is about sleep and learning. For example, in Chapter 7, Walker writes that ‘a memory retention benefit of between 20 and 40 percent [is] being offered by sleep’. This shows how important sleep is for memory and you have not refuted this part.”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#in-chapter-15-walker-writes-that-after-a-thirty-hour-shift-without-sleep-residents-make-a-whopping-460-percent-more-diagnostic-mistakes-in-the-intensive-care-unit-than-when-well-rested-after-enough-sleep-this-shows-how-dangerous-it-is-to-not-sleep-and-you-have-not-refuted-this-part">“In Chapter 15, Walker writes that ‘after a thirty-hour shift without sleep, residents make a whopping 460 percent more diagnostic mistakes in the intensive care unit than when well rested after enough sleep’. This shows how dangerous it is to not sleep and you have not refuted this part.”</a></li></ul></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-my-personal-experience-with-sleep">Appendix: my personal experience with sleep</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-the-concrete-harm-done-by-the-book">Appendix: the concrete harm done by the book</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-what-do-you-do-when-a-part-of-the-graph-contradicts-your-argument-you-cut-it-out-of-course">Appendix: what do you do when a part of the graph contradicts your argument? You cut it out, of course</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-a-strong-contender-for-the-single-most-absurd-paragraph-in-the-book">Appendix: a strong contender for the single most absurd paragraph in the book</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-sleep-and-testicles-sleep-and-testosterone">Appendix: sleep and testicles; sleep and testosterone</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-where-did-walker-get-his-phd">Appendix: where did Walker get his PhD?</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-serious-problems-in-chapter-8-found-by-a-reader">Appendix: serious problems in Chapter 8 found by a reader</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix-fatal-familial-insomnia">Appendix: fatal familial insomnia</a></li><li><a href="https://guzey.com/books/why-we-sleep/#appendix">Appendix</a><ul><li><a href="https://guzey.com/books/why-we-sleep/#possible-origin-of-the-sleeplessness-epidemic-thing">Possible origin of the “sleeplessness epidemic” thing</a></li><li><a href="https://guzey.com/books/why-we-sleep/#what-you-can-learn-from-hunter-gatherers-sleeping-patterns">“What You Can Learn From Hunter-Gatherers’ Sleeping Patterns”</a></li><li><a href="https://guzey.com/books/why-we-sleep/#most-sleep-does-not-serve-a-vital-function-evidence-from-drosophila-melanogaster">Most sleep does not serve a vital function: Evidence from Drosophila melanogaster</a></li><li><a href="https://guzey.com/books/why-we-sleep/#no-not-every-living-creature-generates-a-circadian-rhythm">No, not every living creature generates a circadian rhythm</a></li><li><a href="https://guzey.com/books/why-we-sleep/#extended-quote-about-the-dangers-of-lack-sleep-from-chapter-1">Extended quote about the dangers of lack sleep from Chapter 1</a></li><li><a href="https://guzey.com/books/why-we-sleep/#the-full-discussion-of-sleep-deprivation-therapy-from-chapter-7">The full discussion of sleep deprivation therapy from Chapter 7</a></li></ul></li></ul></li></ul>'
- - https://guzey.com/
  - Alexey Guzey homepage
  - Alexy Guzey
  - ''
  - ''
  - ! '<p>I’m an independent researcher with background in Economics, Mathematics, and Cognitive Science. My biggest intellectual influences are <a href="https://guzey.com/favorite/slate-star-codex/">Scott Alexander</a>, <a href="https://guzey.com/favorite/media/#podcasts">Dan Carlin</a>, <a href="https://amzn.to/2MIaxRJ">Scott Adams</a>, and <a href="http://www.gwern.net/">Gwern</a>.</p><p>Right now, I think about <a href="https://guzey.com/how-life-sciences-actually-work/">meta-science, biology</a> and <a href="https://guzey.com/patronage-and-research-labs/">philanthropy</a>. My long-term goal is to make the future humane, aesthetic, and to make it happen faster.</p><p>You can contact me at <a href="mailto:alexey@guzey.com">alexey@guzey.com</a> or via <a href="https://twitter.com/alexeyguzey">Twitter</a>, <a href="https://t.me/alexeyguzey">Telegram</a>, <a href="https://facebook.com/alexeyguzey">Facebook</a> or <a href="https://vk.com/alexeyguzey">VK</a></p>'
- - http://www.snowcrystals.com/
  - SnowCrystals.com
  - Kenneth G. Libbrecht
  - 1999-02-01
  - ''
  - ! 'Welcome to SnowCrystals.com! Your online guide to snowflakes, snow crystals, and other ice phenomena. SnowCrystals.com has been bringing you snowflake photos and facts since February 1, 1999. Over 26 million visitors so far! [Photos / books / science; designer snowflakes, how to grow snowflakes, "identical-twin" snowflakes etc]'
- - https://colab.research.google.com/github/nickwalton/AIDungeon/blob/master/AIDungeon_2.ipynb
  - AI Dungeon 2 Colab notebook
  - Nick Walton
  - 2019-12-14
  - ''
  - ! '<blockquote><p>AI Dungeon 2 is a completely AI generated text adventure built with OpenAI’s largest GPT-2 model. It’s a first of its kind game that allows you to enter and will react to any action you can imagine.</p></blockquote><p><em>What is this?</em></p><p>Google Colab is a way to experience machine learning for free. Google provides GPUs that you can run code in. Because this game exploded however, Google likely won’t be able to allow free usage of it for AI Dungeon for very long. We are almost done making an app version of the game where you will be able to play AI Dungeon 2. Until that’s released you can still play the game here.</p><p><em>Main mirrors of AI Dungeon 2 are currently down due to high download costs.</em></p><p>We are using BitTorrent as a temporary solution to host game files and keep this game alive. It’s not fast, but it’s the best we’ve got right now.</p><p>If you want to help, best thing you can do is to download this torrent file with game files and seed it indefinitely to the best of your ability. This will help new players download this game faster, and discover the vast worlds of AI Dungeon 2!</p><ul><li>Follow <span class="citation" data-cites="nickwalton00">[@nickwalton00]</span>(https://twitter.com/nickwalton00) on Twitter for updates on when it will be available again.</li><li><a href="https://www.patreon.com/AIDungeon">Support AI Dungeon 2 on Patreon</a> to help me to continue improving the game with all the awesome ideas I have for its future!</li></ul><p>How to play</p><ol type="1"><li>Click “Tools”-&gt; “Settings…” -&gt; “Theme” -&gt; “Dark” (optional but recommended)</li><li>Go to <strong>Main Game</strong> section below</li><li>Run Install block</li><li>Run Download Model block</li><li>It will then take a couple minutes to boot up as the model is downloaded loaded onto the GPU.</li><li>Run the game block</li><li>If you have questions about getting it to work then please go to github repo to get help.</li></ol>'
- - https://news.yahoo.com/shattered-inside-the-secret-battle-to-save-americas-undercover-spies-in-the-digital-age-100029026.html
  - "'Shattered': Inside the secret battle to save America's undercover spies in the digital age"
  - Jenna McLaughlin, Zach Dorfman (Yahoo News)
  - 2019-12-30
  - ''
  - ! '[Wide-ranging review of how social media, government database hacks, personal genomics, open-source intelligence, and pervasive surveillance are destroying traditional espionage, as undercover agents are unable to enter countries or recruit sources without being instantly exposed, forcing ever greater reliance on signals intelligence/hacking. Failures in OPSEC have resulted in entire countries going dark and the exposure of multiple US espionage networks and execution of sources, as well as embarassing many countries when organizations like Bellingcat are able to expose agents and operations. While agencies like the FBI and CIA have begun adapting to the new reality, they have a long way to go, and countries like Russia or China or North Korea will only become harder to penerate and obtain intelligence on.]'
- - /Turing-complete#how-many-computers-are-in-your-computer
  - "How Many Computers Are In Your Computer?"
  - Gwern Branwen
  - 2018-01-29
  - ''
  - ! '<p>Why are there so many places for backdoors and weird machines in your “computer”? Because your computer is in fact scores or hundreds, perhaps even thousands, of computer chips, many of which are explicitly or implicitly capable of Turing-complete computations (many more powerful than desktops of bygone eras), working together to create the illusion of a single computer. Backdoors, bugs, weird machines, and security do not care about what you think—only where resources can be found and orchestrated into a computation.</p>'
- - /Replication#further-reading
  - "The Replication Crisis: Further Reading"
  - Gwern Branwen
  - 2019-12-06
  - ''
  - ! '[A bibliography of online links to papers/blogs/articles on the Replication Crisis, primarily post-2013 and curated from my newsletter, as a followup to the main article text describing the Replication Crisis.]'
- - /docs/statistics/bias/1976-rosenthal-experimenterexpectancyeffects.pdf
  - "Experimenter Effects in Behavioral Research: Enlarged Edition"
  - Robert Rosenthal
  - '1976'
  - ''
  - ! '<p>Within the context of a general discussion of the unintended effects of scientists on the results of their research, this work reported on the growing evidence that the hypothesis of the behavioral scientist could come to serve as self-fulfilling prophecy, by means of subtle processes of communication between the experimenter and the human or animal research subject. [The <em>Science Citation Index</em> (<em>SCI</em>) and the <em>Social Sciences Citation Index</em> (<em>SSCI</em>) indicate that the book has been cited over 740 times since 1966 [as of 1979].] —<a href="http://garfield.library.upenn.edu/classics1979/A1979HZ32400001.pdf" title="CC/Number 27, 2 July 1979: This Week&#39;s Citation Classic">“Citation Classic”</a></p> [Enlarged Edition, expanded with discussion of the Pygmalion effect etc: ISBN 0-470-01391-5]'
- - https://www.oreilly.com/ideas/piracy-is-progressive-taxation-and-other-thoughts-on-the-evolution-of-online-distribution
  - "Piracy is progressive taxation, and other thoughts on the evolution of online distribution: Seven lessons from Tim O’Reilly’s experience as an author and publisher"
  - "Tim O'Reilly"
  - 2002-12-11
  - ''
  - ! '<p>The continuing controversy over online file sharing sparks me to offer a few thoughts as an author and publisher. To be sure, I write and publish neither movies nor music, but books. But I think that some of the lessons of my experience still apply.</p><ol type="1"><li><p><strong>Lesson 1: Obscurity is a far greater threat to authors and creative artists than piracy.</strong></p><p>…More than 100,000 books are published each year, with several million books in print, yet fewer than 10,000 of those new books have any significant sales, and only a hundred thousand or so of all the books in print are carried in even the largest stores…The web has been a boon for readers, since it makes it easier to spread book recommendations and to purchase the books once you hear about them. But even then, few books survive their first year or two in print. Empty the warehouses and you couldn’t give many of them away…</p></li><li><p><strong>Lesson 2: Piracy is progressive taxation</strong></p><p>For all of these creative artists, most laboring in obscurity, being well-enough known to be pirated would be a crowning achievement. Piracy is a kind of progressive taxation, which may shave a few percentage points off the sales of well-known artists (and I say “may” because even that point is not proven), in exchange for massive benefits to the far greater number for whom exposure may lead to increased revenues….</p></li><li><p><strong>Lesson 3: Customers want to do the right thing, if they can.</strong></p><p>…We’ve found little or no abatement of sales of printed books that are also available for sale online…The simplest way to get customers to stop trading illicit digital copies of music and movies is to give those customers a legitimate alternative, at a fair price.</p></li><li><p><strong>Lesson 4: Shoplifting is a bigger threat than piracy.</strong></p><p>…What we have is a problem that is analogous, at best, to shoplifting, an annoying cost of doing business. And overall, as a book publisher who also makes many of our books available in electronic form, we rate the piracy problem as somewhere below shoplifting as a tax on our revenues. Consistent with my observation that obscurity is a greater danger than piracy, shoplifting of a single copy can lead to lost sales of many more. If a bookstore has only one copy of your book, or a music store one copy of your CD, a shoplifted copy essentially makes it disappear from the next potential buyer’s field of possibility. Because the store’s inventory control system says the product hasn’t been sold, it may not be reordered for weeks or months, perhaps not at all. I have many times asked a bookstore why they didn’t have copies of one of my books, only to be told, after a quick look at the inventory control system: “But we do. It says we still have one copy in stock, and it hasn’t sold in months, so we see no need to reorder.” It takes some prodding to force the point that perhaps it hasn’t sold because it is no longer on the shelf…</p></li><li><p><strong>Lesson 5: File sharing networks don’t threaten book, music, or film publishing. They threaten existing publishers.</strong></p><p>…The question before us is not whether technologies such as peer-to-peer file sharing will undermine the role of the creative artist or the publisher, but how creative artists can leverage new technologies to increase the visibility of their work. For publishers, the question is whether they will understand how to perform their role in the new medium before someone else does. Publishing is an ecological niche; new publishers will rush in to fill it if the old ones fail to do so…Over time, it may be that online music publishing services will replace CDs and other physical distribution media, much as recorded music relegated sheet music publishers to a niche and, for many, made household pianos a nostalgic affectation rather than the home entertainment center. But the role of the artist and the music publisher will remain. The question then, is not the death of book publishing, music publishing, or film production, but rather one of who will be the publishers.</p></li><li><p><strong>Lesson 6: “Free” is eventually replaced by a higher-quality paid service</strong></p><p>A question for my readers: How many of you still get your email via peer-to-peer UUCP dialups or the old “free” Internet, and how many of you pay $19.95 a month or more to an ISP? How many of you watch “free” television over the airwaves, and how many of you pay $20–$60 a month for cable or satellite television? (Not to mention continue to rent movies on videotape and DVD, and purchasing physical copies of your favorites.) Services like Kazaa flourish in the absence of competitive alternatives. I confidently predict that once the music industry provides a service that provides access to all the same songs, freedom from onerous copy-restriction, more accurate metadata and other added value, there will be hundreds of millions of paying subscribers…Another lesson from television is that people prefer subscriptions to pay-per-view, except for very special events. What’s more, they prefer subscriptions to larger collections of content, rather than single channels. So, people subscribe to “the movie package,” “the sports package” and so on. The recording industry’s “per song” trial balloons may work, but I predict that in the long term, an “all-you-can-eat” monthly subscription service (perhaps segmented by musical genre) will prevail in the marketplace.</p></li><li><p><strong>Lesson 7: There’s more than one way to do it.</strong></p><p>A study of other media marketplaces shows, though, that there is no single silver-bullet solution. A smart company maximizes revenue through all its channels, realizing that its real opportunity comes when it serves the customer who ultimately pays its bills….Interestingly, some of our most successful print/online hybrids have come about where we present the same material in different ways for the print and online contexts. For example, much of the content of our bestselling book Programming Perl (more than 600,000 copies in print) is available online as part of the standard Perl documentation. But the entire package–not to mention the convenience of a paper copy, and the aesthetic pleasure of the strongly branded packaging–is only available in print. Multiple ways to present the same information and the same product increase the overall size and richness of the market. And that’s the ultimate lesson. “Give the wookie what he wants!” as Han Solo said so memorably in the first <em>Star Wars</em> movie. Give it to him in as many ways as you can find, at a fair price, and let him choose which works best for him.</p></li></ol>'
- - /docs/psychology/okcupid/themathematicsofbeauty.html
  - The Mathematics Of Beauty
  - Christian Rudder (OKCupid)
  - 2011-01-10
  - ''
  - ! '<p>[Today’s dataset: 1.54m votes, 596k messages, 64k profiles.]</p><p>This post investigates female attractiveness, but without the usual photo analysis stuff. Instead, we look <em>past</em> a woman’s picture, into the reaction she creates in the reptile mind of the human male. Among the remarkable things we’ll show:</p><ul><li>that the more men as a group <em>disagree</em> about a woman’s looks, the more they end up liking her</li><li>guys tend to ignore girls who are merely <em>cute</em></li><li>and, in fact, having some men think she’s <em>ugly</em> actually works in woman’s favor</li></ul><p>…Now let’s look back at the two real users from before, this time with their own graphs. OkCupid uses a <em>1 to 5 star</em> system for rating people, so the rest of our discussion will be in those terms. All the users pictured were generous and confident enough to allow us to dissect their experience on our site, and we appreciate it. Okay, so we have: […] As you can see, though the average attractiveness for the two women above is very close, their vote patterns differ. On the left you have consensus, and on the right you have split opinion.</p><p>To put a fine point on it:</p><ul><li>Ms. Left is, in an absolute sense, considered slightly <em>more attractive</em></li><li>Ms. Right was also given the <em>lowest rating</em> 142% more often</li><li>yet Ms. Right gets <em>3×</em> as many messages</li></ul><p>When we began pairing other people of similar looks and profiles, but different message outcomes, this pattern presented itself again and again. The less-messaged woman was usually considered <em>consistently attractive</em>, while the more-messaged woman often created <em>variation</em> in male opinion…Our first result was to compare the standard deviation of a woman’s votes to the messages she gets. The more men disagree about a woman’s looks, the more they like her. I’ve plotted the deviation vs. messages curve below, again including some examples…</p>'
- - http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/
  - "Goodbooks-10k: a new dataset for book recommendations"
  - Zygmunt Z. (FastML)
  - 2017-11-29
  - ''
  - ! '<p>There have been a few recommendations datasets for movies (Netflix, Movielens) and music (Million Songs), but not for books. That is, until now. The dataset contains six million ratings for ten thousand most popular books (with most ratings). There are also:</p><ul><li>books marked to read by the users</li><li>book metadata (author, year, etc.)</li><li>tags/shelves/genres</li></ul><p>As to the source, let’s say that these ratings come from a site similar to <code>goodreads.com</code>, but with more permissive terms of use. There are a few types of data here:</p><ul><li>explicit ratings</li><li>implicit feedback indicators (books marked to read)</li><li>tabular data (book info)</li><li>tags</li></ul><p>…<a href="https://github.com/zygmuntz/goodbooks-10k">All files</a> are available on GitHub. Some of them are quite large, so GitHub won’t show their contents online. See <a href="https://github.com/zygmuntz/goodbooks-10k/tree/master/samples">samples</a> for smaller CSV snippets. You can download individual zipped files from <a href="https://github.com/zygmuntz/goodbooks-10k/releases">releases</a>.</p>'
- - https://github.com/zygmuntz/goodbooks-10k
  - "<code>goodbooks-10k</code>: Ten thousand books, six million ratings: http://fastml.com/goodbooks-10k"
  - Zygmunt Z. (FastML)
  - 2017-11-29
  - ''
  - ! '<h1 id="goodbooks-10k">goodbooks-10k</h1><p>This dataset contains six million ratings for ten thousand most popular (with most ratings) books. There are also:</p><ul><li>books marked to read by the users</li><li>book metadata (author, year, etc.)</li><li>tags/shelves/genres</li></ul><h2 id="access">Access</h2><p>Some of these files are quite large, so GitHub won’t show their contents online. See <a href="https://github.com/zygmuntz/goodbooks-10k/samples/">samples/</a> for smaller CSV snippets.</p><p>Open the <a href="https://github.com/zygmuntz/goodbooks-10k/quick_look.ipynb">notebook</a> for a quick look at the data. Download individual zipped files from <a href="https://github.com/zygmuntz/goodbooks-10k/releases">releases</a>.</p><p>The dataset is accessible from <a href="https://maciejkula.github.io/spotlight/datasets/goodbooks.html">Spotlight</a>, recommender software based on PyTorch.</p><h2 id="contents">Contents</h2><p><strong>ratings.csv</strong> contains ratings sorted by time. It is 69MB and looks like that:</p><pre><code>user_id,book_id,rating1,258,52,4081,42,260,52,9296,52,2318,3</code></pre><p>Ratings go from one to five. Both book IDs and user IDs are contiguous. For books, they are 1-10000, for users, 1-53424.</p><p><strong>to_read.csv</strong> provides IDs of the books marked “to read” by each user, as <em>user_id,book_id</em> pairs, sorted by time. There are close to a million pairs.</p><p><strong>books.csv</strong> has metadata for each book (goodreads IDs, authors, title, average rating, etc.). The metadata have been extracted from goodreads XML files, available in <code>books_xml</code>.</p><h3 id="tags">Tags</h3><p><strong>book_tags.csv</strong> contains tags/shelves/genres assigned by users to books. Tags in this file are represented by their IDs. They are sorted by <em>goodreads_book_id</em> ascending and <em>count</em> descending.</p><p>In raw XML files, tags look like this:</p><pre><code>&lt;popular_shelves&gt;    &lt;shelf name=&quot;science-fiction&quot; count=&quot;833&quot;/&gt;    &lt;shelf name=&quot;fantasy&quot; count=&quot;543&quot;/&gt;    &lt;shelf name=&quot;sci-fi&quot; count=&quot;542&quot;/&gt;    ...    &lt;shelf name=&quot;for-fun&quot; count=&quot;8&quot;/&gt;    &lt;shelf name=&quot;all-time-favorites&quot; count=&quot;8&quot;/&gt;    &lt;shelf name=&quot;science-fiction-and-fantasy&quot; count=&quot;7&quot;/&gt;&lt;/popular_shelves&gt;</code></pre><p>Here, each tag/shelf is given an ID. <strong>tags.csv</strong> translates tag IDs to names.</p><h3 id="goodreads-ids">goodreads IDs</h3><p>Each book may have many editions. <em>goodreads_book_id</em> and <em>best_book_id</em> generally point to the most popular edition of a given book, while goodreads <em>work_id</em> refers to the book in the abstract sense.</p><p>You can use the goodreads book and work IDs to create URLs as follows:</p><pre><code>https://www.goodreads.com/book/show/2767052https://www.goodreads.com/work/editions/2792775</code></pre><p>Note that <em>book_id</em> in <strong>ratings.csv</strong> and <strong>to_read.csv</strong> maps to <em>work_id</em>, not to <em>goodreads_book_id</em>, meaning that ratings for different editions are aggregated.</p>'
- - https://ukiyo-e.org/
  - Ukiyo-e Search
  - John Resig
  - '2013'
  - ''
  - ! '<p>"Japanese Woodblock Print Search: Ukiyo-e Search provides an incredible resource: The ability to both search for Japanese woodblock prints by simply taking a picture of an existing print AND the ability to see similar prints across multiple collections of prints.</p><p>…The Ukiyo-e.org database and image similarity analysis engine, created by <a href="https://johnresig.com/about/">John Resig</a> to aide researchers in the study of Japanese woodblock prints, was launched in December 2012. The database currently contains over 213,000 prints from 24 institutions and, as of September 2013, has received 3.4 million page views from 150,000 people.</p><p>The database has the following major features:</p><ul><li>A database of Japanese woodblock print images and metadata aggregated from a variety of museums, universities, libraries, auction houses, and dealers around the world.</li><li>An indexed text search engine of all the metadata provided by the institutions about the prints.</li><li>An image search engine of all the images in the database, searchable by uploading an image of a print.</li><li>Each print image is analyzed and compared against all other print images in the database. Similar prints are displayed together for comparison and analysis.</li><li>Multiple copies of the same print are automatically lined up with each other and made viewable in a gallery for easy comparison.</li><li>The entire web site, and all artist information contained within it, is available in both English and Japanese, aiding international researchers.</li></ul><p>These features, available in the Ukiyo-e.org database, are already providing researchers with substantial benefit. New copies of prints have been located by scholars at museums. Museums have been able to correct unattributed prints, finding the correct artist. Prints have been identified by lay people who cannot read Japanese and/or are unable to interpret the imagery depicted in a print.</p><p>It is challenging to reconcile information from numerous databases, many of which are in different languages. The difficulty of finding and utilizing an effective image similarity search engine, one that is capable of working with images of different sizes, colors, or even in black-and-white, is a point that deserves considerable attention.</p><p>The Ukiyo-e.org database is already significantly impacting Japanese woodblock print studies and may have implications for visual art research and digital humanities at large.</p>'
- - https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/
  - "A Very Unlikely Chess Game"
  - Scott Alexander
  - 2020-01-06
  - ''
  - ! '<p>Black is GPT-2. Its excuse is that it’s a text prediction program with no concept of chess. As far as it knows, it’s trying to predict short alphanumeric strings like “e2e4” or “Nb7”. Nobody told it this represents a board game. It doesn’t even have a concept of 2D space that it could use to understand such a claim. But it still captured my rook! Embarrassing! … Last month, I asked him if he thought GPT-2 could play chess. I wondered if he could train it on a corpus of chess games written in standard notation (where, for example, e2e4 means “move the pawn at square e2 to square e4”). There are literally millions of games written up like this. GPT-2 would learn to predict the next string of text, which would correspond to the next move in the chess game. Then you would prompt it with a chessboard up to a certain point, and it would predict how the chess masters who had produced its training data would continue the game – ie make its next move using the same heuristics they would. Gwern handed the idea to his collaborator Shawn Presser, who had a working GPT-2 chess engine running <em>within</em> a week: … You can play against GPT-2 yourself by following the directions in the last tweet, though it won’t be much of a challenge for anyone better than I am.</p><p>…What does this imply? I’m not sure (and maybe it will imply more if someone manages to make it actually good). It was already weird to see something with no auditory qualia learn passable poetic meter. It’s even weirder to see something with no concept of space learn to play chess. Is any of this <a href="https://slatestarcodex.com/2019/02/28/meaningful/">meaningful</a>? How impressed should we be that the same AI can write poems, compose music, and play chess, without having been designed for any of those tasks? I still don’t know.</p>'
- - https://foundational-research.org/files/Multiverse-wide-Cooperation-via-Correlated-Decision-Making.pdf
  - Multiverse-wide Cooperation via Correlated Decision Making
  - Caspar Oesterheld
  - 2018-01-29
  - ''
  - ! 'Some decision theorists argue that when playing a prisoner’s dilemma-type game against a sufficiently similar opponent, we should cooperate to make it more likely that our opponent also cooperates. This idea, which Hofstadter calls superrationality, has strong implications when combined with the insight from modern physics that we probably live in a large universe or multiverse of some sort. If we care about what happens in civilizations located elsewhere in the multiverse, we can superrationally cooperate with some of their inhabitants. That is, if we take their values into account, this makes it more likely that they do the same for us. In this paper, I attempt to assess the practical implications of this idea. I argue that to reap the full gains from trade, everyone should maximize the same impartially weighted sum of the utility functions of all collaborators. I also argue that we can obtain at least weak evidence about the content of these utility functions. In practice, the application of superrationality implies that we should promote causal cooperation, moral pluralism, moral reflection, and ensure that our descendants, who will be smarter and thus better at finding out how to benefit other superrationalists in the universe, engage in superrational cooperation.'
- - https://possiblywrong.wordpress.com/2019/04/06/follow-up-i-found-two-identical-packs-of-skittles-among-468-packs-with-a-total-of-27740-skittles/
  - "Follow-up: I found two identical packs of Skittles, among 468 packs with a total of 27,740 Skittles"
  -  E.R. Farmer
  - 2019-04-06
  - ''
  - ! '<p>This is a follow-up to <a href="https://possiblywrong.wordpress.com/2019/01/09/identical-packs-of-skittles/" title="Identical packs of Skittles">a post from earlier this year</a> discussing the likelihood of encountering two identical packs of Skittles, that is, two packs having exactly the same number of candies of each flavor. Under some reasonable assumptions, it was estimated that we should expect to have to inspect “only about 400-500 packs” on average until encountering a first duplicate. This is interesting, because as described in that earlier post, there are millions of different possible packs– or even if we discount those that are much less likely to occur (like, say, a pack of nothing but red Skittles), then there are still hundreds of thousands of different “likely” packs that we might expect to encounter.</p><p>So, on 12 January of this year, I started buying boxes of packs of Skittles. This past week, “only” 82 days, 13 boxes, 468 packs, and 27,740 individual Skittles later, I found the following identical 2.17-ounce packs.</p><p>…this seemed like a great opportunity to demonstrate the <em>predictive power</em> of mathematics. A few months ago, we did some calculations on a cocktail napkin, so to speak, <em>predicting</em> that we should be able to find a pair of identical packs of Skittles with a reasonably–and perhaps surprisingly–small amount of effort. Actually seeing that effort through to the finish line can be a vivid demonstration for students of this predictive power of what might otherwise be viewed as “merely abstract” and not concretely useful mathematics.</p>'
- - /docs/philo/1969-west.pdf
  - An Atomist Illustration In Aristotle
  - Martin L. West
  - '1969'
  - 10.1524/phil.1969.113.12.150
  - ! '<p>[Textual criticism of translations/interpretations of <a href="http://classics.mit.edu/Aristotle/gener_corr.1.i.html">a Democritus passage in Aristotle</a>. West argues that the translation of a passage generally translated as the generic observation</p><blockquote><p>Tragedy and comedy come out of the same letters.</p></blockquote><p>or the more abstract observation</p><blockquote><p>Tragedy and Comedy come out of the same letters.</p></blockquote><p>should be read as Democritus engaged in word play:</p><blockquote><p>For ‘Tragedy’ [<em>τρ<strong>α</strong>γωδία</em>] and ‘Comedy’ [<em>τρ<strong>υ</strong>γωδία</em>] come to be out of the same letters.</p></blockquote><p>Because the surrounding passage in Aristotle strongly implies that Democritus is defending the position that small changes (in atoms) can yield large changes (in observed appearance or behavior or property), in the same way that a word can alter its meaning completely based on a single letter (emphasis added):</p><blockquote><p>A similar criticism applies to all our predecessors with the single exception of Democritus. Not one of them penetrated below the surface or made a thorough examination of a single one of the problems. Democritus, however, does seem not only to have thought carefully about all the problems, but also to be distinguished from the outset by his method. For, as we are saying, none of the other philosophers made any definite statement about growth, except such as any amateur might have made. They said that things grow ‘by the accession of like to like’, but they did not proceed to explain the manner of this accession. Nor did they give any account of ‘combination’: and they neglected almost every single one of the remaining problems, offering no explanation, e.g. of ‘action’ or ‘passion’ how in physical actions one thing acts and the other undergoes action. Democritus and Leucippus, however, postulate the ‘figures’, and make ‘alteration’ and coming-to-be result from them. They explain coming-to-be and passing-away by their ‘dissociation’ and ‘association’, but ‘alteration’ by their ‘grouping’ and ‘Position’. And since they thought that the ‘truth lay in the appearance, and the appearances are conflicting and infinitely many, they made the ’figures’ infinite in number. <em>Hence—owing to the changes of the compound—the same thing seems different and conflicting to different people: it is ‘transposed’ by a small additional ingredient, and appears utterly other by the ‘transposition’ of a <strong>single</strong> constituent.</em> [For Tragedy and Comedy are both composed of the same letters.]</p></blockquote><p>West states that if Democritus had not intended this wordplay, he would have used other terms for ‘tragedy’ and ‘comedy’. Hence not using his alternative reading and translation renders the passage ‘unintelligble’.]</p>'
- - /Scanners#citogenesis-how-often-do-researchers-not-read-the-papers-they-cite
  - "How often do researchers not read the papers they cite?"
  - Gwern Branwen
  - 2019-10-07
  - ''
  - ! 'One fertile source of leprechauns seems to be the observation that researchers do not read many of the papers that they cite in their own papers. The frequency of this can be inferred from pre-digital papers, based on bibliographic errors: if a citation has mistakes in it, such that one could not have actually looked up the paper in a library or database, and those mistakes were copied from another paper, then the authors almost certainly did not read the paper (otherwise they would have fixed the mistakes when they found them out the hard way) and simply copied the citation. The empirically-measured spread of bibliographic errors suggest that researchers frequently do not read the papers they cite. The frequency can be further confirmed by examining citations to see when the citers misdescribe the original paper, "quotation errors", showing that the errors involved are substantial and not merely bibliographic.'
- - https://www.lesswrong.com/posts/NkjPp86uuyunxDoB8/subscripting-typographic-convention-for-citations-dates
  - "Subscripting Typographic Convention For Citations/Dates/Sources/Evidentials: A Proposal"
  - Gwern Branwen
  - 2020-01-08
  - ''
  - ! '<p>Reviving an old General Semantics proposal: borrowing from scientific notation and using subscripts like ‘Gwern<sub>2020</sub>’ for denoting sources (like citation, timing, or medium) might be a useful trick for clearer writing, compared to omitting such information or using standard cumbersome circumlocutions.</p>'
- - https://www.tandfonline.com/doi/full/10.1080/10510974.2019.1692884
  - "What’s in a Font?: Ideological Perceptions of Typography"
  - Katherine Haenschen, Daniel J. Tamul
  - 2019-12-20
  - '10.1080/10510974.2019.1692884'
  - ! 'Although extensive political communication research considers the content of candidate messages, scholars have largely ignored how those words are rendered–specifically, the typefaces in which they are set. If typefaces are found to have political attributes, that may impact how voters receive campaign messages. Our paper reports the results of two survey experiments demonstrating that individuals perceive typefaces, type families, and type styles to have ideological qualities. Furthermore, partisanship moderates subjects’ perceptions of typefaces: Republicans generally view typefaces as more conservative than Independents and Democrats. We also find evidence of affective polarization, in that individuals rate typefaces more favorably when perceived as sharing their ideological orientation. Results broaden our understanding of how meaning is conveyed in political communication, laying the groundwork for future research into the functions of typography and graphic design in contemporary political campaigns. Implications for political practitioners are also discussed. Keywords: Political communication, ideology, partisanship, typeface, graphic design. [Ranking: Blackletter, Times New Roman, Jubilat, Gill Sans, Birds of Paradise, Century Gothic, Sunrise.]'
- - https://slatestarcodex.com/2020/01/08/what-intellectual-progress-did-i-make-in-the-2010s/
  - "What Intellectual Progress Did I Make In The 2010s?"
  - Scott Alexander
  - 2020-01-08
  - ''
  - ! '<p>[Scott Alexander look back on how his ideas/beliefs evolved over the past decade of blogging at Jackdaws/LessWrong/SlateStarCodex. Primary topics:</p><ol type="1"><li><p>Bayesian predictive coding as a unified theory of brain perception, control, behavior, and psychiatric disorders as bad priors/updates</p><ul><li>Psychedelics use as modifying brain priors, explaining how psychedelics affect and sometimes benefit their users</li><li>trauma/attachment disorder</li></ul></li><li><p>Philosophy of mental disease</p></li><li><p>efficacy of SSRIs</p></li><li><p>Genetics of psychiatric disorders, especially autism/transsexuals: ???</p></li><li><p>Willpower: also predictive coding???</p></li><li><p>Diet/weight loss: setpoints, somehow</p></li><li><p>Existential risk: dissolving the Great Filter, raising AI risk awareness</p></li><li><p>Secular stagnation: progress is slowing, perhaps because human populations aren’t growing exponentially</p><ul><li>Baumol’s cost disease as core cause of economic stagnation and political backlash</li></ul></li><li><p>The Replication Crisis: even worse than he thought</p></li><li><p>Psychological effects:</p><ul><li>Placebo effect: much more powerless than he thought</li><li>Birth order effects: much more powerful than he thought</li></ul></li><li><p>Utilitarianism: still confused, but more towards rule-utilitarianism</p></li><li><p>Politics: social media turbocharging tribalism/outgroup-bias</p></li><li><p>Ideology of liberalism and SJWism</p></li><li><p>Coordination problems as core problem of politics</p></li><li><p>Enlightenment: not actually that great, possibly wireheading]</p></li></ol>'
- - /docs/iq/smpy/1994-subotnik-beyondterman.pdf
  - "Beyond Terman: contemporary longitudinal studies of giftedness and talent"
  - Rena F. Subotnik, Karen D. Arnold
  - '1994'
  - ''
  - ! '<p><em>Beyond Terman: Contemporary Longitudinal Studies of Giftedness and Talent</em> is an important contribution to the literature in two fields—those of gifted education and educational research. It is significant for the former in terms of the insights and understandings it provides about giftedness and its nurture. It is important for the latter for its elucidations of the methodology associated with longitudinal research. The editors point out that “[the] volume presents recent collected works that demonstrate the fit between longitudinal methodology and the central issues of gifted education. Collectively, the studies investigate the early determinants of later academic and career achievement and creativity while employing varied identification practices, perspectives, theoretical orientations, and populations.”</p><p>The studies described vary along many dimensions, including research problem, sample size and character, length of study, data collection procedures and sources, and longitudinal orientation (i.e., emergent/developmental or retrospective). The studies deal with a variety of talent areas, such as academic achievement, science, technical creativity, music, creative and productive thinking, and career development. The samples include gifted and talented children, youths, and adults, both males and females. Although most of the studies deal with identified gifted/talented individuals, one is a retrospective look at the achievements of graduate students in a university-level leadership education program. Studies originating in Germany and Israel add an international flavor and, more importantly, remind us that there is good research being conducted beyond the borders of the U.S.</p><p>As the premiere longitudinal investigation of a gifted population, the Terman study set a standard of comprehensiveness, large study sample, and societal influence that is difficult to supersede. In spite of the Terman study’s large number of research associates and rich sources of funding support, the data are still being organized for more accurate statistical analysis and examined for more challenging research questions. Further, the <em>Genetic Studies of Genius</em> and its more current follow-ups did not address key questions of concern in today’s social, political, and historical climate, or issues of central importance in the future. The investigations in this book have established a groundwork for answering previously unanswered questions: Are we identifying the “right” people? What are the outcomes associated with various forms of identification and intervention?</p><p>Over the course of his long career, Terman’s perspective on high IQ as a source for potential genius changed to allow personality, interest, special abilities, and opportunity to play a growing role in adult achievement. In filling a vacuum left by Terman, this collection of contemporary studies can guide policy and program development based on the conditions and interventions that contribute to the fulfillment of talent.</p>'
- - /docs/japanese/1997-tsuzuki-tokyoacertainstyle.pdf
  - "Tokyo: A Certain Style"
  - Kyoichi Tsuzuki
  - '1997'
  - ''
  - ! '<p>Writer-photographer Kyoichi Tsuzuki visited a hundred apartments, condos, and houses, documenting what he saw in more than 400 color photos that show the real Tokyo style—a far cry from the serene gardens, shoji screens, and Zen minimalism usually associated with Japanese dwellings.</p> <p>In <em>this</em> Tokyo, necessities such as beds, bathrooms, and kitchens vie for space with electronic gadgets, musical instruments, clothes, books, records, and kitschy collectibles. Candid photos vividly capture the dizzying “cockpit effect”of living in a snug space crammed floor to ceiling with stuff. And it’s not just bohemian types and students who must fit their lives and work into tight quarters, but professionals and families with children, too. In descriptive captions, the inhabitants discuss the ingenious ways they’ve adapted their home environments to suit their diverse lifestyles.</p>'
- - /docs/music-distraction/2012-perham.pdf
  - Disliked Music can be Better for Performance than Liked Music
  - Nick Perham, Martinne Sykora
  - 2012-01-12
  - 10.1002/acp.2826
  - 'Although liked music is known to improve performance through boosting one’s mood and arousal, both liked music and disliked music impair serial recall performance. Given that the key acoustical feature of this impairment is the acoustical variation, it is possible that some music may contain less acoustical variation and so produce less impairment. In this situation, unliked, unfamiliar music could be better for performance than liked, familiar music. This study tested this by asking participants to serially recall eight-item lists in either quiet, liked or disliked music conditions. Results showed that performance was significantly poorer in both music conditions compared with quiet. More importantly, performance in the liked music condition was significantly poorer than in the disliked music condition. These findings provide further illustration of the irrelevant sound effect and limitations of the impact of liked music on cognition.'
- - /docs/predictions/2001-armstrong-principlesforecasting.pdf
  - "Principles of Forecasting: A Handbook for Researchers and Practitioners"
  - J. Scott Armstrong
  - '2001'
  - ''
  - ! '<p>Forecasting is important in many aspects of our lives. As individuals, we try to predict success in our marriages, occupations, and investments. Organizations invest enormous amounts based on forecasts for new products, factories, retail outlets, and contracts with executives. Government agencies need forecasts of the economy, environmental impacts, new sports stadiums, and effects of proposed social programs.</p> <p>The purpose of this book is to summarize knowledge of forecasting as a set of principles. These “principles” represent advice, guidelines, prescriptions, condition-action statements, and rules. We expect principles to be supported by empirical evidence. For this book, however, I asked authors to be ambitious in identifying principles for forecasting by including those based on expert judgment and even those that might be speculative. The authors describe the evidence so that you can judge how much confidence can be placed in the principles.</p> <P>To summarize the findings, I invited 39 leading researchers to describe principles in their areas of expertise...Most of the book is devoted to descriptions of forecasting methods, discussions of the conditions under which they are most useful, and summaries of the evidence.</p>'
- - /docs/radiance/1984-berger.pdf
  - "The Astounding Investigation: The Manhattan Project's Confrontation With Science Fiction, published in <em>Analog Science Fiction/Science Fact</em>"
  - Albert I. Berger
  - '1984-09-01'
  - ''
  - ! '<p>In the spring of 1944, agents from the Manhattan Project’s security division interviewed Cleve Cartmill and John Campbell in the wake of Campbell’s publication of Cartmill’s short story “‘Deadline’’ in the March, 1944 issue of <em>Astounding Science Fiction</em>, in which U-235 had been separated from non-fissionable isotopes and was ready to be detonated in a functional bomb, whose details were described. As described, Cartmill’s bomb would not work; and it did not resemble the uranium bomb being built by the Manhattan Project. However, suspecting a leak from the Project (whose most difficult engineering problem with uranium was its separation into fissionable and non-fissionable isotopes), agents interviewed both author and editor.”Where did you get this idea?"</p><p>The incident has become part of science fiction folklore. Campbell spoke of it often before his death, and it is often referred to by members of the <em>Analog Science Fiction/Science Fact</em> science fiction community, usually in the context of discussing the genre’s anticipation of actual scientific and technological developments. However, the military intelligence agents kept records of the investigation, records which have just been released in response to a request under the Freedom of Information Act. Seven separate documents, comprising some 39 pages of reports and memoranda filed under Cleve Cartmill’s name, show just how the people who were guarding the building of the real atomic bomb responded to the news that a disreputable pulp fiction magazine was apparently keeping pace with this recent and most secret research. Coincidentally, they shed light on Astounding’s fabled editorial practices just as World War II was disrupting the ‘‘stable’’ of famous science fiction writers John Campbell had assembled there between 1937 and 1941.</p><p>The Manhattan Project sought to provide internal security through compartmentalization. Only at the very top, and on a need-to-know basis, were the participants supposed to know what they were working on. Campbell and Cartmill had created a problem by naming what was intended to be unnameable: the near-term practical possibility of an atomic bomb. Campbell seems to have known something was up: “I’m stating fact, not theory,” he had written to Cartmill. Cartmill was afraid before he began writing that “Deadline” would do exactly what it did do: inadvertently call attention to a real bomb project. As contemptuous as Project security and the censor were of science fiction, they were also little afraid of precisely what Campbell’s science fiction did best: putting scattered bits of scientific knowledge together into a specific, concrete idea or device, and speculating on what that idea or device’s impact might be on the world at large. That kind of speculation represents a way of thinking distinctly at odds with those of bureaucracies like the Manhattan Project. The latter are often perfectly aware that two and two add up to four, but they equally often want to control the distribution of that news, for legitimate (as in this case perhaps) as frequently as for disreputable reasons.</p><p>So the affair represents more than just the anecdote which it has become. Cartmill’s letters reveal many of the constraints under which Campbell labored during the war; the affair as a whole shows the extremely casual way in which Campbell regarded so-called “voluntary censorship”. But that casualness, juxtaposed with the grim concern for control and fear of undue speculation on the part of the Project, marks an early and quite concrete example of the tension between the imagination engendered by science fiction and the concerns of the giant bureaucracies (governmental or private) which have so dominated scientific research and technological development since the end of World War II. It is probably belaboring <em>Analog</em> readers to remind them that that tension has furnished themes for more than a generation of science fiction stories.</p>'
- - /docs/statistics/bayes/1814-laplace-philosophicalessayonprobabilities-ch5probabilitiestestimonies.pdf
  - "Philosophical Essay on Probabilities, Chapter 11: Concerning the Probabilities of Testimonies"
  - Pierre-Simon Laplace
  - '1814'
  - ''
  - ! '<p>The majority of our opinions being founded on the probability of proofs it is indeed important to submit it to calculus. Things it is true often become impossible by the difficulty of appreciating the veracity of witnesses and by the great number of circumstances which accompany the deeds they attest; but one is able in several cases to resolve the problems which have much analogy with the questions which are proposed and whose solutions may be regarded as suitable approximations to guide and to defend us againt the errors and the dangers of false reasoning to which we are exposed. An approximation of this kind, when it is well made, is always preferable to the most specious reasonings.</p> <p>We would give no credence to the testimony of a man who should attest to us that in throwing a hundred dice into the air they had all fallen on the same face. If we had ourselves been spectators of this event we should believe our own eyes only after having carefully examined all the circumstances, and after having brought in the testimonies of other eyes in order to be quite sure that there had been neither hallucination nor deception. But after this examination we should not hesitate to admit it in spite of its extreme improbability; and no one would be tempted, in order to explain it, to recur to a denial of the laws of vision. We ought to conclude from it that the probability of the constancy of the laws of nature is for us greater than this, that the event in question has not taken place at all a probability greater than that of the majority of historical facts which we regard as incontestable. One may judge by this the immense weight of testimonies necessary to admit a suspension of natural laws, and how improper it would be to apply to this case the ordinary rules of criticism. All those who without offering this immensity of testimonies support this when making recitals of events contrary to those laws, decrease rather than augment the belief which they wish to inspire; for then those recitals render very probable the error or the falsehood of their authors. But that which diminishes the belief of educated men increases often that of the uneducated, always greedy for the wonderful.</p> <p>The action of time enfeebles then, without ceasing, the probability of historical facts just as it changes the most durable monuments. One can indeed diminish it by multiplying and conserving the testimonies and the monuments which support them. Printing offers for this purpose a great means, unfortunately unknown to the ancients. In spite of the infinite advantages which it procures the physical and moral revolutions by which the surface of this globe will always be agitated will end, in conjunction with the inevitable effect of time, by rendering doubtful after thousands of years the historical facts regarded to-day as the most certain.</p>'
- - /docs/statistics/decision/1959-schlaifer-probabilitystatisticsbusinessdecisions.pdf
  - 'Probability and Statistics for Business Decisions: An Introduction to Managerial Economics Under Uncertainty'
  - Robert Schlaifer
  - '1959'
  - ''
  - ! '<p>This book is a nonmathematical introduction to the logical analysis of practical business problems in which a decision must be reached under uncertainty. The analysis which it recommends is based on the modern theory of utility and what has come to be known as the “‘personal”’ definition of probability; the author believes, in other words, that when the consequences of various possible courses of action depend on some unpredictable event, the practical way of choosing the ‘‘best’’ act is to assign values to consequences and probabilities to events and then to select the act with the highest expected value. In the author’s experience, thoughtful businessmen intuitively apply exactly this kind of analysis in problems which are simple enough to allow of purely intuitive analysis; and he believes that they will readily accept its formalization once the essential logic of this formalization is presented in a way which can be comprehended by an intelligent layman. Excellent books on the pure mathematical theory of decision under uncertainty already exist; the present text is an endeavor to show how formal analysis of practical decision problems can be made to pay its way.</p> <p>From the point of view taken in this book,there is no real difference between a ‘‘statistical’’ decision problem in which a part of the available evidence happens to come from a ‘“‘sample”’ and a problem in which all the evidence is of a less formal nature. Both kinds of problems are analyzed by use of the same basic principles; and one of the resulting advantages is that it becomes possible to avoid having to assert that nothing useful can be said about a sample which contains an unknown amount of bias while at the same time having to admit that in most practical situations it is totally impossible to draw a sample which does not contain an unknown amount of bias. In the same way and for the same reason there is no real difference between a decision problem in which the long-run-average demand for some commodity is known with certainty and one in which it is not; and not the least of the advantages which result from recognizing this fact is that it becomes possible to analyze a problem of inventory control without having to pretend that a finite amount of experience can ever give anyone perfect knowledge of long-run-average demand. The author is quite ready to admit that in some situations it may be difficult for the businessman to assess the numerical probabilities and utilities which are required for the kind of analysis recommended in this book, but he is confident that the businessman who really tries to make a reasoned analysis of a difficult decision problem will find it far easier to do this than to make a direct determination of, say, the correct risk premium to add to the pure cost of capital or of the correct level at which to conduct a test of significance.</p> <p>In sum, the author believes that the modern theories of utility and personal probability have at last made it possible to develop a really complete theory to guide the making of managerial decisions—a theory into which the traditional disciplines of statistics and economics under certainty and the collection of miscellaneous techniques taught under the name of operations research will all enter as constituent parts. He hopes, therefore, that the present book will be of interest and value not only to students and practitioners of inventory control, quality control, marketing research, and other specific business functions but also to students of business and businessmen who are interested in the basic principles of managerial economics and to students of economics who are interested in the theory of the firm. Even the teacher of a course in mathematical decision theory who wishes to include applications as well as complete-class and existence theory may find the book useful as a source of examples of the practical decision problems which do arise in the real world.</p>'
- - /docs/sunkcosts/1984-northcraft.pdf
  - "Dollars, Sense, and Sunk Costs: A Life Cycle Model of Resource Allocation Decisions"
  - Gregory B. Northcraft, Gerrit Wolf
  - '1984-04'
  - 10.5465/amr.1984.4277636
  - ! 'Decisions as to whether to cut off a losing enterprise (clouded by what already has been invested in the venture) may be facilitated by a new model proposed here—the life cycle model. The model, borrowing an accounting measure (the time adjusted rate of return) to describe the effect of "sunk costs" on the expected rate of return for future costs in a project, is used to examine the relevance of negative feedback to the decision to commit further resources to completion of a project.'
- - /docs/sunkcosts/1988-arkes.pdf
  - Eliminating the Hindsight Bias
  - Hal R. Arkes, David Faust, Thomas J. Guilmette, Kathleen Hart
  - 1988-05
  - 10.1037/0021-9010.73.2.305
  - ! '<p>Those who consider the likelihood of an event after it has occurred exaggerate their likelihood of having been able to predict that event in advance. We attempted to eliminate this hindsight bias among 194 neuropsychologists. Foresight subjects read a case history and were asked to estimate the probability of three different diagnoses. Subjects in each of the three hindsight groups were told that one of the three diagnoses was correct and were asked to state what probability they would have assigned to each diagnosis if they were making the original diagnosis. Foresight-reasons and hindsight-reasons subjects performed the same task as their foresight and hindsight counterparts, except they had to list one reason why each of the possible diagnoses might be correct. The frequency of subjects succumbing to the hindsight bias was lower in the hindsight-reasons groups than in the hindsight groups not asked to list reasons, <em>x</em><sup>2</sup>( 1, <em>N</em> = 140) = 4.12, <em>p</em> &lt; .05.</p>'
- - http://jtoomim.org/files/Ling_2009-Cognitive_effects_of_creatine_ethyl_ester_supplementation.pdf
  - Cognitive effects of creatine ethyl ester supplementation
  - Jonathan Ling, Minos Kritikos, Brian Tiplady
  - 2009-12
  - 10.1097/fbp.0b013e3283323c2a
  - ! 'Supplementation with creatine-based substances as a means of enhancing athletic performance has become widespread. Until recently, however, the effects of creatine supplementation on cognitive performance has been given little attention. This study used a new form of creatine–creatine ethyl ester–to investigate whether supplementation would improve performance in 5 cognitive tasks, using a double-blind, placebo-controlled study. Creatine dosing led to an improvement over the placebo condition on several measures. Although creatine seems to facilitate cognition on some tasks, these results require replication using objective measures of compliance. The improvement is discussed in the context of research examining the influence of brain energy capacity on cognitive performance.'
- - ! 'http://www.justice.gov/usao/nys/pressreleases/December13/JonesetalArrestsSilkRoad2PR/Jones,%20Andrew,%20et%20al%20(Silk%20Road)%20Indictment.pdf'
  - 'United States of America v. Jones, Andrew Michael, et. al.'
  - United States District Court Southern District of New York
  - 2013-12-20
  - ''
  - ! "From, in or about January 2011, up to and including on or about October 2, 2013, an underground website known as 'Silk Road' hosted a sprawling black-market bazaar on the Internet, where illegal drugs and other illicit goods and services were regularly bought and sold by the site's users. The Grand Jury indicts Defendants Andrew Michael Jones, Gary Davis, and Peter Phillip Nash on three counts of Narcotics Trafficking Conspiracy, Computer Hacking Conspiracy, and Money Laundering Conspiracy."
- - http://www.klingberglab.se/pub/McNab2008.pdf
  - 'Common and unique components of inhibition and working memory: An fMRI, within-subjects investigation'
  - Fiona McNab, Gaelle Leroux, Fredrik Strand, Lisa Thorell, Sissela Bergman, Torkel Klingberg
  - 2008-05-16
  - 10.1016/j.neuropsychologia.2008.04.023
  - ! 'Behavioural findings indicate that the core executive functions of inhibition and working memory are closely linked, and neuroimaging studies indicate overlap between their neural correlates. There has not, however, been a comprehensive study, including several inhibition tasks and several working memory tasks, performed by the same subjects. In the present study, 11 healthy adult subjects completed separate blocks of 3 inhibition tasks (a stop task, a go/no-go task and a flanker task), and 2 working memory tasks (one spatial and one verbal). Activation common to all 5 tasks was identified in the right inferior frontal gyrus, and, at a lower threshold, also the right middle frontal gyrus and right parietal regions (BA 40 and BA 7). Left inferior frontal regions of interest (ROIs) showed a significant conjunction between all tasks except the flanker task. The present study could not pinpoint the specific function of each common region, but the parietal region identified here has previously been consistently related to working memory storage and the right inferior frontal gyrus has been associated with inhibition in both lesion and imaging studies. These results support the notion that inhibitory and working memory tasks involve common neural components, which may provide a neural basis for the interrelationship between the two systems.'
- - https://deepmind.com/documents/183/SPIRAL.pdf
  - Synthesizing Programs for Images using Reinforced Adversarial Learning
  - Yaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, S. M. Ali Eslami, Oriol Vinyals
  - 2018-04-03
  - ''
  - ! '<p>Advances in deep generative networks have led to impressive results in recent years. Nevertheless, such models can often waste their capacity on the minutiae of datasets, presumably due to weak inductive biases in their decoders. This is where graphics engines may come in handy since they abstract away low-level details and represent images as high-level programs. Current methods that combine deep learning and renderers are limited by hand-crafted likelihood or distance functions, a need for large amounts of supervision, or difficulties in scaling their inference algorithms to richer datasets. To mitigate these issues, we present SPIRAL, an adversarially trained agent that generates a program which is executed by a graphics engine to interpret and sample images. The goal of this agent is to fool a discriminator network that distinguishes between real and rendered data, trained with a distributed reinforcement learning setup without any supervision. A surprising finding is that using the discriminator’s output as a reward signal is the key to allow the agent to make meaningful progress at matching the desired output rendering. To the best of our knowledge, this is the first demonstration of an end-to-end, unsupervised and adversarial inverse graphics agent on challenging real world (MNIST, OMNIGLOT, CELEBA) and synthetic 3D datasets. A video of the agent can be found at <a href="https://youtu.be/iSyvwAwa7vk">YouTube</a>.</p>'
- - https://pdfs.semanticscholar.org/29d0/884cf4ed6acdb2711f556863a1ef2bd3a908.pdf
  - In vitro eugenics
  - Robert Sparrow
  - 2014-11
  - 10.1136/medethics-2012-101200
  - ! '<p>A series of recent scientific results suggest that, in the not-too-distant future, it will be possible to create viable human gametes from human stem cells. This paper discusses the potential of this technology to make possible what I call “<em>in vitro</em> eugenics”: the deliberate breeding of human beings <em>in vitro</em> by fusing sperm and egg derived from different stem-cell lines to create an embryo and then deriving new gametes from stem cells derived from that embryo. Repeated iterations of this process would allow scientists to proceed through multiple human generations in the laboratory. <em>In vitro</em> eugenics might be used to study the heredity of genetic disorders and to produce cell lines of a desired character for medical applications. More controversially, it might also function as a powerful technology of ‘human enhancement’ by allowing researchers to use all the techniques of selective breeding to produce individuals with a desired genotype.</p>'
- - https://pdfs.semanticscholar.org/cfda/7aa20912874b9818ae242a04703cc0922181.pdf
  - "Seeing the Forest from the Trees: When Predicting the Behavior or Status of Groups, Correlate Means"
  - David Lubinski, Lloyd G. Humphreys
  - '1996'
  - 10.1037/1076-8971.2.2.363
  - ! '<p>When measures of individual differences are used to predict group performance, the reporting of correlations computed on samples of individuals invites misinterpretation and dismissal of the data. In contrast, if regression equations, in which the correlations required are computed on bivariate means, as are the distribution statistics, it is difficult to underappreciate or lightly dismiss the utility of psychological predictors. Given sufficient sample size and linearity of regression, this technique produces cross-validated regression equations that forecast criterion means with almost perfect accuracy. This level of accuracy is provided by correlations approaching unity between bivariate samples of predictor and criterion means, and this holds true regardless of the magnitude of the “simple” correlation (e.g., <em>r</em><sub>xy</sub> = .20, or <em>r</em><sub>xy</sub> = .80). We illustrate this technique empirically using a measure of general intelligence as the predictor and other measures of individual differences and socioeconomic status as criteria. In addition to theoretical applications pertaining to group trends, this methodology also has implications for applied problems aimed at developing policy in education, medical, and psychological clinics, business, industry, the military, and other domains of public welfare. Linkages between this approach and epidemiological research reinforce its utility as a tool for making decisions about policy.</p>'
- - https://www.biorxiv.org/content/biorxiv/early/2016/05/03/051094.full.pdf
  - 'LD Hub: a centralized database and web interface to perform LD score regression that maximizes the potential of summary level GWAS data for SNP heritability and genetic correlation analysis'
  - Jie Zheng, A. Mesut Erzurumluoglu, Benjamin L. Elsworth, Laurence Howe, Philip C. Haycock, Gibran Hemani, Katherine Tansey, Charles Laurin, Early Genetics and Lifecourse Epidemiology (EAGLE) Eczema Consortium, Beate St. Pourcain, Nicole M. Warrington, Hilary K. Finucane, Alkes L. Price, Brendan K. Bulik-Sullivan, Verneri Anttila, Lavinia Paternoster, Tom R. Gaunt, David M. Evans, Benjamin M. Neale
  - 2016-05-03
  - 10.1101/051094
  - ! '<p><strong>Motivation:</strong> LD score regression is a reliable and efficient method of using genome-wide association study (GWAS) summary-level results data to estimate the SNP heritability of complex traits and diseases, partition this heritability into functional categories, and estimate the genetic correlation between different phenotypes. Because the method relies on summary level results data, LD score regression is computationally tractable even for very large sample sizes. However, publicly available GWAS summary-level data are typically stored in different databases and have different formats, making it difficult to apply LD score regression to estimate genetic correlations across many different traits simultaneously.</p><p><strong>Results:</strong> In this manuscript, we describe LD Hub—a centralized database of summary-level GWAS results for 177 diseases/traits from different publicly available resources/consortia and a web interface that automates the LD score regression analysis pipeline. To demonstrate functionality and validate our software, we replicated previously reported LD score regression analyses of 49 traits/diseases using LD Hub; and estimated SNP heritability and the genetic correlation across the different phenotypes. We also present new results obtained by uploading a recent atopic dermatitis GWAS meta-analysis to examine the genetic correlation between the condition and other potentially related traits. In response to the growing availability of publicly accessible GWAS summary-level results data, our database and the accompanying web interface will ensure maximal uptake of the LD score regression methodology, provide a useful database for the public dissemination of GWAS results, and provide a method for easily screening hundreds of traits for overlapping genetic aetiologies.</p><p><strong>Availability and implementation:</strong> The web interface and instructions for using LD Hub are available at <a href="http://ldsc.broadinstitute.org/">LDSC</a></p>'
- - https://www.donorsiblingregistry.com/sites/default/files/files/dissertation%281%29.pdf
  - Quantitative Genetics in the Postmodern Family of the Donor Sibling Registry
  - Joseph Christopher Lee
  - 2013-06-12
  - ''
  - ! '<p>Quantitative genetics is primarily concerned with two subjects: the correlation between relatives and the response to selection. The correlation between relatives is used to determine the heritability of a trait—the key quantity that addresses the question of nature vs. nurture. Heritability, in turn, is used to predict the response to selection—the main driver of improvements in crops and livestock. The theory of quantitative genetics has been thoroughly tested and applied in plants and animals, but heritability and selection remain open questions in humans due to limited natural experimental designs.</p><p>The Donor Sibling Registry (DSR) is an organization that helps individuals conceived as a result of sperm, egg, or embryo donation make contact with genetically related individuals. Families who conceived children via anonymous sperm donation join the DSR and match with other families who used the same donor ID at the same sperm bank. The resulting donor pedigree consists of heterosexual, lesbian, and single mother families who are connected through the common anonymous sperm donor used to conceive their children.</p><p>Here, we introduce a new quantitative genetic study design based on the unprecedented family relationships found in the donor pedigree. We surveyed 945 individual families constituting 159 donor pedigrees from the Donor Sibling Registry and used their demographic, physical, and behavioral characteristics to conduct a quantitative genetic study of selection and heritability. A direct measurement of phenotypic assortment showed mothers actively selected mates for height, eye color, and religion. Artificial selection for donor height increased mean child height in a manner consistent with the selection differential. Reared-apart donor-conceived paternal half-siblings provided unbiased heritability estimates for traits influenced by maternal and contrast effects. Maternal effects were important in determining the variance of birth weight while eliminating contrast effects revealed sociability to be a highly heritable childhood temperament. Thus, the unprecedented family relationships in the donor pedigree enable a universal model for quantitative genetics.</p>'
- - https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-soska-updated.pdf
  - Measuring the Longitudinal Evolution of the Online Anonymous Marketplace Ecosystem
  - Kyle Soska, Nicolas Christin
  - 2015-08
  - ''
  - ! 'February 2011 saw the emergence of Silk Road, the first successful online anonymous marketplace, in which buyers and sellers could transact with anonymity properties far superior to those available in alternative online or offline means of commerce. Business on Silk Road, primarily involving narcotics trafficking, rapidly boomed, and competitors emerged. At the same time, law enforcement did not sit idle, and eventually managed to shut down Silk Road in October 2013 and arrest its operator. Far from causing the demise of this novel form of commerce, the Silk Road take-down spawned an entire, dynamic, online anonymous marketplace ecosystem, which has continued to evolve to this day. This paper presents a long-term measurement analysis of a large portion of this online anonymous marketplace ecosystem, including 16 different marketplaces, over more than two years (2013–2015). By using long-term measurements, and combining our own data collection with publicly available previous efforts, we offer a detailed understanding of the growth of the online anonymous marketplace ecosystem. We are able to document the evolution of the types of goods being sold, and assess the effect (or lack thereof) of adversarial events, such as law enforcement operations or large-scale frauds, on the overall size of the economy. We also provide insights into how vendors are diversifying and replicating across marketplaces, and how vendor security practices (e.g., PGP adoption) are evolving. These different aspects help us understand how traditional, physical-world criminal activities are developing an online presence, in the same manner traditional commerce diversified online in the 1990s.'
- - /docs/statistics/decision/1939-pearson.pdf
  - '"Student" as Statistician'
  - E. S. Pearson
  - 1939-01-00
  - 10.2307/2332648
  - ! "[Egon Pearson describes Student, or Gosset, as a statistician: Student corresponded widely with young statisticians/mathematicians, encouraging them, and having an outsized influence not reflected in his publication. Student's preferred statistical tools were remarkably simple, focused on correlations and standard deviations, but wielded effectively in the analysis and efficient design of experiments (particularly agricultural experiments), and he was an early decision-theorist, focused on practical problems connected to his Guinness Brewery job—which detachment from academia partially explains why he didn't publish methods or results immediately or often. The need to handle small <em>n</em> of the brewery led to his work on small-sample approximations rather than, like Pearson et al in the Galton biometric tradition, relying on collecting large datasets and using asymptotic methods, and Student carried out one of the first Monte Carlo simulations.]"
- - https://www.nature.com/articles/s41599-019-0366-y
  - "Statistical reliability analysis for a most dangerous occupation: Roman emperor"
  - Joseph Homer Saleh
  - 2019-12-23
  - 10.1057/s41599-019-0366-y
  - ! 'Popular culture associates the lives of Roman emperors with luxury, cruelty, and debauchery, sometimes rightfully so. One missing attribute in this list is, surprisingly, that this mighty office was most dangerous for its holder. Of the 69 rulers of the unified Roman Empire, from Augustus (d. 14 CE) to Theodosius (d. 395 CE), 62% suffered violent death. This has been known for a while, if not quantitatively at least qualitatively. What is not known, however, and has never been examined is the time-to-violent-death of Roman emperors. This work adopts the statistical tools of survival data analysis to an unlikely population, Roman emperors, and it examines a particular event in their rule, not unlike the focus of reliability engineering, but instead of their time-to-failure, their time-to-violent-death. We investigate the temporal signature of this seemingly haphazardous stochastic process that is the violent death of a Roman emperor, and we examine whether there is some structure underlying the randomness in this process or not. Nonparametric and parametric results show that: (i) emperors faced a significantly high risk of violent death in the first year of their rule, which is reminiscent of infant mortality in reliability engineering; (ii) their risk of violent death further increased after 12 years, which is reminiscent of wear-out period in reliability engineering; (iii) their failure rate displayed a bathtub-like curve, similar to that of a host of mechanical engineering items and electronic components. Results also showed that the stochastic process underlying the violent deaths of emperors is remarkably well captured by a (mixture) Weibull distribution. We discuss the interpretation and possible reasons for this uncanny result, and we propose a number of fruitful venues for future work to help better understand the deeper etiology of the spectacle of regicide of Roman emperors.'
- - https://www.nytimes.com/2018/04/04/technology/nasim-aghdam-youtube-shooter.html
  - "‘Vegan Bodybuilder’: How YouTube Attacker, Nasim Aghdam, Went Viral in Iran"
  - Daisuke Wakabayashi, Thomas Erdbrink, Matthew Haag (NYT)
  - 2018-04-04
  - ''
  - ! '<p>In Iran, she was known as Green Nasim, a social media star with followings on YouTube, on Instagram and elsewhere. ¶ In the United States, she cast a very different profile, a proponent of vegan diets, animal rights and home exercise who had increasingly become agitated by one of the tech companies that helped give her a platform… ¶ The police said Ms. Aghdam’s anger over what she believed to be unfair treatment by YouTube had set her on a 500-mile drive from her home near San Diego to YouTube’s offices on the northern edge of Silicon Valley. ¶ “People like me are not good for big business, like for animal business, medicine business and for many other businesses. That’s why they are discriminating and censoring us,” she said in a video posted online last year criticizing YouTube. “This is what they are doing to vegan activists and many other people who try to promote healthy, humane and smart living.”</p><p>…Ms. Aghdam was in her late 30s. In several of her videos, she said she was born in Iran, in the city of Urmia, where most people also speak Turkish, as she does in some of her videos. Ms. Aghdam had YouTube pages in Persian, Turkish and English. She explained that she and her family were members of the Baha’i faith, which faces persecution in Iran, a country with a Muslim majority. ¶ Several of her colorful—and sometimes bizarre—videos had gone viral in Iran. Her website, which said it was quoting Western news outlets, identified her as “the first Persian female vegan bodybuilder.” ¶ “Now the media will be faced with a new type of Iranian female which does not fit within any of their usual categorizations,” a Twitter user named Katayoon said Wednesday. ¶ “This was shocking and saddening,” one Iranian, Bahare, wrote on Twitter of Ms. Aghdam. “We laughed so much but now it turns out all those videos were so serious for herself.” ¶ Ms. Aghdam became especially famous for one clip in which she wears a revealing purple dress, showing cleavage, and begins to slowly strip off her clothes to reveal a pair of fake plastic breasts. “Don’t trust your eyes,” read a caption in English on the clip.</p><p>…Her personal website and videos posted to YouTube and elsewhere were filled with complaints about YouTube. “When searching for my website in google, at top of link they add ‘an error occurred’ but there is no error!” a website under Ms. Aghdam’s name, NasimeSabz.com, said in February 2016. “They add it to keep you from my visiting my site.” ¶ Life in the United States had not been good, she said in one video from March 30. “There they kill you by ax,” she said of Iran. “Here they kill you with cotton,” referring to an Iranian expression meaning dying by something that you do not know is dangerous. ¶ In another video, she responded to viewers who had begun to wonder if she was mentally ill: “I don’t have any special mental or physical disease, but I live on a planet filled with disease, disorders, perversions and injustices.” ¶ The American dream appeared to be tarnished for her after she began to face hurdles in the United States. ¶ “If you are superficial, you will think it is heaven here, that you can go naked outside and have sex left and right like other animals without any morality,” she said in one video in Persian. “But if you enter the system, you will see that it is worse than Iran,” she said. “Those who want to inform people against the system and big companies get censored.”</p>'
- - https://slatestarcodex.com/2013/04/12/noisy-poll-results-and-reptilian-muslim-climatologists-from-mars/
  - "Lizardman’s Constant Is 4%"
  - Scott Alexander
  - 2013-04-12
  - ''
  - ! '<p>I have only done a little bit of social science research, but it was enough to make me hate people. One study I helped with analyzed whether people from different countries had different answers on a certain psychological test. So we put up a website where people answered some questions about themselves (like “what country are you from?”) and then took the psychological test. ¶ And so of course people screwed it up in every conceivable way. There were the merely dumb, like the guy who put “male” as his nationality and “American” as his gender. But there were also the actively malicious or at least annoying, like the people (yes, more than one) who wrote in “Martian”. ¶ I think we all probably know someone like this, maybe a couple people like this. ¶ I also think most of us <em>don’t</em> know someone who believes reptilian aliens in human form control all the major nations of Earth. ¶ Public Policy Polling’s recent poll on conspiracy theories mostly showed up on my Facebook feed as “4% of Americans believe lizardmen are running the Earth”. ¶ (of note, an additional 7% of Americans are “not sure” whether lizardmen are running the Earth or not.) ¶ Imagine the situation. You’re at home, eating dinner. You get a call from someone who says “Hello, this is Public Policy Polling. Would you mind answering some questions for us?” You say “Sure”. An extremely dignified sounding voice says–and this is the exact wording of the question–“Do you believe that shape-shifting reptilian people control our world by taking on human form and gaining political power to manipulate our society, or not?” Then it urges you to press 1 if yes, press 2 if no, press 3 if not sure. ¶ So first we get the people who think “Wait, was 1 the one for if I did believe in lizardmen, or if I didn’t? I’ll just press 1 and move on to the next question.” ¶ Then we get the people who are like “I never heard it before, but if this nice pollster thinks it’s true, I might as well go along with them.” ¶ Then we get the people who are all “F#&amp;k you, polling company, I don’t want people calling me when I’m at dinner. You screw with me, I tell you what I’m going to do. I’m going to tell you I believe lizard people are running the planet.” ¶ And <em>then</em> we get the people who put “Martian” as their nationality in psychology experiments. Because some men just want to watch the world burn. ¶ Do these three groups total 4% of the US population? Seems plausible.</p><p>…But sometimes it’s not some abstruse subtle bias. Sometimes it’s not a good-natured joke. Sometimes people might just be actively working to corrupt your data. ¶ Another link I’ve seen on my Facebook wall a few times is this one: “Are Climate Change Sceptics More Likely To Be Conspiracy Theorists?” It’s based on a paper by Stephen Lewandowsky et al called “NASA Faked The Moon Landing, Therefore Climate Science Is A Hoax–An Analysis Of The Motivated Rejection Of Science”. ¶ The paper’s thesis was that climate change skeptics are motivated by conspiracy ideation–a belief that there are large groups of sinister people out to deceive them. This seems sort of reasonable on the face of it–being a climate change skeptic requires going against the belief of the entire scientific establishment. My guess is that there probably is a significant link here waiting to be discovered. ¶ …But a bunch of global warming skeptics started re-analyzing the data and coming up with their own interpretations…More interestingly, they found that pretty much all of the link between global warming skepticism and stupidity was a couple of people (there were so few skeptics, <em>and</em> so few conspiracy believers, that these couple of people made up a pretty big proportion of them, and way more than enough to get a “significant” difference with the global warming believers). Further, most of these couple of people had given the maximally skeptical answer to every single question about global warming, and the maximally credulous answer to every single question about conspiracies. ¶ The danger here now seems obvious. Global warming believer blogs publish a link to this study, saying gleefully that it’s going to prove that global warming skeptics are idiots who also think NASA faked the moon landing and the world is run by lizardmen or whatever. Some global warming believers decide to help this process along by pretending to be super-strong global warming skeptics and filling in the stupidest answers they can to every question. The few real global warming skeptics who take the survey aren’t enough signal to completely drown out this noise. Therefore, they do the statistics and triumphantly announce that global warming skepticism is linked to stupid beliefs.</p><p>…The lesson from all three of the cases in this post seems clear. When we’re talking about very unpopular beliefs, polls can only give a weak signal. Any possible source of noise–jokesters, cognitive biases, or deliberate misbehavior–can easily overwhelm the signal. Therefore, polls that rely on detecting very weak signals should be taken with a grain of salt.</p>'
- - /docs/genetics/selection/1992-innis.pdf
  - "Tolman and Tryon: Early research on the inheritance of the ability to learn"
  - N. K. Innis
  - '1992'
  - '10.1037/0003-066X.47.2.190'
  - ! "Few psychologists today are aware of the seminal role played by learning theorist Edward C. Tolman in the early development of the field of behavior genetics. Tolman was the first to publish a study of selective breeding for maze-learning ability in rats. He continued to foster research in this field by supporting the work of his students, particularly Robert C. Tryon. Tryon carried out the first major long-term study of maze-bright and maze-dull rats. This article focuses on Tolman's early years at Berkeley and the events culminating in the inheritance project, as well as on the evolution of this research under Tryon's direction."
- - /docs/sociology/1999-lee.pdf
  - "Parachuting for charity: is it worth the money? A 5-year audit of parachute injuries in Tayside and the cost to the NHS"
  - C.T. Lee, P. Williams, W.A. Hadden
  - 1999-05
  - "10.1016/S0020-1383(99)00083-2"
  - ! 'All parachute injuries from two local parachute centres over a 5-year period were analysed. Of 174 patients with injuries of varying severity, 94% were first-time charity-parachutists. The injury rate in charity-parachutists was 11% at an average cost of £3751 per casualty. 63% of casualties who were charity-parachutists required hospital admission, representing a serious injury rate of 7%, at an average cost of £5781 per patient. The amount raised per person for charity was £30. Each pound raised for charity cost the NHS £13.75 in return. Parachuting for charity costs more money than it raises, carries a high risk of serious personal injury and places a significant burden on health resources.'
- - https://www.lesswrong.com/posts/SmDziGM9hBjW9DKmf/2019-ai-alignment-literature-review-and-charity-comparison
  - 2019 AI Alignment Literature Review and Charity Comparison
  - Larks
  - 2019-12-18
  - ''
  - ! '<p>As in <a href="https://forum.effectivealtruism.org/posts/nSot23sAjoZRgaEwa/2016-ai-risk-literature-review-and-charity-comparison">2016</a>, <a href="https://forum.effectivealtruism.org/posts/XKwiEpWRdfWo7jy7f/2017-ai-safety-literature-review-and-charity-comparison">2017</a> and <a href="https://forum.effectivealtruism.org/posts/BznrRBgiDdcTwWWsB/2018-ai-alignment-literature-review-and-charity-comparison">2018</a>, I have attempted to review the research that has been produced by various organisations working on AI safety, to help potential donors gain a better understanding of the landscape. This is a similar role to that which GiveWell performs for global health charities, and somewhat similar to a securities analyst with regards to possible investments. My aim is basically to judge the output of each organisation in 2019 and compare it to their budget. This should give a sense of the organisations’ average cost-effectiveness. We can also compare their financial reserves to their 2019 budgets to get a sense of urgency.</p><p>…Here are the un-scientifically-chosen hashtags: Agent Foundations ¶ AI Theory ¶ Amplification ¶ Careers ¶ CIRL ¶ Decision Theory ¶ Ethical Theory ¶ Forecasting ¶ Introduction ¶ Misc ¶ ML safety ¶ Other Xrisk ¶ Overview ¶ Philosophy ¶ Politics ¶ RL ¶ Security ¶ Short-term ¶ Strategy.</p><ul><li><em>Research organisations reviewed</em>: FHI (The Future of Humanity Institute) ¶ CHAI (The Center for Human-Aligned AI) ¶ MIRI (The Machine Intelligence Research Institute) ¶ GCRI (The Global Catastrophic Risks Institute) ¶ CSER (The Center for the Study of Existential Risk) ¶ Ought ¶ OpenAI ¶ Google DeepMind ¶ AI Safety camp ¶ FLI (The Future of Life Institute) ¶ AI Impacts ¶ GPI (The Global Priorities Institute) ¶ FRI (The Foundational Research Institute) ¶ Median Group ¶ CSET (The Center for Security and Emerging Technology) ¶ Leverhulme Center for the Future of Intelligence ¶ BERI (The Berkeley Existential Risk Initiative) ¶ AI Pulse</li><li><em>Capital Allocators reviewed</em>: LTFF (Long-term future fund) ¶ OpenPhil (The Open Philanthropy Project)</li></ul><p>…The size of the field continues to grow, both in terms of funding and researchers. Both make it increasingly hard for individual donors. I’ve attempted to subjectively weigh the productivity of the different organisations against the resources they used to generate that output, and donate accordingly.</p>'
- - /docs/iq/1999-spitz.pdf
  - "Beleaguered 'Pygmalion': A History of the Controversy Over Claims that Teacher Expectancy Raises Intelligence"
  - Herman H. Spitz
  - 1999-09
  - "10.1016/S0160-2896(99)00026-4"
  - ! "The 1968 publication of the Rosenthal and Jacobson's <em>Pygmalion in the Classroom</em> offered the optimistic message that raising teachers' expectations of their pupils' potentials would raise their pupils' intelligence. This claim was, and still is, endorsed by many psychologists and educators. The original study, along with the scores of attempted replications and the acrimonious controversy that followed it, is reviewed, and its consequences discussed."
- - https://www.nature.com/articles/s41586-019-1466-y
  - A national experiment reveals where a growth mindset improves achievement
  - David S. Yeager, Paul Hanselman, Gregory M. Walton, Jared S. Murray, Robert Crosnoe, Chandra Muller, Elizabeth Tipton, Barbara Schneider, Chris S. Hulleman, Cintia P. Hinojosa, David Paunesku, Carissa Romero, Kate Flint, Alice Roberts, Jill Trott, Ronaldo Iachan, Jenny Buontempo, Sophia Man Yang, Carlos M. Carvalho, P. Richard Hahn, Maithreyi Gopalan, Pratik Mhatre, Ronald Ferguson, Angela L. Duckworth, Carol S. Dweck
  - 2019-08-07
  - '10.1038/s41586-019-1466-y'
  - ! 'A global priority for the behavioural sciences is to develop cost-effective, scalable interventions that could improve the academic outcomes of adolescents at a population level, but no such interventions have so far been evaluated in a population-generalizable sample. Here we show that a short (less than one hour), online growth mindset intervention—which teaches that intellectual abilities can be developed—improved grades among lower-achieving students and increased overall enrolment to advanced mathematics courses in a nationally representative sample of students in secondary education in the United States. Notably, the study identified school contexts that sustained the effects of the growth mindset intervention: the intervention changed grades when peer norms aligned with the messages of the intervention. Confidence in the conclusions of this study comes from independent data collection and processing, pre-registration of analyses, and corroboration of results by a blinded Bayesian analysis.'
- - https://www.sciencedirect.com/science/article/pii/S0160289619301680
  - "Working memory training does not enhance older adults' cognitive skills: A comprehensive meta-analysis"
  - "Giovanni Sala, N. Deniz Aksayli, K. Semir Tatlidil, Yasuyuki Gondo, Fernand Gobet"
  - 2019-11
  - "10.1016/j.intell.2019.101386"
  - ! '<ul><li>Working memory (WM) training does not enhance older adults’ cognitive function.</li><li>The training slightly improves older adults’ performance in untrained memory tasks.</li><li>The same pattern of results is observed in younger adults.</li><li>The models exhibit a high degree of consistency; hence this literature is not noisy.</li></ul><p>Abstract:</p><p>In the last two decades, considerable efforts have been devoted to finding a way to enhance cognitive function by cognitive training. To date, the attempt to boost broad cognitive functions in the general population has failed. However, it is still possible that some cognitive training regimens exert a positive influence on specific populations, such as older adults. In this meta-analytic review, we investigated the effects of working memory (WM) training on older adults’ cognitive skills. Three robust-variance-estimation meta-analyses (<em>N</em> = 2140, <em>m</em> = 43, and <em>k</em> = 698) were run to analyze the effects of the intervention on (a) the trained tasks, (b) near-transfer measures, and (c) far-transfer measures. While large effects were found for the trained tasks (<em>g</em> = 0.877), only modest (<em>g</em> = 0.274) and near-zero (<em>g</em> = 0.121) effects were obtained in the near-transfer and far-transfer meta-analyses, respectively. Publication-bias analysis provided adjusted estimates that were slightly lower. Moreover, when active control groups were implemented, the far-transfer effects were null (<em>g</em> = −0.008). Finally, the effects were highly consistent across studies (i.e., low or null true heterogeneity), especially in the near- and far-transfer models. While confirming the difficulty in obtaining transfer effects with cognitive training, these results corroborate recent empirical evidence suggesting that WM is not isomorphic with other fundamental cognitive skills such as fluid intelligence.</p>'
- - https://psyarxiv.com/7s8wr/
  - "Cognitive and academic benefits of music training with children: A multilevel meta-analysis"
  - Giovanni Sala, Fernand Gobet
  - 2020-01-14
  - 10.31234/osf.io/7s8wr
  - ! '<p>Music training has repeatedly been claimed to positively impact on children’s cognitive skills and academic achievement. This claim relies on the assumption that engaging in intellectually demanding activities fosters particular domain-general cognitive skills, or even general intelligence. The present meta-analytic review (<em>N</em> = 6,984, <em>k</em> = 254, <em>m</em> = 54) shows that this belief is incorrect. Once the study quality design is controlled for, the overall effect of music training programs is null (<em>g</em> ≈ 0) and highly consistent across studies (τ<sup>2</sup> ≈ 0). Small statistically significant overall effects are obtained only in those studies implementing no random allocation of participants and employing non-active controls (<em>g</em> ≈ 0.200, <em>p</em> &lt; .001). Interestingly, music training is ineffective regardless of the type of outcome measure (e.g., verbal, non-verbal, speed-related, etc.). Furthermore, we note that, beyond meta-analysis of experimental studies, a considerable amount of cross-sectional evidence indicates that engagement in music has no impact on people’s non-music cognitive skills or academic achievement. We conclude that researchers’ optimism about the benefits of music training is empirically unjustified and stem from misinterpretation of the empirical data and, possibly, confirmation bias. Given the clarity of the results, the large number of participants involved, and the numerous studies carried out so far, we conclude that this line of research should be dismissed.</p>'
- - https://statistics.fas.harvard.edu/files/statistics-2/files/statistical_paradises_and_paradoxes.pdf
  - "Statistical paradises and paradoxes in big data (I): Law of large populations, big data paradox, and the 2016 US presidential election"
  - Xiao-Li Meng
  - 2018-07-28
  - '10.1214/18-AOAS1161SF'
  - ! '<p>Statisticians are increasingly posed with thought-provoking and even paradoxical questions, challenging our qualifications for entering the statistical paradises created by Big Data. By developing measures for data quality, this article suggests a framework to address such a question: “Which one should I trust more: a 1% survey with 60% response rate or a self-reported administrative dataset covering 80% of the population?” A 5-element Euler-formula-like identity shows that for any dataset of size <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>, probabilistic or not, the difference between the sample average <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>X</mi><mo accent="true">¯</mo></mover><mi>n</mi></msub><annotation encoding="application/x-tex">\overline{X}_{n}</annotation></semantics></math> and the population average <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>X</mi><mo accent="true">¯</mo></mover><mi>N</mi></msub><annotation encoding="application/x-tex">\overline{X}_{N}</annotation></semantics></math> is the product of three terms: (1) a <i>data quality</i> measure, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><annotation encoding="application/x-tex">\rho_{{R,X}}</annotation></semantics></math>, the correlation between <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>j</mi></msub><annotation encoding="application/x-tex">X_{j}</annotation></semantics></math> and the response/recording indicator <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>R</mi><mi>j</mi></msub><annotation encoding="application/x-tex">R_{j}</annotation></semantics></math>; (2) a <i>data quantity</i> measure, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msqrt><mrow><mo stretchy="false" form="prefix">(</mo><mi>N</mi><mo>−</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo><mi>/</mi><mi>n</mi></mrow></msqrt><annotation encoding="application/x-tex">\sqrt{(N-n)/n}</annotation></semantics></math>, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is the population size; and (3) a <i>problem difficulty</i> measure, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>σ</mi><mi>X</mi></msub><annotation encoding="application/x-tex">\sigma_{X}</annotation></semantics></math>, the standard deviation of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>. This decomposition provides multiple insights: (I) Probabilistic sampling ensures high data quality by controlling <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><annotation encoding="application/x-tex">\rho_{{R,X}}</annotation></semantics></math> at the level of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>N</mi><mrow><mo>−</mo><mn>1</mn><mi>/</mi><mn>2</mn></mrow></msup><annotation encoding="application/x-tex">N^{-1/2}</annotation></semantics></math>; (II) When we lose this control, the impact of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> is no longer canceled by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><annotation encoding="application/x-tex">\rho_{{R,X}}</annotation></semantics></math>, leading to a <i>Law of Large Populations</i> (LLP), that is, our estimation error, relative to the benchmarking rate <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>/</mi><msqrt><mi>n</mi></msqrt></mrow><annotation encoding="application/x-tex">1/\sqrt{n}</annotation></semantics></math>, increases with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msqrt><mi>N</mi></msqrt><annotation encoding="application/x-tex">\sqrt{N}</annotation></semantics></math>; and (III) the “bigness” of such Big Data (for population inferences) should be measured by the <i>relative size</i> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>=</mo><mi>n</mi><mi>/</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">f=n/N</annotation></semantics></math>, not the <i>absolute size</i> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>; (IV) When combining data sources for population inferences, those relatively tiny but higher quality ones should be given far more weights than suggested by their sizes.</p><p>Estimates obtained from the Cooperative Congressional Election Study (CCES) of the 2016 US presidential election suggest a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ρ</mi><mrow><mi>R</mi><mo>,</mo><mi>X</mi></mrow></msub><mo>≈</mo><mo>−</mo><mn>0.005</mn></mrow><annotation encoding="application/x-tex">\rho_{{R,X}}\approx-0.005</annotation></semantics></math> for self-reporting to vote for Donald Trump. Because of LLP, this seemingly minuscule data defect correlation implies that the simple sample proportion of the self-reported voting preference for Trump from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">1\%</annotation></semantics></math> of the US eligible voters, that is, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≈</mo><mn>2</mn><mtext mathvariant="normal">,</mtext><mn>300</mn><mtext mathvariant="normal">,</mtext><mn>000</mn></mrow><annotation encoding="application/x-tex">n\approx2\mbox{,}300\mbox{,}000</annotation></semantics></math>, has the same mean squared error as the corresponding sample proportion from a genuine simple random sample of size <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≈</mo><mn>400</mn></mrow><annotation encoding="application/x-tex">n\approx400</annotation></semantics></math>, a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>99.98</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">99.98\%</annotation></semantics></math> reduction of sample size (and hence our confidence). The CCES data demonstrate LLP vividly: on average, the larger the state’s voter populations, the further away the actual Trump vote shares from the usual <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>95</mn><mi>%</mi></mrow><annotation encoding="application/x-tex">95\%</annotation></semantics></math> confidence intervals based on the sample proportions. This should remind us that, without taking data quality into account, population inferences with Big Data are subject to a <i>Big Data Paradox</i>: the more the data, the surer we fool ourselves.</p>'
- - 'https://www.journalofexpertise.org/articles/volume2_issue4/JoE_2_4_Kell&Wai.pdf'
  - "Right-Tail Range Restriction: A Lurking Threat to Detecting Associations between Traits and Skill among Experts"
  - Harrison J. Kell, Jonathan Wai
  - '2019'
  - ''
  - ! 'It has been claimed by prominent authors that there is no relationship between differences in some human traits (e.g., cognitive ability, physical ability) and differences in skill among experts. We assert that the failure to detect such associations is often due to an extreme form of range restriction that particularly plagues research focused on expert samples: <em>right-tail range restriction</em> (RTRR). RTRR refers to a lack of representation of data from the far right segment of the normal distribution, inhibiting the observation of statistical associations. Using two example studies we demonstrate that, when RTRR is not present, relationships between differences in experts’ traits and differences in their degree of skill can be observed. Based on the characteristics of these studies we make recommendations for methodological practices that can be followed to help investigators overcome RTRR and facilitate the continued development of a robust and replicable science of expertise. [Keywords: Range restriction, expertise, traits, cognitive ability, physical ability, performance, athletics, psychological attributes]'
- - '/docs/genetics/correlation/2019-pgc.pdf'
  - 'Genomic Relationships, Novel Loci, and Pleiotropic Mechanisms across Eight Psychiatric Disorders'
  - Cross-Disorder Group of the Psychiatric Genomics Consortium (PGC)
  - 2019-12-12
  - '10.1016/j.cell.2019.11.020'
  - ! '<ul><li>Three groups of highly genetically-related disorders among 8 psychiatric disorders</li><li>Identified 109 pleiotropic loci affecting more than one disorder</li><li>Pleiotropic genes show heightened expression beginning in 2nd prenatal trimester</li><li>Pleiotropic genes play prominent roles in neurodevelopmental processes</li></ul><p>Genetic influences on psychiatric disorders transcend diagnostic boundaries, suggesting substantial pleiotropy of contributing loci. However, the nature and mechanisms of these pleiotropic effects remain unclear. We performed analyses of 232,964 cases and 494,162 controls from genome-wide studies of anorexia nervosa, attention-deficit/hyperactivity disorder, autism spectrum disorder, bipolar disorder, major depression, obsessive-compulsive disorder, schizophrenia, and Tourette syndrome. Genetic correlation analyses revealed a meaningful structure within the eight disorders, identifying three groups of inter-related disorders. Meta-analysis across these eight disorders detected 109 loci associated with at least two psychiatric disorders, including 23 loci with pleiotropic effects on four or more disorders and 11 loci with antagonistic effects on multiple disorders. The pleiotropic loci are located within genes that show heightened expression in the brain throughout the lifespan, beginning prenatally in the second trimester, and play prominent roles in neurodevelopmental processes. These findings have important implications for psychiatric nosology, drug development, and risk prediction.</p>'
- - /docs/catnip/2017-ottoni.pdf
  - "The palaeogenetics of cat dispersal in the ancient world"
  - Claudio Ottoni, Wim Van Neer, Bea De Cupere, Julien Daligault, Silvia Guimaraes, Joris Peters, Nikolai Spassov, Mary E. Prendergast, Nicole Boivin, Arturo Morales-Muñiz, Adrian Bălăşescu, Cornelia Becker, Norbert Benecke, Adina Boroneant, Hijlke Buitenhuis, Jwana Chahoud, Alison Crowther, Laura Llorente, Nina Manaseryan, Hervé Monchot, Vedat Onar, Marta Osypińska, Olivier Putelat, Eréndira M. Quintana Morales, Jacqueline Studer, Ursula Wierer, Ronny Decorte, Thierry Grange, Eva-Maria Geigl
  - 2017-06-19
  - 10.1038/s41559-017-0139
  - ! 'The cat has long been important to human societies as a pest-control agent, object of symbolic value and companion animal, but little is known about its domestication process and early anthropogenic dispersal. Here we show, using ancient DNA analysis of geographically and temporally widespread archaeological cat remains, that both the Near Eastern and Egyptian populations of <em>Felis silvestris lybica</em> contributed to the gene pool of the domestic cat at different historical times. While the cat’s worldwide conquest began during the Neolithic period in the Near East, its dispersal gained momentum during the Classical period, when the Egyptian cat successfully spread throughout the Old World. The expansion patterns and ranges suggest dispersal along human maritime and terrestrial routes of trade and connectivity. A coat-colour variant was found at high frequency only after the Middle Ages, suggesting that directed breeding of cats occurred later than with most other domesticated animals.'
- - /docs/psychology/2008-macknik.pdf
  - "Attention and awareness in stage magic: turning tricks into research"
  - Stephen L. Macknik, Mac King, James Randi, Apollo Robbins, Teller, John Thompson, Susana Martinez-Conde
  - 2008-07-30
  - 10.1038/nrn2473
  - ! "Just as vision scientists study visual art and illusions to elucidate the workings of the visual system, so too can cognitive scientists study cognitive illusions to elucidate the underpinnings of cognition. Magic shows are a manifestation of accomplished magic performers' deep intuition for and understanding of human attention and awareness. By studying magicians and their techniques, neuroscientists can learn powerful methods to manipulate attention and awareness in the laboratory. Such methods could be exploited to directly study the behavioural and neural basis of consciousness itself, for instance through the use of brain imaging and other neural recording techniques."
- - https://scholarspace.manoa.hawaii.edu/bitstream/10125/64076/0269.pdf
  - "Knowledge Sharing Network in a Community of Illicit Practice: A Cybermarket Subreddit Case"
  - K. Hazel Kwon, Weiwen Yu, Steve Kilar, Chun Shao, Kailey Broussard, Thomas Lutes
  - 2020-01-07
  - ''
  - ! 'Often neglected in the literature about communities of practice is the fact that online knowledge-sharing communities thrive among illicit collectives whose activities are stigmatized or outlawed. This paper focuses on a knowledge-sharing community of users who engage in illegal practices by examining the ways in which the community’s network structure changes when a high-stakes, uncertain event—the July 2017 shutdown of the dark web market Alphabay—occurs. This study compares the discussion network structures in the subreddit r/AlphaBay during pre-shutdown days (the “routine” period) and shutdown days (the “market defect” period) and offers a content analysis of the knowledge and resources shared by users during these periods. Several differences were observed: (a) the network structure changed such that the network size grew while becoming more centralized; (b) new crisis-specific players emerged; (c) types of knowledge shared during the market defect period was qualitatively different from the routine period.'
- - https://www.laurenceking.com/blog/2019/09/26/dorodango-blog/
  - "Dorodango, the Japanese art of making mud balls: <em>Dorodango</em> author Bruce Gardner shares the story of how he discovered the Japanese art of hikaru dorodango"
  - Bruce Gardner
  - 2019-09-26
  - ''
  - ! '<p>[Photo essay on making shiny balls of mud.]</p> <p>Hi there, this is Bruce Gardner. I am out of Albuquerque, New Mexico and my strange superpower is: I am very good at making mud balls, aka hikaru dorodango. I’m taking over the Laurence King blog today to introduce my new book, <a href="https://www.laurenceking.com/product/dorodango/"><em>Dorodango: The Japanese Art of Making Mud Balls</em></a>…Coming from the words <em>doro</em>, meaning “mud” and <em>dango</em>, a type of Japanese flour cake, hikaru dorodango consists of forming a mud ball by hand. Layers of increasingly fine dirt are added to the surface over the space of days to a point at which the dorodango can be polished to a high sheen (hikaru means “shining”)…I was introduced to hikaru dorodango by <a href="https://www.gwern.net/docs/japanese/2002-gibson">a William Gibson essay</a> in Tate Magazine, way back in 2002. I was immediately bowled over by the idea of creating art from such a humble material; I have been creating mud balls ever since.</p><p>…Here is an image of a few of my pieces that illustrate the scope of colour and texture that is possible with soil gathered from different locations (various parts of New Mexico, in this case).</p><p><img src="https://s3-eu-west-1.amazonaws.com/laurence-king/wp-content/uploads/2019/09/20163632/Dorodango-by-Bruce-Gardner-Laurence-King-Publishing1-1440x1080.jpg" /></p><p>…The process of creating hikaru dorodango is very conducive to flow: There is a repetitive quality to the work but it is still challenging as the dorodango changes, one minute to the next. Your mind remains engaged but you’re disconnected from everything else. Hours can easily slip by this way…How sturdy are they? That varies by soil. Some would shatter like glass if you dropped them. This one would dent your hardwood floor and roll away.</p>'
- - https://www.frontiersin.org/articles/10.3389/fendo.2019.00845/full
  - "Utility and First Clinical Application of Screening Embryos for Polygenic Disease Risk Reduction"
  - Nathan R. Treff, Jennifer Eccles, Lou Lello, Elan Bechor, Jeffrey Hsu, Kathryn Plunkett, Raymond Zimmerman, Bhavini Rana, Artem Samoilenko, Steven Hsu, Laurent C. A. M. Tellier (Genomic Prediction)
  - 2019-12-04
  - '10.3389/fendo.2019.00845'
  - ! 'For over 2 decades preimplantation genetic testing (PGT) has been in clinical use to reduce the risk of miscarriage and genetic disease in patients with advanced maternal age and risk of transmitting disease. Recently developed methods of genome-wide genotyping and machine learning algorithms now offer the ability to genotype embryos for polygenic disease risk with accuracy equivalent to adults. In addition, contemporary studies on adults indicate the ability to predict polygenic disorders with risk equivalent to monogenic disorders. Existing biobanks provide opportunities to model the clinical utility of polygenic disease risk reduction among sibling adults. Here, we provide a mathematical model for the use of embryo screening to reduce the risk of type 1 diabetes. Results indicate a 45–72% reduced risk with blinded genetic selection of one sibling. The first clinical case of polygenic risk scoring in human preimplantation embryos from patients with a family history of complex disease is reported. In addition to these data, several common and accepted practices place PGT for polygenic disease risk in the applicable context of contemporary reproductive medicine. In addition, prediction of risk for PCOS, endometriosis, and aneuploidy are of particular interest and relevance to patients with infertility and represent an important focus of future research on polygenic risk scoring in embryos.'
- - https://jamanetwork.com/journals/jama/fullarticle/2759201
  - Backlash Over Meat Dietary Recommendations Raises Questions About Corporate Ties to Nutrition Scientists
  - Rita Rubin (JAMA)
  - 2020-01-15
  - 10.1001/jama.2019.21441
  - ! '<p>[Summary of vegetarian activist/researcher reaction to recent reviews &amp; meta-analysis indicating that the correlation of meat-eating with bad health often does not appear in epidemiological datasets, the randomized experiments do not support the strong claims, and the overall evidence that eating meat = bad health is low quality &amp; weak:</p><ul><li><a href="https://annals.org/aim/fullarticle/2752329/meat-consumption-health-food-thought">“Meat Consumption and Health: Food for Thought”</a>, Carroll &amp; Doherty 2019 (editorial)</li><li><a href="https://annals.org/aim/fullarticle/2752320/red-processed-meat-consumption-risk-all-cause-mortality-cardiometabolic-outcomes">“Red and Processed Meat Consumption and Risk for All-Cause Mortality and Cardiometabolic Outcomes: A Systematic Review and Meta-analysis of Cohort Studies”</a>, Zeraatkar et al 2019a</li><li><a href="https://annals.org/aim/fullarticle/2752321/reduction-red-processed-meat-intake-cancer-mortality-incidence-systematic-review">“Reduction of Red and Processed Meat Intake and Cancer Mortality and Incidence: A Systematic Review and Meta-analysis of Cohort Studies”</a>, Han et al 2019</li><li><a href="https://annals.org/aim/fullarticle/2752327/patterns-red-processed-meat-consumption-risk-cardiometabolic-cancer-outcomes-systematic">“Patterns of Red and Processed Meat Consumption and Risk for Cardiometabolic and Cancer Outcomes: A Systematic Review and Meta-analysis of Cohort Studies”</a>, Vernooij et al 2019</li><li><a href="https://www.gwern.net/docs/longevity/2019-zeraatkar.pdf">“Effect of Lower Versus Higher Red Meat Intake on Cardiometabolic and Cancer Outcomes: A Systematic Review of Randomized Trials”</a>, Zeraatkar et al 2019b</li><li><a href="https://annals.org/aim/fullarticle/2752323/health-related-values-preferences-regarding-meat-consumption-mixed-methods-systematic">“Health-Related Values and Preferences Regarding Meat Consumption: A Mixed-Methods Systematic Review”</a>, Valli et al 2019</li><li><a href="https://annals.org/aim/fullarticle/2752328/unprocessed-red-meat-processed-meat-consumption-dietary-guideline-recommendations-from">“Unprocessed Red Meat and Processed Meat Consumption: Dietary Guideline Recommendations From the Nutritional Recommendations (NutriRECS) Consortium”</a>, Johnston et al 2019</li></ul><p>After breaking the embargo, they began lobbying against it, spamming the journal editor, demanding the papers be retracted before publication, denouncing it in talks, and contacting the Federal Trade Commission &amp; district attorneys demanding they investigate; they justify these activities by saying that since high-quality evidence can’t be easily obtained in nutrition, there is no need for it, and accusing the authors of financial conflicts of interest and comparing them to global warming deniers.</p><p>However, the conflicts of interest represent very small percentages of funding, and the vegetarian activist/researchers themselves are heavily funded by anti-meat interests, such as olive research institutions, walnut industry bodies, the egg industry, snack companies, and alternative diet groups, with the list of funders of one member including but far from limited to “the <a href="https://en.wikipedia.org/wiki/Pulse_(legume)">Pulse</a> Research Network, the Almond Board of California, the International Nut and Dried Fruit Council; Soy Foods Association of North America; the Peanut Institute; Kellogg’s Canada; and Quaker Oats Canada.”]</p>'
- - https://annals.org/aim/fullarticle/2752329/meat-consumption-health-food-thought
  - "Meat Consumption and Health: Food for Thought"
  - Aaron E. Carroll, Tiffany S. Doherty
  - 2019-11-19
  - 10.7326/M19-2620
  - ! '<p>For some time, medical and science organizations have been beating the drum that red and processed meat are bad for you. For almost as long, they have lamented that their efforts to inform the public have not convinced enough people to change their consumption. This month’s issue offers us food for thought on why. The field of nutritional epidemiology is plagued by observational studies that have conducted inappropriate analyses, accompanied by likely erroneous conclusions (1). Many studies selectively report results, and many lack an a priori hypothesis. Many use notoriously unreliable self-reports of food consumption while failing to collect or appropriately control for data on numerous potential confounders.</p><p>…Four more studies join the evidence base this month, and because they review all of the evidence that came before, they cannot be accused of cherry-picking. The first was a meta-analysis of cohort studies that focused on how dietary patterns, including differing amounts of red or processed meat, affected all-cause mortality, cardiometabolic outcomes, and cancer incidence and mortality (6). More than 100 studies including more than 6 million participants were analyzed. The overall conclusions were that dietary patterns, including differences in meat consumption, may result in only small differences in risk outcomes over long periods.</p><p>The next study was a meta-analysis that homed in specifically on cohort studies examining how reductions in red and processed meat might affect cancer incidence and mortality (7). It included 118 studies with more than 6 million participants, and it, too, found that the possible impact of reduced meat intake was very small. The third study was a meta-analysis of cohort studies that looked specifically at meat consumption and its relationship to all-cause mortality and cardiometabolic outcomes (8), and—once again—it found that any link was very small.</p><p>…In a fourth analysis in this issue (9), researchers examined randomized controlled trials that compared diets with differing amounts of red meat consumption for at least 6 months. They found 12 eligible studies, but one of them—the Women’s Health Initiative—was so large (almost 49 000 women) that it dominated the analysis. We can wish for more studies, and we could hope that they had more homogenous outcomes and better fidelity to assigned diets, but the overall conclusions from what they had were that “red meat may have little or no effect on major cardiometabolic outcomes and cancer mortality and incidence.”</p><p>…it may be time to stop producing observational research in this area. These meta-analyses include millions of participants. Further research involving much smaller cohorts has limited value. High-quality randomized controlled trials are welcome, but only if they’re designed to tell us things we don’t already know.</p>'
- - https://annals.org/aim/fullarticle/2752328/unprocessed-red-meat-processed-meat-consumption-dietary-guideline-recommendations-from
  - "Unprocessed Red Meat and Processed Meat Consumption: Dietary Guideline Recommendations From the Nutritional Recommendations (NutriRECS) Consortium"
  - 'Bradley C. Johnston, Dena Zeraatkar, Mi Ah Han, Robin W.M. Vernooij, Claudia Valli, Regina El Dib, Catherine Marshall, Patrick J. Stover, Susan Fairweather-Taitt, Grzegorz Wójcik, Faiz Bhatia, Russell de Souza, Carlos Brotons, Joerg J. Meerpohl, Chirag J. Patel, Benjamin Djulbegovic, Pablo Alonso-Coello, Malgorzata M. Bala, Gordon H. Guyatt'
  - '2019-11-19'
  - '10.7326/M19-1621'
  - ! '<p><em>Description</em>: Dietary guideline recommendations require consideration of the certainty in the evidence, the magnitude of potential benefits and harms, and explicit consideration of people’s values and preferences. A set of recommendations on red meat and processed meat consumption was developed on the basis of 5 de novo systematic reviews that considered all of these issues.</p><p><em>Methods</em>: The recommendations were developed by using the Nutritional Recommendations (NutriRECS) guideline development process, which includes rigorous systematic review methodology, and GRADE methods to rate the certainty of evidence for each outcome and to move from evidence to recommendations. A panel of 14 members, including 3 community members, from 7 countries voted on the final recommendations. Strict criteria limited the conflicts of interest among panel members. Considerations of environmental impact or animal welfare did not bear on the recommendations. Four systematic reviews addressed the health effects associated with red meat and processed meat consumption, and 1 systematic review addressed people’s health-related values and preferences regarding meat consumption.</p><p><em>Recommendations</em>: The panel suggests that adults continue current unprocessed red meat consumption (weak recommendation, low-certainty evidence). Similarly, the panel suggests adults continue current processed meat consumption (weak recommendation, low-certainty evidence).</p>'
- - https://annals.org/aim/fullarticle/2752327/patterns-red-processed-meat-consumption-risk-cardiometabolic-cancer-outcomes-systematic
  - "Patterns of Red and Processed Meat Consumption and Risk for Cardiometabolic and Cancer Outcomes: A Systematic Review and Meta-analysis of Cohort Studies"
  - Robin W.M. Vernooij, Dena Zeraatkar, Mi Ah Han, MD, Regina El Dib, Max Zworth, Kirolos Milio, Daegan Sit, Yung Lee, Huda Gomaa, Claudia Valli, Mateusz J. Swierz, Yaping Chang, Steven E. Hanna, Paula M. Brauer, John Sievenpiper, Russell de Souza, Pablo Alonso-Coello, Malgorzata M. Bala, Gordon H. Guyatt, Bradley C. Johnston
  - 2019-11-19
  - 10.7326/M19-1583
  - ! '<p><em>Background</em>: Studying dietary patterns may provide insights into the potential effects of red and processed meat on health outcomes.</p><p><em>Purpose</em>: To evaluate the effect of dietary patterns, including different amounts of red or processed meat, on all-cause mortality, cardiometabolic outcomes, and cancer incidence and mortality.</p><p><em>Data Sources</em>: Systematic search of <span class="smallcaps">MEDLINE</span>, <span class="smallcaps">EMBASE</span>, the Cochrane Central Register of Controlled Trials, <span class="smallcaps">CINAHL</span>, Web of Science, and ProQuest Dissertations &amp; Theses Global from inception to April 2019 with no restrictions on year or language.</p><p><em>Study Selection</em>: Teams of 2 reviewers independently screened search results and included prospective cohort studies with 1000 or more participants that reported on the association between dietary patterns and health outcomes.</p><p><em>Data Extraction</em>: Two reviewers independently extracted data, assessed risk of bias, and evaluated the certainty of evidence using <span class="smallcaps">GRADE</span> (Grading of Recommendations Assessment, Development and Evaluation) criteria.</p><p><em>Data Synthesis</em>: Eligible studies that followed patients for 2 to 34 years revealed low- to very-low-certainty evidence that dietary patterns lower in red and processed meat intake result in very small or possibly small decreases in all-cause mortality, cancer mortality and incidence, cardiovascular mortality, nonfatal coronary heart disease, fatal and nonfatal myocardial infarction, and type 2 diabetes. For all-cause, cancer, and cardiovascular mortality and incidence of some types of cancer, the total sample included more than 400 000 patients; for other outcomes, total samples included 4000 to more than 300 000 patients.</p><p><em>Limitation</em>: Observational studies are prone to residual confounding, and these studies provide low- or very-low-certainty evidence according to the <span class="smallcaps">GRADE</span> criteria.</p><p><em>Conclusion</em>: Low- or very-low-certainty evidence suggests that dietary patterns with less red and processed meat intake may result in very small reductions in adverse cardiometabolic and cancer outcomes.</p>'
- - https://annals.org/aim/fullarticle/2752323/health-related-values-preferences-regarding-meat-consumption-mixed-methods-systematic
  - "Health-Related Values and Preferences Regarding Meat Consumption: A Mixed-Methods Systematic Review"
  - Claudia Valli, Montserrat Rabassa, Bradley C. Johnston, Ruben Kuijpers, Anna Prokop-Dorner, Joanna Zajac, Dawid Storman, Monika Storman, Malgorzata M. Bala, Ivan Solà, Dena Zeraatkar, Mi Ah Han, Robin W.M. Vernooij, Gordon H. Guyatt, Pablo Alonso-Coello
  - 2019-11-19
  - 10.7326/M19-1326
  - ! '<p><em>Background</em>: A person’s meat consumption is often determined by their values and preferences.</p><p><em>Purpose</em>: To identify and evaluate evidence addressing health-related values and preferences regarding meat consumption.</p><p><em>Data Sources</em>: <span class="smallcaps">MEDLINE</span>, <span class="smallcaps">EMBASE</span>, Web of Science, Centre for Agriculture and Biosciences Abstracts, International System for Agricultural Science and Technology, and Food Science and Technology Abstracts were searched from inception to July 2018 without language restrictions.</p><p><em>Study Selection</em>: Pairs of reviewers independently screened search results and included quantitative and qualitative studies reporting adults’ health-related values and preferences regarding meat consumption.</p><p><em>Data Extraction</em>: Pairs of reviewers independently extracted data and assessed risk of bias.</p><p><em>Data Synthesis</em>: Data were synthesized into narrative form, and summaries were tabulated and certainty of evidence was assessed using the <span class="smallcaps">GRADE</span> (Grading of Recommendations Assessment, Development and Evaluation) approach. Of 19 172 initial citations, 41 quantitative studies (38 addressed reasons for meat consumption and 5 addressed willingness to reduce meat consumption) and 13 qualitative studies (10 addressed reasons for meat consumption and 4 addressed willingness to reduce meat consumption) were eligible for inclusion. Thirteen studies reported that omnivores enjoy eating meat, 18 reported that these persons consider meat an essential component of a healthy diet, and 7 reported that they believe they lack the skills needed to prepare satisfactory meals without meat. Omnivores are generally unwilling to change their meat consumption. The certainty of evidence was low for both “reasons for meat consumption” and “willingness to reduce meat consumption in the face of undesirable health effects.”</p><p><em>Limitation</em>: Limited generalizability of findings to lower-income countries, low-certainty evidence for willingness to reduce meat consumption, and limited applicability to specific types of meat (red and processed meat).</p><p><em>Conclusion</em>: Low-certainty evidence suggests that omnivores are attached to meat and are unwilling to change this behavior when faced with potentially undesirable health effects.</p>'
- - https://annals.org/aim/fullarticle/2752321/reduction-red-processed-meat-intake-cancer-mortality-incidence-systematic-review
  - "Reduction of Red and Processed Meat Intake and Cancer Mortality and Incidence: A Systematic Review and Meta-analysis of Cohort Studies"
  - Mi Ah Han, Dena Zeraatkar, Gordon H. Guyatt, Robin W.M. Vernooij, Regina El Dib, Ying Zhang, Abdullah Algarni, Gareth Leung, Dawid Storman, Claudia Valli, Montserrat Rabassa, Nadia Rehman, Michael K. Parvizian, Max Zworth, Luciane Cruz Lopes, Daegan Sit, Malgorzata M. Bala, Pablo Alonso-Coello, Bradley C. Johnston
  - 2019-11-19
  - 10.7326/M19-0699
  - ! '<p><em>Background</em>: Cancer incidence has continuously increased over the past few centuries and represents a major health burden worldwide.</p><p><em>Purpose</em>: To evaluate the possible causal relationship between intake of red and processed meat and cancer mortality and incidence.</p><p><em>Data Sources</em>: Embase, Cochrane Central Register of Controlled Trials, Web of Science, <span class="smallcaps">CINAHL</span>, and ProQuest from inception until July 2018 and <span class="smallcaps">MEDLINE</span> from inception until April 2019 without language restrictions.</p><p><em>Study Selection</em>: Cohort studies that included more than 1000 adults and reported the association between consumption of unprocessed red and processed meat and cancer mortality and incidence.</p><p><em>Data Extraction</em>: Teams of 2 reviewers independently extracted data and assessed risk of bias; 1 reviewer evaluated the certainty of evidence, which was confirmed or revised by the senior reviewer.</p><p><em>Data Synthesis</em>: Of 118 articles (56 cohorts) with more than 6 million participants, 73 articles were eligible for the dose–response meta-analyses, 30 addressed cancer mortality, and 80 reported cancer incidence. Low-certainty evidence suggested that an intake reduction of 3 servings of unprocessed meat per week was associated with a very small reduction in overall cancer mortality over a lifetime. Evidence of low to very low certainty suggested that each intake reduction of 3 servings of processed meat per week was associated with very small decreases in overall cancer mortality over a lifetime; prostate cancer mortality; and incidence of esophageal, colorectal, and breast cancer.</p><p><em>Limitation</em>: Limited causal inferences due to residual confounding in observational studies, risk of bias due to limitations in diet assessment and adjustment for confounders, recall bias in dietary assessment, and insufficient data for planned subgroup analyses.</p><p><em>Conclusion</em>: The possible absolute effects of red and processed meat consumption on cancer mortality and incidence are very small, and the certainty of evidence is low to very low.</p>'
- - https://annals.org/aim/fullarticle/2752320/red-processed-meat-consumption-risk-all-cause-mortality-cardiometabolic-outcomes
  - "Red and Processed Meat Consumption and Risk for All-Cause Mortality and Cardiometabolic Outcomes: A Systematic Review and Meta-analysis of Cohort Studies"
  - Dena Zeraatkar, Mi Ah Han, Gordon H. Guyatt, Robin W.M. Vernooij, Regina El Dib, Kevin Cheung, Kirolos Milio, Max Zworth, Jessica J. Bartoszko, Claudia Valli, Montserrat Rabassa, Yung Lee, Joanna Zajac, Anna Prokop-Dorner, Calvin Lo, Malgorzata M. Bala, Pablo Alonso-Coello, Steven E. Hanna, Bradley C. Johnston
  - 2019-11-19
  - 10.7326/M19-0655
  - ! '<p><em>Background</em>: Dietary guidelines generally recommend limiting intake of red and processed meat. However, the quality of evidence implicating red and processed meat in adverse health outcomes remains unclear.</p><p><em>Purpose</em>: To evaluate the association between red and processed meat consumption and all-cause mortality, cardiometabolic outcomes, quality of life, and satisfaction with diet among adults.</p><p><em>Data Sources</em>: <span class="smallcaps">EMBASE</span> (Elsevier), Cochrane Central Register of Controlled Trials (Wiley), Web of Science (Clarivate Analytics), <span class="smallcaps">CINAHL</span> (<span class="smallcaps">EBSCO</span>), and ProQuest from inception until July 2018 and <span class="smallcaps">MEDLINE</span> from inception until April 2019, without language restrictions, as well as bibliographies of relevant articles.</p><p><em>Study Selection</em>: Cohort studies with at least 1000 participants that reported an association between unprocessed red or processed meat intake and outcomes of interest.</p><p><em>Data Extraction</em>: Teams of 2 reviewers independently extracted data and assessed risk of bias. One investigator assessed certainty of evidence, and the senior investigator confirmed the assessments.</p><p><em>Data Synthesis</em>: Of 61 articles reporting on 55 cohorts with more than 4 million participants, none addressed quality of life or satisfaction with diet. Low-certainty evidence was found that a reduction in unprocessed red meat intake of 3 servings per week is associated with a very small reduction in risk for cardiovascular mortality, stroke, myocardial infarction (MI), and type 2 diabetes. Likewise, low-certainty evidence was found that a reduction in processed meat intake of 3 servings per week is associated with a very small decrease in risk for all-cause mortality, cardiovascular mortality, stroke, MI, and type 2 diabetes.</p><p><em>Limitation</em>: Inadequate adjustment for known confounders, residual confounding due to observational design, and recall bias associated with dietary measurement.</p><p><em>Conclusion</em>: The magnitude of association between red and processed meat consumption and all-cause mortality and adverse cardiometabolic outcomes is very small, and the evidence is of low certainty.</p>'
- - /docs/psychology/2008-macknik.pdf
  - "Attention and awareness in stage magic: turning tricks into research"
  - Stephen L. Macknik, Mac King, James Randi, Apollo Robbins, Teller, John Thompson, Susana Martinez-Conde
  - 2008-07-30
  - 10.1038/nrn2473
  - ! "Just as vision scientists study visual art and illusions to elucidate the workings of the visual system, so too can cognitive scientists study cognitive illusions to elucidate the underpinnings of cognition. Magic shows are a manifestation of accomplished magic performers' deep intuition for and understanding of human attention and awareness. By studying magicians and their techniques, neuroscientists can learn powerful methods to manipulate attention and awareness in the laboratory. Such methods could be exploited to directly study the behavioural and neural basis of consciousness itself, for instance through the use of brain imaging and other neural recording techniques."
- - https://www.tensorflow.org/tfrc
  - "TensorFlow Research Cloud (TFRC): Accelerate your cutting-edge machine learning research with free Cloud TPUs"
  - TFRC (Google)
  - ''
  - ''
  - ! "<p>The TensorFlow Research Cloud (TFRC) program enables researchers to apply for access to a cluster of more than 1,000 Cloud TPUs. In total, this cluster delivers a total of more than 180 petaflops of raw compute power! Researchers accepted into the TFRC program can use these Cloud TPUs at no charge to accelerate the next wave of open research breakthroughs. Participants in the TFRC program will be expected to share their TFRC-supported research with the world through peer-reviewed publications, open source code, blog posts, or other means. They should also be willing to share detailed feedback with Google to help us improve the TFRC program and the underlying Cloud TPU platform over time. In addition, participants accept Google's Terms and Conditions, acknowledge that their information will be used in accordance with our Privacy Policy, and agree to conduct their research in accordance with the Google AI principles. Machine learning researchers around the world have done amazing things with the limited computational resources they currently have available. We'd like to empower researchers from many different backgrounds to think even bigger and tackle exciting new challenges that would be inaccessible otherwise.</p> <p>[TFRC is an easy-to-apply cloud credit program which grants free access to up to hundreds of GCP TPUs and sometimes whole TPU pods to researchers & hobbyists like me; I relyed on TFRC credits to train a variety of GPT-2-1.5b models which are infeasible on consumer GPUs. It took seconds to apply, they replied in hours with credits, and were highly responsive thereafter as we encountered various TPU issues.]</p>"
- - https://thegradient.pub/machine-learning-ancient-japan/
  - How Machine Learning Can Help Unlock the World of Ancient Japan
  - Alex Lamb
  - 2019-11-17
  - ''
  - ! '<p>Humanity’s rich history has left behind an enormous number of historical documents and artifacts. However, virtually none of these documents, containing stories and recorded experiences essential to our cultural heritage, can be understood by non-experts due to language and writing changes over time…This is a global problem, yet one of the most striking examples is the case of Japan. From 800 until 1900 CE, Japan used a writing system called Kuzushiji, which was removed from the curriculum in 1900 when the elementary school education was reformed. Currently, the overwhelming majority of Japanese speakers cannot read texts which are more than 150 years old. The volume of these texts—comprised of over three million books in storage but only readable by a handful of specially-trained scholars—is staggering. One library alone has digitized 20 million pages from such documents. The total number of documents—including, but not limited to, letters and personal diaries—is estimated to be over one billion. Given that very few people can understand these texts, mostly those with PhDs in classical Japanese literature and Japanese history, it would be very expensive and time-consuming to finance for scholars to convert these documents to modern Japanese. This has motivated the use of machine learning to automatically understand these texts.</p><p>…Given its importance to Japanese culture, the problem with utilizing computers to help with Kuzushiji recognition has been explored extensively through the use of various methods in deep learning and computer vision. However, these models were unable to achieve strong performance on Kuzushiji recognition. This was due to inadequate understanding of Japanese historical literature in the optical character recognition (OCR) community and the lack of high quality standardized datasets. To address this, the National Institute of Japanese Literature (NIJL) created and released a Kuzushiji dataset, curated by the Center for Open Data in the Humanities (CODH). The dataset currently has over 4000 character classes and a million character images.</p><p><strong>KuroNet</strong>: KuroNet is a Kuzushiji transcription model that I developed with my collaborators, Tarin Clanuwat and Asanobu Kitamoto from the ROIS-DS Center for Open Data in the Humanities at the National Institute of Informatics in Japan. The KuroNet method is motivated by the idea of processing an entire page of text together, with the goal of capturing both long-range and local dependencies. KuroNet passes images containing an entire page of text through a residual U-Net architecture (FusionNet) in order to obtain a feature representation…For more information about KuroNet, please checkout our paper <a href="https://arxiv.org/abs/1910.09433" title="Clanuwat et al 2019">“KuroNet: Pre-Modern Japanese Kuzushiji Character Recognition with Deep Learning”</a>, which was accepted to the 2019 International Conference on Document Analysis and Recognition (ICDAR)</p><p>…<strong>Kaggle Kuzushiji Recognition Competition</strong>: While KuroNet achieved state-of-the-art results at the time of its development and was published in the top tier conference on document analysis and recognition, we wanted to open this research up to the broader community. We did this partially to stimulate further research on Kuzushiji and to discover ways in which KuroNet may be deficient. Ultimately, after 3 months of competition, which saw 293 teams, 338 competitors, and 2652 submissions, the winner achieved an F1 score of 0.950. When we evaluated KuroNet on the same setup, we found that it achieved an F1 score 0.902, which would have put it in 12th place—which, although acceptable, remains well below the best performing solutions.</p><p>…<strong>Future Research</strong>: The work done by CODH has already led to substantial progress in transcribing Kuzushiji documents, however, the overall problem of unlocking the knowledge of historical documents is far from solved.</p>'
- - https://scholarspace.manoa.hawaii.edu/bitstream/10125/64319/0465.pdf
  - "Dishing the Deets: How dark-web users teach each other about international drug shipments"
  - Reagan C. Smith, Richard Frank
  - 2020-01-07
  - ''
  - ! 'International trafficking of drugs enabled by the dark-web is still a problem despite the increase in take-down actions. Even though the transaction takes place digitally, the national postal systems are the ones being exploited and used for delivery. Users of the dark-web readily share information on forums, cryptomarkets, and feedback pages to maximize their safety and success while conducting these drug transactions. Using data collected from forums, vendor profiles, and feedback pages, this study provides an evidence that the knowledge being shared on the dark-web is rich data law enforcement and governments need to use as intelligence. Users discuss all aspect of the delivery process, including proper addressing, stealth packaging, and risks associated with taking delivery of the package. Based on these findings, policy recommendations are made to guide the implementation of techniques to counter the rise of dark-web-enabled drug shipments in the fight against drugs and cryptomarkets....Data collected for this research was obtained from two forums and one cryptomarket between the period of November 2017 and April 2018. [/r/DNM, Dread, & Dream Market respectively].'
- - https://onlinelibrary.wiley.com/doi/full/10.1002/acp.3532
  - "Background music stints creativity: Evidence from compound remote associate tasks"
  - Emma Threadgold, John E. Marsh, Neil McLatchie, Linden J. Ball
  - 2019-02-02
  - 10.1002/acp.3532
  - ! "Background music has been claimed to enhance people's creativity. In three experiments, we investigated the impact of background music on performance of Compound Remote Associate Tasks (CRATs), which are widely thought to tap creativity. Background music with foreign (unfamiliar) lyrics (Experiment 1), instrumental music without lyrics (Experiment 2), and music with familiar lyrics (Experiment 3) all significantly impaired CRAT performance in comparison with quiet background conditions. Furthermore, Experiment 3 demonstrated that background music impaired CRAT performance regardless of whether the music induced a positive mood or whether participants typically studied in the presence of music. The findings challenge the view that background music enhances creativity and are discussed in terms of an auditory distraction account (interference-by-process) and the processing disfluency account."
- - https://mindhacks.com/2016/12/08/rational-judges-not-extraneous-factors-in-decisions/
  - "Rational Judges, Not Extraneous Factors In Decisions"
  - Tom Stafford
  - 2016-12-08
  - ''
  - ! '<p>This seeming evidence of the irrationality of judges has been cited hundreds of times, in economics, psychology and legal scholarship. Now, a new analysis by <a href="http://journal.sjdm.org/16/16823/jdm16823.html" title="The irrational hungry judge effect revisited: Simulations reveal that the magnitude of the effect is overestimated">Andreas Glöckner in the journal <em>Judgement and Decision Making</em></a> questions these conclusions.</p><p>Glöckner’s analysis doesn’t prove that extraneous factors weren’t influencing the judges, but he shows how the same effect could be produced by entirely rational judges interacting with the protocols required by the legal system.</p><p>The main analysis works like this: we know that favourable rulings take longer than unfavourable ones (~7 mins vs ~5 mins), and we assume that judges are able to guess how long a case will take to rule on before they begin it (from clues like the thickness of the file, the types of request made, the representation the prisoner has and so on). Finally, we assume judges have a time limit in mind for each of the three sessions of the day, and will avoid starting cases which they estimate will overrun the time limit for the current session.</p><p>It turns out that this kind of rational time-management is sufficient to generate the drops in favourable outcomes. How this occurs isn’t straightforward and interacts with a quirk of original author’s data presentation (specifically their graph shows the order number of cases when the number of cases in each session varied day to day–so, for example, it shows that the 12<sup>th</sup> case after a break is least likely to be judged favourably, but there wasn’t always a 12<sup>th</sup> case in each session. So sessions in which there were more unfavourable cases were more likely to contribute to this data point).</p>'
- - http://nautil.us/blog/impossibly-hungry-judges
  - Impossibly Hungry Judges
  - Daniël Lakens
  - 2017-07-05
  - ''
  - ! '<p>I was listening to a recent Radiolab episode on blame and guilt, where the guest Robert Sapolsky mentioned a famous study on judges handing out harsher sentences before lunch than after lunch….During the podcast, it was mentioned that the percentage of favorable decisions drops from 65% to 0% over the number of cases that are decided on. This sounded unlikely. I looked at Figure 1 from the paper (below), and I couldn’t believe my eyes. Not only is the drop indeed as large as mentioned—it occurs three times in a row over the course of the day, and after a break, it returns to exactly 65%!</p><p>…Some people dislike statistics. They are only interested in effects that are so large, you can see them by just plotting the data. This study might seem to be a convincing illustration of such an effect. My goal in this blog is to argue against this idea. You need statistics, maybe <em>especially</em> when effects are so large they jump out at you. When reporting findings, authors should report <em>and interpret</em> effect sizes. An important reason for this is that effects can be impossibly large.</p><p>…If hunger had an effect on our mental resources of this magnitude, our society would fall into minor chaos every day at 11:45 a.m. Or at the very least, our society would have organized itself around this incredibly strong effect of mental depletion. Just like manufacturers take size differences between men and women into account when producing items such as golf clubs or watches, we would stop teaching in the time before lunch, doctors would not schedule surgery, and driving before lunch would be illegal. If a psychological effect is this big, we don’t need to discover it and publish it in a scientific journal—you would already know it exists. Sort of how the “after lunch dip” is a strong and replicable finding that you can <em>feel</em> yourself (and that, as it happens, is directly in conflict with the finding that judges perform better immediately after lunch—surprisingly, the authors don’t discuss the <em>after lunch dip</em>).</p><p>…I think it is telling that most psychologists don’t seem to be able to recognize data patterns that are too large to be caused by psychological mechanisms. There are simply no plausible psychological effects that are strong enough to cause the data pattern in the hungry judges study. Implausibility is not a reason to completely dismiss empirical findings, but impossibility is. It is up to authors to interpret the effect size in their study, and to show the mechanism through which an effect that is impossibly large, becomes plausible. Without such an explanation, the finding should simply be dismissed.</p>'
- - https://www.newyorker.com/magazine/2020/01/13/a-world-without-pain
  - "A World Without Pain: Does hurting make us human?"
  - Ariel Levy (The New Yorker)
  - 2020-01-06
  - ''
  - ! '<p>Cameron is entirely insensitive to physical pain. As a child, she fell and hurt her arm while roller-skating, but had no idea she’d broken it until her mother noticed that it was hanging strangely. Giving birth was no worse…Cameron was having a trapeziectomy, an operation to remove a small bone at the base of the thumb joint. Though her hands never hurt, they’d become so deformed by arthritis that she couldn’t hold a pen properly. She’d had a similar experience with her hip, which had recently been replaced; it didn’t hurt, but her family noticed that she wasn’t walking normally. She saw her local doctor about it several times, but the first question was always “How much pain are you in?” And the answer was always “None.” (“The third time I was there I think they figured, ‘We’ll just take an X-ray to shut this woman up,’” Cameron told me. “Then the X-ray came in and it was really bad. Everything was all distorted and mangled and crumbling. He said, ‘<em>Wow</em>. This has got to be done.’”)…Cameron is beguiled by the idea that she can help alleviate others’ suffering—she remembers the terrible migraines that tormented her mother. Her father, however, was pain-free. “I never saw him take an aspirin,” Cameron said. “I’m convinced he was the same as me, because I never heard my father complaining about any pain, ever. He died suddenly, of a brain hemorrhage—I think other people would have had a warning.” ¶ …People with severe congenital neuropathy tend to die young, because they injure themselves so frequently and severely. (Without pain, children are in constant danger. They swallow something burning hot, the esophagus ruptures, bacteria spill into the internal organs, and terminal sepsis sets in. They break their necks roughhousing. To protect some patients, doctors have removed all their teeth to prevent them from chewing off their tongues and bleeding to death.) ¶ …Cameron does not have neuropathy: she can feel all the sensations the rest of us do, except pain. The most striking difference between her and everyone else is the way she processes endocannabinoids—chemicals that exist naturally in every human brain. Endocannabinoids mitigate our stress response, and they bind to the same receptors as the THC in the kind of cannabis you smoke. Normally, they are broken down by an enzyme called fatty acid amide hydrolase, or FAAH. But Cameron has a mutation on her FAAH gene that makes the enzyme less effective—so her endocannabinoids build up. She has extraordinarily high levels of one in particular: anandamide, whose name is derived from the Sanskrit word for “bliss.” ¶ About a third of the population has a mutation in the FAAH gene, which provides increased levels of anandamide. “That phenotype—low levels of anxiety, forgetfulness, a happy-go-lucky demeanor—isn’t representative of how everyone responds to cannabis, but you see a lot of the prototypical changes in them that occur when people consume cannabis,” said Matthew Hill, a biologist at the University of Calgary’s Hotchkiss Brain Institute, who was a co-author of the Cameron paper. The FAAH gene, like every gene, comes in a pair. People who have the mutation in one allele of the gene seem a little high; people who have it in both even more so. Jo Cameron is fully baked. “When I met Jo for the first time, I was just struck by her,” Cox, an affable forty-year-old with a scruffy beard, told me, one afternoon in his lab at U.C.L. “She was <em>very</em> chatty. Did you notice that?” (It’s hard to miss.) “I said to her, ‘Are you worried about what’s going to happen today?’ Because she was meeting our clinicians to have a skin biopsy and do quantitative sensory testing—pain-threshold tests. She said, ‘No. In fact, I’m never worried about anything.’” Cox told me that it was difficult to get through everything in the time they’d allotted, because Cameron was so friendly and loquacious with the scientists, even as they burned her, stuck her with pins, and pinched her with tweezers until she bled. This imperviousness to pain is what makes her distinct from everyone else with a FAAH mutation. They, like even the most committed stoners, can still get hurt. ¶ …I asked Matthew Hill—a renowned expert on cannabinoids and stress—if there was any downside to Cameron’s biology, and he laughed out loud. “Yes! From an evolutionary perspective, it would be tremendously destructive for a species to have that,” he said. Without fear, you drown in waves that you shouldn’t be swimming in; you take late-night strolls in cities that you don’t know; you go to work at a construction site and neglect to put on a hard hat. “Her phenotype is only beneficial in an environment where there is no danger,” Hill asserted. “If you can’t be concerned about a situation where you’d be at risk of something adverse happening to you, you are more likely to put yourself in one. Anxiety is a highly adaptive process: that’s why every mammalian species exhibits some form of it.” ¶ Unlike other pain-insensitive people, Cameron has made it into her seventies without getting badly hurt. Sometimes she realizes that she’s burning her hand on the stove because she smells singeing; sometimes she cuts herself in the garden and sees that she’s bleeding. But none of that has been severe, and Cameron did raise two children safely into adulthood. “The human brain is very capable of learning, ‘This is what’s appropriate to do in this situation,’” Hill said. Cameron’s relative cautiousness may have developed imitatively. “And there may not have been that much threat presented to her—she’s lived in a rural community in Scotland,” he concluded. “Maybe she hasn’t had to deal with that much that would physically or emotionally harm her.” ¶ …One complicating question is how much of Cameron’s Cameronness is really a consequence of her FAAH mutation and FAAH OUT deletion. She has plenty of other genes, after all, and her upbringing and her early environment also played a role in making her who she is. Since the paper was published, Matthew Hill has heard from half a dozen people with pain insensitivity, and he told me that many of them seemed nuts. “If you had this phenotype and weren’t a generally pleasant person like Jo—maybe you’re, like, a douche-y frat boy—the way that you would process this might be entirely different. Our whole perception of this phenotype is explicitly based on the fact that it was Jo who presented it.”</p>'
- - https://csimq-journals.rtu.lv/article/download/csimq.2019-21.04/1744
  - "Evaluation of Adblock Software Usage"
  - Anna Sołtysik-Piorunkiewicz, Artur Strzelecki, Edyta Abramek
  - 2019-12
  - 10.7250/csimq.2019-21.04
  - ! 'The article shows the main factors of adblocking software usage. The study was based on data obtained by a web questionnaire. The research was focused on evaluation of ad blocking (adblock) software usage factors in five categories: (1) gender, age, and education; (2) use of advertising and sources of knowledge about advertising; (3) technical and social reasons for blocking online advertisements; (4) usage of an adblock-wall; and (5) type of online advertisement. An evaluation of adblock usage factors revealed four main technical reasons for adblock usage connected with website technology and web development problems—interruption, amount of ads, speed, and security; and one social reason for adblock usage, namely, the problem of privacy. [Keywords: Adblock Software, Web Advertisement, Website, Security, Privacy.]'
- - /docs/eva/2012-hoffer.pdf
  - "Aesthetics of Destruction: Music and the Worldview of Shinji Ikari in <em>Neon Genesis Evangelion</em>"
  - Heike Hoffer
  - '2012'
  - ''
  - ! "Director Anno Hideaki's series <em>Neon Genesis Evangelion</em> caused a sensation when it first aired on TV Tokyo in 1995 and has become one of the most influential anime ever made. Since its premiere, fans across the globe have debated the possible interpretations of the complex plot, but little has been said about how composer Sagisu Shiro's score might contribute to understanding the series. Anno's rehabilitation in a Jungian clinic and subsequent personal study of human psychology plays heavily into understanding the main character Ikari Shinji, and music has much to contribute to appreciating Shinji's view of the world. Shinji is an impressionable fourteen-year old boy, so his musical interpretations of the people and things around him do not always match reality. Sagisu's music gives the viewers welcome insight into Shinji's thoughts and feelings as he matures throughout the series."
- - /docs/economics/2016-kuran.pdf
  - "Legal Roots of Authoritarian Rule in the Middle East: Civic Legacies of the Islamic Waqf"
  - "Timur Kuran"
  - '2016'
  - "10.5131/AJCL.2016.0014"
  - ! "In the legal system of the premodern Middle East, the closest thing to an autonomous private organization was the Islamic waqf. This non-state institution inhibited political participation, collective action, and rule of law, among other indicators of democratization. It did so through several mechanisms. Its activities were essentially set by its founder, which limited its capacity to meet political challenges. Being designed to provide a service on its own, it could not participate in lasting political coalitions. The waqf’s beneficiaries had no say in evaluating or selecting its officers, and they had trouble forming a political community. Thus, for all the resources it controlled, the Islamic waqf contributed minimally to building civil society. As a core element of Islam’s classical institutional complex, it perpetuated authoritarian rule by keeping the state largely unrestrained. Therein lies a key reason for the slow pace of the Middle East’s democratization process."
- - https://github.com/ricsonc/transformers-play-chess/blob/master/README.md
  - Transformers Play Chess
  - Ricson Cheng
  - 2020-01-10
  - ''
  - ! '<p>The Shannon entropy of natural English language is roughly one byte per word, depending on the dataset used. Shannon estimated the number of possible chess games to be 10<sup>120</sup>. I’ve also seen an estimate of 3 reasonable moves per ply (so 10<sup>40</sup> possible 40 move games). This begs the question: just how much information is there in a chess move?…I treated this as a sequence modeling problem. An alternative (and possibly better) approach would be to explicitly make use of the board state. However as I was lazy, I did not do this. I was also motivated by the idea of recreating blindfold chess, which is challenging for humans, but unclear for computers (how would you blindfold a computer?—(also see Tom Murphy’s Elo World)). Also as the “arkovian” approach of simply predicting the move given the current board state has been done many, many times before, I decided this was more interesting.</p><p>…The <code>lichess.org</code> game database contains at the time of writing roughly 1 billion games…I chose to use long algebraic notation, which specifies the start and end coordinate of every piece moved (for example, e2e4). “special” moves also include castling and promotion. There are slightly less than 2000 valid unique tokens in this notation</p><p>…I used the <code>transformer_big_single_gpu</code> (henceforth known as T78) model from the tensor2tensor repository which has roughly 78 million parameters. I used the default hyperparameters and did not tune anything. I trained on a single 1080ti for almost 4 days (~2 million steps). This turns out to be roughly 50 million games, which is to say, the model only saw 25% of the dataset.</p><p>…Results:</p><ul><li>A games: 2.15 bits per ply, 4.43 perplexity</li><li>B games: 2.26 bits per ply, 4.80 perplexity</li></ul><p>I “preregistered” a guess of 2.5 bits per ply before running any experiments. After seeing the results, I believe a better designed model could probably reach between 1.6 and 2.0 BPP. I also believe a larger model would perform better, as I was probably close to saturating the capacity of T78.</p><p>[Response to <a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/">“A Very Unlikely Chess Game”</a>, see <a href="https://www.reddit.com/r/slatestarcodex/comments/el87vo/a_very_unlikely_chess_game/fdh0vqd/">Reddit</a>.]</p>'
- - /docs/genetics/selection/2019-trumble.pdf
  - "The Exposome in Human Evolution: From Dust to Diesel"
  - Benjamin C. Trumble, Caleb E. Finch
  - 2019-12
  - 10.1086/706768
  - ! 'Global exposures to air pollution and cigarette smoke are novel in human evolutionary history and are associated with at least 12 million premature deaths per year. We investigate the history of the human <em>exposome</em> for relationships between novel environmental toxins and genetic changes during human evolution in six phases. Phase I: With increased walking on savannas, early human ancestors inhaled crustal dust, fecal aerosols, and spores; carrion scavenging introduced new infectious pathogens. Phase II: Domestic fire exposed early <em>Homo</em> to novel toxins from smoke and cooking. Phases III and IV: Neolithic to preindustrial <em>Homo</em> sapiens incurred infectious pathogens from domestic animals and dense communities with limited sanitation. Phase V: Industrialization introduced novel toxins from fossil fuels, industrial chemicals, and tobacco at the same time infectious pathogens were diminishing. Thereby, pathogen-driven causes of mortality were replaced by chronic diseases driven by sterile inflammogens, exogenous and endogenous. Phase VI: Considers future health during global warming with increased air pollution and infections. We hypothesize that adaptation to some ancient toxins persists in genetic variations associated with inflammation and longevity. [Keywords: exposome, human evolution, genes, toxins, infections.]'
- - https://www.nytimes.com/2020/01/13/science/air-pollution-fires-genes.html
  - "Air Pollution, Evolution, and the Fate of Billions of Humans: It’s not just a modern problem. Airborne toxins are so pernicious that they may have shaped our DNA over millions of years"
  - Carl Zimmer (The New York Times)
  - 2020-01-13
  - ''
  - ! '<p>Scientists are still figuring out how air pollution causes these ailments. They are also puzzling over the apparent resilience that some people have to this modern onslaught. Some researchers now argue that the answers to these questions lie in our distant evolutionary past, millions of years before the first cigarette was lit and the first car hit the road.</p><p>Our ancestors were bedeviled by airborne toxins even as bipedal apes walking the African savanna, argued Benjamin Trumble, a biologist at Arizona State University, and Caleb Finch of the University of Southern California, in the December issue of the Quarterly Review of Biology. Our forebears evolved defenses against these pollutants, the scientists propose. Today, those adaptations may provide protection, albeit limited, against tobacco smoke and other airborne threats. But our evolutionary legacy may also be a burden, Dr. Trumble and Dr. Finch speculated. Some genetic adaptations may have increased our vulnerability to diseases linked to air pollution. It is “a really creative, interesting contribution to evolutionary medicine,” said Molly Fox, an anthropologist at the University of California, Los Angeles, who was not involved in the new study. The story begins about seven million years ago. Africa at the time was gradually growing more arid. The Sahara emerged in northern Africa, while grasslands opened up in eastern and southern Africa. The ancestors of chimpanzees and gorillas remained in the retreating forests, but our ancient relatives adapted to the new environments. They evolved into a tall, slender frame well suited to walking and running long distances. Dr. Finch and Dr. Trumble believe that early humans faced another challenge that has gone largely overlooked: the air. Periodically, the savanna would have experienced heavy dust storms from the Sahara, and our distant ancestors may have risked harm to their lungs from breathing in the silica-rich particles. “When the dust is up, we’re going to see more pulmonary problems,” Dr. Finch said. Even today, Greek researchers have found that when Sahara winds reach their country, patients surge into hospitals with respiratory complaints. The dense foliage of tropical forests gave chimpanzees and gorillas a refuge from dust. But the earliest humans, wandering the open grasslands, had nowhere to hide. Dust was not the only hazard. The lungs of early humans also may have been irritated by the high levels of pollen and particles of fecal matter produced by the savanna’s vast herds of grazing animals. Dr. Finch and Dr. Trumble maintain that scientists should consider whether these new challenges altered our biology through natural selection. Is it possible, for instance, that people who are resilient to cigarette smoke have inherited genetic variants that protected their distant ancestors from cave fires?</p><p>…“Most traditional people live in a highly smoky environment,” Dr. Finch said. “I think it has been a fact of human living for us even before our species.” Smoke created a new evolutionary pressure, he and Dr. Trumble believe. Humans evolved powerful liver enzymes, for example, to break down toxins passing into the bloodstream from the lungs. Gary Perdew, a molecular toxicologist at Penn State University, and his colleagues have found evidence of smoke-driven evolution in another gene, <span class="smallcaps">AHR</span>. This gene makes a protein found on cells in the gut, lungs and skin. When toxins get snagged on the protein, cells release enzymes that break down the poisons. Other mammals use <span class="smallcaps">AHR</span> to detoxify their food. But the protein is also effective against some of the compounds in wood smoke. Compared to other species, the human version produces a weaker response to toxins, perhaps because <span class="smallcaps">AHR</span> protein is not the perfect protector—the fragments it leaves behind can cause tissue damage. Before fire, our ancestors did not need to use <span class="smallcaps">AHR</span> very often; in theory, their bodies could tolerate the limited damage the protein caused. But when we began breathing smoke regularly and needing the <span class="smallcaps">AHR</span> protein constantly, the gene might have become dangerous to our health. Dr. Perdew believes that humans evolved a weaker <span class="smallcaps">AHR</span> response as a way to find “a sweet spot,” a compromise that minimized the damage of airborne pollutants without causing too many side effects. These adaptations were never perfect, as evidenced by the fact that millions of people still die today from indoor air pollution. But evolution doesn’t seek perfect health.</p>'
- - https://www.stalbansreview.co.uk/news/4125149.blind-veteran-tells-tales-from-war-and-life-since/
  - "Blind veteran tells tales from war and life since: An ex-serviceman blinded in battle has spoken exclusively to reporter Alexandra Barham about the horrors of war and the trials and tribulations of life that followed without sight"
  - Alexandra Barham, Michael Tetley
  - 2009-02-13
  - ''
  - ! '<p>Mike, who was born and raised in Kenya speaking its native language Swahili, was conscripted to command indigenous troops in the King’s African Rifles as unrest began to spread throughout his homeland. It was after Mau Mau militants ambushed a police truck that a battle erupted between the rivals. A clash Mike so vividly recalls as it marked the last time he could appreciate the gift of sight before it was lost. Remembering the battle, Mike said: <q>“One of the Mau Mau threw a grenade at me and it landed by my foot. I jumped away from it and threw myself on the ground hoping that when it went off I wouldn’t get hit.”</q>The next thing I remember I was running flat out and I got a bullet in my right ear which came out of my right eye. <q>“My dad always said I didn’t have anything between my ears and now he’s got definite proof.”</q>The next thing I remember I fell over and as I picked myself up everything went black. I sat down and I can’t remember much more than that—not in a logical sense anyway." Dissatisfied with blasting their victim with a rifle—nearly killing him—the Mau Mau rebels returned armed with machetes to cut up Mike, who lay helpless on the ground nursing his wound. Powerless to defend himself, Mike has always owed his survival to an ally soldier, Reguton—with whom he still has regular contact—who shot dead the seven rebels.</p><p>…Mike was transferred to a military hospital in England after the attack where he received the devastating news that he would never see again. Just a week before the shooting Mike had asked for his girlfriend’s hand in marriage, but following doctors’ gloomy prognosis he broke off the engagement. <q>“After I was blinded I never thought I could look after a wife,”</q> he said. <q>“I didn’t think I would be able to look after myself let alone anyone else—it’s one of my biggest regrets.”</q> But anxious not to allow his disability to blight the years ahead of him, Mike began learning the art of braille at St Dunstan’s, a national charity for the blind. Soon after Mike enrolled on a physiotherapy course with the Royal National Institute for the Blind (<span class="smallcaps">RNIB</span>) suggested by his dad who felt the career suited his structural interests. It was during his training that he met his late wife Selma, and the couple eventually married in 1957. For the past 45 years Mike has been running a thriving physiotherapy clinic at his St Albans home and he remains committed to his work.</p>'
- - https://www.theguardian.com/society/2011/jul/17/the-rape-of-men
  - "The rape of men: the darkest secret of war: Sexual violence is one of the most horrific weapons of war, an instrument of terror used against women. Yet huge numbers of men are also victims. In this harrowing report, Will Storr travels to Uganda to meet traumatised survivors, and reveals how male rape is endemic in many of the world's conflicts"
  - Will Storr (The Guardian)
  - 2011-07-17
  - ''
  - ! '<p>Of all the secrets of war, there is one that is so well kept that it exists mostly as a rumour. It is usually denied by the perpetrator and his victim. Governments, aid agencies and human rights defenders at the UN barely acknowledge its possibility. Yet every now and then someone gathers the courage to tell of it…<q>“That was hard for me to take,”</q> Owiny tells me today. <q>“There are certain things you just don’t believe can happen to a man, you get me? But I know now that sexual violence against men is a huge problem. Everybody has heard the women’s stories. But nobody has heard the men’s.”</q></p><p>It’s not just in East Africa that these stories remain unheard. One of the few academics to have looked into the issue in any detail is Lara Stemple, of the University of California’s Health and Human Rights Law Project. Her study <a href="https://repository.uchastings.edu/cgi/viewcontent.cgi?article=3728&amp;context=hastings_law_journal#page=2" title="Stemple 2009"><q>“Male Rape and Human Rights”</q></a> notes incidents of male sexual violence as a weapon of wartime or political aggression in countries such as Chile, Greece, Croatia, Iran, Kuwait, the former Soviet Union and the former Yugoslavia. Twenty-one per cent of Sri Lankan males who were seen at a London torture treatment centre reported sexual abuse while in detention. In El Salvador, 76% of male political prisoners surveyed in the 1980s described at least one incidence of sexual torture. A study of 6,000 concentration-camp inmates in Sarajevo found that 80% of men reported having been raped…Dolan first heard of wartime sexual violence against men in the late 1990s while researching his PhD in northern Uganda, and he sensed that the problem might be dramatically underestimated. Keen to gain a fuller grasp of its depth and nature, he put up posters throughout Kampala in June 2009 announcing a <q>“workshop”</q> on the issue in a local school. On the day, 150 men arrived. In a burst of candour, one attendee admitted: <q>“It’s happened to all of us here.”</q>…a rare 2010 survey, published in the Journal of the American Medical Association, found that 22% of men and 30% of women in Eastern Congo reported conflict-related sexual violence.</p><p>…Back at <span class="smallcaps">RLP</span> I’m told about the other ways in which their clients have been made to suffer. Men aren’t simply raped, they are forced to penetrate holes in banana trees that run with acidic sap, to sit with their genitals over a fire, to drag rocks tied to their penis, to give oral sex to queues of soldiers, to be penetrated with screwdrivers and sticks. Atim has now seen so many male survivors that, frequently, she can spot them the moment they sit down. <q>“They tend to lean forward and will often sit on one buttock,”</q> she tells me. <q>“When they cough, they grab their lower regions. At times, they will stand up and there’s blood on the chair. And they often have some kind of smell.”</q></p>'
- - https://www.theguardian.com/world/2017/nov/03/revealed-male-used-systematically-in-libya-as-instrument-of-war
  - "Revealed: male rape used systematically in Libya as instrument of war: Videos and testimony expose brutal tactics used by several factions in fractured country"
  - Cécile Allegra
  - 2017-11-03
  - ''
  - ! '<p>Male rape is being used systematically in Libya as an instrument of war and political domination by rival factions, according to multiple testimonies gathered by investigators. Years of work by a Tunis-based group and witnessed by a journalist from <em>Le Monde</em> have produced harrowing reports from victims, and video footage showing men being sodomised by various objects, including rockets and broom handles. In several instances, witnesses say a victim was thrown into a room with other prisoners, who were ordered to rape him or be killed.</p><p>The atrocity is being perpetrated to humiliate and neutralise opponents in the lawless, militia-dominated country. Male rape is such a taboo in Arab societies that the abused generally feel too damaged to rejoin political, military or civic life. One man, Ahmed, told investigators he was detained for four years in a prison in Tomina, on the outskirts of Misrata. “They separate you to subjugate you,” he said. “‘Subjugate the men’, that’s the expression that they use. So that you never hold your head up again. And they were filming everything with their phones. “They take a broom and fix it on the wall. If you want to eat, you have to take off your pants, back on to the broom and not move off until the jailer sees blood flowing. Nobody can escape it.”</p><p>…In one camp, south of Tripoli, a man called Ali recounted his experience. He was 39 but looked 65 and walked with a cane. “Some of us were locked in a room, naked, for a whole night with groups of migrants,” he said. “The guards did not release them until they had all raped each other. Fortunately, I didn’t go through that, I only got the stick and the wheel.” The “wheel” involved being put naked and folded double, through a tyre suspended from the ceiling, making it easier for torturers to penetrate him with weaponry. Ali said he now had physical problems, “leaks” as he called them.</p><p>In another camp in southern Tripoli, Fathia said women were not immune. She said her entire family was violated by a militia from Misrata, with the men being deliberately targeted. “They dragged me in the street, in front of everyone, saying: ‘You raped our girls. We’ll do the same thing to you.’ “The worst thing they did to me,” she whispered, “is to rape me in front of my eldest son. Since then, he won’t speak to me.” Asked about other inmates who suffered a similar ordeal, Fathia said: “I only heard men’s voices. They were screaming, day and night.”</p>'
- - /docs/economics/2017-akam-theexquisitelyenglishandamazinglylucrativeworldoflondonclerks.html
  - "The Exquisitely English (and Amazingly Lucrative) World of London Clerks: It’s a Dickensian profession that can still pay upwards of $650,000 per year"
  - Simon Akam (Bloomberg News)
  - 2017-05-23
  - ''
  - ! '<p>Alex/John/Mark Taylor belongs to one of the last surviving professions of Dickensian London. Clerks have co-existed with chimney sweeps and gene splicers. It’s a trade that one can enter as a teenager, with no formal qualifications, and that’s astonishingly well-paid. A senior clerk can earn a half-million pounds per year, or more than $650,000, and some who are especially entrenched make far more.</p><p>Clerks—pronounced “clarks”—have no equivalent in the U.S. legal system, and have nothing in common with the Ivy League–trained Supreme Court aides of the same spelling. They exist because in England and Wales, to simplify a bit, the role of lawyer is divided in two: There are solicitors, who provide legal advice from their offices, and there are barristers, who argue in court. Barristers get the majority of their business via solicitors, and clerks act as the crucial middlemen between the tribes—they work for and sell the services of their barristers, steering inquiring solicitors to the right man or woman. Clerks are by their own cheerful admission “wheeler-dealers,” what Americans might call hustlers. They take a certain pride in managing the careers of their bosses, the barristers—a breed that often combines academic brilliance with emotional fragility. Many barristers regard clerks as their pimps. Some, particularly at the junior end of the profession, live in terror of clerks. The power dynamic is baroque and deeply English, with a naked class divide seen in few other places on the planet. Barristers employ clerks, but a bad relationship can strangle their supply of cases. In his 1861 novel <em>Orley Farm</em>, Anthony Trollope described a barrister’s clerk as a man who “looked down from a considerable altitude on some men who from their professional rank might have been considered as his superiors.”…One of the most peculiar aspects of the clerk-barrister relationship is that clerks handle money negotiations with clients. Barristers argue that avoiding fee discussions keeps their own interactions with clients clean and uncomplicated, but as a consequence, they’re sometimes unaware of how much they actually charge. The practice also insulates and coddles them. Clerks become enablers of all sorts of curious, and in some cases self-destructive, behavior.</p><p>…John Flood, a legal sociologist who in 1983 published the only book-length study of barristers’ clerks, subtitled <em>The Law’s Middlemen</em>, uses an anthropological lens to explain the relationship. He suggests that barristers, as the de facto priests of English law—with special clothes and beautiful workplaces—require a separate tribe to keep the temple flames alight and press money from their congregation. Clerks keep barristers’ hands clean; in so doing they accrue power, and they’re paid accordingly. I asked more than a dozen clerks and barristers, as well as a professional recruiter, what the field pays. Junior clerks, traditionally recruited straight after leaving school at 16 and potentially with no formal academic qualifications, start at £15,000 to £22,000 ($19,500 to $28,600); after 10 years they can make £85,000. Pay for senior clerks ranges from £120,000 to £500,000, and a distinct subset can earn £750,000. The Institute of Barristers’ Clerks disputed these figures, saying the lows were too low and the highs too high. But there’s no doubt that the best clerks are well-rewarded. David Grief, 63, a senior clerk at the esteemed Essex Court Chambers, spoke to me enthusiastically about his personal light airplane, a TB20 Trinidad.</p><p>…Before the U.K. decimalized its currency in 1971, clerks received “shillings on the guinea” for each case fee. Under the new money system, the senior clerks’ take was standardized at 10% of their chambers’ gross revenue. Sometimes, but not always, they paid their junior staff and expenses out of this tithe. Chambers at the time were typically small, four to six barristers strong, but in the 1980s, they grew. As they added barristers and collected more money, each chambers maintained just one chief clerk, whose income soared. The system was opaque: The self-employed barristers didn’t know what their peers within their own chambers were paid, and in a precomputer age, with all transactions recorded in a byzantine paper system, barristers sometimes didn’t know what their clerks earned, either. Jason Housden, a longtime clerk who now works at Matrix Chambers, told me that, when he started out in the 1980s at another office, his senior clerk routinely earned as much as the top barristers and on occasion was the best-paid man in the building. ¶ One anecdote from around the same time, possibly apocryphal, is widely shared. At a chambers that had expanded and was bringing in more money, three silks decided their chief clerk’s compensation, at 10%, had gotten out of hand. They summoned him for a meeting and told him so. In a tactical response that highlights all the class baggage of the clerk-barrister relationship, as well as the acute British phobia of discussing money, the clerk surprised the barristers by agreeing with them. “I’m not going to take a penny more from you,” he concluded. The barristers, gobsmacked and paralyzed by manners, never raised the pay issue again, and the clerk remained on at 10% until retirement. ¶ Since the 1980s, fee structures have often been renegotiated when a senior clerk retires. Purely commission-based arrangements are now rare—combinations of salary and incentive are the rule, though some holdouts remain. Goddard told me last summer that he receives 3% of the entire take of the barristers at 4 Stone; later he said this was inaccurate, and that his pay was determined by a “complicated formula.” (Pupil barristers, as trainees are known, start there at £65,000 per year, and the top silks each make several million pounds.) ¶ The huge sums that clerks earn, at least relative to their formal qualifications, both sit at odds with the feudal nature of their employment and underpin it. In some chambers, clerks still refer to even junior barristers as “sir” or “miss.” Housden remembers discussing this issue early in his career with a senior clerk. He asked the man whether he found calling people half his age “sir” demeaning. The reply was straightforward: “For three-quarters of a million pounds per year, I’ll call anyone sir.”</p>'
- - https://www.reddit.com/r/SubSimulatorGPT2Meta/comments/entfgx/update_upgrading_to_15b_gpt2_and_adding_22_new/
  - "Update: Upgrading to 1.5B GPT-2, and adding 22 new subreddit-bots"
  - disumbrationist
  - '2020-01-12'
  - ''
  - ! '<p>When I originally trained the models in May 2019, I’d used the 345M version of GPT-2, which at the time was the largest one that OpenAI had publicly released. Last November, however, OpenAI <a href="https://openai.com/blog/gpt-2-1-5b-release/">finally released the full 1.5 billion parameter model</a>.</p><p>The 1.5B model requires much more memory to fine-tune than the 345M, so I was initially having a lot of difficulty getting it to work on Colab. Thankfully, I was contacted by <a href="https://www.reddit.com/u/gwern">/u/gwern</a> (<a href="https://www.patreon.com/gwern">here’s his Patreon</a>) and Shawn Presser (<a href="https://www.reddit.com/u/shawwwn">/u/shawwwn</a>), who very generously offered to do the fine-tuning themselves if I provided them with the dataset. This training took about 2 weeks, and apparently required <a href="https://twitter.com/gwern/status/1215005375407112193">around $70K worth of TPU credits</a>, so in hindsight this upgrade definitely wouldn’t have been possible for me to do myself, without their assistance.</p><p>Based on my tests of the new model so far, I’m pretty happy with the quality, and IMO it is noticeably more coherent than the 345M version.</p><p>One thing that I should point out about the upgrade is that the original 345M models had been separately fine-tuned for each subreddit individually (i.e. there were 108 separate models), whereas the upgraded one is just a single 1.5B model that has been fine-tuned using a combined dataset containing the comments/submissions from <em>all</em> the subreddits that I scraped. The main reason for this decision is simply that it would not have been feasible to train ~100 separate 1.5B models. Also, there may have been benefits from transfer learning across subreddits, which wouldn’t occur with separate models.</p><p>…Here is the full list of new bots to be added: /r/capitalismvsocialism ¶ /r/chess ¶ /r/conlangs ¶ /r/dota2 ¶ /r/etymology ¶ /r/fiftyfifty ¶ /r/hobbydrama ¶ /r/markmywords ¶ /r/moviedetails ¶ /r/neoliberal ¶ /r/obscuremedia ¶ /r/recipes ¶ /r/riddles ¶ /r/stonerphilosophy ¶ /r/subsimulatorgpt2 ¶ /r/subsimulatorgpt2meta ¶ /r/tellmeafact ¶ /r/twosentencehorror ¶ /r/ukpolitics ¶ /r/wordavalanches ¶ /r/wouldyourather ¶ /r/zen</p>'
- - http://unsongbook.com/
  - '<em>Unsong</em>'
  - Scott Alexander
  - 2015-12-28
  - ''
  - ! '<p>[<em>Unsong</em> is a finished (2015–2017) online web serial fantasy “kabbalah-punk” novel written by Scott Alexander (<a href="https://slatestarcodex.com/">SSC</a>). GoodReads summary:</p><blockquote><p>Aaron Smith-Teller works in a kabbalistic sweatshop in Silicon Valley, where he and hundreds of other minimum-wage workers try to brute-force the Holy Names of God. All around him, vast forces have been moving their pieces into place for the final confrontation. An overworked archangel tries to debug the laws of physics. Henry Kissinger transforms the ancient conflict between Heaven and Hell into a US-Soviet proxy war. A Mexican hedge wizard with no actual magic wreaks havoc using the dark art of placebomancy. The Messiah reads a book by Peter Singer and starts wondering exactly what it would mean to do as much good as possible…</p><p>Aaron doesn’t care about any of this. He and his not-quite-girlfriend Ana are engaged in something far more important – griping about magical intellectual property law. But when a chance discovery brings them into conflict with mysterious international magic-intellectual-property watchdog UNSONG, they find themselves caught in a web of plots, crusades, and prophecies leading inexorably to the end of the world.</p></blockquote><p><a href="https://tvtropes.org/pmwiki/pmwiki.php/Literature/Unsong">TVTropes</a>; <a href="https://www.goodreads.com/review/show/1997706071">my review of <em>Unsong</em></a>: ★★★★☆.]</p>'
- - /docs/sociology/2020-richmondrakerd.pdf
  - Clustering of health, crime and social-welfare inequality in 4 million citizens from two nations
  - Leah S. Richmond-Rakerd, Stephanie D’Souza, Signe Hald Andersen, Sean Hogan, Renate M. Houts, Richie Poulton, Sandhya Ramrakha, Avshalom Caspi, Barry J. Milne, Terrie E. Moffitt
  - 2020-01-20
  - 10.1038/s41562-019-0810-4
  - ! 'Health and social scientists have documented the hospital revolving-door problem, the concentration of crime, and long-term welfare dependence. Have these distinct fields identified the same citizens? Using administrative databases linked to 1.7 million New Zealanders, we quantified and monetized inequality in distributions of health and social problems and tested whether they aggregate within individuals. Marked inequality was observed: Gini coefficients equalled 0.96 for criminal convictions, 0.91 for public-hospital nights, 0.86 for welfare benefits, 0.74 for prescription-drug fills and 0.54 for injury-insurance claims. Marked aggregation was uncovered: a small population segment accounted for a disproportionate share of use-events and costs across multiple sectors. These findings were replicated in 2.3 million Danes. We then integrated the New Zealand databases with the four-decade-long Dunedin Study. The high-need/high-cost population segment experienced early-life factors that reduce workforce readiness, including low education and poor mental health. In midlife they reported low life satisfaction. Investing in young people’s education and training potential could reduce health and social inequalities and enhance population wellbeing.'
- - https://www.atlasobscura.com/articles/cyoa-choose-your-own-adventure-maps
  - "These Maps Reveal the Hidden Structures of <em>Choose Your Own Adventure</em> Books: If you decide to see more, click on this story"
  - Sarah Laskow (Atlas Obscura)
  - 2017-06-13
  - ''
  - ! '<p>The last installment of the original <a href="https://en.wikipedia.org/wiki/Choose_Your_Own_Adventure">“Choose Your Own Adventure”</a> series came out in 1998, but since 2004, <a href="https://en.wikipedia.org/wiki/Chooseco">Chooseco</a>, founded by one of the series’ original authors, R.A. Montgomery, has been republishing classic volumes, as well as new riffs on the form of interactive fiction that seemed ubiquitous in the 1980s and ’90s. The new editions also carry an additional feature—maps of the hidden structure of each book.</p><figure><img src="https://assets.atlasobscura.com/media/W1siZiIsInVwbG9hZHMvYXNzZXRzL2RlMTkxYzNlZjk4NGYyNmI3N19lYjMxYmQ3MDUzZWNhMDkzYmNfVGF0dG9vIE1hcC0xIGNvcHkuanBnIl0sWyJwIiwiY29udmVydCIsIiJdLFsicCIsImNvbnZlcnQiLCItcXVhbGl0eSA4MSAtYXV0by1vcmllbnQiXSxbInAiLCJ0aHVtYiIsIjEyODB4PiJdXQ/eb31bd7053eca093bc_Tattoo%20Map-1%20copy.jpg" alt="Tattoo of Death, Choose Your Own Adventure #22 (All maps courtesy of ChooseCo)" /><figcaption><em>Tattoo of Death</em>, Choose Your Own Adventure #22 (All maps courtesy of ChooseCo)</figcaption></figure><p>For years, fans have been creating visualizations of the forking structures of “Choose Your Own Adventure” books. Often, they’re interested in the types of outcomes at the end of each path. One map labels each ending as “new life, return home, or death,” and another separates them into “cliffhanger, solution, or death.” Christian Swinehart’s extensive graphical analysis of the books labels the endings as “great, favorable, mediocre, disappointing, or catastrophic.”</p><p>…Mapping the bones of the books can have other purposes, too. Nick Montfort, a poet and professor at the Massachusetts Institute of Technology who studies interactive fiction, has a habit of asking people what they know about “Choose Your Own Adventure” books. “They often say, ‘You have two choices after every page,’” he says. “That’s not true. Sometimes you have one choice. Sometimes you have more than two. When you show the maps, you can see that these books don’t look exactly the same.” The older volumes, for instance, tend to have more endings than the later ones, and three of the oldest—<em>Journey Under the Sea</em>, <em>Space and Beyond</em>, and <em>By Balloon to the Sahara</em>—have 42 endings each, more than any other books in the series….In just about every case, it can be surprising how a simple choice leads you down a complex path. In <em>By Balloon to the Sahara</em>, you’re in a balloon and are presented with a choice on the very first page. Storm clouds are on the horizon. Choice 1: “If you act now, you can release gas from the balloon and land before the storm overtakes you.” Choice 2: “Perhaps the storm will pass quickly. Maybe you can ride it out.” That’s just the beginning, since this book has the most decision points—48—of the series.</p><p>…There is yet another possibility in these nonlinear books: hidden endings. <em>Inside UFO 54-40</em> has a hidden ending that’s only available to a reader who ignores the decisions and flips to it without prompting. But it’s there. “It’s a two-page, big illustration of this city,” says Montfort, the MIT professor. “The land of Ultima. As you flip through the book, even if you’re being very obedient, you can’t help but wonder what this text is.”</p><p>…Maps like the ones Chooseco created can reveal the structure of a book that gives readers choices, but though the multiple story lines are part of what makes the series so fun, they’re not the only thing that defines it. The meat of “Choose Your Own Adventure” stories are gender-neutral romps in worlds where there are no obviously right or wrong moral choices. There’s danger around bend, usually in the form of something like space monkeys, malicious ghosts, or conniving grown-ups. Even with a map, there’s no way to find out what really comes next without making a choice and flipping to another page.</p>'
- - https://samizdat.co/cyoa/
  - "Choose Your Own Adventure: One Book, Many Readings"
  - Christian Swinehart
  - '2009'
  - ''
  - ! '<p>[Visualizing CYOA by generating graphs and coloring events by desirability; Swinehart observes distinct patterns in network types, harshness, linearity, and highlights various curious anomalies and tricks CYOA books could play on the reader.]</p> <p>...To get a sense for the distribution of pages within the actual CYOA books, I’ve prepared a dataset of 12 books. The earliest dates from 1979 and at the later edge are a handful from 1986. They are laid out chronologically (or according to series order for books released in the same year) with the oldest at the top left and more recent books below. Each book has been arranged into rows of ten pages apiece. In scanning over the distribution of colors in this plot, one clear pattern is a gradual decline in the number of endings. The earliest books (in the top row) are awash in reds and oranges, with a healthy number of ‘winning’ endings mixed in. Later CYOA books tended to favor a single ‘best’ ending (see CYOA 44 & 53). The most extreme case of this was actually not a Choose Your Own Adventure book at all but a gamebook offshoot of the Zork text adventure series. <em>The Cavern of Doom</em> (labeled WDIDN 3 above) has a virtually linear progression where endings later in the book are increasingly better than those on earlier pages. This is reflected in the nearly unbroken spectrum from red to blue when scanning down the rows. The one outlier is the catastrophic ending seen in the third row from the bottom. This was a punishment page that could only be reached by cheating. Unlike most other endings in the book it does not offer to let you continue the story from a few pages back but instead calls you a cheater and leaves you with no choice but to start over from the beginning. Another surprising change over time is the decline in the number of choices in the books. The mess of light grey boxes in the top row gives way to books like <em>A New Hope</em> (CYOASW 1) which have more pages devoted to linear narrative than to decisions and endings combined. But to address this apparent pattern with more rigor it would be best to look at the numbers of pages in each category independent of their placement in the book...I’d be very curious to know the reason for this progression toward linearity. Presumably the invisible hand was guiding this development, but whether the hunger was for less difficulty in the books or simply for something with more in the way of traditional storytelling is harder to unravel. I could also imagine that this balance between interaction and exposition was peculiar to the individual writers, so this could merely reflect a changing set of practitioners.</p>'
- - /docs/philo/1997-mikkelson.pdf
  - "Who Is Arguing About the Cat? Moral Action and Enlightenment According to Dōgen"
  - Douglas K. Mikkelson
  - 1997-07
  - 10.2307/1399911
  - ! '<blockquote><p>Once Ejo asked: “What is meant by the expression: ‘Cause and effect are not clouded’?” Dogen said: “Cause and effect are immovable.” Ejo asked: “If this is so, how can we escape?” Dogen replied: “Cause and effect emerge clearly at the same time.” Ejo asked: “If this is so, does cause prompt the next effect, or does effect bring about the next cause?” Dogen said: “If everything were like that, it would be like Nan-ch’uan cutting the cat. Because the assembly was unable to say anything, Nan-ch’uan cut the cat in two. Later, when Nan-ch’uan told this story to Chao-chou, the latter put his straw sandal on his head and went out, an excellent performance. If I had been Nan-ch’uan, I would have said: ‘Even if you can speak, I will cut the cat, and even if you cannot speak, I will still cut it. Who is arguing about the cat? Who can save the cat?’”</p></blockquote><p>—Dogen, <em>Shobogenzo Zuimonki</em>, 1.6<sup>1</sup></p><blockquote><p>…“One day a student asked me, ‘Does a man of enlightenment fall under the yoke of causation or not?’ I answered, ‘No, he does not.’ Since then I have been doomed to undergo five hundred rebirths as a fox. I beg you now to give the turning word to release me from my life as a fox. Tell me, does a man of enlightenment fall under the yoke of causation or not?” Hyakujo answered, “He does not ignore [cloud] causation [cause and effect].” No sooner had the old man heard these words than he was enlightened.<sup>2</sup></p></blockquote><p>“Causation” in this passage refers to “moral causation.” The Buddhist concept of karma acknowledges that good/bad deeds, thoughts, and so forth result in good/bad effects. Thus the import of the question posed by the “fox” is whether or not the enlightened person is subject to karma. Hyakujo’s answer, in effect, affirms that the enlightened person is subject to moral causation. Katsuki Sekida offers a common Zen interpretation of this passage in his comment: “Thus to ignore causation only compounds one’s malady. To recognize causation constitutes the remedy for it.”<sup>4</sup></p><p>Dōgen’s employment of this story in the “Daishugyo” chapter of the <a href="https://en.wikipedia.org/wiki/Sh%C5%8Db%C5%8Dgenz%C5%8D"><em>Shōbōgenzō</em></a> implies that, on one level, he thinks Hyakujo’s answer indeed provides a “remedy” for the old man’s predicament.<sup>5</sup> Yet Dogen was rarely content with merely citing traditional Zen interpretations of passages; typically, he sought to push his students to a further understanding by a creative reinterpretation of a passage. Lest his disciple therefore think this not-ignoring/recognition of causation is de facto a release from it in an ultimate sense, Dogen answers that the passage means “cause and effect are immovable.” In other words, moral causation, for Dogen, is an inexorable fact of human existence.</p><p>Given this fact, Ejo then asks how we can ever “escape” moral causation. Dogen’s response is enigmatic: “Cause and effect arise at the same time.” Nowhere in the <em>Shōbōgenzō Zuimonki</em> does he further clarify this passage. However, the key to understanding this statement can be gleaned from his discussion of causation in the “Shoakumakusa” chapter of the <em>Shōbōgenzō</em>, wherein he observes that “cause is not before and effect is not after.”<sup>6</sup> As Hee-Jin Kim explains, Dogen saw cause and effect as absolutely discontinuous moments that, in any given action, arise simultaneously from “thusness.” Therefore,</p><blockquote><p>no sooner does one choose and act according to a particular course of action than are the results thereof (heavens, hells, or otherwise) realized in it …. Man lives in the midst of causation from which he cannot escape even for a moment; nevertheless, he can live from moment to moment in such a way that these moments are the fulfilled moments of moral and spiritual freedom and purity in thusness.<sup>7</sup></p></blockquote><p>…Dogen’s own proposed response helps us to see the point he is trying to make via the words of the old Master: “In expressing full function, there are no fixed methods.” In other words, there is no fixed formula for expressing and eliciting without-thinking. Nan-ch’uan, in Dogen’s view, betrayed an attachment to only two positions—to kill or not kill the cat. He was “fixated,” we might say, by these two possibilities. This is evidenced by the fact that he does indeed carry out one of them precisely as he said he would.</p>'
- - https://www.goodreads.com/review/show/396645245
  - "Review of R. Scott Bakker's <em>Second Apocalypse</em>"
  - Gwern Branwen
  - 2017-08-03
  - ''
  - ! '<p>Review of <a href="https://en.wikipedia.org/wiki/R._Scott_Bakker">R. Scott Bakker’s</a> epic fantasy series, <em>The Second Apocalypse</em>, a philosophically-oriented retelling of the Crusades in a universe where advanced aliens, having learned that nothing matters and consciousness is an illusion and the gods are actually demons who feast on the suffering of the damned in the afterlife, seek to cut the world off from Hell and save themselves from eternal torment.</p><p>The series follows a monk from a hidden monastery of monks who have devoted themselves to the mastery of all intellectual / physical capabilities and freedom from any external influence or control or manipulation, which they call “the darkness that comes before” , who comes out into the world on a mission to assassinate his defector father who might interfere with the monastery’s mission, and, using his hyper-developed abilities, takes over countries to launch a crusade against his father, founds an empire, and succeeds in killing his father.</p><p>He then turns his crusade against the aliens, who are a threat to all humanity. Contemporaneously, the last survivor of the monks achieves enlightenment and commits suicide. After fighting across a continent and reaching the very throne room of the aliens and on the brink of defeating them, he fails when his son turns out to be the missing key to the aliens’ technology, enabling them to resurrect the ‘no-god’ which seals off the world from Hell.</p><p>I note that <em>The Second Apocalypse</em> draws heavily on Frank Herbert’s <em>Dune</em>, and both deal with similar themes of human capability and free will. But where Herbert sees increasing human freedom and capabilities as desirable and a progression without end, leading to endless destinations in a universe going on to infinity, Bakker sees liberation as leading to a ‘semantic holocaust’, where one realizes the empty illusion of consciousness and the nonexistence of morals, yielding only hedonism and nihilism; the monks’ goal of absolute freedom leads to an enlightenment whose logical consummation is death.</p>'
- - https://believermag.com/under-the-weather/
  - "Under the Weather: As Psychiatrists And Philosophers Begin To Define A Pervasive Mental Health Crisis Triggered By Climate Change, They Ask Who Is Really Sick: The Individual Or Society?"
  - Ash Sanders (The Believer)
  - 2019-12-02
  - ''
  - ! '<p>Eating fallen fruit and sleeping outside, however, didn’t provide him relief from his feelings of guilt and foreboding. He began to feel a dread that was inescapable and all-consuming. A devastating depression that he had suffered a few years before that fall semester returned. Normally a math phenom, Chris started failing his tests. In his apartment, he would sit in the dark—he didn’t want to waste electricity—listen to records, and cry. “I felt like I was slowly dying,” he said. A few months later, Chris left Davis to pursue a PhD in philosophy at the University of Kansas. But his condition didn’t improve. After having subsisted on scavenged persimmons and radishes for the entire fall term, he’d lost a dangerous amount of weight. His mother paid a visit to campus and, horrified by his appearance, immediately drove him to the grocery store to buy food. At home, Chris’s family had a hard time understanding the intensity of the self-denial that governed his life. His father and sister blamed his breakdown on abuse that Chris had suffered as a child; they believed his desire to escape society was a projection, an act of taking responsibility for something that wasn’t his fault. But Chris had a different explanation. When he was fifteen, his father had taken him and his sister on a trip to Mount St. Helens. Halfway up the mountain, they had passed clear-cut land. As Chris recalls, one moment there was only evergreen forest and the next moment there was nothing—just bare ground and stumps as far as he could see. A word came to his mind: <em>evil</em>…“They made it sound like I had a psychosis or a mental breakdown and that this is just the form it took, when really, shouldn’t anyone who is ethical and compassionate also choose to opt out of this society?”</p><p>…I was working fifty-hour weeks, mostly unpaid. My mother, concerned, suggested that I take a break. But I refused. There was no pause button on climate change, so why should I get a break? On some days, Salt Lake City, where I lived, had exceptionally bad air quality, a thick soup of pollution settling between the mountains and the valley. The corridor between Salt Lake and Provo, where I’d gone to college, had been completely converted from farmland to strip malls in just ten years. To the south lay one of the biggest open-pit copper mines in the world, to the north was an industrial warren of refineries, and to the west was nuclear waste buried in clay-sealed chambers, reeking of death. That was just the local stuff. Coral reefs were collapsing, ocean ecosystems were overfished, and people in island nations were trapped between salted well water and the swallowing sea. Meanwhile, everyone around me was fine…Sometimes I could do it. Other times I got combative, desperate, contrary. Meanwhile, Chris got married and had two children. When we hung out, he was happier. But he was different too. In his purist days, he’d let his lawn go to seed, refusing to use scarce water resources to keep it green. Now he was living in the suburbs, putting in Kentucky bluegrass. “Why don’t you just keep your lawn the way it was?” I said, too urgently. “Because I’ve been sad my whole life,” Chris said, “and sometimes I just want to sit on my green lawn with my wife and feel love.” I knew it was just a lawn, but it upset me anyway.</p><p>…I quit climate activism for a time, but I’ve kept going to therapy, and I keep confusing my therapists by talking about the end of the world. As it turns out, I’m not alone. A report released in 2012 by the National Wildlife Federation warned that climate change is creating a mental health crisis. The climate scientists, psychologists, and policy experts who authored the study estimated that two hundred million Americans will suffer from mental illness as a result of natural disasters, droughts, heat waves, and economic downturn. Recent disasters bear this out. In the wake of Hurricane Maria, Puerto Rico’s worst natural disaster on record, there was a 7% spike in PTSD among the children who survived. In the year after Hurricane Katrina, the suicide rate in New Orleans tripled, and the number of instances of depression and PTSD grew to what health experts described as near-epidemic levels. Even people who aren’t directly impacted by climate disasters can be affected. According to a 2017 report by the American Psychological Association, merely acknowledging the reality of climate change and its consequences can trigger chronic fear, fatalism, anger, and exhaustion—a condition that psychologists are increasingly referring to as eco-anxiety. Eco-anxiety can manifest in other serious ways. In 2008, in the midst of a severe drought in Australia, a seventeen-year-old boy refused to drink water because he was afraid that doing so would lead to the deaths of millions of people. Doctors diagnosed him with “climate delusion” and prescribed antidepressants. When they asked him why he took such drastic action, he said he felt guilty….Greta Thunberg, a sixteen-year-old Swedish girl who inspired the growing student climate strike movement, says that learning about climate change—and seeing adults’ inaction—contributed to a severe depression during which she stopped eating and drinking…other activists are turning the violence of climate change on themselves—like David Buckel, a human rights lawyer who in 2018 lit himself on fire in Prospect Park, in Brooklyn, to call attention to the scale of the climate plight…Quante told me that one of her earliest memories was learning that so many things around her were alive—the trees, the grass, the frogs. It terrified her to realize the harm she was capable of. One day, after it had rained, her mother made her walk along a worm-strewn sidewalk, and she screamed as she was dragged along. “We’re killing them!” she said. “We’re killing them!”…Van Susteren started having trouble sleeping. After getting into bed and closing her eyes, she would be ambushed by intrusive images. She would see refugees surrounded by barbed wire, animals trapped in the path of a hurricane, people stranded in floodwaters. The worst image was of a child. It wasn’t any child she knew, but a sort of representative for all children. The child looked at Van Susteren and asked the same question again and again: “Why didn’t you do anything?” As a psychiatrist, Van Susteren recognized her symptoms. The stress, the insomnia, the intrusive thoughts—they read like PTSD. And yet the trauma she was imagining hadn’t happened yet, or at least it hadn’t happened to her…Van Susteren coined a new term for her condition: <em>pre-traumatic stress disorder</em>…In the back of the class, a student started crying. “If I didn’t have hope, how could I live?” she asked.</p><p>…Robert Salo, the doctor who diagnosed the Australian boy with climate psychosis, was careful to note the boy’s other symptoms (long-term depression, suicidal thoughts, and hearing voices) and the disproportionate sense of importance he placed on his own actions (believing that his own small water usage would lead to widespread deaths). Other critics have pointed out that climate delusion usually afflicts people who already suffer from other mental health maladies, and that the triggers for psychotic episodes generally take the form of the dominant political or cultural issues of the time, from nuclear holocaust to Cold War–era fears about the spread of communism.</p>'
- - https://www.theeagle.com/news/local/cc-world-s-first-cloned-cat-turns-years-old/article_d2aeac6e-2471-11ea-a5f2-7b6c21b2b4b4.html
  - "CC, world’s first cloned cat, turns 18 years old"
  - Chelsea Katz (The Eagle)
  - 2020-01-02
  - ''
  - ! '<p>The first of her kind, CC the cloned cat is breaking more boundaries as she turns 18 years old. There are no big plans locally to mark the day, but CC—Carbon Copy or Copy Cat—will be the focus of a Dutch cartoon set for release today to celebrate her birthday, researcher and owner Duane Kraemer said. </p> <p>...CC is not only enjoying life as the Kraemers’ pet, but she has her own condo called the “kitty house” behind the Kraemers’ house where she lives with her three offspring, sired by a cat named Smokey. Those offspring, just by existing, helped CC make headlines in the scientific community. There had not been much research done in the reproduction success of clones—and none had been done with a cat. Tim, Zip and Tess were born Sept. 1, 2006, along with a fourth kitten that was stillborn. Not knowing CC’s reaction would be to her kittens, Kraemer said, they found CC was “the perfect mother” and had the innate maternal instincts they were hoping she would exhibit. Besides proving clones can successfully reproduce, CC also proved not all clones die young. “Dolly the sheep, that was the first of the mammals to be cloned by nuclear transfer, had died at, I think, at 6 years of age,” Kraemer said. “So the fact that CC didn’t die young was news.” About 20% of cloned animals have developmental abnormalities of some kind, he said, with some being serious enough to result in the animal’s death at a young age or at birth. However, the other 80% born without those conditions “would probably live to a normal variation of ages.”</p>'
- - https://samizdat.co/me/
  - "Me"
  - Christian Swinehart
  - ''
  - ''
  - ! '<p>Christian Swinehart is a graphic designer, software developer, and data artist. His practice focuses on interaction and user interface design with a specialty in data visualization. He is the founder and principal of Samizdat Drafting Co. and is an active participant in the open-source world as the author of the <a href="http://plotdevice.io">PlotDevice</a> and <a href="http://arborjs.org">Arbor.js</a> visualization tools.</p><p>Christian’s work is informed by a background in biology and computational modeling. His projects frequently employ simulation and numerical analysis as a means to communicate the structure within complex systems. Recent clients include The New York Times, Bloomberg, Gallup, Pentagram, Diller Scofidio + Renfro, and Allied Works Architects.</p><p>Degrees Held:</p><ul><li>MFA | Graphic Design (RISD, 2008)</li><li>Ph.D. | Computational Neuroscience (Brandeis University, 2005)</li><li>BS | Cognitive Science (Dickinson College, 1998)</li></ul>'
- - /docs/psychology/2019-forscher.pdf
  - "A Meta-Analysis of Procedures to Change Implicit Measures"
  - Patrick Forscher, Calvin Lai, Jordan Axt, Charles Ebersole, Michelle Herman, Patricia Devine, Brian Nosek
  - 2019-08-19
  - 10.1037/pspa0000160
  - ! 'Using a novel technique known as network meta-analysis, we synthesized evidence from 492 studies (87,418 participants) to investigate the effectiveness of procedures in changing implicit measures, which we define as response biases on implicit tasks. We also evaluated these procedures’ effects on explicit and behavioral measures. We found that implicit measures can be changed, but effects are often relatively weak (|ds| < .30). Most studies focused on producing short-term changes with brief, single-session manipulations. Procedures that associate sets of concepts, invoke goals or motivations, or tax mental resources changed implicit measures the most, whereas procedures that induced threat, affirmation, or specific moods/emotions changed implicit measures the least. Bias tests suggested that implicit effects could be inflated relative to their true population values. Procedures changed explicit measures less consistently and to a smaller degree than implicit measures and generally produced trivial changes in behavior. Finally, changes in implicit measures did not mediate changes in explicit measures or behavior. Our findings suggest that changes in implicit measures are possible, but those changes do not necessarily translate into changes in explicit measures or behavior.'
- - /docs/sociology/2019-kristal.pdf
  - "What we can learn from five naturalistic field experiments that failed to shift commuter behaviour"
  - Ariella S. Kristal, Ashley V. Whillans
  - 2019-12-23
  - 10.1038/s41562-019-0795-z
  - ! '<p>Across five field experiments with employees of a large organization (<em>n</em> = 68,915), we examined whether standard behavioural interventions (‘nudges’) successfully reduced single-occupancy vehicle commutes. In Studies  1 and 2, we sent letters and emails with nudges designed to increase carpooling. These interventions failed to increase carpool sign-up or usage. In Studies  3a and 4, we examined the efficacy of other well-established behavioural interventions: non-cash incentives and personalized travel plans. Again, we found no positive effect of these interventions. Across studies, effect sizes ranged from Cohen’s <em>d</em> = −0.01 to <em>d</em> = 0.05. Equivalence testing, using study-specific smallest effect sizes of interest, revealed that the treatment effects observed in 4 out of 5 of our experiments were statistically equivalent to zero (<em>P</em> &lt; 0.04). The failure of these well-powered experiments designed to nudge commuting behaviour highlights both the difficulty of changing commuter behaviour and the importance of publishing null results to build cumulative knowledge about how to encourage sustainable travel.</p>'
- - /docs/anime/2019-ye.pdf
  - "Interactive Anime Sketch Colorization with Style Consistency via a Deep Residual Neural Network"
  - Ru-Ting Ye, Wei-Li Wang, Ju-Chin Chen, Kawuu W. Lin
  - 2019-11-21
  - 10.1109/taai48200.2019.8959911
  - ! "Anime line sketch colorization is to fill a variety of colors the anime sketch, to make it colorful and diverse. The coloring problem is not a new research direction in the field of deep learning technology. Because of coloring of the anime sketch does not have fixed color and we can't take texture or shadow as reference, so it is difficult to learn and have a certain standard to determine whether it is correct or not. After generative adversarial networks (GANs) was proposed, some used GANs to do coloring research, achieved some result, but the coloring effect is limited. This study proposes a method use deep residual network, and adding discriminator to network, that expect the color of colored images can consistent with the desired color by the user and can achieve good coloring results."
- - https://pure.tue.nl/ws/portalfiles/portal/142614149/J.R.Ubbink_09_09_2019_thesis_final.pdf
  - Characterization of illegal dark web arms markets
  - J. R. Ubbink
  - 2019-09
  - ''
  - ! '<p>The nature of online underground gun markets on the dark web has been relatively under-researched in comparison to those regarding drugs or malware. This work attempts to improve the general understanding of the nature of these markets, with a longitudinal assessment of the market as a whole. From this assessment, the various properties that characterize the market such as overall sales and the breadth of items on offer can be catalogued and compared against offline markets, or other online markets.</p><p>In addition to this longitudinal study, the online communities surrounding the sale of firearms were identified, with topic models fit to the datasets spanning approximately five years, with the intent of characterizing and comparing them to each other in a more structured manner. Once the topic models were generated, documents were drawn from before and after mass shooting attacks. These documents were then labeled by the separate topic models, and then contrasted and compared against each other in order to assess the reactions of these communities to traumatic events, thus observing if there were clear patterns of behavior universal across these communities.</p><p>Online underground arms markets were found to be generally thin, albeit larger in scale than a few years before, and appear to be predominantly focused on the sale of rifles, pistols, and custom orders. Gun communities online were observed to differ depending on the strictness of moderation of their parent communities, though still have a number of shared topics, such as gun legislation or usage. Furthermore, the assessed communities varied heavily in their reactions to attacks, further highlighting their differences.</p>'
